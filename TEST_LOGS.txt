========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 38 items

kornia/geometry/test_conversions.py ......................................                                                                                                                       [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
=================================================================================== 38 passed in 1872.66s (0:31:12) ====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 2 items

kornia/geometry/test_boxes.py FF                                                                                                                                                                 [100%]

=============================================================================================== FAILURES ===============================================================================================
___________________________________________________________________________________ test_Boxes[tensorflow-s2s-False] ___________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_Boxes(target_framework, mode, backend_compile):
        print("kornia.geometry.boxes.Boxes")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledBoxes = ivy.transpile(kornia.geometry.boxes.Boxes, source="torch", target=target_framework)
    
        torch_args = (
            torch.as_tensor([[0, 3, 1, 4], [5, 1, 8, 4]]),
        )
        transpiled_args = _nest_torch_tensor_to_new_framework(torch_args, target_framework)
    
        # test .from_tensor
        torch_boxes = kornia.geometry.boxes.Boxes.from_tensor(*torch_args, mode="xyxy")
        transpiled_boxes = TranspiledBoxes.from_tensor(*transpiled_args, mode="xyxy")
        _check_boxes_same(torch_boxes, transpiled_boxes)
    
        # test .compute_area
        torch_area = torch_boxes.compute_area()
        transpiled_area = transpiled_boxes.compute_area()
        _to_numpy_and_allclose(torch_area, transpiled_area)
    
        # test .get_boxes_shape
        torch_heights, torch_widths = torch_boxes.get_boxes_shape()
        transpiled_heights, transpiled_widths = transpiled_boxes.get_boxes_shape()
        _to_numpy_and_allclose(torch_heights, transpiled_heights)
        _to_numpy_and_allclose(torch_widths, transpiled_widths)
    
        # test .merge
        torch_x = torch.as_tensor([[6, 6, 10, 10], [6, 6, 10, 10]])
        transpiled_x = _nest_torch_tensor_to_new_framework(torch_x, target_framework)
        merge_boxes = kornia.geometry.boxes.Boxes.from_tensor(torch_x, mode="xyxy")
        transpiled_merge_boxes = TranspiledBoxes.from_tensor(transpiled_x, mode="xyxy")
        torch_merged_boxes = torch_boxes.merge(merge_boxes)
        transpiled_merged_boxes = transpiled_boxes.merge(transpiled_merge_boxes)
        _check_boxes_same(torch_merged_boxes, transpiled_merged_boxes)
    
        # test .to_mask
        height, width = 10, 10
        torch_mask = torch_boxes.to_mask(height, width)
        transpiled_mask = transpiled_boxes.to_mask(height, width)
>       _to_numpy_and_allclose(torch_mask, transpiled_mask)

kornia/geometry/test_boxes.py:70: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

torch_x = tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0....., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]])
transpiled_x = <tf.Tensor: shape=(2, 10, 10), dtype=float32, numpy=
array([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0....,
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]], dtype=float32)>
tolerance = 0.001

    def _to_numpy_and_allclose(torch_x, transpiled_x, tolerance=1e-3):
        orig_data = _nest_array_to_numpy(torch_x)
        transpiled_data = _nest_array_to_numpy(transpiled_x)
>       _check_allclose(orig_data, transpiled_data, tolerance=tolerance)

helpers.py:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0...],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]], dtype=float32)
y = array([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0...],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]], dtype=float32)
tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
>           assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
E           AssertionError: numpy array values are not all close

helpers.py:26: AssertionError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.boxes.Boxes
__________________________________________________________________________________ test_Boxes3D[tensorflow-s2s-False] __________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_Boxes3D(target_framework, mode, backend_compile):
        print("kornia.geometry.boxes.Boxes3D")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledBoxes3D = ivy.transpile(kornia.geometry.boxes.Boxes3D, source="torch", target=target_framework)
    
        torch_args = (
            torch.as_tensor([[0, 3, 6, 1, 4, 8], [5, 1, 3, 8, 4, 9]]),
        )
        transpiled_args = _nest_torch_tensor_to_new_framework(torch_args, target_framework)
    
        # test .from_tensor
        torch_boxes3d = kornia.geometry.boxes.Boxes3D.from_tensor(*torch_args, mode="xyzxyz")
        transpiled_boxes3d = TranspiledBoxes3D.from_tensor(*transpiled_args, mode="xyzxyz")
        _check_boxes_same(torch_boxes3d, transpiled_boxes3d)
    
        # test .get_boxes_shape
        torch_depths, torch_heights, torch_widths = torch_boxes3d.get_boxes_shape()
        transpiled_depths, transpiled_heights, transpiled_widths = transpiled_boxes3d.get_boxes_shape()
        _to_numpy_and_allclose(torch_depths, transpiled_depths)
        _to_numpy_and_allclose(torch_heights, transpiled_heights)
        _to_numpy_and_allclose(torch_widths, transpiled_widths)
    
        # test .to_mask
        depth, height, width = 10, 10, 10
        torch_mask = torch_boxes3d.to_mask(depth, height, width)
        transpiled_mask = transpiled_boxes3d.to_mask(depth, height, width)
>       _to_numpy_and_allclose(torch_mask, transpiled_mask)

kornia/geometry/test_boxes.py:121: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

torch_x = tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0... [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]]]])
transpiled_x = <tf.Tensor: shape=(2, 10, 10, 10), dtype=float32, numpy=
array([[[[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0.,...., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]]]], dtype=float32)>
tolerance = 0.001

    def _to_numpy_and_allclose(torch_x, transpiled_x, tolerance=1e-3):
        orig_data = _nest_array_to_numpy(torch_x)
        transpiled_data = _nest_array_to_numpy(transpiled_x)
>       _check_allclose(orig_data, transpiled_data, tolerance=tolerance)

helpers.py:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]...0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]]]], dtype=float32)
y = array([[[[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]...0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]]]], dtype=float32)
tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
>           assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
E           AssertionError: numpy array values are not all close

helpers.py:26: AssertionError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.boxes.Boxes3D
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/geometry/test_boxes.py::test_Boxes[tensorflow-s2s-False] - AssertionError: numpy array values are not all close
FAILED kornia/geometry/test_boxes.py::test_Boxes3D[tensorflow-s2s-False] - AssertionError: numpy array values are not all close
==================================================================================== 2 failed in 241.70s (0:04:01) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 1 item

kornia/geometry/test_quaternion.py .                                                                                                                                                             [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
===================================================================================== 1 passed in 95.89s (0:01:35) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 5 items

kornia/geometry/test_calibration.py ....F                                                                                                                                                        [100%]

=============================================================================================== FAILURES ===============================================================================================
__________________________________________________________________________________ test_solve_pnp_dlt[jax-s2s-False] ___________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_solve_pnp_dlt(target_framework, mode, backend_compile):
        trace_args = (
            torch.tensor([[
                [5.0, -5.0, 0.0], [0.0, 0.0, 1.5],
                [2.5, 3.0, 6.0], [9.0, -2.0, 3.0],
                [-4.0, 5.0, 2.0], [-5.0, 5.0, 1.0]
            ]], dtype=torch.float64),
            torch.tensor([[
                [1409.1504, -800.936], [407.0207, -182.1229],
                [392.7021, 177.9428], [1016.838, -2.9416],
                [-63.1116, 142.9204], [-219.3874, 99.666]
            ]], dtype=torch.float64),
            torch.tensor([[
                [500.0, 0.0, 250.0],
                [0.0, 500.0, 250.0],
                [0.0, 0.0, 1.0]
            ]], dtype=torch.float64),
        )
        trace_kwargs = {'svd_eps': 1e-3}
        test_args = (
            torch.tensor([[
                [10.0, -10.0, 0.0], [0.0, 0.0, 3.0],
                [5.0, 6.0, 12.0], [18.0, -4.0, 6.0],
                [-8.0, 10.0, 4.0], [-10.0, 10.0, 2.0]
            ]], dtype=torch.float64),
            torch.tensor([[
                [2818.3008, -1601.872], [814.0414, -364.2458],
                [785.4042, 355.8856], [2033.676, -5.8832],
                [-126.2232, 285.8408], [-438.7748, 199.332]
            ]], dtype=torch.float64),
            torch.tensor([[
                [1000.0, 0.0, 500.0],
                [0.0, 1000.0, 500.0],
                [0.0, 0.0, 1.0]
            ]], dtype=torch.float64),
        )
        test_kwargs = {'svd_eps': 1e-3}
>       _test_function(
            kornia.geometry.calibration.solve_pnp_dlt,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/geometry/test_calibration.py:148: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function solve_pnp_dlt at 0x7fe557ab2950>
trace_args = (tensor([[[ 5.0000, -5.0000,  0.0000],
         [ 0.0000,  0.0000,  1.5000],
         [ 2.5000,  3.0000,  6.0000],
   ...loat64), tensor([[[500.,   0., 250.],
         [  0., 500., 250.],
         [  0.,   0.,   1.]]], dtype=torch.float64))
trace_kwargs = {'svd_eps': 0.001}
test_args = (tensor([[[ 10., -10.,   0.],
         [  0.,   0.,   3.],
         [  5.,   6.,  12.],
         [ 18.,  -4.,   6.],
 ...tensor([[[1000.,    0.,  500.],
         [   0., 1000.,  500.],
         [   0.,    0.,    1.]]], dtype=torch.float64))
test_kwargs = {'svd_eps': 0.001}, target = 'jax', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function solve_pnp_dlt at 0x7fe557ab2950>, fn_name = 'kornia.geometry.calibration.solve_pnp_dlt'
trace_args = (tensor([[[ 5.0000, -5.0000,  0.0000],
         [ 0.0000,  0.0000,  1.5000],
         [ 2.5000,  3.0000,  6.0000],
   ...loat64), tensor([[[500.,   0., 250.],
         [  0., 500., 250.],
         [  0.,   0.,   1.]]], dtype=torch.float64))
trace_kwargs = {'svd_eps': 0.001}
test_args = (tensor([[[ 10., -10.,   0.],
         [  0.,   0.,   3.],
         [  5.,   6.,  12.],
         [ 18.,  -4.,   6.],
 ...tensor([[[1000.,    0.,  500.],
         [   0., 1000.,  500.],
         [   0.,    0.,    1.]]], dtype=torch.float64))
test_kwargs = {'svd_eps': 0.001}, target = 'jax', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

world_points = Array([[[ 5. , -5. ,  0. ],
        [ 0. ,  0. ,  1.5],
        [ 2.5,  3. ,  6. ],
        [ 9. , -2. ,  3. ],
        [-4. ,  5. ,  2. ],
        [-5. ,  5. ,  1. ]]], dtype=float64)
img_points = Array([[[1409.1504, -800.936 ],
        [ 407.0207, -182.1229],
        [ 392.7021,  177.9428],
        [1016.838 ,   -2.9416],
        [ -63.1116,  142.9204],
        [-219.3874,   99.666 ]]], dtype=float64)
intrinsics = Array([[[500.,   0., 250.],
        [  0., 500., 250.],
        [  0.,   0.,   1.]]], dtype=float64), weights = None, svd_eps = 0.001

    def jax_solve_pnp_dlt(
        world_points, img_points, intrinsics, weights=None, svd_eps=0.0001
    ):
        from ....ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ...utils.helpers import jax__torch_linalg_svdvals
        from ....ivy.functional.frontends.torch.reduction_ops import jax_any_frnt
        from ....ivy.functional.frontends.torch.blas_and_lapack_ops import jax_inverse_frnt
        from ..conversions import jax_convert_points_to_homogeneous
        from ..linalg import jax_transform_points
        from ....ivy.functional.backends.jax.general import jax_set_item
        from ....ivy.functional.frontends.torch.blas_and_lapack_ops import (
            jax_svd_frnt_base_count_1_frnt,
        )
        from ....ivy.functional.frontends.torch.tensor import jax_reshape_frnt_
        from ...utils.misc import jax_eye_like
        from ....ivy.functional.frontends.torch.blas_and_lapack_ops import jax_bmm_frnt
        from ....ivy.functional.frontends.torch.blas_and_lapack_ops import jax_det_frnt
        from ....ivy.functional.frontends.torch.reduction_ops import jax_norm_frnt
        from ....ivy.functional.frontends.torch.linalg import jax_qr_frnt
        from ....ivy.functional.frontends.torch.pointwise_ops import jax_sign_frnt
        from ....ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            jax_cat_frnt,
        )
        from ...core._backend import zeros
        from ...core._backend import ones_like
        from ...core._backend import where
    
        if not isinstance(world_points, (jax.Array, nnx.Param)):
            raise AssertionError(
                f"world_points is not an instance of torch.Tensor. Type of world_points is {type(world_points)}"
            )
        if not isinstance(img_points, (jax.Array, nnx.Param)):
            raise AssertionError(
                f"img_points is not an instance of torch.Tensor. Type of img_points is {type(img_points)}"
            )
        if not isinstance(intrinsics, (jax.Array, nnx.Param)):
            raise AssertionError(
                f"intrinsics is not an instance of torch.Tensor. Type of intrinsics is {type(intrinsics)}"
            )
        if weights is not None and not isinstance(weights, (jax.Array, nnx.Param)):
            raise AssertionError(
                f"If weights is not None, then weights should be an instance of torch.Tensor. Type of weights is {type(weights)}"
            )
        if not isinstance(svd_eps, (float,)):
            raise AssertionError(f"Type of svd_eps is not float. Got {type(svd_eps)}")
        accepted_dtypes = jnp.float32, jnp.float64
        if world_points.dtype not in accepted_dtypes:
            raise AssertionError(
                f"world_points must have one of the following dtypes {accepted_dtypes}. Currently it has {world_points.dtype}."
            )
        if img_points.dtype not in accepted_dtypes:
            raise AssertionError(
                f"img_points must have one of the following dtypes {accepted_dtypes}. Currently it has {img_points.dtype}."
            )
        if intrinsics.dtype not in accepted_dtypes:
            raise AssertionError(
                f"intrinsics must have one of the following dtypes {accepted_dtypes}. Currently it has {intrinsics.dtype}."
            )
        if len(jax_shape_frnt_(world_points)) != 3 or jax_shape_frnt_(world_points)[2] != 3:
            raise AssertionError(
                f"world_points must be of shape (B, N, 3). Got shape {jax_shape_frnt_(world_points)}."
            )
        if len(jax_shape_frnt_(img_points)) != 3 or jax_shape_frnt_(img_points)[2] != 2:
            raise AssertionError(
                f"img_points must be of shape (B, N, 2). Got shape {jax_shape_frnt_(img_points)}."
            )
        if len(jax_shape_frnt_(intrinsics)) != 3 or jax_shape_frnt_(intrinsics)[1:] != (
            3,
            3,
        ):
            raise AssertionError(
                f"intrinsics must be of shape (B, 3, 3). Got shape {jax_shape_frnt_(intrinsics)}."
            )
        if jax_shape_frnt_(world_points)[1] != jax_shape_frnt_(img_points)[1]:
            raise AssertionError(
                "world_points and img_points must have equal number of points."
            )
        if (
            jax_shape_frnt_(world_points)[0] != jax_shape_frnt_(img_points)[0]
            or jax_shape_frnt_(world_points)[0] != jax_shape_frnt_(intrinsics)[0]
        ):
            raise AssertionError(
                "world_points, img_points and intrinsics must have the same batch size."
            )
        if jax_shape_frnt_(world_points)[1] < 6:
            raise AssertionError(
                f"At least 6 points are required to use this function. Got {jax_shape_frnt_(world_points)[1]} points."
            )
        B, N = jax_shape_frnt_(world_points)[:2][0], jax_shape_frnt_(world_points)[:2][1]
        world_points_norm, world_transform_norm = jax__mean_isotropic_scale_normalize(
            world_points
        )
        s = jax__torch_linalg_svdvals(world_points_norm)
        if jax_any_frnt(s[:, -1] < svd_eps):
            raise AssertionError(
                f"The last singular value of one/more of the elements of the batch is smaller than {svd_eps}. This function cannot be used if all world_points (of any element of the batch) lie on a line or if all world_points (of any element of the batch) lie on a plane."
            )
        intrinsics_inv = jax_inverse_frnt(intrinsics)
        world_points_norm_h = jax_convert_points_to_homogeneous(world_points_norm)
        img_points_inv = jax_transform_points(intrinsics_inv, img_points)
        img_points_norm, img_transform_norm = jax__mean_isotropic_scale_normalize(
            img_points_inv
        )
        inv_img_transform_norm = jax_inverse_frnt(img_transform_norm)
        system = zeros((B, 2 * N, 12), dtype=world_points.dtype, device=world_points.device)
        system = jax_set_item(
            system,
            (slice(None, None, None), slice(0, None, 2), slice(0, 4, None)),
            world_points_norm_h,
        )
        system = jax_set_item(
            system,
            (slice(None, None, None), slice(1, None, 2), slice(4, 8, None)),
            world_points_norm_h,
        )
        system = jax_set_item(
            system,
            (slice(None, None, None), slice(0, None, 2), slice(8, 12, None)),
            world_points_norm_h * -1 * img_points_norm[..., 0:1],
        )
        system = jax_set_item(
            system,
            (slice(None, None, None), slice(1, None, 2), slice(8, 12, None)),
            world_points_norm_h * -1 * img_points_norm[..., 1:2],
        )
        _, _, v = jax_svd_frnt_base_count_1_frnt(system)
        solution = v[..., -1]
        solution = jax_reshape_frnt_(solution, B, 3, 4)
        solution_4x4 = jax_eye_like(4, solution)
        solution_4x4 = jax_set_item(
            solution_4x4,
            (slice(None, None, None), slice(None, 3, None), slice(None, None, None)),
            solution,
        )
        intermediate = jax_bmm_frnt(solution_4x4, world_transform_norm)
        solution = jax_bmm_frnt(inv_img_transform_norm, intermediate[:, :3, :])
        det = jax_det_frnt(solution[:, :3, :3])
        ones = ones_like(det)
        sign_fix = where(det < 0, ones * -1, ones)
        solution = solution * sign_fix[:, None, None]
>       norm_col = jax_norm_frnt(input=solution[:, :3, 0], p=2, dim=1)

ivy_transpiled_outputs/jax_outputs/kornia/geometry/calibration/pnp.py:217: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (), kwargs = {'dim': 1, 'input': Array([[0.0754885 , 0.02388222, 0.0574928 ]], dtype=float64), 'p': 2}, jax_is_array_bknd = <function jax_is_array_bknd at 0x7fe4bec10280>

    @functools.wraps(fn)
    def wrapper(*args, **kwargs):
        from ..functional.ivy.general import jax_is_array_bknd
    
>       array_like = args[0]
E       IndexError: tuple index out of range

ivy_transpiled_outputs/jax_outputs/ivy/utils/decorator_utils.py:193: IndexError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.calibration.pnp.solve_pnp_dlt
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/geometry/test_calibration.py::test_solve_pnp_dlt[jax-s2s-False] - IndexError: tuple index out of range
=============================================================================== 1 failed, 4 passed in 317.43s (0:05:17) ================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 1 item

kornia/geometry/test_quaternion.py s                                                                                                                                                             [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
========================================================================================== 1 skipped in 5.01s ==========================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 5 items

kornia/test_x.py sssss                                                                                                                                                                           [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
========================================================================================== 5 skipped in 5.03s ==========================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 19 items

kornia/test_feature1.py ...................                                                                                                                                                      [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
=================================================================================== 19 passed in 1486.89s (0:24:46) ====================================================================================


========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 8 items

kornia/geometry/test_bbox.py ........                                                                                                                                                            [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
==================================================================================== 8 passed in 481.76s (0:08:01) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 13 items

kornia/test_feature3.py .........F...                                                                                                                                                            [100%]

=============================================================================================== FAILURES ===============================================================================================
____________________________________________________________________________ test_ScaleSpaceDetector[tensorflow-s2s-False] _____________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_ScaleSpaceDetector(target_framework, mode, backend_compile):
        print("kornia.feature.ScaleSpaceDetector")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledScaleSpaceDetector = ivy.transpile(kornia.feature.ScaleSpaceDetector, source="torch", target=target_framework)
    
        x = torch.rand(1, 1, 32, 32) * 10.
        transpiled_x = _nest_torch_tensor_to_new_framework(x, target_framework)
    
        model = kornia.feature.ScaleSpaceDetector()
        torch_out = model(x)
    
        transpiled_model = TranspiledScaleSpaceDetector()
        if target_framework == "tensorflow":
            # build the layers
>           transpiled_model(transpiled_x)

kornia/test_feature3.py:200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_ScaleSpaceDetector(num_features=500, mr_size=6.0, scale_pyr=tensorflow_ScalePyramid(n_levels=3, init_sigma=...ates=False, eps=1e-08, strict_maxima_bonus=0.0, output_value=True), ori=tensorflow_PassLAF(), aff=tensorflow_PassLAF())
args = (<tf.Tensor: shape=(1, 1, 32, 32), dtype=float32, numpy=
array([[[[6.8718762 , 0.7105458 , 3.7422621 , ..., 4.588311  ...
         [6.9055862 , 1.65896   , 2.9007971 , ..., 6.26267   ,
          3.4714603 , 1.1476839 ]]]], dtype=float32)>,)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x7f25fa2b1f10, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...ode_context=['        return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_ScaleSpaceDetector(num_features=500, mr_size=6.0, scale_pyr=tensorflow_ScalePyramid(n_levels=3, init_sigma...,
         [6.9055862 , 1.65896   , 2.9007971 , ..., 6.26267   ,
          3.4714603 , 1.1476839 ]]]], dtype=float32)>)
kwargs = {}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_ScaleSpaceDetector(num_features=500, mr_size=6.0, scale_pyr=tensorflow_ScalePyramid(n_levels=3, init_sigma=...ates=False, eps=1e-08, strict_maxima_bonus=0.0, output_value=True), ori=tensorflow_PassLAF(), aff=tensorflow_PassLAF())
v = None, buffers = None
args = (<tf.Tensor: shape=(1, 1, 32, 32), dtype=float32, numpy=
array([[[[6.8718762 , 0.7105458 , 3.7422621 , ..., 4.588311  ...
         [6.9055862 , 1.65896   , 2.9007971 , ..., 6.26267   ,
          3.4714603 , 1.1476839 ]]]], dtype=float32)>,)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:2013: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_ScaleSpaceDetector(num_features=500, mr_size=6.0, scale_pyr=tensorflow_ScalePyramid(n_levels=3, init_sigma...,
         [6.9055862 , 1.65896   , 2.9007971 , ..., 6.26267   ,
          3.4714603 , 1.1476839 ]]]], dtype=float32)>)
kwargs = {'buffers': None, 'v': None}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_ScaleSpaceDetector(num_features=500, mr_size=6.0, scale_pyr=tensorflow_ScalePyramid(n_levels=3, init_sigma=...ates=False, eps=1e-08, strict_maxima_bonus=0.0, output_value=True), ori=tensorflow_PassLAF(), aff=tensorflow_PassLAF())
v = None, buffers = None
args = (<tf.Tensor: shape=(1, 1, 32, 32), dtype=float32, numpy=
array([[[[6.8718762 , 0.7105458 , 3.7422621 , ..., 4.588311  ...
         [6.9055862 , 1.65896   , 2.9007971 , ..., 6.26267   ,
          3.4714603 , 1.1476839 ]]]], dtype=float32)>,)
kwargs = {}
first_arr = <tf.Tensor: shape=(1, 1, 32, 32), dtype=float32, numpy=
array([[[[6.8718762 , 0.7105458 , 3.7422621 , ..., 4.588311  ,...],
         [6.9055862 , 1.65896   , 2.9007971 , ..., 6.26267   ,
          3.4714603 , 1.1476839 ]]]], dtype=float32)>
replace_v = False, replace_buffers = False, call_signature = <Signature (img, mask=None)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Model, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Model, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Model, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1783: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_ScaleSpaceDetector(num_features=500, mr_size=6.0, scale_pyr=tensorflow_ScalePyramid(n_levels=3, init_sigma...es=False, eps=1e-08, strict_maxima_bonus=0.0, output_value=True), ori=tensorflow_PassLAF(), aff=tensorflow_PassLAF()),)
kwargs = {'img': <tf.Tensor: shape=(1, 1, 32, 32), dtype=float32, numpy=
array([[[[6.8718762 , 0.7105458 , 3.7422621 , ..., 4.5...,
         [6.9055862 , 1.65896   , 2.9007971 , ..., 6.26267   ,
          3.4714603 , 1.1476839 ]]]], dtype=float32)>}

    @wraps(fn)
    def error_handler(*args, **kwargs):
        if not is_traceback_filtering_enabled():
            return fn(*args, **kwargs)
    
        filtered_tb = None
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            filtered_tb = _process_traceback_frames(e.__traceback__)
            # To get the full stack trace, call:
            # `keras.config.disable_traceback_filtering()`
>           raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/keras/src/utils/traceback_utils.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_ScaleSpaceDetector(num_features=500, mr_size=6.0, scale_pyr=tensorflow_ScalePyramid(n_levels=3, init_sigma=...ates=False, eps=1e-08, strict_maxima_bonus=0.0, output_value=True), ori=tensorflow_PassLAF(), aff=tensorflow_PassLAF())
img = <tf.Tensor: shape=(1, 1, 32, 32), dtype=float32, numpy=
array([[[[6.8718762 , 0.7105458 , 3.7422621 , ..., 4.588311  ,...],
         [6.9055862 , 1.65896   , 2.9007971 , ..., 6.26267   ,
          3.4714603 , 1.1476839 ]]]], dtype=float32)>
mask = None

    def call(self, img, mask=None):
>       responses, lafs = self.detect(img, self.num_features, mask)

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/scale_space_detector.py:275: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_ScaleSpaceDetector(num_features=500, mr_size=6.0, scale_pyr=tensorflow_ScalePyramid(n_levels=3, init_sigma=...ates=False, eps=1e-08, strict_maxima_bonus=0.0, output_value=True), ori=tensorflow_PassLAF(), aff=tensorflow_PassLAF())
img = <tf.Tensor: shape=(1, 1, 32, 32), dtype=float32, numpy=
array([[[[6.8718762 , 0.7105458 , 3.7422621 , ..., 4.588311  ,...],
         [6.9055862 , 1.65896   , 2.9007971 , ..., 6.26267   ,
          3.4714603 , 1.1476839 ]]]], dtype=float32)>
num_feats = 500, mask = None

    def detect(self, img, num_feats, mask=None):
        from ...ivy.functional.backends.tensorflow.general import tensorflow_get_item
        from ...ivy.functional.frontends.torch.tensor import tensorflow_size_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_view_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_reshape_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_permute_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_to_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_unsqueeze_frnt_
        from ...ivy.functional.frontends.torch.comparison_ops import (
            tensorflow_topk_frnt,
        )
        from ...ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            tensorflow_gather_frnt,
        )
        from ...ivy.functional.frontends.torch.tensor import tensorflow_repeat_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_item_frnt_
        from .laf import tensorflow_laf_is_inside_image
        from ..core._backend import eye
        from ..core._backend import concatenate
    
        dev: typing.Any = img.device
        dtype: typing.Any = img.dtype
        sigmas: typing.Any
        sp, sigmas, _ = self.scale_pyr(img)
        all_responses: typing.Any = []
        all_lafs: typing.Any = []
        px_size = 0.5 if self.scale_pyr.double_image else 1.0
        for oct_idx, octave in enumerate(sp):
            sigmas_oct = tensorflow_get_item(sigmas, oct_idx)
            B, CH, L, H, W = tensorflow_size_frnt_(octave)
            if self.scale_space_response:
                oct_resp = self.resp(octave, tensorflow_view_frnt_(sigmas_oct, -1))
            else:
                oct_resp = tensorflow_view_frnt_(
                    self.resp(
                        tensorflow_reshape_frnt_(
                            tensorflow_permute_frnt_(octave, 0, 2, 1, 3, 4),
                            B * L,
                            CH,
                            H,
                            W,
                        ),
                        tensorflow_view_frnt_(sigmas_oct, -1),
                    ),
                    B,
                    L,
                    CH,
                    H,
                    W,
                )
                oct_resp = tensorflow_permute_frnt_(oct_resp, 0, 2, 1, 3, 4)
                if (
                    isinstance(
                        self.scale_pyr.extra_levels,
                        (tensorflow.Tensor, tensorflow.Variable),
                    )
                    and self.scale_pyr.extra_levels % 2 != 0
                ):
                    oct_resp = oct_resp[:, :, :-1]
            if mask is not None:
                oct_mask: typing.Any = tensorflow__create_octave_mask(
                    mask, tensorflow_shape_frnt_(oct_resp)
                )
                oct_resp = oct_mask * oct_resp
            coord_max: typing.Any
            response_max: typing.Any
            coord_max, response_max = self.nms(oct_resp)
            if self.minima_are_also_good:
                coord_min, response_min = self.nms(-oct_resp)
                take_min_mask = tensorflow_to_frnt_(
                    response_min > response_max, response_max.dtype
                )
                response_max = (
                    response_min * take_min_mask + (1 - take_min_mask) * response_max
                )
                coord_max = (
                    coord_min * tensorflow_unsqueeze_frnt_(take_min_mask, 2)
                    + (1 - tensorflow_unsqueeze_frnt_(take_min_mask, 2)) * coord_max
                )
            responses_flatten = tensorflow_view_frnt_(
                response_max, tensorflow_size_frnt_(response_max, 0), -1
            )
            max_coords_flatten = tensorflow_permute_frnt_(
                tensorflow_view_frnt_(
                    coord_max, tensorflow_size_frnt_(response_max, 0), 3, -1
                ),
                0,
                2,
                1,
            )
            if tensorflow_size_frnt_(responses_flatten, 1) > num_feats:
                resp_flat_best, idxs = tensorflow_topk_frnt(
                    responses_flatten, k=num_feats, dim=1
                )
                max_coords_best = tensorflow_gather_frnt(
                    max_coords_flatten,
                    1,
                    tensorflow_repeat_frnt_(
                        tensorflow_unsqueeze_frnt_(idxs, -1), 1, 1, 3
                    ),
                )
            else:
                resp_flat_best = responses_flatten
                max_coords_best = max_coords_flatten
            B, N = tensorflow_size_frnt_(resp_flat_best)
            if isinstance(
                self.scale_pyr.n_levels, (tensorflow.Tensor, tensorflow.Variable)
            ):
                num_levels = int(tensorflow_item_frnt_(self.scale_pyr.n_levels))
            elif isinstance(self.scale_pyr.n_levels, (int,)):
                num_levels = self.scale_pyr.n_levels
            else:
                raise TypeError(
                    f"Expected the scale pyramid module to have `n_levels` as a Tensor or int.Gotcha {type(self.scale_pyr.n_levels)}"
                )
            max_coords_best = tensorflow__scale_index_to_scale(
                max_coords_best, sigmas_oct, num_levels
            )
            rotmat = tensorflow_view_frnt_(eye(2, dtype=dtype, device=dev), 1, 1, 2, 2)
            current_lafs = concatenate(
                [
                    self.mr_size
                    * tensorflow_view_frnt_(max_coords_best[:, :, 0], B, N, 1, 1)
                    * rotmat,
                    tensorflow_view_frnt_(max_coords_best[:, :, 1:3], B, N, 2, 1),
                ],
                3,
            )
>           good_mask = tensorflow_laf_is_inside_image(current_lafs, octave[:, 0])

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/scale_space_detector.py:252: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

laf = <tf.Tensor: shape=(1, 500, 2, 3), dtype=float32, numpy=
array([[[[10.764555 ,  0.       , 17.941029 ],
         [ 0.  ...2 ]],

        [[27.125072 ,  0.       ,  2.983759 ],
         [ 0.       , 27.125072 ,  8.998856 ]]]], dtype=float32)>
images = <tf.Tensor: shape=(1, 6, 32, 32), dtype=float32, numpy=
array([[[[4.535638 , 4.475082 , 4.294832 , ..., 4.9686656, 5.2...02652 ],
         [4.864592 , 4.862467 , 4.8562207, ..., 4.8101726, 4.7975063,
          4.7931013]]]], dtype=float32)>
border = 0

    def tensorflow_laf_is_inside_image(laf, images, border=0):
        from ..core.check import tensorflow_KORNIA_CHECK_LAF
        from ...ivy.functional.frontends.torch.tensor import tensorflow_size_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_min_frnt_
    
        tensorflow_KORNIA_CHECK_LAF(laf)
        _, _, h, w = tensorflow_size_frnt_(images)
        pts = tensorflow_laf_to_boundary_points(laf, 12)
        good_lafs_mask = (
>           (pts[..., 0] >= border)
            * (pts[..., 0] <= w - border)
            * (pts[..., 1] >= border)
            * (pts[..., 1] <= h - border)
        )

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/laf.py:105: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <tf.Tensor: shape=(1, 500, 12), dtype=bool, numpy=
array([[[ True,  True,  True, ...,  True,  True,  True],
        [ ...],
        [ True,  True,  True, ..., False, False,  True],
        [ True,  True,  True, ..., False, False,  True]]])>
rhs = <tf.Tensor: shape=(1, 500, 12), dtype=bool, numpy=
array([[[ True,  True,  True, ...,  True,  True,  True],
        [ ...],
        [ True,  True,  True, ...,  True,  True,  True],
        [ True,  True,  True, ...,  True,  True,  True]]])>

    def impl(self, rhs):
        try:
            return original_method(self, rhs)
        except Exception:
>           return patched_method(self, rhs)

ivy_transpiled_outputs/tensorflow_outputs/__init__.py:65: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = <tf.Tensor: shape=(1, 500, 12), dtype=bool, numpy=
array([[[ True,  True,  True, ...,  True,  True,  True],
        [ ...],
        [ True,  True,  True, ..., False, False,  True],
        [ True,  True,  True, ..., False, False,  True]]])>
other = <tf.Tensor: shape=(1, 500, 12), dtype=bool, numpy=
array([[[ True,  True,  True, ...,  True,  True,  True],
        [ ...],
        [ True,  True,  True, ...,  True,  True,  True],
        [ True,  True,  True, ...,  True,  True,  True]]])>

    def tensorflow___mul___frnt_(tensor, other):
        from .pointwise_ops import tensorflow_mul_frnt
    
>       return tensorflow_mul_frnt(tensor, other)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/tensor.py:111: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = <tf.Tensor: shape=(1, 500, 12), dtype=bool, numpy=
array([[[ True,  True,  True, ...,  True,  True,  True],
        [ ...],
        [ True,  True,  True, ..., False, False,  True],
        [ True,  True,  True, ..., False, False,  True]]])>
other = <tf.Tensor: shape=(1, 500, 12), dtype=bool, numpy=
array([[[ True,  True,  True, ...,  True,  True,  True],
        [ ...],
        [ True,  True,  True, ...,  True,  True,  True],
        [ True,  True,  True, ...,  True,  True,  True]]])>

    def tensorflow_mul_frnt(input, other, *, out=None):
        from .__init__ import tensorflow_promote_types_of_torch_inputs_frnt
        from ...backends.tensorflow.elementwise import tensorflow_multiply
    
        input, other = tensorflow_promote_types_of_torch_inputs_frnt(input, other)
>       return tensorflow_multiply(input, other, out=out)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/pointwise_ops.py:100: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x1 = <tf.Tensor: shape=(1, 500, 12), dtype=bool, numpy=
array([[[ True,  True,  True, ...,  True,  True,  True],
        [ ...],
        [ True,  True,  True, ..., False, False,  True],
        [ True,  True,  True, ..., False, False,  True]]])>
x2 = <tf.Tensor: shape=(1, 500, 12), dtype=bool, numpy=
array([[[ True,  True,  True, ...,  True,  True,  True],
        [ ...],
        [ True,  True,  True, ...,  True,  True,  True],
        [ True,  True,  True, ...,  True,  True,  True]]])>

    def tensorflow_multiply(
        x1: Union[float, tensorflow.Tensor, tensorflow.Variable],
        x2: Union[float, tensorflow.Tensor, tensorflow.Variable],
        /,
        *,
        out: Optional[Union[tensorflow.Tensor, tensorflow.Variable]] = None,
    ):
        from ...ivy.data_type import tensorflow_promote_types_of_inputs_bknd
    
        x1, x2 = tensorflow_promote_types_of_inputs_bknd(x1, x2)
>       return tensorflow.math.multiply(x1, x2)
E       tensorflow.python.framework.errors_impl.InvalidArgumentError: Exception encountered when calling tensorflow_ScaleSpaceDetector.call().
E       
E       [1mValue for attr 'T' of bool is not in the list of allowed values: bfloat16, half, float, double, uint8, int8, uint16, int16, int32, uint32, uint64, int64, complex64, complex128
E       	; NodeDef: {{node Mul}}; Op<name=Mul; signature=x:T, y:T -> z:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE, DT_UINT8, DT_INT8, DT_UINT16, DT_INT16, DT_INT32, DT_UINT32, DT_UINT64, DT_INT64, DT_COMPLEX64, DT_COMPLEX128]; is_commutative=true> [Op:Mul] name: [0m
E       
E       Arguments received by tensorflow_ScaleSpaceDetector.call():
E          img=tf.Tensor(shape=(1, 1, 32, 32), dtype=float32)
E          mask=None

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/backends/tensorflow/elementwise.py:239: InvalidArgumentError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.ScaleSpaceDetector
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/test_feature3.py::test_ScaleSpaceDetector[tensorflow-s2s-False] - tensorflow.python.framework.errors_impl.InvalidArgumentError: Exception encountered when calling tensorflow_ScaleSpac...
============================================================================== 1 failed, 12 passed in 2300.74s (0:38:20) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 13 items

kornia/test_utils.py .............                                                                                                                                                               [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
==================================================================================== 13 passed in 823.75s (0:13:43) ====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 6 items

kornia/test_nerf.py .F...F                                                                                                                                                                       [100%]

=============================================================================================== FAILURES ===============================================================================================
________________________________________________________________________________ test_NerfModelRenderer[jax-s2s-False] _________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_NerfModelRenderer(target_framework, mode, backend_compile):
        print("kornia.nerf.nerf_model.NerfModelRenderer")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledPinholeCamera = ivy.transpile(kornia.geometry.camera.pinhole.PinholeCamera, source="torch", target=target_framework)
        TranspiledNerfModel = ivy.transpile(nerf_model.NerfModel, source="torch", target=target_framework)
        TranspiledNerfModelRenderer = ivy.transpile(nerf_model.NerfModelRenderer, source="torch", target=target_framework)
    
        torch_nerf_model = nerf_model.NerfModel(num_ray_points=32)
        transpiled_nerf_model = TranspiledNerfModel(num_ray_points=32)
    
        torch_camera_args = (
            torch.rand(1, 4, 4),
            torch.rand(1, 4, 4),
            torch.tensor([256]),
            torch.tensor([256]),
        )
>       transpiled_camera_args = _nest_torch_tensor_to_new_framework(torch_camera_args)
E       TypeError: _nest_torch_tensor_to_new_framework() missing 1 required positional argument: 'target'

kornia/test_nerf.py:63: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.nerf.nerf_model.NerfModelRenderer
_________________________________________________________________________________ test_RandomRaySampler[jax-s2s-False] _________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_RandomRaySampler(target_framework, mode, backend_compile):
        print("kornia.nerf.samplers.RandomRaySampler")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledPinholeCamera = ivy.transpile(kornia.geometry.camera.pinhole.PinholeCamera, source="torch", target=target_framework)
        TranspiledRandomRaySampler = ivy.transpile(samplers.RandomRaySampler, source="torch", target=target_framework)
    
        torch_camera_args = (
            torch.rand(1, 4, 4),
            torch.rand(1, 4, 4),
            torch.tensor([256]),
            torch.tensor([256]),
        )
        transpiled_camera_args = _nest_torch_tensor_to_new_framework(torch_camera_args, target_framework)
    
        torch_camera = kornia.geometry.camera.pinhole.PinholeCamera(*torch_camera_args)
        transpiled_camera = TranspiledPinholeCamera(*transpiled_camera_args)
    
        heights, widths = torch.tensor([256]), torch.tensor([256])
        transpiled_heights = _array_to_new_backend(heights, target_framework)
        transpiled_widths = _array_to_new_backend(widths, target_framework)
    
        torch_sampler = samplers.RandomRaySampler(min_depth=0.1, max_depth=10.0, ndc=True, device="cpu", dtype=torch.float32)
        transpiled_sampler = TranspiledRandomRaySampler(min_depth=0.1, max_depth=10.0, ndc=True, device="cpu", dtype=torch.float32)
    
        torch_sampler.calc_ray_params(torch_camera, torch.tensor([1]))
>       transpiled_sampler.calc_ray_params(transpiled_camera, _array_to_new_backend(torch.tensor([1]), target_framework))

kornia/test_nerf.py:250: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <ivy_transpiled_outputs.jax_outputs.kornia.nerf.samplers.jax_RandomRaySampler object at 0x7fb740ea19f0>
cameras = <ivy_transpiled_outputs.jax_outputs.kornia.geometry.camera.pinhole.jax_PinholeCamera object at 0x7fb740ea05e0>, num_img_rays = Array([1], dtype=int64)

    def calc_ray_params(self, cameras, num_img_rays):
        from ...ivy.functional.frontends.torch.tensor import jax_shape_frnt_
    
        num_cams = cameras.batch_size
        if num_cams != jax_shape_frnt_(num_img_rays)[0]:
            raise ValueError(
                f"Number of cameras {num_cams} does not match size of tensor to define number of rays to march from each camera {jax_shape_frnt_(num_img_rays)[0]}"
            )
>       points_2d_camera = self.sample_points_2d(
            cameras.height, cameras.width, num_img_rays
        )

ivy_transpiled_outputs/jax_outputs/kornia/nerf/samplers.py:359: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <ivy_transpiled_outputs.jax_outputs.kornia.nerf.samplers.jax_RandomRaySampler object at 0x7fb740ea19f0>, heights = Array([256], dtype=int64), widths = Array([256], dtype=int64)
num_img_rays = Array([1], dtype=int32)

    def sample_points_2d(self, heights, widths, num_img_rays):
        from ...ivy.functional.frontends.torch.tensor import jax_int_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_tolist_frnt_
        from ...ivy.functional.frontends.torch.pointwise_ops import jax_trunc_frnt
        from ...ivy.functional.frontends.torch.random_sampling import jax_rand_frnt
    
        num_img_rays = jax_int_frnt_(num_img_rays)
        points2d_as_flat_tensors: typing.Any = {}
        for camera_id, (height, width, n) in enumerate(
            zip(
                jax_tolist_frnt_(heights),
                jax_tolist_frnt_(widths),
                jax_tolist_frnt_(num_img_rays),
            )
        ):
            y_rand = jax_trunc_frnt(
>               jax_rand_frnt(n, device=self._device, dtype=self._dtype) * height
            )

ivy_transpiled_outputs/jax_outputs/kornia/nerf/samplers.py:341: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

generator = None, out = None, dtype = torch.float32, layout = None, device = 'cpu', requires_grad = False, pin_memory = False, size = (1,), kwargs = {}
jax_random_uniform = <function jax_random_uniform at 0x7fb728a20040>, seed = None

    def jax_rand_frnt(
        *size,
        generator=None,
        out=None,
        dtype=None,
        layout=None,
        device=None,
        requires_grad=False,
        pin_memory=False,
        **kwargs,
    ):
        from ...backends.jax.random import jax_random_uniform
    
        if not size and "size" not in kwargs:
            raise ValueError("Missing 1 required positional/keyword argument: size")
        size = size if size else kwargs["size"]
        if (
            isinstance(size, (list, tuple))
            and len(size) == 1
            and isinstance(size[0], (list, tuple, tuple))
        ):
            size = size[0]
        seed = generator.initial_seed() if generator is not None else None
>       return jax_random_uniform(
            shape=size, seed=seed, out=out, dtype=dtype, device=device
        )

ivy_transpiled_outputs/jax_outputs/ivy/functional/frontends/torch/random_sampling.py:51: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype = torch.float32, args = (), kwargs = {'device': 'cpu', 'out': None, 'seed': None, 'shape': (1,)}, jax_exists_bknd = <function jax_exists_bknd at 0x7fb728a48280>
jax_default_dtype_bknd = <function jax_default_dtype_bknd at 0x7fb72896b640>, arr = None

    @functools.wraps(fn)
    def _infer_dtype(*args, dtype=None, **kwargs):
        from .functional.ivy.general import jax_exists_bknd
        from .functional.ivy.data_type import jax_default_dtype_bknd
    
        arr = None if jax_exists_bknd(dtype) else jax__get_first_array(*args, **kwargs)
        dtype = jax_default_dtype_bknd(dtype=dtype, item=arr, as_native=True)
>       return fn(*args, dtype=dtype, **kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/func_wrapper.py:144: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    @jax_infer_dtype
    def jax_random_uniform(
        *,
        low: Union[float, jax.Array] = 0.0,
        high: Union[float, jax.Array, None] = 1.0,
        shape: Optional[Union[tuple, Sequence[int]]] = None,
        device: jaxlib.xla_extension.Device = None,
        dtype: jax.numpy.dtype,
        seed: Optional[int] = None,
        out: Optional[jax.Array] = None,
    ):
        from ...ivy.random import jax__check_bounds_and_get_shape_bknd
    
        if high is None:
            high = float(
                jax.numpy.finfo(dtype).max
                if dtype is not None
                else jax.numpy.finfo(jax.numpy.float32).max
            )
        shape = jax__check_bounds_and_get_shape_bknd(low, high, shape)
        if seed:
            rng_input = jax.random.PRNGKey(seed)
        else:
            RNG_, rng_input = jax.random.split(jax__getRNG())
            jax__setRNG(RNG_)
>       return jax.numpy.astype(
            jax.random.uniform(
                rng_input, shape, minval=low, maxval=high, dtype=jax.numpy.float32
            ),
            dtype,
        )

ivy_transpiled_outputs/jax_outputs/ivy/functional/backends/jax/random.py:80: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = Array([0.10536897], dtype=float32), dtype = torch.float32

    def astype(x: ArrayLike, dtype: DTypeLike | None,
               /, *, copy: bool = False,
               device: xc.Device | Sharding | None = None) -> Array:
      """Convert an array to a specified dtype.
    
      JAX imlementation of :func:`numpy.astype`.
    
      This is implemented via :func:`jax.lax.convert_element_type`, which may
      have slightly different behavior than :func:`numpy.astype` in some cases.
      In particular, the details of float-to-int and int-to-float casts are
      implementation dependent.
    
      Args:
        x: input array to convert
        dtype: output dtype
        copy: if True, then always return a copy. If False (default) then only
          return a copy if necessary.
        device: optionally specify the device to which the output will be committed.
    
      Returns:
        An array with the same shape as ``x``, containing values of the specified
        dtype.
    
      See Also:
        - :func:`jax.lax.convert_element_type`: lower-level function for XLA-style
          dtype conversions.
    
      Examples:
        >>> x = jnp.array([0, 1, 2, 3])
        >>> x
        Array([0, 1, 2, 3], dtype=int32)
        >>> x.astype('float32')
        Array([0.0, 1.0, 2.0, 3.0], dtype=float32)
    
        >>> y = jnp.array([0.0, 0.5, 1.0])
        >>> y.astype(int)  # truncates fractional values
        Array([0, 0, 1], dtype=int32)
      """
      util.check_arraylike("astype", x)
      x_arr = asarray(x)
    
      if dtype is None:
        dtype = dtypes.canonicalize_dtype(float_)
>     dtypes.check_user_dtype_supported(dtype, "astype")

/opt/fw/jax/jax/_src/numpy/lax_numpy.py:5091: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype = torch.float32, fun_name = 'astype'

    def check_user_dtype_supported(dtype, fun_name=None):
      if isinstance(dtype, Array):
        # Deprecation warning added 2024 June 13.
        warnings.warn("Passing an array as a dtype argument is deprecated; "
                      "instead of dtype=arr use dtype=arr.dtype.",
                      category=DeprecationWarning, stacklevel=3)
        return  # no further check needed, as array dtypes have already been validated.
>     if issubdtype(dtype, extended):

/opt/fw/jax/jax/_src/dtypes.py:776: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = torch.float32, b = <class 'jax.dtypes.extended'>

    def issubdtype(a: DTypeLike | ExtendedDType | None,
                   b: DTypeLike | ExtendedDType | None) -> bool:
      """Returns True if first argument is a typecode lower/equal in type hierarchy.
    
      This is like :func:`numpy.issubdtype`, but can handle dtype extensions such as
      :obj:`jax.dtypes.bfloat16` and `jax.dtypes.prng_key`.
      """
      # Main departures from np.issubdtype are:
      # - "extended" dtypes (like prng key types) are not normal numpy dtypes, so we
      #   need to handle them specifically. However, their scalar types do conform to
      #   the numpy scalar type hierarchy.
      # - custom dtypes (like bfloat16, int4, etc.) are normal numpy dtypes, but they
      #   don't conform to the standard numpy type hierarchy (e.g. the bfloat16 scalar
      #   type is not a subclass of np.floating) so we must also handle these specially.
    
      # We cannot use the cached version directly for all inputs, because some may be
      # unhashable (e.g. custom objects with a dtype attribute). The following check is
      # fast and covers the majority of calls to this function within JAX library code.
      return _issubdtype_cached(
>       a if isinstance(a, (type, np.dtype, ExtendedDType)) else np.dtype(a),  # type: ignore[arg-type]
        b if isinstance(b, (type, np.dtype, ExtendedDType)) else np.dtype(b),  # type: ignore[arg-type]
      )
E     TypeError: Cannot interpret 'torch.float32' as a data type

/opt/fw/jax/jax/_src/dtypes.py:363: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.nerf.samplers.RandomRaySampler
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/test_nerf.py::test_NerfModelRenderer[jax-s2s-False] - TypeError: _nest_torch_tensor_to_new_framework() missing 1 required positional argument: 'target'
FAILED kornia/test_nerf.py::test_RandomRaySampler[jax-s2s-False] - TypeError: Cannot interpret 'torch.float32' as a data type
=============================================================================== 2 failed, 4 passed in 331.03s (0:05:31) ================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 1 item

kornia/geometry/test_ransac.py .                                                                                                                                                                 [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
==================================================================================== 1 passed in 191.86s (0:03:11) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 15 items

kornia/geometry/test_subpix.py ..F.........F..                                                                                                                                                   [100%]

=============================================================================================== FAILURES ===============================================================================================
____________________________________________________________________________ test_conv_quad_interp3d[tensorflow-s2s-False] _____________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_conv_quad_interp3d(target_framework, mode, backend_compile):
        trace_args = (
            torch.rand(2, 2, 2, 5, 5),
        )
        trace_kwargs = {
            'strict_maxima_bonus': 10.0,
            'eps': 1e-7,
        }
        test_args = (
            torch.rand(1, 2, 2, 5, 5),
        )
        test_kwargs = {
            'strict_maxima_bonus': 5.0,
            'eps': 1e-7,
        }
>       _test_function(
            kornia.geometry.subpix.conv_quad_interp3d,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/geometry/test_subpix.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function conv_quad_interp3d at 0x7fdaf8cd0ca0>
trace_args = (tensor([[[[[0.6220, 0.7316, 0.5007, 0.1081, 0.1374],
           [0.0236, 0.2819, 0.1852, 0.4903, 0.7729],
           ....0147],
           [0.7238, 0.9606, 0.8727, 0.1356, 0.2494],
           [0.9350, 0.8605, 0.0562, 0.0675, 0.8327]]]]]),)
trace_kwargs = {'eps': 1e-07, 'strict_maxima_bonus': 10.0}
test_args = (tensor([[[[[0.8856, 0.3016, 0.7711, 0.1043, 0.5271],
           [0.6210, 0.8167, 0.9247, 0.2611, 0.7513],
           ....6324],
           [0.2765, 0.1665, 0.9313, 0.4757, 0.6717],
           [0.3875, 0.4145, 0.2169, 0.9209, 0.3141]]]]]),)
test_kwargs = {'eps': 1e-07, 'strict_maxima_bonus': 5.0}, target = 'tensorflow', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function conv_quad_interp3d at 0x7fdaf8cd0ca0>, fn_name = 'kornia.geometry.subpix.conv_quad_interp3d'
trace_args = (tensor([[[[[0.6220, 0.7316, 0.5007, 0.1081, 0.1374],
           [0.0236, 0.2819, 0.1852, 0.4903, 0.7729],
           ....0147],
           [0.7238, 0.9606, 0.8727, 0.1356, 0.2494],
           [0.9350, 0.8605, 0.0562, 0.0675, 0.8327]]]]]),)
trace_kwargs = {'eps': 1e-07, 'strict_maxima_bonus': 10.0}
test_args = (tensor([[[[[0.8856, 0.3016, 0.7711, 0.1043, 0.5271],
           [0.6210, 0.8167, 0.9247, 0.2611, 0.7513],
           ....6324],
           [0.2765, 0.1665, 0.9313, 0.4757, 0.6717],
           [0.3875, 0.4145, 0.2169, 0.9209, 0.3141]]]]]),)
test_kwargs = {'eps': 1e-07, 'strict_maxima_bonus': 5.0}, target = 'tensorflow', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
>           graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:326: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = <tf.Tensor: shape=(2, 2, 2, 5, 5), dtype=float32, numpy=
array([[[[[0.62202513, 0.7315643 , 0.5007361 , 0.10806972, 0....3562948, 0.24941552],
          [0.9349865 , 0.86051995, 0.05621958, 0.0674569 , 0.83273876]]]]],
      dtype=float32)>
strict_maxima_bonus = 10.0, eps = 1e-07

    def tensorflow_conv_quad_interp3d(input, strict_maxima_bonus=10.0, eps=1e-07):
        from ...core._backend import stack
        from ...core._backend import rand
        from ...core._backend import zeros_like
        from ...core._backend import where
        from ....ivy.functional.frontends.torch.tensor_functions import (
            tensorflow_is_tensor_frnt_,
        )
        from ....ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ....ivy.functional.frontends.torch.tensor import tensorflow_permute_frnt_
        from ...utils.grid import tensorflow_create_meshgrid3d
        from ....ivy.functional.frontends.torch.tensor import tensorflow_to_frnt_
        from ...filters.sobel import tensorflow_spatial_gradient3d
        from ....ivy.functional.frontends.torch.tensor import tensorflow_reshape_frnt_
        from ....ivy.functional.frontends.torch.tensor import tensorflow_view_frnt_
        from ...utils._compat import tensorflow_torch_version_ge
        from ....ivy.functional.frontends.torch.tensor import tensorflow_abs_frnt_
        from ....ivy.functional.frontends.torch.tensor import tensorflow_size_frnt_
        from .nms import tensorflow_nms3d
        from ...utils.helpers import tensorflow_safe_solve_with_mask
        from ....ivy.functional.backends.tensorflow.general import tensorflow_get_item
        from ....ivy.functional.frontends.torch.tensor import (
            tensorflow_masked_scatter_frnt_,
        )
        from ....ivy.functional.backends.tensorflow.general import tensorflow_set_item
        from ....ivy.functional.frontends.torch.tensor import tensorflow_max_frnt_
        from ....ivy.functional.frontends.torch.tensor import tensorflow_masked_fill__frnt_
        from ....ivy.functional.frontends.torch.tensor import tensorflow_expand_as_frnt_
        from ....ivy.functional.frontends.torch.blas_and_lapack_ops import (
            tensorflow_bmm_frnt,
        )
        from ....ivy.functional.frontends.torch.tensor import tensorflow_flip_frnt_
        from ....ivy.functional.frontends.torch.tensor import tensorflow_unsqueeze_frnt_
        from ....ivy.functional.frontends.torch.tensor import tensorflow_repeat_frnt_
    
        if not tensorflow_is_tensor_frnt_(input):
            raise TypeError(f"Input type is not a Tensor. Got {type(input)}")
        if not len(tensorflow_shape_frnt_(input)) == 5:
            raise ValueError(
                f"Invalid input shape, we expect BxCxDxHxW. Got: {tensorflow_shape_frnt_(input)}"
            )
        B, CH, D, H, W = tensorflow_shape_frnt_(input)
        grid_global: typing.Any = tensorflow_permute_frnt_(
            tensorflow_create_meshgrid3d(D, H, W, False, device=input.device), 0, 4, 1, 2, 3
        )
        grid_global = tensorflow_to_frnt_(grid_global, input.dtype)
        b: typing.Any = tensorflow_spatial_gradient3d(input, order=1, mode="diff")
        b = tensorflow_reshape_frnt_(
            tensorflow_permute_frnt_(b, 0, 1, 3, 4, 5, 2), -1, 3, 1
        )
        A: typing.Any = tensorflow_spatial_gradient3d(input, order=2, mode="diff")
        A = tensorflow_reshape_frnt_(tensorflow_permute_frnt_(A, 0, 1, 3, 4, 5, 2), -1, 6)
        dxx = A[..., 0]
        dyy = A[..., 1]
        dss = A[..., 2]
        dxy = 0.25 * A[..., 3]
        dys = 0.25 * A[..., 4]
        dxs = 0.25 * A[..., 5]
        Hes = tensorflow_view_frnt_(
            stack([dxx, dxy, dxs, dxy, dyy, dys, dxs, dys, dss], -1), -1, 3, 3
        )
        if not tensorflow_torch_version_ge(1, 10):
            Hes = (
                Hes
                + tensorflow_abs_frnt_(
                    rand(tensorflow_size_frnt_(Hes[0]), device=Hes.device)
                )[None]
                * eps
            )
        nms_mask: typing.Any = tensorflow_nms3d(input, (3, 3, 3), True)
        x_solved: typing.Any = zeros_like(b)
        x_solved_masked, _, solved_correctly = tensorflow_safe_solve_with_mask(
            tensorflow_get_item(b, tensorflow_view_frnt_(nms_mask, -1)),
            tensorflow_get_item(Hes, tensorflow_view_frnt_(nms_mask, -1)),
        )
        new_nms_mask = tensorflow_masked_scatter_frnt_(nms_mask, nms_mask, solved_correctly)
        x_solved = tensorflow_set_item(
            x_solved,
>           where(new_nms_mask.view(-1, 1, 1))[0],
            tensorflow_get_item(x_solved_masked, solved_correctly),
        )

ivy_transpiled_outputs/tensorflow_outputs/kornia/geometry/subpix/spatial_soft_argmax.py:111: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <tf.Tensor: shape=(2, 2, 2, 5, 5), dtype=bool, numpy=
array([[[[[False, False, False, False, False],
          [False,...alse, False, False],
          [False, False, False, False, False],
          [False, False, False, False, False]]]]])>
name = 'view'

    def __getattr__(self, name):
      if name in {"T", "astype", "ravel", "transpose", "reshape", "clip", "size",
                  "tolist", "data"}:
        # TODO(wangpeng): Export the enable_numpy_behavior knob
        raise AttributeError(
            f"{type(self).__name__} object has no attribute '{name}'. " + """
          If you are looking for numpy-related methods, please run the following:
          tf.experimental.numpy.experimental_enable_numpy_behavior()
        """)
>     self.__getattribute__(name)
E     AttributeError: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'view'

/opt/fw/tensorflow/tensorflow/python/framework/tensor.py:260: AttributeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.subpix.spatial_soft_argmax.conv_quad_interp3d
_____________________________________________________________________________ test_ConvQuadInterp3d[tensorflow-s2s-False] ______________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_ConvQuadInterp3d(target_framework, mode, backend_compile):
        print("kornia.geometry.subpix.ConvQuadInterp3d")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledConvQuadInterp3d = ivy.transpile(
            kornia.geometry.subpix.ConvQuadInterp3d, source="torch", target=target_framework
        )
    
        conv_quad_interp3d = kornia.geometry.subpix.ConvQuadInterp3d()
        transpiled_conv_quad_interp3d = TranspiledConvQuadInterp3d()
    
        heatmap = torch.randn(1, 1, 3, 5, 5, requires_grad=True)
        transpiled_heatmap = _nest_torch_tensor_to_new_framework(heatmap, target_framework)
    
        torch_output = conv_quad_interp3d(heatmap)
>       transpiled_output = transpiled_conv_quad_interp3d(transpiled_heatmap)

kornia/geometry/test_subpix.py:371: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_ConvQuadInterp3d(strict_maxima_bonus=10.0)
args = (<tf.Tensor: shape=(1, 1, 3, 5, 5), dtype=float32, numpy=
array([[[[[-1.6979785 , -0.05829525, -0.47710443,  0.3820966...768483 ],
          [ 0.4863193 ,  1.2184281 , -0.9243951 ,  0.23044115,
           -0.1664918 ]]]]], dtype=float32)>,)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x55fd109ac880, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...ode_context=['        return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_ConvQuadInterp3d(strict_maxima_bonus=10.0), <tf.Tensor: shape=(1, 1, 3, 5, 5), dtype=float32, numpy=
array...7768483 ],
          [ 0.4863193 ,  1.2184281 , -0.9243951 ,  0.23044115,
           -0.1664918 ]]]]], dtype=float32)>)
kwargs = {}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_ConvQuadInterp3d(strict_maxima_bonus=10.0), v = None, buffers = None
args = (<tf.Tensor: shape=(1, 1, 3, 5, 5), dtype=float32, numpy=
array([[[[[-1.6979785 , -0.05829525, -0.47710443,  0.3820966...768483 ],
          [ 0.4863193 ,  1.2184281 , -0.9243951 ,  0.23044115,
           -0.1664918 ]]]]], dtype=float32)>,)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:2013: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_ConvQuadInterp3d(strict_maxima_bonus=10.0), <tf.Tensor: shape=(1, 1, 3, 5, 5), dtype=float32, numpy=
array...7768483 ],
          [ 0.4863193 ,  1.2184281 , -0.9243951 ,  0.23044115,
           -0.1664918 ]]]]], dtype=float32)>)
kwargs = {'buffers': None, 'v': None}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_ConvQuadInterp3d(strict_maxima_bonus=10.0), v = None, buffers = None
args = (<tf.Tensor: shape=(1, 1, 3, 5, 5), dtype=float32, numpy=
array([[[[[-1.6979785 , -0.05829525, -0.47710443,  0.3820966...768483 ],
          [ 0.4863193 ,  1.2184281 , -0.9243951 ,  0.23044115,
           -0.1664918 ]]]]], dtype=float32)>,)
kwargs = {}
first_arr = <tf.Tensor: shape=(1, 1, 3, 5, 5), dtype=float32, numpy=
array([[[[[-1.6979785 , -0.05829525, -0.47710443,  0.38209662....7768483 ],
          [ 0.4863193 ,  1.2184281 , -0.9243951 ,  0.23044115,
           -0.1664918 ]]]]], dtype=float32)>
replace_v = False, replace_buffers = False, call_signature = <Signature (x)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Model, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Model, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Model, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1783: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_ConvQuadInterp3d(strict_maxima_bonus=10.0),)
kwargs = {'x': <tf.Tensor: shape=(1, 1, 3, 5, 5), dtype=float32, numpy=
array([[[[[-1.6979785 , -0.05829525, -0.47710443,  0.38...7768483 ],
          [ 0.4863193 ,  1.2184281 , -0.9243951 ,  0.23044115,
           -0.1664918 ]]]]], dtype=float32)>}

    @wraps(fn)
    def error_handler(*args, **kwargs):
        if not is_traceback_filtering_enabled():
            return fn(*args, **kwargs)
    
        filtered_tb = None
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            filtered_tb = _process_traceback_frames(e.__traceback__)
            # To get the full stack trace, call:
            # `keras.config.disable_traceback_filtering()`
>           raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/keras/src/utils/traceback_utils.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_ConvQuadInterp3d(strict_maxima_bonus=10.0)
x = <tf.Tensor: shape=(1, 1, 3, 5, 5), dtype=float32, numpy=
array([[[[[-1.6979785 , -0.05829525, -0.47710443,  0.38209662....7768483 ],
          [ 0.4863193 ,  1.2184281 , -0.9243951 ,  0.23044115,
           -0.1664918 ]]]]], dtype=float32)>

    def call(self, x):
>       return tensorflow_conv_quad_interp3d(x, self.strict_maxima_bonus, self.eps)

ivy_transpiled_outputs/tensorflow_outputs/kornia/geometry/subpix/spatial_soft_argmax.py:165: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = <tf.Tensor: shape=(1, 1, 3, 5, 5), dtype=float32, numpy=
array([[[[[-1.6979785 , -0.05829525, -0.47710443,  0.38209662....7768483 ],
          [ 0.4863193 ,  1.2184281 , -0.9243951 ,  0.23044115,
           -0.1664918 ]]]]], dtype=float32)>
strict_maxima_bonus = 10.0, eps = 1e-07

    def tensorflow_conv_quad_interp3d(input, strict_maxima_bonus=10.0, eps=1e-07):
        from ...core._backend import stack
        from ...core._backend import rand
        from ...core._backend import zeros_like
        from ...core._backend import where
        from ....ivy.functional.frontends.torch.tensor_functions import (
            tensorflow_is_tensor_frnt_,
        )
        from ....ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ....ivy.functional.frontends.torch.tensor import tensorflow_permute_frnt_
        from ...utils.grid import tensorflow_create_meshgrid3d
        from ....ivy.functional.frontends.torch.tensor import tensorflow_to_frnt_
        from ...filters.sobel import tensorflow_spatial_gradient3d
        from ....ivy.functional.frontends.torch.tensor import tensorflow_reshape_frnt_
        from ....ivy.functional.frontends.torch.tensor import tensorflow_view_frnt_
        from ...utils._compat import tensorflow_torch_version_ge
        from ....ivy.functional.frontends.torch.tensor import tensorflow_abs_frnt_
        from ....ivy.functional.frontends.torch.tensor import tensorflow_size_frnt_
        from .nms import tensorflow_nms3d
        from ...utils.helpers import tensorflow_safe_solve_with_mask
        from ....ivy.functional.backends.tensorflow.general import tensorflow_get_item
        from ....ivy.functional.frontends.torch.tensor import (
            tensorflow_masked_scatter_frnt_,
        )
        from ....ivy.functional.backends.tensorflow.general import tensorflow_set_item
        from ....ivy.functional.frontends.torch.tensor import tensorflow_max_frnt_
        from ....ivy.functional.frontends.torch.tensor import tensorflow_masked_fill__frnt_
        from ....ivy.functional.frontends.torch.tensor import tensorflow_expand_as_frnt_
        from ....ivy.functional.frontends.torch.blas_and_lapack_ops import (
            tensorflow_bmm_frnt,
        )
        from ....ivy.functional.frontends.torch.tensor import tensorflow_flip_frnt_
        from ....ivy.functional.frontends.torch.tensor import tensorflow_unsqueeze_frnt_
        from ....ivy.functional.frontends.torch.tensor import tensorflow_repeat_frnt_
    
        if not tensorflow_is_tensor_frnt_(input):
            raise TypeError(f"Input type is not a Tensor. Got {type(input)}")
        if not len(tensorflow_shape_frnt_(input)) == 5:
            raise ValueError(
                f"Invalid input shape, we expect BxCxDxHxW. Got: {tensorflow_shape_frnt_(input)}"
            )
        B, CH, D, H, W = tensorflow_shape_frnt_(input)
        grid_global: typing.Any = tensorflow_permute_frnt_(
            tensorflow_create_meshgrid3d(D, H, W, False, device=input.device), 0, 4, 1, 2, 3
        )
        grid_global = tensorflow_to_frnt_(grid_global, input.dtype)
        b: typing.Any = tensorflow_spatial_gradient3d(input, order=1, mode="diff")
        b = tensorflow_reshape_frnt_(
            tensorflow_permute_frnt_(b, 0, 1, 3, 4, 5, 2), -1, 3, 1
        )
        A: typing.Any = tensorflow_spatial_gradient3d(input, order=2, mode="diff")
        A = tensorflow_reshape_frnt_(tensorflow_permute_frnt_(A, 0, 1, 3, 4, 5, 2), -1, 6)
        dxx = A[..., 0]
        dyy = A[..., 1]
        dss = A[..., 2]
        dxy = 0.25 * A[..., 3]
        dys = 0.25 * A[..., 4]
        dxs = 0.25 * A[..., 5]
        Hes = tensorflow_view_frnt_(
            stack([dxx, dxy, dxs, dxy, dyy, dys, dxs, dys, dss], -1), -1, 3, 3
        )
        if not tensorflow_torch_version_ge(1, 10):
            Hes = (
                Hes
                + tensorflow_abs_frnt_(
                    rand(tensorflow_size_frnt_(Hes[0]), device=Hes.device)
                )[None]
                * eps
            )
        nms_mask: typing.Any = tensorflow_nms3d(input, (3, 3, 3), True)
        x_solved: typing.Any = zeros_like(b)
        x_solved_masked, _, solved_correctly = tensorflow_safe_solve_with_mask(
            tensorflow_get_item(b, tensorflow_view_frnt_(nms_mask, -1)),
            tensorflow_get_item(Hes, tensorflow_view_frnt_(nms_mask, -1)),
        )
        new_nms_mask = tensorflow_masked_scatter_frnt_(nms_mask, nms_mask, solved_correctly)
        x_solved = tensorflow_set_item(
            x_solved,
>           where(new_nms_mask.view(-1, 1, 1))[0],
            tensorflow_get_item(x_solved_masked, solved_correctly),
        )
E       AttributeError: Exception encountered when calling tensorflow_ConvQuadInterp3d.call().
E       
E       [1m'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'view'[0m
E       
E       Arguments received by tensorflow_ConvQuadInterp3d.call():
E          x=tf.Tensor(shape=(1, 1, 3, 5, 5), dtype=float32)

ivy_transpiled_outputs/tensorflow_outputs/kornia/geometry/subpix/spatial_soft_argmax.py:114: AttributeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.subpix.ConvQuadInterp3d
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/geometry/test_subpix.py::test_conv_quad_interp3d[tensorflow-s2s-False] - AttributeError: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'view'
FAILED kornia/geometry/test_subpix.py::test_ConvQuadInterp3d[tensorflow-s2s-False] - AttributeError: Exception encountered when calling tensorflow_ConvQuadInterp3d.call().
============================================================================== 2 failed, 13 passed in 1351.88s (0:22:31) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 8 items

kornia/geometry/test_homography.py .F......                                                                                                                                                      [100%]

=============================================================================================== FAILURES ===============================================================================================
___________________________________________________________________________ test_find_homography_dlt_iterated[jax-s2s-False] ___________________________________________________________________________
jax.errors.SimplifiedTraceback: For simplicity, JAX has removed its internal frames from the traceback of the following exception. Set JAX_TRACEBACK_FILTERING=off to include these.

The above exception was the direct cause of the following exception:

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_find_homography_dlt_iterated(target_framework, mode, backend_compile):
        trace_args = (
            torch.rand(1, 4, 2),
            torch.rand(1, 4, 2),
            torch.rand(1, 4),
        )
        trace_kwargs = {'soft_inl_th': 3.0, 'n_iter': 5}
        test_args = (
            torch.rand(5, 4, 2),
            torch.rand(5, 4, 2),
            torch.rand(5, 4),
        )
        test_kwargs = {'soft_inl_th': 4.0, 'n_iter': 5}
>       _test_function(
            kornia.geometry.homography.find_homography_dlt_iterated,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=5e-2,
            mode=mode,
            # NOTE: numerical instability in svd()/lu() leads to logits not being allclose
            deterministic=False,
        )

kornia/geometry/test_homography.py:48: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function find_homography_dlt_iterated at 0x7f0d54b69120>
trace_args = (tensor([[[0.1790, 0.7294],
         [0.3539, 0.6538],
         [0.2004, 0.4438],
         [0.1970, 0.5012]]]), tensor... [0.0801, 0.8323],
         [0.9756, 0.8470],
         [0.3773, 0.2330]]]), tensor([[0.6817, 0.5606, 0.5702, 0.5000]]))
trace_kwargs = {'n_iter': 5, 'soft_inl_th': 3.0}
test_args = (tensor([[[0.2609, 0.2135],
         [0.7802, 0.4302],
         [0.9132, 0.7205],
         [0.2319, 0.9465]],

       ...[0.1359, 0.8313, 0.2463, 0.9257],
        [0.5610, 0.8895, 0.2599, 0.2745],
        [0.7194, 0.8789, 0.0135, 0.5947]]))
test_kwargs = {'n_iter': 5, 'soft_inl_th': 4.0}, target = 'jax', backend_compile = False, tolerance = 0.05, mode = 's2s', skip = False, deterministic = False, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function find_homography_dlt_iterated at 0x7f0d54b69120>, fn_name = 'kornia.geometry.homography.find_homography_dlt_iterated'
trace_args = (tensor([[[0.1790, 0.7294],
         [0.3539, 0.6538],
         [0.2004, 0.4438],
         [0.1970, 0.5012]]]), tensor... [0.0801, 0.8323],
         [0.9756, 0.8470],
         [0.3773, 0.2330]]]), tensor([[0.6817, 0.5606, 0.5702, 0.5000]]))
trace_kwargs = {'n_iter': 5, 'soft_inl_th': 3.0}
test_args = (tensor([[[0.2609, 0.2135],
         [0.7802, 0.4302],
         [0.9132, 0.7205],
         [0.2319, 0.9465]],

       ...[0.1359, 0.8313, 0.2463, 0.9257],
        [0.5610, 0.8895, 0.2599, 0.2745],
        [0.7194, 0.8789, 0.0135, 0.5947]]))
test_kwargs = {'n_iter': 5, 'soft_inl_th': 4.0}, target = 'jax', backend_compile = False, tolerance = 0.05, deterministic = False, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

points1 = Array([[[0.17898017, 0.72939765],
        [0.3539378 , 0.65375495],
        [0.20038235, 0.44382536],
        [0.19704413, 0.501202  ]]], dtype=float32)
points2 = Array([[[0.33611107, 0.61231226],
        [0.08013135, 0.83227503],
        [0.9755533 , 0.8469865 ],
        [0.37732798, 0.23296642]]], dtype=float32)
weights = Array([[0.6816612 , 0.5606276 , 0.57023835, 0.49998546]], dtype=float32), soft_inl_th = 3.0, n_iter = 5

    def jax_find_homography_dlt_iterated(
        points1, points2, weights, soft_inl_th=3.0, n_iter=5
    ):
        from ...ivy.functional.frontends.torch.pointwise_ops import jax_exp_frnt
    
>       H: typing.Any = jax_find_homography_dlt(points1, points2, weights)

ivy_transpiled_outputs/jax_outputs/kornia/geometry/homography.py:181: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

points1 = Array([[[0.17898017, 0.72939765],
        [0.3539378 , 0.65375495],
        [0.20038235, 0.44382536],
        [0.19704413, 0.501202  ]]], dtype=float32)
points2 = Array([[[0.33611107, 0.61231226],
        [0.08013135, 0.83227503],
        [0.9755533 , 0.8469865 ],
        [0.37732798, 0.23296642]]], dtype=float32)
weights = Array([[0.6816612 , 0.5606276 , 0.57023835, 0.49998546]], dtype=float32), solver = 'lu'

    def jax_find_homography_dlt(points1, points2, weights=None, solver="lu"):
        from ...ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ..core.check import jax_KORNIA_CHECK_SHAPE
        from ..utils.helpers import jax__extract_device_dtype
        from .epipolar.fundamental import jax_normalize_points
        from ...ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            jax_chunk_frnt,
        )
        from ...ivy.functional.frontends.torch.creation_ops import (
            jax_ones_like_v_0p4p0_and_above_frnt,
        )
        from ...ivy.functional.frontends.torch.creation_ops import jax_zeros_like_frnt
        from ...ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            jax_cat_frnt,
        )
        from ...ivy.functional.frontends.torch.tensor import jax_reshape_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_transpose_frnt_
        from ...ivy.functional.frontends.torch.miscellaneous_ops import jax_diag_embed_frnt
        from ...ivy.functional.frontends.torch.tensor import jax_repeat_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_unsqueeze_frnt_
        from ..utils.helpers import jax__torch_svd_cast
        from ...ivy.functional.frontends.torch.creation_ops import jax_empty_frnt
        from ...ivy.functional.frontends.torch.tensor import jax_size_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_view_frnt_
        from ...ivy.functional.frontends.torch.creation_ops import jax_ones_frnt
        from ..utils.helpers import jax_safe_solve_with_mask
        from ..utils.helpers import jax_safe_inverse_with_mask
    
        if jax_shape_frnt_(points1) != jax_shape_frnt_(points2):
            raise AssertionError(jax_shape_frnt_(points1))
        if jax_shape_frnt_(points1)[1] < 4:
            raise AssertionError(jax_shape_frnt_(points1))
        jax_KORNIA_CHECK_SHAPE(points1, ["B", "N", "2"])
        jax_KORNIA_CHECK_SHAPE(points2, ["B", "N", "2"])
        device, dtype = jax__extract_device_dtype([points1, points2])
        eps: typing.Any = 1e-08
        points1_norm, transform1 = jax_normalize_points(points1)
        points2_norm, transform2 = jax_normalize_points(points2)
        x1, y1 = jax_chunk_frnt(points1_norm, dim=-1, chunks=2)
        x2, y2 = jax_chunk_frnt(points2_norm, dim=-1, chunks=2)
        ones, zeros = jax_ones_like_v_0p4p0_and_above_frnt(x1), jax_zeros_like_frnt(x1)
        ax = jax_cat_frnt(
            [zeros, zeros, zeros, -x1, -y1, -ones, y2 * x1, y2 * y1, y2], dim=-1
        )
        ay = jax_cat_frnt(
            [x1, y1, ones, zeros, zeros, zeros, -x2 * x1, -x2 * y1, -x2], dim=-1
        )
        A = jax_reshape_frnt_(
            jax_cat_frnt((ax, ay), dim=-1),
            jax_shape_frnt_(ax)[0],
            -1,
            jax_shape_frnt_(ax)[-1],
        )
        if weights is None:
            A = jax_transpose_frnt_(A, -2, -1) @ A
        else:
            if not (
                len(jax_shape_frnt_(weights)) == 2
                and jax_shape_frnt_(weights) == jax_shape_frnt_(points1)[:2]
            ):
                raise AssertionError(jax_shape_frnt_(weights))
            w_diag = jax_diag_embed_frnt(
                jax_reshape_frnt_(
                    jax_repeat_frnt_(jax_unsqueeze_frnt_(weights, dim=-1), 1, 1, 2),
                    jax_shape_frnt_(weights)[0],
                    -1,
                )
            )
            A = jax_transpose_frnt_(A, -2, -1) @ w_diag @ A
        if solver == "svd":
            try:
                _, _, V = jax__torch_svd_cast(A)
            except RuntimeError:
                warnings.warn("SVD did not converge", RuntimeWarning)
                return jax_empty_frnt(
                    (jax_size_frnt_(points1_norm, 0), 3, 3), device=device, dtype=dtype
                )
            H = jax_view_frnt_(V[..., -1], -1, 3, 3)
        elif solver == "lu":
            B = jax_ones_frnt(
                jax_shape_frnt_(A)[0], jax_shape_frnt_(A)[1], device=device, dtype=dtype
            )
>           sol, _, _ = jax_safe_solve_with_mask(B, A)

ivy_transpiled_outputs/jax_outputs/kornia/geometry/homography.py:167: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

B = Array([[1., 1., 1., 1., 1., 1., 1., 1., 1.]], dtype=float32)
A = Array([[[ 1.3129259 ,  0.39821222, -0.0497375 ,  0.        ,
          0.        ,  0.        ,  1.2648863 , -0.028176...7044, -0.7060455 ,
         -0.21309261, -0.09024197,  0.347059  , -3.7441177 ,
          5.31678   ]]], dtype=float32)

    def jax_safe_solve_with_mask(B, A):
        from ._compat import jax_torch_version_ge
        from ...ivy.functional.frontends.torch.creation_ops import jax_ones_frnt
        from ...ivy.functional.frontends.torch.linalg import jax_lu_factor_ex_frnt
        from ...ivy.functional.frontends.torch.tensor import jax_to_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_unsqueeze_frnt_
        from ...ivy.functional.frontends.torch.linalg import jax_lu_solve_frnt
        from ...ivy.functional.frontends.torch.miscellaneous_ops import (
            jax_lu_solve_frnt_base_count_1_frnt,
        )
        from ...ivy.functional.frontends.torch.linalg import lu
    
        if not jax_torch_version_ge(1, 10):
            sol = jax__torch_solve_cast(A, B)
            warnings.warn(
                "PyTorch version < 1.10, solve validness mask maybe not correct",
                RuntimeWarning,
            )
            return sol, sol, jax_ones_frnt(len(A), dtype=jnp.bool, device=A.device)
        if not isinstance(B, (jax.Array, nnx.Param)):
            raise AssertionError(f"B must be Tensor. Got: {type(B)}.")
        dtype: typing.Any = B.dtype
        if dtype not in (jnp.float32, jnp.float64):
            dtype = jnp.float32
        if TYPE_CHECKING:
            A_LU: typing.Any
            pivots: typing.Any
            info: typing.Any
        elif jax_torch_version_ge(1, 13):
>           A_LU, pivots, info = jax_lu_factor_ex_frnt(jax_to_frnt_(A, dtype))

ivy_transpiled_outputs/jax_outputs/kornia/utils/helpers.py:120: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

A = Array([[[ 1.3129259 ,  0.39821222, -0.0497375 ,  0.        ,
          0.        ,  0.        ,  1.2648863 , -0.028176...7044, -0.7060455 ,
         -0.21309261, -0.09024197,  0.347059  , -3.7441177 ,
          5.31678   ]]], dtype=float32)

    def jax_lu_factor_ex_frnt(A, *, pivot=True, check_errors=False, out=None):
        from ...backends.jax.experimental.linear_algebra import jax_lu_factor
        from ...backends.jax.creation import jax_zeros
        from .tensor import jax_shape_frnt_
        from ...backends.jax.creation import jax_full_like
        from ...backends.jax.creation import jax_ones
    
        try:
>           LU, pivots = jax_lu_factor(A, pivot=pivot, out=out)

ivy_transpiled_outputs/jax_outputs/ivy/functional/frontends/torch/linalg.py:68: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = [Array([[[ 1.3129259 ,  0.39821222, -0.0497375 ,  0.        ,
          0.        ,  0.        ,  1.2648863 , -0.02817...044, -0.7060455 ,
         -0.21309261, -0.09024197,  0.347059  , -3.7441177 ,
          5.31678   ]]], dtype=float32)]
kwargs = {'out': None, 'pivot': True}, jax_is_array_bknd = <function jax_is_array_bknd at 0x7f0cec2d4040>, jax_set_item = <function jax_set_item at 0x7f0cec2d75b0>
jax_asarray = <function jax_asarray at 0x7f0cec2d4a60>, jax_get_item = <function jax_get_item at 0x7f0cec2d7400>, num_args = 1
type_hints = mappingproxy(OrderedDict([('x', <Parameter "x: jax.Array">), ('pivot', <Parameter "pivot: Optional[bool] = True">), ('out', <Parameter "out: Optional[jax.Array] = None">)]))
parameters = ['x', 'pivot', 'out'], annotations = [<class 'jax.Array'>, typing.Optional[bool], typing.Optional[jax.Array]], device = CpuDevice(id=0), i = 0

    @functools.wraps(fn)
    def _handle_array_like_without_promotion(*args, **kwargs):
        from .functional.ivy.general import jax_is_array_bknd
        from .functional.backends.jax.general import jax_set_item
        from .functional.backends.jax.creation import jax_asarray
        from .functional.backends.jax.general import jax_get_item
    
        args = list(args)
        num_args = len(args)
        try:
            type_hints = inspect.signature(fn).parameters
        except (TypeError, ValueError):
            return fn(*args, **kwargs)
        parameters = list(type_hints.keys())
        annotations = [param.annotation for param in type_hints.values()]
        device = jax__get_preferred_device(args, kwargs)
        for i, (annotation, parameter, arg) in enumerate(
            zip(annotations, parameters, args)
        ):
            annotation_str = str(annotation)
            if (
                ("rray" in annotation_str or "Tensor" in annotation_str)
                and parameter != "out"
                and all(
                    sq not in annotation_str
                    for sq in ["Sequence", "List", "Tuple", "float", "int", "bool"]
                )
            ):
                if i < num_args:
                    if arg is None or jax__check_in_nested_sequence(
                        arg, value=Ellipsis, _type=slice
                    ):
                        continue
                    if not jax_is_array_bknd(arg):
                        args = jax_set_item(args, i, jax_asarray(arg, device=device))
                elif parameters in kwargs:
                    kwarg = jax_get_item(kwargs, parameter)
                    if not jax_is_array_bknd(kwarg):
                        kwargs = jax_set_item(
                            kwargs, parameter, jax_asarray(kwarg, device=device)
                        )
>       return fn(*args, **kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/func_wrapper.py:130: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = Array([[[ 1.3129259 ,  0.39821222, -0.0497375 ,  0.        ,
          0.        ,  0.        ,  1.2648863 , -0.028176...7044, -0.7060455 ,
         -0.21309261, -0.09024197,  0.347059  , -3.7441177 ,
          5.31678   ]]], dtype=float32)

    @jax_handle_array_like_without_promotion
    def jax_lu_factor(
        x: jax.Array, /, *, pivot: Optional[bool] = True, out: Optional[jax.Array] = None
    ):
>       ret = jax.scipy.linalg.lu(x)

ivy_transpiled_outputs/jax_outputs/ivy/functional/backends/jax/experimental/linear_algebra.py:48: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = Traced<ShapedArray(float32[1,9,9])>with<DynamicJaxprTrace(level=1/0)>, permute_l = False

    @partial(jit, static_argnames=('permute_l', 'overwrite_a', 'check_finite'))
    def lu(a: ArrayLike, permute_l: bool = False, overwrite_a: bool = False,
           check_finite: bool = True) -> tuple[Array, Array] | tuple[Array, Array, Array]:
      """Compute the LU decomposition
    
      JAX implementation of :func:`scipy.linalg.lu`.
    
      The LU decomposition of a matrix `A` is:
    
      .. math::
    
         A = P L U
    
      where `P` is a permutation matrix, `L` is lower-triangular and `U` is upper-triangular.
    
      Args:
        a: array of shape ``(..., M, N)`` to decompose.
        permute_l: if True, then permute ``L`` and return ``(P @ L, U)`` (default: False)
        overwrite_a: not used by JAX
        check_finite: not used by JAX
    
      Returns:
        A tuple of arrays ``(P @ L, U)`` if ``permute_l`` is True, else ``(P, L, U)``:
    
        - ``P`` is a permutation matrix of shape ``(..., M, M)``
        - ``L`` is a lower-triangular matrix of shape ``(... M, K)``
        - ``U`` is an upper-triangular matrix of shape ``(..., K, N)``
    
        with ``K = min(M, N)``
    
      See also:
        - :func:`jax.numpy.linalg.lu`: NumPy-style API for LU decomposition.
        - :func:`jax.lax.linalg.lu`: XLA-style API for LU decomposition.
        - :func:`jax.scipy.linalg.lu_solve`: LU-based linear solver.
    
      Examples:
        An LU decomposition of a 3x3 matrix:
    
        >>> a = jnp.array([[1., 2., 3.],
        ...                [5., 4., 2.],
        ...                [3., 2., 1.]])
        >>> P, L, U = jax.scipy.linalg.lu(a)
    
        ``P`` is a permutation matrix: i.e. each row and column has a single ``1``:
    
        >>> P
        Array([[0., 1., 0.],
               [1., 0., 0.],
               [0., 0., 1.]], dtype=float32)
    
        ``L`` and ``U`` are lower-triangular and upper-triangular matrices:
    
        >>> with jnp.printoptions(precision=3):
        ...   print(L)
        ...   print(U)
        [[ 1.     0.     0.   ]
         [ 0.2    1.     0.   ]
         [ 0.6   -0.333  1.   ]]
        [[5.    4.    2.   ]
         [0.    1.2   2.6  ]
         [0.    0.    0.667]]
    
        The original matrix can be reconstructed by multiplying the three together:
    
        >>> a_reconstructed = P @ L @ U
        >>> jnp.allclose(a, a_reconstructed)
        Array(True, dtype=bool)
      """
      del overwrite_a, check_finite  # unused
>     return _lu(a, permute_l)

/opt/fw/jax/jax/_src/scipy/linalg.py:821: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = Traced<ShapedArray(float32[1,9,9])>with<DynamicJaxprTrace(level=2/0)>, permute_l = False

    @partial(jit, static_argnums=(1,))
    def _lu(a: ArrayLike, permute_l: bool) -> tuple[Array, Array] | tuple[Array, Array, Array]:
      a, = promote_dtypes_inexact(jnp.asarray(a))
      lu, _, permutation = lax_linalg.lu(a)
      dtype = lax.dtype(a)
>     m, n = jnp.shape(a)
E     ValueError: too many values to unpack (expected 2)

/opt/fw/jax/jax/_src/scipy/linalg.py:729: ValueError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.homography.find_homography_dlt_iterated
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/geometry/test_homography.py::test_find_homography_dlt_iterated[jax-s2s-False] - ValueError: too many values to unpack (expected 2)
=============================================================================== 1 failed, 7 passed in 584.66s (0:09:44) ================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 8 items

kornia/test_image.py ssssssss                                                                                                                                                                    [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
========================================================================================== 8 skipped in 5.28s ==========================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 15 items

kornia/test_contrib.py ....FF......FF.                                                                                                                                                           [100%]

=============================================================================================== FAILURES ===============================================================================================
__________________________________________________________________________________ test_diamond_square[jax-s2s-False] __________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_diamond_square(target_framework, mode, backend_compile):
        trace_args = ((1, 1, 8, 8),)
        trace_kwargs = {
            "roughness": 0.5,
            "random_scale": 1.0,
            "normalize_range": (0.0, 1.0),
            "random_fn": torch.ones,
        }
        test_args = ((5, 1, 8, 8),)
        test_kwargs = {
            "roughness": 0.7,
            "random_scale": 0.9,
            "normalize_range": (-1.0, 1.0),
            "random_fn": torch.ones,
        }
>       _test_function(
            kornia.contrib.diamond_square,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/test_contrib.py:141: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function diamond_square at 0x7ff8586a7130>, trace_args = ((1, 1, 8, 8),)
trace_kwargs = {'normalize_range': (0.0, 1.0), 'random_fn': <built-in method ones of type object at 0x7ff873f91900>, 'random_scale': 1.0, 'roughness': 0.5}, test_args = ((5, 1, 8, 8),)
test_kwargs = {'normalize_range': (-1.0, 1.0), 'random_fn': <built-in method ones of type object at 0x7ff873f91900>, 'random_scale': 0.9, 'roughness': 0.7}, target = 'jax', backend_compile = False
tolerance = 0.001, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function diamond_square at 0x7ff8586a7130>, fn_name = 'kornia.contrib.diamond_square', trace_args = ((1, 1, 8, 8),)
trace_kwargs = {'normalize_range': (0.0, 1.0), 'random_fn': <built-in method ones of type object at 0x7ff873f91900>, 'random_scale': 1.0, 'roughness': 0.5}, test_args = ((5, 1, 8, 8),)
test_kwargs = {'normalize_range': (-1.0, 1.0), 'random_fn': <built-in method ones of type object at 0x7ff873f91900>, 'random_scale': 0.9, 'roughness': 0.7}, target = 'jax', backend_compile = False
tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

output_size = (1, 1, 8, 8), roughness = Array([[[[0.5]]]], dtype=float64), random_scale = Array([[[[1.]]]], dtype=float64), random_fn = <built-in method ones of type object at 0x7ff873f91900>
normalize_range = (0.0, 1.0), device = None, dtype = None

    def jax_diamond_square(
        output_size,
        roughness=0.5,
        random_scale=1.0,
        random_fn=jax_rand_frnt,
        normalize_range=None,
        device=None,
        dtype=None,
    ):
        from ..core.check import jax_KORNIA_CHECK
        from ...ivy.functional.frontends.torch.tensor import jax_to_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_expand_frnt_
        from ..core.check import jax_KORNIA_CHECK_IS_TENSOR
        from ...ivy.functional.frontends.torch.tensor import jax_view_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_reshape_frnt_
        from ...ivy.functional.backends.jax.general import jax_get_item
        from ..enhance.normalize import jax_normalize_min_max
        from ...ivy.functional.frontends.torch.tensor import jax_contiguous_frnt_
    
        jax_KORNIA_CHECK(len(output_size) == 4, "output_size must be (B,C,H,W)")
        if not isinstance(random_scale, (jax.Array, nnx.Param)):
            random_scale = jax_to_frnt_(jnp.asarray([[[[random_scale]]]]), device, dtype)
            random_scale = jax_expand_frnt_(
                random_scale, [output_size[0] * output_size[1], 1, 1, 1]
            )
        else:
            jax_KORNIA_CHECK_IS_TENSOR(random_scale)
            random_scale = jax_view_frnt_(random_scale, -1, 1, 1, 1)
            random_scale = jax_expand_frnt_(
                random_scale, [output_size[0], output_size[1], 1, 1]
            )
            random_scale = jax_reshape_frnt_(random_scale, [-1, 1, 1, 1])
        if not isinstance(roughness, (jax.Array, nnx.Param)):
            roughness = jax_to_frnt_(jnp.asarray([[[[roughness]]]]), device, dtype)
            roughness = jax_expand_frnt_(
                roughness, [output_size[0] * output_size[1], 1, 1, 1]
            )
        else:
            roughness = jax_view_frnt_(roughness, -1, 1, 1, 1)
            roughness = jax_expand_frnt_(roughness, [output_size[0], output_size[1], 1, 1])
            roughness = jax_reshape_frnt_(roughness, [-1, 1, 1, 1])
        width, height = output_size[-2:][0], output_size[-2:][1]
        num_samples: typing.Any = 1
        for x in output_size[:-2]:
            num_samples = num_samples * x
        p2_width: typing.Any = 2 ** math.ceil(math.log2(width - 1)) + 1
        p2_height: typing.Any = 2 ** math.ceil(math.log2(height - 1)) + 1
        recursion_depth: typing.Any = int(
            min(math.log2(p2_width - 1) - 1, math.log2(p2_height - 1) - 1)
        )
        seed_width: typing.Any = (p2_width - 1) // 2**recursion_depth + 1
        seed_height: typing.Any = (p2_height - 1) // 2**recursion_depth + 1
>       img: typing.Any = random_scale * jax__diamond_square_seed(
            num_samples, seed_width, seed_height, random_fn, device, dtype
        )
E       TypeError: unsupported operand type(s) for *: 'jaxlib.xla_extension.ArrayImpl' and 'Tensor'

ivy_transpiled_outputs/jax_outputs/kornia/contrib/diamond_square.py:225: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.contrib.diamond_square.diamond_square
___________________________________________________________________________________ test_EdgeDetector[jax-s2s-False] ___________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_EdgeDetector(target_framework, mode, backend_compile):
        print("kornia.contrib.EdgeDetector")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledEdgeDetector = ivy.transpile(kornia.contrib.EdgeDetector, source="torch", target=target_framework)
    
        torch_detector = kornia.contrib.EdgeDetector()
        transpiled_detector = TranspiledEdgeDetector()
    
        torch_args = (
            torch.rand(1, 3, 320, 320),
        )
        torch_out = torch_detector(*torch_args)
    
        transpiled_args = _nest_torch_tensor_to_new_framework(torch_args, target_framework)
>       transpiled_out = transpiled_detector(*transpiled_args)

kornia/test_contrib.py:171: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_EdgeDetector(
  (model): jax_DexiNed(
    (block_1): jax_DoubleConvBlock(
      (conv1): FlaxConv(in_features=3, o..., 1), padding=0, padding_mode=zeros)
      (bn): FlaxBatchNorm2D(1, eps=1e-05, momentum=0.99, affine=True, 
    )
  )
)
image = Array([[[[0.3903858 , 0.367651  , 0.6543811 , ..., 0.28826892,
          0.87268084, 0.16615558],
         [0.7292358 ...2],
         [0.84213346, 0.58906585, 0.38962215, ..., 0.5907187 ,
          0.5112709 , 0.42018783]]]], dtype=float32)

    def __call__(self, image):
        from ..core.check import jax_KORNIA_CHECK_SHAPE
    
        jax_KORNIA_CHECK_SHAPE(image, ["B", "3", "H", "W"])
        img = self.preprocess(image)
>       out = self.model(img)

ivy_transpiled_outputs/jax_outputs/kornia/contrib/edge_detection.py:57: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_DexiNed(
  (block_1): jax_DoubleConvBlock(
    (conv1): FlaxConv(in_features=3, out_features=32, kernel_size=(3, 3...rides=(1, 1), padding=0, padding_mode=zeros)
    (bn): FlaxBatchNorm2D(1, eps=1e-05, momentum=0.99, affine=True, 
  )
)
x = Array([[[[0.3903858 , 0.367651  , 0.6543811 , ..., 0.28826892,
          0.87268084, 0.16615558],
         [0.7292358 ...2],
         [0.84213346, 0.58906585, 0.38962215, ..., 0.5907187 ,
          0.5112709 , 0.42018783]]]], dtype=float32)

    def __call__(self, x):
        from ...ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ..core._backend import concatenate
    
        block_1 = self.block_1(x)
>       block_1_side = self.side_1(block_1)

ivy_transpiled_outputs/jax_outputs/kornia/filters/dexined.py:611: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_SingleConvBlock(
  (conv): FlaxConv(in_features=64, out_features=128, kernel_size=(1, 1), strides=(2, 2), padding=0, padding_mode=zeros)
  (bn): FlaxBatchNorm2D(128, eps=1e-05, momentum=0.99, affine=True, 
)
x = Array([[[[-0.08871075,  0.05636391, -0.05054828, ...,  0.03467775,
          -0.02450775,  0.06578831],
         [-0.0...       [ 0.23567228, -0.12611915, -0.01061413, ...,  0.09159876,
           0.04204382, -0.00664441]]]], dtype=float32)

    def __call__(self, x):
        x = self.conv(x)
        if self.use_bn:
>           x = self.bn(x)

ivy_transpiled_outputs/jax_outputs/kornia/filters/dexined.py:372: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = FlaxBatchNorm2D(128, eps=1e-05, momentum=0.99, affine=True, 
args = (Array([[[[-0.08871075,  0.05636391, -0.05054828, ...,  0.03467775,
          -0.02450775,  0.06578831],
         [-0....     [ 0.23567228, -0.12611915, -0.01061413, ...,  0.09159876,
           0.04204382, -0.00664441]]]], dtype=float32),)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x55beeef75820, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/jax_outputs/jax__st...y', lineno=159, function='pytest_pyfunc_call', code_context=['    result = testfunction(**testargs)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/jax_outputs/jax__stateful.py:102: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = FlaxBatchNorm2D(128, eps=1e-05, momentum=0.99, affine=True, 
args = (Array([[[[-0.08871075,  0.05636391, -0.05054828, ...,  0.03467775,
          -0.02450775,  0.06578831],
         [-0....     [ 0.23567228, -0.12611915, -0.01061413, ...,  0.09159876,
           0.04204382, -0.00664441]]]], dtype=float32),)
kwargs = {}, jax_get_item = <function jax_get_item at 0x7ff7bfb76e60>, jax_set_item = <function jax_set_item at 0x7ff7bfb77010>, DATA_FORMAT = 'channels_last'
fn_args_and_kwargs = {'inputs': Array([[[[-0.08871075,  0.03133315, -0.08212467, ...,  0.24794045,
          -0.40011942,  0.0073953 ],
   ...      [ 0.04097455,  0.0608313 , -0.24814056, ..., -0.00457909,
          -0.1790712 , -0.00664441]]]], dtype=float32)}
conv_block_start = <function jax_handle_transpose_in_input_and_output.<locals>.transpose_wrapper.<locals>.<lambda> at 0x7ff7d04e16c0>, next_call_in_seq = None, conv_block_continued = None
arg_name = 'inputs'
input = Array([[[[-0.08871075,  0.05636391, -0.05054828, ...,  0.03467775,
          -0.02450775,  0.06578831],
         [-0.0...       [ 0.23567228, -0.12611915, -0.01061413, ...,  0.09159876,
           0.04204382, -0.00664441]]]], dtype=float32)
transpose = <jax_TransposeType.CONV2D: 'conv2d'>

    @functools.wraps(fn)
    def transpose_wrapper(self, *args, **kwargs):
        from ..functional.backends.jax.general import jax_get_item
        from ..functional.backends.jax.general import jax_set_item
    
        DATA_FORMAT = os.environ.get("DATA_FORMAT", "channels_first")
        kwargs_call = {
            key: val
            for key, val in kwargs.items()
            if key not in dict(original_signature.parameters)
        }
        fn_args_and_kwargs = {
            key: val for key, val in kwargs.items() if key not in kwargs_call
        }
        fn_args_and_kwargs.update(dict(zip(fn.__code__.co_varnames[1:], args)))
        conv_block_start = lambda f: any(
            substr in f.__qualname__
            for substr in CONV_FUNCS
            + NORM_FUNCS
            + POOL_FUNCS
            + KERAS_CONV_FUNCS
            + KERAS_NORM_FUNCS
            + KERAS_POOL_FUNCS
            + FLAX_CONV_FUNCS
            + FLAX_NORM_FUNCS
            + FLAX_POOL_FUNCS
        )
        next_call_in_seq = jax_get_next_func(self)
        name_of_next_call = (
            next_call_in_seq.__class__.__name__
            if hasattr(next_call_in_seq, "__class__")
            else ""
        )
        conv_block_continued = next_call_in_seq and any(
            substr in name_of_next_call for substr in CONV_BLOCK_FNS
        )
        arg_name = "input" if "input" in fn_args_and_kwargs else "inputs"
        if DATA_FORMAT == "channels_first" and conv_block_start(self.__class__):
            input = jax_get_item(fn_args_and_kwargs, arg_name)
            if len(input.shape) > 4:
                transpose = jax_TransposeType.CONV3D
            elif len(input.shape) > 3:
                transpose = jax_TransposeType.CONV2D
            elif len(input.shape) > 2:
                transpose = jax_TransposeType.CONV1D
            else:
                transpose = jax_TransposeType.NO_TRANSPOSE
            fn_args_and_kwargs = jax_set_item(
                fn_args_and_kwargs,
                arg_name,
                jax_apply_transpose(input, transpose=transpose, pt_to_tf=True),
            )
            DATA_FORMAT = "channels_last"
            os.environ = jax_set_item(os.environ, "DATA_FORMAT", DATA_FORMAT)
>       res = fn(self, **fn_args_and_kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/utils/decorator_utils.py:412: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = FlaxBatchNorm2D(128, eps=1e-05, momentum=0.99, affine=True, 
inputs = Array([[[[-0.08871075,  0.03133315, -0.08212467, ...,  0.24794045,
          -0.40011942,  0.0073953 ],
         [ 0.0...       [ 0.04097455,  0.0608313 , -0.24814056, ..., -0.00457909,
          -0.1790712 , -0.00664441]]]], dtype=float32)
use_running_average = None

    @store_frame_info
    @jax_handle_transpose_in_input_and_output
    def __call__(self, inputs, use_running_average=None, *, mask=None):
        self._built = True
>       logits = super().__call__(
            inputs, use_running_average=use_running_average, mask=mask
        )

ivy_transpiled_outputs/jax_outputs/jax__stateful_layers.py:479: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = FlaxBatchNorm2D(128, eps=1e-05, momentum=0.99, affine=True, 
x = Array([[[[-0.08871075,  0.03133315, -0.08212467, ...,  0.24794045,
          -0.40011942,  0.0073953 ],
         [ 0.0...       [ 0.04097455,  0.0608313 , -0.24814056, ..., -0.00457909,
          -0.1790712 , -0.00664441]]]], dtype=float32)
use_running_average = True

    def __call__(
      self,
      x,
      use_running_average: tp.Optional[bool] = None,
      *,
      mask: tp.Optional[jax.Array] = None,
    ):
      """Normalizes the input using batch statistics.
    
      Args:
        x: the input to be normalized.
        use_running_average: if true, the stored batch statistics will be
          used instead of computing the batch statistics on the input. The
          ``use_running_average`` flag passed into the call method will take
          precedence over the ``use_running_average`` flag passed into the
          constructor.
    
      Returns:
        Normalized inputs (the same shape as inputs).
      """
    
      use_running_average = first_from(
        use_running_average,
        self.use_running_average,
        error_msg="""No `use_running_average` argument was provided to BatchNorm
          as either a __call__ argument, class attribute, or nnx.flag.""",
      )
      feature_axes = _canonicalize_axes(x.ndim, self.axis)
      reduction_axes = tuple(i for i in range(x.ndim) if i not in feature_axes)
    
      if use_running_average:
        mean, var = self.mean.value, self.var.value
      else:
        mean, var = _compute_stats(
          x,
          reduction_axes,
          dtype=self.dtype,
          axis_name=self.axis_name,
          axis_index_groups=self.axis_index_groups,
          use_fast_variance=self.use_fast_variance,
          mask=mask,
        )
    
        self.mean.value = (
          self.momentum * self.mean.value + (1 - self.momentum) * mean
        )
        self.var.value = (
          self.momentum * self.var.value + (1 - self.momentum) * var
        )
    
>     return _normalize(
        x,
        mean,
        var,
        self.scale.value,
        self.bias.value,
        reduction_axes,
        feature_axes,
        self.dtype,
        self.epsilon,
      )

/opt/fw/jax/flax/nnx/nnx/nn/normalization.py:367: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = Array([[[[-0.08871075,  0.03133315, -0.08212467, ...,  0.24794045,
          -0.40011942,  0.0073953 ],
         [ 0.0...       [ 0.04097455,  0.0608313 , -0.24814056, ..., -0.00457909,
          -0.1790712 , -0.00664441]]]], dtype=float32)
mean = Param(
  value=Array([-0.2449035 ,  0.32071695, -0.8167501 , -0.30144545, -0.18064821,
          0.00530162,  0.227697..., -0.6198849 , -0.3519681 ,  0.04875631, -0.61422706,
          0.27642408, -0.27212012, -0.04358729], dtype=float32)
)
var = Param(
  value=Array([0.2625539 , 0.27113461, 0.21946596, 0.15521275, 0.25643   ,
         0.21336786, 0.39907008, 0.2...8342604, 0.5336697 , 0.19832538, 0.22804523, 0.6139669 ,
         0.32740036, 0.37694854, 0.2545803 ], dtype=float32)
)
scale = Array([0.9180028 , 0.85888755, 0.83077097, 0.8763835 , 0.96300054,
       0.8625907 , 0.8677793 , 0.9038065 , 0.968281... 0.9293163 , 0.97165966, 0.9689161 , 0.9450734 , 0.8873313 ,
       0.88254374, 0.99936277, 0.848198  ], dtype=float32)
bias = Array([-0.07675791, -0.03457952, -0.06084337,  0.0461219 , -0.04142413,
        0.07173445, -0.01962172,  0.00044565, ...8167, -0.02156175, -0.02820837,  0.02331718, -0.01897949,
        0.0239033 ,  0.00923689, -0.05559541], dtype=float32)
reduction_axes = (0, 1, 2), feature_axes = (3,), dtype = None, epsilon = 1e-05

    def _normalize(
      x: Array,
      mean: Array,
      var: Array,
      scale: tp.Optional[Array],
      bias: tp.Optional[Array],
      reduction_axes: Axes,
      feature_axes: Axes,
      dtype: tp.Optional[Dtype],
      epsilon: float,
    ):
      """ "Normalizes the input of a normalization layer and optionally applies a learned scale and bias.
    
      Arguments:
        x: The input.
        mean: Mean to use for normalization.
        var: Variance to use for normalization.
        reduction_axes: The axes in ``x`` to reduce.
        feature_axes: Axes containing features. A separate bias and scale is learned
          for each specified feature.
        dtype: The dtype of the result (default: infer from input and params).
        epsilon: Normalization epsilon.
    
      Returns:
        The normalized input.
      """
      reduction_axes = _canonicalize_axes(x.ndim, reduction_axes)
      feature_axes = _canonicalize_axes(x.ndim, feature_axes)
      stats_shape = list(x.shape)
      for axis in reduction_axes:
        stats_shape[axis] = 1
>     mean = mean.reshape(stats_shape)

/opt/fw/jax/flax/nnx/nnx/nn/normalization.py:163: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = Param(
  value=Array([-0.2449035 ,  0.32071695, -0.8167501 , -0.30144545, -0.18064821,
          0.00530162,  0.227697..., -0.6198849 , -0.3519681 ,  0.04875631, -0.61422706,
          0.27642408, -0.27212012, -0.04358729], dtype=float32)
)
name = 'reshape'

    def custom_getattr(self, name):
        if name in ("shape", "device", "dtype", "ndim", "size", "itemsize", "T"):
            value = getattr(self, "value")
            if value is not None:
                # Attempt to retrieve the attribute from the wrapped object (`value`)
                return getattr(value, name)
>       return object.__getattribute__(self, name)
E       AttributeError: 'Param' object has no attribute 'reshape'. Did you mean: 'shape'?

ivy_transpiled_outputs/jax_outputs/__init__.py:91: AttributeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.contrib.EdgeDetector
----------------------------------------------------------------------------------------- Captured stderr call -----------------------------------------------------------------------------------------
Downloading: "http://cmp.felk.cvut.cz/~mishkdmy/models/DexiNed_BIPED_10.pth" to /root/.cache/torch/hub/checkpoints/DexiNed_BIPED_10.pth

  0%|          | 0.00/135M [00:00<?, ?B/s]
  0%|          | 128k/135M [00:00<08:49, 266kB/s]
  0%|          | 256k/135M [00:00<05:21, 438kB/s]
  0%|          | 512k/135M [00:00<02:55, 802kB/s]
  1%|          | 896k/135M [00:00<01:47, 1.30MB/s]
  1%|         | 1.75M/135M [00:01<00:53, 2.62MB/s]
  3%|         | 3.50M/135M [00:01<00:26, 5.23MB/s]
  5%|         | 6.25M/135M [00:01<00:15, 8.95MB/s]
  7%|         | 9.25M/135M [00:01<00:10, 12.0MB/s]
  9%|         | 12.1M/135M [00:01<00:09, 13.9MB/s]
 11%|         | 15.0M/135M [00:01<00:08, 15.3MB/s]
 13%|        | 18.0M/135M [00:02<00:07, 16.4MB/s]
 16%|        | 21.0M/135M [00:02<00:06, 17.2MB/s]
 18%|        | 23.9M/135M [00:02<00:06, 17.6MB/s]
 20%|        | 26.9M/135M [00:02<00:06, 18.0MB/s]
 22%|       | 29.6M/135M [00:02<00:06, 17.9MB/s]
 24%|       | 32.6M/135M [00:02<00:05, 18.1MB/s]
 26%|       | 35.6M/135M [00:03<00:05, 18.4MB/s]
 29%|       | 38.6M/135M [00:03<00:05, 18.6MB/s]
 31%|       | 41.5M/135M [00:03<00:05, 18.6MB/s]
 33%|      | 44.5M/135M [00:03<00:05, 18.7MB/s]
 35%|      | 47.4M/135M [00:03<00:04, 18.5MB/s]
 37%|      | 50.2M/135M [00:03<00:04, 18.5MB/s]
 40%|      | 53.2M/135M [00:04<00:04, 18.7MB/s]
 42%|     | 56.2M/135M [00:04<00:04, 18.8MB/s]
 44%|     | 59.1M/135M [00:04<00:04, 18.7MB/s]
 46%|     | 62.1M/135M [00:04<00:04, 18.8MB/s]
 48%|     | 65.1M/135M [00:04<00:03, 18.9MB/s]
 50%|     | 67.8M/135M [00:04<00:03, 18.3MB/s]
 53%|    | 70.8M/135M [00:05<00:03, 18.5MB/s]
 55%|    | 73.6M/135M [00:05<00:03, 18.5MB/s]
 57%|    | 76.5M/135M [00:05<00:03, 18.4MB/s]
 59%|    | 79.4M/135M [00:05<00:03, 18.4MB/s]
 61%|    | 82.2M/135M [00:05<00:02, 18.4MB/s]
 63%|   | 85.2M/135M [00:05<00:02, 18.6MB/s]
 66%|   | 88.1M/135M [00:06<00:02, 18.5MB/s]
 68%|   | 91.1M/135M [00:06<00:02, 18.7MB/s]
 70%|   | 94.0M/135M [00:06<00:02, 18.6MB/s]
 72%|  | 97.0M/135M [00:06<00:02, 18.8MB/s]
 74%|  | 99.9M/135M [00:06<00:01, 18.6MB/s]
 76%|  | 102M/135M [00:06<00:01, 18.1MB/s] 
 78%|  | 105M/135M [00:07<00:01, 18.1MB/s]
 80%|  | 108M/135M [00:07<00:01, 18.2MB/s]
 83%| | 111M/135M [00:07<00:01, 18.0MB/s]
 85%| | 114M/135M [00:07<00:01, 18.3MB/s]
 87%| | 117M/135M [00:07<00:01, 18.3MB/s]
 89%| | 120M/135M [00:07<00:00, 18.6MB/s]
 91%|| 123M/135M [00:08<00:00, 18.6MB/s]
 93%|| 126M/135M [00:08<00:00, 18.6MB/s]
 96%|| 129M/135M [00:08<00:00, 18.5MB/s]
 98%|| 132M/135M [00:08<00:00, 18.5MB/s]
100%|| 134M/135M [00:08<00:00, 18.2MB/s]
100%|| 135M/135M [00:08<00:00, 16.2MB/s]
__________________________________________________________________________________ test_ImageStitcher[jax-s2s-False] ___________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_ImageStitcher(target_framework, mode, backend_compile):
        print("kornia.contrib.ImageStitcher")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledLoFTR = ivy.transpile(kornia.feature.LoFTR, source="torch", target=target_framework)
        TranspiledImageStitcher = ivy.transpile(kornia.contrib.ImageStitcher, source="torch", target=target_framework)
    
        torch_matcher = kornia.feature.LoFTR(pretrained='outdoor')
>       transpiled_matcher = TranspiledLoFTR(pretrained='outdoor')

kornia/test_contrib.py:314: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.loftr.loftr.jax_LoFTR'>, args = (), kwargs = {'pretrained': 'outdoor'}

    def __call__(cls, *args: Any, **kwargs: Any) -> Any:
>     return _graph_node_meta_call(cls, *args, **kwargs)

/opt/fw/jax/flax/nnx/nnx/object.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.loftr.loftr.jax_LoFTR'>, args = (), kwargs = {'pretrained': 'outdoor'}, node = jax_LoFTR()

    def _graph_node_meta_call(cls: tp.Type[G], *args, **kwargs) -> G:
      node = cls.__new__(cls, *args, **kwargs)
      vars(node)['_object__state'] = ObjectState()
>     cls._object_meta_construct(node, *args, **kwargs)

/opt/fw/jax/flax/nnx/nnx/object.py:88: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.loftr.loftr.jax_LoFTR'>, self = jax_LoFTR(), args = (), kwargs = {'pretrained': 'outdoor'}

    def _object_meta_construct(cls, self, *args, **kwargs):
>     self.__init__(*args, **kwargs)

/opt/fw/jax/flax/nnx/nnx/object.py:82: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_LoFTR(), pretrained = 'outdoor'
config = {'backbone_type': 'ResNetFPN', 'coarse': {'attention': 'linear', 'd_ffn': 256, 'd_model': 256, 'layer_names': ['self',...: 'linear', 'd_ffn': 128, 'd_model': 128, 'layer_names': ['self', 'cross'], ...}, 'fine_concat_coarse_feat': True, ...}

    def __init__(self, pretrained="outdoor", config=default_cfg):
        from ....ivy.functional.backends.jax.general import jax_set_item
        from .backbone.__init__ import jax_build_backbone
        from .utils.position_encoding import jax_PositionEncodingSine
        from .loftr_module.transformer import jax_LocalFeatureTransformer
        from .utils.coarse_matching import jax_CoarseMatching
        from .loftr_module.fine_preprocess import jax_FinePreprocess
        from .utils.fine_matching import jax_FineMatching
        from ....ivy.functional.frontends.torch.hub.hub import (
            jax_load_state_dict_from_url_frnt,
        )
        from ....ivy.functional.backends.jax.general import jax_get_item
        from ...utils.helpers import jax_map_location_to_cpu
    
        self.super___init__(
            pretrained=pretrained,
            config=config,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        self.config = config
        if pretrained == "indoor_new":
            self.config["coarse"] = jax_set_item(
                self.config["coarse"], "temp_bug_fix", True
            )
>       self.backbone = jax_build_backbone(config)

ivy_transpiled_outputs/jax_outputs/kornia/feature/loftr/loftr.py:108: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

config = {'backbone_type': 'ResNetFPN', 'coarse': {'attention': 'linear', 'd_ffn': 256, 'd_model': 256, 'layer_names': ['self',...: 'linear', 'd_ffn': 128, 'd_model': 128, 'layer_names': ['self', 'cross'], ...}, 'fine_concat_coarse_feat': True, ...}

    def jax_build_backbone(config):
        if config["backbone_type"] == "ResNetFPN":
            if config["resolution"] == (8, 2):
>               return kornia.feature.loftr.resnet_fpn.ResNetFPN_8_2(config["resnetfpn"])
E               NameError: name 'kornia' is not defined

ivy_transpiled_outputs/jax_outputs/kornia/feature/loftr/backbone/__init__.py:42: NameError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.contrib.ImageStitcher
----------------------------------------------------------------------------------------- Captured stderr call -----------------------------------------------------------------------------------------
Downloading: "http://cmp.felk.cvut.cz/~mishkdmy/models/loftr_outdoor.ckpt" to /root/.cache/torch/hub/checkpoints/loftr_outdoor.ckpt

  0%|          | 0.00/44.2M [00:00<?, ?B/s]
  0%|          | 128k/44.2M [00:00<02:53, 266kB/s]
  1%|          | 256k/44.2M [00:00<01:45, 437kB/s]
  1%|          | 512k/44.2M [00:00<00:57, 801kB/s]
  2%|         | 896k/44.2M [00:00<00:34, 1.30MB/s]
  4%|         | 1.75M/44.2M [00:01<00:17, 2.62MB/s]
  8%|         | 3.50M/44.2M [00:01<00:08, 5.22MB/s]
 15%|        | 6.50M/44.2M [00:01<00:04, 9.44MB/s]
 21%|       | 9.50M/44.2M [00:01<00:02, 12.4MB/s]
 28%|       | 12.4M/44.2M [00:01<00:02, 14.2MB/s]
 35%|      | 15.4M/44.2M [00:01<00:01, 15.7MB/s]
 41%|     | 18.2M/44.2M [00:02<00:01, 16.5MB/s]
 48%|     | 21.2M/44.2M [00:02<00:01, 17.3MB/s]
 55%|    | 24.2M/44.2M [00:02<00:01, 17.8MB/s]
 61%|   | 27.1M/44.2M [00:02<00:00, 18.0MB/s]
 68%|   | 30.1M/44.2M [00:02<00:00, 18.2MB/s]
 75%|  | 33.0M/44.2M [00:02<00:00, 18.4MB/s]
 81%|  | 35.9M/44.2M [00:03<00:00, 18.2MB/s]
 88%| | 38.8M/44.2M [00:03<00:00, 18.3MB/s]
 94%|| 41.8M/44.2M [00:03<00:00, 18.5MB/s]
100%|| 44.2M/44.2M [00:03<00:00, 13.4MB/s]
______________________________________________________________________________________ test_Lambda[jax-s2s-False] ______________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_Lambda(target_framework, mode, backend_compile):
        print("kornia.contrib.Lambda")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_fn = ivy.transpile(kornia.color.rgb_to_grayscale, source="torch", target=target_framework)
        TranspiledLambda = ivy.transpile(kornia.contrib.Lambda, source="torch", target=target_framework)
    
        x = torch.rand(1, 3, 5, 5)
        torch_out = kornia.contrib.Lambda(lambda x: kornia.color.rgb_to_grayscale(x))(x)
    
        transpiled_x = _nest_torch_tensor_to_new_framework(x, target_framework)
>       transpiled_out = TranspiledLambda(lambda x: transpiled_fn(x))(transpiled_x)

kornia/test_contrib.py:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_Lambda()
img = Array([[[[0.24838495, 0.16381115, 0.9520681 , 0.86008495, 0.6474858 ],
         [0.6257968 , 0.8783659 , 0.41070157, 0... 0.75066984, 0.3293057 ],
         [0.561671  , 0.05817503, 0.5122101 , 0.06966799, 0.7259842 ]]]],      dtype=float32)
args = (), kwargs = {}

    def __call__(self, img, *args, **kwargs):
>       return self.func(img, *args, **kwargs)

ivy_transpiled_outputs/jax_outputs/kornia/contrib/lambda_module.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = Array([[[[0.24838495, 0.16381115, 0.9520681 , 0.86008495, 0.6474858 ],
         [0.6257968 , 0.8783659 , 0.41070157, 0... 0.75066984, 0.3293057 ],
         [0.561671  , 0.05817503, 0.5122101 , 0.06966799, 0.7259842 ]]]],      dtype=float32)

>   transpiled_out = TranspiledLambda(lambda x: transpiled_fn(x))(transpiled_x)

kornia/test_contrib.py:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

image = Array([[[[0.24838495, 0.16381115, 0.9520681 , 0.86008495, 0.6474858 ],
         [0.6257968 , 0.8783659 , 0.41070157, 0... 0.75066984, 0.3293057 ],
         [0.561671  , 0.05817503, 0.5122101 , 0.06966799, 0.7259842 ]]]],      dtype=float32)
rgb_weights = None

>   ???
E   ModuleNotFoundError: No module named 'ivy_transpiled_outputs.jax_outputs.kornia.core'

/ivy/ivy-integration-tests/ivy_transpiled_outputs/jax_outputs/kornia/color/gray.py:32: ModuleNotFoundError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.contrib.Lambda
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/test_contrib.py::test_diamond_square[jax-s2s-False] - TypeError: unsupported operand type(s) for *: 'jaxlib.xla_extension.ArrayImpl' and 'Tensor'
FAILED kornia/test_contrib.py::test_EdgeDetector[jax-s2s-False] - AttributeError: 'Param' object has no attribute 'reshape'. Did you mean: 'shape'?
FAILED kornia/test_contrib.py::test_ImageStitcher[jax-s2s-False] - NameError: name 'kornia' is not defined
FAILED kornia/test_contrib.py::test_Lambda[jax-s2s-False] - ModuleNotFoundError: No module named 'ivy_transpiled_outputs.jax_outputs.kornia.core'
============================================================================== 4 failed, 11 passed in 1526.31s (0:25:26) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 17 items

kornia/augmentation/test_augmentation4.py FF.....F...F..FFF                                                                                                                                      [100%]

=============================================================================================== FAILURES ===============================================================================================
_______________________________________________________________________________ test_RandomMosaic[tensorflow-s2s-False] ________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_RandomMosaic(target_framework, mode, backend_compile):
        print("kornia.augmentation.RandomMosaic")
    
        init_args = ((300, 300),)
        init_kwargs = {"data_keys": ["input", "bbox_xyxy"]}
        call_args = (
            torch.randn(8, 3, 224, 224),
            torch.tensor([[
                [70, 5, 150, 100],
                [60, 180, 175, 220],
            ]]).repeat(8, 1, 1),
        )
        call_kwargs = {}
    
>       _test_augmentation_class(
            kornia.augmentation.RandomMosaic,
            target_framework,
            init_args,
            init_kwargs,
            call_args,
            call_kwargs,
            deterministic_output=False,
            backend_compile=backend_compile,
        )

kornia/augmentation/test_augmentation4.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

augmentation_cls = <class 'kornia.augmentation._2d.mix.mosaic.RandomMosaic'>, target = 'tensorflow', init_args = ((300, 300),), init_kwargs = {'data_keys': ['input', 'bbox_xyxy']}
call_args = (tensor([[[[-4.8530e-02,  3.9875e-01, -1.6448e+00,  ...,  9.9163e-01,
           -1.6396e-01, -1.0020e+00],
          ...[ 70,   5, 150, 100],
         [ 60, 180, 175, 220]],

        [[ 70,   5, 150, 100],
         [ 60, 180, 175, 220]]]))
call_kwargs = {}, deterministic_output = False, backend_compile = False, tolerance = 0.001

    def _test_augmentation_class(
        augmentation_cls,
        target,
        init_args=(),
        init_kwargs={},
        call_args=(),
        call_kwargs={},
        deterministic_output=True,
        backend_compile=False,
        tolerance=1e-3,
    ):
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_cls = ivy.transpile(augmentation_cls, source="torch", target=target)
    
        torch_aug = augmentation_cls(*init_args, **init_kwargs)
        transpiled_init_args = _nest_torch_tensor_to_new_framework(init_args, target)
        transpiled_init_kwargs = _nest_torch_tensor_to_new_framework(init_kwargs, target)
        transpiled_aug = transpiled_cls(*transpiled_init_args, **transpiled_init_kwargs)
    
        # assert dir(torch_aug) == dir(transpiled_aug), f"attributes/methods of transpiled object do not align with the original - orig: {dir(torch_aug)} != transpiled: {dir(transpiled_aug)}"
    
        torch_out = torch_aug(*call_args, **call_kwargs)
        transpiled_call_args = _nest_torch_tensor_to_new_framework(call_args, target)
        transpiled_call_kwargs = _nest_torch_tensor_to_new_framework(call_kwargs, target)
>       transpiled_out = transpiled_aug(*transpiled_call_args, **transpiled_call_kwargs)

kornia/augmentation/test_augmentation4.py:43: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomMosaic(output_size=(300, 300), mosaic_grid=(2, 2), start_ratio_range=(0.3, 0.7), p=0.7, p_batch=1.0, ..._size=(300, 300), min_bbox_size=0.0, padding_mode=constant, resample=bilinear, align_corners=True, cropping_mode=slice)
args = (<tf.Tensor: shape=(8, 3, 224, 224), dtype=float32, numpy=
array([[[[-4.85302620e-02,  3.98753285e-01, -1.64482164e+00... [[ 70,   5, 150, 100],
        [ 60, 180, 175, 220]],

       [[ 70,   5, 150, 100],
        [ 60, 180, 175, 220]]])>)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x7fcae82eb840, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...kexec', code_context=['        return self._inner_hookexec(hook_name, methods, kwargs, firstresult)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomMosaic(output_size=(300, 300), mosaic_grid=(2, 2), start_ratio_range=(0.3, 0.7), p=0.7, p_batch=1.0,... [[ 70,   5, 150, 100],
        [ 60, 180, 175, 220]],

       [[ 70,   5, 150, 100],
        [ 60, 180, 175, 220]]])>)
kwargs = {}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomMosaic(output_size=(300, 300), mosaic_grid=(2, 2), start_ratio_range=(0.3, 0.7), p=0.7, p_batch=1.0, ..._size=(300, 300), min_bbox_size=0.0, padding_mode=constant, resample=bilinear, align_corners=True, cropping_mode=slice)
v = None, buffers = None
args = (<tf.Tensor: shape=(8, 3, 224, 224), dtype=float32, numpy=
array([[[[-4.85302620e-02,  3.98753285e-01, -1.64482164e+00... [[ 70,   5, 150, 100],
        [ 60, 180, 175, 220]],

       [[ 70,   5, 150, 100],
        [ 60, 180, 175, 220]]])>)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomMosaic(output_size=(300, 300), mosaic_grid=(2, 2), start_ratio_range=(0.3, 0.7), p=0.7, p_batch=1.0,... [[ 70,   5, 150, 100],
        [ 60, 180, 175, 220]],

       [[ 70,   5, 150, 100],
        [ 60, 180, 175, 220]]])>)
kwargs = {'buffers': None, 'v': None}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomMosaic(output_size=(300, 300), mosaic_grid=(2, 2), start_ratio_range=(0.3, 0.7), p=0.7, p_batch=1.0, ..._size=(300, 300), min_bbox_size=0.0, padding_mode=constant, resample=bilinear, align_corners=True, cropping_mode=slice)
v = None, buffers = None
args = (<tf.Tensor: shape=(8, 3, 224, 224), dtype=float32, numpy=
array([[[[-4.85302620e-02,  3.98753285e-01, -1.64482164e+00... [[ 70,   5, 150, 100],
        [ 60, 180, 175, 220]],

       [[ 70,   5, 150, 100],
        [ 60, 180, 175, 220]]])>)
kwargs = {}
first_arr = <tf.Tensor: shape=(8, 3, 224, 224), dtype=float32, numpy=
array([[[[-4.85302620e-02,  3.98753285e-01, -1.64482164e+00,...19562e+00, -1.55068457e+00, ...,
           4.78754938e-01,  2.16482937e-01,  7.31021106e-01]]]],
      dtype=float32)>
replace_v = False, replace_buffers = False, call_signature = <Signature (*input, params=None, data_keys=None)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Layer, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Layer, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Layer, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomMosaic(output_size=(300, 300), mosaic_grid=(2, 2), start_ratio_range=(0.3, 0.7), p=0.7, p_batch=1.0,...ize=(300, 300), min_bbox_size=0.0, padding_mode=constant, resample=bilinear, align_corners=True, cropping_mode=slice),)
kwargs = {'input': <tf.Tensor: shape=(8, 3, 224, 224), dtype=float32, numpy=
array([[[[-4.85302620e-02,  3.98753285e-01, -1.644... [[ 70,   5, 150, 100],
        [ 60, 180, 175, 220]],

       [[ 70,   5, 150, 100],
        [ 60, 180, 175, 220]]])>}

    @wraps(fn)
    def error_handler(*args, **kwargs):
        if not is_traceback_filtering_enabled():
            return fn(*args, **kwargs)
    
        filtered_tb = None
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            filtered_tb = _process_traceback_frames(e.__traceback__)
            # To get the full stack trace, call:
            # `keras.config.disable_traceback_filtering()`
>           raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/keras/src/utils/traceback_utils.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <Signature (*input, params=None, data_keys=None)>, args = ()
kwargs = {'input': <tf.Tensor: shape=(8, 3, 224, 224), dtype=float32, numpy=
array([[[[-4.85302620e-02,  3.98753285e-01, -1.644...9562e+00, -1.55068457e+00, ...,
           4.78754938e-01,  2.16482937e-01,  7.31021106e-01]]]],
      dtype=float32)>}

    def bind(self, /, *args, **kwargs):
        """Get a BoundArguments object, that maps the passed `args`
        and `kwargs` to the function's signature.  Raises `TypeError`
        if the passed arguments can not be bound.
        """
>       return self._bind(args, kwargs)

/opt/miniconda/envs/multienv/lib/python3.10/inspect.py:3177: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <Signature (*input, params=None, data_keys=None)>, args = ()
kwargs = {'input': <tf.Tensor: shape=(8, 3, 224, 224), dtype=float32, numpy=
array([[[[-4.85302620e-02,  3.98753285e-01, -1.644...9562e+00, -1.55068457e+00, ...,
           4.78754938e-01,  2.16482937e-01,  7.31021106e-01]]]],
      dtype=float32)>}

    def _bind(self, args, kwargs, *, partial=False):
        """Private method. Don't use directly."""
    
        arguments = {}
    
        parameters = iter(self.parameters.values())
        parameters_ex = ()
        arg_vals = iter(args)
    
        while True:
            # Let's iterate through the positional arguments and corresponding
            # parameters
            try:
                arg_val = next(arg_vals)
            except StopIteration:
                # No more positional arguments
                try:
                    param = next(parameters)
                except StopIteration:
                    # No more parameters. That's it. Just need to check that
                    # we have no `kwargs` after this while loop
                    break
                else:
                    if param.kind == _VAR_POSITIONAL:
                        # That's OK, just empty *args.  Let's start parsing
                        # kwargs
                        break
                    elif param.name in kwargs:
                        if param.kind == _POSITIONAL_ONLY:
                            msg = '{arg!r} parameter is positional only, ' \
                                  'but was passed as a keyword'
                            msg = msg.format(arg=param.name)
                            raise TypeError(msg) from None
                        parameters_ex = (param,)
                        break
                    elif (param.kind == _VAR_KEYWORD or
                                                param.default is not _empty):
                        # That's fine too - we have a default value for this
                        # parameter.  So, lets start parsing `kwargs`, starting
                        # with the current parameter
                        parameters_ex = (param,)
                        break
                    else:
                        # No default, not VAR_KEYWORD, not VAR_POSITIONAL,
                        # not in `kwargs`
                        if partial:
                            parameters_ex = (param,)
                            break
                        else:
                            msg = 'missing a required argument: {arg!r}'
                            msg = msg.format(arg=param.name)
                            raise TypeError(msg) from None
            else:
                # We have a positional argument to process
                try:
                    param = next(parameters)
                except StopIteration:
                    raise TypeError('too many positional arguments') from None
                else:
                    if param.kind in (_VAR_KEYWORD, _KEYWORD_ONLY):
                        # Looks like we have no parameter for this positional
                        # argument
                        raise TypeError(
                            'too many positional arguments') from None
    
                    if param.kind == _VAR_POSITIONAL:
                        # We have an '*args'-like argument, let's fill it with
                        # all positional arguments we have left and move on to
                        # the next phase
                        values = [arg_val]
                        values.extend(arg_vals)
                        arguments[param.name] = tuple(values)
                        break
    
                    if param.name in kwargs and param.kind != _POSITIONAL_ONLY:
                        raise TypeError(
                            'multiple values for argument {arg!r}'.format(
                                arg=param.name)) from None
    
                    arguments[param.name] = arg_val
    
        # Now, we iterate through the remaining parameters to process
        # keyword arguments
        kwargs_param = None
        for param in itertools.chain(parameters_ex, parameters):
            if param.kind == _VAR_KEYWORD:
                # Memorize that we have a '**kwargs'-like parameter
                kwargs_param = param
                continue
    
            if param.kind == _VAR_POSITIONAL:
                # Named arguments don't refer to '*args'-like parameters.
                # We only arrive here if the positional arguments ended
                # before reaching the last parameter before *args.
                continue
    
            param_name = param.name
            try:
                arg_val = kwargs.pop(param_name)
            except KeyError:
                # We have no value for this parameter.  It's fine though,
                # if it has a default value, or it is an '*args'-like
                # parameter, left alone by the processing of positional
                # arguments.
                if (not partial and param.kind != _VAR_POSITIONAL and
                                                    param.default is _empty):
                    raise TypeError('missing a required argument: {arg!r}'. \
                                    format(arg=param_name)) from None
    
            else:
                if param.kind == _POSITIONAL_ONLY:
                    # This should never happen in case of a properly built
                    # Signature object (but let's have this check here
                    # to ensure correct behaviour just in case)
                    raise TypeError('{arg!r} parameter is positional only, '
                                    'but was passed as a keyword'. \
                                    format(arg=param.name))
    
                arguments[param_name] = arg_val
    
        if kwargs:
            if kwargs_param is not None:
                # Process our '**kwargs'-like parameter
                arguments[kwargs_param.name] = kwargs
            else:
>               raise TypeError(
                    'got an unexpected keyword argument {arg!r}'.format(
                        arg=next(iter(kwargs))))
E               TypeError: got an unexpected keyword argument 'input'

/opt/miniconda/envs/multienv/lib/python3.10/inspect.py:3166: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.RandomMosaic
___________________________________________________________________________ test_RandomTransplantation[tensorflow-s2s-False] ___________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_RandomTransplantation(target_framework, mode, backend_compile):
        print("kornia.augmentation.RandomTransplantation")
    
        init_args = ()
        init_kwargs = {"p": 1.}
        call_args = (torch.randn(2, 3, 5, 5), torch.randint(0, 3, (2, 5, 5)))
        call_kwargs = {}
    
>       _test_augmentation_class(
            kornia.augmentation.RandomTransplantation,
            target_framework,
            init_args,
            init_kwargs,
            call_args,
            call_kwargs,
            deterministic_output=False,
            backend_compile=backend_compile,
        )

kornia/augmentation/test_augmentation4.py:99: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

augmentation_cls = <class 'kornia.augmentation._2d.mix.transplantation.RandomTransplantation'>, target = 'tensorflow', init_args = (), init_kwargs = {'p': 1.0}
call_args = (tensor([[[[ 0.3470,  0.0685, -0.5236,  1.7079, -1.0833],
          [ 0.3099, -0.5293, -0.1608, -0.3365, -0.1397],
   ...2, 1, 2, 1],
         [2, 1, 1, 1, 1],
         [1, 1, 2, 2, 2],
         [1, 1, 2, 2, 0],
         [2, 0, 1, 1, 1]]]))
call_kwargs = {}, deterministic_output = False, backend_compile = False, tolerance = 0.001

    def _test_augmentation_class(
        augmentation_cls,
        target,
        init_args=(),
        init_kwargs={},
        call_args=(),
        call_kwargs={},
        deterministic_output=True,
        backend_compile=False,
        tolerance=1e-3,
    ):
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_cls = ivy.transpile(augmentation_cls, source="torch", target=target)
    
        torch_aug = augmentation_cls(*init_args, **init_kwargs)
        transpiled_init_args = _nest_torch_tensor_to_new_framework(init_args, target)
        transpiled_init_kwargs = _nest_torch_tensor_to_new_framework(init_kwargs, target)
        transpiled_aug = transpiled_cls(*transpiled_init_args, **transpiled_init_kwargs)
    
        # assert dir(torch_aug) == dir(transpiled_aug), f"attributes/methods of transpiled object do not align with the original - orig: {dir(torch_aug)} != transpiled: {dir(transpiled_aug)}"
    
        torch_out = torch_aug(*call_args, **call_kwargs)
        transpiled_call_args = _nest_torch_tensor_to_new_framework(call_args, target)
        transpiled_call_kwargs = _nest_torch_tensor_to_new_framework(call_kwargs, target)
>       transpiled_out = transpiled_aug(*transpiled_call_args, **transpiled_call_kwargs)

kornia/augmentation/test_augmentation4.py:43: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomTransplantation(p=1.0, p_batch=1.0, same_on_batch=False)
args = (<tf.Tensor: shape=(2, 3, 5, 5), dtype=float32, numpy=
array([[[[ 0.34703526,  0.06851114, -0.5236001 ,  1.7079297 ,
 ...2, 2, 1, 2, 1],
        [2, 1, 1, 1, 1],
        [1, 1, 2, 2, 2],
        [1, 1, 2, 2, 0],
        [2, 0, 1, 1, 1]]])>)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x7fcae8453040, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...kexec', code_context=['        return self._inner_hookexec(hook_name, methods, kwargs, firstresult)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomTransplantation(p=1.0, p_batch=1.0, same_on_batch=False), <tf.Tensor: shape=(2, 3, 5, 5), dtype=floa...2, 2, 1, 2, 1],
        [2, 1, 1, 1, 1],
        [1, 1, 2, 2, 2],
        [1, 1, 2, 2, 0],
        [2, 0, 1, 1, 1]]])>)
kwargs = {}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomTransplantation(p=1.0, p_batch=1.0, same_on_batch=False), v = None, buffers = None
args = (<tf.Tensor: shape=(2, 3, 5, 5), dtype=float32, numpy=
array([[[[ 0.34703526,  0.06851114, -0.5236001 ,  1.7079297 ,
 ...2, 2, 1, 2, 1],
        [2, 1, 1, 1, 1],
        [1, 1, 2, 2, 2],
        [1, 1, 2, 2, 0],
        [2, 0, 1, 1, 1]]])>)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomTransplantation(p=1.0, p_batch=1.0, same_on_batch=False), <tf.Tensor: shape=(2, 3, 5, 5), dtype=floa...2, 2, 1, 2, 1],
        [2, 1, 1, 1, 1],
        [1, 1, 2, 2, 2],
        [1, 1, 2, 2, 0],
        [2, 0, 1, 1, 1]]])>)
kwargs = {'buffers': None, 'v': None}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomTransplantation(p=1.0, p_batch=1.0, same_on_batch=False), v = None, buffers = None
args = (<tf.Tensor: shape=(2, 3, 5, 5), dtype=float32, numpy=
array([[[[ 0.34703526,  0.06851114, -0.5236001 ,  1.7079297 ,
 ...2, 2, 1, 2, 1],
        [2, 1, 1, 1, 1],
        [1, 1, 2, 2, 2],
        [1, 1, 2, 2, 0],
        [2, 0, 1, 1, 1]]])>)
kwargs = {}
first_arr = <tf.Tensor: shape=(2, 3, 5, 5), dtype=float32, numpy=
array([[[[ 0.34703526,  0.06851114, -0.5236001 ,  1.7079297 ,
  ... -0.24848117],
         [-0.9647657 , -0.9770897 ,  0.5254606 , -0.38090822,
          -0.41989362]]]], dtype=float32)>
replace_v = False, replace_buffers = False, call_signature = <Signature (*input, params=None, data_keys=None, **kwargs)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Layer, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Layer, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Layer, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomTransplantation(p=1.0, p_batch=1.0, same_on_batch=False),)
kwargs = {'input': <tf.Tensor: shape=(2, 3, 5, 5), dtype=float32, numpy=
array([[[[ 0.34703526,  0.06851114, -0.5236001 ,  1.70...2, 2, 1, 2, 1],
        [2, 1, 1, 1, 1],
        [1, 1, 2, 2, 2],
        [1, 1, 2, 2, 0],
        [2, 0, 1, 1, 1]]])>}

    @wraps(fn)
    def error_handler(*args, **kwargs):
        if not is_traceback_filtering_enabled():
            return fn(*args, **kwargs)
    
        filtered_tb = None
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            filtered_tb = _process_traceback_frames(e.__traceback__)
            # To get the full stack trace, call:
            # `keras.config.disable_traceback_filtering()`
>           raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/keras/src/utils/traceback_utils.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomTransplantation(p=1.0, p_batch=1.0, same_on_batch=False)
params = <tf.Tensor: shape=(2, 5, 5), dtype=int64, numpy=
array([[[0, 2, 2, 0, 2],
        [0, 2, 2, 0, 1],
        [1, 0, 0, 1...[2, 2, 1, 2, 1],
        [2, 1, 1, 1, 1],
        [1, 1, 2, 2, 2],
        [1, 1, 2, 2, 0],
        [2, 0, 1, 1, 1]]])>
data_keys = None, input = ()
kwargs = {'input': <tf.Tensor: shape=(2, 3, 5, 5), dtype=float32, numpy=
array([[[[ 0.34703526,  0.06851114, -0.5236001 ,  1.70...-0.24848117],
         [-0.9647657 , -0.9770897 ,  0.5254606 , -0.38090822,
          -0.41989362]]]], dtype=float32)>}
tensorflow_get_item = <function tensorflow_get_item at 0x7fcae233a290>, tensorflow_shape_frnt_ = <function tensorflow_shape_frnt_ at 0x7fcae179d2d0>
tensorflow_clone_frnt_ = <function tensorflow_clone_frnt_ at 0x7fcae17679a0>, tensorflow__validate_input_dtype = <function tensorflow__validate_input_dtype at 0x7fcae34b52d0>
tensorflow_index_put_frnt_ = <function tensorflow_index_put_frnt_ at 0x7fcae1766200>, keys = [<tensorflow_DataKey.IMAGE: 0>, <tensorflow_DataKey.MASK: 1>]

    def call(self, *input, params=None, data_keys=None, **kwargs):
        from ....constants import tensorflow_DataKey
        from .....ivy.functional.backends.tensorflow.general import tensorflow_get_item
        from .....ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from .....ivy.functional.frontends.torch.tensor import tensorflow_clone_frnt_
        from ...utils.helpers import tensorflow__validate_input_dtype
        from .....ivy.functional.frontends.torch.tensor import (
            tensorflow_index_put_frnt_,
        )
    
        keys: typing.Any
        if data_keys is None:
            keys = self.data_keys
        else:
            keys = [tensorflow_DataKey.get(inp) for inp in data_keys]
        if params is None:
            mask: typing.Any = tensorflow_get_item(
                input, keys.index(tensorflow_DataKey.MASK)
            )
            self._params = self.forward_parameters(tensorflow_shape_frnt_(mask))
        else:
            self._params = params
>       if any(
            k not in self._params
            for k in ["acceptor_indices", "donor_indices", "selection"]
        ):

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/_2d/mix/transplantation.py:244: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

.0 = <tuple_iterator object at 0x7fcae1835360>

    if any(
>       k not in self._params
        for k in ["acceptor_indices", "donor_indices", "selection"]
    ):

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/_2d/mix/transplantation.py:245: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <tf.Tensor: shape=(5, 5), dtype=int64, numpy=
array([[0, 2, 2, 0, 2],
       [0, 2, 2, 0, 1],
       [1, 0, 0, 1, 2],
       [1, 2, 2, 0, 0],
       [1, 1, 0, 1, 1]])>, rhs = 'acceptor_indices'

    def impl(self, rhs):
        try:
            res = original_method(self, rhs)
            if isinstance(rhs, (list, tuple)):
                return False if orig_method_name == "__eq__" else True
            return res
        except Exception:
>           return patched_method(self, rhs)

ivy_transpiled_outputs/tensorflow_outputs/__init__.py:58: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = <tf.Tensor: shape=(5, 5), dtype=int64, numpy=
array([[0, 2, 2, 0, 2],
       [0, 2, 2, 0, 1],
       [1, 0, 0, 1, 2],
       [1, 2, 2, 0, 0],
       [1, 1, 0, 1, 1]])>
other = 'acceptor_indices'

    def tensorflow___eq___frnt_(tensor, other):
        from .comparison_ops import tensorflow_eq_frnt
    
        if isinstance(other, (list, tuple)):
            return False
>       return tensorflow_eq_frnt(tensor, other)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/tensor.py:101: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = <tf.Tensor: shape=(5, 5), dtype=int64, numpy=
array([[0, 2, 2, 0, 2],
       [0, 2, 2, 0, 1],
       [1, 0, 0, 1, 2],
       [1, 2, 2, 0, 0],
       [1, 1, 0, 1, 1]])>
other = 'acceptor_indices'

    def tensorflow_eq_frnt(input, other, *, out=None):
        from .__init__ import tensorflow_promote_types_of_torch_inputs_frnt
        from ...backends.tensorflow.elementwise import tensorflow_equal
    
>       input, other = tensorflow_promote_types_of_torch_inputs_frnt(input, other)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/comparison_ops.py:110: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x1 = <tf.Tensor: shape=(5, 5), dtype=int64, numpy=
array([[0, 2, 2, 0, 2],
       [0, 2, 2, 0, 1],
       [1, 0, 0, 1, 2],
       [1, 2, 2, 0, 0],
       [1, 1, 0, 1, 1]])>, x2 = 'acceptor_indices'

    def tensorflow_promote_types_of_torch_inputs_frnt(x1, x2, /):
        from ...ivy.general import tensorflow_isscalar_bknd
        from ...ivy.data_type import tensorflow_is_int_dtype_bknd
        from ...backends.tensorflow.creation import tensorflow_asarray
        from ...ivy.data_type import tensorflow_default_dtype_bknd
        from .tensor import tensorflow_shape_frnt_
        from ...ivy.device import tensorflow_default_device_bknd
        from ....data_classes.array.data_type import tensorflow_astype_bknd_
    
        """Promote the dtype of the given native array inputs to a common dtype
        based on type promotion rules.
    
        While passing float or integer values or any other non-array input
        to this function, it should be noted that the return will be an
        array-like object. Therefore, outputs from this function should be
        used as inputs only for those functions that expect an array-like or
        tensor-like objects, otherwise it might give unexpected results.
        """
        if (
            tensorflow_isscalar_bknd(x1) or isinstance(x1, (list, tuple))
        ) and tensorflow_is_int_dtype_bknd(x1):
            x1 = tensorflow_asarray(x1, dtype="int64")
        elif tensorflow_isscalar_bknd(x1) or isinstance(x1, (list, tuple)):
            x1 = tensorflow_asarray(x1)
        if (
            tensorflow_isscalar_bknd(x2) or isinstance(x2, (list, tuple))
>       ) and tensorflow_is_int_dtype_bknd(x2):

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/__init__.py:222: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = 'acceptor_indices'

    def tensorflow_is_int_dtype_bknd(
        dtype_in: Union[str, str, tensorflow.Tensor, tf.Tensor, Number], /
    ):
        from .general import tensorflow_is_array_bknd
        from ..backends.tensorflow.data_type import tensorflow_dtype
        from .nest import tensorflow_nested_argwhere_bknd
        from ..backends.tensorflow.data_type import tensorflow_as_ivy_dtype
    
        if tensorflow_is_array_bknd(dtype_in):
            dtype_in = tensorflow_dtype(dtype_in)
        elif isinstance(dtype_in, tuple):
            dtype_in = tensorflow_default_int_dtype_bknd()
        elif isinstance(dtype_in, np.ndarray):
            return "int" in dtype_in.dtype.name
        elif isinstance(dtype_in, Number):
            return isinstance(dtype_in, (int, np.integer)) and not isinstance(
                dtype_in, bool
            )
        elif isinstance(dtype_in, (list, tuple, dict)):
    
            def nested_fun(x):
                from .general import tensorflow_is_array_bknd
                from ..backends.tensorflow.data_type import tensorflow_dtype
    
                return (
                    isinstance(x, (int, np.integer))
                    or tensorflow_is_array_bknd(x)
                    and "int" in tensorflow_dtype(x)
                ) and x is not bool
    
            return bool(tensorflow_nested_argwhere_bknd(dtype_in, nested_fun))
>       return "int" in tensorflow_as_ivy_dtype(dtype_in)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:485: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = 'acceptor_indices'

    def tensorflow_as_ivy_dtype(
        dtype_in: Union[tensorflow.DType, str, int, float, complex, bool, np.dtype], /
    ):
        from ...ivy.data_type import tensorflow_default_int_dtype_bknd
        from ...ivy.data_type import tensorflow_default_float_dtype_bknd
        from ...ivy.data_type import tensorflow_default_complex_dtype_bknd
    
        if dtype_in is int:
            return tensorflow_default_int_dtype_bknd()
        if dtype_in is float:
            return tensorflow_default_float_dtype_bknd()
        if dtype_in is complex:
            return tensorflow_default_complex_dtype_bknd()
        if dtype_in is bool:
            return str("bool")
        if isinstance(dtype_in, np.dtype):
            dtype_in = dtype_in.name
        if isinstance(dtype_in, str):
            if dtype_in in native_dtype_dict:
                dtype_str = dtype_in
            else:
>               raise Exception(
                    f"Cannot convert to ivy dtype. {dtype_in} is not supported by TensorFlow backend."
                )
E               Exception: Exception encountered when calling tensorflow_RandomTransplantation.call().
E               
E               [1mCannot convert to ivy dtype. acceptor_indices is not supported by TensorFlow backend.[0m
E               
E               Arguments received by tensorflow_RandomTransplantation.call():
E                  input=<class 'inspect._empty'>
E                  params=tf.Tensor(shape=(2, 5, 5), dtype=int64)
E                  data_keys=None
E                  kwargs={'input': 'tf.Tensor(shape=(2, 3, 5, 5), dtype=float32)'}

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/backends/tensorflow/data_type.py:204: Exception
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.RandomTransplantation
_____________________________________________________________________________ test_RandomRotation3D[tensorflow-s2s-False] ______________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_RandomRotation3D(target_framework, mode, backend_compile):
        print("kornia.augmentation.RandomRotation3D")
    
        init_args = ((15., 20., 20.),)
        init_kwargs = {"p": 1.}
        call_args = (torch.rand(1, 1, 3, 3, 3),)
        call_kwargs = {}
    
>       _test_augmentation_class(
            kornia.augmentation.RandomRotation3D,
            target_framework,
            init_args,
            init_kwargs,
            call_args,
            call_kwargs,
            deterministic_output=False,
            backend_compile=backend_compile,
        )

kornia/augmentation/test_augmentation4.py:219: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

augmentation_cls = <class 'kornia.augmentation._3d.geometric.rotation.RandomRotation3D'>, target = 'tensorflow', init_args = ((15.0, 20.0, 20.0),), init_kwargs = {'p': 1.0}
call_args = (tensor([[[[[0.7397, 0.4566, 0.8438],
           [0.9594, 0.8339, 0.0163],
           [0.4022, 0.9368, 0.9255]],

    ...,

          [[0.8264, 0.6010, 0.7298],
           [0.5825, 0.3233, 0.6915],
           [0.4431, 0.0472, 0.2712]]]]]),)
call_kwargs = {}, deterministic_output = False, backend_compile = False, tolerance = 0.001

    def _test_augmentation_class(
        augmentation_cls,
        target,
        init_args=(),
        init_kwargs={},
        call_args=(),
        call_kwargs={},
        deterministic_output=True,
        backend_compile=False,
        tolerance=1e-3,
    ):
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_cls = ivy.transpile(augmentation_cls, source="torch", target=target)
    
        torch_aug = augmentation_cls(*init_args, **init_kwargs)
        transpiled_init_args = _nest_torch_tensor_to_new_framework(init_args, target)
        transpiled_init_kwargs = _nest_torch_tensor_to_new_framework(init_kwargs, target)
        transpiled_aug = transpiled_cls(*transpiled_init_args, **transpiled_init_kwargs)
    
        # assert dir(torch_aug) == dir(transpiled_aug), f"attributes/methods of transpiled object do not align with the original - orig: {dir(torch_aug)} != transpiled: {dir(transpiled_aug)}"
    
        torch_out = torch_aug(*call_args, **call_kwargs)
        transpiled_call_args = _nest_torch_tensor_to_new_framework(call_args, target)
        transpiled_call_kwargs = _nest_torch_tensor_to_new_framework(call_kwargs, target)
>       transpiled_out = transpiled_aug(*transpiled_call_args, **transpiled_call_kwargs)

kornia/augmentation/test_augmentation4.py:43: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomRotation3D(degrees=(15.0, 20.0, 20.0), p=1.0, p_batch=1.0, same_on_batch=False, resample=bilinear, align_corners=False)
args = (<tf.Tensor: shape=(1, 1, 3, 3, 3), dtype=float32, numpy=
array([[[[[0.73966706, 0.45661658, 0.8437984 ],
          [0...,
          [0.5825046 , 0.32327795, 0.6915082 ],
          [0.4430666 , 0.047207  , 0.27122563]]]]], dtype=float32)>,)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x7fcae2373040, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...kexec', code_context=['        return self._inner_hookexec(hook_name, methods, kwargs, firstresult)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomRotation3D(degrees=(15.0, 20.0, 20.0), p=1.0, p_batch=1.0, same_on_batch=False, resample=bilinear, a...],
          [0.5825046 , 0.32327795, 0.6915082 ],
          [0.4430666 , 0.047207  , 0.27122563]]]]], dtype=float32)>)
kwargs = {}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomRotation3D(degrees=(15.0, 20.0, 20.0), p=1.0, p_batch=1.0, same_on_batch=False, resample=bilinear, align_corners=False), v = None, buffers = None
args = (<tf.Tensor: shape=(1, 1, 3, 3, 3), dtype=float32, numpy=
array([[[[[0.73966706, 0.45661658, 0.8437984 ],
          [0...,
          [0.5825046 , 0.32327795, 0.6915082 ],
          [0.4430666 , 0.047207  , 0.27122563]]]]], dtype=float32)>,)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomRotation3D(degrees=(15.0, 20.0, 20.0), p=1.0, p_batch=1.0, same_on_batch=False, resample=bilinear, a...],
          [0.5825046 , 0.32327795, 0.6915082 ],
          [0.4430666 , 0.047207  , 0.27122563]]]]], dtype=float32)>)
kwargs = {'buffers': None, 'v': None}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomRotation3D(degrees=(15.0, 20.0, 20.0), p=1.0, p_batch=1.0, same_on_batch=False, resample=bilinear, align_corners=False), v = None, buffers = None
args = (<tf.Tensor: shape=(1, 1, 3, 3, 3), dtype=float32, numpy=
array([[[[[0.73966706, 0.45661658, 0.8437984 ],
          [0...,
          [0.5825046 , 0.32327795, 0.6915082 ],
          [0.4430666 , 0.047207  , 0.27122563]]]]], dtype=float32)>,)
kwargs = {}
first_arr = <tf.Tensor: shape=(1, 1, 3, 3, 3), dtype=float32, numpy=
array([[[[[0.73966706, 0.45661658, 0.8437984 ],
          [0.... ],
          [0.5825046 , 0.32327795, 0.6915082 ],
          [0.4430666 , 0.047207  , 0.27122563]]]]], dtype=float32)>
replace_v = False, replace_buffers = False, call_signature = <Signature (input, params=None, **kwargs)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Layer, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Layer, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Layer, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomRotation3D(degrees=(15.0, 20.0, 20.0), p=1.0, p_batch=1.0, same_on_batch=False, resample=bilinear, align_corners=False),)
kwargs = {'input': <tf.Tensor: shape=(1, 1, 3, 3, 3), dtype=float32, numpy=
array([[[[[0.73966706, 0.45661658, 0.8437984 ],
   ...],
          [0.5825046 , 0.32327795, 0.6915082 ],
          [0.4430666 , 0.047207  , 0.27122563]]]]], dtype=float32)>}

    @wraps(fn)
    def error_handler(*args, **kwargs):
        if not is_traceback_filtering_enabled():
            return fn(*args, **kwargs)
    
        filtered_tb = None
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            filtered_tb = _process_traceback_frames(e.__traceback__)
            # To get the full stack trace, call:
            # `keras.config.disable_traceback_filtering()`
>           raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/keras/src/utils/traceback_utils.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomRotation3D(degrees=(15.0, 20.0, 20.0), p=1.0, p_batch=1.0, same_on_batch=False, resample=bilinear, align_corners=False)
input = <tf.Tensor: shape=(1, 1, 3, 3, 3), dtype=float32, numpy=
array([[[[[0.73966706, 0.45661658, 0.8437984 ],
          [0.... ],
          [0.5825046 , 0.32327795, 0.6915082 ],
          [0.4430666 , 0.047207  , 0.27122563]]]]], dtype=float32)>
params = {'batch_prob': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>, 'forward_input_shape': <tf.Te....52635], dtype=float32)>, 'roll': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([3.0267677], dtype=float32)>, ...}
kwargs = {}, tensorflow_shape_frnt_ = <function tensorflow_shape_frnt_ at 0x7fcaecf4ab00>, tensorflow_set_item = <function tensorflow_set_item at 0x7fcae09a8670>
tensor = <function tensorflow_tensor_frnt at 0x7fcae0916f80>
in_tensor = <tf.Tensor: shape=(1, 1, 3, 3, 3), dtype=float32, numpy=
array([[[[[0.73966706, 0.45661658, 0.8437984 ],
          [0.... ],
          [0.5825046 , 0.32327795, 0.6915082 ],
          [0.4430666 , 0.047207  , 0.27122563]]]]], dtype=float32)>
input_shape = ivy.frontends.torch.Size([1, 1, 3, 3, 3]), batch_shape = ivy.frontends.torch.Size([1, 1, 3, 3, 3]), flags = {'align_corners': False, 'resample': <tensorflow_Resample.BILINEAR: 1>}

    def call(self, input, params=None, **kwargs):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ...ivy.functional.backends.tensorflow.general import tensorflow_set_item
        from ..core._backend import tensor
    
        in_tensor = self.__unpack_input__(input)
        input_shape = tensorflow_shape_frnt_(in_tensor)
        in_tensor = self.transform_tensor(in_tensor)
        batch_shape = tensorflow_shape_frnt_(in_tensor)
        if params is None:
            params = self.forward_parameters(batch_shape)
        if "batch_prob" not in params:
            params = tensorflow_set_item(
                params, "batch_prob", tensor([True] * batch_shape[0])
            )
        params, flags = self._process_kwargs_to_params_and_flags(
            params, self.flags, **kwargs
        )
>       output = self.apply_func(in_tensor, params, flags)

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/base.py:236: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomRotation3D(degrees=(15.0, 20.0, 20.0), p=1.0, p_batch=1.0, same_on_batch=False, resample=bilinear, align_corners=False)
in_tensor = <tf.Tensor: shape=(1, 1, 3, 3, 3), dtype=float32, numpy=
array([[[[[0.73966706, 0.45661658, 0.8437984 ],
          [0.... ],
          [0.5825046 , 0.32327795, 0.6915082 ],
          [0.4430666 , 0.047207  , 0.27122563]]]]], dtype=float32)>
params = {'batch_prob': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>, 'forward_input_shape': <tf.Te....52635], dtype=float32)>, 'roll': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([3.0267677], dtype=float32)>, ...}
flags = {'align_corners': False, 'resample': <tensorflow_Resample.BILINEAR: 1>}

    def apply_func(self, in_tensor, params, flags=None):
        if flags is None:
            flags = self.flags
>       trans_matrix = self.generate_transformation_matrix(in_tensor, params, flags)

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/_3d/base.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomRotation3D(degrees=(15.0, 20.0, 20.0), p=1.0, p_batch=1.0, same_on_batch=False, resample=bilinear, align_corners=False)
input = <tf.Tensor: shape=(1, 1, 3, 3, 3), dtype=float32, numpy=
array([[[[[0.73966706, 0.45661658, 0.8437984 ],
          [0.... ],
          [0.5825046 , 0.32327795, 0.6915082 ],
          [0.4430666 , 0.047207  , 0.27122563]]]]], dtype=float32)>
params = {'batch_prob': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>, 'forward_input_shape': <tf.Te....52635], dtype=float32)>, 'roll': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([3.0267677], dtype=float32)>, ...}
flags = {'align_corners': False, 'resample': <tensorflow_Resample.BILINEAR: 1>}

    def generate_transformation_matrix(self, input, params, flags):
        from ....ivy.functional.frontends.torch.tensor import tensorflow_any_frnt_
        from ....ivy.functional.frontends.torch.tensor import tensorflow_all_frnt_
        from ....ivy.functional.frontends.torch.tensor import tensorflow_index_put_frnt_
        from ....ivy.functional.backends.tensorflow.general import tensorflow_get_item
    
        batch_prob = params["batch_prob"]
        to_apply = batch_prob > 0.5
        in_tensor = self.transform_tensor(input)
        if not tensorflow_any_frnt_(to_apply):
            trans_matrix = self.identity_matrix(in_tensor)
        elif tensorflow_all_frnt_(to_apply):
>           trans_matrix = self.compute_transformation(
                in_tensor, params=params, flags=flags
            )

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/_3d/base.py:90: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomRotation3D(degrees=(15.0, 20.0, 20.0), p=1.0, p_batch=1.0, same_on_batch=False, resample=bilinear, align_corners=False)
input = <tf.Tensor: shape=(1, 1, 3, 3, 3), dtype=float32, numpy=
array([[[[[0.73966706, 0.45661658, 0.8437984 ],
          [0.... ],
          [0.5825046 , 0.32327795, 0.6915082 ],
          [0.4430666 , 0.047207  , 0.27122563]]]]], dtype=float32)>
params = {'batch_prob': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>, 'forward_input_shape': <tf.Te....52635], dtype=float32)>, 'roll': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([3.0267677], dtype=float32)>, ...}
flags = {'align_corners': False, 'resample': <tensorflow_Resample.BILINEAR: 1>}

    def compute_transformation(self, input, params, flags):
        from .....ivy.functional.frontends.torch.tensor import tensorflow_to_frnt_
        from ....geometry.transform.affwarp import tensorflow__compute_tensor_center3d
        from ....geometry.transform.affwarp import tensorflow__compute_rotation_matrix3d
        from .....ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ....utils.misc import tensorflow_eye_like
        from .....ivy.functional.backends.tensorflow.general import tensorflow_set_item
    
        yaw: typing.Any = tensorflow_to_frnt_(params["yaw"], input)
        pitch: typing.Any = tensorflow_to_frnt_(params["pitch"], input)
        roll: typing.Any = tensorflow_to_frnt_(params["roll"], input)
        center: typing.Any = tensorflow__compute_tensor_center3d(input)
        rotation_mat: typing.Any = tensorflow__compute_rotation_matrix3d(
>           yaw, pitch, roll, center.expand(tensorflow_shape_frnt_(yaw)[0], -1)
        )
E       AttributeError: Exception encountered when calling tensorflow_RandomRotation3D.call().
E       
E       [1m'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'expand'[0m
E       
E       Arguments received by tensorflow_RandomRotation3D.call():
E          input=tf.Tensor(shape=(1, 1, 3, 3, 3), dtype=float32)
E          params=None
E          kwargs=<class 'inspect._empty'>

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/_3d/geometric/rotation.py:68: AttributeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.RandomRotation3D
__________________________________________________________________________ test_RandomTransplantation3D[tensorflow-s2s-False] __________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_RandomTransplantation3D(target_framework, mode, backend_compile):
        print("kornia.augmentation.RandomTransplantation3D")
    
        init_args = ()
        init_kwargs = {"p": 1.}
        call_args = (torch.randn(2, 3, 5, 5), torch.randint(0, 3, (2, 5, 5)))
        call_kwargs = {}
    
>       _test_augmentation_class(
            kornia.augmentation.RandomTransplantation3D,
            target_framework,
            init_args,
            init_kwargs,
            call_args,
            call_kwargs,
            deterministic_output=False,
            backend_compile=backend_compile,
        )

kornia/augmentation/test_augmentation4.py:299: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

augmentation_cls = <class 'kornia.augmentation._3d.mix.transplantation.RandomTransplantation3D'>, target = 'tensorflow', init_args = (), init_kwargs = {'p': 1.0}
call_args = (tensor([[[[ 0.4051, -0.5306,  1.5509,  0.6333,  0.7627],
          [ 0.3133,  1.5792,  0.6465,  0.5936,  2.0188],
   ...1, 1, 1, 2],
         [1, 1, 0, 1, 0],
         [2, 2, 0, 0, 2],
         [0, 2, 0, 0, 1],
         [1, 1, 0, 2, 1]]]))
call_kwargs = {}, deterministic_output = False, backend_compile = False, tolerance = 0.001

    def _test_augmentation_class(
        augmentation_cls,
        target,
        init_args=(),
        init_kwargs={},
        call_args=(),
        call_kwargs={},
        deterministic_output=True,
        backend_compile=False,
        tolerance=1e-3,
    ):
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_cls = ivy.transpile(augmentation_cls, source="torch", target=target)
    
        torch_aug = augmentation_cls(*init_args, **init_kwargs)
        transpiled_init_args = _nest_torch_tensor_to_new_framework(init_args, target)
        transpiled_init_kwargs = _nest_torch_tensor_to_new_framework(init_kwargs, target)
        transpiled_aug = transpiled_cls(*transpiled_init_args, **transpiled_init_kwargs)
    
        # assert dir(torch_aug) == dir(transpiled_aug), f"attributes/methods of transpiled object do not align with the original - orig: {dir(torch_aug)} != transpiled: {dir(transpiled_aug)}"
    
        torch_out = torch_aug(*call_args, **call_kwargs)
        transpiled_call_args = _nest_torch_tensor_to_new_framework(call_args, target)
        transpiled_call_kwargs = _nest_torch_tensor_to_new_framework(call_kwargs, target)
>       transpiled_out = transpiled_aug(*transpiled_call_args, **transpiled_call_kwargs)

kornia/augmentation/test_augmentation4.py:43: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomTransplantation3D(p=1.0, p_batch=1.0, same_on_batch=False)
args = (<tf.Tensor: shape=(2, 3, 5, 5), dtype=float32, numpy=
array([[[[ 0.40510568, -0.5306206 ,  1.5508789 ,  0.63332146,
 ...0, 1, 1, 1, 2],
        [1, 1, 0, 1, 0],
        [2, 2, 0, 0, 2],
        [0, 2, 0, 0, 1],
        [1, 1, 0, 2, 1]]])>)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x7fcae3e8dc40, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...kexec', code_context=['        return self._inner_hookexec(hook_name, methods, kwargs, firstresult)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomTransplantation3D(p=1.0, p_batch=1.0, same_on_batch=False), <tf.Tensor: shape=(2, 3, 5, 5), dtype=fl...0, 1, 1, 1, 2],
        [1, 1, 0, 1, 0],
        [2, 2, 0, 0, 2],
        [0, 2, 0, 0, 1],
        [1, 1, 0, 2, 1]]])>)
kwargs = {}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomTransplantation3D(p=1.0, p_batch=1.0, same_on_batch=False), v = None, buffers = None
args = (<tf.Tensor: shape=(2, 3, 5, 5), dtype=float32, numpy=
array([[[[ 0.40510568, -0.5306206 ,  1.5508789 ,  0.63332146,
 ...0, 1, 1, 1, 2],
        [1, 1, 0, 1, 0],
        [2, 2, 0, 0, 2],
        [0, 2, 0, 0, 1],
        [1, 1, 0, 2, 1]]])>)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomTransplantation3D(p=1.0, p_batch=1.0, same_on_batch=False), <tf.Tensor: shape=(2, 3, 5, 5), dtype=fl...0, 1, 1, 1, 2],
        [1, 1, 0, 1, 0],
        [2, 2, 0, 0, 2],
        [0, 2, 0, 0, 1],
        [1, 1, 0, 2, 1]]])>)
kwargs = {'buffers': None, 'v': None}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomTransplantation3D(p=1.0, p_batch=1.0, same_on_batch=False), v = None, buffers = None
args = (<tf.Tensor: shape=(2, 3, 5, 5), dtype=float32, numpy=
array([[[[ 0.40510568, -0.5306206 ,  1.5508789 ,  0.63332146,
 ...0, 1, 1, 1, 2],
        [1, 1, 0, 1, 0],
        [2, 2, 0, 0, 2],
        [0, 2, 0, 0, 1],
        [1, 1, 0, 2, 1]]])>)
kwargs = {}
first_arr = <tf.Tensor: shape=(2, 3, 5, 5), dtype=float32, numpy=
array([[[[ 0.40510568, -0.5306206 ,  1.5508789 ,  0.63332146,
  ... -0.6285885 ],
         [ 1.0989467 , -0.34465596, -2.090751  , -0.3250456 ,
          -0.6116657 ]]]], dtype=float32)>
replace_v = False, replace_buffers = False, call_signature = <Signature (*input, params=None, data_keys=None, **kwargs)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Layer, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Layer, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Layer, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomTransplantation3D(p=1.0, p_batch=1.0, same_on_batch=False),)
kwargs = {'input': <tf.Tensor: shape=(2, 3, 5, 5), dtype=float32, numpy=
array([[[[ 0.40510568, -0.5306206 ,  1.5508789 ,  0.63...0, 1, 1, 1, 2],
        [1, 1, 0, 1, 0],
        [2, 2, 0, 0, 2],
        [0, 2, 0, 0, 1],
        [1, 1, 0, 2, 1]]])>}

    @wraps(fn)
    def error_handler(*args, **kwargs):
        if not is_traceback_filtering_enabled():
            return fn(*args, **kwargs)
    
        filtered_tb = None
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            filtered_tb = _process_traceback_frames(e.__traceback__)
            # To get the full stack trace, call:
            # `keras.config.disable_traceback_filtering()`
>           raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/keras/src/utils/traceback_utils.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomTransplantation3D(p=1.0, p_batch=1.0, same_on_batch=False)
params = <tf.Tensor: shape=(2, 5, 5), dtype=int64, numpy=
array([[[0, 2, 1, 1, 2],
        [2, 2, 0, 1, 1],
        [2, 0, 2, 2...[0, 1, 1, 1, 2],
        [1, 1, 0, 1, 0],
        [2, 2, 0, 0, 2],
        [0, 2, 0, 0, 1],
        [1, 1, 0, 2, 1]]])>
data_keys = None, input = ()
kwargs = {'input': <tf.Tensor: shape=(2, 3, 5, 5), dtype=float32, numpy=
array([[[[ 0.40510568, -0.5306206 ,  1.5508789 ,  0.63...-0.6285885 ],
         [ 1.0989467 , -0.34465596, -2.090751  , -0.3250456 ,
          -0.6116657 ]]]], dtype=float32)>}
tensorflow_get_item = <function tensorflow_get_item at 0x7fcae054af80>, tensorflow_shape_frnt_ = <function tensorflow_shape_frnt_ at 0x7fcaccefa3b0>
tensorflow_clone_frnt_ = <function tensorflow_clone_frnt_ at 0x7fcadc1d9870>, tensorflow__validate_input_dtype = <function tensorflow__validate_input_dtype at 0x7fcae051bac0>
tensorflow_index_put_frnt_ = <function tensorflow_index_put_frnt_ at 0x7fcadc2a7640>, keys = [<tensorflow_DataKey.IMAGE: 0>, <tensorflow_DataKey.MASK: 1>]

    def call(self, *input, params=None, data_keys=None, **kwargs):
        from ....constants import tensorflow_DataKey
        from .....ivy.functional.backends.tensorflow.general import tensorflow_get_item
        from .....ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from .....ivy.functional.frontends.torch.tensor import tensorflow_clone_frnt_
        from ...utils.helpers import tensorflow__validate_input_dtype
        from .....ivy.functional.frontends.torch.tensor import (
            tensorflow_index_put_frnt_,
        )
    
        keys: typing.Any
        if data_keys is None:
            keys = self.data_keys
        else:
            keys = [tensorflow_DataKey.get(inp) for inp in data_keys]
        if params is None:
            mask: typing.Any = tensorflow_get_item(
                input, keys.index(tensorflow_DataKey.MASK)
            )
            self._params = self.forward_parameters(tensorflow_shape_frnt_(mask))
        else:
            self._params = params
>       if any(
            k not in self._params
            for k in ["acceptor_indices", "donor_indices", "selection"]
        ):

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/_2d/mix/transplantation.py:246: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

.0 = <tuple_iterator object at 0x7fcaecf71360>

    if any(
>       k not in self._params
        for k in ["acceptor_indices", "donor_indices", "selection"]
    ):

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/_2d/mix/transplantation.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <tf.Tensor: shape=(5, 5), dtype=int64, numpy=
array([[0, 2, 1, 1, 2],
       [2, 2, 0, 1, 1],
       [2, 0, 2, 2, 1],
       [2, 0, 2, 0, 2],
       [2, 1, 1, 1, 1]])>, rhs = 'acceptor_indices'

    def impl(self, rhs):
        try:
            res = original_method(self, rhs)
            if isinstance(rhs, (list, tuple)):
                return False if orig_method_name == "__eq__" else True
            return res
        except Exception:
>           return patched_method(self, rhs)

ivy_transpiled_outputs/tensorflow_outputs/__init__.py:58: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = <tf.Tensor: shape=(5, 5), dtype=int64, numpy=
array([[0, 2, 1, 1, 2],
       [2, 2, 0, 1, 1],
       [2, 0, 2, 2, 1],
       [2, 0, 2, 0, 2],
       [2, 1, 1, 1, 1]])>
other = 'acceptor_indices'

    def tensorflow___eq___frnt_(tensor, other):
        from .comparison_ops import tensorflow_eq_frnt
    
        if isinstance(other, (list, tuple)):
            return False
>       return tensorflow_eq_frnt(tensor, other)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/tensor.py:101: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = <tf.Tensor: shape=(5, 5), dtype=int64, numpy=
array([[0, 2, 1, 1, 2],
       [2, 2, 0, 1, 1],
       [2, 0, 2, 2, 1],
       [2, 0, 2, 0, 2],
       [2, 1, 1, 1, 1]])>
other = 'acceptor_indices'

    def tensorflow_eq_frnt(input, other, *, out=None):
        from .__init__ import tensorflow_promote_types_of_torch_inputs_frnt
        from ...backends.tensorflow.elementwise import tensorflow_equal
    
>       input, other = tensorflow_promote_types_of_torch_inputs_frnt(input, other)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/comparison_ops.py:110: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x1 = <tf.Tensor: shape=(5, 5), dtype=int64, numpy=
array([[0, 2, 1, 1, 2],
       [2, 2, 0, 1, 1],
       [2, 0, 2, 2, 1],
       [2, 0, 2, 0, 2],
       [2, 1, 1, 1, 1]])>, x2 = 'acceptor_indices'

    def tensorflow_promote_types_of_torch_inputs_frnt(x1, x2, /):
        from ...ivy.general import tensorflow_isscalar_bknd
        from ...ivy.data_type import tensorflow_is_int_dtype_bknd
        from ...backends.tensorflow.creation import tensorflow_asarray
        from ...ivy.data_type import tensorflow_default_dtype_bknd
        from .tensor import tensorflow_shape_frnt_
        from ...ivy.device import tensorflow_default_device_bknd
        from ....data_classes.array.data_type import tensorflow_astype_bknd_
    
        """Promote the dtype of the given native array inputs to a common dtype
        based on type promotion rules.
    
        While passing float or integer values or any other non-array input
        to this function, it should be noted that the return will be an
        array-like object. Therefore, outputs from this function should be
        used as inputs only for those functions that expect an array-like or
        tensor-like objects, otherwise it might give unexpected results.
        """
        if (
            tensorflow_isscalar_bknd(x1) or isinstance(x1, (list, tuple))
        ) and tensorflow_is_int_dtype_bknd(x1):
            x1 = tensorflow_asarray(x1, dtype="int64")
        elif tensorflow_isscalar_bknd(x1) or isinstance(x1, (list, tuple)):
            x1 = tensorflow_asarray(x1)
        if (
            tensorflow_isscalar_bknd(x2) or isinstance(x2, (list, tuple))
>       ) and tensorflow_is_int_dtype_bknd(x2):

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/__init__.py:222: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = 'acceptor_indices'

    def tensorflow_is_int_dtype_bknd(
        dtype_in: Union[str, str, tensorflow.Tensor, tf.Tensor, Number], /
    ):
        from .general import tensorflow_is_array_bknd
        from ..backends.tensorflow.data_type import tensorflow_dtype
        from .nest import tensorflow_nested_argwhere_bknd
        from ..backends.tensorflow.data_type import tensorflow_as_ivy_dtype
    
        if tensorflow_is_array_bknd(dtype_in):
            dtype_in = tensorflow_dtype(dtype_in)
        elif isinstance(dtype_in, tuple):
            dtype_in = tensorflow_default_int_dtype_bknd()
        elif isinstance(dtype_in, np.ndarray):
            return "int" in dtype_in.dtype.name
        elif isinstance(dtype_in, Number):
            return isinstance(dtype_in, (int, np.integer)) and not isinstance(
                dtype_in, bool
            )
        elif isinstance(dtype_in, (list, tuple, dict)):
    
            def nested_fun(x):
                from .general import tensorflow_is_array_bknd
                from ..backends.tensorflow.data_type import tensorflow_dtype
    
                return (
                    isinstance(x, (int, np.integer))
                    or tensorflow_is_array_bknd(x)
                    and "int" in tensorflow_dtype(x)
                ) and x is not bool
    
            return bool(tensorflow_nested_argwhere_bknd(dtype_in, nested_fun))
>       return "int" in tensorflow_as_ivy_dtype(dtype_in)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:485: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = 'acceptor_indices'

    def tensorflow_as_ivy_dtype(
        dtype_in: Union[tensorflow.DType, str, int, float, complex, bool, np.dtype], /
    ):
        from ...ivy.data_type import tensorflow_default_int_dtype_bknd
        from ...ivy.data_type import tensorflow_default_float_dtype_bknd
        from ...ivy.data_type import tensorflow_default_complex_dtype_bknd
    
        if dtype_in is int:
            return tensorflow_default_int_dtype_bknd()
        if dtype_in is float:
            return tensorflow_default_float_dtype_bknd()
        if dtype_in is complex:
            return tensorflow_default_complex_dtype_bknd()
        if dtype_in is bool:
            return str("bool")
        if isinstance(dtype_in, np.dtype):
            dtype_in = dtype_in.name
        if isinstance(dtype_in, str):
            if dtype_in in native_dtype_dict:
                dtype_str = dtype_in
            else:
>               raise Exception(
                    f"Cannot convert to ivy dtype. {dtype_in} is not supported by TensorFlow backend."
                )
E               Exception: Exception encountered when calling tensorflow_RandomTransplantation3D.call().
E               
E               [1mCannot convert to ivy dtype. acceptor_indices is not supported by TensorFlow backend.[0m
E               
E               Arguments received by tensorflow_RandomTransplantation3D.call():
E                  input=<class 'inspect._empty'>
E                  params=tf.Tensor(shape=(2, 5, 5), dtype=int64)
E                  data_keys=None
E                  kwargs={'input': 'tf.Tensor(shape=(2, 3, 5, 5), dtype=float32)'}

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/backends/tensorflow/data_type.py:204: Exception
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.RandomTransplantation3D
______________________________________________________________________________ test_LongestMaxSize[tensorflow-s2s-False] _______________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_LongestMaxSize(target_framework, mode, backend_compile):
        print("kornia.augmentation.LongestMaxSize")
    
        init_args = (100,)
        init_kwargs = {}
        call_args = (torch.rand(10, 3, 200, 200),)
        call_kwargs = {}
    
>       _test_augmentation_class(
            kornia.augmentation.LongestMaxSize,
            target_framework,
            init_args,
            init_kwargs,
            call_args,
            call_kwargs,
            deterministic_output=True,
            backend_compile=backend_compile,
        )

kornia/augmentation/test_augmentation4.py:359: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

augmentation_cls = <class 'kornia.augmentation._2d.geometric.resize.LongestMaxSize'>, target = 'tensorflow', init_args = (100,), init_kwargs = {}
call_args = (tensor([[[[2.0314e-01, 8.6375e-01, 7.8882e-01,  ..., 1.4046e-01,
           2.4468e-01, 4.7141e-01],
          [1.012... 1.3413e-01],
          [2.9813e-01, 2.3610e-01, 7.4430e-01,  ..., 8.5916e-01,
           9.0200e-01, 9.9499e-01]]]]),)
call_kwargs = {}, deterministic_output = True, backend_compile = False, tolerance = 0.001

    def _test_augmentation_class(
        augmentation_cls,
        target,
        init_args=(),
        init_kwargs={},
        call_args=(),
        call_kwargs={},
        deterministic_output=True,
        backend_compile=False,
        tolerance=1e-3,
    ):
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_cls = ivy.transpile(augmentation_cls, source="torch", target=target)
    
        torch_aug = augmentation_cls(*init_args, **init_kwargs)
        transpiled_init_args = _nest_torch_tensor_to_new_framework(init_args, target)
        transpiled_init_kwargs = _nest_torch_tensor_to_new_framework(init_kwargs, target)
        transpiled_aug = transpiled_cls(*transpiled_init_args, **transpiled_init_kwargs)
    
        # assert dir(torch_aug) == dir(transpiled_aug), f"attributes/methods of transpiled object do not align with the original - orig: {dir(torch_aug)} != transpiled: {dir(transpiled_aug)}"
    
        torch_out = torch_aug(*call_args, **call_kwargs)
        transpiled_call_args = _nest_torch_tensor_to_new_framework(call_args, target)
        transpiled_call_kwargs = _nest_torch_tensor_to_new_framework(call_kwargs, target)
        transpiled_out = transpiled_aug(*transpiled_call_args, **transpiled_call_kwargs)
    
        orig_np = _nest_array_to_numpy(torch_out)
        transpiled_np = _nest_array_to_numpy(transpiled_out)
    
        _check_shape_allclose(orig_np, transpiled_np)
    
        if deterministic_output:
            orig_np = _nest_array_to_numpy(torch_out)
            transpiled_np = _nest_array_to_numpy(transpiled_out)
>           _check_allclose(orig_np, transpiled_np, tolerance=tolerance)

kornia/augmentation/test_augmentation4.py:53: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[[0.20313758, 0.7901495 , 0.7143988 , ..., 0.44231722,
          0.14817204, 0.4714113 ],
         [0.7124665 ...7],
         [0.2981305 , 0.737317  , 0.27765378, ..., 0.53438336,
          0.8519738 , 0.99499404]]]], dtype=float32)
y = array([[[[0.41768646, 0.8673862 , 0.42020932, ..., 0.55539364,
          0.48903397, 0.56629336],
         [0.77934027...6],
         [0.48930013, 0.41363472, 0.4846276 , ..., 0.39925936,
          0.4457168 , 0.75145006]]]], dtype=float32)
tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
>           assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
E           AssertionError: numpy array values are not all close

helpers.py:26: AssertionError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.LongestMaxSize
__________________________________________________________________________________ test_Resize[tensorflow-s2s-False] ___________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_Resize(target_framework, mode, backend_compile):
        print("kornia.augmentation.Resize")
    
        init_args = ((100, 100),)
        init_kwargs = {}
        call_args = (torch.rand(10, 3, 50, 50),)
        call_kwargs = {}
    
>       _test_augmentation_class(
            kornia.augmentation.Resize,
            target_framework,
            init_args,
            init_kwargs,
            call_args,
            call_kwargs,
            deterministic_output=True,
            backend_compile=backend_compile,
        )

kornia/augmentation/test_augmentation4.py:379: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

augmentation_cls = <class 'kornia.augmentation._2d.geometric.resize.Resize'>, target = 'tensorflow', init_args = ((100, 100),), init_kwargs = {}
call_args = (tensor([[[[2.7744e-01, 5.8221e-01, 7.0529e-01,  ..., 2.1333e-01,
           3.6500e-01, 3.1947e-01],
          [5.893... 1.2597e-01],
          [4.6912e-01, 7.1223e-02, 9.9312e-01,  ..., 1.6594e-01,
           8.7789e-01, 3.5455e-01]]]]),)
call_kwargs = {}, deterministic_output = True, backend_compile = False, tolerance = 0.001

    def _test_augmentation_class(
        augmentation_cls,
        target,
        init_args=(),
        init_kwargs={},
        call_args=(),
        call_kwargs={},
        deterministic_output=True,
        backend_compile=False,
        tolerance=1e-3,
    ):
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_cls = ivy.transpile(augmentation_cls, source="torch", target=target)
    
        torch_aug = augmentation_cls(*init_args, **init_kwargs)
        transpiled_init_args = _nest_torch_tensor_to_new_framework(init_args, target)
        transpiled_init_kwargs = _nest_torch_tensor_to_new_framework(init_kwargs, target)
        transpiled_aug = transpiled_cls(*transpiled_init_args, **transpiled_init_kwargs)
    
        # assert dir(torch_aug) == dir(transpiled_aug), f"attributes/methods of transpiled object do not align with the original - orig: {dir(torch_aug)} != transpiled: {dir(transpiled_aug)}"
    
        torch_out = torch_aug(*call_args, **call_kwargs)
        transpiled_call_args = _nest_torch_tensor_to_new_framework(call_args, target)
        transpiled_call_kwargs = _nest_torch_tensor_to_new_framework(call_kwargs, target)
        transpiled_out = transpiled_aug(*transpiled_call_args, **transpiled_call_kwargs)
    
        orig_np = _nest_array_to_numpy(torch_out)
        transpiled_np = _nest_array_to_numpy(transpiled_out)
    
        _check_shape_allclose(orig_np, transpiled_np)
    
        if deterministic_output:
            orig_np = _nest_array_to_numpy(torch_out)
            transpiled_np = _nest_array_to_numpy(transpiled_out)
>           _check_allclose(orig_np, transpiled_np, tolerance=tolerance)

kornia/augmentation/test_augmentation4.py:53: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[[0.27744293, 0.42828798, 0.579133  , ..., 0.36453602,
          0.34200335, 0.31947064],
         [0.4317967 ...7],
         [0.4691158 , 0.27217877, 0.07524173, ..., 0.8725991 ,
          0.6135756 , 0.35455203]]]], dtype=float32)
y = array([[[[0.27744293, 0.35363507, 0.50601935, ..., 0.35361457,
          0.33085197, 0.31947064],
         [0.35540733... ],
         [0.4691158 , 0.3696425 , 0.1706959 , ..., 0.7470521 ,
          0.4853854 , 0.35455203]]]], dtype=float32)
tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
>           assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
E           AssertionError: numpy array values are not all close

helpers.py:26: AssertionError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.Resize
______________________________________________________________________________ test_SmallestMaxSize[tensorflow-s2s-False] ______________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_SmallestMaxSize(target_framework, mode, backend_compile):
        print("kornia.augmentation.SmallestMaxSize")
    
        init_args = (100,)
        init_kwargs = {}
        call_args = (torch.rand(10, 3, 50, 50),)
        call_kwargs = {}
    
>       _test_augmentation_class(
            kornia.augmentation.SmallestMaxSize,
            target_framework,
            init_args,
            init_kwargs,
            call_args,
            call_kwargs,
            deterministic_output=True,
            backend_compile=backend_compile,
        )

kornia/augmentation/test_augmentation4.py:399: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

augmentation_cls = <class 'kornia.augmentation._2d.geometric.resize.SmallestMaxSize'>, target = 'tensorflow', init_args = (100,), init_kwargs = {}
call_args = (tensor([[[[0.7433, 0.8123, 0.6571,  ..., 0.1727, 0.0350, 0.8786],
          [0.7669, 0.6731, 0.3432,  ..., 0.8664, 0...., 0.8093, 0.7424,  ..., 0.7997, 0.5282, 0.1712],
          [0.7966, 0.1331, 0.9392,  ..., 0.5009, 0.3199, 0.8528]]]]),)
call_kwargs = {}, deterministic_output = True, backend_compile = False, tolerance = 0.001

    def _test_augmentation_class(
        augmentation_cls,
        target,
        init_args=(),
        init_kwargs={},
        call_args=(),
        call_kwargs={},
        deterministic_output=True,
        backend_compile=False,
        tolerance=1e-3,
    ):
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_cls = ivy.transpile(augmentation_cls, source="torch", target=target)
    
        torch_aug = augmentation_cls(*init_args, **init_kwargs)
        transpiled_init_args = _nest_torch_tensor_to_new_framework(init_args, target)
        transpiled_init_kwargs = _nest_torch_tensor_to_new_framework(init_kwargs, target)
        transpiled_aug = transpiled_cls(*transpiled_init_args, **transpiled_init_kwargs)
    
        # assert dir(torch_aug) == dir(transpiled_aug), f"attributes/methods of transpiled object do not align with the original - orig: {dir(torch_aug)} != transpiled: {dir(transpiled_aug)}"
    
        torch_out = torch_aug(*call_args, **call_kwargs)
        transpiled_call_args = _nest_torch_tensor_to_new_framework(call_args, target)
        transpiled_call_kwargs = _nest_torch_tensor_to_new_framework(call_kwargs, target)
        transpiled_out = transpiled_aug(*transpiled_call_args, **transpiled_call_kwargs)
    
        orig_np = _nest_array_to_numpy(torch_out)
        transpiled_np = _nest_array_to_numpy(transpiled_out)
    
        _check_shape_allclose(orig_np, transpiled_np)
    
        if deterministic_output:
            orig_np = _nest_array_to_numpy(torch_out)
            transpiled_np = _nest_array_to_numpy(transpiled_out)
>           _check_allclose(orig_np, transpiled_np, tolerance=tolerance)

kornia/augmentation/test_augmentation4.py:53: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[[0.74332315, 0.77744627, 0.8115694 , ..., 0.04355035,
          0.46108696, 0.87862355],
         [0.75496984... ],
         [0.7965554 , 0.46819583, 0.13983618, ..., 0.32528362,
          0.58903885, 0.8527941 ]]]], dtype=float32)
y = array([[[[0.74332315, 0.7605588 , 0.7950301 , ..., 0.24592759,
          0.6677249 , 0.87862355],
         [0.7492059 ...4],
         [0.7965554 , 0.6307003 , 0.29899007, ..., 0.45312405,
          0.71957076, 0.8527941 ]]]], dtype=float32)
tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
>           assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
E           AssertionError: numpy array values are not all close

helpers.py:26: AssertionError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.SmallestMaxSize
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/augmentation/test_augmentation4.py::test_RandomMosaic[tensorflow-s2s-False] - TypeError: got an unexpected keyword argument 'input'
FAILED kornia/augmentation/test_augmentation4.py::test_RandomTransplantation[tensorflow-s2s-False] - Exception: Exception encountered when calling tensorflow_RandomTransplantation.call().
FAILED kornia/augmentation/test_augmentation4.py::test_RandomRotation3D[tensorflow-s2s-False] - AttributeError: Exception encountered when calling tensorflow_RandomRotation3D.call().
FAILED kornia/augmentation/test_augmentation4.py::test_RandomTransplantation3D[tensorflow-s2s-False] - Exception: Exception encountered when calling tensorflow_RandomTransplantation3D.call().
FAILED kornia/augmentation/test_augmentation4.py::test_LongestMaxSize[tensorflow-s2s-False] - AssertionError: numpy array values are not all close
FAILED kornia/augmentation/test_augmentation4.py::test_Resize[tensorflow-s2s-False] - AssertionError: numpy array values are not all close
FAILED kornia/augmentation/test_augmentation4.py::test_SmallestMaxSize[tensorflow-s2s-False] - AssertionError: numpy array values are not all close
============================================================================== 7 failed, 10 passed in 3599.54s (0:59:59) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 6 items

kornia/geometry/test_depth.py ......                                                                                                                                                             [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
==================================================================================== 6 passed in 418.76s (0:06:58) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 14 items

kornia/test_feature4.py .F.....FFFF...                                                                                                                                                           [100%]

=============================================================================================== FAILURES ===============================================================================================
______________________________________________________________________________ test_SIFTFeatureScaleSpace[jax-s2s-False] _______________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_SIFTFeatureScaleSpace(target_framework, mode, backend_compile):
        print("kornia.feature.SIFTFeatureScaleSpace")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledSIFTFeatureScaleSpace = ivy.transpile(kornia.feature.SIFTFeatureScaleSpace, source="torch", target=target_framework)
    
        x = torch.rand(1, 1, 256, 256)
        transpiled_x = _nest_torch_tensor_to_new_framework(x, target_framework)
    
        model = kornia.feature.SIFTFeatureScaleSpace(num_features=10)
        torch_out = model(x)
    
        transpiled_model = TranspiledSIFTFeatureScaleSpace(num_features=10)
        if target_framework == "tensorflow":
            # build the layers
            transpiled_model(transpiled_x)
    
        ivy.sync_models(model, transpiled_model)
    
>       transpiled_out = transpiled_model(transpiled_x)

kornia/test_feature4.py:64: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_SIFTFeatureScaleSpace(
  (detector): jax_ScaleSpaceDetector(num_features=10, mr_size=6.0, scale_pyr=jax_ScalePyram...ng_bins=8, num_spatial_bins=4, patch_size=41, rootsift=True, clipval=0.2), patch_size=41, grayscale_descriptor='True)
)
img = Array([[[[0.21531397, 0.07496196, 0.80778515, ..., 0.95532554,
          0.8023334 , 0.8851133 ],
         [0.902963  ...6],
         [0.8784824 , 0.7906149 , 0.01833093, ..., 0.4191293 ,
          0.6341826 , 0.74397737]]]], dtype=float32)
mask = None

    def __call__(self, img, mask=None):
        from .laf import jax_scale_laf
    
>       lafs, responses = self.detector(img, mask)

ivy_transpiled_outputs/jax_outputs/kornia/feature/integrated.py:202: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_ScaleSpaceDetector(num_features=10, mr_size=6.0, scale_pyr=jax_ScalePyramid(n_levels=3, init_sigma=1.6, min_size=3...19, angle_detector=jax_PatchDominantGradientOrientation(patch_size=19, num_ang_bins=36, eps=1e-08)), aff=jax_PassLAF())
img = Array([[[[0.21531397, 0.07496196, 0.80778515, ..., 0.95532554,
          0.8023334 , 0.8851133 ],
         [0.902963  ...6],
         [0.8784824 , 0.7906149 , 0.01833093, ..., 0.4191293 ,
          0.6341826 , 0.74397737]]]], dtype=float32)
mask = None

    def __call__(self, img, mask=None):
>       responses, lafs = self.detect(img, self.num_features, mask)

ivy_transpiled_outputs/jax_outputs/kornia/feature/scale_space_detector.py:256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_ScaleSpaceDetector(num_features=10, mr_size=6.0, scale_pyr=jax_ScalePyramid(n_levels=3, init_sigma=1.6, min_size=3...19, angle_detector=jax_PatchDominantGradientOrientation(patch_size=19, num_ang_bins=36, eps=1e-08)), aff=jax_PassLAF())
img = Array([[[[0.21531397, 0.07496196, 0.80778515, ..., 0.95532554,
          0.8023334 , 0.8851133 ],
         [0.902963  ...6],
         [0.8784824 , 0.7906149 , 0.01833093, ..., 0.4191293 ,
          0.6341826 , 0.74397737]]]], dtype=float32)
num_feats = 10, mask = None

    def detect(self, img, num_feats, mask=None):
        from ...ivy.functional.backends.jax.general import jax_get_item
        from ...ivy.functional.frontends.torch.tensor import jax_size_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_view_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_reshape_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_permute_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_to_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_unsqueeze_frnt_
        from ...ivy.functional.frontends.torch.comparison_ops import jax_topk_frnt
        from ...ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            jax_gather_frnt,
        )
        from ...ivy.functional.frontends.torch.tensor import jax_repeat_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_item_frnt_
        from .laf import jax_laf_is_inside_image
        from ..core._backend import eye
        from ..core._backend import concatenate
    
        dev: typing.Any = img.device
        dtype: typing.Any = img.dtype
        sigmas: typing.Any
>       sp, sigmas, _ = self.scale_pyr(img)

ivy_transpiled_outputs/jax_outputs/kornia/feature/scale_space_detector.py:145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_ScalePyramid(n_levels=3, init_sigma=1.6, min_size=32, extra_levels=3, border=15, sigma_step=1.2599210498948732, double_image=True)
x = Array([[[[0.21531397, 0.07496196, 0.80778515, ..., 0.95532554,
          0.8023334 , 0.8851133 ],
         [0.902963  ...6],
         [0.8784824 , 0.7906149 , 0.01833093, ..., 0.4191293 ,
          0.6341826 , 0.74397737]]]], dtype=float32)

    def __call__(self, x):
        from ...filters.gaussian import jax_gaussian_blur2d
        from ....ivy.functional.frontends.torch.tensor import jax_size_frnt_
        from ....ivy.functional.frontends.torch.tensor import jax_to_frnt_
        from ....ivy.functional.backends.jax.general import jax_set_item
        from ....ivy.functional.backends.jax.general import jax_get_item
        from ....ivy.functional.frontends.torch.creation_ops import jax_ones_frnt
        from ...core._backend import ones
        from ...core._backend import stack
    
        bs, _, _, _ = jax_size_frnt_(x)
>       cur_level, cur_sigma, pixel_distance = self.get_first_level(x)

ivy_transpiled_outputs/jax_outputs/kornia/geometry/transform/pyramid.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_ScalePyramid(n_levels=3, init_sigma=1.6, min_size=32, extra_levels=3, border=15, sigma_step=1.2599210498948732, double_image=True)
input = Array([[[[0.21531397, 0.07496196, 0.80778515, ..., 0.95532554,
          0.8023334 , 0.8851133 ],
         [0.902963  ...6],
         [0.8784824 , 0.7906149 , 0.01833093, ..., 0.4191293 ,
          0.6341826 , 0.74397737]]]], dtype=float32)

    def get_first_level(self, input):
        from ...filters.gaussian import jax_gaussian_blur2d
    
        pixel_distance = 1.0
        cur_sigma = 0.5
        if self.double_image:
>           x = jax_upscale_double(input)

ivy_transpiled_outputs/jax_outputs/kornia/geometry/transform/pyramid.py:89: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = Array([[[[0.21531397, 0.07496196, 0.80778515, ..., 0.95532554,
          0.8023334 , 0.8851133 ],
         [0.902963  ...6],
         [0.8784824 , 0.7906149 , 0.01833093, ..., 0.4191293 ,
          0.6341826 , 0.74397737]]]], dtype=float32)

    def jax_upscale_double(x):
        from ...core._backend import zeros
        from ...core.check import jax_KORNIA_CHECK_IS_TENSOR
        from ...core.check import jax_KORNIA_CHECK_SHAPE
        from ....ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ....ivy.functional.backends.jax.general import jax_set_item
    
        jax_KORNIA_CHECK_IS_TENSOR(x)
        jax_KORNIA_CHECK_SHAPE(x, ["*", "H", "W"])
        double_shape = jax_shape_frnt_(x)[:-2] + (
            jax_shape_frnt_(x)[-2] * 2,
            jax_shape_frnt_(x)[-1] * 2,
        )
        upscaled = zeros(double_shape, device=x.device, dtype=x.dtype)
        upscaled = jax_set_item(
            upscaled, (..., slice(None, None, 2), slice(None, None, 2)), x
        )
>       upscaled[..., ::2, 1::2] = jax_set_item(
            upscaled[..., ::2, 1::2],
            (..., slice(None, -1, None)),
            (upscaled[..., ::2, ::2][..., :-1] + upscaled[..., ::2, 2::2]) / 2,
        )

ivy_transpiled_outputs/jax_outputs/kornia/geometry/transform/pyramid.py:307: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = Array([[[[0.21531397, 0.        , 0.07496196, ..., 0.        ,
          0.8851133 , 0.        ],
         [0.        ... ],
         [0.        , 0.        , 0.        , ..., 0.        ,
          0.        , 0.        ]]]], dtype=float32)
i = (Ellipsis, slice(None, None, 2), slice(1, None, 2))
x = Array([[[[0.14513797, 0.44137356, 0.6943295 , ..., 0.8788295 ,
          0.84372336, 0.        ],
         [0.9143372 ... ],
         [0.83454865, 0.40447292, 0.25461856, ..., 0.5266559 ,
          0.68908   , 0.        ]]]], dtype=float32)

    def _unimplemented_setitem(self, i, x):
      msg = ("'{}' object does not support item assignment. JAX arrays are "
             "immutable. Instead of ``x[idx] = y``, use ``x = x.at[idx].set(y)`` "
             "or another .at[] method: "
             "https://jax.readthedocs.io/en/latest/_autosummary/jax.numpy.ndarray.at.html")
>     raise TypeError(msg.format(type(self)))
E     TypeError: '<class 'jaxlib.xla_extension.ArrayImpl'>' object does not support item assignment. JAX arrays are immutable. Instead of ``x[idx] = y``, use ``x = x.at[idx].set(y)`` or another .at[] method: https://jax.readthedocs.io/en/latest/_autosummary/jax.numpy.ndarray.at.html

/opt/fw/jax/jax/_src/numpy/array_methods.py:587: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.SIFTFeatureScaleSpace
All parameters and buffers are now synced!
_______________________________________________________________________________ test_LocalFeatureMatcher[jax-s2s-False] ________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_LocalFeatureMatcher(target_framework, mode, backend_compile):
        print("kornia.feature.LocalFeatureMatcher")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledGFTTAffNetHardNet = ivy.transpile(kornia.feature.GFTTAffNetHardNet, source="torch", target=target_framework)
        TranspiledDescriptorMatcher = ivy.transpile(kornia.feature.DescriptorMatcher, source="torch", target=target_framework)
        TranspiledLocalFeatureMatcher = ivy.transpile(kornia.feature.LocalFeatureMatcher, source="torch", target=target_framework)
    
        data = {
            "image0": torch.rand(1, 1, 320, 200),
            "image1": torch.rand(1, 1, 128, 128),
        }
        transpiled_data = _nest_torch_tensor_to_new_framework(data, target_framework)
    
        torch_local_feature = kornia.feature.GFTTAffNetHardNet(10)
        torch_matcher = kornia.feature.DescriptorMatcher('snn', 0.8)
        model = kornia.feature.LocalFeatureMatcher(torch_local_feature, torch_matcher)
>       torch_out = model(data)

kornia/test_feature4.py:225: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalFeatureMatcher(
  (local_feature): GFTTAffNetHardNet(
    (detector): MultiResolutionDetector(
      (model): Cor...ck_running_stats=True)
      )
    ), patch_size=32, grayscale_descriptor='True)
  )
  (matcher): DescriptorMatcher()
)
args = ({'image0': Array([[[[0.5100496 , 0.44573033, 0.7819073 , ..., 0.6621872 ,
          0.5735683 , 0.2152471 ],
        ...
         [0.6075862 , 0.8292808 , 0.30822068, ..., 0.4155295 ,
          0.4593925 , 0.6521452 ]]]], dtype=float32)},)
kwargs = {}

    def _wrapped_call_impl(self, *args, **kwargs):
        if self._compiled_call_impl is not None:
            return self._compiled_call_impl(*args, **kwargs)  # type: ignore[misc]
        else:
>           return self._call_impl(*args, **kwargs)

/opt/fw/torch/torch/nn/modules/module.py:1553: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalFeatureMatcher(
  (local_feature): GFTTAffNetHardNet(
    (detector): MultiResolutionDetector(
      (model): Cor...ck_running_stats=True)
      )
    ), patch_size=32, grayscale_descriptor='True)
  )
  (matcher): DescriptorMatcher()
)
args = ({'image0': Array([[[[0.5100496 , 0.44573033, 0.7819073 , ..., 0.6621872 ,
          0.5735683 , 0.2152471 ],
        ...
         [0.6075862 , 0.8292808 , 0.30822068, ..., 0.4155295 ,
          0.4593925 , 0.6521452 ]]]], dtype=float32)},)
kwargs = {}
forward_call = <bound method LocalFeatureMatcher.forward of LocalFeatureMatcher(
  (local_feature): GFTTAffNetHardNet(
    (detector)...k_running_stats=True)
      )
    ), patch_size=32, grayscale_descriptor='True)
  )
  (matcher): DescriptorMatcher()
)>

    def _call_impl(self, *args, **kwargs):
        forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)
        # If we don't have any hooks, we want to skip the rest of the logic in
        # this function, and just call forward.
        if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks
                or _global_backward_pre_hooks or _global_backward_hooks
                or _global_forward_hooks or _global_forward_pre_hooks):
>           return forward_call(*args, **kwargs)

/opt/fw/torch/torch/nn/modules/module.py:1562: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalFeatureMatcher(
  (local_feature): GFTTAffNetHardNet(
    (detector): MultiResolutionDetector(
      (model): Cor...ck_running_stats=True)
      )
    ), patch_size=32, grayscale_descriptor='True)
  )
  (matcher): DescriptorMatcher()
)
data = {'image0': Array([[[[0.5100496 , 0.44573033, 0.7819073 , ..., 0.6621872 ,
          0.5735683 , 0.2152471 ],
         ...],
         [0.6075862 , 0.8292808 , 0.30822068, ..., 0.4155295 ,
          0.4593925 , 0.6521452 ]]]], dtype=float32)}

    def forward(self, data: Dict[str, Tensor]) -> Dict[str, Tensor]:
        """
        Args:
            data: dictionary containing the input data in the following format:
    
        Keyword Args:
            image0: left image with shape :math:`(N, 1, H1, W1)`.
            image1: right image with shape :math:`(N, 1, H2, W2)`.
            mask0 (optional): left image mask. '0' indicates a padded position :math:`(N, H1, W1)`.
            mask1 (optional): right image mask. '0' indicates a padded position :math:`(N, H2, W2)`.
    
        Returns:
            - ``keypoints0``, matching keypoints from image0 :math:`(NC, 2)`.
            - ``keypoints1``, matching keypoints from image1 :math:`(NC, 2)`.
            - ``confidence``, confidence score [0, 1] :math:`(NC)`.
            - ``lafs0``, matching LAFs from image0 :math:`(1, NC, 2, 3)`.
            - ``lafs1``, matching LAFs from image1 :math:`(1, NC, 2, 3)`.
            - ``batch_indexes``, batch indexes for the keypoints and lafs :math:`(NC)`.
        """
        num_image_pairs: int = data["image0"].shape[0]
    
        if ("lafs0" not in data.keys()) or ("descriptors0" not in data.keys()):
            # One can supply pre-extracted local features
>           feats_dict0: Dict[str, Tensor] = self.extract_features(data["image0"])

/opt/miniconda/envs/multienv/lib/python3.10/site-packages/kornia/feature/integrated.py:349: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalFeatureMatcher(
  (local_feature): GFTTAffNetHardNet(
    (detector): MultiResolutionDetector(
      (model): Cor...ck_running_stats=True)
      )
    ), patch_size=32, grayscale_descriptor='True)
  )
  (matcher): DescriptorMatcher()
)
image = Array([[[[0.5100496 , 0.44573033, 0.7819073 , ..., 0.6621872 ,
          0.5735683 , 0.2152471 ],
         [0.8681404 ...5],
         [0.6717273 , 0.3416745 , 0.57589597, ..., 0.53901374,
          0.18703866, 0.92339593]]]], dtype=float32)
mask = None

    def extract_features(self, image: Tensor, mask: Optional[Tensor] = None) -> Dict[str, Tensor]:
        """Function for feature extraction from simple image."""
>       lafs0, resps0, descs0 = self.local_feature(image, mask)

/opt/miniconda/envs/multienv/lib/python3.10/site-packages/kornia/feature/integrated.py:313: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = GFTTAffNetHardNet(
  (detector): MultiResolutionDetector(
    (model): CornerGFTT(grads_mode=sobel)
    (nms): NonMaxi...ps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    )
  ), patch_size=32, grayscale_descriptor='True)
)
args = (Array([[[[0.5100496 , 0.44573033, 0.7819073 , ..., 0.6621872 ,
          0.5735683 , 0.2152471 ],
         [0.8681404...      [0.6717273 , 0.3416745 , 0.57589597, ..., 0.53901374,
          0.18703866, 0.92339593]]]], dtype=float32), None)
kwargs = {}

    def _wrapped_call_impl(self, *args, **kwargs):
        if self._compiled_call_impl is not None:
            return self._compiled_call_impl(*args, **kwargs)  # type: ignore[misc]
        else:
>           return self._call_impl(*args, **kwargs)

/opt/fw/torch/torch/nn/modules/module.py:1553: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = GFTTAffNetHardNet(
  (detector): MultiResolutionDetector(
    (model): CornerGFTT(grads_mode=sobel)
    (nms): NonMaxi...ps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    )
  ), patch_size=32, grayscale_descriptor='True)
)
args = (Array([[[[0.5100496 , 0.44573033, 0.7819073 , ..., 0.6621872 ,
          0.5735683 , 0.2152471 ],
         [0.8681404...      [0.6717273 , 0.3416745 , 0.57589597, ..., 0.53901374,
          0.18703866, 0.92339593]]]], dtype=float32), None)
kwargs = {}
forward_call = <bound method LocalFeature.forward of GFTTAffNetHardNet(
  (detector): MultiResolutionDetector(
    (model): CornerGFT...s=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    )
  ), patch_size=32, grayscale_descriptor='True)
)>

    def _call_impl(self, *args, **kwargs):
        forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)
        # If we don't have any hooks, we want to skip the rest of the logic in
        # this function, and just call forward.
        if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks
                or _global_backward_pre_hooks or _global_backward_hooks
                or _global_forward_hooks or _global_forward_pre_hooks):
>           return forward_call(*args, **kwargs)

/opt/fw/torch/torch/nn/modules/module.py:1562: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = GFTTAffNetHardNet(
  (detector): MultiResolutionDetector(
    (model): CornerGFTT(grads_mode=sobel)
    (nms): NonMaxi...ps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    )
  ), patch_size=32, grayscale_descriptor='True)
)
img = Array([[[[0.5100496 , 0.44573033, 0.7819073 , ..., 0.6621872 ,
          0.5735683 , 0.2152471 ],
         [0.8681404 ...5],
         [0.6717273 , 0.3416745 , 0.57589597, ..., 0.53901374,
          0.18703866, 0.92339593]]]], dtype=float32)
mask = None

    def forward(self, img: Tensor, mask: Optional[Tensor] = None) -> Tuple[Tensor, Tensor, Tensor]:
        """
        Args:
            img: image to extract features with shape :math:`(B,C,H,W)`.
            mask: a mask with weights where to apply the response function.
                The shape must be the same as the input image.
    
        Returns:
            - Detected local affine frames with shape :math:`(B,N,2,3)`.
            - Response function values for corresponding lafs with shape :math:`(B,N,1)`.
            - Local descriptors of shape :math:`(B,N,D)` where :math:`D` is descriptor size.
        """
>       lafs, responses = self.detector(img, mask)

/opt/miniconda/envs/multienv/lib/python3.10/site-packages/kornia/feature/integrated.py:139: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = MultiResolutionDetector(
  (model): CornerGFTT(grads_mode=sobel)
  (nms): NonMaximaSuppression2d()
  (ori): LAFOriente...d(64, 3, kernel_size=(8, 8), stride=(1, 1))
      (20): Tanh()
      (21): AdaptiveAvgPool2d(output_size=1)
    )
  )
)
args = (Array([[[[0.5100496 , 0.44573033, 0.7819073 , ..., 0.6621872 ,
          0.5735683 , 0.2152471 ],
         [0.8681404...      [0.6717273 , 0.3416745 , 0.57589597, ..., 0.53901374,
          0.18703866, 0.92339593]]]], dtype=float32), None)
kwargs = {}

    def _wrapped_call_impl(self, *args, **kwargs):
        if self._compiled_call_impl is not None:
            return self._compiled_call_impl(*args, **kwargs)  # type: ignore[misc]
        else:
>           return self._call_impl(*args, **kwargs)

/opt/fw/torch/torch/nn/modules/module.py:1553: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = MultiResolutionDetector(
  (model): CornerGFTT(grads_mode=sobel)
  (nms): NonMaximaSuppression2d()
  (ori): LAFOriente...d(64, 3, kernel_size=(8, 8), stride=(1, 1))
      (20): Tanh()
      (21): AdaptiveAvgPool2d(output_size=1)
    )
  )
)
args = (Array([[[[0.5100496 , 0.44573033, 0.7819073 , ..., 0.6621872 ,
          0.5735683 , 0.2152471 ],
         [0.8681404...      [0.6717273 , 0.3416745 , 0.57589597, ..., 0.53901374,
          0.18703866, 0.92339593]]]], dtype=float32), None)
kwargs = {}
forward_call = <bound method MultiResolutionDetector.forward of MultiResolutionDetector(
  (model): CornerGFTT(grads_mode=sobel)
  (n...(64, 3, kernel_size=(8, 8), stride=(1, 1))
      (20): Tanh()
      (21): AdaptiveAvgPool2d(output_size=1)
    )
  )
)>

    def _call_impl(self, *args, **kwargs):
        forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)
        # If we don't have any hooks, we want to skip the rest of the logic in
        # this function, and just call forward.
        if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks
                or _global_backward_pre_hooks or _global_backward_hooks
                or _global_forward_hooks or _global_forward_pre_hooks):
>           return forward_call(*args, **kwargs)

/opt/fw/torch/torch/nn/modules/module.py:1562: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = MultiResolutionDetector(
  (model): CornerGFTT(grads_mode=sobel)
  (nms): NonMaximaSuppression2d()
  (ori): LAFOriente...d(64, 3, kernel_size=(8, 8), stride=(1, 1))
      (20): Tanh()
      (21): AdaptiveAvgPool2d(output_size=1)
    )
  )
)
img = Array([[[[0.5100496 , 0.44573033, 0.7819073 , ..., 0.6621872 ,
          0.5735683 , 0.2152471 ],
         [0.8681404 ...5],
         [0.6717273 , 0.3416745 , 0.57589597, ..., 0.53901374,
          0.18703866, 0.92339593]]]], dtype=float32)
mask = None

    def forward(self, img: Tensor, mask: Optional[Tensor] = None) -> Tuple[Tensor, Tensor]:
        """Three stage local feature detection. First the location and scale of interest points are determined by
        detect function. Then affine shape and orientation.
    
        Args:
            img: image to extract features with shape [1xCxHxW]. KeyNetDetector does not support batch processing,
        because the number of detections is different on each image.
            mask: a mask with weights where to apply the response function. The shape must be the same as
              the input image.
    
        Returns:
            lafs: shape [1xNx2x3]. Detected local affine frames.
            responses: shape [1xNx1]. Response function values for corresponding lafs
        """
        KORNIA_CHECK_SHAPE(img, ["1", "C", "H", "W"])
>       responses, lafs = self.detect(img, mask)

/opt/miniconda/envs/multienv/lib/python3.10/site-packages/kornia/feature/scale_space_detector.py:392: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = MultiResolutionDetector(
  (model): CornerGFTT(grads_mode=sobel)
  (nms): NonMaximaSuppression2d()
  (ori): LAFOriente...d(64, 3, kernel_size=(8, 8), stride=(1, 1))
      (20): Tanh()
      (21): AdaptiveAvgPool2d(output_size=1)
    )
  )
)
img = Array([[[[0.5100496 , 0.44573033, 0.7819073 , ..., 0.6621872 ,
          0.5735683 , 0.2152471 ],
         [0.8681404 ...5],
         [0.6717273 , 0.3416745 , 0.57589597, ..., 0.53901374,
          0.18703866, 0.92339593]]]], dtype=float32)
mask = None

    def detect(self, img: Tensor, mask: Optional[Tensor] = None) -> Tuple[Tensor, Tensor]:
        # Compute points per level
        num_features_per_level: List[float] = []
        tmp = 0.0
        factor_points = self.scale_factor_levels**2
        levels = self.num_pyramid_levels + self.num_upscale_levels + 1
        for idx_level in range(levels):
            tmp += factor_points ** (-1 * (idx_level - self.num_upscale_levels))
            nf = self.num_features * factor_points ** (-1 * (idx_level - self.num_upscale_levels))
            num_features_per_level.append(nf)
        num_features_per_level = [int(x / tmp) for x in num_features_per_level]
    
        _, _, h, w = img.shape
        img_up = img
        cur_img = img
        all_responses: List[Tensor] = []
        all_lafs: List[Tensor] = []
        # Extract features from the upper levels
        for idx_level in range(self.num_upscale_levels):
            nf = num_features_per_level[len(num_features_per_level) - self.num_pyramid_levels - 1 - (idx_level + 1)]
            num_points_level = int(nf)
    
            # Resize input image
            up_factor = self.scale_factor_levels ** (1 + idx_level)
            nh, nw = int(h * up_factor), int(w * up_factor)
            up_factor_kpts = (float(w) / float(nw), float(h) / float(nh))
>           img_up = resize(img_up, (nh, nw), interpolation="bilinear", align_corners=False)

/opt/miniconda/envs/multienv/lib/python3.10/site-packages/kornia/feature/scale_space_detector.py:345: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = Array([[[[0.5100496 , 0.44573033, 0.7819073 , ..., 0.6621872 ,
          0.5735683 , 0.2152471 ],
         [0.8681404 ...5],
         [0.6717273 , 0.3416745 , 0.57589597, ..., 0.53901374,
          0.18703866, 0.92339593]]]], dtype=float32)
args = ((452, 282),), kwargs = {'align_corners': False, 'interpolation': 'bilinear'}

    @wraps(f)
    def _wrapper(input: Tensor, *args: Any, **kwargs: Any) -> Tensor:
        if not isinstance(input, Tensor):
>           raise TypeError(f"Input input type is not a Tensor. Got {type(input)}")
E           TypeError: Input input type is not a Tensor. Got <class 'jaxlib.xla_extension.ArrayImpl'>

/opt/miniconda/envs/multienv/lib/python3.10/site-packages/kornia/utils/image.py:224: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.LocalFeatureMatcher
_________________________________________________________________________________ test_LightGlueMatcher[jax-s2s-False] _________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_LightGlueMatcher(target_framework, mode, backend_compile):
        print("kornia.feature.LightGlueMatcher")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledLightGlueMatcher = ivy.transpile(kornia.feature.LightGlueMatcher, source="torch", target=target_framework)
    
        torch_args = (
            torch.rand(2, 128),
            torch.rand(5, 128),
            torch.rand(1, 2, 2, 3),
            torch.rand(1, 5, 2, 3),
        )
        transpiled_args = _nest_torch_tensor_to_new_framework(torch_args, target_framework)
    
        model = kornia.feature.LightGlueMatcher('disk')
        torch_out = model(*torch_args)
    
>       transpiled_model = TranspiledLightGlueMatcher('disk')

kornia/test_feature4.py:260: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.integrated.jax_LightGlueMatcher'>, args = ('disk',), kwargs = {}

    def __call__(cls, *args: Any, **kwargs: Any) -> Any:
>     return _graph_node_meta_call(cls, *args, **kwargs)

/opt/fw/jax/flax/nnx/nnx/object.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.integrated.jax_LightGlueMatcher'>, args = ('disk',), kwargs = {}, node = jax_LightGlueMatcher()

    def _graph_node_meta_call(cls: tp.Type[G], *args, **kwargs) -> G:
      node = cls.__new__(cls, *args, **kwargs)
      vars(node)['_object__state'] = ObjectState()
>     cls._object_meta_construct(node, *args, **kwargs)

/opt/fw/jax/flax/nnx/nnx/object.py:88: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.integrated.jax_LightGlueMatcher'>, self = jax_LightGlueMatcher(), args = ('disk',), kwargs = {}

    def _object_meta_construct(cls, self, *args, **kwargs):
>     self.__init__(*args, **kwargs)

/opt/fw/jax/flax/nnx/nnx/object.py:82: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_LightGlueMatcher(), feature_name = 'disk', params = {}

    def __init__(self, feature_name="disk", params={}):
        from .lightglue import jax_LightGlue
    
        feature_name_: typing.Any = feature_name.lower()
        super().__init__(feature_name_)
        self.feature_name = feature_name_
        self.params = params
>       self.matcher = jax_LightGlue(self.feature_name, **params)

ivy_transpiled_outputs/jax_outputs/kornia/feature/integrated.py:51: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.lightglue.jax_LightGlue'>, args = ('disk',), kwargs = {}

    def __call__(cls, *args: Any, **kwargs: Any) -> Any:
>     return _graph_node_meta_call(cls, *args, **kwargs)

/opt/fw/jax/flax/nnx/nnx/object.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.lightglue.jax_LightGlue'>, args = ('disk',), kwargs = {}
node = jax_LightGlue(
  (input_proj): FlaxLinear(in_features=128, out_features=256, use_bias=True)
  (posenc): jax_LearnableFourierPositionalEncoding(
    (Wr): FlaxLinear(in_features=2, out_features=32, use_bias=False)
  )
)

    def _graph_node_meta_call(cls: tp.Type[G], *args, **kwargs) -> G:
      node = cls.__new__(cls, *args, **kwargs)
      vars(node)['_object__state'] = ObjectState()
>     cls._object_meta_construct(node, *args, **kwargs)

/opt/fw/jax/flax/nnx/nnx/object.py:88: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.lightglue.jax_LightGlue'>
self = jax_LightGlue(
  (input_proj): FlaxLinear(in_features=128, out_features=256, use_bias=True)
  (posenc): jax_LearnableFourierPositionalEncoding(
    (Wr): FlaxLinear(in_features=2, out_features=32, use_bias=False)
  )
)
args = ('disk',), kwargs = {}

    def _object_meta_construct(cls, self, *args, **kwargs):
>     self.__init__(*args, **kwargs)

/opt/fw/jax/flax/nnx/nnx/object.py:82: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_LightGlue(
  (input_proj): FlaxLinear(in_features=128, out_features=256, use_bias=True)
  (posenc): jax_LearnableFourierPositionalEncoding(
    (Wr): FlaxLinear(in_features=2, out_features=32, use_bias=False)
  )
)
args = ('disk',), kwargs = {}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/utils/decorator_utils.py:245: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_LightGlue(
  (input_proj): FlaxLinear(in_features=128, out_features=256, use_bias=True)
  (posenc): jax_LearnableFourierPositionalEncoding(
    (Wr): FlaxLinear(in_features=2, out_features=32, use_bias=False)
  )
)
features = 'disk', conf_ = {}, jax_KORNIA_CHECK = <function jax_KORNIA_CHECK at 0x7fa2c128f490>, jax_get_item = <function jax_get_item at 0x7fa2c127a170>
jax_Identity = <class 'ivy_transpiled_outputs.jax_outputs.torch.nn.modules.linear.jax_Identity'>, jax_load_state_dict_from_url_frnt = <function jax_load_state_dict_from_url_frnt at 0x7fa2c3595630>
jax_load_frnt = <function jax_load_frnt at 0x7fa2c3595bd0>, ModuleList = <class 'ivy_transpiled_outputs.jax_outputs.torch.nn.modules.container.jax_ModuleList'>
FlaxLinear = <class 'ivy_transpiled_outputs.jax_outputs.jax__stateful_layers.FlaxLinear'>

    @jax_store_config_info
    def __init__(self, features="superpoint", **conf_):
        from ..core.check import jax_KORNIA_CHECK
        from ...ivy.functional.backends.jax.general import jax_get_item
        from ...torch.nn.modules.linear import jax_Identity
        from ...ivy.functional.frontends.torch.hub.hub import (
            jax_load_state_dict_from_url_frnt,
        )
        from ...ivy.functional.frontends.torch.serialization.serialization import (
            jax_load_frnt,
        )
        from ..core._backend import ModuleList
        from ...jax__stateful_layers import FlaxLinear
    
        self.super___init__(
            features=features,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        self.conf = conf = SimpleNamespace(**{**self.default_conf, **conf_})
        if features is not None:
            jax_KORNIA_CHECK(
                features in list(self.features.keys()), "Features keys are wrong"
            )
            for k, v in jax_get_item(self.features, features).items():
                setattr(conf, k, v)
        jax_KORNIA_CHECK(not (self.conf.add_scale_ori and self.conf.add_laf))
        if conf.input_dim != conf.descriptor_dim:
            self.input_proj = FlaxLinear(
                in_features=conf.input_dim,
                out_features=conf.descriptor_dim,
                use_bias=True,
            )
        else:
            self.input_proj = jax_Identity()
        head_dim = conf.descriptor_dim // conf.num_heads
        self.posenc = jax_LearnableFourierPositionalEncoding(
            2 + 2 * conf.add_scale_ori + 4 * conf.add_laf, head_dim, head_dim
        )
        h, n, d = conf.num_heads, conf.n_layers, conf.descriptor_dim
        ag__result_list_0 = []
        for _ in range(n):
>           res = jax_TransformerLayer(d, h, conf.flash)

ivy_transpiled_outputs/jax_outputs/kornia/feature/lightglue.py:1389: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.lightglue.jax_TransformerLayer'>, args = (256, 4, True), kwargs = {}

    def __call__(cls, *args: Any, **kwargs: Any) -> Any:
>     return _graph_node_meta_call(cls, *args, **kwargs)

/opt/fw/jax/flax/nnx/nnx/object.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.lightglue.jax_TransformerLayer'>, args = (256, 4, True), kwargs = {}, node = jax_TransformerLayer()

    def _graph_node_meta_call(cls: tp.Type[G], *args, **kwargs) -> G:
      node = cls.__new__(cls, *args, **kwargs)
      vars(node)['_object__state'] = ObjectState()
>     cls._object_meta_construct(node, *args, **kwargs)

/opt/fw/jax/flax/nnx/nnx/object.py:88: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.lightglue.jax_TransformerLayer'>, self = jax_TransformerLayer(), args = (256, 4, True), kwargs = {}

    def _object_meta_construct(cls, self, *args, **kwargs):
>     self.__init__(*args, **kwargs)

/opt/fw/jax/flax/nnx/nnx/object.py:82: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_TransformerLayer(), args = (256, 4, True), kwargs = {}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/utils/decorator_utils.py:245: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_TransformerLayer(), args = (256, 4, True), kwargs = {}

    @jax_store_config_info
    def __init__(self, *args, **kwargs):
        self.super___init__(
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
>       self.self_attn = jax_SelfBlock(*args, **kwargs)

ivy_transpiled_outputs/jax_outputs/kornia/feature/lightglue.py:944: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.lightglue.jax_SelfBlock'>, args = (256, 4, True), kwargs = {}

    def __call__(cls, *args: Any, **kwargs: Any) -> Any:
>     return _graph_node_meta_call(cls, *args, **kwargs)

/opt/fw/jax/flax/nnx/nnx/object.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.lightglue.jax_SelfBlock'>, args = (256, 4, True), kwargs = {}
node = jax_SelfBlock(
  (Wqkv): FlaxLinear(in_features=256, out_features=768, use_bias=True)
)

    def _graph_node_meta_call(cls: tp.Type[G], *args, **kwargs) -> G:
      node = cls.__new__(cls, *args, **kwargs)
      vars(node)['_object__state'] = ObjectState()
>     cls._object_meta_construct(node, *args, **kwargs)

/opt/fw/jax/flax/nnx/nnx/object.py:88: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.lightglue.jax_SelfBlock'>, self = jax_SelfBlock(
  (Wqkv): FlaxLinear(in_features=256, out_features=768, use_bias=True)
)
args = (256, 4, True), kwargs = {}

    def _object_meta_construct(cls, self, *args, **kwargs):
>     self.__init__(*args, **kwargs)

/opt/fw/jax/flax/nnx/nnx/object.py:82: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_SelfBlock(
  (Wqkv): FlaxLinear(in_features=256, out_features=768, use_bias=True)
), args = (256, 4, True), kwargs = {}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/utils/decorator_utils.py:245: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_SelfBlock(
  (Wqkv): FlaxLinear(in_features=256, out_features=768, use_bias=True)
), embed_dim = 256, num_heads = 4, flash = True, bias = True

    @jax_store_config_info
    def __init__(self, embed_dim, num_heads, flash=False, bias=True):
        from ..core.check import jax_KORNIA_CHECK
        from ...torch.nn.modules.container import jax_Sequential
        from ...torch.nn.modules.normalization import jax_LayerNorm
        from ...torch.nn.modules.activation import jax_GELU
        from ...jax__stateful_layers import FlaxLinear
    
        self.super___init__(
            embed_dim,
            num_heads,
            flash=flash,
            bias=bias,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        self.embed_dim = embed_dim
        self.num_heads = num_heads
        jax_KORNIA_CHECK(
            self.embed_dim % num_heads == 0,
            "Embed dimension should be dividable by num_heads",
        )
        self.head_dim = self.embed_dim // num_heads
        self.Wqkv = FlaxLinear(
            in_features=embed_dim, out_features=3 * embed_dim, use_bias=bias
        )
>       self.inner_attn = jax_Attention(flash)

ivy_transpiled_outputs/jax_outputs/kornia/feature/lightglue.py:588: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.lightglue.jax_Attention'>, args = (True,), kwargs = {}

    def __call__(cls, *args: Any, **kwargs: Any) -> Any:
>     return _graph_node_meta_call(cls, *args, **kwargs)

/opt/fw/jax/flax/nnx/nnx/object.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.lightglue.jax_Attention'>, args = (True,), kwargs = {}, node = jax_Attention()

    def _graph_node_meta_call(cls: tp.Type[G], *args, **kwargs) -> G:
      node = cls.__new__(cls, *args, **kwargs)
      vars(node)['_object__state'] = ObjectState()
>     cls._object_meta_construct(node, *args, **kwargs)

/opt/fw/jax/flax/nnx/nnx/object.py:88: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.lightglue.jax_Attention'>, self = jax_Attention(), args = (True,), kwargs = {}

    def _object_meta_construct(cls, self, *args, **kwargs):
>     self.__init__(*args, **kwargs)

/opt/fw/jax/flax/nnx/nnx/object.py:82: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_Attention(), args = (True,), kwargs = {}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/utils/decorator_utils.py:245: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_Attention(), allow_flash = True

    @jax_store_config_info
    def __init__(self, allow_flash):
        self.super___init__(
            allow_flash,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        if allow_flash and not FLASH_AVAILABLE:
            warnings.warn(
                "FlashAttention is not available. For optimal speed, consider installing torch >= 2.0 or flash-attn.",
                stacklevel=2,
            )
        self.enable_flash = allow_flash and FLASH_AVAILABLE
>       self.has_sdp = hasattr(torch.nn.functional, "scaled_dot_product_attention")
E       NameError: name 'torch' is not defined

ivy_transpiled_outputs/jax_outputs/kornia/feature/lightglue.py:398: NameError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.LightGlueMatcher
Loaded LightGlue model
----------------------------------------------------------------------------------------- Captured stderr call -----------------------------------------------------------------------------------------
Downloading: "https://github.com/cvg/LightGlue/releases/download/v0.1_arxiv/disk_lightglue.pth" to /root/.cache/torch/hub/checkpoints/disk_lightglue_v0-1_arxiv-pth

  0%|          | 0.00/45.4M [00:00<?, ?B/s]
 82%| | 37.1M/45.4M [00:00<00:00, 388MB/s]
100%|| 45.4M/45.4M [00:00<00:00, 365MB/s]
____________________________________________________________________________________ test_LightGlue[jax-s2s-False] _____________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_LightGlue(target_framework, mode, backend_compile):
        print("kornia.feature.LightGlue")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledLightGlue = ivy.transpile(kornia.feature.LightGlue, source="torch", target=target_framework)
    
        data = {
            "image0": {
                "keypoints": torch.rand(1, 100, 2),
                "descriptors": torch.rand(1, 100, 256),
                "image_size": torch.tensor([[640, 480]]),
            },
            "image1": {
                "keypoints": torch.rand(1, 120, 2),
                "descriptors": torch.rand(1, 120, 256),
                "image_size": torch.tensor([[640, 480]]),
            }
        }
        transpiled_data = _nest_torch_tensor_to_new_framework(data, target_framework)
    
        model = kornia.feature.LightGlue(features='superpoint')
>       torch_out = model(data)

kornia/test_feature4.py:295: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LightGlue(
  (input_proj): Identity()
  (posenc): LearnableFourierPositionalEncoding(
    (Wr): Linear(in_features=2, ... Sequential(
        (0): Linear(in_features=256, out_features=1, bias=True)
        (1): Sigmoid()
      )
    )
  )
)
args = ({'image0': {'descriptors': Array([[[0.6966898 , 0.15158236, 0.24737197, ..., 0.39148146,
         0.7698963 , 0.33581...84616423e-01],
        [8.98283124e-01, 2.72608161e-01],
        [1.26591802e-01, 6.75775528e-01]]], dtype=float32)}},)
kwargs = {}

    def _wrapped_call_impl(self, *args, **kwargs):
        if self._compiled_call_impl is not None:
            return self._compiled_call_impl(*args, **kwargs)  # type: ignore[misc]
        else:
>           return self._call_impl(*args, **kwargs)

/opt/fw/torch/torch/nn/modules/module.py:1553: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LightGlue(
  (input_proj): Identity()
  (posenc): LearnableFourierPositionalEncoding(
    (Wr): Linear(in_features=2, ... Sequential(
        (0): Linear(in_features=256, out_features=1, bias=True)
        (1): Sigmoid()
      )
    )
  )
)
args = ({'image0': {'descriptors': Array([[[0.6966898 , 0.15158236, 0.24737197, ..., 0.39148146,
         0.7698963 , 0.33581...84616423e-01],
        [8.98283124e-01, 2.72608161e-01],
        [1.26591802e-01, 6.75775528e-01]]], dtype=float32)}},)
kwargs = {}
forward_call = <bound method LightGlue.forward of LightGlue(
  (input_proj): Identity()
  (posenc): LearnableFourierPositionalEncodin...Sequential(
        (0): Linear(in_features=256, out_features=1, bias=True)
        (1): Sigmoid()
      )
    )
  )
)>

    def _call_impl(self, *args, **kwargs):
        forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)
        # If we don't have any hooks, we want to skip the rest of the logic in
        # this function, and just call forward.
        if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks
                or _global_backward_pre_hooks or _global_backward_hooks
                or _global_forward_hooks or _global_forward_pre_hooks):
>           return forward_call(*args, **kwargs)

/opt/fw/torch/torch/nn/modules/module.py:1562: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LightGlue(
  (input_proj): Identity()
  (posenc): LearnableFourierPositionalEncoding(
    (Wr): Linear(in_features=2, ... Sequential(
        (0): Linear(in_features=256, out_features=1, bias=True)
        (1): Sigmoid()
      )
    )
  )
)
data = {'image0': {'descriptors': Array([[[0.6966898 , 0.15158236, 0.24737197, ..., 0.39148146,
         0.7698963 , 0.335817...5.84616423e-01],
        [8.98283124e-01, 2.72608161e-01],
        [1.26591802e-01, 6.75775528e-01]]], dtype=float32)}}

    def forward(self, data: dict) -> dict:  # type: ignore
        """Match keypoints and descriptors between two images.
    
        Input (dict):
            image0: dict
                keypoints: [B x M x 2]
                descriptors: [B x M x D]
                image: [B x C x H x W] or image_size: [B x 2]
            image1: dict
                keypoints: [B x N x 2]
                descriptors: [B x N x D]
                image: [B x C x H x W] or image_size: [B x 2]
        Output (dict):
            log_assignment: [B x M+1 x N+1]
            matches0: [B x M]
            matching_scores0: [B x M]
            matches1: [B x N]
            matching_scores1: [B x N]
            matches: List[[Si x 2]], scores: List[[Si]]
        """
        with torch.autocast(enabled=self.conf.mp, device_type="cuda"):
>           return self._forward(data)

/opt/miniconda/envs/multienv/lib/python3.10/site-packages/kornia/feature/lightglue.py:497: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LightGlue(
  (input_proj): Identity()
  (posenc): LearnableFourierPositionalEncoding(
    (Wr): Linear(in_features=2, ... Sequential(
        (0): Linear(in_features=256, out_features=1, bias=True)
        (1): Sigmoid()
      )
    )
  )
)
data = {'image0': {'descriptors': Array([[[0.6966898 , 0.15158236, 0.24737197, ..., 0.39148146,
         0.7698963 , 0.335817...5.84616423e-01],
        [8.98283124e-01, 2.72608161e-01],
        [1.26591802e-01, 6.75775528e-01]]], dtype=float32)}}

    def _forward(self, data: dict) -> dict:  # type: ignore
        for key in self.required_data_keys:
            KORNIA_CHECK(key in data, f"Missing key {key} in data")
        data0, data1 = data["image0"], data["image1"]
        kpts0, kpts1 = data0["keypoints"], data1["keypoints"]
        b, m, _ = kpts0.shape
        b, n, _ = kpts1.shape
        device = kpts0.device
        size0, size1 = data0.get("image_size"), data1.get("image_size")
        size0 = size0 if size0 is not None else data0["image"].shape[-2:][::-1]
        size1 = size1 if size1 is not None else data1["image"].shape[-2:][::-1]
    
>       kpts0 = normalize_keypoints(kpts0, size0).clone()

/opt/miniconda/envs/multienv/lib/python3.10/site-packages/kornia/feature/lightglue.py:511: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (Array([[[0.7673678 , 0.20182496],
        [0.16454417, 0.16597098],
        [0.7779314 , 0.4557045 ],
        [0.7720...        [0.52833414, 0.50609833],
        [0.9912729 , 0.62044847]]], dtype=float32), Array([[640, 480]], dtype=int64))
kwargs = {}, autocast_context = False

    @functools.wraps(fwd)
    def decorate_fwd(*args, **kwargs):
        args[0]._dtype = torch.get_autocast_dtype(device_type)
        if cast_inputs is None:
            args[0]._fwd_used_autocast = torch.is_autocast_enabled(device_type)
            return fwd(*args, **kwargs)
        else:
            autocast_context = torch.is_autocast_enabled(device_type)
            args[0]._fwd_used_autocast = False
            if autocast_context:
                with autocast(device_type=device_type, enabled=False):
                    return fwd(
                        *_cast(args, device_type, cast_inputs),
                        **_cast(kwargs, device_type, cast_inputs),
                    )
            else:
>               return fwd(*args, **kwargs)

/opt/fw/torch/torch/amp/autocast_mode.py:466: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

kpts = Array([[[0.7673678 , 0.20182496],
        [0.16454417, 0.16597098],
        [0.7779314 , 0.4557045 ],
        [0.77206...
        [0.01579726, 0.01194423],
        [0.52833414, 0.50609833],
        [0.9912729 , 0.62044847]]], dtype=float32)
size = Array([[640, 480]], dtype=int64)

    @torch.cuda.amp.custom_fwd(cast_inputs=torch.float32)
    def normalize_keypoints(kpts: Tensor, size: Tensor) -> Tensor:
        if isinstance(size, torch.Size):
            size = Tensor(size)[None]
>       shift = size.float().to(kpts) / 2
E       AttributeError: 'jaxlib.xla_extension.ArrayImpl' object has no attribute 'float'. Did you mean: 'flat'?

/opt/miniconda/envs/multienv/lib/python3.10/site-packages/kornia/feature/lightglue.py:48: AttributeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.LightGlue
Loaded LightGlue model
----------------------------------------------------------------------------------------- Captured stderr call -----------------------------------------------------------------------------------------
Downloading: "https://github.com/cvg/LightGlue/releases/download/v0.1_arxiv/superpoint_lightglue.pth" to /root/.cache/torch/hub/checkpoints/superpoint_lightglue_v0-1_arxiv-pth

  0%|          | 0.00/45.3M [00:00<?, ?B/s]
 52%|    | 23.8M/45.3M [00:00<00:00, 249MB/s]
100%|| 45.3M/45.3M [00:00<00:00, 291MB/s]
______________________________________________________________________________________ test_LoFTR[jax-s2s-False] _______________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_LoFTR(target_framework, mode, backend_compile):
        print("kornia.feature.LoFTR")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledLoFTR = ivy.transpile(kornia.feature.LoFTR, source="torch", target=target_framework)
    
        data = {"image0": torch.rand(1, 1, 320, 200), "image1": torch.rand(1, 1, 128, 128)}
        transpiled_data = _nest_torch_tensor_to_new_framework(data, target_framework)
    
        model = kornia.feature.LoFTR(None)
>       torch_out = model(data)

kornia/test_feature4.py:322: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LoFTR(
  (backbone): ResNetFPN_8_2(
    (conv1): Conv2d(1, 128, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bia...   (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (fine_matching): FineMatching()
)
args = ({'image0': Array([[[[4.4982684e-01, 2.5278330e-04, 9.2534173e-01, ...,
          3.8101572e-01, 6.2732899e-01, 2.1114...
         [0.12415963, 0.19707769, 0.00739896, ..., 0.26862258,
          0.8852669 , 0.6650938 ]]]], dtype=float32)},)
kwargs = {}

    def _wrapped_call_impl(self, *args, **kwargs):
        if self._compiled_call_impl is not None:
            return self._compiled_call_impl(*args, **kwargs)  # type: ignore[misc]
        else:
>           return self._call_impl(*args, **kwargs)

/opt/fw/torch/torch/nn/modules/module.py:1553: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LoFTR(
  (backbone): ResNetFPN_8_2(
    (conv1): Conv2d(1, 128, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bia...   (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (fine_matching): FineMatching()
)
args = ({'image0': Array([[[[4.4982684e-01, 2.5278330e-04, 9.2534173e-01, ...,
          3.8101572e-01, 6.2732899e-01, 2.1114...
         [0.12415963, 0.19707769, 0.00739896, ..., 0.26862258,
          0.8852669 , 0.6650938 ]]]], dtype=float32)},)
kwargs = {}
forward_call = <bound method LoFTR.forward of LoFTR(
  (backbone): ResNetFPN_8_2(
    (conv1): Conv2d(1, 128, kernel_size=(7, 7), str...  (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (fine_matching): FineMatching()
)>

    def _call_impl(self, *args, **kwargs):
        forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)
        # If we don't have any hooks, we want to skip the rest of the logic in
        # this function, and just call forward.
        if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks
                or _global_backward_pre_hooks or _global_backward_hooks
                or _global_forward_hooks or _global_forward_pre_hooks):
>           return forward_call(*args, **kwargs)

/opt/fw/torch/torch/nn/modules/module.py:1562: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LoFTR(
  (backbone): ResNetFPN_8_2(
    (conv1): Conv2d(1, 128, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bia...   (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (fine_matching): FineMatching()
)
data = {'image0': Array([[[[4.4982684e-01, 2.5278330e-04, 9.2534173e-01, ...,
          3.8101572e-01, 6.2732899e-01, 2.11143...],
         [0.12415963, 0.19707769, 0.00739896, ..., 0.26862258,
          0.8852669 , 0.6650938 ]]]], dtype=float32)}

    def forward(self, data: dict[str, Tensor]) -> dict[str, Tensor]:
        """
        Args:
            data: dictionary containing the input data in the following format:
    
        Keyword Args:
            image0: left image with shape :math:`(N, 1, H1, W1)`.
            image1: right image with shape :math:`(N, 1, H2, W2)`.
            mask0 (optional): left image mask. '0' indicates a padded position :math:`(N, H1, W1)`.
            mask1 (optional): right image mask. '0' indicates a padded position :math:`(N, H2, W2)`.
    
        Returns:
            - ``keypoints0``, matching keypoints from image0 :math:`(NC, 2)`.
            - ``keypoints1``, matching keypoints from image1 :math:`(NC, 2)`.
            - ``confidence``, confidence score [0, 1] :math:`(NC)`.
            - ``batch_indexes``, batch indexes for the keypoints and lafs :math:`(NC)`.
        """
        # 1. Local Feature CNN
        _data: dict[str, Tensor | int | torch.Size] = {
>           "bs": data["image0"].size(0),
            "hw0_i": data["image0"].shape[2:],
            "hw1_i": data["image1"].shape[2:],
        }
E       TypeError: 'int' object is not callable

/opt/miniconda/envs/multienv/lib/python3.10/site-packages/kornia/feature/loftr/loftr.py:123: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.LoFTR
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/test_feature4.py::test_SIFTFeatureScaleSpace[jax-s2s-False] - TypeError: '<class 'jaxlib.xla_extension.ArrayImpl'>' object does not support item assignment. JAX arrays are immutable. ...
FAILED kornia/test_feature4.py::test_LocalFeatureMatcher[jax-s2s-False] - TypeError: Input input type is not a Tensor. Got <class 'jaxlib.xla_extension.ArrayImpl'>
FAILED kornia/test_feature4.py::test_LightGlueMatcher[jax-s2s-False] - NameError: name 'torch' is not defined
FAILED kornia/test_feature4.py::test_LightGlue[jax-s2s-False] - AttributeError: 'jaxlib.xla_extension.ArrayImpl' object has no attribute 'float'. Did you mean: 'flat'?
FAILED kornia/test_feature4.py::test_LoFTR[jax-s2s-False] - TypeError: 'int' object is not callable
=============================================================================== 5 failed, 9 passed in 3189.83s (0:53:09) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 14 items

kornia/test_feature4.py FFFF...FFFF...                                                                                                                                                           [100%]

=============================================================================================== FAILURES ===============================================================================================
________________________________________________________________________________ test_SIFTFeature[tensorflow-s2s-False] ________________________________________________________________________________

inp = <tf.Variable 'Variable:0' shape=(5, 1, 1) dtype=float32, numpy=
array([[[ 0.47538185]],

       [[-0.20317745]],

       [[ 0.59031725]],

       [[ 0.9571643 ]],

       [[ 0.21384907]]], dtype=float32)>
query = slice(None, None, None), val = <tf.Tensor: shape=(1, 5), dtype=float32, numpy=
array([[0.1190625 , 0.2311236 , 0.29962778, 0.2311236 , 0.1190625 ]],
      dtype=float32)>, kwargs = {}

    @functools.wraps(fn)
    def wrapper(inp, query, val, **kwargs):
        try:
>           inp.__setitem__(query, val)
E           AttributeError: 'ResourceVariable' object has no attribute '__setitem__'. Did you mean: '__getitem__'?

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:233: AttributeError

During handling of the above exception, another exception occurred:

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_SIFTFeature(target_framework, mode, backend_compile):
        print("kornia.feature.SIFTFeature")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledSIFTFeature = ivy.transpile(kornia.feature.SIFTFeature, source="torch", target=target_framework)
    
        x = torch.rand(1, 1, 256, 256)
        transpiled_x = _nest_torch_tensor_to_new_framework(x, target_framework)
    
        model = kornia.feature.SIFTFeature(num_features=10)
        torch_out = model(x)
    
>       transpiled_model = TranspiledSIFTFeature(num_features=10)

kornia/test_feature4.py:31: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_SIFTFeature object at 0x7f429bc04940>, num_features = 10, upright = False, rootsift = True
device = 'cpu', config = {'nms_size': 15, 'pyramid_levels': 4, 's_mult': 22.0, 'scale_factor_levels': 1.4142135623730951, ...}

    def __init__(
        self,
        num_features=8000,
        upright=False,
        rootsift=True,
        device=tensorflow_device_frnt("cpu"),
        config=tensorflow_get_default_detector_config(),
    ):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_to_frnt_
        from .scale_space_detector import tensorflow_MultiResolutionDetector
        from .responses import tensorflow_BlobDoGSingle
        from .orientation import tensorflow_PassLAF
        from .orientation import tensorflow_LAFOrienter
        from .siftdesc import tensorflow_SIFTDescriptor
    
        patch_size: typing.Any = 41
        detector = tensorflow_to_frnt_(
            tensorflow_MultiResolutionDetector(
                tensorflow_BlobDoGSingle(1.0, 1.6),
                num_features,
                config,
                ori_module=tensorflow_PassLAF()
                if upright
>               else tensorflow_LAFOrienter(19),
                aff_module=tensorflow_PassLAF(),
            ),
            device,
        )

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/integrated.py:353: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'tensorflow_LAFOrienter' object has no attribute 'angle_detector'") raised in repr()] tensorflow_LAFOrienter object at 0x7f429bc04670>, args = (19,), kwargs = {}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'tensorflow_LAFOrienter' object has no attribute 'angle_detector'") raised in repr()] tensorflow_LAFOrienter object at 0x7f429bc04670>, patch_size = 19, num_angular_bins = 36
angle_detector = None

    @tensorflow_store_config_info
    def __init__(self, patch_size=32, num_angular_bins=36, angle_detector=None):
        self.super___init__(
            patch_size=patch_size,
            num_angular_bins=num_angular_bins,
            angle_detector=angle_detector,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        self.patch_size = patch_size
        self.num_ang_bins = num_angular_bins
        self.angle_detector: typing.Any
        if angle_detector is None:
>           self.angle_detector = tensorflow_PatchDominantGradientOrientation(
                self.patch_size, self.num_ang_bins
            )

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/orientation.py:387: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_PatchDominantGradientOrientation(patch_size=19, num_ang_bins=36, eps=1e-08), args = (19, 36), kwargs = {}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_PatchDominantGradientOrientation(patch_size=19, num_ang_bins=36, eps=1e-08), patch_size = 19, num_angular_bins = 36, eps = 1e-08

    @tensorflow_store_config_info
    def __init__(self, patch_size=32, num_angular_bins=36, eps=1e-08):
        from ..filters.sobel import tensorflow_SpatialGradient
        from ...torch.nn.modules.conv import tensorflow_Conv1d
        from ...ivy.functional.backends.tensorflow.general import tensorflow_set_item
        from ..filters.kernels import tensorflow_get_gaussian_discrete_kernel1d
        from ..filters.kernels import tensorflow_get_gaussian_kernel2d
    
        self.super___init__(
            patch_size=patch_size,
            num_angular_bins=num_angular_bins,
            eps=eps,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        self.patch_size = patch_size
        self.num_ang_bins = num_angular_bins
        self.gradient = tensorflow_SpatialGradient("sobel", 1)
        self.eps = eps
        self.angular_smooth = tensorflow_Conv1d(
            1, 1, kernel_size=5, padding=2, bias=False, padding_mode="circular"
        )
>       self.angular_smooth.weight = tensorflow_set_item(
            self.angular_smooth.weight,
            slice(None, None, None),
            tensorflow_get_gaussian_discrete_kernel1d(5, 1.6),
        )

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/orientation.py:178: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

inp = <tf.Variable 'Variable:0' shape=(5, 1, 1) dtype=float32, numpy=
array([[[ 0.47538185]],

       [[-0.20317745]],

       [[ 0.59031725]],

       [[ 0.9571643 ]],

       [[ 0.21384907]]], dtype=float32)>
query = slice(None, None, None), val = <tf.Tensor: shape=(1, 5), dtype=float32, numpy=
array([[0.1190625 , 0.2311236 , 0.29962778, 0.2311236 , 0.1190625 ]],
      dtype=float32)>, kwargs = {}

    @functools.wraps(fn)
    def wrapper(inp, query, val, **kwargs):
        try:
            inp.__setitem__(query, val)
            res = inp
        except IndexError:
            raise
        except Exception:
>           res = fn(inp, query, val, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:238: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (<tf.Variable 'Variable:0' shape=(5, 1, 1) dtype=float32, numpy=
array([[[ 0.47538185]],

       [[-0.20317745]],

   ... 5), dtype=float32, numpy=
array([[0.1190625 , 0.2311236 , 0.29962778, 0.2311236 , 0.1190625 ]],
      dtype=float32)>)
kwargs = {}, handle_mixed_in_backend = True

    @functools.wraps(fn)
    def _handle_partial_mixed_function(*args, **kwargs):
        handle_mixed_in_backend = False
        if not hasattr(fn, "partial_mixed_handler"):
            handle_mixed_in_backend = True
        else:
            compos = getattr(fn, "compos")
            condition = getattr(fn, "partial_mixed_handler")
        if handle_mixed_in_backend or condition(*args, **kwargs):
>           return fn(*args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/func_wrapper.py:173: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[ 0.47538185]],

       [[-0.20317745]],

       [[ 0.59031725]],

       [[ 0.9571643 ]],

       [[ 0.21384907]]], dtype=float32), query = slice(None, None, None)
val = array([[0.1190625 , 0.2311236 , 0.29962778, 0.2311236 , 0.1190625 ]],
      dtype=float32)

    @tensorflow_handle_set_item
    @tensorflow_handle_partial_mixed_function
    def tensorflow_set_item(
        x: Union[tensorflow.Tensor, tensorflow.Variable],
        query: Union[tensorflow.Tensor, tensorflow.Variable, Tuple],
        val: Union[tensorflow.Tensor, tensorflow.Variable],
        /,
        *,
        copy: Optional[bool] = False,
    ):
        if tensorflow.is_tensor(x):
            x = x.numpy()
        if tensorflow.is_tensor(val):
            val = val.numpy()
        if isinstance(query, (tensorflow.Tensor, tensorflow.Variable)):
            query = query.numpy()
        elif isinstance(query, tuple):
            query = tuple(
                q.numpy() if isinstance(q, (tensorflow.Tensor, tensorflow.Variable)) else q
                for q in query
            )
>       x[query] = val
E       ValueError: could not broadcast input array from shape (1,5) into shape (5,1,1)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/backends/tensorflow/general.py:109: ValueError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.SIFTFeature
___________________________________________________________________________ test_SIFTFeatureScaleSpace[tensorflow-s2s-False] ___________________________________________________________________________

inp = <tf.Variable 'Variable:0' shape=(5, 1, 1) dtype=float32, numpy=
array([[[-0.9409752 ]],

       [[ 0.7687769 ]],

       [[ 0.96980596]],

       [[-0.6349077 ]],

       [[-0.8625691 ]]], dtype=float32)>
query = slice(None, None, None), val = <tf.Tensor: shape=(1, 5), dtype=float32, numpy=
array([[0.1190625 , 0.2311236 , 0.29962778, 0.2311236 , 0.1190625 ]],
      dtype=float32)>, kwargs = {}

    @functools.wraps(fn)
    def wrapper(inp, query, val, **kwargs):
        try:
>           inp.__setitem__(query, val)
E           AttributeError: 'ResourceVariable' object has no attribute '__setitem__'. Did you mean: '__getitem__'?

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:233: AttributeError

During handling of the above exception, another exception occurred:

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_SIFTFeatureScaleSpace(target_framework, mode, backend_compile):
        print("kornia.feature.SIFTFeatureScaleSpace")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledSIFTFeatureScaleSpace = ivy.transpile(kornia.feature.SIFTFeatureScaleSpace, source="torch", target=target_framework)
    
        x = torch.rand(1, 1, 256, 256)
        transpiled_x = _nest_torch_tensor_to_new_framework(x, target_framework)
    
        model = kornia.feature.SIFTFeatureScaleSpace(num_features=10)
        torch_out = model(x)
    
>       transpiled_model = TranspiledSIFTFeatureScaleSpace(num_features=10)

kornia/test_feature4.py:57: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_SIFTFeatureScaleSpace object at 0x7f4288459630>, num_features = 10, upright = False, rootsift = True
device = 'cpu'

    def __init__(
        self,
        num_features=8000,
        upright=False,
        rootsift=True,
        device=tensorflow_device_frnt("cpu"),
    ):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_to_frnt_
        from .scale_space_detector import tensorflow_ScaleSpaceDetector
        from .responses import tensorflow_BlobDoG
        from ..geometry.subpix.spatial_soft_argmax import tensorflow_ConvQuadInterp3d
        from ..geometry.transform.pyramid import tensorflow_ScalePyramid
        from .orientation import tensorflow_PassLAF
        from .orientation import tensorflow_LAFOrienter
        from .siftdesc import tensorflow_SIFTDescriptor
    
        patch_size: typing.Any = 41
        detector = tensorflow_to_frnt_(
            tensorflow_ScaleSpaceDetector(
                num_features,
                resp_module=tensorflow_BlobDoG(),
                nms_module=tensorflow_ConvQuadInterp3d(10),
                scale_pyr_module=tensorflow_ScalePyramid(3, 1.6, 32, double_image=True),
                ori_module=tensorflow_PassLAF()
                if upright
>               else tensorflow_LAFOrienter(19),
                scale_space_response=True,
                minima_are_also_good=True,
                mr_size=6.0,
            ),
            device,
        )

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/integrated.py:354: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'tensorflow_LAFOrienter' object has no attribute 'angle_detector'") raised in repr()] tensorflow_LAFOrienter object at 0x7f4288459a80>, args = (19,), kwargs = {}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'tensorflow_LAFOrienter' object has no attribute 'angle_detector'") raised in repr()] tensorflow_LAFOrienter object at 0x7f4288459a80>, patch_size = 19, num_angular_bins = 36
angle_detector = None

    @tensorflow_store_config_info
    def __init__(self, patch_size=32, num_angular_bins=36, angle_detector=None):
        self.super___init__(
            patch_size=patch_size,
            num_angular_bins=num_angular_bins,
            angle_detector=angle_detector,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        self.patch_size = patch_size
        self.num_ang_bins = num_angular_bins
        self.angle_detector: typing.Any
        if angle_detector is None:
>           self.angle_detector = tensorflow_PatchDominantGradientOrientation(
                self.patch_size, self.num_ang_bins
            )

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/orientation.py:387: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_PatchDominantGradientOrientation(patch_size=19, num_ang_bins=36, eps=1e-08), args = (19, 36), kwargs = {}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_PatchDominantGradientOrientation(patch_size=19, num_ang_bins=36, eps=1e-08), patch_size = 19, num_angular_bins = 36, eps = 1e-08

    @tensorflow_store_config_info
    def __init__(self, patch_size=32, num_angular_bins=36, eps=1e-08):
        from ..filters.sobel import tensorflow_SpatialGradient
        from ...torch.nn.modules.conv import tensorflow_Conv1d
        from ...ivy.functional.backends.tensorflow.general import tensorflow_set_item
        from ..filters.kernels import tensorflow_get_gaussian_discrete_kernel1d
        from ..filters.kernels import tensorflow_get_gaussian_kernel2d
    
        self.super___init__(
            patch_size=patch_size,
            num_angular_bins=num_angular_bins,
            eps=eps,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        self.patch_size = patch_size
        self.num_ang_bins = num_angular_bins
        self.gradient = tensorflow_SpatialGradient("sobel", 1)
        self.eps = eps
        self.angular_smooth = tensorflow_Conv1d(
            1, 1, kernel_size=5, padding=2, bias=False, padding_mode="circular"
        )
>       self.angular_smooth.weight = tensorflow_set_item(
            self.angular_smooth.weight,
            slice(None, None, None),
            tensorflow_get_gaussian_discrete_kernel1d(5, 1.6),
        )

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/orientation.py:178: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

inp = <tf.Variable 'Variable:0' shape=(5, 1, 1) dtype=float32, numpy=
array([[[-0.9409752 ]],

       [[ 0.7687769 ]],

       [[ 0.96980596]],

       [[-0.6349077 ]],

       [[-0.8625691 ]]], dtype=float32)>
query = slice(None, None, None), val = <tf.Tensor: shape=(1, 5), dtype=float32, numpy=
array([[0.1190625 , 0.2311236 , 0.29962778, 0.2311236 , 0.1190625 ]],
      dtype=float32)>, kwargs = {}

    @functools.wraps(fn)
    def wrapper(inp, query, val, **kwargs):
        try:
            inp.__setitem__(query, val)
            res = inp
        except IndexError:
            raise
        except Exception:
>           res = fn(inp, query, val, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:238: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (<tf.Variable 'Variable:0' shape=(5, 1, 1) dtype=float32, numpy=
array([[[-0.9409752 ]],

       [[ 0.7687769 ]],

   ... 5), dtype=float32, numpy=
array([[0.1190625 , 0.2311236 , 0.29962778, 0.2311236 , 0.1190625 ]],
      dtype=float32)>)
kwargs = {}, handle_mixed_in_backend = True

    @functools.wraps(fn)
    def _handle_partial_mixed_function(*args, **kwargs):
        handle_mixed_in_backend = False
        if not hasattr(fn, "partial_mixed_handler"):
            handle_mixed_in_backend = True
        else:
            compos = getattr(fn, "compos")
            condition = getattr(fn, "partial_mixed_handler")
        if handle_mixed_in_backend or condition(*args, **kwargs):
>           return fn(*args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/func_wrapper.py:173: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[-0.9409752 ]],

       [[ 0.7687769 ]],

       [[ 0.96980596]],

       [[-0.6349077 ]],

       [[-0.8625691 ]]], dtype=float32), query = slice(None, None, None)
val = array([[0.1190625 , 0.2311236 , 0.29962778, 0.2311236 , 0.1190625 ]],
      dtype=float32)

    @tensorflow_handle_set_item
    @tensorflow_handle_partial_mixed_function
    def tensorflow_set_item(
        x: Union[tensorflow.Tensor, tensorflow.Variable],
        query: Union[tensorflow.Tensor, tensorflow.Variable, Tuple],
        val: Union[tensorflow.Tensor, tensorflow.Variable],
        /,
        *,
        copy: Optional[bool] = False,
    ):
        if tensorflow.is_tensor(x):
            x = x.numpy()
        if tensorflow.is_tensor(val):
            val = val.numpy()
        if isinstance(query, (tensorflow.Tensor, tensorflow.Variable)):
            query = query.numpy()
        elif isinstance(query, tuple):
            query = tuple(
                q.numpy() if isinstance(q, (tensorflow.Tensor, tensorflow.Variable)) else q
                for q in query
            )
>       x[query] = val
E       ValueError: could not broadcast input array from shape (1,5) into shape (5,1,1)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/backends/tensorflow/general.py:109: ValueError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.SIFTFeatureScaleSpace
_____________________________________________________________________________ test_GFTTAffNetHardNet[tensorflow-s2s-False] _____________________________________________________________________________

inp = <tf.Variable 'Variable:0' shape=(5, 1, 1) dtype=float32, numpy=
array([[[ 0.93479824]],

       [[ 0.99527645]],

       [[ 0.10666323]],

       [[-0.64859843]],

       [[ 0.9379387 ]]], dtype=float32)>
query = slice(None, None, None), val = <tf.Tensor: shape=(1, 5), dtype=float32, numpy=
array([[0.1190625 , 0.2311236 , 0.29962778, 0.2311236 , 0.1190625 ]],
      dtype=float32)>, kwargs = {}

    @functools.wraps(fn)
    def wrapper(inp, query, val, **kwargs):
        try:
>           inp.__setitem__(query, val)
E           AttributeError: 'ResourceVariable' object has no attribute '__setitem__'. Did you mean: '__getitem__'?

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:233: AttributeError

During handling of the above exception, another exception occurred:

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_GFTTAffNetHardNet(target_framework, mode, backend_compile):
        print("kornia.feature.GFTTAffNetHardNet")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledGFTTAffNetHardNet = ivy.transpile(kornia.feature.GFTTAffNetHardNet, source="torch", target=target_framework)
    
        x = torch.rand(1, 1, 256, 256)
        transpiled_x = _nest_torch_tensor_to_new_framework(x, target_framework)
    
        model = kornia.feature.GFTTAffNetHardNet(num_features=10)
        torch_out = model(x)
    
>       transpiled_model = TranspiledGFTTAffNetHardNet(num_features=10)

kornia/test_feature4.py:83: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_GFTTAffNetHardNet object at 0x7f42883f2980>, num_features = 10, upright = False, device = 'cpu'
config = {'nms_size': 15, 'pyramid_levels': 4, 's_mult': 22.0, 'scale_factor_levels': 1.4142135623730951, ...}

    def __init__(
        self,
        num_features=8000,
        upright=False,
        device=tensorflow_device_frnt("cpu"),
        config=tensorflow_get_default_detector_config(),
    ):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_to_frnt_
        from .scale_space_detector import tensorflow_MultiResolutionDetector
        from .responses import tensorflow_CornerGFTT
        from .orientation import tensorflow_PassLAF
        from .orientation import tensorflow_LAFOrienter
        from .affine_shape import tensorflow_LAFAffNetShapeEstimator
    
        detector = tensorflow_to_frnt_(
            tensorflow_MultiResolutionDetector(
                tensorflow_CornerGFTT(),
                num_features,
                config,
                ori_module=tensorflow_PassLAF()
                if upright
>               else tensorflow_LAFOrienter(19),
                aff_module=tensorflow_LAFAffNetShapeEstimator(True).eval(),
            ),
            device,
        )

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/integrated.py:351: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'tensorflow_LAFOrienter' object has no attribute 'angle_detector'") raised in repr()] tensorflow_LAFOrienter object at 0x7f42883f3940>, args = (19,), kwargs = {}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'tensorflow_LAFOrienter' object has no attribute 'angle_detector'") raised in repr()] tensorflow_LAFOrienter object at 0x7f42883f3940>, patch_size = 19, num_angular_bins = 36
angle_detector = None

    @tensorflow_store_config_info
    def __init__(self, patch_size=32, num_angular_bins=36, angle_detector=None):
        self.super___init__(
            patch_size=patch_size,
            num_angular_bins=num_angular_bins,
            angle_detector=angle_detector,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        self.patch_size = patch_size
        self.num_ang_bins = num_angular_bins
        self.angle_detector: typing.Any
        if angle_detector is None:
>           self.angle_detector = tensorflow_PatchDominantGradientOrientation(
                self.patch_size, self.num_ang_bins
            )

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/orientation.py:387: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_PatchDominantGradientOrientation(patch_size=19, num_ang_bins=36, eps=1e-08), args = (19, 36), kwargs = {}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_PatchDominantGradientOrientation(patch_size=19, num_ang_bins=36, eps=1e-08), patch_size = 19, num_angular_bins = 36, eps = 1e-08

    @tensorflow_store_config_info
    def __init__(self, patch_size=32, num_angular_bins=36, eps=1e-08):
        from ..filters.sobel import tensorflow_SpatialGradient
        from ...torch.nn.modules.conv import tensorflow_Conv1d
        from ...ivy.functional.backends.tensorflow.general import tensorflow_set_item
        from ..filters.kernels import tensorflow_get_gaussian_discrete_kernel1d
        from ..filters.kernels import tensorflow_get_gaussian_kernel2d
    
        self.super___init__(
            patch_size=patch_size,
            num_angular_bins=num_angular_bins,
            eps=eps,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        self.patch_size = patch_size
        self.num_ang_bins = num_angular_bins
        self.gradient = tensorflow_SpatialGradient("sobel", 1)
        self.eps = eps
        self.angular_smooth = tensorflow_Conv1d(
            1, 1, kernel_size=5, padding=2, bias=False, padding_mode="circular"
        )
>       self.angular_smooth.weight = tensorflow_set_item(
            self.angular_smooth.weight,
            slice(None, None, None),
            tensorflow_get_gaussian_discrete_kernel1d(5, 1.6),
        )

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/orientation.py:178: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

inp = <tf.Variable 'Variable:0' shape=(5, 1, 1) dtype=float32, numpy=
array([[[ 0.93479824]],

       [[ 0.99527645]],

       [[ 0.10666323]],

       [[-0.64859843]],

       [[ 0.9379387 ]]], dtype=float32)>
query = slice(None, None, None), val = <tf.Tensor: shape=(1, 5), dtype=float32, numpy=
array([[0.1190625 , 0.2311236 , 0.29962778, 0.2311236 , 0.1190625 ]],
      dtype=float32)>, kwargs = {}

    @functools.wraps(fn)
    def wrapper(inp, query, val, **kwargs):
        try:
            inp.__setitem__(query, val)
            res = inp
        except IndexError:
            raise
        except Exception:
>           res = fn(inp, query, val, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:238: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (<tf.Variable 'Variable:0' shape=(5, 1, 1) dtype=float32, numpy=
array([[[ 0.93479824]],

       [[ 0.99527645]],

   ... 5), dtype=float32, numpy=
array([[0.1190625 , 0.2311236 , 0.29962778, 0.2311236 , 0.1190625 ]],
      dtype=float32)>)
kwargs = {}, handle_mixed_in_backend = True

    @functools.wraps(fn)
    def _handle_partial_mixed_function(*args, **kwargs):
        handle_mixed_in_backend = False
        if not hasattr(fn, "partial_mixed_handler"):
            handle_mixed_in_backend = True
        else:
            compos = getattr(fn, "compos")
            condition = getattr(fn, "partial_mixed_handler")
        if handle_mixed_in_backend or condition(*args, **kwargs):
>           return fn(*args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/func_wrapper.py:173: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[ 0.93479824]],

       [[ 0.99527645]],

       [[ 0.10666323]],

       [[-0.64859843]],

       [[ 0.9379387 ]]], dtype=float32), query = slice(None, None, None)
val = array([[0.1190625 , 0.2311236 , 0.29962778, 0.2311236 , 0.1190625 ]],
      dtype=float32)

    @tensorflow_handle_set_item
    @tensorflow_handle_partial_mixed_function
    def tensorflow_set_item(
        x: Union[tensorflow.Tensor, tensorflow.Variable],
        query: Union[tensorflow.Tensor, tensorflow.Variable, Tuple],
        val: Union[tensorflow.Tensor, tensorflow.Variable],
        /,
        *,
        copy: Optional[bool] = False,
    ):
        if tensorflow.is_tensor(x):
            x = x.numpy()
        if tensorflow.is_tensor(val):
            val = val.numpy()
        if isinstance(query, (tensorflow.Tensor, tensorflow.Variable)):
            query = query.numpy()
        elif isinstance(query, tuple):
            query = tuple(
                q.numpy() if isinstance(q, (tensorflow.Tensor, tensorflow.Variable)) else q
                for q in query
            )
>       x[query] = val
E       ValueError: could not broadcast input array from shape (1,5) into shape (5,1,1)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/backends/tensorflow/general.py:109: ValueError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.GFTTAffNetHardNet
----------------------------------------------------------------------------------------- Captured stderr call -----------------------------------------------------------------------------------------
Downloading: "https://github.com/ducha-aiki/affnet/raw/master/pretrained/AffNet.pth" to /root/.cache/torch/hub/checkpoints/AffNet.pth

  0%|          | 0.00/332k [00:00<?, ?B/s]
100%|| 332k/332k [00:00<00:00, 48.4MB/s]
Downloading: "https://github.com/DagnyT/hardnet/raw/master/pretrained/train_liberty_with_aug/checkpoint_liberty_with_aug.pth" to /root/.cache/torch/hub/checkpoints/checkpoint_liberty_with_aug.pth

  0%|          | 0.00/5.10M [00:00<?, ?B/s]
100%|| 5.10M/5.10M [00:00<00:00, 262MB/s]
____________________________________________________________________________ test_KeyNetAffNetHardNet[tensorflow-s2s-False] ____________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_KeyNetAffNetHardNet(target_framework, mode, backend_compile):
        print("kornia.feature.KeyNetAffNetHardNet")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledKeyNetAffNetHardNet = ivy.transpile(kornia.feature.KeyNetAffNetHardNet, source="torch", target=target_framework)
    
        x = torch.rand(1, 1, 256, 256)
        transpiled_x = _nest_torch_tensor_to_new_framework(x, target_framework)
    
        model = kornia.feature.KeyNetAffNetHardNet(num_features=10)
        torch_out = model(x)
    
        transpiled_model = TranspiledKeyNetAffNetHardNet(num_features=10)
        if target_framework == "tensorflow":
            # build the layers
            transpiled_model(transpiled_x)
    
        ivy.sync_models(model, transpiled_model)
    
        transpiled_out = transpiled_model(transpiled_x)
    
>       _to_numpy_and_allclose(torch_out, transpiled_out)

kornia/test_feature4.py:118: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

torch_x = (tensor([[[[ 13.3534,  -7.1295,  61.5249],
          [  7.5840,  14.0774, 104.6630]],

         [[ -3.7339,  12.3692, ...76,  0.0835],
         [ 0.0355,  0.0282, -0.1590,  ...,  0.0649,  0.0581,  0.0062]]],
       grad_fn=<ViewBackward0>))
transpiled_x = (<tf.Tensor: shape=(1, 10, 2, 3), dtype=float32, numpy=
array([[[[ 13.353235  ,  -7.129807  ,  61.524864  ],
         ...       [ 0.03564163,  0.0279189 , -0.15865853, ...,  0.06469215,
          0.05856277,  0.00564649]]], dtype=float32)>)
tolerance = 0.001

    def _to_numpy_and_allclose(torch_x, transpiled_x, tolerance=1e-3):
        orig_data = _nest_array_to_numpy(torch_x)
        transpiled_data = _nest_array_to_numpy(transpiled_x)
>       _check_allclose(orig_data, transpiled_data, tolerance=tolerance)

helpers.py:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = (array([[[[ 13.353409 ,  -7.1294894,  61.524864 ],
         [  7.584035 ,  14.077409 , 104.66299  ]],

        [[ -3.7...        [ 0.03554754,  0.02815038, -0.15904142, ...,  0.06493687,
          0.05808785,  0.00620071]]], dtype=float32))
y = (array([[[[ 13.353235  ,  -7.129807  ,  61.524864  ],
         [  7.5843763 ,  14.07723   , 104.66299   ]],

        [...        [ 0.03564163,  0.0279189 , -0.15865853, ...,  0.06469215,
          0.05856277,  0.00564649]]], dtype=float32))
tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
            assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
            return
    
        if isinstance(x, (list, set, tuple)):
>           all([
                _check_allclose(element_x, element_y, tolerance=tolerance) for element_x, element_y in zip(x, y)
            ])

helpers.py:30: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

.0 = <zip object at 0x7f42a1a86580>

    all([
>       _check_allclose(element_x, element_y, tolerance=tolerance) for element_x, element_y in zip(x, y)
    ])

helpers.py:31: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[[ 13.353409 ,  -7.1294894,  61.524864 ],
         [  7.584035 ,  14.077409 , 104.66299  ]],

        [[ -3.73...

        [[ 14.965198 , -11.321778 ,  41.       ],
         [ 16.996504 ,  19.483162 , 123.       ]]]], dtype=float32)
y = array([[[[ 13.353235  ,  -7.129807  ,  61.524864  ],
         [  7.5843763 ,  14.07723   , 104.66299   ]],

        [[...    [[ 14.9614    , -11.3268585 ,  41.        ],
         [ 17.003038  ,  19.477388  , 123.        ]]]], dtype=float32)
tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
>           assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
E           AssertionError: numpy array values are not all close

helpers.py:26: AssertionError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.KeyNetAffNetHardNet
All parameters and buffers are now synced!
----------------------------------------------------------------------------------------- Captured stderr call -----------------------------------------------------------------------------------------
Downloading: "https://github.com/ducha-aiki/affnet/raw/master/pretrained/OriNet.pth" to /root/.cache/torch/hub/checkpoints/OriNet.pth

  0%|          | 0.00/316k [00:00<?, ?B/s]
100%|| 316k/316k [00:00<00:00, 55.5MB/s]
Downloading: "https://github.com/axelBarroso/Key.Net-Pytorch/raw/main/model/weights/keynet_pytorch.pth" to /root/.cache/torch/hub/checkpoints/keynet_pytorch.pth

  0%|          | 0.00/78.0k [00:00<?, ?B/s]
100%|| 78.0k/78.0k [00:00<00:00, 15.2MB/s]
____________________________________________________________________________ test_LocalFeatureMatcher[tensorflow-s2s-False] ____________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_LocalFeatureMatcher(target_framework, mode, backend_compile):
        print("kornia.feature.LocalFeatureMatcher")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledGFTTAffNetHardNet = ivy.transpile(kornia.feature.GFTTAffNetHardNet, source="torch", target=target_framework)
        TranspiledDescriptorMatcher = ivy.transpile(kornia.feature.DescriptorMatcher, source="torch", target=target_framework)
        TranspiledLocalFeatureMatcher = ivy.transpile(kornia.feature.LocalFeatureMatcher, source="torch", target=target_framework)
    
        data = {
            "image0": torch.rand(1, 1, 320, 200),
            "image1": torch.rand(1, 1, 128, 128),
        }
        transpiled_data = _nest_torch_tensor_to_new_framework(data, target_framework)
    
        torch_local_feature = kornia.feature.GFTTAffNetHardNet(10)
        torch_matcher = kornia.feature.DescriptorMatcher('snn', 0.8)
        model = kornia.feature.LocalFeatureMatcher(torch_local_feature, torch_matcher)
>       torch_out = model(data)

kornia/test_feature4.py:225: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalFeatureMatcher(
  (local_feature): GFTTAffNetHardNet(
    (detector): MultiResolutionDetector(
      (model): Cor...ck_running_stats=True)
      )
    ), patch_size=32, grayscale_descriptor='True)
  )
  (matcher): DescriptorMatcher()
)
args = ({'image0': <tf.Tensor: shape=(1, 1, 320, 200), dtype=float32, numpy=
array([[[[0.72395253, 0.07796919, 0.03607643, .....         [0.09701228, 0.18770742, 0.107638  , ..., 0.53307295,
          0.39619124, 0.59942126]]]], dtype=float32)>},)
kwargs = {}

    def _wrapped_call_impl(self, *args, **kwargs):
        if self._compiled_call_impl is not None:
            return self._compiled_call_impl(*args, **kwargs)  # type: ignore[misc]
        else:
>           return self._call_impl(*args, **kwargs)

/opt/fw/torch/torch/nn/modules/module.py:1553: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalFeatureMatcher(
  (local_feature): GFTTAffNetHardNet(
    (detector): MultiResolutionDetector(
      (model): Cor...ck_running_stats=True)
      )
    ), patch_size=32, grayscale_descriptor='True)
  )
  (matcher): DescriptorMatcher()
)
args = ({'image0': <tf.Tensor: shape=(1, 1, 320, 200), dtype=float32, numpy=
array([[[[0.72395253, 0.07796919, 0.03607643, .....         [0.09701228, 0.18770742, 0.107638  , ..., 0.53307295,
          0.39619124, 0.59942126]]]], dtype=float32)>},)
kwargs = {}
forward_call = <bound method LocalFeatureMatcher.forward of LocalFeatureMatcher(
  (local_feature): GFTTAffNetHardNet(
    (detector)...k_running_stats=True)
      )
    ), patch_size=32, grayscale_descriptor='True)
  )
  (matcher): DescriptorMatcher()
)>

    def _call_impl(self, *args, **kwargs):
        forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)
        # If we don't have any hooks, we want to skip the rest of the logic in
        # this function, and just call forward.
        if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks
                or _global_backward_pre_hooks or _global_backward_hooks
                or _global_forward_hooks or _global_forward_pre_hooks):
>           return forward_call(*args, **kwargs)

/opt/fw/torch/torch/nn/modules/module.py:1562: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalFeatureMatcher(
  (local_feature): GFTTAffNetHardNet(
    (detector): MultiResolutionDetector(
      (model): Cor...ck_running_stats=True)
      )
    ), patch_size=32, grayscale_descriptor='True)
  )
  (matcher): DescriptorMatcher()
)
data = {'image0': <tf.Tensor: shape=(1, 1, 320, 200), dtype=float32, numpy=
array([[[[0.72395253, 0.07796919, 0.03607643, ......,
         [0.09701228, 0.18770742, 0.107638  , ..., 0.53307295,
          0.39619124, 0.59942126]]]], dtype=float32)>}

    def forward(self, data: Dict[str, Tensor]) -> Dict[str, Tensor]:
        """
        Args:
            data: dictionary containing the input data in the following format:
    
        Keyword Args:
            image0: left image with shape :math:`(N, 1, H1, W1)`.
            image1: right image with shape :math:`(N, 1, H2, W2)`.
            mask0 (optional): left image mask. '0' indicates a padded position :math:`(N, H1, W1)`.
            mask1 (optional): right image mask. '0' indicates a padded position :math:`(N, H2, W2)`.
    
        Returns:
            - ``keypoints0``, matching keypoints from image0 :math:`(NC, 2)`.
            - ``keypoints1``, matching keypoints from image1 :math:`(NC, 2)`.
            - ``confidence``, confidence score [0, 1] :math:`(NC)`.
            - ``lafs0``, matching LAFs from image0 :math:`(1, NC, 2, 3)`.
            - ``lafs1``, matching LAFs from image1 :math:`(1, NC, 2, 3)`.
            - ``batch_indexes``, batch indexes for the keypoints and lafs :math:`(NC)`.
        """
        num_image_pairs: int = data["image0"].shape[0]
    
        if ("lafs0" not in data.keys()) or ("descriptors0" not in data.keys()):
            # One can supply pre-extracted local features
>           feats_dict0: Dict[str, Tensor] = self.extract_features(data["image0"])

/opt/miniconda/envs/multienv/lib/python3.10/site-packages/kornia/feature/integrated.py:349: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalFeatureMatcher(
  (local_feature): GFTTAffNetHardNet(
    (detector): MultiResolutionDetector(
      (model): Cor...ck_running_stats=True)
      )
    ), patch_size=32, grayscale_descriptor='True)
  )
  (matcher): DescriptorMatcher()
)
image = <tf.Tensor: shape=(1, 1, 320, 200), dtype=float32, numpy=
array([[[[0.72395253, 0.07796919, 0.03607643, ..., 0.0982551...],
         [0.6750302 , 0.7294554 , 0.20845097, ..., 0.64720136,
          0.10116732, 0.7279768 ]]]], dtype=float32)>
mask = None

    def extract_features(self, image: Tensor, mask: Optional[Tensor] = None) -> Dict[str, Tensor]:
        """Function for feature extraction from simple image."""
>       lafs0, resps0, descs0 = self.local_feature(image, mask)

/opt/miniconda/envs/multienv/lib/python3.10/site-packages/kornia/feature/integrated.py:313: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = GFTTAffNetHardNet(
  (detector): MultiResolutionDetector(
    (model): CornerGFTT(grads_mode=sobel)
    (nms): NonMaxi...ps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    )
  ), patch_size=32, grayscale_descriptor='True)
)
args = (<tf.Tensor: shape=(1, 1, 320, 200), dtype=float32, numpy=
array([[[[0.72395253, 0.07796919, 0.03607643, ..., 0.098255...     [0.6750302 , 0.7294554 , 0.20845097, ..., 0.64720136,
          0.10116732, 0.7279768 ]]]], dtype=float32)>, None)
kwargs = {}

    def _wrapped_call_impl(self, *args, **kwargs):
        if self._compiled_call_impl is not None:
            return self._compiled_call_impl(*args, **kwargs)  # type: ignore[misc]
        else:
>           return self._call_impl(*args, **kwargs)

/opt/fw/torch/torch/nn/modules/module.py:1553: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = GFTTAffNetHardNet(
  (detector): MultiResolutionDetector(
    (model): CornerGFTT(grads_mode=sobel)
    (nms): NonMaxi...ps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    )
  ), patch_size=32, grayscale_descriptor='True)
)
args = (<tf.Tensor: shape=(1, 1, 320, 200), dtype=float32, numpy=
array([[[[0.72395253, 0.07796919, 0.03607643, ..., 0.098255...     [0.6750302 , 0.7294554 , 0.20845097, ..., 0.64720136,
          0.10116732, 0.7279768 ]]]], dtype=float32)>, None)
kwargs = {}
forward_call = <bound method LocalFeature.forward of GFTTAffNetHardNet(
  (detector): MultiResolutionDetector(
    (model): CornerGFT...s=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    )
  ), patch_size=32, grayscale_descriptor='True)
)>

    def _call_impl(self, *args, **kwargs):
        forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)
        # If we don't have any hooks, we want to skip the rest of the logic in
        # this function, and just call forward.
        if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks
                or _global_backward_pre_hooks or _global_backward_hooks
                or _global_forward_hooks or _global_forward_pre_hooks):
>           return forward_call(*args, **kwargs)

/opt/fw/torch/torch/nn/modules/module.py:1562: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = GFTTAffNetHardNet(
  (detector): MultiResolutionDetector(
    (model): CornerGFTT(grads_mode=sobel)
    (nms): NonMaxi...ps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    )
  ), patch_size=32, grayscale_descriptor='True)
)
img = <tf.Tensor: shape=(1, 1, 320, 200), dtype=float32, numpy=
array([[[[0.72395253, 0.07796919, 0.03607643, ..., 0.0982551...],
         [0.6750302 , 0.7294554 , 0.20845097, ..., 0.64720136,
          0.10116732, 0.7279768 ]]]], dtype=float32)>
mask = None

    def forward(self, img: Tensor, mask: Optional[Tensor] = None) -> Tuple[Tensor, Tensor, Tensor]:
        """
        Args:
            img: image to extract features with shape :math:`(B,C,H,W)`.
            mask: a mask with weights where to apply the response function.
                The shape must be the same as the input image.
    
        Returns:
            - Detected local affine frames with shape :math:`(B,N,2,3)`.
            - Response function values for corresponding lafs with shape :math:`(B,N,1)`.
            - Local descriptors of shape :math:`(B,N,D)` where :math:`D` is descriptor size.
        """
>       lafs, responses = self.detector(img, mask)

/opt/miniconda/envs/multienv/lib/python3.10/site-packages/kornia/feature/integrated.py:139: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = MultiResolutionDetector(
  (model): CornerGFTT(grads_mode=sobel)
  (nms): NonMaximaSuppression2d()
  (ori): LAFOriente...d(64, 3, kernel_size=(8, 8), stride=(1, 1))
      (20): Tanh()
      (21): AdaptiveAvgPool2d(output_size=1)
    )
  )
)
args = (<tf.Tensor: shape=(1, 1, 320, 200), dtype=float32, numpy=
array([[[[0.72395253, 0.07796919, 0.03607643, ..., 0.098255...     [0.6750302 , 0.7294554 , 0.20845097, ..., 0.64720136,
          0.10116732, 0.7279768 ]]]], dtype=float32)>, None)
kwargs = {}

    def _wrapped_call_impl(self, *args, **kwargs):
        if self._compiled_call_impl is not None:
            return self._compiled_call_impl(*args, **kwargs)  # type: ignore[misc]
        else:
>           return self._call_impl(*args, **kwargs)

/opt/fw/torch/torch/nn/modules/module.py:1553: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = MultiResolutionDetector(
  (model): CornerGFTT(grads_mode=sobel)
  (nms): NonMaximaSuppression2d()
  (ori): LAFOriente...d(64, 3, kernel_size=(8, 8), stride=(1, 1))
      (20): Tanh()
      (21): AdaptiveAvgPool2d(output_size=1)
    )
  )
)
args = (<tf.Tensor: shape=(1, 1, 320, 200), dtype=float32, numpy=
array([[[[0.72395253, 0.07796919, 0.03607643, ..., 0.098255...     [0.6750302 , 0.7294554 , 0.20845097, ..., 0.64720136,
          0.10116732, 0.7279768 ]]]], dtype=float32)>, None)
kwargs = {}
forward_call = <bound method MultiResolutionDetector.forward of MultiResolutionDetector(
  (model): CornerGFTT(grads_mode=sobel)
  (n...(64, 3, kernel_size=(8, 8), stride=(1, 1))
      (20): Tanh()
      (21): AdaptiveAvgPool2d(output_size=1)
    )
  )
)>

    def _call_impl(self, *args, **kwargs):
        forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)
        # If we don't have any hooks, we want to skip the rest of the logic in
        # this function, and just call forward.
        if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks
                or _global_backward_pre_hooks or _global_backward_hooks
                or _global_forward_hooks or _global_forward_pre_hooks):
>           return forward_call(*args, **kwargs)

/opt/fw/torch/torch/nn/modules/module.py:1562: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = MultiResolutionDetector(
  (model): CornerGFTT(grads_mode=sobel)
  (nms): NonMaximaSuppression2d()
  (ori): LAFOriente...d(64, 3, kernel_size=(8, 8), stride=(1, 1))
      (20): Tanh()
      (21): AdaptiveAvgPool2d(output_size=1)
    )
  )
)
img = <tf.Tensor: shape=(1, 1, 320, 200), dtype=float32, numpy=
array([[[[0.72395253, 0.07796919, 0.03607643, ..., 0.0982551...],
         [0.6750302 , 0.7294554 , 0.20845097, ..., 0.64720136,
          0.10116732, 0.7279768 ]]]], dtype=float32)>
mask = None

    def forward(self, img: Tensor, mask: Optional[Tensor] = None) -> Tuple[Tensor, Tensor]:
        """Three stage local feature detection. First the location and scale of interest points are determined by
        detect function. Then affine shape and orientation.
    
        Args:
            img: image to extract features with shape [1xCxHxW]. KeyNetDetector does not support batch processing,
        because the number of detections is different on each image.
            mask: a mask with weights where to apply the response function. The shape must be the same as
              the input image.
    
        Returns:
            lafs: shape [1xNx2x3]. Detected local affine frames.
            responses: shape [1xNx1]. Response function values for corresponding lafs
        """
        KORNIA_CHECK_SHAPE(img, ["1", "C", "H", "W"])
>       responses, lafs = self.detect(img, mask)

/opt/miniconda/envs/multienv/lib/python3.10/site-packages/kornia/feature/scale_space_detector.py:392: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = MultiResolutionDetector(
  (model): CornerGFTT(grads_mode=sobel)
  (nms): NonMaximaSuppression2d()
  (ori): LAFOriente...d(64, 3, kernel_size=(8, 8), stride=(1, 1))
      (20): Tanh()
      (21): AdaptiveAvgPool2d(output_size=1)
    )
  )
)
img = <tf.Tensor: shape=(1, 1, 320, 200), dtype=float32, numpy=
array([[[[0.72395253, 0.07796919, 0.03607643, ..., 0.0982551...],
         [0.6750302 , 0.7294554 , 0.20845097, ..., 0.64720136,
          0.10116732, 0.7279768 ]]]], dtype=float32)>
mask = None

    def detect(self, img: Tensor, mask: Optional[Tensor] = None) -> Tuple[Tensor, Tensor]:
        # Compute points per level
        num_features_per_level: List[float] = []
        tmp = 0.0
        factor_points = self.scale_factor_levels**2
        levels = self.num_pyramid_levels + self.num_upscale_levels + 1
        for idx_level in range(levels):
            tmp += factor_points ** (-1 * (idx_level - self.num_upscale_levels))
            nf = self.num_features * factor_points ** (-1 * (idx_level - self.num_upscale_levels))
            num_features_per_level.append(nf)
        num_features_per_level = [int(x / tmp) for x in num_features_per_level]
    
        _, _, h, w = img.shape
        img_up = img
        cur_img = img
        all_responses: List[Tensor] = []
        all_lafs: List[Tensor] = []
        # Extract features from the upper levels
        for idx_level in range(self.num_upscale_levels):
            nf = num_features_per_level[len(num_features_per_level) - self.num_pyramid_levels - 1 - (idx_level + 1)]
            num_points_level = int(nf)
    
            # Resize input image
            up_factor = self.scale_factor_levels ** (1 + idx_level)
            nh, nw = int(h * up_factor), int(w * up_factor)
            up_factor_kpts = (float(w) / float(nw), float(h) / float(nh))
>           img_up = resize(img_up, (nh, nw), interpolation="bilinear", align_corners=False)

/opt/miniconda/envs/multienv/lib/python3.10/site-packages/kornia/feature/scale_space_detector.py:345: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = <tf.Tensor: shape=(1, 1, 320, 200), dtype=float32, numpy=
array([[[[0.72395253, 0.07796919, 0.03607643, ..., 0.0982551...],
         [0.6750302 , 0.7294554 , 0.20845097, ..., 0.64720136,
          0.10116732, 0.7279768 ]]]], dtype=float32)>
args = ((452, 282),), kwargs = {'align_corners': False, 'interpolation': 'bilinear'}

    @wraps(f)
    def _wrapper(input: Tensor, *args: Any, **kwargs: Any) -> Tensor:
        if not isinstance(input, Tensor):
>           raise TypeError(f"Input input type is not a Tensor. Got {type(input)}")
E           TypeError: Input input type is not a Tensor. Got <class 'tensorflow.python.framework.ops.EagerTensor'>

/opt/miniconda/envs/multienv/lib/python3.10/site-packages/kornia/utils/image.py:224: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.LocalFeatureMatcher
_____________________________________________________________________________ test_LightGlueMatcher[tensorflow-s2s-False] ______________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_LightGlueMatcher(target_framework, mode, backend_compile):
        print("kornia.feature.LightGlueMatcher")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledLightGlueMatcher = ivy.transpile(kornia.feature.LightGlueMatcher, source="torch", target=target_framework)
    
        torch_args = (
            torch.rand(2, 128),
            torch.rand(5, 128),
            torch.rand(1, 2, 2, 3),
            torch.rand(1, 5, 2, 3),
        )
        transpiled_args = _nest_torch_tensor_to_new_framework(torch_args, target_framework)
    
        model = kornia.feature.LightGlueMatcher('disk')
        torch_out = model(*torch_args)
    
>       transpiled_model = TranspiledLightGlueMatcher('disk')

kornia/test_feature4.py:260: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_LightGlueMatcher(), feature_name = 'disk', params = {}

    def __init__(self, feature_name="disk", params={}):
        from .lightglue import tensorflow_LightGlue
    
        feature_name_: typing.Any = feature_name.lower()
        super().__init__(feature_name_)
        self.feature_name = feature_name_
        self.params = params
>       self.matcher = tensorflow_LightGlue(self.feature_name, **params)

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/integrated.py:54: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_LightGlue(
  (input_proj): KerasDense()
  (posenc): tensorflow_LearnableFourierPositionalEncoding(
    (Wr): KerasDense()
  )
), args = ('disk',), kwargs = {}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_LightGlue(
  (input_proj): KerasDense()
  (posenc): tensorflow_LearnableFourierPositionalEncoding(
    (Wr): KerasDense()
  )
), features = 'disk', conf_ = {}
tensorflow_KORNIA_CHECK = <function tensorflow_KORNIA_CHECK at 0x7f42887c51b0>, tensorflow_get_item = <function tensorflow_get_item at 0x7f428876e9e0>
tensorflow_Identity = <class 'ivy_transpiled_outputs.tensorflow_outputs.torch.nn.modules.linear.tensorflow_Identity'>
tensorflow_load_state_dict_from_url_frnt = <function tensorflow_load_state_dict_from_url_frnt at 0x7f42a21e84c0>, tensorflow_load_frnt = <function tensorflow_load_frnt at 0x7f428871c1f0>
ModuleList = <class 'ivy_transpiled_outputs.tensorflow_outputs.torch.nn.modules.container.tensorflow_ModuleList'>
KerasDense = <class 'ivy_transpiled_outputs.tensorflow_outputs.tensorflow__stateful_layers.KerasDense'>

    @tensorflow_store_config_info
    def __init__(self, features="superpoint", **conf_):
        from ..core.check import tensorflow_KORNIA_CHECK
        from ...ivy.functional.backends.tensorflow.general import tensorflow_get_item
        from ...torch.nn.modules.linear import tensorflow_Identity
        from ...ivy.functional.frontends.torch.hub.hub import (
            tensorflow_load_state_dict_from_url_frnt,
        )
        from ...ivy.functional.frontends.torch.serialization.serialization import (
            tensorflow_load_frnt,
        )
        from ..core._backend import ModuleList
        from ...tensorflow__stateful_layers import KerasDense
    
        self.super___init__(
            features=features,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        self.conf = conf = SimpleNamespace(**{**self.default_conf, **conf_})
        if features is not None:
            tensorflow_KORNIA_CHECK(
                features in list(self.features.keys()), "Features keys are wrong"
            )
            for k, v in tensorflow_get_item(self.features, features).items():
                setattr(conf, k, v)
        tensorflow_KORNIA_CHECK(not (self.conf.add_scale_ori and self.conf.add_laf))
        if conf.input_dim != conf.descriptor_dim:
            self.input_proj = KerasDense(
                in_features=conf.input_dim, units=conf.descriptor_dim, use_bias=True
            )
        else:
            self.input_proj = tensorflow_Identity()
        head_dim = conf.descriptor_dim // conf.num_heads
        self.posenc = tensorflow_LearnableFourierPositionalEncoding(
            2 + 2 * conf.add_scale_ori + 4 * conf.add_laf, head_dim, head_dim
        )
        h, n, d = conf.num_heads, conf.n_layers, conf.descriptor_dim
        ag__result_list_0 = []
        for _ in range(n):
>           res = tensorflow_TransformerLayer(d, h, conf.flash)

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/lightglue.py:1433: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_TransformerLayer(), args = (256, 4, True), kwargs = {}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_TransformerLayer(), args = (256, 4, True), kwargs = {}

    @tensorflow_store_config_info
    def __init__(self, *args, **kwargs):
        self.super___init__(
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
>       self.self_attn = tensorflow_SelfBlock(*args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/lightglue.py:976: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_SelfBlock(
  (Wqkv): KerasDense()
), args = (256, 4, True), kwargs = {}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_SelfBlock(
  (Wqkv): KerasDense()
), embed_dim = 256, num_heads = 4, flash = True, bias = True

    @tensorflow_store_config_info
    def __init__(self, embed_dim, num_heads, flash=False, bias=True):
        from ..core.check import tensorflow_KORNIA_CHECK
        from ...torch.nn.modules.container import tensorflow_Sequential
        from ...torch.nn.modules.normalization import tensorflow_LayerNorm
        from ...torch.nn.modules.activation import tensorflow_GELU
        from ...tensorflow__stateful_layers import KerasDense
    
        self.super___init__(
            embed_dim,
            num_heads,
            flash=flash,
            bias=bias,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        self.embed_dim = embed_dim
        self.num_heads = num_heads
        tensorflow_KORNIA_CHECK(
            self.embed_dim % num_heads == 0,
            "Embed dimension should be dividable by num_heads",
        )
        self.head_dim = self.embed_dim // num_heads
        self.Wqkv = KerasDense(
            in_features=embed_dim, units=3 * embed_dim, use_bias=bias
        )
>       self.inner_attn = tensorflow_Attention(flash)

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/lightglue.py:612: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Attention(), args = (True,), kwargs = {}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Attention(), allow_flash = True

    @tensorflow_store_config_info
    def __init__(self, allow_flash):
        self.super___init__(
            allow_flash,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        if allow_flash and not FLASH_AVAILABLE:
            warnings.warn(
                "FlashAttention is not available. For optimal speed, consider installing torch >= 2.0 or flash-attn.",
                stacklevel=2,
            )
        self.enable_flash = allow_flash and FLASH_AVAILABLE
>       self.has_sdp = hasattr(torch.nn.functional, "scaled_dot_product_attention")
E       NameError: name 'torch' is not defined

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/lightglue.py:411: NameError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.LightGlueMatcher
Loaded LightGlue model
----------------------------------------------------------------------------------------- Captured stderr call -----------------------------------------------------------------------------------------
Downloading: "https://github.com/cvg/LightGlue/releases/download/v0.1_arxiv/disk_lightglue.pth" to /root/.cache/torch/hub/checkpoints/disk_lightglue_v0-1_arxiv-pth

  0%|          | 0.00/45.4M [00:00<?, ?B/s]
 44%|     | 20.1M/45.4M [00:00<00:00, 189MB/s]
100%|| 45.4M/45.4M [00:00<00:00, 229MB/s]
_________________________________________________________________________________ test_LightGlue[tensorflow-s2s-False] _________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_LightGlue(target_framework, mode, backend_compile):
        print("kornia.feature.LightGlue")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledLightGlue = ivy.transpile(kornia.feature.LightGlue, source="torch", target=target_framework)
    
        data = {
            "image0": {
                "keypoints": torch.rand(1, 100, 2),
                "descriptors": torch.rand(1, 100, 256),
                "image_size": torch.tensor([[640, 480]]),
            },
            "image1": {
                "keypoints": torch.rand(1, 120, 2),
                "descriptors": torch.rand(1, 120, 256),
                "image_size": torch.tensor([[640, 480]]),
            }
        }
        transpiled_data = _nest_torch_tensor_to_new_framework(data, target_framework)
    
        model = kornia.feature.LightGlue(features='superpoint')
>       torch_out = model(data)

kornia/test_feature4.py:295: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LightGlue(
  (input_proj): Identity()
  (posenc): LearnableFourierPositionalEncoding(
    (Wr): Linear(in_features=2, ... Sequential(
        (0): Linear(in_features=256, out_features=1, bias=True)
        (1): Sigmoid()
      )
    )
  )
)
args = ({'image0': {'descriptors': <tf.Tensor: shape=(1, 100, 256), dtype=float32, numpy=
array([[[0.4881292 , 0.56666106, 0....    [0.05805534, 0.8573005 ],
        [0.53481424, 0.7816777 ],
        [0.11046511, 0.96916455]]], dtype=float32)>}},)
kwargs = {}

    def _wrapped_call_impl(self, *args, **kwargs):
        if self._compiled_call_impl is not None:
            return self._compiled_call_impl(*args, **kwargs)  # type: ignore[misc]
        else:
>           return self._call_impl(*args, **kwargs)

/opt/fw/torch/torch/nn/modules/module.py:1553: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LightGlue(
  (input_proj): Identity()
  (posenc): LearnableFourierPositionalEncoding(
    (Wr): Linear(in_features=2, ... Sequential(
        (0): Linear(in_features=256, out_features=1, bias=True)
        (1): Sigmoid()
      )
    )
  )
)
args = ({'image0': {'descriptors': <tf.Tensor: shape=(1, 100, 256), dtype=float32, numpy=
array([[[0.4881292 , 0.56666106, 0....    [0.05805534, 0.8573005 ],
        [0.53481424, 0.7816777 ],
        [0.11046511, 0.96916455]]], dtype=float32)>}},)
kwargs = {}
forward_call = <bound method LightGlue.forward of LightGlue(
  (input_proj): Identity()
  (posenc): LearnableFourierPositionalEncodin...Sequential(
        (0): Linear(in_features=256, out_features=1, bias=True)
        (1): Sigmoid()
      )
    )
  )
)>

    def _call_impl(self, *args, **kwargs):
        forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)
        # If we don't have any hooks, we want to skip the rest of the logic in
        # this function, and just call forward.
        if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks
                or _global_backward_pre_hooks or _global_backward_hooks
                or _global_forward_hooks or _global_forward_pre_hooks):
>           return forward_call(*args, **kwargs)

/opt/fw/torch/torch/nn/modules/module.py:1562: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LightGlue(
  (input_proj): Identity()
  (posenc): LearnableFourierPositionalEncoding(
    (Wr): Linear(in_features=2, ... Sequential(
        (0): Linear(in_features=256, out_features=1, bias=True)
        (1): Sigmoid()
      )
    )
  )
)
data = {'image0': {'descriptors': <tf.Tensor: shape=(1, 100, 256), dtype=float32, numpy=
array([[[0.4881292 , 0.56666106, 0.3...      [0.05805534, 0.8573005 ],
        [0.53481424, 0.7816777 ],
        [0.11046511, 0.96916455]]], dtype=float32)>}}

    def forward(self, data: dict) -> dict:  # type: ignore
        """Match keypoints and descriptors between two images.
    
        Input (dict):
            image0: dict
                keypoints: [B x M x 2]
                descriptors: [B x M x D]
                image: [B x C x H x W] or image_size: [B x 2]
            image1: dict
                keypoints: [B x N x 2]
                descriptors: [B x N x D]
                image: [B x C x H x W] or image_size: [B x 2]
        Output (dict):
            log_assignment: [B x M+1 x N+1]
            matches0: [B x M]
            matching_scores0: [B x M]
            matches1: [B x N]
            matching_scores1: [B x N]
            matches: List[[Si x 2]], scores: List[[Si]]
        """
        with torch.autocast(enabled=self.conf.mp, device_type="cuda"):
>           return self._forward(data)

/opt/miniconda/envs/multienv/lib/python3.10/site-packages/kornia/feature/lightglue.py:497: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LightGlue(
  (input_proj): Identity()
  (posenc): LearnableFourierPositionalEncoding(
    (Wr): Linear(in_features=2, ... Sequential(
        (0): Linear(in_features=256, out_features=1, bias=True)
        (1): Sigmoid()
      )
    )
  )
)
data = {'image0': {'descriptors': <tf.Tensor: shape=(1, 100, 256), dtype=float32, numpy=
array([[[0.4881292 , 0.56666106, 0.3...      [0.05805534, 0.8573005 ],
        [0.53481424, 0.7816777 ],
        [0.11046511, 0.96916455]]], dtype=float32)>}}

    def _forward(self, data: dict) -> dict:  # type: ignore
        for key in self.required_data_keys:
            KORNIA_CHECK(key in data, f"Missing key {key} in data")
        data0, data1 = data["image0"], data["image1"]
        kpts0, kpts1 = data0["keypoints"], data1["keypoints"]
        b, m, _ = kpts0.shape
        b, n, _ = kpts1.shape
        device = kpts0.device
        size0, size1 = data0.get("image_size"), data1.get("image_size")
        size0 = size0 if size0 is not None else data0["image"].shape[-2:][::-1]
        size1 = size1 if size1 is not None else data1["image"].shape[-2:][::-1]
    
>       kpts0 = normalize_keypoints(kpts0, size0).clone()

/opt/miniconda/envs/multienv/lib/python3.10/site-packages/kornia/feature/lightglue.py:511: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (<tf.Tensor: shape=(1, 100, 2), dtype=float32, numpy=
array([[[8.62723112e-01, 4.65162694e-01],
        [5.84941089e-0...[7.28487015e-01, 9.90527093e-01]]], dtype=float32)>, <tf.Tensor: shape=(1, 2), dtype=int64, numpy=array([[640, 480]])>)
kwargs = {}, autocast_context = False

    @functools.wraps(fwd)
    def decorate_fwd(*args, **kwargs):
        args[0]._dtype = torch.get_autocast_dtype(device_type)
        if cast_inputs is None:
            args[0]._fwd_used_autocast = torch.is_autocast_enabled(device_type)
            return fwd(*args, **kwargs)
        else:
            autocast_context = torch.is_autocast_enabled(device_type)
            args[0]._fwd_used_autocast = False
            if autocast_context:
                with autocast(device_type=device_type, enabled=False):
                    return fwd(
                        *_cast(args, device_type, cast_inputs),
                        **_cast(kwargs, device_type, cast_inputs),
                    )
            else:
>               return fwd(*args, **kwargs)

/opt/fw/torch/torch/amp/autocast_mode.py:466: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

kpts = <tf.Tensor: shape=(1, 100, 2), dtype=float32, numpy=
array([[[8.62723112e-01, 4.65162694e-01],
        [5.84941089e-01... 8.47756624e-01],
        [4.65014577e-01, 3.60723257e-01],
        [7.28487015e-01, 9.90527093e-01]]], dtype=float32)>
size = <tf.Tensor: shape=(1, 2), dtype=int64, numpy=array([[640, 480]])>

    @torch.cuda.amp.custom_fwd(cast_inputs=torch.float32)
    def normalize_keypoints(kpts: Tensor, size: Tensor) -> Tensor:
        if isinstance(size, torch.Size):
            size = Tensor(size)[None]
>       shift = size.float().to(kpts) / 2

/opt/miniconda/envs/multienv/lib/python3.10/site-packages/kornia/feature/lightglue.py:48: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <tf.Tensor: shape=(1, 2), dtype=int64, numpy=array([[640, 480]])>, name = 'float'

    def __getattr__(self, name):
      if name in {"T", "astype", "ravel", "transpose", "reshape", "clip", "size",
                  "tolist", "data"}:
        # TODO(wangpeng): Export the enable_numpy_behavior knob
        raise AttributeError(
            f"{type(self).__name__} object has no attribute '{name}'. " + """
          If you are looking for numpy-related methods, please run the following:
          tf.experimental.numpy.experimental_enable_numpy_behavior()
        """)
>     self.__getattribute__(name)
E     AttributeError: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'float'

/opt/fw/tensorflow/tensorflow/python/framework/tensor.py:260: AttributeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.LightGlue
Loaded LightGlue model
----------------------------------------------------------------------------------------- Captured stderr call -----------------------------------------------------------------------------------------
Downloading: "https://github.com/cvg/LightGlue/releases/download/v0.1_arxiv/superpoint_lightglue.pth" to /root/.cache/torch/hub/checkpoints/superpoint_lightglue_v0-1_arxiv-pth

  0%|          | 0.00/45.3M [00:00<?, ?B/s]
 49%|     | 22.0M/45.3M [00:00<00:00, 230MB/s]
100%|| 45.3M/45.3M [00:00<00:00, 247MB/s]
___________________________________________________________________________________ test_LoFTR[tensorflow-s2s-False] ___________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_LoFTR(target_framework, mode, backend_compile):
        print("kornia.feature.LoFTR")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledLoFTR = ivy.transpile(kornia.feature.LoFTR, source="torch", target=target_framework)
    
        data = {"image0": torch.rand(1, 1, 320, 200), "image1": torch.rand(1, 1, 128, 128)}
        transpiled_data = _nest_torch_tensor_to_new_framework(data, target_framework)
    
        model = kornia.feature.LoFTR(None)
>       torch_out = model(data)

kornia/test_feature4.py:322: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LoFTR(
  (backbone): ResNetFPN_8_2(
    (conv1): Conv2d(1, 128, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bia...   (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (fine_matching): FineMatching()
)
args = ({'image0': <tf.Tensor: shape=(1, 1, 320, 200), dtype=float32, numpy=
array([[[[0.8431617 , 0.73625225, 0.6940427 , .....0e-01, 3.6699396e-01, 4.6295232e-01, ...,
          6.5749884e-04, 3.3981550e-01, 4.2790413e-01]]]], dtype=float32)>},)
kwargs = {}

    def _wrapped_call_impl(self, *args, **kwargs):
        if self._compiled_call_impl is not None:
            return self._compiled_call_impl(*args, **kwargs)  # type: ignore[misc]
        else:
>           return self._call_impl(*args, **kwargs)

/opt/fw/torch/torch/nn/modules/module.py:1553: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LoFTR(
  (backbone): ResNetFPN_8_2(
    (conv1): Conv2d(1, 128, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bia...   (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (fine_matching): FineMatching()
)
args = ({'image0': <tf.Tensor: shape=(1, 1, 320, 200), dtype=float32, numpy=
array([[[[0.8431617 , 0.73625225, 0.6940427 , .....0e-01, 3.6699396e-01, 4.6295232e-01, ...,
          6.5749884e-04, 3.3981550e-01, 4.2790413e-01]]]], dtype=float32)>},)
kwargs = {}
forward_call = <bound method LoFTR.forward of LoFTR(
  (backbone): ResNetFPN_8_2(
    (conv1): Conv2d(1, 128, kernel_size=(7, 7), str...  (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (fine_matching): FineMatching()
)>

    def _call_impl(self, *args, **kwargs):
        forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)
        # If we don't have any hooks, we want to skip the rest of the logic in
        # this function, and just call forward.
        if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks
                or _global_backward_pre_hooks or _global_backward_hooks
                or _global_forward_hooks or _global_forward_pre_hooks):
>           return forward_call(*args, **kwargs)

/opt/fw/torch/torch/nn/modules/module.py:1562: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LoFTR(
  (backbone): ResNetFPN_8_2(
    (conv1): Conv2d(1, 128, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bia...   (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (fine_matching): FineMatching()
)
data = {'image0': <tf.Tensor: shape=(1, 1, 320, 200), dtype=float32, numpy=
array([[[[0.8431617 , 0.73625225, 0.6940427 , ......510e-01, 3.6699396e-01, 4.6295232e-01, ...,
          6.5749884e-04, 3.3981550e-01, 4.2790413e-01]]]], dtype=float32)>}

    def forward(self, data: dict[str, Tensor]) -> dict[str, Tensor]:
        """
        Args:
            data: dictionary containing the input data in the following format:
    
        Keyword Args:
            image0: left image with shape :math:`(N, 1, H1, W1)`.
            image1: right image with shape :math:`(N, 1, H2, W2)`.
            mask0 (optional): left image mask. '0' indicates a padded position :math:`(N, H1, W1)`.
            mask1 (optional): right image mask. '0' indicates a padded position :math:`(N, H2, W2)`.
    
        Returns:
            - ``keypoints0``, matching keypoints from image0 :math:`(NC, 2)`.
            - ``keypoints1``, matching keypoints from image1 :math:`(NC, 2)`.
            - ``confidence``, confidence score [0, 1] :math:`(NC)`.
            - ``batch_indexes``, batch indexes for the keypoints and lafs :math:`(NC)`.
        """
        # 1. Local Feature CNN
        _data: dict[str, Tensor | int | torch.Size] = {
>           "bs": data["image0"].size(0),
            "hw0_i": data["image0"].shape[2:],
            "hw1_i": data["image1"].shape[2:],
        }
E       TypeError: 'numpy.int64' object is not callable

/opt/miniconda/envs/multienv/lib/python3.10/site-packages/kornia/feature/loftr/loftr.py:123: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.LoFTR
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/test_feature4.py::test_SIFTFeature[tensorflow-s2s-False] - ValueError: could not broadcast input array from shape (1,5) into shape (5,1,1)
FAILED kornia/test_feature4.py::test_SIFTFeatureScaleSpace[tensorflow-s2s-False] - ValueError: could not broadcast input array from shape (1,5) into shape (5,1,1)
FAILED kornia/test_feature4.py::test_GFTTAffNetHardNet[tensorflow-s2s-False] - ValueError: could not broadcast input array from shape (1,5) into shape (5,1,1)
FAILED kornia/test_feature4.py::test_KeyNetAffNetHardNet[tensorflow-s2s-False] - AssertionError: numpy array values are not all close
FAILED kornia/test_feature4.py::test_LocalFeatureMatcher[tensorflow-s2s-False] - TypeError: Input input type is not a Tensor. Got <class 'tensorflow.python.framework.ops.EagerTensor'>
FAILED kornia/test_feature4.py::test_LightGlueMatcher[tensorflow-s2s-False] - NameError: name 'torch' is not defined
FAILED kornia/test_feature4.py::test_LightGlue[tensorflow-s2s-False] - AttributeError: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'float'
FAILED kornia/test_feature4.py::test_LoFTR[tensorflow-s2s-False] - TypeError: 'numpy.int64' object is not callable
=============================================================================== 8 failed, 6 passed in 2828.63s (0:47:08) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 17 items

kornia/augmentation/test_augmentation2.py ...F.......F.F...                                                                                                                                      [100%]

=============================================================================================== FAILURES ===============================================================================================
_________________________________________________________________________________ test_RandomMotionBlur[jax-s2s-False] _________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_RandomMotionBlur(target_framework, mode, backend_compile):
        print("kornia.augmentation.RandomMotionBlur")
    
        init_args = (3, 35., 0.5)
        init_kwargs = {"p": 1.}
        call_args = (torch.ones(1, 1, 5, 5),)
        call_kwargs = {}
    
>       _test_augmentation_class(
            kornia.augmentation.RandomMotionBlur,
            target_framework,
            init_args,
            init_kwargs,
            call_args,
            call_kwargs,
            deterministic_output=False,
            backend_compile=backend_compile,
        )

kornia/augmentation/test_augmentation2.py:133: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

augmentation_cls = <class 'kornia.augmentation._2d.intensity.motion_blur.RandomMotionBlur'>, target = 'jax', init_args = (3, 35.0, 0.5), init_kwargs = {'p': 1.0}
call_args = (tensor([[[[1., 1., 1., 1., 1.],
          [1., 1., 1., 1., 1.],
          [1., 1., 1., 1., 1.],
          [1., 1., 1., 1., 1.],
          [1., 1., 1., 1., 1.]]]]),), call_kwargs = {}
deterministic_output = False, backend_compile = False, tolerance = 0.001

    def _test_augmentation_class(
        augmentation_cls,
        target,
        init_args=(),
        init_kwargs={},
        call_args=(),
        call_kwargs={},
        deterministic_output=True,
        backend_compile=False,
        tolerance=1e-3,
    ):
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_cls = ivy.transpile(augmentation_cls, source="torch", target=target)
    
        torch_aug = augmentation_cls(*init_args, **init_kwargs)
        transpiled_init_args = _nest_torch_tensor_to_new_framework(init_args, target)
        transpiled_init_kwargs = _nest_torch_tensor_to_new_framework(init_kwargs, target)
        transpiled_aug = transpiled_cls(*transpiled_init_args, **transpiled_init_kwargs)
    
        # assert dir(torch_aug) == dir(transpiled_aug), f"attributes/methods of transpiled object do not align with the original - orig: {dir(torch_aug)} != transpiled: {dir(transpiled_aug)}"
    
        torch_out = torch_aug(*call_args, **call_kwargs)
        transpiled_call_args = _nest_torch_tensor_to_new_framework(call_args, target)
        transpiled_call_kwargs = _nest_torch_tensor_to_new_framework(call_kwargs, target)
>       transpiled_out = transpiled_aug(*transpiled_call_args, **transpiled_call_kwargs)

kornia/augmentation/test_augmentation2.py:43: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_RandomMotionBlur(kernel_size=3, angle=35.0, direction=0.5, p=1.0, p_batch=1.0, same_on_batch=False, border_type=constant, resample=nearest)
input = Array([[[[1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.]]]], dtype=float32), params = None
kwargs = {}, jax_shape_frnt_ = <function jax_shape_frnt_ at 0x7fe3cfa335b0>, jax_set_item = <function jax_set_item at 0x7fe3b446e200>, tensor = <function jax_tensor_frnt at 0x7fe3a4fdbac0>
in_tensor = Array([[[[1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.]]]], dtype=float32)
input_shape = ivy.frontends.torch.Size([1, 1, 5, 5]), batch_shape = ivy.frontends.torch.Size([1, 1, 5, 5])

    def __call__(self, input, params=None, **kwargs):
        from ...ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ...ivy.functional.backends.jax.general import jax_set_item
        from ..core._backend import tensor
    
        in_tensor = self.__unpack_input__(input)
        input_shape = jax_shape_frnt_(in_tensor)
        in_tensor = self.transform_tensor(in_tensor)
        batch_shape = jax_shape_frnt_(in_tensor)
        if params is None:
>           params = self.forward_parameters(batch_shape)

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/base.py:213: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_RandomMotionBlur(kernel_size=3, angle=35.0, direction=0.5, p=1.0, p_batch=1.0, same_on_batch=False, border_type=constant, resample=nearest)
batch_shape = ivy.frontends.torch.Size([1, 1, 5, 5])

    def forward_parameters(self, batch_shape):
        from ...ivy.functional.frontends.torch.tensor import jax_sum_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_item_frnt_
        from ...ivy.functional.backends.jax.general import jax_set_item
        from ..core._backend import tensor
    
        batch_prob = self.__batch_prob_generator__(
            batch_shape, self.p, self.p_batch, self.same_on_batch
        )
        to_apply = batch_prob > 0.5
>       _params = self.generate_parameters(
            tuple((int(jax_item_frnt_(jax_sum_frnt_(to_apply))), *batch_shape[1:]))
        )

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/base.py:190: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_RandomMotionBlur(kernel_size=3, angle=35.0, direction=0.5, p=1.0, p_batch=1.0, same_on_batch=False, border_type=constant, resample=nearest), batch_shape = (1, 1, 5, 5)

    def generate_parameters(self, batch_shape):
        from ....core._backend import tensor
        from .....ivy.functional.backends.jax.general import jax_set_item
        from .....ivy.functional.frontends.torch.random_sampling import jax_randint_frnt
    
        params = super().generate_parameters(batch_shape)
        params = jax_set_item(
            params,
            "idx",
            tensor([0])
            if batch_shape[0] == 0
>           else jax_randint_frnt(batch_shape[0], (1,)),
        )
E       TypeError: jax_randint_frnt() missing 1 required positional argument: 'size'

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/_2d/intensity/motion_blur.py:66: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.RandomMotionBlur
_____________________________________________________________________________ test_RandomSaltAndPepperNoise[jax-s2s-False] _____________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_RandomSaltAndPepperNoise(target_framework, mode, backend_compile):
        print("kornia.augmentation.RandomSaltAndPepperNoise")
    
        init_args = ()
        init_kwargs = {"amount": 0.5, "salt_vs_pepper": 0.5, "p": 1.}
        call_args = (torch.rand(1, 3, 3, 3),)
        call_kwargs = {}
    
>       _test_augmentation_class(
            kornia.augmentation.RandomSaltAndPepperNoise,
            target_framework,
            init_args,
            init_kwargs,
            call_args,
            call_kwargs,
            deterministic_output=False,
            backend_compile=backend_compile,
        )

kornia/augmentation/test_augmentation2.py:293: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

augmentation_cls = <class 'kornia.augmentation._2d.intensity.salt_pepper_noise.RandomSaltAndPepperNoise'>, target = 'jax', init_args = ()
init_kwargs = {'amount': 0.5, 'p': 1.0, 'salt_vs_pepper': 0.5}
call_args = (tensor([[[[0.9239, 0.7457, 0.5423],
          [0.5318, 0.7700, 0.0051],
          [0.6782, 0.8181, 0.9422]],

       ...48]],

         [[0.0383, 0.6939, 0.9663],
          [0.8813, 0.9225, 0.4820],
          [0.0762, 0.9805, 0.5948]]]]),)
call_kwargs = {}, deterministic_output = False, backend_compile = False, tolerance = 0.001

    def _test_augmentation_class(
        augmentation_cls,
        target,
        init_args=(),
        init_kwargs={},
        call_args=(),
        call_kwargs={},
        deterministic_output=True,
        backend_compile=False,
        tolerance=1e-3,
    ):
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_cls = ivy.transpile(augmentation_cls, source="torch", target=target)
    
        torch_aug = augmentation_cls(*init_args, **init_kwargs)
        transpiled_init_args = _nest_torch_tensor_to_new_framework(init_args, target)
        transpiled_init_kwargs = _nest_torch_tensor_to_new_framework(init_kwargs, target)
        transpiled_aug = transpiled_cls(*transpiled_init_args, **transpiled_init_kwargs)
    
        # assert dir(torch_aug) == dir(transpiled_aug), f"attributes/methods of transpiled object do not align with the original - orig: {dir(torch_aug)} != transpiled: {dir(transpiled_aug)}"
    
        torch_out = torch_aug(*call_args, **call_kwargs)
        transpiled_call_args = _nest_torch_tensor_to_new_framework(call_args, target)
        transpiled_call_kwargs = _nest_torch_tensor_to_new_framework(call_kwargs, target)
>       transpiled_out = transpiled_aug(*transpiled_call_args, **transpiled_call_kwargs)

kornia/augmentation/test_augmentation2.py:43: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_RandomSaltAndPepperNoise(amount=(0.5, 0.5), salt_and_pepper=(0.5, 0.5), p=1.0, p_batch=1.0, same_on_batch=False)
input = Array([[[[0.9239121 , 0.7456605 , 0.5422942 ],
         [0.53175604, 0.77001727, 0.00512099],
         [0.67819095, 0....26604],
         [0.88134724, 0.92250144, 0.4820245 ],
         [0.07615823, 0.9805285 , 0.5947689 ]]]], dtype=float32)
params = {'amount_factor': Array([0.5], dtype=float32), 'batch_prob': Array([1.], dtype=float32), 'forward_input_shape': Array(...,

        [[False, False,  True],
         [False, False, False],
         [False,  True, False]]]], dtype=bool), ...}
kwargs = {}, jax_shape_frnt_ = <function jax_shape_frnt_ at 0x7fe393d931c0>, jax_set_item = <function jax_set_item at 0x7fe3cfe435b0>, tensor = <function jax_tensor_frnt at 0x7fe3db5405e0>
in_tensor = Array([[[[0.9239121 , 0.7456605 , 0.5422942 ],
         [0.53175604, 0.77001727, 0.00512099],
         [0.67819095, 0....26604],
         [0.88134724, 0.92250144, 0.4820245 ],
         [0.07615823, 0.9805285 , 0.5947689 ]]]], dtype=float32)
input_shape = ivy.frontends.torch.Size([1, 3, 3, 3]), batch_shape = ivy.frontends.torch.Size([1, 3, 3, 3]), flags = {}

    def __call__(self, input, params=None, **kwargs):
        from ...ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ...ivy.functional.backends.jax.general import jax_set_item
        from ..core._backend import tensor
    
        in_tensor = self.__unpack_input__(input)
        input_shape = jax_shape_frnt_(in_tensor)
        in_tensor = self.transform_tensor(in_tensor)
        batch_shape = jax_shape_frnt_(in_tensor)
        if params is None:
            params = self.forward_parameters(batch_shape)
        if "batch_prob" not in params:
            params = jax_set_item(params, "batch_prob", tensor([True] * batch_shape[0]))
        params, flags = self._process_kwargs_to_params_and_flags(
            params, self.flags, **kwargs
        )
>       output = self.apply_func(in_tensor, params, flags)

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/base.py:219: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_RandomSaltAndPepperNoise(amount=(0.5, 0.5), salt_and_pepper=(0.5, 0.5), p=1.0, p_batch=1.0, same_on_batch=False)
in_tensor = Array([[[[0.9239121 , 0.7456605 , 0.5422942 ],
         [0.53175604, 0.77001727, 0.00512099],
         [0.67819095, 0....26604],
         [0.88134724, 0.92250144, 0.4820245 ],
         [0.07615823, 0.9805285 , 0.5947689 ]]]], dtype=float32)
params = {'amount_factor': Array([0.5], dtype=float32), 'batch_prob': Array([1.], dtype=float32), 'forward_input_shape': Array(...,

        [[False, False,  True],
         [False, False, False],
         [False,  True, False]]]], dtype=bool), ...}
flags = {}

    def apply_func(self, in_tensor, params, flags=None):
        if flags is None:
            flags = self.flags
        trans_matrix = self.generate_transformation_matrix(in_tensor, params, flags)
>       output = self.transform_inputs(in_tensor, params, flags, trans_matrix)

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/_2d/base.py:123: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_RandomSaltAndPepperNoise(amount=(0.5, 0.5), salt_and_pepper=(0.5, 0.5), p=1.0, p_batch=1.0, same_on_batch=False)
input = Array([[[[0.9239121 , 0.7456605 , 0.5422942 ],
         [0.53175604, 0.77001727, 0.00512099],
         [0.67819095, 0....26604],
         [0.88134724, 0.92250144, 0.4820245 ],
         [0.07615823, 0.9805285 , 0.5947689 ]]]], dtype=float32)
params = {'amount_factor': Array([0.5], dtype=float32), 'batch_prob': Array([1.], dtype=float32), 'forward_input_shape': Array(...,

        [[False, False,  True],
         [False, False, False],
         [False,  True, False]]]], dtype=bool), ...}
flags = {}, transform = Array([[[1., 0., 0.],
        [0., 1., 0.],
        [0., 0., 1.]]], dtype=float32), kwargs = {}, jax_shape_frnt_ = <function jax_shape_frnt_ at 0x7fe393d931c0>
jax_all_frnt_ = <function jax_all_frnt_ at 0x7fe3939fe830>, jax_any_frnt_ = <function jax_any_frnt_ at 0x7fe3cff61990>, jax_get_item = <function jax_get_item at 0x7fe3cfe43400>
jax_is_autocast_enabled = <function jax_is_autocast_enabled at 0x7fe3cfeb4a60>, jax_type_frnt_ = <function jax_type_frnt_ at 0x7fe3cff61fc0>
jax_index_put_frnt_ = <function jax_index_put_frnt_ at 0x7fe3cff61ea0>

    def transform_inputs(self, input, params, flags, transform=None, **kwargs):
        from ...ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_all_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_any_frnt_
        from ...ivy.functional.backends.jax.general import jax_get_item
        from ..utils.helpers import jax_is_autocast_enabled
        from ...ivy.functional.frontends.torch.tensor import jax_type_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_index_put_frnt_
        from .utils.helpers import jax__transform_output_shape
    
        params, flags = self._process_kwargs_to_params_and_flags(
            self._params if params is None else params, flags, **kwargs
        )
        batch_prob = params["batch_prob"]
        to_apply = batch_prob > 0.5
        ori_shape = jax_shape_frnt_(input)
        in_tensor = self.transform_tensor(input)
        self.validate_tensor(in_tensor)
        if jax_all_frnt_(to_apply):
>           output = self.apply_transform(in_tensor, params, flags, transform=transform)

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/base.py:333: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_RandomSaltAndPepperNoise(amount=(0.5, 0.5), salt_and_pepper=(0.5, 0.5), p=1.0, p_batch=1.0, same_on_batch=False)
input = Array([[[[0.9239121 , 0.7456605 , 0.5422942 ],
         [0.53175604, 0.77001727, 0.00512099],
         [0.67819095, 0....26604],
         [0.88134724, 0.92250144, 0.4820245 ],
         [0.07615823, 0.9805285 , 0.5947689 ]]]], dtype=float32)
params = {'amount_factor': Array([0.5], dtype=float32), 'batch_prob': Array([1.], dtype=float32), 'forward_input_shape': Array(...,

        [[False, False,  True],
         [False, False, False],
         [False,  True, False]]]], dtype=bool), ...}
flags = {}, transform = Array([[[1., 0., 0.],
        [0., 1., 0.],
        [0., 0., 1.]]], dtype=float32)

    def apply_transform(self, input, params, flags, transform=None):
        from ....core.check import jax_KORNIA_CHECK
        from .....ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from .....ivy.functional.frontends.torch.tensor import jax_clone_frnt_
        from .....ivy.functional.backends.jax.general import jax_set_item
    
        jax_KORNIA_CHECK(
            len(jax_shape_frnt_(input)) in (3, 4), "Wrong input dimension."
        )
        if len(jax_shape_frnt_(input)) == 3:
            input = input[None, :, :, :]
        jax_KORNIA_CHECK(
            jax_shape_frnt_(input)[1] in {3, 1},
            "Number of color channels should be 1 or 3.",
        )
        noisy_image = jax_clone_frnt_(input)
        noisy_image = jax_set_item(
>           noisy_image, params["mask_salt"].to(input.device), 1.0
        )
E       AttributeError: 'jaxlib.xla_extension.ArrayImpl' object has no attribute 'to'

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/_2d/intensity/salt_pepper_noise.py:92: AttributeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.RandomSaltAndPepperNoise
_________________________________________________________________________________ test_RandomSharpness[jax-s2s-False] __________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_RandomSharpness(target_framework, mode, backend_compile):
        print("kornia.augmentation.RandomSharpness")
    
        init_args = (1.,)
        init_kwargs = {"p": 1.}
        call_args = (torch.rand(1, 1, 5, 5),)
        call_kwargs = {}
    
>       _test_augmentation_class(
            kornia.augmentation.RandomSharpness,
            target_framework,
            init_args,
            init_kwargs,
            call_args,
            call_kwargs,
            deterministic_output=False,
            backend_compile=backend_compile,
        )

kornia/augmentation/test_augmentation2.py:333: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

augmentation_cls = <class 'kornia.augmentation._2d.intensity.sharpness.RandomSharpness'>, target = 'jax', init_args = (1.0,), init_kwargs = {'p': 1.0}
call_args = (tensor([[[[0.8822, 0.6728, 0.0135, 0.6729, 0.3023],
          [0.9455, 0.4201, 0.2759, 0.8464, 0.0832],
          [0...., 0.7903],
          [0.8265, 0.6674, 0.2441, 0.0594, 0.9900],
          [0.6794, 0.5912, 0.7828, 0.1981, 0.3596]]]]),)
call_kwargs = {}, deterministic_output = False, backend_compile = False, tolerance = 0.001

    def _test_augmentation_class(
        augmentation_cls,
        target,
        init_args=(),
        init_kwargs={},
        call_args=(),
        call_kwargs={},
        deterministic_output=True,
        backend_compile=False,
        tolerance=1e-3,
    ):
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_cls = ivy.transpile(augmentation_cls, source="torch", target=target)
    
        torch_aug = augmentation_cls(*init_args, **init_kwargs)
        transpiled_init_args = _nest_torch_tensor_to_new_framework(init_args, target)
        transpiled_init_kwargs = _nest_torch_tensor_to_new_framework(init_kwargs, target)
        transpiled_aug = transpiled_cls(*transpiled_init_args, **transpiled_init_kwargs)
    
        # assert dir(torch_aug) == dir(transpiled_aug), f"attributes/methods of transpiled object do not align with the original - orig: {dir(torch_aug)} != transpiled: {dir(transpiled_aug)}"
    
        torch_out = torch_aug(*call_args, **call_kwargs)
        transpiled_call_args = _nest_torch_tensor_to_new_framework(call_args, target)
        transpiled_call_kwargs = _nest_torch_tensor_to_new_framework(call_kwargs, target)
>       transpiled_out = transpiled_aug(*transpiled_call_args, **transpiled_call_kwargs)

kornia/augmentation/test_augmentation2.py:43: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_RandomSharpness(sharpness=1.0, p=1.0, p_batch=1.0, same_on_batch=False)
input = Array([[[[0.8821787 , 0.67277884, 0.01352173, 0.6728928 , 0.30228943],
         [0.94549924, 0.42013097, 0.275935  , 0... 0.05938029, 0.98996407],
         [0.67944753, 0.59124196, 0.7828174 , 0.19805491, 0.3596291 ]]]],      dtype=float32)
params = {'batch_prob': Array([1.], dtype=float32), 'forward_input_shape': Array([1, 1, 5, 5], dtype=int64), 'sharpness': Array([0.10536897], dtype=float32)}, kwargs = {}
jax_shape_frnt_ = <function jax_shape_frnt_ at 0x7fe3933dd000>, jax_set_item = <function jax_set_item at 0x7fe3b437cee0>, tensor = <function jax_tensor_frnt at 0x7fe3db5b25f0>
in_tensor = Array([[[[0.8821787 , 0.67277884, 0.01352173, 0.6728928 , 0.30228943],
         [0.94549924, 0.42013097, 0.275935  , 0... 0.05938029, 0.98996407],
         [0.67944753, 0.59124196, 0.7828174 , 0.19805491, 0.3596291 ]]]],      dtype=float32)
input_shape = ivy.frontends.torch.Size([1, 1, 5, 5]), batch_shape = ivy.frontends.torch.Size([1, 1, 5, 5]), flags = {}

    def __call__(self, input, params=None, **kwargs):
        from ...ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ...ivy.functional.backends.jax.general import jax_set_item
        from ..core._backend import tensor
    
        in_tensor = self.__unpack_input__(input)
        input_shape = jax_shape_frnt_(in_tensor)
        in_tensor = self.transform_tensor(in_tensor)
        batch_shape = jax_shape_frnt_(in_tensor)
        if params is None:
            params = self.forward_parameters(batch_shape)
        if "batch_prob" not in params:
            params = jax_set_item(params, "batch_prob", tensor([True] * batch_shape[0]))
        params, flags = self._process_kwargs_to_params_and_flags(
            params, self.flags, **kwargs
        )
>       output = self.apply_func(in_tensor, params, flags)

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/base.py:219: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_RandomSharpness(sharpness=1.0, p=1.0, p_batch=1.0, same_on_batch=False)
in_tensor = Array([[[[0.8821787 , 0.67277884, 0.01352173, 0.6728928 , 0.30228943],
         [0.94549924, 0.42013097, 0.275935  , 0... 0.05938029, 0.98996407],
         [0.67944753, 0.59124196, 0.7828174 , 0.19805491, 0.3596291 ]]]],      dtype=float32)
params = {'batch_prob': Array([1.], dtype=float32), 'forward_input_shape': Array([1, 1, 5, 5], dtype=int64), 'sharpness': Array([0.10536897], dtype=float32)}, flags = {}

    def apply_func(self, in_tensor, params, flags=None):
        if flags is None:
            flags = self.flags
        trans_matrix = self.generate_transformation_matrix(in_tensor, params, flags)
>       output = self.transform_inputs(in_tensor, params, flags, trans_matrix)

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/_2d/base.py:123: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_RandomSharpness(sharpness=1.0, p=1.0, p_batch=1.0, same_on_batch=False)
input = Array([[[[0.8821787 , 0.67277884, 0.01352173, 0.6728928 , 0.30228943],
         [0.94549924, 0.42013097, 0.275935  , 0... 0.05938029, 0.98996407],
         [0.67944753, 0.59124196, 0.7828174 , 0.19805491, 0.3596291 ]]]],      dtype=float32)
params = {'batch_prob': Array([1.], dtype=float32), 'forward_input_shape': Array([1, 1, 5, 5], dtype=int64), 'sharpness': Array([0.10536897], dtype=float32)}, flags = {}
transform = Array([[[1., 0., 0.],
        [0., 1., 0.],
        [0., 0., 1.]]], dtype=float32), kwargs = {}, jax_shape_frnt_ = <function jax_shape_frnt_ at 0x7fe3933dd000>
jax_all_frnt_ = <function jax_all_frnt_ at 0x7fe3933dc700>, jax_any_frnt_ = <function jax_any_frnt_ at 0x7fe3933aa290>, jax_get_item = <function jax_get_item at 0x7fe3b437cd30>
jax_is_autocast_enabled = <function jax_is_autocast_enabled at 0x7fe3cfbf9fc0>, jax_type_frnt_ = <function jax_type_frnt_ at 0x7fe3933abf40>
jax_index_put_frnt_ = <function jax_index_put_frnt_ at 0x7fe3933a9630>

    def transform_inputs(self, input, params, flags, transform=None, **kwargs):
        from ...ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_all_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_any_frnt_
        from ...ivy.functional.backends.jax.general import jax_get_item
        from ..utils.helpers import jax_is_autocast_enabled
        from ...ivy.functional.frontends.torch.tensor import jax_type_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_index_put_frnt_
        from .utils.helpers import jax__transform_output_shape
    
        params, flags = self._process_kwargs_to_params_and_flags(
            self._params if params is None else params, flags, **kwargs
        )
        batch_prob = params["batch_prob"]
        to_apply = batch_prob > 0.5
        ori_shape = jax_shape_frnt_(input)
        in_tensor = self.transform_tensor(input)
        self.validate_tensor(in_tensor)
        if jax_all_frnt_(to_apply):
>           output = self.apply_transform(in_tensor, params, flags, transform=transform)

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/base.py:333: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_RandomSharpness(sharpness=1.0, p=1.0, p_batch=1.0, same_on_batch=False)
input = Array([[[[0.8821787 , 0.67277884, 0.01352173, 0.6728928 , 0.30228943],
         [0.94549924, 0.42013097, 0.275935  , 0... 0.05938029, 0.98996407],
         [0.67944753, 0.59124196, 0.7828174 , 0.19805491, 0.3596291 ]]]],      dtype=float32)
params = {'batch_prob': Array([1.], dtype=float32), 'forward_input_shape': Array([1, 1, 5, 5], dtype=int64), 'sharpness': Array([0.10536897], dtype=float32)}, flags = {}
transform = Array([[[1., 0., 0.],
        [0., 1., 0.],
        [0., 0., 1.]]], dtype=float32)

    def apply_transform(self, input, params, flags, transform=None):
        factor = params["sharpness"]
>       return sharpness(input, factor)
E       NameError: name 'sharpness' is not defined

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/_2d/intensity/sharpness.py:41: NameError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.RandomSharpness
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/augmentation/test_augmentation2.py::test_RandomMotionBlur[jax-s2s-False] - TypeError: jax_randint_frnt() missing 1 required positional argument: 'size'
FAILED kornia/augmentation/test_augmentation2.py::test_RandomSaltAndPepperNoise[jax-s2s-False] - AttributeError: 'jaxlib.xla_extension.ArrayImpl' object has no attribute 'to'
FAILED kornia/augmentation/test_augmentation2.py::test_RandomSharpness[jax-s2s-False] - NameError: name 'sharpness' is not defined
============================================================================== 3 failed, 14 passed in 3529.30s (0:58:49) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 2 items

kornia/geometry/test_line.py Fs                                                                                                                                                                  [100%]

=============================================================================================== FAILURES ===============================================================================================
____________________________________________________________________________________ test_fit_line[numpy-s2s-False] ____________________________________________________________________________________

target_framework = 'numpy', mode = 's2s', backend_compile = False

    def test_fit_line(target_framework, mode, backend_compile):
        print("kornia.geometry.line.fit_line")
    
        if backend_compile:
            pytest.skip()
    
>       transpiled_fit_line = ivy.transpile(kornia.geometry.line.fit_line, source="torch", target=target_framework)

kornia/geometry/test_line.py:24: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

object = <function fit_line at 0x7fd8ab6191b0>, source = 'torch', target = 'numpy', reuse_existing = True

    def transpile(
        object,
        source: str = "torch",
        target: str = "tensorflow",
        reuse_existing: bool = True,
    ):
        """Converts a given object (class/function) from one framework to another.
    
        This function performs source-to-source translation of a given object from the source framework
        to the target framework.
    
        The object can be translated between two frameworks or between the Ivy IR as well
        e.g. (source="torch_frontend", target="ivy") or (source="torch_frontend", target="tensorflow") etc.
    
        Args:
            object: The object (class/function) to be translated.
            source (str, optional): The source framework. Defaults to 'torch'.
            target (str, optional): The target framework. Defaults to 'tensorflow'.
            reuse_existing (bool, optional): If True, the function will check if `object`
                                             already exists in the translated directory and reuse it.
                                             If False, it will re-translate `object`,
                                             even if it already exists in the directory, and overwrite
                                             the old implementation. Defaults to 'True'.
    
        Returns:
            The translated object."""
    
        from ._compiler import transpile as _transpile
    
>       return _transpile(
            object=object,
            source=source,
            target=target,
            reuse_existing=reuse_existing,
        )

../ivy/ivy/compiler/compiler.py:201: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   ivy.utils.exceptions.IvyException: Cannot transpile the object '<class 'ivy_transpiled_outputs.ivy_outputs.kornia.geometry.line.ivy_ParametrizedLine'>' to `numpy` because it is an instance of a stateful class.

IXC.pyx:379: IvyException
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.line.fit_line
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/geometry/test_line.py::test_fit_line[numpy-s2s-False] - ivy.utils.exceptions.IvyException: Cannot transpile the object '<class 'ivy_transpiled_outputs.ivy_outputs.kornia.geometry.line...
=============================================================================== 1 failed, 1 skipped in 68.49s (0:01:08) ================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 5 items

kornia/geometry/test_solvers.py .....                                                                                                                                                            [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
==================================================================================== 5 passed in 276.05s (0:04:36) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 35 items

kornia/test_losses.py .................FF...F............                                                                                                                                        [100%]

=============================================================================================== FAILURES ===============================================================================================
_________________________________________________________________________________ test_HausdorffERLoss[jax-s2s-False] __________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_HausdorffERLoss(target_framework, mode, backend_compile):
        print("kornia.losses.HausdorffERLoss")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledHausdorffERLoss = ivy.transpile(kornia.losses.HausdorffERLoss, source="torch", target=target_framework)
    
        torch_loss_fn = kornia.losses.HausdorffERLoss()
        transpiled_loss_fn = TranspiledHausdorffERLoss()
    
        torch_args = (
            torch.randn(5, 3, 20, 20),
            (torch.rand(5, 1, 20, 20) * 2).long(),
        )
        transpiled_args = _nest_torch_tensor_to_new_framework(torch_args, target_framework)
    
        torch_res = torch_loss_fn(*torch_args)
>       transpiled_res = transpiled_loss_fn(*transpiled_args)

kornia/test_losses.py:446: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_HausdorffERLoss()
pred = Array([[[[ 1.21370125e+00,  1.19621769e-01,  7.56473660e-01, ...,
          -6.13189638e-01, -3.12515795e-02, -3.05491...3795960e+00, -1.64430678e+00, ...,
           1.89253137e-01, -3.18794131e-01, -9.35967505e-01]]]],      dtype=float32)
target = Array([[[[0, 0, 0, ..., 1, 0, 1],
         [1, 0, 1, ..., 1, 1, 1],
         [0, 0, 1, ..., 0, 1, 1],
         ...,
  ...,
         [0, 0, 1, ..., 0, 1, 1],
         [1, 1, 1, ..., 0, 1, 1],
         [1, 0, 1, ..., 1, 0, 0]]]], dtype=int64)

    def __call__(self, pred, target):
        from ...ivy.functional.frontends.torch.tensor import jax_dim_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_max_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_size_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_min_frnt_
    
        if jax_dim_frnt_(pred) != 4:
            raise ValueError(f"Only 2D images supported. Got {jax_dim_frnt_(pred)}.")
        if not (
            jax_max_frnt_(target) < jax_size_frnt_(pred, 1)
            and jax_min_frnt_(target) >= 0
            and target.dtype == jnp.int64
        ):
            raise ValueError(
                f"Expect long type target value in range (0, {jax_size_frnt_(pred, 1)}). ({jax_min_frnt_(target)}, {jax_max_frnt_(target)})"
            )
>       return super().__call__(pred, target)

ivy_transpiled_outputs/jax_outputs/kornia/losses/hausdorff.py:279: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_HausdorffERLoss()
pred = Array([[[[ 1.21370125e+00,  1.19621769e-01,  7.56473660e-01, ...,
          -6.13189638e-01, -3.12515795e-02, -3.05491...3795960e+00, -1.64430678e+00, ...,
           1.89253137e-01, -3.18794131e-01, -9.35967505e-01]]]],      dtype=float32)
target = Array([[[[0, 0, 0, ..., 1, 0, 1],
         [1, 0, 1, ..., 1, 1, 1],
         [0, 0, 1, ..., 0, 1, 1],
         ...,
  ...,
         [0, 0, 1, ..., 0, 1, 1],
         [1, 1, 1, ..., 0, 1, 1],
         [1, 0, 1, ..., 1, 0, 0]]]], dtype=int64)

    def __call__(self, pred, target):
        from ..core._backend import where
        from ..core._backend import stack
        from ..core._backend import tensor
        from ...ivy.functional.frontends.torch.tensor import jax_size_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_item_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_max_frnt_
        from ...ivy.functional.backends.jax.general import jax_get_item
        from ...ivy.functional.frontends.torch.tensor import jax_mean_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_sum_frnt_
    
        if not (
            jax_shape_frnt_(pred)[2:] == jax_shape_frnt_(target)[2:]
            and jax_size_frnt_(pred, 0) == jax_size_frnt_(target, 0)
            and jax_size_frnt_(target, 1) == 1
        ):
            raise ValueError(
                f"Prediction and target need to be of same size, and target should not be one-hot.Got {jax_shape_frnt_(pred)} and {jax_shape_frnt_(target)}."
            )
        if jax_size_frnt_(pred, 1) < jax_item_frnt_(jax_max_frnt_(target)):
            raise ValueError("Invalid target value.")
        out = stack(
>           [
                self.perform_erosion(
                    jax_get_item(
                        pred, (slice(None, None, None), slice(i, i + 1, None))
                    ),
                    where(
                        target == i,
                        tensor(1, device=target.device, dtype=target.dtype),
                        tensor(0, device=target.device, dtype=target.dtype),
                    ),
                )
                for i in range(jax_size_frnt_(pred, 1))
            ]
        )

ivy_transpiled_outputs/jax_outputs/kornia/losses/hausdorff.py:118: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

.0 = <range_iterator object at 0x7fd9a22f8f90>

        [
>           self.perform_erosion(
                jax_get_item(
                    pred, (slice(None, None, None), slice(i, i + 1, None))
                ),
                where(
                    target == i,
                    tensor(1, device=target.device, dtype=target.dtype),
                    tensor(0, device=target.device, dtype=target.dtype),
                ),
            )
            for i in range(jax_size_frnt_(pred, 1))
        ]
    )

ivy_transpiled_outputs/jax_outputs/kornia/losses/hausdorff.py:119: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_HausdorffERLoss()
pred = Array([[[[ 1.21370125e+00,  1.19621769e-01,  7.56473660e-01, ...,
          -6.13189638e-01, -3.12515795e-02, -3.05491...2319105e+00,  9.29546833e-01, ...,
          -2.60436237e-01,  4.18013521e-02,  1.29388750e+00]]]],      dtype=float32)
target = Array([[[[1, 1, 1, ..., 0, 1, 0],
         [0, 1, 0, ..., 0, 0, 0],
         [1, 1, 0, ..., 1, 0, 0],
         ...,
  ...,
         [1, 1, 0, ..., 1, 0, 0],
         [0, 0, 0, ..., 1, 0, 0],
         [0, 1, 0, ..., 0, 1, 1]]]], dtype=int64)

    def perform_erosion(self, pred, target):
        from ..core._backend import as_tensor
        from ..core._backend import zeros_like
        from ..core._backend import where
        from ...ivy.functional.frontends.torch.creation_ops import (
            jax_ones_like_v_0p4p0_and_above_frnt,
        )
        from ...ivy.functional.frontends.torch.tensor import jax_size_frnt_
        from ...ivy.functional.backends.jax.general import jax_set_item
        from ...ivy.functional.frontends.torch.tensor import jax_squeeze_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_any_frnt_
    
        bound = (pred - target) ** 2
        kernel = as_tensor(self.kernel, device=pred.device, dtype=pred.dtype)
        eroded = zeros_like(bound, device=pred.device, dtype=pred.dtype)
        mask = jax_ones_like_v_0p4p0_and_above_frnt(
            bound, device=pred.device, dtype=jnp.bool
        )
        padding = (jax_size_frnt_(kernel, -1) - 1) // 2
        for k in range(self.k):
>           dilation = self.conv(bound, weight=kernel, padding=padding, groups=1)
E           TypeError: jax_conv2d_frnt() got multiple values for argument 'weight'

ivy_transpiled_outputs/jax_outputs/kornia/losses/hausdorff.py:81: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.losses.HausdorffERLoss
________________________________________________________________________________ test_HausdorffERLoss3D[jax-s2s-False] _________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_HausdorffERLoss3D(target_framework, mode, backend_compile):
        print("kornia.losses.HausdorffERLoss3D")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledHausdorffERLoss3D = ivy.transpile(kornia.losses.HausdorffERLoss3D, source="torch", target=target_framework)
    
        torch_loss_fn = kornia.losses.HausdorffERLoss3D()
        transpiled_loss_fn = TranspiledHausdorffERLoss3D()
    
        torch_args = (
            torch.randn(5, 3, 20, 20, 20),
            (torch.rand(5, 1, 20, 20, 20) * 2).long(),
        )
        transpiled_args = _nest_torch_tensor_to_new_framework(torch_args, target_framework)
    
        torch_res = torch_loss_fn(*torch_args)
>       transpiled_res = transpiled_loss_fn(*transpiled_args)

kornia/test_losses.py:471: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_HausdorffERLoss3D()
pred = Array([[[[[ 6.95650280e-01, -2.01039028e+00,  7.07832038e-01, ...,
            3.45221817e-01,  4.21433359e-01,  1.077...16619e+00, -6.08188152e-01, ...,
            6.93994284e-01, -3.38663757e-01,  5.02468348e-02]]]]],      dtype=float32)
target = Array([[[[[1, 1, 0, ..., 1, 0, 1],
          [0, 1, 0, ..., 1, 1, 1],
          [0, 0, 0, ..., 1, 1, 0],
          ......        [1, 1, 0, ..., 0, 1, 0],
          [1, 0, 0, ..., 1, 0, 1],
          [0, 1, 0, ..., 0, 0, 0]]]]], dtype=int64)

    def __call__(self, pred, target):
        from ...ivy.functional.frontends.torch.tensor import jax_dim_frnt_
    
        if jax_dim_frnt_(pred) != 5:
            raise ValueError(f"Only 3D images supported. Got {jax_dim_frnt_(pred)}.")
>       return super().__call__(pred, target)

ivy_transpiled_outputs/jax_outputs/kornia/losses/hausdorff.py:270: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_HausdorffERLoss3D()
pred = Array([[[[[ 6.95650280e-01, -2.01039028e+00,  7.07832038e-01, ...,
            3.45221817e-01,  4.21433359e-01,  1.077...16619e+00, -6.08188152e-01, ...,
            6.93994284e-01, -3.38663757e-01,  5.02468348e-02]]]]],      dtype=float32)
target = Array([[[[[1, 1, 0, ..., 1, 0, 1],
          [0, 1, 0, ..., 1, 1, 1],
          [0, 0, 0, ..., 1, 1, 0],
          ......        [1, 1, 0, ..., 0, 1, 0],
          [1, 0, 0, ..., 1, 0, 1],
          [0, 1, 0, ..., 0, 0, 0]]]]], dtype=int64)

    def __call__(self, pred, target):
        from ..core._backend import where
        from ..core._backend import stack
        from ..core._backend import tensor
        from ...ivy.functional.frontends.torch.tensor import jax_size_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_item_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_max_frnt_
        from ...ivy.functional.backends.jax.general import jax_get_item
        from ...ivy.functional.frontends.torch.tensor import jax_mean_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_sum_frnt_
    
        if not (
            jax_shape_frnt_(pred)[2:] == jax_shape_frnt_(target)[2:]
            and jax_size_frnt_(pred, 0) == jax_size_frnt_(target, 0)
            and jax_size_frnt_(target, 1) == 1
        ):
            raise ValueError(
                f"Prediction and target need to be of same size, and target should not be one-hot.Got {jax_shape_frnt_(pred)} and {jax_shape_frnt_(target)}."
            )
        if jax_size_frnt_(pred, 1) < jax_item_frnt_(jax_max_frnt_(target)):
            raise ValueError("Invalid target value.")
        out = stack(
>           [
                self.perform_erosion(
                    jax_get_item(
                        pred, (slice(None, None, None), slice(i, i + 1, None))
                    ),
                    where(
                        target == i,
                        tensor(1, device=target.device, dtype=target.dtype),
                        tensor(0, device=target.device, dtype=target.dtype),
                    ),
                )
                for i in range(jax_size_frnt_(pred, 1))
            ]
        )

ivy_transpiled_outputs/jax_outputs/kornia/losses/hausdorff.py:118: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

.0 = <range_iterator object at 0x7fd9a09241b0>

        [
>           self.perform_erosion(
                jax_get_item(
                    pred, (slice(None, None, None), slice(i, i + 1, None))
                ),
                where(
                    target == i,
                    tensor(1, device=target.device, dtype=target.dtype),
                    tensor(0, device=target.device, dtype=target.dtype),
                ),
            )
            for i in range(jax_size_frnt_(pred, 1))
        ]
    )

ivy_transpiled_outputs/jax_outputs/kornia/losses/hausdorff.py:119: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_HausdorffERLoss3D()
pred = Array([[[[[ 6.95650280e-01, -2.01039028e+00,  7.07832038e-01, ...,
            3.45221817e-01,  4.21433359e-01,  1.077...63429e-01, -1.66031718e-01, ...,
           -7.90705800e-01,  2.90636212e-01,  6.47161186e-01]]]]],      dtype=float32)
target = Array([[[[[0, 0, 1, ..., 0, 1, 0],
          [1, 0, 1, ..., 0, 0, 0],
          [1, 1, 1, ..., 0, 0, 1],
          ......        [0, 0, 1, ..., 1, 0, 1],
          [0, 1, 1, ..., 0, 1, 0],
          [1, 0, 1, ..., 1, 1, 1]]]]], dtype=int64)

    def perform_erosion(self, pred, target):
        from ..core._backend import as_tensor
        from ..core._backend import zeros_like
        from ..core._backend import where
        from ...ivy.functional.frontends.torch.creation_ops import (
            jax_ones_like_v_0p4p0_and_above_frnt,
        )
        from ...ivy.functional.frontends.torch.tensor import jax_size_frnt_
        from ...ivy.functional.backends.jax.general import jax_set_item
        from ...ivy.functional.frontends.torch.tensor import jax_squeeze_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_any_frnt_
    
        bound = (pred - target) ** 2
        kernel = as_tensor(self.kernel, device=pred.device, dtype=pred.dtype)
        eroded = zeros_like(bound, device=pred.device, dtype=pred.dtype)
        mask = jax_ones_like_v_0p4p0_and_above_frnt(
            bound, device=pred.device, dtype=jnp.bool
        )
        padding = (jax_size_frnt_(kernel, -1) - 1) // 2
        for k in range(self.k):
>           dilation = self.conv(bound, weight=kernel, padding=padding, groups=1)
E           TypeError: jax_conv3d_frnt() got multiple values for argument 'weight'

ivy_transpiled_outputs/jax_outputs/kornia/losses/hausdorff.py:81: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.losses.HausdorffERLoss3D
__________________________________________________________________________________ test_TotalVariation[jax-s2s-False] __________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_TotalVariation(target_framework, mode, backend_compile):
        print("kornia.losses.TotalVariation")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledTotalVariation = ivy.transpile(kornia.losses.TotalVariation, source="torch", target=target_framework)
    
        torch_loss_fn = kornia.losses.TotalVariation()
        transpiled_loss_fn = TranspiledTotalVariation()
    
        torch_args = (
            torch.ones((2, 3, 4, 4)),
        )
        transpiled_args = _nest_torch_tensor_to_new_framework(torch_args, target_framework)
    
        torch_res = torch_loss_fn(*torch_args).data
>       transpiled_res = transpiled_loss_fn(*transpiled_args).data
E       AttributeError: 'jaxlib.xla_extension.ArrayImpl' object has no attribute 'data'

kornia/test_losses.py:570: AttributeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.losses.TotalVariation
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/test_losses.py::test_HausdorffERLoss[jax-s2s-False] - TypeError: jax_conv2d_frnt() got multiple values for argument 'weight'
FAILED kornia/test_losses.py::test_HausdorffERLoss3D[jax-s2s-False] - TypeError: jax_conv3d_frnt() got multiple values for argument 'weight'
FAILED kornia/test_losses.py::test_TotalVariation[jax-s2s-False] - AttributeError: 'jaxlib.xla_extension.ArrayImpl' object has no attribute 'data'
============================================================================== 3 failed, 32 passed in 2278.61s (0:37:58) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 6 items

kornia/test_nerf.py .FF..F                                                                                                                                                                       [100%]

=============================================================================================== FAILURES ===============================================================================================
_____________________________________________________________________________ test_NerfModelRenderer[tensorflow-s2s-False] _____________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_NerfModelRenderer(target_framework, mode, backend_compile):
        print("kornia.nerf.nerf_model.NerfModelRenderer")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledPinholeCamera = ivy.transpile(kornia.geometry.camera.pinhole.PinholeCamera, source="torch", target=target_framework)
        TranspiledNerfModel = ivy.transpile(nerf_model.NerfModel, source="torch", target=target_framework)
        TranspiledNerfModelRenderer = ivy.transpile(nerf_model.NerfModelRenderer, source="torch", target=target_framework)
    
        torch_nerf_model = nerf_model.NerfModel(num_ray_points=32)
        transpiled_nerf_model = TranspiledNerfModel(num_ray_points=32)
    
        torch_camera_args = (
            torch.rand(1, 4, 4),
            torch.rand(1, 4, 4),
            torch.tensor([256]),
            torch.tensor([256]),
        )
>       transpiled_camera_args = _nest_torch_tensor_to_new_framework(torch_camera_args)
E       TypeError: _nest_torch_tensor_to_new_framework() missing 1 required positional argument: 'target'

kornia/test_nerf.py:63: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.nerf.nerf_model.NerfModelRenderer
____________________________________________________________________________________ test_MLP[tensorflow-s2s-False] ____________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_MLP(target_framework, mode, backend_compile):
        print("kornia.nerf.nerf_model.MLP")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledMLP = ivy.transpile(nerf_model.MLP, source="torch", target=target_framework)
    
        torch_args = (
            torch.rand(5, 3),
        )
        transpiled_args = _nest_torch_tensor_to_new_framework(torch_args, target_framework)
    
        torch_mlp = nerf_model.MLP(num_dims=3)
        transpiled_mlp = TranspiledMLP(num_dims=3)
    
        torch_out = torch_mlp(*torch_args)
>       transpiled_out = transpiled_mlp(*transpiled_args)

kornia/test_nerf.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_MLP(
  (_mlp): tensorflow_ModuleList(
    (0-7): 8 x tensorflow_Sequential(
      (0): KerasDense()
      (1): tensorflow_ReLU()
    )
  )
)
args = (<tf.Tensor: shape=(5, 3), dtype=float32, numpy=
array([[0.99466026, 0.04579037, 0.0993588 ],
       [0.23921704, 0.95...304515  ],
       [0.39345646, 0.503147  , 0.7791169 ],
       [0.5150622 , 0.77496874, 0.17296743]], dtype=float32)>,)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x7f6809bc5b70, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...ode_context=['        return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)\n'], index=0), ...]

>   ???

/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_MLP(
  (_mlp): tensorflow_ModuleList(
    (0-7): 8 x tensorflow_Sequential(
      (0): KerasDense()
      ....304515  ],
       [0.39345646, 0.503147  , 0.7791169 ],
       [0.5150622 , 0.77496874, 0.17296743]], dtype=float32)>)
kwargs = {}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_MLP(
  (_mlp): tensorflow_ModuleList(
    (0-7): 8 x tensorflow_Sequential(
      (0): KerasDense()
      (1): tensorflow_ReLU()
    )
  )
), v = None, buffers = None
args = (<tf.Tensor: shape=(5, 3), dtype=float32, numpy=
array([[0.99466026, 0.04579037, 0.0993588 ],
       [0.23921704, 0.95...304515  ],
       [0.39345646, 0.503147  , 0.7791169 ],
       [0.5150622 , 0.77496874, 0.17296743]], dtype=float32)>,)
kwargs = {}

>   ???

/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_MLP(
  (_mlp): tensorflow_ModuleList(
    (0-7): 8 x tensorflow_Sequential(
      (0): KerasDense()
      ....304515  ],
       [0.39345646, 0.503147  , 0.7791169 ],
       [0.5150622 , 0.77496874, 0.17296743]], dtype=float32)>)
kwargs = {'buffers': None, 'v': None}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_MLP(
  (_mlp): tensorflow_ModuleList(
    (0-7): 8 x tensorflow_Sequential(
      (0): KerasDense()
      (1): tensorflow_ReLU()
    )
  )
), v = None, buffers = None
args = (<tf.Tensor: shape=(5, 3), dtype=float32, numpy=
array([[0.99466026, 0.04579037, 0.0993588 ],
       [0.23921704, 0.95...304515  ],
       [0.39345646, 0.503147  , 0.7791169 ],
       [0.5150622 , 0.77496874, 0.17296743]], dtype=float32)>,)
kwargs = {}
first_arr = <tf.Tensor: shape=(5, 3), dtype=float32, numpy=
array([[0.99466026, 0.04579037, 0.0993588 ],
       [0.23921704, 0.952...0.304515  ],
       [0.39345646, 0.503147  , 0.7791169 ],
       [0.5150622 , 0.77496874, 0.17296743]], dtype=float32)>
replace_v = False, replace_buffers = False, call_signature = <Signature (x)>

>   ???

/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_MLP(
  (_mlp): tensorflow_ModuleList(
    (0-7): 8 x tensorflow_Sequential(
      (0): KerasDense()
      (1): tensorflow_ReLU()
    )
  )
),)
kwargs = {'x': <tf.Tensor: shape=(5, 3), dtype=float32, numpy=
array([[0.99466026, 0.04579037, 0.0993588 ],
       [0.23921704,....304515  ],
       [0.39345646, 0.503147  , 0.7791169 ],
       [0.5150622 , 0.77496874, 0.17296743]], dtype=float32)>}

    @wraps(fn)
    def error_handler(*args, **kwargs):
        if not is_traceback_filtering_enabled():
            return fn(*args, **kwargs)
    
        filtered_tb = None
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            filtered_tb = _process_traceback_frames(e.__traceback__)
            # To get the full stack trace, call:
            # `keras.config.disable_traceback_filtering()`
>           raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/keras/src/utils/traceback_utils.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_MLP(
  (_mlp): tensorflow_ModuleList(
    (0-7): 8 x tensorflow_Sequential(
      (0): KerasDense()
      (1): tensorflow_ReLU()
    )
  )
)
x = <tf.Tensor: shape=(5, 3), dtype=float32, numpy=
array([[0.99466026, 0.04579037, 0.0993588 ],
       [0.23921704, 0.952...0.304515  ],
       [0.39345646, 0.503147  , 0.7791169 ],
       [0.5150622 , 0.77496874, 0.17296743]], dtype=float32)>

>   ???

/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/kornia/nerf/nerf_model.py:77: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Sequential(
  (0): KerasDense()
  (1): tensorflow_ReLU()
)
args = (<tf.Tensor: shape=(5, 3), dtype=float32, numpy=
array([[0.99466026, 0.04579037, 0.0993588 ],
       [0.23921704, 0.95...304515  ],
       [0.39345646, 0.503147  , 0.7791169 ],
       [0.5150622 , 0.77496874, 0.17296743]], dtype=float32)>,)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x557690c06ac0, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...function='__call__', code_context=['                    outputs = super().__call__(*args, **kwargs)\n'], index=0), ...]

>   ???

/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Sequential(
  (0): KerasDense()
  (1): tensorflow_ReLU()
), v = None, buffers = None
args = (<tf.Tensor: shape=(5, 3), dtype=float32, numpy=
array([[0.99466026, 0.04579037, 0.0993588 ],
       [0.23921704, 0.95...304515  ],
       [0.39345646, 0.503147  , 0.7791169 ],
       [0.5150622 , 0.77496874, 0.17296743]], dtype=float32)>,)
kwargs = {}

>   ???

/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Sequential(
  (0): KerasDense()
  (1): tensorflow_ReLU()
), v = None, buffers = None
args = (<tf.Tensor: shape=(5, 3), dtype=float32, numpy=
array([[0.99466026, 0.04579037, 0.0993588 ],
       [0.23921704, 0.95...304515  ],
       [0.39345646, 0.503147  , 0.7791169 ],
       [0.5150622 , 0.77496874, 0.17296743]], dtype=float32)>,)
kwargs = {}
first_arr = <tf.Tensor: shape=(5, 3), dtype=float32, numpy=
array([[0.99466026, 0.04579037, 0.0993588 ],
       [0.23921704, 0.952...0.304515  ],
       [0.39345646, 0.503147  , 0.7791169 ],
       [0.5150622 , 0.77496874, 0.17296743]], dtype=float32)>
replace_v = False, replace_buffers = False, call_signature = <Signature (input)>

>   ???

/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Sequential(
  (0): KerasDense()
  (1): tensorflow_ReLU()
)
input = <tf.Tensor: shape=(5, 128), dtype=float32, numpy=
array([[-1.31898582e-01, -7.98799321e-02, -3.67182083e-02,
        -...
         4.87492941e-02, -7.84049183e-02,  1.54328868e-01,
         1.41416088e-01, -1.53635457e-01]], dtype=float32)>

>   ???

/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/torch/nn/modules/container.py:199: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_ReLU()
args = (<tf.Tensor: shape=(5, 128), dtype=float32, numpy=
array([[-1.31898582e-01, -7.98799321e-02, -3.67182083e-02,
        ...        4.87492941e-02, -7.84049183e-02,  1.54328868e-01,
         1.41416088e-01, -1.53635457e-01]], dtype=float32)>,)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x7f680a1efa60, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...function='__call__', code_context=['                    outputs = super().__call__(*args, **kwargs)\n'], index=0), ...]

>   ???

/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_ReLU(), v = None, buffers = None
args = (<tf.Tensor: shape=(5, 128), dtype=float32, numpy=
array([[-1.31898582e-01, -7.98799321e-02, -3.67182083e-02,
        ...        4.87492941e-02, -7.84049183e-02,  1.54328868e-01,
         1.41416088e-01, -1.53635457e-01]], dtype=float32)>,)
kwargs = {}

>   ???

/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_ReLU(), v = None, buffers = None
args = (<tf.Tensor: shape=(5, 128), dtype=float32, numpy=
array([[-1.31898582e-01, -7.98799321e-02, -3.67182083e-02,
        ...        4.87492941e-02, -7.84049183e-02,  1.54328868e-01,
         1.41416088e-01, -1.53635457e-01]], dtype=float32)>,)
kwargs = {}
first_arr = <tf.Tensor: shape=(5, 128), dtype=float32, numpy=
array([[-1.31898582e-01, -7.98799321e-02, -3.67182083e-02,
        -...
         4.87492941e-02, -7.84049183e-02,  1.54328868e-01,
         1.41416088e-01, -1.53635457e-01]], dtype=float32)>
replace_v = False, replace_buffers = False, call_signature = <Signature (input)>

>   ???

/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_ReLU(), args = ()
kwargs = {'input': <tf.Tensor: shape=(5, 128), dtype=float32, numpy=
array([[-1.31898582e-01, -7.98799321e-02, -3.67182083e-02,...         4.87492941e-02, -7.84049183e-02,  1.54328868e-01,
         1.41416088e-01, -1.53635457e-01]], dtype=float32)>}
tensorflow_get_item = <function tensorflow_get_item at 0x7f6809126050>, tensorflow_set_item = <function tensorflow_set_item at 0x7f6809126200>, DATA_FORMAT = 'channels_first'
fn_args_and_kwargs = {'input': <tf.Tensor: shape=(5, 128), dtype=float32, numpy=
array([[-1.31898582e-01, -7.98799321e-02, -3.67182083e-02,...         4.87492941e-02, -7.84049183e-02,  1.54328868e-01,
         1.41416088e-01, -1.53635457e-01]], dtype=float32)>}
conv_block_start = <function tensorflow_handle_transpose_in_input_and_output.<locals>.transpose_wrapper.<locals>.<lambda> at 0x7f6809eb0700>

>   ???

/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:387: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

obj = tensorflow_ReLU()

>   ???

/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:315: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

object = <frame at 0x55768fd84850, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/kornia/nerf/nerf_model.py', line 77, code call>

    def getsourcelines(object):
        """Return a list of source lines and starting line number for an object.
    
        The argument may be a module, class, method, function, traceback, frame,
        or code object.  The source code is returned as a list of the lines
        corresponding to the object and the line number indicates where in the
        original source file the first line of code was found.  An OSError is
        raised if the source code cannot be retrieved."""
        object = unwrap(object)
>       lines, lnum = findsource(object)

/opt/miniconda/envs/multienv/lib/python3.10/inspect.py:1129: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

object = <frame at 0x55768fd84850, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/kornia/nerf/nerf_model.py', line 77, code call>

    def findsource(object):
        """Return the entire source file and starting line number for an object.
    
        The argument may be a module, class, method, function, traceback, frame,
        or code object.  The source code is returned as a list of all the lines
        in the file and the line number indexes a line in that list.  An OSError
        is raised if the source code cannot be retrieved."""
    
        file = getsourcefile(object)
        if file:
            # Invalidate cache if needed.
            linecache.checkcache(file)
        else:
            file = getfile(object)
            # Allow filenames in form of "<something>" to pass through.
            # `doctest` monkeypatches `linecache` module to enable
            # inspection, so let `linecache.getlines` to be called.
            if not (file.startswith('<') and file.endswith('>')):
                raise OSError('source code not available')
    
        module = getmodule(object, file)
        if module:
            lines = linecache.getlines(file, module.__dict__)
        else:
            lines = linecache.getlines(file)
        if not lines:
>           raise OSError('could not get source code')
E           OSError: Exception encountered when calling tensorflow_ReLU.call().
E           
E           [1mcould not get source code[0m
E           
E           Arguments received by tensorflow_ReLU.call():
E              input=tf.Tensor(shape=(5, 128), dtype=float32)

/opt/miniconda/envs/multienv/lib/python3.10/inspect.py:958: OSError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.nerf.nerf_model.MLP
_____________________________________________________________________________ test_RandomRaySampler[tensorflow-s2s-False] ______________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_RandomRaySampler(target_framework, mode, backend_compile):
        print("kornia.nerf.samplers.RandomRaySampler")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledPinholeCamera = ivy.transpile(kornia.geometry.camera.pinhole.PinholeCamera, source="torch", target=target_framework)
        TranspiledRandomRaySampler = ivy.transpile(samplers.RandomRaySampler, source="torch", target=target_framework)
    
        torch_camera_args = (
            torch.rand(1, 4, 4),
            torch.rand(1, 4, 4),
            torch.tensor([256]),
            torch.tensor([256]),
        )
        transpiled_camera_args = _nest_torch_tensor_to_new_framework(torch_camera_args, target_framework)
    
        torch_camera = kornia.geometry.camera.pinhole.PinholeCamera(*torch_camera_args)
        transpiled_camera = TranspiledPinholeCamera(*transpiled_camera_args)
    
        heights, widths = torch.tensor([256]), torch.tensor([256])
        transpiled_heights = _array_to_new_backend(heights, target_framework)
        transpiled_widths = _array_to_new_backend(widths, target_framework)
    
        torch_sampler = samplers.RandomRaySampler(min_depth=0.1, max_depth=10.0, ndc=True, device="cpu", dtype=torch.float32)
        transpiled_sampler = TranspiledRandomRaySampler(min_depth=0.1, max_depth=10.0, ndc=True, device="cpu", dtype=torch.float32)
    
        torch_sampler.calc_ray_params(torch_camera, torch.tensor([1]))
>       transpiled_sampler.calc_ray_params(transpiled_camera, _array_to_new_backend(torch.tensor([1]), target_framework))

kornia/test_nerf.py:250: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <ivy_transpiled_outputs.tensorflow_outputs.kornia.nerf.samplers.tensorflow_RandomRaySampler object at 0x7f6808856d10>
cameras = <ivy_transpiled_outputs.tensorflow_outputs.kornia.geometry.camera.pinhole.tensorflow_PinholeCamera object at 0x7f6808856200>
num_img_rays = <tf.Tensor: shape=(1,), dtype=int64, numpy=array([1])>

    def calc_ray_params(self, cameras, num_img_rays):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
    
        num_cams = cameras.batch_size
        if num_cams != tensorflow_shape_frnt_(num_img_rays)[0]:
            raise ValueError(
                f"Number of cameras {num_cams} does not match size of tensor to define number of rays to march from each camera {tensorflow_shape_frnt_(num_img_rays)[0]}"
            )
>       points_2d_camera = self.sample_points_2d(
            cameras.height, cameras.width, num_img_rays
        )

ivy_transpiled_outputs/tensorflow_outputs/kornia/nerf/samplers.py:384: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <ivy_transpiled_outputs.tensorflow_outputs.kornia.nerf.samplers.tensorflow_RandomRaySampler object at 0x7f6808856d10>, heights = <tf.Tensor: shape=(1,), dtype=int64, numpy=array([256])>
widths = <tf.Tensor: shape=(1,), dtype=int64, numpy=array([256])>, num_img_rays = <tf.Tensor: shape=(1,), dtype=int32, numpy=array([1], dtype=int32)>

    def sample_points_2d(self, heights, widths, num_img_rays):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_int_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_tolist_frnt_
        from ...ivy.functional.frontends.torch.pointwise_ops import (
            tensorflow_trunc_frnt,
        )
        from ...ivy.functional.frontends.torch.random_sampling import (
            tensorflow_rand_frnt,
        )
    
        num_img_rays = tensorflow_int_frnt_(num_img_rays)
        points2d_as_flat_tensors: typing.Any = {}
        for camera_id, (height, width, n) in enumerate(
            zip(
                tensorflow_tolist_frnt_(heights),
                tensorflow_tolist_frnt_(widths),
                tensorflow_tolist_frnt_(num_img_rays),
            )
        ):
            y_rand = tensorflow_trunc_frnt(
>               tensorflow_rand_frnt(n, device=self._device, dtype=self._dtype) * height
            )

ivy_transpiled_outputs/tensorflow_outputs/kornia/nerf/samplers.py:364: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

generator = None, out = None, dtype = torch.float32, layout = None, device = 'cpu', requires_grad = False, pin_memory = False, size = (1,), kwargs = {}
tensorflow_random_uniform = <function tensorflow_random_uniform at 0x7f680820eb00>, seed = None

    def tensorflow_rand_frnt(
        *size,
        generator=None,
        out=None,
        dtype=None,
        layout=None,
        device=None,
        requires_grad=False,
        pin_memory=False,
        **kwargs,
    ):
        from ...backends.tensorflow.random import tensorflow_random_uniform
    
        if not size and "size" not in kwargs:
            raise ValueError("Missing 1 required positional/keyword argument: size")
        size = size if size else kwargs["size"]
        if (
            isinstance(size, (list, tuple))
            and len(size) == 1
            and isinstance(size[0], (list, tuple, tuple))
        ):
            size = size[0]
        seed = generator.initial_seed() if generator is not None else None
>       return tensorflow_random_uniform(
            shape=size, seed=seed, out=out, dtype=dtype, device=device
        )

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/random_sampling.py:55: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype = torch.float32, args = (), kwargs = {'device': 'cpu', 'out': None, 'seed': None, 'shape': (1,)}, tensorflow_exists_bknd = <function tensorflow_exists_bknd at 0x7f680819d000>
tensorflow_default_dtype_bknd = <function tensorflow_default_dtype_bknd at 0x7f680819c670>, arr = None

    @functools.wraps(fn)
    def _infer_dtype(*args, dtype=None, **kwargs):
        from .functional.ivy.general import tensorflow_exists_bknd
        from .functional.ivy.data_type import tensorflow_default_dtype_bknd
    
        arr = (
            None
            if tensorflow_exists_bknd(dtype)
            else tensorflow__get_first_array(*args, **kwargs)
        )
        dtype = tensorflow_default_dtype_bknd(dtype=dtype, item=arr, as_native=True)
>       return fn(*args, dtype=dtype, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/func_wrapper.py:157: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    @tensorflow_infer_dtype
    def tensorflow_random_uniform(
        *,
        low: Union[float, tensorflow.Tensor, tensorflow.Variable] = 0.0,
        high: Union[float, tensorflow.Tensor, tensorflow.Variable, None] = 1.0,
        shape: Optional[Union[tf.TensorShape, Sequence[int], tensorflow.Tensor]] = None,
        dtype: tf.DType,
        device: Optional[str] = None,
        seed: Optional[int] = None,
        out: Optional[Union[tensorflow.Tensor, tensorflow.Variable]] = None,
    ):
        from ...ivy.random import tensorflow__check_bounds_and_get_shape_bknd
    
        shape = tensorflow__check_bounds_and_get_shape_bknd(
            low,
            float(
                tensorflow.experimental.numpy.finfo(tensorflow.float32).max
                if dtype is None
                else tensorflow.experimental.numpy.finfo(dtype).max
            )
            if high is None
            else high,
            shape,
        )
>       low = tensorflow.cast(low, dtype)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/backends/tensorflow/random.py:61: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (0.0, torch.float32), kwargs = {}

    def error_handler(*args, **kwargs):
      try:
        if not is_traceback_filtering_enabled():
          return fn(*args, **kwargs)
      except NameError:
        # In some very rare cases,
        # `is_traceback_filtering_enabled` (from the outer scope) may not be
        # accessible from inside this function
        return fn(*args, **kwargs)
    
      filtered_tb = None
      try:
        return fn(*args, **kwargs)
      except Exception as e:
        filtered_tb = _process_traceback_frames(e.__traceback__)
>       raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/tensorflow/python/util/traceback_utils.py:153: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

type_value = torch.float32

    @tf_export("dtypes.as_dtype", "as_dtype")
    def as_dtype(type_value):
      """Converts the given `type_value` to a `tf.DType`.
    
      Inputs can be existing `tf.DType` objects, a [`DataType`
      enum](https://www.tensorflow.org/code/tensorflow/core/framework/types.proto),
      a string type name, or a
      [`numpy.dtype`](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html).
    
      Examples:
      >>> tf.as_dtype(2)  # Enum value for float64.
      tf.float64
    
      >>> tf.as_dtype('float')
      tf.float32
    
      >>> tf.as_dtype(np.int32)
      tf.int32
    
      Note: `DType` values are interned (i.e. a single instance of each dtype is
      stored in a map). When passed a new `DType` object, `as_dtype` always returns
      the interned value.
    
      Args:
        type_value: A value that can be converted to a `tf.DType` object.
    
      Returns:
        A `DType` corresponding to `type_value`.
    
      Raises:
        TypeError: If `type_value` cannot be converted to a `DType`.
      """
      if isinstance(type_value, DType):
        if type_value._handle_data is None:  # pylint:disable=protected-access
          return _INTERN_TABLE[type_value.as_datatype_enum]
        else:
          return type_value
    
      if isinstance(type_value, np.dtype):
        try:
          return _NP_TO_TF[type_value.type]
        except KeyError:
          pass
    
      try:
        return _ANY_TO_TF[type_value]
      except (KeyError, TypeError):
        # TypeError indicates that type_value is not hashable.
        pass
    
      if hasattr(type_value, "dtype"):
        try:
          return _NP_TO_TF[np.dtype(type_value.dtype).type]
        except (KeyError, TypeError):
          pass
    
      if isinstance(type_value, _dtypes.DType):
        return _INTERN_TABLE[type_value.as_datatype_enum]
    
>     raise TypeError(f"Cannot convert the argument `type_value`: {type_value!r} "
                      "to a TensorFlow DType.")
E     TypeError: Cannot convert the argument `type_value`: torch.float32 to a TensorFlow DType.

/opt/fw/tensorflow/tensorflow/python/framework/dtypes.py:852: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.nerf.samplers.RandomRaySampler
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/test_nerf.py::test_NerfModelRenderer[tensorflow-s2s-False] - TypeError: _nest_torch_tensor_to_new_framework() missing 1 required positional argument: 'target'
FAILED kornia/test_nerf.py::test_MLP[tensorflow-s2s-False] - OSError: Exception encountered when calling tensorflow_ReLU.call().
FAILED kornia/test_nerf.py::test_RandomRaySampler[tensorflow-s2s-False] - TypeError: Cannot convert the argument `type_value`: torch.float32 to a TensorFlow DType.
=============================================================================== 3 failed, 3 passed in 358.63s (0:05:58) ================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 17 items

kornia/test_feature2.py .......F.....F...                                                                                                                                                        [100%]

=============================================================================================== FAILURES ===============================================================================================
____________________________________________________________________________ test_laf_is_inside_image[tensorflow-s2s-False] ____________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_laf_is_inside_image(target_framework, mode, backend_compile):
        trace_args = (
            torch.rand(1, 5, 2, 3),
            torch.rand(1, 1, 32, 32),
        )
        trace_kwargs = {'border': 0}
        test_args = (
            torch.rand(2, 10, 2, 3),
            torch.rand(2, 1, 64, 64),
        )
        test_kwargs = {'border': 1}
>       _test_function(
            kornia.feature.laf_is_inside_image,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/test_feature2.py:192: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function laf_is_inside_image at 0x7fdcb9e425f0>
trace_args = (tensor([[[[0.5652, 0.9421, 0.4894],
          [0.0100, 0.6599, 0.7138]],

         [[0.9699, 0.9092, 0.4341],
       ...3, 0.4987, 0.3475,  ..., 0.5067, 0.8775, 0.7466],
          [0.9555, 0.7735, 0.0718,  ..., 0.6434, 0.5646, 0.6299]]]]))
trace_kwargs = {'border': 0}
test_args = (tensor([[[[0.0430, 0.3250, 0.0326],
          [0.8564, 0.3824, 0.8533]],

         [[0.2033, 0.2844, 0.8573],
       ...0, 0.0755, 0.9495,  ..., 0.8560, 0.7340, 0.9270],
          [0.3853, 0.5338, 0.3207,  ..., 0.4299, 0.1548, 0.1651]]]]))
test_kwargs = {'border': 1}, target = 'tensorflow', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function laf_is_inside_image at 0x7fdcb9e425f0>, fn_name = 'kornia.feature.laf_is_inside_image'
trace_args = (tensor([[[[0.5652, 0.9421, 0.4894],
          [0.0100, 0.6599, 0.7138]],

         [[0.9699, 0.9092, 0.4341],
       ...3, 0.4987, 0.3475,  ..., 0.5067, 0.8775, 0.7466],
          [0.9555, 0.7735, 0.0718,  ..., 0.6434, 0.5646, 0.6299]]]]))
trace_kwargs = {'border': 0}
test_args = (tensor([[[[0.0430, 0.3250, 0.0326],
          [0.8564, 0.3824, 0.8533]],

         [[0.2033, 0.2844, 0.8573],
       ...0, 0.0755, 0.9495,  ..., 0.8560, 0.7340, 0.9270],
          [0.3853, 0.5338, 0.3207,  ..., 0.4299, 0.1548, 0.1651]]]]))
test_kwargs = {'border': 1}, target = 'tensorflow', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
>           graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:326: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

laf = <tf.Tensor: shape=(1, 5, 2, 3), dtype=float32, numpy=
array([[[[0.5651897 , 0.9420623 , 0.48940527],
         [0.01000...94]],

        [[0.47653425, 0.10419363, 0.8260713 ],
         [0.6194245 , 0.35478973, 0.6503368 ]]]], dtype=float32)>
images = <tf.Tensor: shape=(1, 1, 32, 32), dtype=float32, numpy=
array([[[[0.5556637 , 0.4534062 , 0.31049323, ..., 0.5859555 ,...],
         [0.95550793, 0.77352786, 0.07176083, ..., 0.6434414 ,
          0.56461304, 0.6299235 ]]]], dtype=float32)>
border = 0

    def tensorflow_laf_is_inside_image(laf, images, border=0):
        from ..core.check import tensorflow_KORNIA_CHECK_LAF
        from ...ivy.functional.frontends.torch.tensor import tensorflow_size_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_min_frnt_
    
        tensorflow_KORNIA_CHECK_LAF(laf)
        _, _, h, w = tensorflow_size_frnt_(images)
        pts = tensorflow_laf_to_boundary_points(laf, 12)
        good_lafs_mask = (
>           (pts[..., 0] >= border)
            * (pts[..., 0] <= w - border)
            * (pts[..., 1] >= border)
            * (pts[..., 1] <= h - border)
        )

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/laf.py:105: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <tf.Tensor: shape=(1, 5, 12), dtype=bool, numpy=
array([[[ True,  True,  True,  True,  True,  True, False, False, Fals...True,  True],
        [ True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True]]])>
rhs = <tf.Tensor: shape=(1, 5, 12), dtype=bool, numpy=
array([[[ True,  True,  True,  True,  True,  True,  True,  True,  Tru...True,  True],
        [ True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True]]])>

    def impl(self, rhs):
        try:
            return original_method(self, rhs)
        except Exception:
>           return patched_method(self, rhs)

ivy_transpiled_outputs/tensorflow_outputs/__init__.py:65: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = <tf.Tensor: shape=(1, 5, 12), dtype=bool, numpy=
array([[[ True,  True,  True,  True,  True,  True, False, False, Fals...True,  True],
        [ True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True]]])>
other = <tf.Tensor: shape=(1, 5, 12), dtype=bool, numpy=
array([[[ True,  True,  True,  True,  True,  True,  True,  True,  Tru...True,  True],
        [ True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True]]])>

    def tensorflow___mul___frnt_(tensor, other):
        from .pointwise_ops import tensorflow_mul_frnt
    
>       return tensorflow_mul_frnt(tensor, other)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/tensor.py:93: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = <tf.Tensor: shape=(1, 5, 12), dtype=bool, numpy=
array([[[ True,  True,  True,  True,  True,  True, False, False, Fals...True,  True],
        [ True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True]]])>
other = <tf.Tensor: shape=(1, 5, 12), dtype=bool, numpy=
array([[[ True,  True,  True,  True,  True,  True,  True,  True,  Tru...True,  True],
        [ True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True]]])>

    def tensorflow_mul_frnt(input, other, *, out=None):
        from .__init__ import tensorflow_promote_types_of_torch_inputs_frnt
        from ...backends.tensorflow.elementwise import tensorflow_multiply
    
        input, other = tensorflow_promote_types_of_torch_inputs_frnt(input, other)
>       return tensorflow_multiply(input, other, out=out)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/pointwise_ops.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x1 = <tf.Tensor: shape=(1, 5, 12), dtype=bool, numpy=
array([[[ True,  True,  True,  True,  True,  True, False, False, Fals...True,  True],
        [ True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True]]])>
x2 = <tf.Tensor: shape=(1, 5, 12), dtype=bool, numpy=
array([[[ True,  True,  True,  True,  True,  True,  True,  True,  Tru...True,  True],
        [ True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True]]])>

    def tensorflow_multiply(
        x1: Union[float, tensorflow.Tensor, tensorflow.Variable],
        x2: Union[float, tensorflow.Tensor, tensorflow.Variable],
        /,
        *,
        out: Optional[Union[tensorflow.Tensor, tensorflow.Variable]] = None,
    ):
        from ...ivy.data_type import tensorflow_promote_types_of_inputs_bknd
    
        x1, x2 = tensorflow_promote_types_of_inputs_bknd(x1, x2)
>       return tensorflow.math.multiply(x1, x2)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/backends/tensorflow/elementwise.py:151: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (<tf.Tensor: shape=(1, 5, 12), dtype=bool, numpy=
array([[[ True,  True,  True,  True,  True,  True, False, False, Fal...rue,  True],
        [ True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True]]])>)
kwargs = {}

    def wrapper(*args, **kwargs):
      if not ops.is_auto_dtype_conversion_enabled():
>       return op(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/ops/weak_tensor_ops.py:142: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (<tf.Tensor: shape=(1, 5, 12), dtype=bool, numpy=
array([[[ True,  True,  True,  True,  True,  True, False, False, Fal...rue,  True],
        [ True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True]]])>)
kwargs = {}

    def error_handler(*args, **kwargs):
      try:
        if not is_traceback_filtering_enabled():
          return fn(*args, **kwargs)
      except NameError:
        # In some very rare cases,
        # `is_traceback_filtering_enabled` (from the outer scope) may not be
        # accessible from inside this function
        return fn(*args, **kwargs)
    
      filtered_tb = None
      try:
        return fn(*args, **kwargs)
      except Exception as e:
        filtered_tb = _process_traceback_frames(e.__traceback__)
>       raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/tensorflow/python/util/traceback_utils.py:153: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

e = _NotOkStatusException(), name = None

    def raise_from_not_ok_status(e, name) -> NoReturn:
      e.message += (" name: " + str(name if name is not None else ""))
>     raise core._status_to_exception(e) from None  # pylint: disable=protected-access
E     tensorflow.python.framework.errors_impl.InvalidArgumentError: Value for attr 'T' of bool is not in the list of allowed values: bfloat16, half, float, double, uint8, int8, uint16, int16, int32, uint32, uint64, int64, complex64, complex128
E     	; NodeDef: {{node Mul}}; Op<name=Mul; signature=x:T, y:T -> z:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE, DT_UINT8, DT_INT8, DT_UINT16, DT_INT16, DT_INT32, DT_UINT32, DT_UINT64, DT_INT64, DT_COMPLEX64, DT_COMPLEX128]; is_commutative=true> [Op:Mul] name:

/opt/fw/tensorflow/tensorflow/python/framework/ops.py:5983: InvalidArgumentError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.laf.laf_is_inside_image
_______________________________________________________________________________ test_MKDDescriptor[tensorflow-s2s-False] _______________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_MKDDescriptor(target_framework, mode, backend_compile):
        print("kornia.feature.MKDDescriptor")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledMKDDescriptor = ivy.transpile(kornia.feature.MKDDescriptor, source="torch", target=target_framework)
    
        x = torch.rand(23, 1, 32, 32)
        transpiled_x = _nest_torch_tensor_to_new_framework(x, target_framework)
    
        model = kornia.feature.MKDDescriptor()
        torch_out = model(x)
    
>       transpiled_model = TranspiledMKDDescriptor()

kornia/test_feature2.py:339: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'tensorflow_MKDDescriptor' object has no attribute 'output_dims'") raised in repr()] tensorflow_MKDDescriptor object at 0x7fdc41fd5720>, patch_size = 32
kernel_type = 'concat', whitening = 'pcawt', training_set = 'liberty', output_dims = 128

    def __init__(
        self,
        patch_size=32,
        kernel_type="concat",
        whitening="pcawt",
        training_set="liberty",
        output_dims=128,
    ):
        from ..filters.gaussian import tensorflow_GaussianBlur2d
        from ...ivy.functional.backends.tensorflow.general import tensorflow_get_item
        from ...ivy.functional.backends.tensorflow.general import tensorflow_set_item
        from ...torch.nn.modules.container import tensorflow_Sequential
        from ...ivy.functional.frontends.torch.hub.hub import (
            tensorflow_load_state_dict_from_url_frnt,
        )
        from ..utils.helpers import tensorflow_map_location_to_cpu
    
        self.super___init__(
            patch_size=patch_size,
            kernel_type=kernel_type,
            whitening=whitening,
            training_set=training_set,
            output_dims=output_dims,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        self.patch_size: typing.Any = patch_size
        self.kernel_type: typing.Any = kernel_type
        self.whitening: typing.Any = whitening
        self.training_set: typing.Any = training_set
        self.sigma = 1.4 * (patch_size / 64)
        self.smoothing = tensorflow_GaussianBlur2d(
            (5, 5), (self.sigma, self.sigma), "replicate"
        )
        self.gradients = tensorflow_MKDGradients()
        polar_s: typing.Any = "polar"
        cart_s: typing.Any = "cart"
        self.parametrizations = (
            [polar_s, cart_s] if self.kernel_type == "concat" else [self.kernel_type]
        )
        self.odims: typing.Any = 0
        relative_orientations = {polar_s: True, cart_s: False}
        self.feats = {}
        for parametrization in self.parametrizations:
            gradient_embedding = tensorflow_EmbedGradients(
                patch_size=patch_size,
                relative=tensorflow_get_item(relative_orientations, parametrization),
            )
>           spatial_encoding = tensorflow_ExplicitSpacialEncoding(
                kernel_type=parametrization,
                fmap_size=patch_size,
                in_dims=gradient_embedding.kernel.d,
            )

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/mkd.py:991: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'tensorflow_ExplicitSpacialEncoding' object has no attribute 'out_dims'") raised in repr()] tensorflow_ExplicitSpacialEncoding object at 0x7fdc48c13ca0>, args = ()
kwargs = {'fmap_size': 32, 'in_dims': 7, 'kernel_type': 'polar'}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'tensorflow_ExplicitSpacialEncoding' object has no attribute 'out_dims'") raised in repr()] tensorflow_ExplicitSpacialEncoding object at 0x7fdc48c13ca0>, kernel_type = 'polar'
fmap_size = 32, in_dims = 7, do_gmask = True, do_l2 = True

    @tensorflow_store_config_info
    def __init__(
        self, kernel_type="polar", fmap_size=32, in_dims=7, do_gmask=True, do_l2=True
    ):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_unsqueeze_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
    
        self.super___init__(
            kernel_type=kernel_type,
            fmap_size=fmap_size,
            in_dims=in_dims,
            do_gmask=do_gmask,
            do_l2=do_l2,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        if kernel_type not in ["polar", "cart"]:
            raise NotImplementedError(
                f"{kernel_type} is not valid, use polar or cart)."
            )
        self.kernel_type = kernel_type
        self.fmap_size = fmap_size
        self.in_dims = in_dims
        self.do_gmask = do_gmask
        self.do_l2 = do_l2
        self.grid = tensorflow_get_grid_dict(fmap_size)
        self.gmask = None
>       emb = tensorflow_spatial_kernel_embedding(self.kernel_type, self.grid)

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/mkd.py:575: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

kernel_type = 'polar'
grids = {'x': <tf.Tensor: shape=(32, 32), dtype=float32, numpy=
array([[-1.        , -0.9354839 , -0.87096775, ...,  0.8709677...,
       [ 2.3561945 ,  2.3228736 ,  2.287338  , ...,  0.8542547 ,
         0.81871915,  0.7853981 ]], dtype=float32)>}

    def tensorflow_spatial_kernel_embedding(kernel_type, grids):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ...ivy.functional.backends.tensorflow.general import tensorflow_get_item
        from ...ivy.functional.frontends.torch.tensor import tensorflow_float_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_unsqueeze_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_squeeze_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_index_select_frnt_
        from ..constants import pi
    
        factors = {"phi": 1.0, "rho": pi / sqrt2, "x": pi / 2, "y": pi / 2}
        if kernel_type == "cart":
            coeffs_ = "xy"
            params_ = ["x", "y"]
        elif kernel_type == "polar":
            coeffs_ = "rhophi"
            params_ = ["phi", "rho"]
        keys = list(grids.keys())
        patch_size = tensorflow_shape_frnt_(tensorflow_get_item(grids, keys[0]))[-1]
        grids_normed = {k: (v * tensorflow_get_item(factors, k)) for k, v in grids.items()}
        grids_normed = {
            k: tensorflow_float_frnt_(
                tensorflow_unsqueeze_frnt_(tensorflow_unsqueeze_frnt_(v, 0), 0)
            )
            for k, v in grids_normed.items()
        }
        vm_a = tensorflow_VonMisesKernel(
            patch_size=patch_size, coeffs=tensorflow_get_item(COEFFS, coeffs_)
        )
        vm_b = tensorflow_VonMisesKernel(
            patch_size=patch_size, coeffs=tensorflow_get_item(COEFFS, coeffs_)
        )
        emb_a = tensorflow_squeeze_frnt_(
>           vm_a(tensorflow_get_item(grids_normed, params_[0]))
        )

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/mkd.py:534: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_VonMisesKernel(patch_size=32, n=2, d=5, coeffs=[0.14343168 0.268285   0.21979234])
args = (<tf.Tensor: shape=(1, 1, 32, 32), dtype=float32, numpy=
array([[[[-2.3561945 , -2.3228736 , -2.287338  , ..., -0.8542...    [ 2.3561945 ,  2.3228736 ,  2.287338  , ...,  0.8542547 ,
           0.81871915,  0.7853981 ]]]], dtype=float32)>,)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x5558575e28a0, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...339, function='test_MKDDescriptor', code_context=['    transpiled_model = TranspiledMKDDescriptor()\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_VonMisesKernel(patch_size=32, n=2, d=5, coeffs=[0.14343168 0.268285   0.21979234]), <tf.Tensor: shape=(1, ...     [ 2.3561945 ,  2.3228736 ,  2.287338  , ...,  0.8542547 ,
           0.81871915,  0.7853981 ]]]], dtype=float32)>)
kwargs = {}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_VonMisesKernel(patch_size=32, n=2, d=5, coeffs=[0.14343168 0.268285   0.21979234]), v = None, buffers = None
args = (<tf.Tensor: shape=(1, 1, 32, 32), dtype=float32, numpy=
array([[[[-2.3561945 , -2.3228736 , -2.287338  , ..., -0.8542...    [ 2.3561945 ,  2.3228736 ,  2.287338  , ...,  0.8542547 ,
           0.81871915,  0.7853981 ]]]], dtype=float32)>,)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_VonMisesKernel(patch_size=32, n=2, d=5, coeffs=[0.14343168 0.268285   0.21979234]), <tf.Tensor: shape=(1, ...     [ 2.3561945 ,  2.3228736 ,  2.287338  , ...,  0.8542547 ,
           0.81871915,  0.7853981 ]]]], dtype=float32)>)
kwargs = {'buffers': None, 'v': None}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_VonMisesKernel(patch_size=32, n=2, d=5, coeffs=[0.14343168 0.268285   0.21979234]), v = None, buffers = None
args = (<tf.Tensor: shape=(1, 1, 32, 32), dtype=float32, numpy=
array([[[[-2.3561945 , -2.3228736 , -2.287338  , ..., -0.8542...    [ 2.3561945 ,  2.3228736 ,  2.287338  , ...,  0.8542547 ,
           0.81871915,  0.7853981 ]]]], dtype=float32)>,)
kwargs = {}
first_arr = <tf.Tensor: shape=(1, 1, 32, 32), dtype=float32, numpy=
array([[[[-2.3561945 , -2.3228736 , -2.287338  , ..., -0.85425...      [ 2.3561945 ,  2.3228736 ,  2.287338  , ...,  0.8542547 ,
           0.81871915,  0.7853981 ]]]], dtype=float32)>
replace_v = False, replace_buffers = False, call_signature = <Signature (x)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Layer, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Layer, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Layer, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_VonMisesKernel(patch_size=32, n=2, d=5, coeffs=[0.14343168 0.268285   0.21979234]),)
kwargs = {'x': <tf.Tensor: shape=(1, 1, 32, 32), dtype=float32, numpy=
array([[[[-2.3561945 , -2.3228736 , -2.287338  , ..., -0...     [ 2.3561945 ,  2.3228736 ,  2.287338  , ...,  0.8542547 ,
           0.81871915,  0.7853981 ]]]], dtype=float32)>}

    @wraps(fn)
    def error_handler(*args, **kwargs):
        if not is_traceback_filtering_enabled():
            return fn(*args, **kwargs)
    
        filtered_tb = None
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            filtered_tb = _process_traceback_frames(e.__traceback__)
            # To get the full stack trace, call:
            # `keras.config.disable_traceback_filtering()`
>           raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/keras/src/utils/traceback_utils.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_VonMisesKernel(patch_size=32, n=2, d=5, coeffs=[0.14343168 0.268285   0.21979234])
x = <tf.Tensor: shape=(1, 1, 32, 32), dtype=float32, numpy=
array([[[[-2.3561945 , -2.3228736 , -2.287338  , ..., -0.85425...      [ 2.3561945 ,  2.3228736 ,  2.287338  , ...,  0.8542547 ,
           0.81871915,  0.7853981 ]]]], dtype=float32)>

    def call(self, x):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_repeat_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_to_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_size_frnt_
        from ...ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            tensorflow_cat_frnt,
        )
        from ..core._backend import cos
        from ..core._backend import sin
    
        if not isinstance(x, (tensorflow.Tensor, tensorflow.Variable)):
            raise TypeError(f"Input type is not a Tensor. Got {type(x)}")
        if not len(tensorflow_shape_frnt_(x)) == 4 or tensorflow_shape_frnt_(x)[1] != 1:
            raise ValueError(
                f"Invalid input shape, we expect Bx1xHxW. Got: {tensorflow_shape_frnt_(x)}"
            )
        if not isinstance(self.emb0, (tensorflow.Tensor, tensorflow.Variable)):
            raise TypeError(f"Emb0 type is not a Tensor. Got {type(x)}")
        emb0 = tensorflow_repeat_frnt_(
            tensorflow_to_frnt_(self.emb0, x), tensorflow_size_frnt_(x, 0), 1, 1, 1
        )
        frange = tensorflow_to_frnt_(self.frange, x) * x
        emb1 = cos(frange)
        emb2 = sin(frange)
        embedding = tensorflow_cat_frnt([emb0, emb1, emb2], dim=1)
>       embedding = self.pt_weights * embedding

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/mkd.py:265: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_VonMisesKernel(patch_size=32, n=2, d=5, coeffs=[0.14343168 0.268285   0.21979234]), name = 'pt_weights'

    @tf.autograph.experimental.do_not_convert
    def __getattr__(self, name):
        if name == "v":
            if not super().__getattribute__("_v") and not getattr(  # noqa: E501
                self, "_built", False
            ):
                return self._build_and_return_v(
                    *self._args, dynamic_backend=self._dynamic_backend, **self._kwargs
                )
    
        _dict = super().__getattribute__("__dict__")
        if name in _dict:
            return _dict[name]
    
        elif "_v" in _dict and name in _dict["_v"]:
            return _dict["_v"][name]
    
>       return super().__getattribute__(name)
E       AttributeError: Exception encountered when calling tensorflow_VonMisesKernel.call().
E       
E       [1m'tensorflow_VonMisesKernel' object has no attribute 'pt_weights'[0m
E       
E       Arguments received by tensorflow_VonMisesKernel.call():
E          x=tf.Tensor(shape=(1, 1, 32, 32), dtype=float32)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1343: AttributeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.MKDDescriptor
----------------------------------------------------------------------------------------- Captured stderr call -----------------------------------------------------------------------------------------
Downloading: "https://github.com/manyids2/mkd_pytorch/raw/master/mkd_pytorch/mkd-concat-64.pth" to /root/.cache/torch/hub/checkpoints/mkd-concat-64.pth

  0%|          | 0.00/1.31M [00:00<?, ?B/s]
100%|| 1.31M/1.31M [00:00<00:00, 122MB/s]
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/test_feature2.py::test_laf_is_inside_image[tensorflow-s2s-False] - tensorflow.python.framework.errors_impl.InvalidArgumentError: Value for attr 'T' of bool is not in the list of allow...
FAILED kornia/test_feature2.py::test_MKDDescriptor[tensorflow-s2s-False] - AttributeError: Exception encountered when calling tensorflow_VonMisesKernel.call().
============================================================================== 2 failed, 15 passed in 1380.06s (0:23:00) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 6 items

kornia/augmentation/test_container.py ...F.F                                                                                                                                                     [100%]

=============================================================================================== FAILURES ===============================================================================================
_________________________________________________________________________________ test_ImageSequential[jax-s2s-False] __________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_ImageSequential(target_framework, mode, backend_compile):
        print("kornia.augmentation.container.ImageSequential")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledImageSequential = ivy.transpile(
            kornia.augmentation.container.ImageSequential,
            source="torch",
            target=target_framework,
        )
        TranspiledColorJiggle = ivy.transpile(
            kornia.augmentation.ColorJiggle,
            source="torch",
            target=target_framework,
        )
        TranspiledRandomAffine = ivy.transpile(
            kornia.augmentation.RandomAffine,
            source="torch",
            target=target_framework,
        )
        TranspiledBgrToRgb = ivy.transpile(
            kornia.color.BgrToRgb,
            source="torch",
            target=target_framework,
        )
        TranspiledMedianBlur = ivy.transpile(
            kornia.filters.MedianBlur,
            source="torch",
            target=target_framework,
        )
        TranspiledInvert = ivy.transpile(
            kornia.enhance.Invert,
            source="torch",
            target=target_framework,
        )
        TranspiledRandomMixUpV2 = ivy.transpile(
            kornia.augmentation.RandomMixUpV2,
            source="torch",
            target=target_framework,
        )
    
        torch_aug_list = kornia.augmentation.container.ImageSequential(
            kornia.color.BgrToRgb(),
            kornia.augmentation.ColorJiggle(0.1, 0.1, 0.1, 0.1, p=1.0),
            kornia.filters.MedianBlur((3, 3)),
            kornia.augmentation.RandomAffine(360, p=1.0),
            kornia.enhance.Invert(),
            kornia.augmentation.RandomMixUpV2(p=1.0),
            same_on_batch=True,
            random_apply=10,
        )
        transpiled_aug_list = TranspiledImageSequential(
            TranspiledBgrToRgb(),
>           TranspiledColorJiggle(0.1, 0.1, 0.1, 0.1, p=1.0),
            TranspiledMedianBlur((3, 3)),
            TranspiledRandomAffine(360, p=1.0),
            TranspiledInvert(),
            TranspiledRandomMixUpV2(p=1.0),
            same_on_batch=True,
            random_apply=10,
        )

kornia/augmentation/test_container.py:261: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.augmentation._2d.intensity.color_jiggle.jax_ColorJiggle'>, args = (0.1, 0.1, 0.1, 0.1), kwargs = {'p': 1.0}

    def __call__(cls, *args: Any, **kwargs: Any) -> Any:
>     return _graph_node_meta_call(cls, *args, **kwargs)

/opt/fw/jax/flax/nnx/nnx/object.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.augmentation._2d.intensity.color_jiggle.jax_ColorJiggle'>, args = (0.1, 0.1, 0.1, 0.1), kwargs = {'p': 1.0}
node = <[AttributeError("'jax_ColorJiggle' object has no attribute 'p'") raised in repr()] jax_ColorJiggle object at 0x7f78477b0460>

    def _graph_node_meta_call(cls: tp.Type[G], *args, **kwargs) -> G:
      node = cls.__new__(cls, *args, **kwargs)
      vars(node)['_object__state'] = ObjectState()
>     cls._object_meta_construct(node, *args, **kwargs)

/opt/fw/jax/flax/nnx/nnx/object.py:88: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.augmentation._2d.intensity.color_jiggle.jax_ColorJiggle'>
self = <[AttributeError("'jax_ColorJiggle' object has no attribute 'p'") raised in repr()] jax_ColorJiggle object at 0x7f78477b0460>, args = (0.1, 0.1, 0.1, 0.1), kwargs = {'p': 1.0}

    def _object_meta_construct(cls, self, *args, **kwargs):
>     self.__init__(*args, **kwargs)

/opt/fw/jax/flax/nnx/nnx/object.py:82: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'jax_ColorJiggle' object has no attribute 'p'") raised in repr()] jax_ColorJiggle object at 0x7f78477b0460>, args = (0.1, 0.1, 0.1, 0.1), kwargs = {'p': 1.0}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/utils/decorator_utils.py:245: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'jax_ColorJiggle' object has no attribute 'p'") raised in repr()] jax_ColorJiggle object at 0x7f78477b0460>, brightness = 0.1, contrast = 0.1, saturation = 0.1, hue = 0.1
same_on_batch = False, p = 1.0, keepdim = False

>   ???
E   ModuleNotFoundError: No module named 'ivy_transpiled_outputs.jax_outputs.kornia.augmentation.random_generator._2d.color_jiggle'

/ivy/ivy-integration-tests/ivy_transpiled_outputs/jax_outputs/kornia/augmentation/_2d/intensity/color_jiggle.py:43: ModuleNotFoundError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.container.ImageSequential
_________________________________________________________________________________ test_VideoSequential[jax-s2s-False] __________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_VideoSequential(target_framework, mode, backend_compile):
        print("kornia.augmentation.container.VideoSequential")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledVideoSequential = ivy.transpile(
            kornia.augmentation.container.VideoSequential,
            source="torch",
            target=target_framework,
        )
        TranspiledColorJiggle = ivy.transpile(
            kornia.augmentation.ColorJiggle,
            source="torch",
            target=target_framework,
        )
        TranspiledRandomAffine = ivy.transpile(
            kornia.augmentation.RandomAffine,
            source="torch",
            target=target_framework,
        )
        TranspiledBgrToRgb = ivy.transpile(
            kornia.color.BgrToRgb,
            source="torch",
            target=target_framework,
        )
    
        torch_aug_list = kornia.augmentation.container.VideoSequential(
            kornia.augmentation.ColorJiggle(0.1, 0.1, 0.1, 0.1, p=1.0),
            kornia.color.BgrToRgb(),
            kornia.augmentation.RandomAffine(360, p=1.0),
            random_apply=10,
            data_format="BCTHW",
            same_on_frame=True
        )
        transpiled_aug_list =  TranspiledVideoSequential(
>           TranspiledColorJiggle(0.1, 0.1, 0.1, 0.1, p=1.0),
            TranspiledBgrToRgb(),
            TranspiledRandomAffine(360, p=1.0),
            random_apply=10,
            data_format="BCTHW",
            same_on_frame=True
        )

kornia/augmentation/test_container.py:406: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.augmentation._2d.intensity.color_jiggle.jax_ColorJiggle'>, args = (0.1, 0.1, 0.1, 0.1), kwargs = {'p': 1.0}

    def __call__(cls, *args: Any, **kwargs: Any) -> Any:
>     return _graph_node_meta_call(cls, *args, **kwargs)

/opt/fw/jax/flax/nnx/nnx/object.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.augmentation._2d.intensity.color_jiggle.jax_ColorJiggle'>, args = (0.1, 0.1, 0.1, 0.1), kwargs = {'p': 1.0}
node = <[ModuleNotFoundError("No module named 'ivy_transpiled_outputs.jax_outputs.kornia.augmentation'") raised in repr()] jax_ColorJiggle object at 0x7f78529d5000>

    def _graph_node_meta_call(cls: tp.Type[G], *args, **kwargs) -> G:
      node = cls.__new__(cls, *args, **kwargs)
      vars(node)['_object__state'] = ObjectState()
>     cls._object_meta_construct(node, *args, **kwargs)

/opt/fw/jax/flax/nnx/nnx/object.py:88: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.augmentation._2d.intensity.color_jiggle.jax_ColorJiggle'>
self = <[ModuleNotFoundError("No module named 'ivy_transpiled_outputs.jax_outputs.kornia.augmentation'") raised in repr()] jax_ColorJiggle object at 0x7f78529d5000>, args = (0.1, 0.1, 0.1, 0.1)
kwargs = {'p': 1.0}

    def _object_meta_construct(cls, self, *args, **kwargs):
>     self.__init__(*args, **kwargs)

/opt/fw/jax/flax/nnx/nnx/object.py:82: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[ModuleNotFoundError("No module named 'ivy_transpiled_outputs.jax_outputs.kornia.augmentation'") raised in repr()] jax_ColorJiggle object at 0x7f78529d5000>, args = (0.1, 0.1, 0.1, 0.1)
kwargs = {'p': 1.0}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/utils/decorator_utils.py:245: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[ModuleNotFoundError("No module named 'ivy_transpiled_outputs.jax_outputs.kornia.augmentation'") raised in repr()] jax_ColorJiggle object at 0x7f78529d5000>, brightness = 0.1, contrast = 0.1
saturation = 0.1, hue = 0.1, same_on_batch = False, p = 1.0, keepdim = False

>   ???
E   ModuleNotFoundError: No module named 'ivy_transpiled_outputs.jax_outputs.kornia.augmentation'

/ivy/ivy-integration-tests/ivy_transpiled_outputs/jax_outputs/kornia/augmentation/_2d/intensity/color_jiggle.py:43: ModuleNotFoundError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.container.VideoSequential
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/augmentation/test_container.py::test_ImageSequential[jax-s2s-False] - ModuleNotFoundError: No module named 'ivy_transpiled_outputs.jax_outputs.kornia.augmentation.random_generator._2d...
FAILED kornia/augmentation/test_container.py::test_VideoSequential[jax-s2s-False] - ModuleNotFoundError: No module named 'ivy_transpiled_outputs.jax_outputs.kornia.augmentation'
=============================================================================== 2 failed, 4 passed in 2277.10s (0:37:57) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 17 items

kornia/test_feature2.py ...............F.                                                                                                                                                        [100%]

=============================================================================================== FAILURES ===============================================================================================
_____________________________________________________________________________________ test_HardNet8[jax-s2s-False] _____________________________________________________________________________________
jax.errors.SimplifiedTraceback: For simplicity, JAX has removed its internal frames from the traceback of the following exception. Set JAX_TRACEBACK_FILTERING=off to include these.

The above exception was the direct cause of the following exception:

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_HardNet8(target_framework, mode, backend_compile):
        print("kornia.feature.HardNet8")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledHardNet8 = ivy.transpile(kornia.feature.HardNet8, source="torch", target=target_framework)
    
        x = torch.rand(16, 1, 32, 32)
        torch_out = kornia.feature.HardNet8()(x)
    
        transpiled_x = _nest_torch_tensor_to_new_framework(x, target_framework)
>       transpiled_out = TranspiledHardNet8()(transpiled_x)

kornia/test_feature2.py:380: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_HardNet8(
  (features): jax_Sequential(
    (0): FlaxConv(in_features=1, out_features=32, kernel_size=(3, 3), stri...es=(1, 1), padding=0, padding_mode=zeros)
    (23): FlaxBatchNorm2D(512, eps=1e-05, momentum=0.99, affine=False, 
  )
)
input = Array([[[[0.25312704, 0.18557829, 0.39625788, ..., 0.70427275,
          0.33864224, 0.07747459],
         [0.7759562 ...1],
         [0.08556569, 0.63406986, 0.19873744, ..., 0.16128677,
          0.40494704, 0.07278395]]]], dtype=float32)

    def __call__(self, input):
        from ..core.check import jax_KORNIA_CHECK_SHAPE
        from ...ivy.functional.frontends.torch._jit_internal import jax_annotate_frnt
        from ...ivy.functional.frontends.torch.nn.functional.non_linear_activation_functions import (
            jax_normalize_frnt,
        )
        from ...ivy.functional.frontends.torch.tensor import jax_view_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_size_frnt_
        from ...ivy.functional.frontends.torch.blas_and_lapack_ops import jax_mm_frnt
    
        jax_KORNIA_CHECK_SHAPE(input, ["B", "1", "32", "32"])
        x_norm: typing.Any = self._normalize_input(input)
>       x_features: typing.Any = self.features(x_norm)

ivy_transpiled_outputs/jax_outputs/kornia/feature/hardnet.py:292: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_Sequential(
  (0): FlaxConv(in_features=1, out_features=32, kernel_size=(3, 3), strides=(1, 1), padding=1, padding... strides=(1, 1), padding=0, padding_mode=zeros)
  (23): FlaxBatchNorm2D(512, eps=1e-05, momentum=0.99, affine=False, 
)
input = Array([[[[-0.88088953, -1.1088265 , -0.3979078 , ...,  0.64145976,
          -0.5923264 , -1.4736123 ],
         [ 0.8...       [-1.5141314 ,  0.4153629 , -1.1160227 , ..., -1.2477645 ,
          -0.3906313 , -1.5590942 ]]]], dtype=float32)

    def __call__(self, input):
        for i, module in enumerate(self):
>           input = module(input)

ivy_transpiled_outputs/jax_outputs/torch/nn/modules/container.py:181: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = FlaxConv(in_features=1, out_features=32, kernel_size=(3, 3), strides=(1, 1), padding=1, padding_mode=zeros)
args = (Array([[[[-0.88088953, -1.1088265 , -0.3979078 , ...,  0.64145976,
          -0.5923264 , -1.4736123 ],
         [ 0....     [-1.5141314 ,  0.4153629 , -1.1160227 , ..., -1.2477645 ,
          -0.3906313 , -1.5590942 ]]]], dtype=float32),)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x561a46817f50, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/jax_outputs/jax__st...neno=103, function='_multicall', code_context=['                    res = hook_impl.function(*args)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/jax_outputs/jax__stateful.py:102: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = FlaxConv(in_features=1, out_features=32, kernel_size=(3, 3), strides=(1, 1), padding=1, padding_mode=zeros)
args = (Array([[[[-0.88088953, -1.1088265 , -0.3979078 , ...,  0.64145976,
          -0.5923264 , -1.4736123 ],
         [ 0....     [-1.5141314 ,  0.4153629 , -1.1160227 , ..., -1.2477645 ,
          -0.3906313 , -1.5590942 ]]]], dtype=float32),)
kwargs = {}, jax_get_item = <function jax_get_item at 0x7f28b09aa170>, jax_set_item = <function jax_set_item at 0x7f28b09aa320>, DATA_FORMAT = 'channels_last'
fn_args_and_kwargs = {'inputs': Array([[[[-0.88088953],
         [-1.1088265 ],
         [-0.3979078 ],
         ...,
         [ 0.64145976...[-1.1160227 ],
         ...,
         [-1.2477645 ],
         [-0.3906313 ],
         [-1.5590942 ]]]], dtype=float32)}
conv_block_start = <function jax_handle_transpose_in_input_and_output.<locals>.transpose_wrapper.<locals>.<lambda> at 0x7f28b2609000>
next_call_in_seq = FlaxBatchNorm2D(32, eps=1e-05, momentum=0.99, affine=False, , conv_block_continued = True, arg_name = 'inputs'
input = Array([[[[-0.88088953, -1.1088265 , -0.3979078 , ...,  0.64145976,
          -0.5923264 , -1.4736123 ],
         [ 0.8...       [-1.5141314 ,  0.4153629 , -1.1160227 , ..., -1.2477645 ,
          -0.3906313 , -1.5590942 ]]]], dtype=float32)
transpose = <jax_TransposeType.CONV2D: 'conv2d'>

    @functools.wraps(fn)
    def transpose_wrapper(self, *args, **kwargs):
        from ..functional.backends.jax.general import jax_get_item
        from ..functional.backends.jax.general import jax_set_item
    
        DATA_FORMAT = os.environ.get("DATA_FORMAT", "channels_first")
        kwargs_call = {
            key: val
            for key, val in kwargs.items()
            if key not in dict(original_signature.parameters)
        }
        fn_args_and_kwargs = {
            key: val for key, val in kwargs.items() if key not in kwargs_call
        }
        fn_args_and_kwargs.update(dict(zip(fn.__code__.co_varnames[1:], args)))
        conv_block_start = lambda f: any(
            substr in f.__qualname__
            for substr in CONV_FUNCS
            + NORM_FUNCS
            + POOL_FUNCS
            + KERAS_CONV_FUNCS
            + KERAS_NORM_FUNCS
            + KERAS_POOL_FUNCS
            + FLAX_CONV_FUNCS
            + FLAX_NORM_FUNCS
            + FLAX_POOL_FUNCS
        )
        next_call_in_seq = jax_get_next_func(self)
        name_of_next_call = (
            next_call_in_seq.__class__.__name__
            if hasattr(next_call_in_seq, "__class__")
            else ""
        )
        conv_block_continued = next_call_in_seq and any(
            substr in name_of_next_call for substr in CONV_BLOCK_FNS
        )
        arg_name = "input" if "input" in fn_args_and_kwargs else "inputs"
        if DATA_FORMAT == "channels_first" and conv_block_start(self.__class__):
            input = jax_get_item(fn_args_and_kwargs, arg_name)
            if len(input.shape) > 4:
                transpose = jax_TransposeType.CONV3D
            elif len(input.shape) > 3:
                transpose = jax_TransposeType.CONV2D
            elif len(input.shape) > 2:
                transpose = jax_TransposeType.CONV1D
            else:
                transpose = jax_TransposeType.NO_TRANSPOSE
            fn_args_and_kwargs = jax_set_item(
                fn_args_and_kwargs,
                arg_name,
                jax_apply_transpose(input, transpose=transpose, pt_to_tf=True),
            )
            DATA_FORMAT = "channels_last"
            os.environ = jax_set_item(os.environ, "DATA_FORMAT", DATA_FORMAT)
>       res = fn(self, **fn_args_and_kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/utils/decorator_utils.py:412: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = FlaxConv(in_features=1, out_features=32, kernel_size=(3, 3), strides=(1, 1), padding=1, padding_mode=zeros)
inputs = Array([[[[-0.88088953],
         [-1.1088265 ],
         [-0.3979078 ],
         ...,
         [ 0.64145976],
        ... [-1.1160227 ],
         ...,
         [-1.2477645 ],
         [-0.3906313 ],
         [-1.5590942 ]]]], dtype=float32)

    @store_frame_info
    @jax_handle_transpose_in_input_and_output
    def __call__(self, inputs):
        self._built = True
        if self.padding_mode != "zeros":
            padding_mode = (
                "constant" if self.padding_mode == "zeros" else self.padding_mode
            )
            # handle Pytorch-style padding
            inputs = torch_pad(
                inputs, self._reversed_padding_repeated_twice, mode=padding_mode
            )
            old_pad = self.padding
            self.padding = 0
            logits = super().__call__(inputs)
            self.padding = old_pad
            self._built = False
            return logits
>       logits = super().__call__(inputs)

ivy_transpiled_outputs/jax_outputs/jax__stateful_layers.py:299: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = FlaxConv(in_features=1, out_features=32, kernel_size=(3, 3), strides=(1, 1), padding=1, padding_mode=zeros)
inputs = Array([[[[-0.88088953],
         [-1.1088265 ],
         [-0.3979078 ],
         ...,
         [ 0.64145976],
        ... [-1.1160227 ],
         ...,
         [-1.2477645 ],
         [-0.3906313 ],
         [-1.5590942 ]]]], dtype=float32)

    def __call__(self, inputs: Array) -> Array:
      """Applies a (potentially unshared) convolution to the inputs.
    
      Args:
        inputs: input data with dimensions ``(*batch_dims, spatial_dims..., features)``.
          This is the channels-last convention, i.e. NHWC for a 2d convolution and
          NDHWC for a 3D convolution. Note: this is different from the input convention
          used by ``lax.conv_general_dilated``, which puts the spatial dimensions last.
          Note: If the input has more than 1 batch dimension, all batch dimensions
          are flattened into a single dimension for the convolution and restored
          before returning.  In some cases directly vmap'ing the layer may yield
          better performance than this default flattening approach.  If the input
          lacks a batch dimension it will be added for the convolution and removed
          n return, an allowance made to enable writing single-example code.
    
      Returns:
        The convolved data.
      """
    
      assert isinstance(self.kernel_size, tuple)
      kernel_size = self.kernel_size
    
      def maybe_broadcast(
        x: tp.Optional[tp.Union[int, tp.Sequence[int]]],
      ) -> tuple[int, ...]:
        if x is None:
          # backward compatibility with using None as sentinel for
          # broadcast 1
          x = 1
        if isinstance(x, int):
          return (x,) * len(kernel_size)
        return tuple(x)
    
      # Combine all input batch dimensions into a single leading batch axis.
      num_batch_dimensions = inputs.ndim - (len(kernel_size) + 1)
      if num_batch_dimensions != 1:
        input_batch_shape = inputs.shape[:num_batch_dimensions]
        total_batch_size = int(np.prod(input_batch_shape))
        flat_input_shape = (total_batch_size,) + inputs.shape[
          num_batch_dimensions:
        ]
        inputs = jnp.reshape(inputs, flat_input_shape)
    
      # self.strides or (1,) * (inputs.ndim - 2)
      strides = maybe_broadcast(self.strides)
      input_dilation = maybe_broadcast(self.input_dilation)
      kernel_dilation = maybe_broadcast(self.kernel_dilation)
    
      padding_lax = canonicalize_padding(self.padding, len(kernel_size))
      if padding_lax == 'CIRCULAR':
        kernel_size_dilated = [
          (k - 1) * d + 1 for k, d in zip(kernel_size, kernel_dilation)
        ]
        zero_pad: tp.List[tuple[int, int]] = [(0, 0)]
        pads = (
          zero_pad
          + [((k - 1) // 2, k // 2) for k in kernel_size_dilated]
          + [(0, 0)]
        )
        inputs = jnp.pad(inputs, pads, mode='wrap')
        padding_lax = 'VALID'
      elif padding_lax == 'CAUSAL':
        if len(kernel_size) != 1:
          raise ValueError(
            'Causal padding is only implemented for 1D convolutions.'
          )
        left_pad = kernel_dilation[0] * (kernel_size[0] - 1)
        pads = [(0, 0), (left_pad, 0), (0, 0)]
        inputs = jnp.pad(inputs, pads)
        padding_lax = 'VALID'
    
      dimension_numbers = _conv_dimension_numbers(inputs.shape)
    
      # One shared convolutional kernel for all pixels in the output.
      assert self.in_features % self.feature_group_count == 0
    
      if self.mask is not None and self.mask.shape != self.kernel_shape:
        raise ValueError(
          'Mask needs to have the same shape as weights. '
          f'Shapes are: {self.mask.shape}, {self.kernel_shape}'
        )
    
      kernel = self.kernel.value
    
      if self.mask is not None:
        kernel *= self.mask
    
      bias = self.bias.value
    
      inputs, kernel, bias = dtypes.promote_dtype(
        (inputs, kernel, bias), dtype=self.dtype
      )
    
>     y = self.conv_general_dilated(
        inputs,
        kernel,
        strides,
        padding_lax,
        lhs_dilation=input_dilation,
        rhs_dilation=kernel_dilation,
        dimension_numbers=dimension_numbers,
        feature_group_count=self.feature_group_count,
        precision=self.precision,
      )

/opt/fw/jax/flax/nnx/nnx/nn/linear.py:777: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

lhs = Array([[[[-0.88088953],
         [-1.1088265 ],
         [-0.3979078 ],
         ...,
         [ 0.64145976],
        ... [-1.1160227 ],
         ...,
         [-1.2477645 ],
         [-0.3906313 ],
         [-1.5590942 ]]]], dtype=float32)
rhs = Array([[ 0.17321092,  0.14065616, -0.1845205 ,  0.04476047,  0.02703602,
         0.05671129,  0.05412335, -0.08114062...0.07064222,  0.01723543,  0.00141026,
        -0.12867665, -0.09788989, -0.0136649 , -0.03683599]],      dtype=float32)
window_strides = (1, 1), padding = ((1, 1), (1, 1)), lhs_dilation = (1, 1), rhs_dilation = (1, 1)
dimension_numbers = ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)), feature_group_count = 1, batch_group_count = 1, precision = None
preferred_element_type = None

    def conv_general_dilated(
      lhs: Array, rhs: Array, window_strides: Sequence[int],
      padding: str | Sequence[tuple[int, int]],
      lhs_dilation: Sequence[int] | None = None,
      rhs_dilation: Sequence[int] | None = None,
      dimension_numbers: ConvGeneralDilatedDimensionNumbers  = None,
      feature_group_count: int = 1, batch_group_count: int = 1,
      precision: lax.PrecisionLike = None,
      preferred_element_type: DTypeLike | None = None) -> Array:
      """General n-dimensional convolution operator, with optional dilation.
    
      Wraps XLA's `Conv
      <https://www.tensorflow.org/xla/operation_semantics#conv_convolution>`_
      operator.
    
      Args:
        lhs: a rank `n+2` dimensional input array.
        rhs: a rank `n+2` dimensional array of kernel weights.
        window_strides: a sequence of `n` integers, representing the inter-window
          strides.
        padding: either the strings `'SAME'`, `'SAME_LOWER'`, or `'VALID'`, or a
          sequence of `n` `(low, high)` integer pairs that give the padding to apply
          before and after each spatial dimension. `'SAME'` and `'SAME_LOWER'` add
          padding to produce same output size as the input. The padding is split
          between the two sides equally or almost equally. In case the padding is an
          odd number, the extra padding is added at the end for `'SAME'` and at the
          beginning for `'SAME_LOWER'`.
        lhs_dilation: `None`, or a sequence of `n` integers, giving the dilation
          factor to apply in each spatial dimension of `lhs`. LHS dilation is also
          known as transposed convolution.
        rhs_dilation: `None`, or a sequence of `n` integers, giving the dilation
          factor to apply in each spatial dimension of `rhs`. RHS dilation is also
          known as atrous convolution.
        dimension_numbers: either `None`, a ``ConvDimensionNumbers`` object, or a
          3-tuple ``(lhs_spec, rhs_spec, out_spec)``, where each element is a string
          of length `n+2`.
        feature_group_count: integer, default 1. See XLA HLO docs.
        batch_group_count: integer, default 1. See XLA HLO docs.
        precision: Optional. Either ``None``, which means the default precision for
          the backend, a :class:`~jax.lax.Precision` enum value
          (``Precision.DEFAULT``, ``Precision.HIGH`` or ``Precision.HIGHEST``), a
          string (e.g. 'highest' or 'fastest', see the
          ``jax.default_matmul_precision`` context manager), or a tuple of two
          :class:`~jax.lax.Precision` enums or strings indicating precision of
          ``lhs`` and ``rhs``.
        preferred_element_type: Optional. Either ``None``, which means the default
          accumulation type for the input types, or a datatype, indicating to
          accumulate results to and return a result with that datatype.
    
      Returns:
        An array containing the convolution result.
    
      In the string case of ``dimension_numbers``, each character identifies by
      position:
    
      - the batch dimensions in ``lhs``, ``rhs``, and the output with the character
        'N',
      - the feature dimensions in `lhs` and the output with the character 'C',
      - the input and output feature dimensions in rhs with the characters 'I'
        and 'O' respectively, and
      - spatial dimension correspondences between lhs, rhs, and the output using
        any distinct characters. The examples below use 'W' and 'H'.
    
      For example, to indicate dimension numbers consistent with the ``conv``
      function with two spatial dimensions, one could use ``('NCHW', 'OIHW',
      'NCHW')``. As another example, to indicate dimension numbers consistent with
      the TensorFlow Conv2D operation, one could use ``('NHWC', 'HWIO', 'NHWC')``.
      When using the latter form of convolution dimension specification, window
      strides are associated with spatial dimension character labels according to
      the order in which the labels appear in the ``rhs_spec`` string, so that
      ``window_strides[0]`` is matched with the dimension corresponding to the first
      character appearing in rhs_spec that is not ``'I'`` or ``'O'``.
    
      If ``dimension_numbers`` is ``None``, the default is ``('NCHW', 'OIHW',
      'NCHW')`` (for a 2D convolution).
      """
      dnums = conv_dimension_numbers(lhs.shape, rhs.shape, dimension_numbers)
      if lhs_dilation is None:
        lhs_dilation = (1,) * (lhs.ndim - 2)
      elif isinstance(padding, str) and not len(lhs_dilation) == lhs_dilation.count(1):
        raise ValueError(
            "String padding is not implemented for transposed convolution "
            "using this op. Please either exactly specify the required padding or "
            "use conv_transpose.")
      if rhs_dilation is None:
        rhs_dilation = (1,) * (rhs.ndim - 2)
      if isinstance(padding, str):
        lhs_perm, rhs_perm, _ = dnums
        rhs_shape = np.take(rhs.shape, rhs_perm)[2:]
        effective_rhs_shape = [core.dilate_dim(k, r) for k, r in zip(rhs_shape, rhs_dilation)]
        padding = lax.padtype_to_pads(
            np.take(lhs.shape, lhs_perm)[2:], effective_rhs_shape,
            window_strides, padding)
      else:
        try:
          padding = tuple((operator.index(lo), operator.index(hi))
                          for lo, hi in padding)
        except (ValueError, TypeError) as e:
          raise ValueError(
            "padding argument to conv_general_dilated should be a string or a "
            f"sequence of (low, high) pairs, got {padding}") from e
    
      preferred_element_type = (
          None if preferred_element_type is None else
          dtypes.canonicalize_dtype(np.dtype(preferred_element_type)))
>     return conv_general_dilated_p.bind(
          lhs, rhs, window_strides=tuple(window_strides), padding=tuple(padding),
          lhs_dilation=tuple(lhs_dilation), rhs_dilation=tuple(rhs_dilation),
          dimension_numbers=dnums,
          feature_group_count=feature_group_count,
          batch_group_count=batch_group_count,
          precision=lax.canonicalize_precision(precision),
          preferred_element_type=preferred_element_type)

/opt/fw/jax/jax/_src/lax/convolution.py:161: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = conv_general_dilated
args = (Array([[[[-0.88088953],
         [-1.1088265 ],
         [-0.3979078 ],
         ...,
         [ 0.64145976],
       ....07064222,  0.01723543,  0.00141026,
        -0.12867665, -0.09788989, -0.0136649 , -0.03683599]],      dtype=float32))
params = {'batch_group_count': 1, 'dimension_numbers': ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)), 'feature_group_count': 1, 'lhs_dilation': (1, 1), ...}

    def bind(self, *args, **params):
      assert (not config.enable_checks.value or
              all(isinstance(arg, Tracer) or valid_jaxtype(arg) for arg in args)), args
>     return self.bind_with_trace(find_top_trace(args), args, params)

/opt/fw/jax/jax/_src/core.py:438: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = conv_general_dilated, trace = EvalTrace(level=0/0)
args = (Array([[[[-0.88088953],
         [-1.1088265 ],
         [-0.3979078 ],
         ...,
         [ 0.64145976],
       ....07064222,  0.01723543,  0.00141026,
        -0.12867665, -0.09788989, -0.0136649 , -0.03683599]],      dtype=float32))
params = {'batch_group_count': 1, 'dimension_numbers': ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)), 'feature_group_count': 1, 'lhs_dilation': (1, 1), ...}

    def bind_with_trace(self, trace, args, params):
      with pop_level(trace.level):
>       out = trace.process_primitive(self, map(trace.full_raise, args), params)

/opt/fw/jax/jax/_src/core.py:442: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = EvalTrace(level=0/0), primitive = conv_general_dilated
tracers = [Array([[[[-0.88088953],
         [-1.1088265 ],
         [-0.3979078 ],
         ...,
         [ 0.64145976],
       ....07064222,  0.01723543,  0.00141026,
        -0.12867665, -0.09788989, -0.0136649 , -0.03683599]],      dtype=float32)]
params = {'batch_group_count': 1, 'dimension_numbers': ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)), 'feature_group_count': 1, 'lhs_dilation': (1, 1), ...}

    def process_primitive(self, primitive, tracers, params):
      if config.debug_key_reuse.value:
        # Import here to avoid circular imports
        from jax.experimental.key_reuse._core import call_impl_with_key_reuse_checks  # pytype: disable=import-error
        return call_impl_with_key_reuse_checks(primitive, primitive.impl, *tracers, **params)
      else:
>       return primitive.impl(*tracers, **params)

/opt/fw/jax/jax/_src/core.py:948: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

prim = conv_general_dilated
args = (Array([[[[-0.88088953],
         [-1.1088265 ],
         [-0.3979078 ],
         ...,
         [ 0.64145976],
       ....07064222,  0.01723543,  0.00141026,
        -0.12867665, -0.09788989, -0.0136649 , -0.03683599]],      dtype=float32))
params = {'batch_group_count': 1, 'dimension_numbers': ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)), 'feature_group_count': 1, 'lhs_dilation': (1, 1), ...}
fun = <PjitFunction of <function conv_general_dilated at 0x7f28c10335b0>>, prev = None

    def apply_primitive(prim, *args, **params):
      """Impl rule that compiles and runs a single primitive 'prim' using XLA."""
      fun = xla_primitive_callable(prim, **params)
      # TODO(yashkatariya): Investigate adding is_primitive to jit and never
      # triggering the disable jit path instead of messing around with it here.
      prev = lib.jax_jit.swap_thread_local_state_disable_jit(False)
      try:
>       outs = fun(*args)
E       ValueError: conv_general_dilated lhs and rhs must have the same number of dimensions, but got (16, 32, 32, 1) and (32, 9).

/opt/fw/jax/jax/_src/dispatch.py:90: ValueError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.HardNet8
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/test_feature2.py::test_HardNet8[jax-s2s-False] - ValueError: conv_general_dilated lhs and rhs must have the same number of dimensions, but got (16, 32, 32, 1) and (32, 9).
============================================================================== 1 failed, 16 passed in 1326.63s (0:22:06) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 6 items

kornia/geometry/test_depth.py ......                                                                                                                                                             [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
==================================================================================== 6 passed in 344.71s (0:05:44) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 8 items

kornia/test_image.py ........                                                                                                                                                                    [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
==================================================================================== 8 passed in 347.72s (0:05:47) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 2 items

kornia/geometry/test_boxes.py ss                                                                                                                                                                 [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
========================================================================================== 2 skipped in 5.21s ==========================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 8 items

kornia/geometry/test_bbox.py ..F.....                                                                                                                                                            [100%]

=============================================================================================== FAILURES ===============================================================================================
_______________________________________________________________________________ test_bbox_to_mask[tensorflow-s2s-False] ________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_bbox_to_mask(target_framework, mode, backend_compile):
        trace_args = (
            torch.tensor([[[1., 1.], [3., 1.], [3., 2.], [1., 2.]]]),
            5,
            5,
        )
        trace_kwargs = {}
        test_args = (
            torch.tensor([[[2., 2.], [4., 2.], [4., 3.], [2., 3.]]]),
            6,
            6,
        )
        test_kwargs = {}
>       _test_function(
            kornia.geometry.bbox.bbox_to_mask,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/geometry/test_bbox.py:82: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function bbox_to_mask at 0x7f4759965f30>, trace_args = (tensor([[[1., 1.],
         [3., 1.],
         [3., 2.],
         [1., 2.]]]), 5, 5), trace_kwargs = {}
test_args = (tensor([[[2., 2.],
         [4., 2.],
         [4., 3.],
         [2., 3.]]]), 6, 6), test_kwargs = {}, target = 'tensorflow', backend_compile = False, tolerance = 0.001, mode = 's2s'
skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function bbox_to_mask at 0x7f4759965f30>, fn_name = 'kornia.geometry.bbox.bbox_to_mask', trace_args = (tensor([[[1., 1.],
         [3., 1.],
         [3., 2.],
         [1., 2.]]]), 5, 5)
trace_kwargs = {}, test_args = (tensor([[[2., 2.],
         [4., 2.],
         [4., 3.],
         [2., 3.]]]), 6, 6), test_kwargs = {}, target = 'tensorflow', backend_compile = False
tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
        graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
    
        if deterministic:
>           _to_numpy_and_allclose(orig_out, graph_out, tolerance=tolerance)

helpers.py:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

torch_x = tensor([[[0., 0., 0., 0., 0.],
         [0., 1., 1., 1., 0.],
         [0., 1., 1., 1., 0.],
         [0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.]]])
transpiled_x = <tf.Tensor: shape=(1, 5, 5), dtype=float32, numpy=
array([[[0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0.]]], dtype=float32)>
tolerance = 0.001

    def _to_numpy_and_allclose(torch_x, transpiled_x, tolerance=1e-3):
        orig_data = _nest_array_to_numpy(torch_x)
        transpiled_data = _nest_array_to_numpy(transpiled_x)
>       _check_allclose(orig_data, transpiled_data, tolerance=tolerance)

helpers.py:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[0., 0., 0., 0., 0.],
        [0., 1., 1., 1., 0.],
        [0., 1., 1., 1., 0.],
        [0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0.]]], dtype=float32)
y = array([[[0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0.]]], dtype=float32), tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
>           assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
E           AssertionError: numpy array values are not all close

helpers.py:26: AssertionError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.bbox.bbox_to_mask
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/geometry/test_bbox.py::test_bbox_to_mask[tensorflow-s2s-False] - AssertionError: numpy array values are not all close
=============================================================================== 1 failed, 7 passed in 505.66s (0:08:25) ================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 13 items

kornia/test_feature3.py sssssssssssss                                                                                                                                                            [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
========================================================================================= 13 skipped in 5.12s ==========================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 4 items

kornia/test_sensors.py ....                                                                                                                                                                      [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
===================================================================================== 4 passed in 85.66s (0:01:25) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 2 items

kornia/geometry/test_vector.py ss                                                                                                                                                                [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
========================================================================================== 2 skipped in 5.12s ==========================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 4 items

kornia/geometry/test_liegroup.py ..F.                                                                                                                                                            [100%]

=============================================================================================== FAILURES ===============================================================================================
____________________________________________________________________________________ test_So2[tensorflow-s2s-False] ____________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_So2(target_framework, mode, backend_compile):
        print("kornia.geometry.liegroup.So2")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        real_part = torch.tensor([1.0], requires_grad=True)
        imaginary_part = torch.tensor([2.0], requires_grad=True)
        complex_number = torch.complex(real_part, imaginary_part)
        torch_so2 = kornia.geometry.liegroup.So2(complex_number)
    
        TranspiledSo2 = ivy.transpile(kornia.geometry.liegroup.So2, source="torch", target=target_framework)
        transpiled_complex_number = _nest_torch_tensor_to_new_framework(complex_number, target_framework)
        transpiled_so2 = TranspiledSo2(transpiled_complex_number)
    
        # Test .matrix()
        torch_matrix = torch_so2.matrix()
        transpiled_matrix = transpiled_so2.matrix()
        _to_numpy_and_allclose(torch_matrix, transpiled_matrix)
    
        # Test .inverse()
        torch_inverse = torch_so2.inverse()
        transpiled_inverse = transpiled_so2.inverse()
        _to_numpy_and_allclose(torch_inverse.z, transpiled_inverse.z)
    
        # Test .log()
        torch_log = torch_so2.log()
        transpiled_log = transpiled_so2.log()
        _to_numpy_and_allclose(torch_log, transpiled_log)
    
        # Test .__mul__()
        other_real_part = torch.tensor([0.5], requires_grad=True)
        other_imaginary_part = torch.tensor([0.5], requires_grad=True)
        other_complex_number = torch.complex(other_real_part, other_imaginary_part)
        other_torch_so2 = kornia.geometry.liegroup.So2(other_complex_number)
    
        transpiled_other_complex_number = _nest_torch_tensor_to_new_framework(other_complex_number, target_framework)
        transpiled_other_so2 = TranspiledSo2(transpiled_other_complex_number)
    
        torch_composed_so2 = torch_so2 * other_torch_so2
        transpiled_composed_so2 = transpiled_so2 * transpiled_other_so2
        _to_numpy_and_allclose(torch_composed_so2.z, transpiled_composed_so2.z)
    
        # Test .adjoint()
        torch_adjoint = torch_so2.adjoint()
>       transpiled_adjoint = transpiled_so2.adjoint()

kornia/geometry/test_liegroup.py:202: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <tf.Variable 'Variable:0' shape=(1,) dtype=complex64, numpy=array([1.+2.j], dtype=complex64)>

    def adjoint(self):
        from ....ivy.functional.frontends.torch.tensor import tensorflow_real_frnt_
        from ....ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
    
>       batch_size = len(self.z) if len(tensorflow_shape_frnt_(self.z)) > 0 else None
E       TypeError: object of type 'ResourceVariable' has no len()

ivy_transpiled_outputs/tensorflow_outputs/kornia/geometry/liegroup/so2.py:196: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.liegroup.So2
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/geometry/test_liegroup.py::test_So2[tensorflow-s2s-False] - TypeError: object of type 'ResourceVariable' has no len()
=============================================================================== 1 failed, 3 passed in 457.62s (0:07:37) ================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 19 items

kornia/geometry/test_camera.py ...................                                                                                                                                               [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
=================================================================================== 19 passed in 1046.93s (0:17:26) ====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 17 items

kornia/augmentation/test_augmentation2.py ...F.......F.F.F.                                                                                                                                      [100%]

=============================================================================================== FAILURES ===============================================================================================
_____________________________________________________________________________ test_RandomMotionBlur[tensorflow-s2s-False] ______________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_RandomMotionBlur(target_framework, mode, backend_compile):
        print("kornia.augmentation.RandomMotionBlur")
    
        init_args = (3, 35., 0.5)
        init_kwargs = {"p": 1.}
        call_args = (torch.ones(1, 1, 5, 5),)
        call_kwargs = {}
    
>       _test_augmentation_class(
            kornia.augmentation.RandomMotionBlur,
            target_framework,
            init_args,
            init_kwargs,
            call_args,
            call_kwargs,
            deterministic_output=False,
            backend_compile=backend_compile,
        )

kornia/augmentation/test_augmentation2.py:133: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

augmentation_cls = <class 'kornia.augmentation._2d.intensity.motion_blur.RandomMotionBlur'>, target = 'tensorflow', init_args = (3, 35.0, 0.5), init_kwargs = {'p': 1.0}
call_args = (tensor([[[[1., 1., 1., 1., 1.],
          [1., 1., 1., 1., 1.],
          [1., 1., 1., 1., 1.],
          [1., 1., 1., 1., 1.],
          [1., 1., 1., 1., 1.]]]]),), call_kwargs = {}
deterministic_output = False, backend_compile = False, tolerance = 0.001

    def _test_augmentation_class(
        augmentation_cls,
        target,
        init_args=(),
        init_kwargs={},
        call_args=(),
        call_kwargs={},
        deterministic_output=True,
        backend_compile=False,
        tolerance=1e-3,
    ):
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_cls = ivy.transpile(augmentation_cls, source="torch", target=target)
    
        torch_aug = augmentation_cls(*init_args, **init_kwargs)
        transpiled_init_args = _nest_torch_tensor_to_new_framework(init_args, target)
        transpiled_init_kwargs = _nest_torch_tensor_to_new_framework(init_kwargs, target)
        transpiled_aug = transpiled_cls(*transpiled_init_args, **transpiled_init_kwargs)
    
        # assert dir(torch_aug) == dir(transpiled_aug), f"attributes/methods of transpiled object do not align with the original - orig: {dir(torch_aug)} != transpiled: {dir(transpiled_aug)}"
    
        torch_out = torch_aug(*call_args, **call_kwargs)
        transpiled_call_args = _nest_torch_tensor_to_new_framework(call_args, target)
        transpiled_call_kwargs = _nest_torch_tensor_to_new_framework(call_kwargs, target)
>       transpiled_out = transpiled_aug(*transpiled_call_args, **transpiled_call_kwargs)

kornia/augmentation/test_augmentation2.py:43: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomMotionBlur(kernel_size=3, angle=35.0, direction=0.5, p=1.0, p_batch=1.0, same_on_batch=False, border_type=constant, resample=nearest)
args = (<tf.Tensor: shape=(1, 1, 5, 5), dtype=float32, numpy=
array([[[[1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.]]]], dtype=float32)>,)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x7f1b1d7a2840, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...kexec', code_context=['        return self._inner_hookexec(hook_name, methods, kwargs, firstresult)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomMotionBlur(kernel_size=3, angle=35.0, direction=0.5, p=1.0, p_batch=1.0, same_on_batch=False, border..., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.]]]], dtype=float32)>)
kwargs = {}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomMotionBlur(kernel_size=3, angle=35.0, direction=0.5, p=1.0, p_batch=1.0, same_on_batch=False, border_type=constant, resample=nearest), v = None, buffers = None
args = (<tf.Tensor: shape=(1, 1, 5, 5), dtype=float32, numpy=
array([[[[1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.]]]], dtype=float32)>,)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomMotionBlur(kernel_size=3, angle=35.0, direction=0.5, p=1.0, p_batch=1.0, same_on_batch=False, border..., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.]]]], dtype=float32)>)
kwargs = {'buffers': None, 'v': None}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomMotionBlur(kernel_size=3, angle=35.0, direction=0.5, p=1.0, p_batch=1.0, same_on_batch=False, border_type=constant, resample=nearest), v = None, buffers = None
args = (<tf.Tensor: shape=(1, 1, 5, 5), dtype=float32, numpy=
array([[[[1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.]]]], dtype=float32)>,)
kwargs = {}
first_arr = <tf.Tensor: shape=(1, 1, 5, 5), dtype=float32, numpy=
array([[[[1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.]]]], dtype=float32)>
replace_v = False, replace_buffers = False, call_signature = <Signature (input, params=None, **kwargs)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Layer, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Layer, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Layer, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomMotionBlur(kernel_size=3, angle=35.0, direction=0.5, p=1.0, p_batch=1.0, same_on_batch=False, border_type=constant, resample=nearest),)
kwargs = {'input': <tf.Tensor: shape=(1, 1, 5, 5), dtype=float32, numpy=
array([[[[1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.]]]], dtype=float32)>}

    @wraps(fn)
    def error_handler(*args, **kwargs):
        if not is_traceback_filtering_enabled():
            return fn(*args, **kwargs)
    
        filtered_tb = None
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            filtered_tb = _process_traceback_frames(e.__traceback__)
            # To get the full stack trace, call:
            # `keras.config.disable_traceback_filtering()`
>           raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/keras/src/utils/traceback_utils.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomMotionBlur(kernel_size=3, angle=35.0, direction=0.5, p=1.0, p_batch=1.0, same_on_batch=False, border_type=constant, resample=nearest)
input = <tf.Tensor: shape=(1, 1, 5, 5), dtype=float32, numpy=
array([[[[1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.]]]], dtype=float32)>
params = None, kwargs = {}, tensorflow_shape_frnt_ = <function tensorflow_shape_frnt_ at 0x7f1b1c77feb0>, tensorflow_set_item = <function tensorflow_set_item at 0x7f1b1dc44ca0>
tensor = <function tensorflow_tensor_frnt at 0x7f1b1dc05090>
in_tensor = <tf.Tensor: shape=(1, 1, 5, 5), dtype=float32, numpy=
array([[[[1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.]]]], dtype=float32)>
input_shape = ivy.frontends.torch.Size([1, 1, 5, 5]), batch_shape = ivy.frontends.torch.Size([1, 1, 5, 5])

    def call(self, input, params=None, **kwargs):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ...ivy.functional.backends.tensorflow.general import tensorflow_set_item
        from ..core._backend import tensor
    
        in_tensor = self.__unpack_input__(input)
        input_shape = tensorflow_shape_frnt_(in_tensor)
        in_tensor = self.transform_tensor(in_tensor)
        batch_shape = tensorflow_shape_frnt_(in_tensor)
        if params is None:
>           params = self.forward_parameters(batch_shape)

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/base.py:228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomMotionBlur(kernel_size=3, angle=35.0, direction=0.5, p=1.0, p_batch=1.0, same_on_batch=False, border_type=constant, resample=nearest)
batch_shape = ivy.frontends.torch.Size([1, 1, 5, 5])

    def forward_parameters(self, batch_shape):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_sum_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_item_frnt_
        from ...ivy.functional.backends.tensorflow.general import tensorflow_set_item
        from ..core._backend import tensor
    
        batch_prob = self.__batch_prob_generator__(
            batch_shape, self.p, self.p_batch, self.same_on_batch
        )
        to_apply = batch_prob > 0.5
>       _params = self.generate_parameters(
            tuple(
                (
                    int(tensorflow_item_frnt_(tensorflow_sum_frnt_(to_apply))),
                    *batch_shape[1:],
                )
            )
        )

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/base.py:200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomMotionBlur(kernel_size=3, angle=35.0, direction=0.5, p=1.0, p_batch=1.0, same_on_batch=False, border_type=constant, resample=nearest), batch_shape = (1, 1, 5, 5)

    def generate_parameters(self, batch_shape):
        from ....core._backend import tensor
        from .....ivy.functional.backends.tensorflow.general import tensorflow_set_item
        from .....ivy.functional.frontends.torch.random_sampling import (
            tensorflow_randint_frnt,
        )
    
        params = super().generate_parameters(batch_shape)
        params = tensorflow_set_item(
            params,
            "idx",
            tensor([0])
            if batch_shape[0] == 0
>           else tensorflow_randint_frnt(batch_shape[0], (1,)),
        )
E       TypeError: Exception encountered when calling tensorflow_RandomMotionBlur.call().
E       
E       [1mtensorflow_randint_frnt() missing 1 required positional argument: 'size'[0m
E       
E       Arguments received by tensorflow_RandomMotionBlur.call():
E          input=tf.Tensor(shape=(1, 1, 5, 5), dtype=float32)
E          params=None
E          kwargs=<class 'inspect._empty'>

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/_2d/intensity/motion_blur.py:73: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.RandomMotionBlur
_________________________________________________________________________ test_RandomSaltAndPepperNoise[tensorflow-s2s-False] __________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_RandomSaltAndPepperNoise(target_framework, mode, backend_compile):
        print("kornia.augmentation.RandomSaltAndPepperNoise")
    
        init_args = ()
        init_kwargs = {"amount": 0.5, "salt_vs_pepper": 0.5, "p": 1.}
        call_args = (torch.rand(1, 3, 3, 3),)
        call_kwargs = {}
    
>       _test_augmentation_class(
            kornia.augmentation.RandomSaltAndPepperNoise,
            target_framework,
            init_args,
            init_kwargs,
            call_args,
            call_kwargs,
            deterministic_output=False,
            backend_compile=backend_compile,
        )

kornia/augmentation/test_augmentation2.py:293: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

augmentation_cls = <class 'kornia.augmentation._2d.intensity.salt_pepper_noise.RandomSaltAndPepperNoise'>, target = 'tensorflow', init_args = ()
init_kwargs = {'amount': 0.5, 'p': 1.0, 'salt_vs_pepper': 0.5}
call_args = (tensor([[[[0.7512, 0.8533, 0.5962],
          [0.1086, 0.2965, 0.2111],
          [0.5656, 0.7912, 0.6652]],

       ...27]],

         [[0.7946, 0.1508, 0.7137],
          [0.7535, 0.8120, 0.3467],
          [0.1741, 0.8808, 0.3525]]]]),)
call_kwargs = {}, deterministic_output = False, backend_compile = False, tolerance = 0.001

    def _test_augmentation_class(
        augmentation_cls,
        target,
        init_args=(),
        init_kwargs={},
        call_args=(),
        call_kwargs={},
        deterministic_output=True,
        backend_compile=False,
        tolerance=1e-3,
    ):
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_cls = ivy.transpile(augmentation_cls, source="torch", target=target)
    
        torch_aug = augmentation_cls(*init_args, **init_kwargs)
        transpiled_init_args = _nest_torch_tensor_to_new_framework(init_args, target)
        transpiled_init_kwargs = _nest_torch_tensor_to_new_framework(init_kwargs, target)
        transpiled_aug = transpiled_cls(*transpiled_init_args, **transpiled_init_kwargs)
    
        # assert dir(torch_aug) == dir(transpiled_aug), f"attributes/methods of transpiled object do not align with the original - orig: {dir(torch_aug)} != transpiled: {dir(transpiled_aug)}"
    
        torch_out = torch_aug(*call_args, **call_kwargs)
        transpiled_call_args = _nest_torch_tensor_to_new_framework(call_args, target)
        transpiled_call_kwargs = _nest_torch_tensor_to_new_framework(call_kwargs, target)
>       transpiled_out = transpiled_aug(*transpiled_call_args, **transpiled_call_kwargs)

kornia/augmentation/test_augmentation2.py:43: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomSaltAndPepperNoise(amount=(0.5, 0.5), salt_and_pepper=(0.5, 0.5), p=1.0, p_batch=1.0, same_on_batch=False)
args = (<tf.Tensor: shape=(1, 3, 3, 3), dtype=float32, numpy=
array([[[[0.7512069 , 0.8532861 , 0.59619415],
         [0.1085...7 ],
         [0.7535221 , 0.8120403 , 0.3467099 ],
         [0.17410171, 0.88075536, 0.35246658]]]], dtype=float32)>,)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x7f1b1fcf6e40, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...kexec', code_context=['        return self._inner_hookexec(hook_name, methods, kwargs, firstresult)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomSaltAndPepperNoise(amount=(0.5, 0.5), salt_and_pepper=(0.5, 0.5), p=1.0, p_batch=1.0, same_on_batch=...77 ],
         [0.7535221 , 0.8120403 , 0.3467099 ],
         [0.17410171, 0.88075536, 0.35246658]]]], dtype=float32)>)
kwargs = {}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomSaltAndPepperNoise(amount=(0.5, 0.5), salt_and_pepper=(0.5, 0.5), p=1.0, p_batch=1.0, same_on_batch=False), v = None, buffers = None
args = (<tf.Tensor: shape=(1, 3, 3, 3), dtype=float32, numpy=
array([[[[0.7512069 , 0.8532861 , 0.59619415],
         [0.1085...7 ],
         [0.7535221 , 0.8120403 , 0.3467099 ],
         [0.17410171, 0.88075536, 0.35246658]]]], dtype=float32)>,)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomSaltAndPepperNoise(amount=(0.5, 0.5), salt_and_pepper=(0.5, 0.5), p=1.0, p_batch=1.0, same_on_batch=...77 ],
         [0.7535221 , 0.8120403 , 0.3467099 ],
         [0.17410171, 0.88075536, 0.35246658]]]], dtype=float32)>)
kwargs = {'buffers': None, 'v': None}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomSaltAndPepperNoise(amount=(0.5, 0.5), salt_and_pepper=(0.5, 0.5), p=1.0, p_batch=1.0, same_on_batch=False), v = None, buffers = None
args = (<tf.Tensor: shape=(1, 3, 3, 3), dtype=float32, numpy=
array([[[[0.7512069 , 0.8532861 , 0.59619415],
         [0.1085...7 ],
         [0.7535221 , 0.8120403 , 0.3467099 ],
         [0.17410171, 0.88075536, 0.35246658]]]], dtype=float32)>,)
kwargs = {}
first_arr = <tf.Tensor: shape=(1, 3, 3, 3), dtype=float32, numpy=
array([[[[0.7512069 , 0.8532861 , 0.59619415],
         [0.10858...377 ],
         [0.7535221 , 0.8120403 , 0.3467099 ],
         [0.17410171, 0.88075536, 0.35246658]]]], dtype=float32)>
replace_v = False, replace_buffers = False, call_signature = <Signature (input, params=None, **kwargs)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Layer, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Layer, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Layer, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomSaltAndPepperNoise(amount=(0.5, 0.5), salt_and_pepper=(0.5, 0.5), p=1.0, p_batch=1.0, same_on_batch=False),)
kwargs = {'input': <tf.Tensor: shape=(1, 3, 3, 3), dtype=float32, numpy=
array([[[[0.7512069 , 0.8532861 , 0.59619415],
       ...77 ],
         [0.7535221 , 0.8120403 , 0.3467099 ],
         [0.17410171, 0.88075536, 0.35246658]]]], dtype=float32)>}

    @wraps(fn)
    def error_handler(*args, **kwargs):
        if not is_traceback_filtering_enabled():
            return fn(*args, **kwargs)
    
        filtered_tb = None
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            filtered_tb = _process_traceback_frames(e.__traceback__)
            # To get the full stack trace, call:
            # `keras.config.disable_traceback_filtering()`
>           raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/keras/src/utils/traceback_utils.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomSaltAndPepperNoise(amount=(0.5, 0.5), salt_and_pepper=(0.5, 0.5), p=1.0, p_batch=1.0, same_on_batch=False)
input = <tf.Tensor: shape=(1, 3, 3, 3), dtype=float32, numpy=
array([[[[0.7512069 , 0.8532861 , 0.59619415],
         [0.10858...377 ],
         [0.7535221 , 0.8120403 , 0.3467099 ],
         [0.17410171, 0.88075536, 0.35246658]]]], dtype=float32)>
params = {'amount_factor': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.5], dtype=float32)>, 'batch_prob': <tf.Tensor:...se, False]],

        [[False, False, False],
         [ True, False,  True],
         [ True, False, False]]]])>, ...}
kwargs = {}, tensorflow_shape_frnt_ = <function tensorflow_shape_frnt_ at 0x7f1b24b457e0>, tensorflow_set_item = <function tensorflow_set_item at 0x7f1b24e49e10>
tensor = <function tensorflow_tensor_frnt at 0x7f1b14dee3b0>
in_tensor = <tf.Tensor: shape=(1, 3, 3, 3), dtype=float32, numpy=
array([[[[0.7512069 , 0.8532861 , 0.59619415],
         [0.10858...377 ],
         [0.7535221 , 0.8120403 , 0.3467099 ],
         [0.17410171, 0.88075536, 0.35246658]]]], dtype=float32)>
input_shape = ivy.frontends.torch.Size([1, 3, 3, 3]), batch_shape = ivy.frontends.torch.Size([1, 3, 3, 3]), flags = {}

    def call(self, input, params=None, **kwargs):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ...ivy.functional.backends.tensorflow.general import tensorflow_set_item
        from ..core._backend import tensor
    
        in_tensor = self.__unpack_input__(input)
        input_shape = tensorflow_shape_frnt_(in_tensor)
        in_tensor = self.transform_tensor(in_tensor)
        batch_shape = tensorflow_shape_frnt_(in_tensor)
        if params is None:
            params = self.forward_parameters(batch_shape)
        if "batch_prob" not in params:
            params = tensorflow_set_item(
                params, "batch_prob", tensor([True] * batch_shape[0])
            )
        params, flags = self._process_kwargs_to_params_and_flags(
            params, self.flags, **kwargs
        )
>       output = self.apply_func(in_tensor, params, flags)

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/base.py:236: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomSaltAndPepperNoise(amount=(0.5, 0.5), salt_and_pepper=(0.5, 0.5), p=1.0, p_batch=1.0, same_on_batch=False)
in_tensor = <tf.Tensor: shape=(1, 3, 3, 3), dtype=float32, numpy=
array([[[[0.7512069 , 0.8532861 , 0.59619415],
         [0.10858...377 ],
         [0.7535221 , 0.8120403 , 0.3467099 ],
         [0.17410171, 0.88075536, 0.35246658]]]], dtype=float32)>
params = {'amount_factor': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.5], dtype=float32)>, 'batch_prob': <tf.Tensor:...se, False]],

        [[False, False, False],
         [ True, False,  True],
         [ True, False, False]]]])>, ...}
flags = {}

    def apply_func(self, in_tensor, params, flags=None):
        if flags is None:
            flags = self.flags
        trans_matrix = self.generate_transformation_matrix(in_tensor, params, flags)
>       output = self.transform_inputs(in_tensor, params, flags, trans_matrix)

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/_2d/base.py:127: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomSaltAndPepperNoise(amount=(0.5, 0.5), salt_and_pepper=(0.5, 0.5), p=1.0, p_batch=1.0, same_on_batch=False)
input = <tf.Tensor: shape=(1, 3, 3, 3), dtype=float32, numpy=
array([[[[0.7512069 , 0.8532861 , 0.59619415],
         [0.10858...377 ],
         [0.7535221 , 0.8120403 , 0.3467099 ],
         [0.17410171, 0.88075536, 0.35246658]]]], dtype=float32)>
params = {'amount_factor': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.5], dtype=float32)>, 'batch_prob': <tf.Tensor:...se, False]],

        [[False, False, False],
         [ True, False,  True],
         [ True, False, False]]]])>, ...}
flags = {}, transform = <tf.Tensor: shape=(1, 3, 3), dtype=float32, numpy=
array([[[1., 0., 0.],
        [0., 1., 0.],
        [0., 0., 1.]]], dtype=float32)>, kwargs = {}
tensorflow_shape_frnt_ = <function tensorflow_shape_frnt_ at 0x7f1b24b457e0>, tensorflow_all_frnt_ = <function tensorflow_all_frnt_ at 0x7f1b24ba3b50>
tensorflow_any_frnt_ = <function tensorflow_any_frnt_ at 0x7f1b14d6e710>, tensorflow_get_item = <function tensorflow_get_item at 0x7f1b24e49c60>
tensorflow_is_autocast_enabled = <function tensorflow_is_autocast_enabled at 0x7f1b1cbdf490>, tensorflow_type_frnt_ = <function tensorflow_type_frnt_ at 0x7f1b14d6c820>
tensorflow_index_put_frnt_ = <function tensorflow_index_put_frnt_ at 0x7f1b14d6d5a0>

    def transform_inputs(self, input, params, flags, transform=None, **kwargs):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_all_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_any_frnt_
        from ...ivy.functional.backends.tensorflow.general import tensorflow_get_item
        from ..utils.helpers import tensorflow_is_autocast_enabled
        from ...ivy.functional.frontends.torch.tensor import tensorflow_type_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_index_put_frnt_
        from .utils.helpers import tensorflow__transform_output_shape
    
        params, flags = self._process_kwargs_to_params_and_flags(
            self._params if params is None else params, flags, **kwargs
        )
        batch_prob = params["batch_prob"]
        to_apply = batch_prob > 0.5
        ori_shape = tensorflow_shape_frnt_(input)
        in_tensor = self.transform_tensor(input)
        self.validate_tensor(in_tensor)
        if tensorflow_all_frnt_(to_apply):
>           output = self.apply_transform(in_tensor, params, flags, transform=transform)

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/base.py:354: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomSaltAndPepperNoise(amount=(0.5, 0.5), salt_and_pepper=(0.5, 0.5), p=1.0, p_batch=1.0, same_on_batch=False)
input = <tf.Tensor: shape=(1, 3, 3, 3), dtype=float32, numpy=
array([[[[0.7512069 , 0.8532861 , 0.59619415],
         [0.10858...377 ],
         [0.7535221 , 0.8120403 , 0.3467099 ],
         [0.17410171, 0.88075536, 0.35246658]]]], dtype=float32)>
params = {'amount_factor': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.5], dtype=float32)>, 'batch_prob': <tf.Tensor:...se, False]],

        [[False, False, False],
         [ True, False,  True],
         [ True, False, False]]]])>, ...}
flags = {}, transform = <tf.Tensor: shape=(1, 3, 3), dtype=float32, numpy=
array([[[1., 0., 0.],
        [0., 1., 0.],
        [0., 0., 1.]]], dtype=float32)>

    def apply_transform(self, input, params, flags, transform=None):
        from ....core.check import tensorflow_KORNIA_CHECK
        from .....ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from .....ivy.functional.frontends.torch.tensor import tensorflow_clone_frnt_
        from .....ivy.functional.backends.tensorflow.general import tensorflow_set_item
    
        tensorflow_KORNIA_CHECK(
            len(tensorflow_shape_frnt_(input)) in (3, 4), "Wrong input dimension."
        )
        if len(tensorflow_shape_frnt_(input)) == 3:
            input = input[None, :, :, :]
        tensorflow_KORNIA_CHECK(
            tensorflow_shape_frnt_(input)[1] in {3, 1},
            "Number of color channels should be 1 or 3.",
        )
        noisy_image = tensorflow_clone_frnt_(input)
        noisy_image = tensorflow_set_item(
>           noisy_image, params["mask_salt"].to(input.device), 1.0
        )
E       AttributeError: Exception encountered when calling tensorflow_RandomSaltAndPepperNoise.call().
E       
E       [1m'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'to'[0m
E       
E       Arguments received by tensorflow_RandomSaltAndPepperNoise.call():
E          input=tf.Tensor(shape=(1, 3, 3, 3), dtype=float32)
E          params=None
E          kwargs=<class 'inspect._empty'>

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/_2d/intensity/salt_pepper_noise.py:99: AttributeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.RandomSaltAndPepperNoise
______________________________________________________________________________ test_RandomSharpness[tensorflow-s2s-False] ______________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_RandomSharpness(target_framework, mode, backend_compile):
        print("kornia.augmentation.RandomSharpness")
    
        init_args = (1.,)
        init_kwargs = {"p": 1.}
        call_args = (torch.rand(1, 1, 5, 5),)
        call_kwargs = {}
    
>       _test_augmentation_class(
            kornia.augmentation.RandomSharpness,
            target_framework,
            init_args,
            init_kwargs,
            call_args,
            call_kwargs,
            deterministic_output=False,
            backend_compile=backend_compile,
        )

kornia/augmentation/test_augmentation2.py:333: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

augmentation_cls = <class 'kornia.augmentation._2d.intensity.sharpness.RandomSharpness'>, target = 'tensorflow', init_args = (1.0,), init_kwargs = {'p': 1.0}
call_args = (tensor([[[[0.6826, 0.5393, 0.5144, 0.7249, 0.8618],
          [0.6537, 0.8816, 0.3957, 0.6021, 0.7414],
          [0...., 0.6552],
          [0.4153, 0.0151, 0.0266, 0.5539, 0.6430],
          [0.1169, 0.6762, 0.2922, 0.5925, 0.3257]]]]),)
call_kwargs = {}, deterministic_output = False, backend_compile = False, tolerance = 0.001

    def _test_augmentation_class(
        augmentation_cls,
        target,
        init_args=(),
        init_kwargs={},
        call_args=(),
        call_kwargs={},
        deterministic_output=True,
        backend_compile=False,
        tolerance=1e-3,
    ):
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_cls = ivy.transpile(augmentation_cls, source="torch", target=target)
    
        torch_aug = augmentation_cls(*init_args, **init_kwargs)
        transpiled_init_args = _nest_torch_tensor_to_new_framework(init_args, target)
        transpiled_init_kwargs = _nest_torch_tensor_to_new_framework(init_kwargs, target)
        transpiled_aug = transpiled_cls(*transpiled_init_args, **transpiled_init_kwargs)
    
        # assert dir(torch_aug) == dir(transpiled_aug), f"attributes/methods of transpiled object do not align with the original - orig: {dir(torch_aug)} != transpiled: {dir(transpiled_aug)}"
    
        torch_out = torch_aug(*call_args, **call_kwargs)
        transpiled_call_args = _nest_torch_tensor_to_new_framework(call_args, target)
        transpiled_call_kwargs = _nest_torch_tensor_to_new_framework(call_kwargs, target)
>       transpiled_out = transpiled_aug(*transpiled_call_args, **transpiled_call_kwargs)

kornia/augmentation/test_augmentation2.py:43: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomSharpness(sharpness=1.0, p=1.0, p_batch=1.0, same_on_batch=False)
args = (<tf.Tensor: shape=(1, 1, 5, 5), dtype=float32, numpy=
array([[[[0.6826286 , 0.5393062 , 0.5144068 , 0.72491753, 0.861...538682 , 0.64302325],
         [0.1169408 , 0.6762271 , 0.2922005 , 0.59248847, 0.3256933 ]]]],
      dtype=float32)>,)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x7f1b1faa5840, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...kexec', code_context=['        return self._inner_hookexec(hook_name, methods, kwargs, firstresult)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomSharpness(sharpness=1.0, p=1.0, p_batch=1.0, same_on_batch=False), <tf.Tensor: shape=(1, 1, 5, 5), d...5538682 , 0.64302325],
         [0.1169408 , 0.6762271 , 0.2922005 , 0.59248847, 0.3256933 ]]]],
      dtype=float32)>)
kwargs = {}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomSharpness(sharpness=1.0, p=1.0, p_batch=1.0, same_on_batch=False), v = None, buffers = None
args = (<tf.Tensor: shape=(1, 1, 5, 5), dtype=float32, numpy=
array([[[[0.6826286 , 0.5393062 , 0.5144068 , 0.72491753, 0.861...538682 , 0.64302325],
         [0.1169408 , 0.6762271 , 0.2922005 , 0.59248847, 0.3256933 ]]]],
      dtype=float32)>,)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomSharpness(sharpness=1.0, p=1.0, p_batch=1.0, same_on_batch=False), <tf.Tensor: shape=(1, 1, 5, 5), d...5538682 , 0.64302325],
         [0.1169408 , 0.6762271 , 0.2922005 , 0.59248847, 0.3256933 ]]]],
      dtype=float32)>)
kwargs = {'buffers': None, 'v': None}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomSharpness(sharpness=1.0, p=1.0, p_batch=1.0, same_on_batch=False), v = None, buffers = None
args = (<tf.Tensor: shape=(1, 1, 5, 5), dtype=float32, numpy=
array([[[[0.6826286 , 0.5393062 , 0.5144068 , 0.72491753, 0.861...538682 , 0.64302325],
         [0.1169408 , 0.6762271 , 0.2922005 , 0.59248847, 0.3256933 ]]]],
      dtype=float32)>,)
kwargs = {}
first_arr = <tf.Tensor: shape=(1, 1, 5, 5), dtype=float32, numpy=
array([[[[0.6826286 , 0.5393062 , 0.5144068 , 0.72491753, 0.8618....5538682 , 0.64302325],
         [0.1169408 , 0.6762271 , 0.2922005 , 0.59248847, 0.3256933 ]]]],
      dtype=float32)>
replace_v = False, replace_buffers = False, call_signature = <Signature (input, params=None, **kwargs)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Layer, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Layer, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Layer, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomSharpness(sharpness=1.0, p=1.0, p_batch=1.0, same_on_batch=False),)
kwargs = {'input': <tf.Tensor: shape=(1, 1, 5, 5), dtype=float32, numpy=
array([[[[0.6826286 , 0.5393062 , 0.5144068 , 0.724917...5538682 , 0.64302325],
         [0.1169408 , 0.6762271 , 0.2922005 , 0.59248847, 0.3256933 ]]]],
      dtype=float32)>}

    @wraps(fn)
    def error_handler(*args, **kwargs):
        if not is_traceback_filtering_enabled():
            return fn(*args, **kwargs)
    
        filtered_tb = None
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            filtered_tb = _process_traceback_frames(e.__traceback__)
            # To get the full stack trace, call:
            # `keras.config.disable_traceback_filtering()`
>           raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/keras/src/utils/traceback_utils.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomSharpness(sharpness=1.0, p=1.0, p_batch=1.0, same_on_batch=False)
input = <tf.Tensor: shape=(1, 1, 5, 5), dtype=float32, numpy=
array([[[[0.6826286 , 0.5393062 , 0.5144068 , 0.72491753, 0.8618....5538682 , 0.64302325],
         [0.1169408 , 0.6762271 , 0.2922005 , 0.59248847, 0.3256933 ]]]],
      dtype=float32)>
params = {'batch_prob': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>, 'forward_input_shape': <tf.Te...py=array([1, 1, 5, 5])>, 'sharpness': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.74389315], dtype=float32)>}
kwargs = {}, tensorflow_shape_frnt_ = <function tensorflow_shape_frnt_ at 0x7f1b14a89360>, tensorflow_set_item = <function tensorflow_set_item at 0x7f1b14d2d090>
tensor = <function tensorflow_tensor_frnt at 0x7f1b14d828c0>
in_tensor = <tf.Tensor: shape=(1, 1, 5, 5), dtype=float32, numpy=
array([[[[0.6826286 , 0.5393062 , 0.5144068 , 0.72491753, 0.8618....5538682 , 0.64302325],
         [0.1169408 , 0.6762271 , 0.2922005 , 0.59248847, 0.3256933 ]]]],
      dtype=float32)>
input_shape = ivy.frontends.torch.Size([1, 1, 5, 5]), batch_shape = ivy.frontends.torch.Size([1, 1, 5, 5]), flags = {}

    def call(self, input, params=None, **kwargs):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ...ivy.functional.backends.tensorflow.general import tensorflow_set_item
        from ..core._backend import tensor
    
        in_tensor = self.__unpack_input__(input)
        input_shape = tensorflow_shape_frnt_(in_tensor)
        in_tensor = self.transform_tensor(in_tensor)
        batch_shape = tensorflow_shape_frnt_(in_tensor)
        if params is None:
            params = self.forward_parameters(batch_shape)
        if "batch_prob" not in params:
            params = tensorflow_set_item(
                params, "batch_prob", tensor([True] * batch_shape[0])
            )
        params, flags = self._process_kwargs_to_params_and_flags(
            params, self.flags, **kwargs
        )
>       output = self.apply_func(in_tensor, params, flags)

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/base.py:236: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomSharpness(sharpness=1.0, p=1.0, p_batch=1.0, same_on_batch=False)
in_tensor = <tf.Tensor: shape=(1, 1, 5, 5), dtype=float32, numpy=
array([[[[0.6826286 , 0.5393062 , 0.5144068 , 0.72491753, 0.8618....5538682 , 0.64302325],
         [0.1169408 , 0.6762271 , 0.2922005 , 0.59248847, 0.3256933 ]]]],
      dtype=float32)>
params = {'batch_prob': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>, 'forward_input_shape': <tf.Te...py=array([1, 1, 5, 5])>, 'sharpness': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.74389315], dtype=float32)>}
flags = {}

    def apply_func(self, in_tensor, params, flags=None):
        if flags is None:
            flags = self.flags
        trans_matrix = self.generate_transformation_matrix(in_tensor, params, flags)
>       output = self.transform_inputs(in_tensor, params, flags, trans_matrix)

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/_2d/base.py:127: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomSharpness(sharpness=1.0, p=1.0, p_batch=1.0, same_on_batch=False)
input = <tf.Tensor: shape=(1, 1, 5, 5), dtype=float32, numpy=
array([[[[0.6826286 , 0.5393062 , 0.5144068 , 0.72491753, 0.8618....5538682 , 0.64302325],
         [0.1169408 , 0.6762271 , 0.2922005 , 0.59248847, 0.3256933 ]]]],
      dtype=float32)>
params = {'batch_prob': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>, 'forward_input_shape': <tf.Te...py=array([1, 1, 5, 5])>, 'sharpness': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.74389315], dtype=float32)>}
flags = {}, transform = <tf.Tensor: shape=(1, 3, 3), dtype=float32, numpy=
array([[[1., 0., 0.],
        [0., 1., 0.],
        [0., 0., 1.]]], dtype=float32)>, kwargs = {}
tensorflow_shape_frnt_ = <function tensorflow_shape_frnt_ at 0x7f1b14a89360>, tensorflow_all_frnt_ = <function tensorflow_all_frnt_ at 0x7f1b14a88ca0>
tensorflow_any_frnt_ = <function tensorflow_any_frnt_ at 0x7f1b14b49750>, tensorflow_get_item = <function tensorflow_get_item at 0x7f1b14d2cee0>
tensorflow_is_autocast_enabled = <function tensorflow_is_autocast_enabled at 0x7f1b1cba6710>, tensorflow_type_frnt_ = <function tensorflow_type_frnt_ at 0x7f1b14fc0430>
tensorflow_index_put_frnt_ = <function tensorflow_index_put_frnt_ at 0x7f1b14fc01f0>

    def transform_inputs(self, input, params, flags, transform=None, **kwargs):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_all_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_any_frnt_
        from ...ivy.functional.backends.tensorflow.general import tensorflow_get_item
        from ..utils.helpers import tensorflow_is_autocast_enabled
        from ...ivy.functional.frontends.torch.tensor import tensorflow_type_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_index_put_frnt_
        from .utils.helpers import tensorflow__transform_output_shape
    
        params, flags = self._process_kwargs_to_params_and_flags(
            self._params if params is None else params, flags, **kwargs
        )
        batch_prob = params["batch_prob"]
        to_apply = batch_prob > 0.5
        ori_shape = tensorflow_shape_frnt_(input)
        in_tensor = self.transform_tensor(input)
        self.validate_tensor(in_tensor)
        if tensorflow_all_frnt_(to_apply):
>           output = self.apply_transform(in_tensor, params, flags, transform=transform)

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/base.py:354: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomSharpness(sharpness=1.0, p=1.0, p_batch=1.0, same_on_batch=False)
input = <tf.Tensor: shape=(1, 1, 5, 5), dtype=float32, numpy=
array([[[[0.6826286 , 0.5393062 , 0.5144068 , 0.72491753, 0.8618....5538682 , 0.64302325],
         [0.1169408 , 0.6762271 , 0.2922005 , 0.59248847, 0.3256933 ]]]],
      dtype=float32)>
params = {'batch_prob': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>, 'forward_input_shape': <tf.Te...py=array([1, 1, 5, 5])>, 'sharpness': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.74389315], dtype=float32)>}
flags = {}, transform = <tf.Tensor: shape=(1, 3, 3), dtype=float32, numpy=
array([[[1., 0., 0.],
        [0., 1., 0.],
        [0., 0., 1.]]], dtype=float32)>

    def apply_transform(self, input, params, flags, transform=None):
        factor = params["sharpness"]
>       return sharpness(input, factor)
E       NameError: Exception encountered when calling tensorflow_RandomSharpness.call().
E       
E       [1mname 'sharpness' is not defined[0m
E       
E       Arguments received by tensorflow_RandomSharpness.call():
E          input=tf.Tensor(shape=(1, 1, 5, 5), dtype=float32)
E          params=None
E          kwargs=<class 'inspect._empty'>

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/_2d/intensity/sharpness.py:46: NameError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.RandomSharpness
______________________________________________________________________________ test_RandomSolarize[tensorflow-s2s-False] _______________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_RandomSolarize(target_framework, mode, backend_compile):
        print("kornia.augmentation.RandomSolarize")
    
        init_args = (0.1, 0.1)
        init_kwargs = {"p": 1.}
        call_args = (torch.rand(1, 1, 5, 5),)
        call_kwargs = {}
    
>       _test_augmentation_class(
            kornia.augmentation.RandomSolarize,
            target_framework,
            init_args,
            init_kwargs,
            call_args,
            call_kwargs,
            deterministic_output=False,
            backend_compile=backend_compile,
        )

kornia/augmentation/test_augmentation2.py:373: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

augmentation_cls = <class 'kornia.augmentation._2d.intensity.solarize.RandomSolarize'>, target = 'tensorflow', init_args = (0.1, 0.1), init_kwargs = {'p': 1.0}
call_args = (tensor([[[[0.5707, 0.1675, 0.1750, 0.3045, 0.5639],
          [0.8792, 0.4872, 0.5921, 0.4961, 0.1826],
          [0...., 0.4432],
          [0.6160, 0.3131, 0.4891, 0.7545, 0.9620],
          [0.5304, 0.3079, 0.8573, 0.8288, 0.2406]]]]),)
call_kwargs = {}, deterministic_output = False, backend_compile = False, tolerance = 0.001

    def _test_augmentation_class(
        augmentation_cls,
        target,
        init_args=(),
        init_kwargs={},
        call_args=(),
        call_kwargs={},
        deterministic_output=True,
        backend_compile=False,
        tolerance=1e-3,
    ):
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_cls = ivy.transpile(augmentation_cls, source="torch", target=target)
    
        torch_aug = augmentation_cls(*init_args, **init_kwargs)
        transpiled_init_args = _nest_torch_tensor_to_new_framework(init_args, target)
        transpiled_init_kwargs = _nest_torch_tensor_to_new_framework(init_kwargs, target)
        transpiled_aug = transpiled_cls(*transpiled_init_args, **transpiled_init_kwargs)
    
        # assert dir(torch_aug) == dir(transpiled_aug), f"attributes/methods of transpiled object do not align with the original - orig: {dir(torch_aug)} != transpiled: {dir(transpiled_aug)}"
    
        torch_out = torch_aug(*call_args, **call_kwargs)
        transpiled_call_args = _nest_torch_tensor_to_new_framework(call_args, target)
        transpiled_call_kwargs = _nest_torch_tensor_to_new_framework(call_kwargs, target)
>       transpiled_out = transpiled_aug(*transpiled_call_args, **transpiled_call_kwargs)

kornia/augmentation/test_augmentation2.py:43: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomSolarize(thresholds=0.1, additions=0.1, p=1.0, p_batch=1.0, same_on_batch=False)
args = (<tf.Tensor: shape=(1, 1, 5, 5), dtype=float32, numpy=
array([[[[0.570668  , 0.1674949 , 0.17501271, 0.30453962, 0.563...544719 , 0.9620496 ],
         [0.53040034, 0.3079133 , 0.85728186, 0.82877636, 0.24056524]]]],
      dtype=float32)>,)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x7f1b1fcf6440, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...kexec', code_context=['        return self._inner_hookexec(hook_name, methods, kwargs, firstresult)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomSolarize(thresholds=0.1, additions=0.1, p=1.0, p_batch=1.0, same_on_batch=False), <tf.Tensor: shape=...7544719 , 0.9620496 ],
         [0.53040034, 0.3079133 , 0.85728186, 0.82877636, 0.24056524]]]],
      dtype=float32)>)
kwargs = {}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomSolarize(thresholds=0.1, additions=0.1, p=1.0, p_batch=1.0, same_on_batch=False), v = None, buffers = None
args = (<tf.Tensor: shape=(1, 1, 5, 5), dtype=float32, numpy=
array([[[[0.570668  , 0.1674949 , 0.17501271, 0.30453962, 0.563...544719 , 0.9620496 ],
         [0.53040034, 0.3079133 , 0.85728186, 0.82877636, 0.24056524]]]],
      dtype=float32)>,)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomSolarize(thresholds=0.1, additions=0.1, p=1.0, p_batch=1.0, same_on_batch=False), <tf.Tensor: shape=...7544719 , 0.9620496 ],
         [0.53040034, 0.3079133 , 0.85728186, 0.82877636, 0.24056524]]]],
      dtype=float32)>)
kwargs = {'buffers': None, 'v': None}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomSolarize(thresholds=0.1, additions=0.1, p=1.0, p_batch=1.0, same_on_batch=False), v = None, buffers = None
args = (<tf.Tensor: shape=(1, 1, 5, 5), dtype=float32, numpy=
array([[[[0.570668  , 0.1674949 , 0.17501271, 0.30453962, 0.563...544719 , 0.9620496 ],
         [0.53040034, 0.3079133 , 0.85728186, 0.82877636, 0.24056524]]]],
      dtype=float32)>,)
kwargs = {}
first_arr = <tf.Tensor: shape=(1, 1, 5, 5), dtype=float32, numpy=
array([[[[0.570668  , 0.1674949 , 0.17501271, 0.30453962, 0.5639....7544719 , 0.9620496 ],
         [0.53040034, 0.3079133 , 0.85728186, 0.82877636, 0.24056524]]]],
      dtype=float32)>
replace_v = False, replace_buffers = False, call_signature = <Signature (input, params=None, **kwargs)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Layer, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Layer, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Layer, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomSolarize(thresholds=0.1, additions=0.1, p=1.0, p_batch=1.0, same_on_batch=False),)
kwargs = {'input': <tf.Tensor: shape=(1, 1, 5, 5), dtype=float32, numpy=
array([[[[0.570668  , 0.1674949 , 0.17501271, 0.304539...7544719 , 0.9620496 ],
         [0.53040034, 0.3079133 , 0.85728186, 0.82877636, 0.24056524]]]],
      dtype=float32)>}

    @wraps(fn)
    def error_handler(*args, **kwargs):
        if not is_traceback_filtering_enabled():
            return fn(*args, **kwargs)
    
        filtered_tb = None
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            filtered_tb = _process_traceback_frames(e.__traceback__)
            # To get the full stack trace, call:
            # `keras.config.disable_traceback_filtering()`
>           raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/keras/src/utils/traceback_utils.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomSolarize(thresholds=0.1, additions=0.1, p=1.0, p_batch=1.0, same_on_batch=False)
input = <tf.Tensor: shape=(1, 1, 5, 5), dtype=float32, numpy=
array([[[[0.570668  , 0.1674949 , 0.17501271, 0.30453962, 0.5639....7544719 , 0.9620496 ],
         [0.53040034, 0.3079133 , 0.85728186, 0.82877636, 0.24056524]]]],
      dtype=float32)>
params = {'additions': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.06338146], dtype=float32)>, 'batch_prob': <tf.Tens...y=array([1, 1, 5, 5])>, 'thresholds': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.46846327], dtype=float32)>}
kwargs = {}, tensorflow_shape_frnt_ = <function tensorflow_shape_frnt_ at 0x7f1b14709f30>, tensorflow_set_item = <function tensorflow_set_item at 0x7f1b1cef5a20>
tensor = <function tensorflow_tensor_frnt at 0x7f1b1466b490>
in_tensor = <tf.Tensor: shape=(1, 1, 5, 5), dtype=float32, numpy=
array([[[[0.570668  , 0.1674949 , 0.17501271, 0.30453962, 0.5639....7544719 , 0.9620496 ],
         [0.53040034, 0.3079133 , 0.85728186, 0.82877636, 0.24056524]]]],
      dtype=float32)>
input_shape = ivy.frontends.torch.Size([1, 1, 5, 5]), batch_shape = ivy.frontends.torch.Size([1, 1, 5, 5]), flags = {}

    def call(self, input, params=None, **kwargs):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ...ivy.functional.backends.tensorflow.general import tensorflow_set_item
        from ..core._backend import tensor
    
        in_tensor = self.__unpack_input__(input)
        input_shape = tensorflow_shape_frnt_(in_tensor)
        in_tensor = self.transform_tensor(in_tensor)
        batch_shape = tensorflow_shape_frnt_(in_tensor)
        if params is None:
            params = self.forward_parameters(batch_shape)
        if "batch_prob" not in params:
            params = tensorflow_set_item(
                params, "batch_prob", tensor([True] * batch_shape[0])
            )
        params, flags = self._process_kwargs_to_params_and_flags(
            params, self.flags, **kwargs
        )
>       output = self.apply_func(in_tensor, params, flags)

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/base.py:236: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomSolarize(thresholds=0.1, additions=0.1, p=1.0, p_batch=1.0, same_on_batch=False)
in_tensor = <tf.Tensor: shape=(1, 1, 5, 5), dtype=float32, numpy=
array([[[[0.570668  , 0.1674949 , 0.17501271, 0.30453962, 0.5639....7544719 , 0.9620496 ],
         [0.53040034, 0.3079133 , 0.85728186, 0.82877636, 0.24056524]]]],
      dtype=float32)>
params = {'additions': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.06338146], dtype=float32)>, 'batch_prob': <tf.Tens...y=array([1, 1, 5, 5])>, 'thresholds': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.46846327], dtype=float32)>}
flags = {}

    def apply_func(self, in_tensor, params, flags=None):
        if flags is None:
            flags = self.flags
        trans_matrix = self.generate_transformation_matrix(in_tensor, params, flags)
>       output = self.transform_inputs(in_tensor, params, flags, trans_matrix)

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/_2d/base.py:127: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomSolarize(thresholds=0.1, additions=0.1, p=1.0, p_batch=1.0, same_on_batch=False)
input = <tf.Tensor: shape=(1, 1, 5, 5), dtype=float32, numpy=
array([[[[0.570668  , 0.1674949 , 0.17501271, 0.30453962, 0.5639....7544719 , 0.9620496 ],
         [0.53040034, 0.3079133 , 0.85728186, 0.82877636, 0.24056524]]]],
      dtype=float32)>
params = {'additions': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.06338146], dtype=float32)>, 'batch_prob': <tf.Tens...y=array([1, 1, 5, 5])>, 'thresholds': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.46846327], dtype=float32)>}
flags = {}, transform = <tf.Tensor: shape=(1, 3, 3), dtype=float32, numpy=
array([[[1., 0., 0.],
        [0., 1., 0.],
        [0., 0., 1.]]], dtype=float32)>, kwargs = {}
tensorflow_shape_frnt_ = <function tensorflow_shape_frnt_ at 0x7f1b14709f30>, tensorflow_all_frnt_ = <function tensorflow_all_frnt_ at 0x7f1b1470b250>
tensorflow_any_frnt_ = <function tensorflow_any_frnt_ at 0x7f1b1464b910>, tensorflow_get_item = <function tensorflow_get_item at 0x7f1b1cef5870>
tensorflow_is_autocast_enabled = <function tensorflow_is_autocast_enabled at 0x7f1b1cf1b490>, tensorflow_type_frnt_ = <function tensorflow_type_frnt_ at 0x7f1b1464b760>
tensorflow_index_put_frnt_ = <function tensorflow_index_put_frnt_ at 0x7f1b1464b5b0>

    def transform_inputs(self, input, params, flags, transform=None, **kwargs):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_all_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_any_frnt_
        from ...ivy.functional.backends.tensorflow.general import tensorflow_get_item
        from ..utils.helpers import tensorflow_is_autocast_enabled
        from ...ivy.functional.frontends.torch.tensor import tensorflow_type_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_index_put_frnt_
        from .utils.helpers import tensorflow__transform_output_shape
    
        params, flags = self._process_kwargs_to_params_and_flags(
            self._params if params is None else params, flags, **kwargs
        )
        batch_prob = params["batch_prob"]
        to_apply = batch_prob > 0.5
        ori_shape = tensorflow_shape_frnt_(input)
        in_tensor = self.transform_tensor(input)
        self.validate_tensor(in_tensor)
        if tensorflow_all_frnt_(to_apply):
>           output = self.apply_transform(in_tensor, params, flags, transform=transform)

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/base.py:354: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomSolarize(thresholds=0.1, additions=0.1, p=1.0, p_batch=1.0, same_on_batch=False)
input = <tf.Tensor: shape=(1, 1, 5, 5), dtype=float32, numpy=
array([[[[0.570668  , 0.1674949 , 0.17501271, 0.30453962, 0.5639....7544719 , 0.9620496 ],
         [0.53040034, 0.3079133 , 0.85728186, 0.82877636, 0.24056524]]]],
      dtype=float32)>
params = {'additions': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.06338146], dtype=float32)>, 'batch_prob': <tf.Tens...y=array([1, 1, 5, 5])>, 'thresholds': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.46846327], dtype=float32)>}
flags = {}, transform = <tf.Tensor: shape=(1, 3, 3), dtype=float32, numpy=
array([[[1., 0., 0.],
        [0., 1., 0.],
        [0., 0., 1.]]], dtype=float32)>

    def apply_transform(self, input, params, flags, transform=None):
        from ....enhance.adjust import tensorflow_solarize
    
        thresholds = params["thresholds"]
        additions: typing.Any
        if "additions" in params:
            additions = params["additions"]
        else:
            additions = None
>       return tensorflow_solarize(input, thresholds, additions)

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/_2d/intensity/solarize.py:57: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = <tf.Tensor: shape=(1, 1, 5, 5), dtype=float32, numpy=
array([[[[0.570668  , 0.1674949 , 0.17501271, 0.30453962, 0.5639....7544719 , 0.9620496 ],
         [0.53040034, 0.3079133 , 0.85728186, 0.82877636, 0.24056524]]]],
      dtype=float32)>
thresholds = <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.46846327], dtype=float32)>, additions = <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.06338146], dtype=float32)>

    def tensorflow_solarize(input, thresholds=0.5, additions=None):
        from ...ivy.functional.frontends.torch.creation_ops import tensorflow_as_tensor_frnt
        from ...ivy.functional.frontends.torch.reduction_ops import tensorflow_all_frnt
        from ...ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_size_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_to_frnt_
        from ...ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            tensorflow_stack_frnt,
        )
        from ...ivy.functional.frontends.torch.tensor import tensorflow_expand_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_clamp_frnt_
    
        if not isinstance(input, (tensorflow.Tensor, tensorflow.Variable)):
            raise TypeError(f"Input type is not a Tensor. Got {type(input)}")
        if not isinstance(thresholds, (float, tensorflow.Tensor, tensorflow.Variable)):
            raise TypeError(
                f"The factor should be either a float or Tensor. Got {type(thresholds)}"
            )
        if isinstance(thresholds, (float,)):
            thresholds = tensorflow_as_tensor_frnt(thresholds)
        if additions is not None:
            if not isinstance(additions, (float, tensorflow.Tensor, tensorflow.Variable)):
                raise TypeError(
                    f"The factor should be either a float or Tensor. Got {type(additions)}"
                )
            if isinstance(additions, (float,)):
                additions = tensorflow_as_tensor_frnt(additions)
>           if not tensorflow_all_frnt((additions < 0.5) * (additions > -0.5)):

ivy_transpiled_outputs/tensorflow_outputs/kornia/enhance/adjust.py:101: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <tf.Tensor: shape=(1,), dtype=bool, numpy=array([ True])>, rhs = <tf.Tensor: shape=(1,), dtype=bool, numpy=array([ True])>

    def impl(self, rhs):
        try:
            return original_method(self, rhs)
        except Exception:
>           return patched_method(self, rhs)

ivy_transpiled_outputs/tensorflow_outputs/__init__.py:65: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = <tf.Tensor: shape=(1,), dtype=bool, numpy=array([ True])>, other = <tf.Tensor: shape=(1,), dtype=bool, numpy=array([ True])>

    def tensorflow___mul___frnt_(tensor, other):
        from .pointwise_ops import tensorflow_mul_frnt
    
>       return tensorflow_mul_frnt(tensor, other)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/tensor.py:93: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = <tf.Tensor: shape=(1,), dtype=bool, numpy=array([ True])>, other = <tf.Tensor: shape=(1,), dtype=bool, numpy=array([ True])>

    def tensorflow_mul_frnt(input, other, *, out=None):
        from .__init__ import tensorflow_promote_types_of_torch_inputs_frnt
        from ...backends.tensorflow.elementwise import tensorflow_multiply
    
        input, other = tensorflow_promote_types_of_torch_inputs_frnt(input, other)
>       return tensorflow_multiply(input, other, out=out)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/pointwise_ops.py:111: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x1 = <tf.Tensor: shape=(1,), dtype=bool, numpy=array([ True])>, x2 = <tf.Tensor: shape=(1,), dtype=bool, numpy=array([ True])>

    def tensorflow_multiply(
        x1: Union[float, tensorflow.Tensor, tensorflow.Variable],
        x2: Union[float, tensorflow.Tensor, tensorflow.Variable],
        /,
        *,
        out: Optional[Union[tensorflow.Tensor, tensorflow.Variable]] = None,
    ):
        from ...ivy.data_type import tensorflow_promote_types_of_inputs_bknd
    
        x1, x2 = tensorflow_promote_types_of_inputs_bknd(x1, x2)
>       return tensorflow.math.multiply(x1, x2)
E       tensorflow.python.framework.errors_impl.InvalidArgumentError: Exception encountered when calling tensorflow_RandomSolarize.call().
E       
E       [1mValue for attr 'T' of bool is not in the list of allowed values: bfloat16, half, float, double, uint8, int8, uint16, int16, int32, uint32, uint64, int64, complex64, complex128
E       	; NodeDef: {{node Mul}}; Op<name=Mul; signature=x:T, y:T -> z:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE, DT_UINT8, DT_INT8, DT_UINT16, DT_INT16, DT_INT32, DT_UINT32, DT_UINT64, DT_INT64, DT_COMPLEX64, DT_COMPLEX128]; is_commutative=true> [Op:Mul] name: [0m
E       
E       Arguments received by tensorflow_RandomSolarize.call():
E          input=tf.Tensor(shape=(1, 1, 5, 5), dtype=float32)
E          params=None
E          kwargs=<class 'inspect._empty'>

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/backends/tensorflow/elementwise.py:299: InvalidArgumentError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.RandomSolarize
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/augmentation/test_augmentation2.py::test_RandomMotionBlur[tensorflow-s2s-False] - TypeError: Exception encountered when calling tensorflow_RandomMotionBlur.call().
FAILED kornia/augmentation/test_augmentation2.py::test_RandomSaltAndPepperNoise[tensorflow-s2s-False] - AttributeError: Exception encountered when calling tensorflow_RandomSaltAndPepperNoise.call().
FAILED kornia/augmentation/test_augmentation2.py::test_RandomSharpness[tensorflow-s2s-False] - NameError: Exception encountered when calling tensorflow_RandomSharpness.call().
FAILED kornia/augmentation/test_augmentation2.py::test_RandomSolarize[tensorflow-s2s-False] - tensorflow.python.framework.errors_impl.InvalidArgumentError: Exception encountered when calling tensor...
============================================================================== 4 failed, 13 passed in 3628.18s (1:00:28) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 2 items

kornia/test_io.py ..                                                                                                                                                                             [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
==================================================================================== 2 passed in 114.65s (0:01:54) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 8 items

kornia/geometry/test_homography.py ........                                                                                                                                                      [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
==================================================================================== 8 passed in 716.22s (0:11:56) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 10 items

kornia/test_feature5.py FF.....FF.                                                                                                                                                               [100%]

=============================================================================================== FAILURES ===============================================================================================
________________________________________________________________________________ test_LAFOrienter[tensorflow-s2s-False] ________________________________________________________________________________

inp = <tf.Variable 'Variable:0' shape=(5, 1, 1) dtype=float32, numpy=
array([[[ 0.08202291]],

       [[ 0.15557551]],

       [[-0.3600111 ]],

       [[ 0.1717596 ]],

       [[-0.18395472]]], dtype=float32)>
query = slice(None, None, None), val = <tf.Tensor: shape=(1, 5), dtype=float32, numpy=
array([[0.1190625 , 0.2311236 , 0.29962778, 0.2311236 , 0.1190625 ]],
      dtype=float32)>, kwargs = {}

    @functools.wraps(fn)
    def wrapper(inp, query, val, **kwargs):
        try:
>           inp.__setitem__(query, val)
E           AttributeError: 'ResourceVariable' object has no attribute '__setitem__'. Did you mean: '__getitem__'?

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:233: AttributeError

During handling of the above exception, another exception occurred:

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_LAFOrienter(target_framework, mode, backend_compile):
        print("kornia.feature.LAFOrienter")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledLAFOrienter = ivy.transpile(kornia.feature.LAFOrienter, source="torch", target=target_framework)
    
        laf = torch.rand(1, 2, 2, 3)
        img = torch.rand(1, 1, 32, 32)
        transpiled_laf = _nest_torch_tensor_to_new_framework(laf, target_framework)
        transpiled_img = _nest_torch_tensor_to_new_framework(img, target_framework)
    
        model = kornia.feature.LAFOrienter()
        torch_out = model(laf, img)
    
>       transpiled_model = TranspiledLAFOrienter()

kornia/test_feature5.py:33: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'tensorflow_LAFOrienter' object has no attribute 'angle_detector'") raised in repr()] tensorflow_LAFOrienter object at 0x7f994ad24250>, patch_size = 32, num_angular_bins = 36
angle_detector = None

    def __init__(self, patch_size=32, num_angular_bins=36, angle_detector=None):
        self.super___init__(
            patch_size=patch_size,
            num_angular_bins=num_angular_bins,
            angle_detector=angle_detector,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        self.patch_size = patch_size
        self.num_ang_bins = num_angular_bins
        self.angle_detector: typing.Any
        if angle_detector is None:
>           self.angle_detector = tensorflow_PatchDominantGradientOrientation(
                self.patch_size, self.num_ang_bins
            )

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/orientation.py:270: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_PatchDominantGradientOrientation(patch_size=32, num_ang_bins=36, eps=1e-08), args = (32, 36), kwargs = {}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_PatchDominantGradientOrientation(patch_size=32, num_ang_bins=36, eps=1e-08), patch_size = 32, num_angular_bins = 36, eps = 1e-08

    @tensorflow_store_config_info
    def __init__(self, patch_size=32, num_angular_bins=36, eps=1e-08):
        from ..filters.sobel import tensorflow_SpatialGradient
        from ...torch.nn.modules.conv import tensorflow_Conv1d
        from ...ivy.functional.backends.tensorflow.general import tensorflow_set_item
        from ..filters.kernels import tensorflow_get_gaussian_discrete_kernel1d
        from ..filters.kernels import tensorflow_get_gaussian_kernel2d
    
        self.super___init__(
            patch_size=patch_size,
            num_angular_bins=num_angular_bins,
            eps=eps,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        self.patch_size = patch_size
        self.num_ang_bins = num_angular_bins
        self.gradient = tensorflow_SpatialGradient("sobel", 1)
        self.eps = eps
        self.angular_smooth = tensorflow_Conv1d(
            1, 1, kernel_size=5, padding=2, bias=False, padding_mode="circular"
        )
>       self.angular_smooth.weight = tensorflow_set_item(
            self.angular_smooth.weight,
            slice(None, None, None),
            tensorflow_get_gaussian_discrete_kernel1d(5, 1.6),
        )

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/orientation.py:62: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

inp = <tf.Variable 'Variable:0' shape=(5, 1, 1) dtype=float32, numpy=
array([[[ 0.08202291]],

       [[ 0.15557551]],

       [[-0.3600111 ]],

       [[ 0.1717596 ]],

       [[-0.18395472]]], dtype=float32)>
query = slice(None, None, None), val = <tf.Tensor: shape=(1, 5), dtype=float32, numpy=
array([[0.1190625 , 0.2311236 , 0.29962778, 0.2311236 , 0.1190625 ]],
      dtype=float32)>, kwargs = {}

    @functools.wraps(fn)
    def wrapper(inp, query, val, **kwargs):
        try:
            inp.__setitem__(query, val)
            res = inp
        except IndexError:
            raise
        except Exception:
>           res = fn(inp, query, val, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:238: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (<tf.Variable 'Variable:0' shape=(5, 1, 1) dtype=float32, numpy=
array([[[ 0.08202291]],

       [[ 0.15557551]],

   ... 5), dtype=float32, numpy=
array([[0.1190625 , 0.2311236 , 0.29962778, 0.2311236 , 0.1190625 ]],
      dtype=float32)>)
kwargs = {}, handle_mixed_in_backend = True

    @functools.wraps(fn)
    def _handle_partial_mixed_function(*args, **kwargs):
        handle_mixed_in_backend = False
        if not hasattr(fn, "partial_mixed_handler"):
            handle_mixed_in_backend = True
        else:
            compos = getattr(fn, "compos")
            condition = getattr(fn, "partial_mixed_handler")
        if handle_mixed_in_backend or condition(*args, **kwargs):
>           return fn(*args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/func_wrapper.py:173: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[ 0.08202291]],

       [[ 0.15557551]],

       [[-0.3600111 ]],

       [[ 0.1717596 ]],

       [[-0.18395472]]], dtype=float32), query = slice(None, None, None)
val = array([[0.1190625 , 0.2311236 , 0.29962778, 0.2311236 , 0.1190625 ]],
      dtype=float32)

    @tensorflow_handle_set_item
    @tensorflow_handle_partial_mixed_function
    def tensorflow_set_item(
        x: Union[tensorflow.Tensor, tensorflow.Variable],
        query: Union[tensorflow.Tensor, tensorflow.Variable, Tuple],
        val: Union[tensorflow.Tensor, tensorflow.Variable],
        /,
        *,
        copy: Optional[bool] = False,
    ):
        if tensorflow.is_tensor(x):
            x = x.numpy()
        if tensorflow.is_tensor(val):
            val = val.numpy()
        if isinstance(query, (tensorflow.Tensor, tensorflow.Variable)):
            query = query.numpy()
        elif isinstance(query, tuple):
            query = tuple(
                q.numpy() if isinstance(q, (tensorflow.Tensor, tensorflow.Variable)) else q
                for q in query
            )
>       x[query] = val
E       ValueError: could not broadcast input array from shape (1,5) into shape (5,1,1)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/backends/tensorflow/general.py:109: ValueError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.LAFOrienter
_____________________________________________________________________ test_PatchDominantGradientOrientation[tensorflow-s2s-False] ______________________________________________________________________

inp = <tf.Variable 'Variable:0' shape=(5, 1, 1) dtype=float32, numpy=
array([[[-0.32304668]],

       [[-0.44872975]],

       [[-0.15750647]],

       [[-0.22749448]],

       [[ 0.5256958 ]]], dtype=float32)>
query = slice(None, None, None), val = <tf.Tensor: shape=(1, 5), dtype=float32, numpy=
array([[0.1190625 , 0.2311236 , 0.29962778, 0.2311236 , 0.1190625 ]],
      dtype=float32)>, kwargs = {}

>   ???
E   AttributeError: 'ResourceVariable' object has no attribute '__setitem__'. Did you mean: '__getitem__'?

/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:233: AttributeError

During handling of the above exception, another exception occurred:

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_PatchDominantGradientOrientation(target_framework, mode, backend_compile):
        print("kornia.feature.PatchDominantGradientOrientation")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledPatchDominantGradientOrientation = ivy.transpile(kornia.feature.PatchDominantGradientOrientation, source="torch", target=target_framework)
    
        patch = torch.rand(10, 1, 32, 32)
        transpiled_patch = _nest_torch_tensor_to_new_framework(patch, target_framework)
    
        model = kornia.feature.PatchDominantGradientOrientation()
        torch_out = model(patch)
    
>       transpiled_model = TranspiledPatchDominantGradientOrientation()

kornia/test_feature5.py:59: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_PatchDominantGradientOrientation(patch_size=32, num_ang_bins=36, eps=1e-08), args = (), kwargs = {}

>   ???

/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_PatchDominantGradientOrientation(patch_size=32, num_ang_bins=36, eps=1e-08), patch_size = 32, num_angular_bins = 36, eps = 1e-08

>   ???

/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/orientation.py:62: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

inp = <tf.Variable 'Variable:0' shape=(5, 1, 1) dtype=float32, numpy=
array([[[-0.32304668]],

       [[-0.44872975]],

       [[-0.15750647]],

       [[-0.22749448]],

       [[ 0.5256958 ]]], dtype=float32)>
query = slice(None, None, None), val = <tf.Tensor: shape=(1, 5), dtype=float32, numpy=
array([[0.1190625 , 0.2311236 , 0.29962778, 0.2311236 , 0.1190625 ]],
      dtype=float32)>, kwargs = {}

>   ???

/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:238: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (<tf.Variable 'Variable:0' shape=(5, 1, 1) dtype=float32, numpy=
array([[[-0.32304668]],

       [[-0.44872975]],

   ... 5), dtype=float32, numpy=
array([[0.1190625 , 0.2311236 , 0.29962778, 0.2311236 , 0.1190625 ]],
      dtype=float32)>)
kwargs = {}, handle_mixed_in_backend = True

>   ???

/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/ivy/func_wrapper.py:173: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[-0.32304668]],

       [[-0.44872975]],

       [[-0.15750647]],

       [[-0.22749448]],

       [[ 0.5256958 ]]], dtype=float32), query = slice(None, None, None)
val = array([[0.1190625 , 0.2311236 , 0.29962778, 0.2311236 , 0.1190625 ]],
      dtype=float32)

>   ???
E   ValueError: could not broadcast input array from shape (1,5) into shape (5,1,1)

/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/backends/tensorflow/general.py:109: ValueError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.PatchDominantGradientOrientation
__________________________________________________________________________________ test_DeDoDe[tensorflow-s2s-False] ___________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_DeDoDe(target_framework, mode, backend_compile):
        print("kornia.feature.DeDoDe")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledDeDoDe = ivy.transpile(kornia.feature.DeDoDe, source="torch", target=target_framework)
    
        x = torch.rand(1, 3, 256, 256)
        transpiled_x = _nest_torch_tensor_to_new_framework(x, target_framework)
    
        model = kornia.feature.DeDoDe(amp_dtype=torch.float32)
        torch_out = model(x)
    
        ivy.set_backend(target_framework)
        transpiled_model = TranspiledDeDoDe(amp_dtype=ivy.as_native_dtype("float32"))
        if target_framework == "tensorflow":
            # build the layers
>           transpiled_model(transpiled_x)

kornia/test_feature5.py:185: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_DeDoDe(
  (detector): tensorflow_DeDoDeDetector(
    (encoder): tensorflow_VGG19(
      (pt_layers): tensor...)
        )
      )
    )
  )
  (normalizer): tensorflow_Normalize(mean=[0.485 0.456 0.406], std=[0.229 0.224 0.225])
)
args = (<tf.Tensor: shape=(1, 3, 256, 256), dtype=float32, numpy=
array([[[[0.5112027 , 0.50668544, 0.42626882, ..., 0.945843...
         [0.79931796, 0.4134665 , 0.54641485, ..., 0.01960593,
          0.6902497 , 0.49325746]]]], dtype=float32)>,)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x55979621b8e0, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...ode_context=['        return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_DeDoDe(
  (detector): tensorflow_DeDoDeDetector(
    (encoder): tensorflow_VGG19(
      (pt_layers): tenso...,
         [0.79931796, 0.4134665 , 0.54641485, ..., 0.01960593,
          0.6902497 , 0.49325746]]]], dtype=float32)>)
kwargs = {}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_DeDoDe(
  (detector): tensorflow_DeDoDeDetector(
    (encoder): tensorflow_VGG19(
      (pt_layers): tensor...)
        )
      )
    )
  )
  (normalizer): tensorflow_Normalize(mean=[0.485 0.456 0.406], std=[0.229 0.224 0.225])
)
v = None, buffers = None
args = (<tf.Tensor: shape=(1, 3, 256, 256), dtype=float32, numpy=
array([[[[0.5112027 , 0.50668544, 0.42626882, ..., 0.945843...
         [0.79931796, 0.4134665 , 0.54641485, ..., 0.01960593,
          0.6902497 , 0.49325746]]]], dtype=float32)>,)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:2013: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_DeDoDe(
  (detector): tensorflow_DeDoDeDetector(
    (encoder): tensorflow_VGG19(
      (pt_layers): tenso...,
         [0.79931796, 0.4134665 , 0.54641485, ..., 0.01960593,
          0.6902497 , 0.49325746]]]], dtype=float32)>)
kwargs = {'buffers': None, 'v': None}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_DeDoDe(
  (detector): tensorflow_DeDoDeDetector(
    (encoder): tensorflow_VGG19(
      (pt_layers): tensor...)
        )
      )
    )
  )
  (normalizer): tensorflow_Normalize(mean=[0.485 0.456 0.406], std=[0.229 0.224 0.225])
)
v = None, buffers = None
args = (<tf.Tensor: shape=(1, 3, 256, 256), dtype=float32, numpy=
array([[[[0.5112027 , 0.50668544, 0.42626882, ..., 0.945843...
         [0.79931796, 0.4134665 , 0.54641485, ..., 0.01960593,
          0.6902497 , 0.49325746]]]], dtype=float32)>,)
kwargs = {}
first_arr = <tf.Tensor: shape=(1, 3, 256, 256), dtype=float32, numpy=
array([[[[0.5112027 , 0.50668544, 0.42626882, ..., 0.945843 ...],
         [0.79931796, 0.4134665 , 0.54641485, ..., 0.01960593,
          0.6902497 , 0.49325746]]]], dtype=float32)>
replace_v = False, replace_buffers = False, call_signature = <Signature (images, n=10000, apply_imagenet_normalization=True, pad_if_not_divisible=True)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Model, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Model, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Model, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1783: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_DeDoDe(
  (detector): tensorflow_DeDoDeDetector(
    (encoder): tensorflow_VGG19(
      (pt_layers): tenso...        )
      )
    )
  )
  (normalizer): tensorflow_Normalize(mean=[0.485 0.456 0.406], std=[0.229 0.224 0.225])
),)
kwargs = {'images': <tf.Tensor: shape=(1, 3, 256, 256), dtype=float32, numpy=
array([[[[0.5112027 , 0.50668544, 0.42626882, ......,
         [0.79931796, 0.4134665 , 0.54641485, ..., 0.01960593,
          0.6902497 , 0.49325746]]]], dtype=float32)>}

    @wraps(fn)
    def error_handler(*args, **kwargs):
        if not is_traceback_filtering_enabled():
            return fn(*args, **kwargs)
    
        filtered_tb = None
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            filtered_tb = _process_traceback_frames(e.__traceback__)
            # To get the full stack trace, call:
            # `keras.config.disable_traceback_filtering()`
>           raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/keras/src/utils/traceback_utils.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_DeDoDe(
  (detector): tensorflow_DeDoDeDetector(
    (encoder): tensorflow_VGG19(
      (pt_layers): tensor...)
        )
      )
    )
  )
  (normalizer): tensorflow_Normalize(mean=[0.485 0.456 0.406], std=[0.229 0.224 0.225])
)
images = <tf.Tensor: shape=(1, 3, 266, 266), dtype=float32, numpy=
array([[[[ 0.11442218,  0.09469616, -0.25646812, ...,  0.   ...      [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ]]]], dtype=float32)>
n = 10000, apply_imagenet_normalization = True, pad_if_not_divisible = True

    def call(
        self,
        images,
        n=10000,
        apply_imagenet_normalization=True,
        pad_if_not_divisible=True,
    ):
        from ....ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ....ivy.functional.frontends.torch.nn.functional.vision_functions import (
            tensorflow_pad_frnt,
        )
        from ...geometry.conversions import tensorflow_denormalize_pixel_coordinates
    
        if apply_imagenet_normalization:
            images = self.normalizer(images)
        B, C, H, W = tensorflow_shape_frnt_(images)
        if pad_if_not_divisible:
            h, w = (
                tensorflow_shape_frnt_(images)[2:][0],
                tensorflow_shape_frnt_(images)[2:][1],
            )
            pd_h = 14 - h % 14 if h % 14 > 0 else 0
            pd_w = 14 - w % 14 if w % 14 > 0 else 0
            images = tensorflow_pad_frnt(images, (0, pd_w, 0, pd_h), value=0.0)
>       keypoints, scores = self.detect(
            images, n=n, apply_imagenet_normalization=False, crop_h=h, crop_w=w
        )

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/dedode/dedode.py:101: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_DeDoDe(
  (detector): tensorflow_DeDoDeDetector(
    (encoder): tensorflow_VGG19(
      (pt_layers): tensor...)
        )
      )
    )
  )
  (normalizer): tensorflow_Normalize(mean=[0.485 0.456 0.406], std=[0.229 0.224 0.225])
)
images = <tf.Tensor: shape=(1, 3, 266, 266), dtype=float32, numpy=
array([[[[ 0.11442218,  0.09469616, -0.25646812, ...,  0.   ...      [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ]]]], dtype=float32)>
n = 10000, apply_imagenet_normalization = False, pad_if_not_divisible = True, crop_h = 256, crop_w = 256

    def detect(
        self,
        images,
        n=10000,
        apply_imagenet_normalization=True,
        pad_if_not_divisible=True,
        crop_h=None,
        crop_w=None,
    ):
        from ....ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ....ivy.functional.frontends.torch.nn.functional.vision_functions import (
            tensorflow_pad_frnt,
        )
        from ...core.check import tensorflow_KORNIA_CHECK_SHAPE
        from ....ivy.functional.backends.tensorflow.general import tensorflow_get_item
        from ....ivy.functional.frontends.torch.tensor import tensorflow_reshape_frnt_
        from ....ivy.functional.frontends.torch.tensor import tensorflow_softmax_frnt_
        from .utils import tensorflow_sample_keypoints
    
        tensorflow_KORNIA_CHECK_SHAPE(images, ["B", "3", "H", "W"])
        self.train(False)
        if pad_if_not_divisible:
            h, w = (
                tensorflow_shape_frnt_(images)[2:][0],
                tensorflow_shape_frnt_(images)[2:][1],
            )
            pd_h = 14 - h % 14 if h % 14 > 0 else 0
            pd_w = 14 - w % 14 if w % 14 > 0 else 0
            images = tensorflow_pad_frnt(images, (0, pd_w, 0, pd_h), value=0.0)
        if apply_imagenet_normalization:
            images = self.normalizer(images)
        B, C, H, W = tensorflow_shape_frnt_(images)
>       logits = self.detector.call(images)

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/dedode/dedode.py:145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_DeDoDeDetector(
  (encoder): tensorflow_VGG19(
    (pt_layers): tensorflow_ModuleList(
      (0): KerasConv...rflow_ReLU()
            (3): KerasConv2D()
          )
        )
        (out_conv): KerasConv2D()
      )
    )
  )
)
images = <tf.Tensor: shape=(1, 3, 266, 266), dtype=float32, numpy=
array([[[[ 0.11442218,  0.09469616, -0.25646812, ...,  0.   ...      [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ]]]], dtype=float32)>

    def call(self, images):
        from ....ivy.functional.frontends.torch.tensor import tensorflow_float_frnt_
        from ....ivy.functional.backends.tensorflow.general import tensorflow_get_item
        from ....ivy.functional.frontends.torch.nn.functional.vision_functions import (
            tensorflow_interpolate_frnt,
        )
        from ....ivy.functional.frontends.torch.tensor import tensorflow_to_frnt_
    
        dtype = images.dtype
        features, sizes = self.encoder(images)
        context = None
        logits = None
        scales = ["8", "4", "2", "1"]
        for idx, (feature_map, scale) in enumerate(zip(reversed(features), scales)):
>           delta_logits, context = self.decoder(
                feature_map, context=context, scale=scale
            )

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/dedode/detector.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Decoder(
  (pt_layers): tensorflow_ModuleDict(
    (8): tensorflow_ConvRefiner(
      (block1): tensorflow_...      (2): tensorflow_ReLU()
          (3): KerasConv2D()
        )
      )
      (out_conv): KerasConv2D()
    )
  )
)
args = (<tf.Tensor: shape=(1, 512, 33, 33), dtype=float32, numpy=
array([[[[0.00169893, 0.00399674, 0.00234177, ..., 0.007693...
         [0.0033443 , 0.00317745, 0.00504295, ..., 0.00082219,
          0.0007232 , 0.00063529]]]], dtype=float32)>,)
kwargs = {'context': None, 'scale': '8'}
stack = [FrameInfo(frame=<frame at 0x7f9950231b70, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...ion.py', lineno=46, function='__call__', code_context=['            return call_fn(*args, **kwargs)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Decoder(
  (pt_layers): tensorflow_ModuleDict(
    (8): tensorflow_ConvRefiner(
      (block1): tensorflow_...      (2): tensorflow_ReLU()
          (3): KerasConv2D()
        )
      )
      (out_conv): KerasConv2D()
    )
  )
)
v = None, buffers = None
args = (<tf.Tensor: shape=(1, 512, 33, 33), dtype=float32, numpy=
array([[[[0.00169893, 0.00399674, 0.00234177, ..., 0.007693...
         [0.0033443 , 0.00317745, 0.00504295, ..., 0.00082219,
          0.0007232 , 0.00063529]]]], dtype=float32)>,)
kwargs = {'context': None, 'scale': '8'}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Decoder(
  (pt_layers): tensorflow_ModuleDict(
    (8): tensorflow_ConvRefiner(
      (block1): tensorflow_...      (2): tensorflow_ReLU()
          (3): KerasConv2D()
        )
      )
      (out_conv): KerasConv2D()
    )
  )
)
v = None, buffers = None
args = (<tf.Tensor: shape=(1, 512, 33, 33), dtype=float32, numpy=
array([[[[0.00169893, 0.00399674, 0.00234177, ..., 0.007693...
         [0.0033443 , 0.00317745, 0.00504295, ..., 0.00082219,
          0.0007232 , 0.00063529]]]], dtype=float32)>,)
kwargs = {'context': None, 'scale': '8'}, replace_v = False, replace_buffers = False, call_signature = <Signature (features, context=None, scale=None)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Layer, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Layer, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Layer, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Decoder(
  (pt_layers): tensorflow_ModuleDict(
    (8): tensorflow_ConvRefiner(
      (block1): tensorflow_...      (2): tensorflow_ReLU()
          (3): KerasConv2D()
        )
      )
      (out_conv): KerasConv2D()
    )
  )
)
features = <tf.Tensor: shape=(1, 512, 33, 33), dtype=float32, numpy=
array([[[[0.00169893, 0.00399674, 0.00234177, ..., 0.0076935...],
         [0.0033443 , 0.00317745, 0.00504295, ..., 0.00082219,
          0.0007232 , 0.00063529]]]], dtype=float32)>
context = None, scale = '8'

    def call(self, features, context=None, scale=None):
        from ....ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            tensorflow_cat_frnt,
        )
        from ....ivy.functional.backends.tensorflow.general import tensorflow_get_item
    
        if context is not None:
            features = tensorflow_cat_frnt((features, context), dim=1)
>       stuff = tensorflow_get_item(self.pt_layers, scale)(features)

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/dedode/decoder.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_ConvRefiner(
  (block1): tensorflow_Sequential(
    (0): KerasConv2D()
    (1): KerasBatchNorm2D()
    (2):...  (1): KerasBatchNorm2D()
      (2): tensorflow_ReLU()
      (3): KerasConv2D()
    )
  )
  (out_conv): KerasConv2D()
)
args = (<tf.Tensor: shape=(1, 512, 33, 33), dtype=float32, numpy=
array([[[[0.00169893, 0.00399674, 0.00234177, ..., 0.007693...
         [0.0033443 , 0.00317745, 0.00504295, ..., 0.00082219,
          0.0007232 , 0.00063529]]]], dtype=float32)>,)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x5597a14e6af0, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...function='__call__', code_context=['                    outputs = super().__call__(*args, **kwargs)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_ConvRefiner(
  (block1): tensorflow_Sequential(
    (0): KerasConv2D()
    (1): KerasBatchNorm2D()
    (2):...  (1): KerasBatchNorm2D()
      (2): tensorflow_ReLU()
      (3): KerasConv2D()
    )
  )
  (out_conv): KerasConv2D()
)
v = None, buffers = None
args = (<tf.Tensor: shape=(1, 512, 33, 33), dtype=float32, numpy=
array([[[[0.00169893, 0.00399674, 0.00234177, ..., 0.007693...
         [0.0033443 , 0.00317745, 0.00504295, ..., 0.00082219,
          0.0007232 , 0.00063529]]]], dtype=float32)>,)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_ConvRefiner(
  (block1): tensorflow_Sequential(
    (0): KerasConv2D()
    (1): KerasBatchNorm2D()
    (2):...  (1): KerasBatchNorm2D()
      (2): tensorflow_ReLU()
      (3): KerasConv2D()
    )
  )
  (out_conv): KerasConv2D()
)
v = None, buffers = None
args = (<tf.Tensor: shape=(1, 512, 33, 33), dtype=float32, numpy=
array([[[[0.00169893, 0.00399674, 0.00234177, ..., 0.007693...
         [0.0033443 , 0.00317745, 0.00504295, ..., 0.00082219,
          0.0007232 , 0.00063529]]]], dtype=float32)>,)
kwargs = {}, replace_v = False, replace_buffers = False, call_signature = <Signature (feats)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Layer, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Layer, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Layer, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_ConvRefiner(
  (block1): tensorflow_Sequential(
    (0): KerasConv2D()
    (1): KerasBatchNorm2D()
    (2):...  (1): KerasBatchNorm2D()
      (2): tensorflow_ReLU()
      (3): KerasConv2D()
    )
  )
  (out_conv): KerasConv2D()
)
feats = <tf.Tensor: shape=(1, 512, 33, 33), dtype=float32, numpy=
array([[[[0.00169893, 0.00399674, 0.00234177, ..., 0.0076935...],
         [0.0033443 , 0.00317745, 0.00504295, ..., 0.00082219,
          0.0007232 , 0.00063529]]]], dtype=float32)>

    def call(self, feats):
        from ....ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
    
        b, c, hs, ws = tensorflow_shape_frnt_(feats)
>       x0 = self.block1(feats)

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/dedode/decoder.py:298: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Sequential(
  (0): KerasConv2D()
  (1): KerasBatchNorm2D()
  (2): tensorflow_ReLU()
  (3): KerasConv2D()
)
args = (<tf.Tensor: shape=(1, 512, 33, 33), dtype=float32, numpy=
array([[[[0.00169893, 0.00399674, 0.00234177, ..., 0.007693...
         [0.0033443 , 0.00317745, 0.00504295, ..., 0.00082219,
          0.0007232 , 0.00063529]]]], dtype=float32)>,)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x7f9950230210, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...function='__call__', code_context=['                    outputs = super().__call__(*args, **kwargs)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Sequential(
  (0): KerasConv2D()
  (1): KerasBatchNorm2D()
  (2): tensorflow_ReLU()
  (3): KerasConv2D()
), v = None, buffers = None
args = (<tf.Tensor: shape=(1, 512, 33, 33), dtype=float32, numpy=
array([[[[0.00169893, 0.00399674, 0.00234177, ..., 0.007693...
         [0.0033443 , 0.00317745, 0.00504295, ..., 0.00082219,
          0.0007232 , 0.00063529]]]], dtype=float32)>,)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Sequential(
  (0): KerasConv2D()
  (1): KerasBatchNorm2D()
  (2): tensorflow_ReLU()
  (3): KerasConv2D()
), v = None, buffers = None
args = (<tf.Tensor: shape=(1, 512, 33, 33), dtype=float32, numpy=
array([[[[0.00169893, 0.00399674, 0.00234177, ..., 0.007693...
         [0.0033443 , 0.00317745, 0.00504295, ..., 0.00082219,
          0.0007232 , 0.00063529]]]], dtype=float32)>,)
kwargs = {}, replace_v = False, replace_buffers = False, call_signature = <Signature (input)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Layer, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Layer, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Layer, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Sequential(
  (0): KerasConv2D()
  (1): KerasBatchNorm2D()
  (2): tensorflow_ReLU()
  (3): KerasConv2D()
)
input = <tf.Tensor: shape=(1, 33, 33, 512), dtype=float32, numpy=
array([[[[-1.6332212e-03,  2.1186336e-03,  1.4464299e-03, .....7.0842793e-03,  3.3269718e-03, ...,
          -2.5125965e-03, -7.4436865e-04, -1.6777078e-03]]]],
      dtype=float32)>

    def call(self, input):
        for i, module in enumerate(self):
>           input = module(input)

ivy_transpiled_outputs/tensorflow_outputs/torch/nn/modules/container.py:199: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = KerasBatchNorm2D()
args = (<tf.Tensor: shape=(1, 33, 33, 512), dtype=float32, numpy=
array([[[[-1.6332212e-03,  2.1186336e-03,  1.4464299e-03, ....0842793e-03,  3.3269718e-03, ...,
          -2.5125965e-03, -7.4436865e-04, -1.6777078e-03]]]],
      dtype=float32)>,)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x559828c4ea60, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...function='__call__', code_context=['                    outputs = super().__call__(*args, **kwargs)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = KerasBatchNorm2D()
args = (<tf.Tensor: shape=(1, 33, 33, 512), dtype=float32, numpy=
array([[[[-1.6332212e-03,  2.1186336e-03,  1.4464299e-03, ....0842793e-03,  3.3269718e-03, ...,
          -2.5125965e-03, -7.4436865e-04, -1.6777078e-03]]]],
      dtype=float32)>,)
kwargs = {}

    @store_frame_info
    def __call__(self, *args, **kwargs):
        if not self.built:
>           res = super().__call__(*args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful_layers.py:1010: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = KerasBatchNorm2D(), input_shape = (1, 33, 33, 512)

    def build(self, input_shape):
        _, ch, _, _ = input_shape
        if (
            not self.built
            and self.axis == -1
            and os.environ.get("DATA_FORMAT", "channels_first") == "channels_first"
        ):
            order = (0, 2, 3, 1)
            new_shape = tuple(input_shape[i] for i in order)
            input_shape = tf.TensorShape(new_shape)
    
>       super().build(input_shape)
E       IndexError: Exception encountered when calling tensorflow_Sequential.call().
E       
E       [1mtuple index out of range[0m
E       
E       Arguments received by tensorflow_Sequential.call():
E          input=tf.Tensor(shape=(1, 512, 33, 33), dtype=float32)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful_layers.py:1030: IndexError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.DeDoDe
----------------------------------------------------------------------------------------- Captured stderr call -----------------------------------------------------------------------------------------
Downloading: "https://dl.fbaipublicfiles.com/dinov2/dinov2_vitl14/dinov2_vitl14_pretrain.pth" to /root/.cache/torch/hub/checkpoints/dinov2_vitl14_pretrain.pth

  0%|          | 0.00/1.13G [00:00<?, ?B/s]
  0%|          | 3.25M/1.13G [00:00<00:42, 28.6MB/s]
  1%|          | 7.25M/1.13G [00:00<00:37, 32.4MB/s]
  1%|          | 12.2M/1.13G [00:00<00:29, 40.7MB/s]
  2%|         | 17.5M/1.13G [00:00<00:27, 43.5MB/s]
  2%|         | 24.6M/1.13G [00:00<00:22, 53.8MB/s]
  3%|         | 33.4M/1.13G [00:00<00:18, 63.0MB/s]
  4%|         | 44.0M/1.13G [00:00<00:15, 77.7MB/s]
  5%|         | 57.1M/1.13G [00:00<00:12, 95.8MB/s]
  6%|         | 72.1M/1.13G [00:00<00:09, 114MB/s] 
  8%|         | 90.5M/1.13G [00:01<00:08, 138MB/s]
 10%|         | 110M/1.13G [00:01<00:06, 159MB/s] 
 11%|        | 131M/1.13G [00:01<00:06, 176MB/s]
 13%|        | 152M/1.13G [00:01<00:05, 188MB/s]
 15%|        | 172M/1.13G [00:01<00:05, 196MB/s]
 17%|        | 193M/1.13G [00:01<00:05, 201MB/s]
 18%|        | 213M/1.13G [00:01<00:04, 206MB/s]
 20%|        | 234M/1.13G [00:01<00:04, 208MB/s]
 22%|       | 254M/1.13G [00:01<00:04, 209MB/s]
 24%|       | 275M/1.13G [00:01<00:04, 211MB/s]
 25%|       | 296M/1.13G [00:02<00:04, 213MB/s]
 27%|       | 316M/1.13G [00:02<00:04, 213MB/s]
 29%|       | 336M/1.13G [00:02<00:04, 214MB/s]
 31%|       | 357M/1.13G [00:02<00:03, 214MB/s]
 33%|      | 378M/1.13G [00:02<00:03, 214MB/s]
 34%|      | 398M/1.13G [00:02<00:03, 214MB/s]
 36%|      | 419M/1.13G [00:02<00:03, 214MB/s]
 38%|      | 439M/1.13G [00:02<00:03, 214MB/s]
 40%|      | 460M/1.13G [00:02<00:03, 213MB/s]
 41%|     | 480M/1.13G [00:02<00:03, 203MB/s]
 43%|     | 500M/1.13G [00:03<00:03, 207MB/s]
 45%|     | 521M/1.13G [00:03<00:03, 209MB/s]
 47%|     | 542M/1.13G [00:03<00:03, 211MB/s]
 48%|     | 562M/1.13G [00:03<00:03, 202MB/s]
 50%|     | 582M/1.13G [00:03<00:02, 206MB/s]
 52%|    | 603M/1.13G [00:03<00:02, 209MB/s]
 54%|    | 624M/1.13G [00:03<00:02, 209MB/s]
 55%|    | 644M/1.13G [00:03<00:02, 211MB/s]
 57%|    | 665M/1.13G [00:03<00:02, 213MB/s]
 59%|    | 686M/1.13G [00:04<00:02, 213MB/s]
 61%|    | 706M/1.13G [00:04<00:02, 213MB/s]
 63%|   | 727M/1.13G [00:04<00:02, 213MB/s]
 64%|   | 747M/1.13G [00:04<00:02, 206MB/s]
 66%|   | 767M/1.13G [00:04<00:01, 208MB/s]
 68%|   | 787M/1.13G [00:04<00:01, 209MB/s]
 70%|   | 807M/1.13G [00:04<00:01, 208MB/s]
 71%|  | 827M/1.13G [00:04<00:01, 204MB/s]
 73%|  | 848M/1.13G [00:04<00:01, 207MB/s]
 75%|  | 868M/1.13G [00:04<00:01, 209MB/s]
 77%|  | 889M/1.13G [00:05<00:01, 208MB/s]
 78%|  | 909M/1.13G [00:05<00:01, 210MB/s]
 80%|  | 930M/1.13G [00:05<00:01, 210MB/s]
 82%| | 950M/1.13G [00:05<00:01, 212MB/s]
 84%| | 971M/1.13G [00:05<00:00, 214MB/s]
 85%| | 992M/1.13G [00:05<00:00, 213MB/s]
 87%| | 0.99G/1.13G [00:05<00:00, 213MB/s]
 89%| | 1.01G/1.13G [00:05<00:00, 211MB/s]
 91%| | 1.03G/1.13G [00:05<00:00, 213MB/s]
 92%|| 1.05G/1.13G [00:05<00:00, 214MB/s]
 94%|| 1.07G/1.13G [00:06<00:00, 214MB/s]
 96%|| 1.09G/1.13G [00:06<00:00, 212MB/s]
 98%|| 1.11G/1.13G [00:06<00:00, 214MB/s]
100%|| 1.13G/1.13G [00:06<00:00, 214MB/s]
100%|| 1.13G/1.13G [00:06<00:00, 191MB/s]
2024-10-12 13:23:02.959705: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 411041792 exceeds 10% of free system memory.
2024-10-12 13:23:03.343070: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 411041792 exceeds 10% of free system memory.
2024-10-12 13:23:03.953114: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 411041792 exceeds 10% of free system memory.
2024-10-12 13:23:04.041667: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 411041792 exceeds 10% of free system memory.
2024-10-12 13:23:04.206620: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 411041792 exceeds 10% of free system memory.
___________________________________________________________________________________ test_DISK[tensorflow-s2s-False] ____________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_DISK(target_framework, mode, backend_compile):
        print("kornia.feature.DISK")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledDISK = ivy.transpile(kornia.feature.DISK, source="torch", target=target_framework)
    
        x = torch.rand(1, 3, 256, 256)
        transpiled_x = _nest_torch_tensor_to_new_framework(x, target_framework)
    
        model = kornia.feature.DISK()
        torch_out = model(x)
    
        transpiled_model = TranspiledDISK()
        if target_framework == "tensorflow":
            # build the layers
>           transpiled_model(transpiled_x)

kornia/test_feature5.py:211: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_DISK(
  (unet): tensorflow_Unet(
    (path_down): tensorflow_ModuleList(
      (0): tensorflow_ThinUnetDown...): tensorflow_PReLU()
          (2): tensorflow_Sequential()
          (3): KerasConv2D()
        )
      )
    )
  )
)
args = (<tf.Tensor: shape=(1, 3, 256, 256), dtype=float32, numpy=
array([[[[0.62739545, 0.374102  , 0.8926827 , ..., 0.722544...
         [0.12496608, 0.5635167 , 0.3481611 , ..., 0.21967703,
          0.52524847, 0.17092574]]]], dtype=float32)>,)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x7f99563885b0, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...ode_context=['        return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_DISK(
  (unet): tensorflow_Unet(
    (path_down): tensorflow_ModuleList(
      (0): tensorflow_ThinUnetDow...,
         [0.12496608, 0.5635167 , 0.3481611 , ..., 0.21967703,
          0.52524847, 0.17092574]]]], dtype=float32)>)
kwargs = {}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_DISK(
  (unet): tensorflow_Unet(
    (path_down): tensorflow_ModuleList(
      (0): tensorflow_ThinUnetDown...): tensorflow_PReLU()
          (2): tensorflow_Sequential()
          (3): KerasConv2D()
        )
      )
    )
  )
)
v = None, buffers = None
args = (<tf.Tensor: shape=(1, 3, 256, 256), dtype=float32, numpy=
array([[[[0.62739545, 0.374102  , 0.8926827 , ..., 0.722544...
         [0.12496608, 0.5635167 , 0.3481611 , ..., 0.21967703,
          0.52524847, 0.17092574]]]], dtype=float32)>,)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:2013: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_DISK(
  (unet): tensorflow_Unet(
    (path_down): tensorflow_ModuleList(
      (0): tensorflow_ThinUnetDow...,
         [0.12496608, 0.5635167 , 0.3481611 , ..., 0.21967703,
          0.52524847, 0.17092574]]]], dtype=float32)>)
kwargs = {'buffers': None, 'v': None}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_DISK(
  (unet): tensorflow_Unet(
    (path_down): tensorflow_ModuleList(
      (0): tensorflow_ThinUnetDown...): tensorflow_PReLU()
          (2): tensorflow_Sequential()
          (3): KerasConv2D()
        )
      )
    )
  )
)
v = None, buffers = None
args = (<tf.Tensor: shape=(1, 3, 256, 256), dtype=float32, numpy=
array([[[[0.62739545, 0.374102  , 0.8926827 , ..., 0.722544...
         [0.12496608, 0.5635167 , 0.3481611 , ..., 0.21967703,
          0.52524847, 0.17092574]]]], dtype=float32)>,)
kwargs = {}
first_arr = <tf.Tensor: shape=(1, 3, 256, 256), dtype=float32, numpy=
array([[[[0.62739545, 0.374102  , 0.8926827 , ..., 0.7225441...],
         [0.12496608, 0.5635167 , 0.3481611 , ..., 0.21967703,
          0.52524847, 0.17092574]]]], dtype=float32)>
replace_v = False, replace_buffers = False, call_signature = <Signature (images, n=None, window_size=5, score_threshold=0.0, pad_if_not_divisible=False)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Model, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Model, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Model, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1783: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_DISK(
  (unet): tensorflow_Unet(
    (path_down): tensorflow_ModuleList(
      (0): tensorflow_ThinUnetDow... tensorflow_PReLU()
          (2): tensorflow_Sequential()
          (3): KerasConv2D()
        )
      )
    )
  )
),)
kwargs = {'images': <tf.Tensor: shape=(1, 3, 256, 256), dtype=float32, numpy=
array([[[[0.62739545, 0.374102  , 0.8926827 , ......,
         [0.12496608, 0.5635167 , 0.3481611 , ..., 0.21967703,
          0.52524847, 0.17092574]]]], dtype=float32)>}

    @wraps(fn)
    def error_handler(*args, **kwargs):
        if not is_traceback_filtering_enabled():
            return fn(*args, **kwargs)
    
        filtered_tb = None
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            filtered_tb = _process_traceback_frames(e.__traceback__)
            # To get the full stack trace, call:
            # `keras.config.disable_traceback_filtering()`
>           raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/keras/src/utils/traceback_utils.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_DISK(
  (unet): tensorflow_Unet(
    (path_down): tensorflow_ModuleList(
      (0): tensorflow_ThinUnetDown...): tensorflow_PReLU()
          (2): tensorflow_Sequential()
          (3): KerasConv2D()
        )
      )
    )
  )
)
images = <tf.Tensor: shape=(1, 3, 256, 256), dtype=float32, numpy=
array([[[[0.62739545, 0.374102  , 0.8926827 , ..., 0.7225441...],
         [0.12496608, 0.5635167 , 0.3481611 , ..., 0.21967703,
          0.52524847, 0.17092574]]]], dtype=float32)>
n = None, window_size = 5, score_threshold = 0.0, pad_if_not_divisible = False

    def call(
        self,
        images,
        n=None,
        window_size=5,
        score_threshold=0.0,
        pad_if_not_divisible=False,
    ):
        from ....ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ....ivy.functional.backends.tensorflow.general import tensorflow_get_item
        from ....ivy.functional.frontends.torch.nn.functional.vision_functions import (
            tensorflow_pad_frnt,
        )
        from .detector import tensorflow_heatmap_to_keypoints
    
        B = tensorflow_shape_frnt_(images)[0]
        if pad_if_not_divisible:
            h, w = (
                tensorflow_shape_frnt_(images)[2:][0],
                tensorflow_shape_frnt_(images)[2:][1],
            )
            pd_h = 16 - h % 16 if h % 16 > 0 else 0
            pd_w = 16 - w % 16 if w % 16 > 0 else 0
            images = tensorflow_pad_frnt(images, (0, pd_w, 0, pd_h), value=0.0)
>       heatmaps, descriptors = self.heatmap_and_dense_descriptors(images)

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/disk/disk.py:99: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_DISK(
  (unet): tensorflow_Unet(
    (path_down): tensorflow_ModuleList(
      (0): tensorflow_ThinUnetDown...): tensorflow_PReLU()
          (2): tensorflow_Sequential()
          (3): KerasConv2D()
        )
      )
    )
  )
)
images = <tf.Tensor: shape=(1, 3, 256, 256), dtype=float32, numpy=
array([[[[0.62739545, 0.374102  , 0.8926827 , ..., 0.7225441...],
         [0.12496608, 0.5635167 , 0.3481611 , ..., 0.21967703,
          0.52524847, 0.17092574]]]], dtype=float32)>

    def heatmap_and_dense_descriptors(self, images):
        from ....ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ....ivy.functional.backends.tensorflow.general import tensorflow_get_item
    
>       unet_output = self.unet(images)

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/disk/disk.py:62: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Unet(
  (path_down): tensorflow_ModuleList(
    (0): tensorflow_ThinUnetDownBlock(
      (0): tensorflow_Se...d()
        (1): tensorflow_PReLU()
        (2): tensorflow_Sequential()
        (3): KerasConv2D()
      )
    )
  )
)
args = (<tf.Tensor: shape=(1, 3, 256, 256), dtype=float32, numpy=
array([[[[0.62739545, 0.374102  , 0.8926827 , ..., 0.722544...
         [0.12496608, 0.5635167 , 0.3481611 , ..., 0.21967703,
          0.52524847, 0.17092574]]]], dtype=float32)>,)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x7f9950232d90, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...ls.py', lineno=117, function='error_handler', code_context=['            return fn(*args, **kwargs)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Unet(
  (path_down): tensorflow_ModuleList(
    (0): tensorflow_ThinUnetDownBlock(
      (0): tensorflow_Se...d()
        (1): tensorflow_PReLU()
        (2): tensorflow_Sequential()
        (3): KerasConv2D()
      )
    )
  )
)
v = None, buffers = None
args = (<tf.Tensor: shape=(1, 3, 256, 256), dtype=float32, numpy=
array([[[[0.62739545, 0.374102  , 0.8926827 , ..., 0.722544...
         [0.12496608, 0.5635167 , 0.3481611 , ..., 0.21967703,
          0.52524847, 0.17092574]]]], dtype=float32)>,)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Unet(
  (path_down): tensorflow_ModuleList(
    (0): tensorflow_ThinUnetDownBlock(
      (0): tensorflow_Se...d()
        (1): tensorflow_PReLU()
        (2): tensorflow_Sequential()
        (3): KerasConv2D()
      )
    )
  )
)
v = None, buffers = None
args = (<tf.Tensor: shape=(1, 3, 256, 256), dtype=float32, numpy=
array([[[[0.62739545, 0.374102  , 0.8926827 , ..., 0.722544...
         [0.12496608, 0.5635167 , 0.3481611 , ..., 0.21967703,
          0.52524847, 0.17092574]]]], dtype=float32)>,)
kwargs = {}, replace_v = False, replace_buffers = False, call_signature = <Signature (inp)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Layer, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Layer, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Layer, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Unet(
  (path_down): tensorflow_ModuleList(
    (0): tensorflow_ThinUnetDownBlock(
      (0): tensorflow_Se...d()
        (1): tensorflow_PReLU()
        (2): tensorflow_Sequential()
        (3): KerasConv2D()
      )
    )
  )
)
inp = <tf.Tensor: shape=(1, 3, 256, 256), dtype=float32, numpy=
array([[[[0.62739545, 0.374102  , 0.8926827 , ..., 0.7225441...],
         [0.12496608, 0.5635167 , 0.3481611 , ..., 0.21967703,
          0.52524847, 0.17092574]]]], dtype=float32)>

    def call(self, inp):
        from .....ivy.functional.frontends.torch.tensor import tensorflow_size_frnt_
    
        if tensorflow_size_frnt_(inp, 1) != self.in_features:
            fmt = "Expected {} feature channels in input, got {}"
            msg = fmt.format(self.in_features, tensorflow_size_frnt_(inp, 1))
            raise ValueError(msg)
        input_size_divisor = 2 ** len(self.up)
        if (
            tensorflow_size_frnt_(inp, 2) % input_size_divisor != 0
            or tensorflow_size_frnt_(inp, 3) % input_size_divisor != 0
        ):
            raise ValueError(
                f"Input image shape must be divisible by {input_size_divisor} (got {tensorflow_size_frnt_(inp)}). This is not inherent to DISK, but to the U-Net architecture used in pretrained models. Please pad if necessary."
            )
        features = [inp]
        for layer in self.path_down:
>           features.append(layer(features[-1]))

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/disk/_unets/unet.py:92: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_ThinUnetDownBlock(
  (0): tensorflow_TrivialDownsample()
  (1): tensorflow_Conv(
    (0): tensorflow_InstanceNorm2d()
    (1): tensorflow_PReLU()
    (2): tensorflow_Sequential()
    (3): KerasConv2D()
  )
)
args = (<tf.Tensor: shape=(1, 16, 256, 256), dtype=float32, numpy=
array([[[[ 2.41236851e-01,  1.87236816e-01,  6.95513114e-0...052e-02,  9.78731886e-02, ...,
           5.55826165e-02,  1.99874282e-01,  3.41834605e-01]]]],
      dtype=float32)>,)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x5597f0e1f4f0, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...function='__call__', code_context=['                    outputs = super().__call__(*args, **kwargs)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_ThinUnetDownBlock(
  (0): tensorflow_TrivialDownsample()
  (1): tensorflow_Conv(
    (0): tensorflow_InstanceNorm2d()
    (1): tensorflow_PReLU()
    (2): tensorflow_Sequential()
    (3): KerasConv2D()
  )
)
v = None, buffers = None
args = (<tf.Tensor: shape=(1, 16, 256, 256), dtype=float32, numpy=
array([[[[ 2.41236851e-01,  1.87236816e-01,  6.95513114e-0...052e-02,  9.78731886e-02, ...,
           5.55826165e-02,  1.99874282e-01,  3.41834605e-01]]]],
      dtype=float32)>,)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_ThinUnetDownBlock(
  (0): tensorflow_TrivialDownsample()
  (1): tensorflow_Conv(
    (0): tensorflow_InstanceNorm2d()
    (1): tensorflow_PReLU()
    (2): tensorflow_Sequential()
    (3): KerasConv2D()
  )
)
v = None, buffers = None
args = (<tf.Tensor: shape=(1, 16, 256, 256), dtype=float32, numpy=
array([[[[ 2.41236851e-01,  1.87236816e-01,  6.95513114e-0...052e-02,  9.78731886e-02, ...,
           5.55826165e-02,  1.99874282e-01,  3.41834605e-01]]]],
      dtype=float32)>,)
kwargs = {}, replace_v = False, replace_buffers = False, call_signature = <Signature (input)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Layer, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Layer, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Layer, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_ThinUnetDownBlock(
  (0): tensorflow_TrivialDownsample()
  (1): tensorflow_Conv(
    (0): tensorflow_InstanceNorm2d()
    (1): tensorflow_PReLU()
    (2): tensorflow_Sequential()
    (3): KerasConv2D()
  )
)
input = <tf.Tensor: shape=(1, 16, 128, 128), dtype=float32, numpy=
array([[[[ 0.35430333,  0.30444214,  0.36908054, ...,  0.33...      [ 0.07904054,  0.07922152,  0.02563202, ...,  0.14754106,
           0.03982726,  0.2599523 ]]]], dtype=float32)>

    def call(self, input):
        for i, module in enumerate(self):
>           input = module(input)

ivy_transpiled_outputs/tensorflow_outputs/torch/nn/modules/container.py:199: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Conv(
  (0): tensorflow_InstanceNorm2d()
  (1): tensorflow_PReLU()
  (2): tensorflow_Sequential()
  (3): KerasConv2D()
)
args = (<tf.Tensor: shape=(1, 16, 128, 128), dtype=float32, numpy=
array([[[[ 0.35430333,  0.30444214,  0.36908054, ...,  0.3...    [ 0.07904054,  0.07922152,  0.02563202, ...,  0.14754106,
           0.03982726,  0.2599523 ]]]], dtype=float32)>,)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x7f9950bd8b20, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...function='__call__', code_context=['                    outputs = super().__call__(*args, **kwargs)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Conv(
  (0): tensorflow_InstanceNorm2d()
  (1): tensorflow_PReLU()
  (2): tensorflow_Sequential()
  (3): KerasConv2D()
), v = None, buffers = None
args = (<tf.Tensor: shape=(1, 16, 128, 128), dtype=float32, numpy=
array([[[[ 0.35430333,  0.30444214,  0.36908054, ...,  0.3...    [ 0.07904054,  0.07922152,  0.02563202, ...,  0.14754106,
           0.03982726,  0.2599523 ]]]], dtype=float32)>,)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Conv(
  (0): tensorflow_InstanceNorm2d()
  (1): tensorflow_PReLU()
  (2): tensorflow_Sequential()
  (3): KerasConv2D()
), v = None, buffers = None
args = (<tf.Tensor: shape=(1, 16, 128, 128), dtype=float32, numpy=
array([[[[ 0.35430333,  0.30444214,  0.36908054, ...,  0.3...    [ 0.07904054,  0.07922152,  0.02563202, ...,  0.14754106,
           0.03982726,  0.2599523 ]]]], dtype=float32)>,)
kwargs = {}, replace_v = False, replace_buffers = False, call_signature = <Signature (input)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Layer, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Layer, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Layer, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Conv(
  (0): tensorflow_InstanceNorm2d()
  (1): tensorflow_PReLU()
  (2): tensorflow_Sequential()
  (3): KerasConv2D()
)
input = <tf.Tensor: shape=(1, 128, 128, 16), dtype=float32, numpy=
array([[[[ 1.0118325 ,  2.4493594 , -1.4591963 , ...,  2.34...      [-1.5239578 ,  2.1825573 , -0.295866  , ..., -2.060751  ,
          -0.07327628,  4.8636894 ]]]], dtype=float32)>

    def call(self, input):
        for i, module in enumerate(self):
>           input = module(input)

ivy_transpiled_outputs/tensorflow_outputs/torch/nn/modules/container.py:199: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_PReLU()
args = (<tf.Tensor: shape=(1, 128, 128, 16), dtype=float32, numpy=
array([[[[ 1.0118325 ,  2.4493594 , -1.4591963 , ...,  2.3...    [-1.5239578 ,  2.1825573 , -0.295866  , ..., -2.060751  ,
          -0.07327628,  4.8636894 ]]]], dtype=float32)>,)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x5597f4997f60, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...function='__call__', code_context=['                    outputs = super().__call__(*args, **kwargs)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_PReLU(), v = None, buffers = None
args = (<tf.Tensor: shape=(1, 128, 128, 16), dtype=float32, numpy=
array([[[[ 1.0118325 ,  2.4493594 , -1.4591963 , ...,  2.3...    [-1.5239578 ,  2.1825573 , -0.295866  , ..., -2.060751  ,
          -0.07327628,  4.8636894 ]]]], dtype=float32)>,)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_PReLU(), v = None, buffers = None
args = (<tf.Tensor: shape=(1, 128, 128, 16), dtype=float32, numpy=
array([[[[ 1.0118325 ,  2.4493594 , -1.4591963 , ...,  2.3...    [-1.5239578 ,  2.1825573 , -0.295866  , ..., -2.060751  ,
          -0.07327628,  4.8636894 ]]]], dtype=float32)>,)
kwargs = {}, replace_v = False, replace_buffers = False, call_signature = <Signature (input)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Layer, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Layer, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Layer, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_PReLU(), args = ()
kwargs = {'input': <tf.Tensor: shape=(1, 128, 128, 16), dtype=float32, numpy=
array([[[[ 1.0118325 ,  2.4493594 , -1.4591963 , ...     [-1.5239578 ,  2.1825573 , -0.295866  , ..., -2.060751  ,
          -0.07327628,  4.8636894 ]]]], dtype=float32)>}
tensorflow_get_item = <function tensorflow_get_item at 0x7f994a2070a0>, tensorflow_set_item = <function tensorflow_set_item at 0x7f994a207250>, DATA_FORMAT = 'channels_last'
fn_args_and_kwargs = {'input': <tf.Tensor: shape=(1, 128, 128, 16), dtype=float32, numpy=
array([[[[ 1.0118325 ,  2.4493594 , -1.4591963 , ...     [-1.5239578 ,  2.1825573 , -0.295866  , ..., -2.060751  ,
          -0.07327628,  4.8636894 ]]]], dtype=float32)>}
conv_block_start = <function tensorflow_handle_transpose_in_input_and_output.<locals>.transpose_wrapper.<locals>.<lambda> at 0x7f994ba63490>, next_call_in_seq = tensorflow_Sequential()
conv_block_continued = tensorflow_Sequential(), arg_name = 'input'

    @functools.wraps(fn)
    def transpose_wrapper(self, *args, **kwargs):
        from ..functional.backends.tensorflow.general import tensorflow_get_item
        from ..functional.backends.tensorflow.general import tensorflow_set_item
    
        DATA_FORMAT = os.environ.get("DATA_FORMAT", "channels_first")
        kwargs_call = {
            key: val
            for key, val in kwargs.items()
            if key not in dict(original_signature.parameters)
        }
        fn_args_and_kwargs = {
            key: val for key, val in kwargs.items() if key not in kwargs_call
        }
        fn_args_and_kwargs.update(dict(zip(fn.__code__.co_varnames[1:], args)))
        conv_block_start = lambda f: any(
            substr in f.__qualname__
            for substr in CONV_FUNCS
            + NORM_FUNCS
            + POOL_FUNCS
            + KERAS_CONV_FUNCS
            + KERAS_NORM_FUNCS
            + KERAS_POOL_FUNCS
            + FLAX_CONV_FUNCS
            + FLAX_NORM_FUNCS
            + FLAX_POOL_FUNCS
        )
        next_call_in_seq = tensorflow_get_next_func(self)
        name_of_next_call = (
            next_call_in_seq.__class__.__name__
            if hasattr(next_call_in_seq, "__class__")
            else ""
        )
        conv_block_continued = next_call_in_seq and any(
            substr in name_of_next_call for substr in CONV_BLOCK_FNS
        )
        arg_name = "input" if "input" in fn_args_and_kwargs else "inputs"
        if DATA_FORMAT == "channels_first" and conv_block_start(self.__class__):
            input = tensorflow_get_item(fn_args_and_kwargs, arg_name)
            if len(input.shape) > 4:
                transpose = tensorflow_TransposeType.CONV3D
            elif len(input.shape) > 3:
                transpose = tensorflow_TransposeType.CONV2D
            elif len(input.shape) > 2:
                transpose = tensorflow_TransposeType.CONV1D
            else:
                transpose = tensorflow_TransposeType.NO_TRANSPOSE
            fn_args_and_kwargs = tensorflow_set_item(
                fn_args_and_kwargs,
                arg_name,
                tensorflow_apply_transpose(input, transpose=transpose, pt_to_tf=True),
            )
            DATA_FORMAT = "channels_last"
            os.environ = tensorflow_set_item(os.environ, "DATA_FORMAT", DATA_FORMAT)
>       res = fn(self, **fn_args_and_kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:414: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_PReLU()
input = <tf.Tensor: shape=(1, 128, 128, 16), dtype=float32, numpy=
array([[[[ 1.0118325 ,  2.4493594 , -1.4591963 , ...,  2.34...      [-1.5239578 ,  2.1825573 , -0.295866  , ..., -2.060751  ,
          -0.07327628,  4.8636894 ]]]], dtype=float32)>

    @tensorflow_handle_transpose_in_input_and_output
    def call(self, input):
        from ....ivy.functional.frontends.torch.nn.functional.non_linear_activation_functions import (
            tensorflow_prelu_frnt,
        )
    
>       return tensorflow_prelu_frnt(input, self.weight)

ivy_transpiled_outputs/tensorflow_outputs/torch/nn/modules/activation.py:78: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = <tf.Tensor: shape=(1, 128, 128, 16), dtype=float32, numpy=
array([[[[ 1.0118325 ,  2.4493594 , -1.4591963 , ...,  2.34...      [-1.5239578 ,  2.1825573 , -0.295866  , ..., -2.060751  ,
          -0.07327628,  4.8636894 ]]]], dtype=float32)>
weight = <tf.Variable 'Variable:0' shape=(16,) dtype=float32, numpy=
array([0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25,
       0.25, 0.25, 0.25, 0.25, 0.25], dtype=float32)>

    def tensorflow_prelu_frnt(input, weight):
        from ...tensor import tensorflow_ndim_frnt_
        from ...tensor import tensorflow_shape_frnt_
        from ......data_classes.array.manipulation import tensorflow_expand_dims_bknd_
        from .....backends.tensorflow.elementwise import tensorflow_add
        from .....backends.tensorflow.elementwise import tensorflow_maximum
        from .....backends.tensorflow.elementwise import tensorflow_multiply
        from .....backends.tensorflow.elementwise import tensorflow_minimum
    
        input_dim = tensorflow_ndim_frnt_(input)
        weight_dim = tensorflow_ndim_frnt_(weight)
        if weight_dim == 0:
            pass
        elif weight_dim == 1:
            if input_dim >= 2:
>               assert (
                    tensorflow_shape_frnt_(weight)[0] == tensorflow_shape_frnt_(input)[1]
                ), "Weight size must match input channels"
E               AssertionError: Exception encountered when calling tensorflow_PReLU.call().
E               
E               [1mWeight size must match input channels[0m
E               
E               Arguments received by tensorflow_PReLU.call():
E                  input=tf.Tensor(shape=(1, 128, 128, 16), dtype=float32)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/nn/functional/non_linear_activation_functions.py:61: AssertionError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.DISK
----------------------------------------------------------------------------------------- Captured stderr call -----------------------------------------------------------------------------------------
/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/torch/nn/modules/instancenorm.py:134: UserWarning: input's size at dim=1 does not match num_features. You can silence this warning by not passing in num_features, which is not used because affine=False
  warnings.warn(
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/test_feature5.py::test_LAFOrienter[tensorflow-s2s-False] - ValueError: could not broadcast input array from shape (1,5) into shape (5,1,1)
FAILED kornia/test_feature5.py::test_PatchDominantGradientOrientation[tensorflow-s2s-False] - ValueError: could not broadcast input array from shape (1,5) into shape (5,1,1)
FAILED kornia/test_feature5.py::test_DeDoDe[tensorflow-s2s-False] - IndexError: Exception encountered when calling tensorflow_Sequential.call().
FAILED kornia/test_feature5.py::test_DISK[tensorflow-s2s-False] - AssertionError: Exception encountered when calling tensorflow_PReLU.call().
=============================================================================== 4 failed, 6 passed in 1385.12s (0:23:05) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 17 items

kornia/augmentation/test_augmentation4.py F......F.........                                                                                                                                      [100%]

=============================================================================================== FAILURES ===============================================================================================
___________________________________________________________________________________ test_RandomMosaic[jax-s2s-False] ___________________________________________________________________________________

inp = jax_DType.INT64 | jax_DType.FLOAT16 | jax_DType.FLOAT32 | jax_DType.FLOAT64, query = '2', kwargs = {}

    @functools.wraps(fn)
    def wrapper(inp, query, **kwargs):
        try:
>           res = inp.__getitem__(query)

ivy_transpiled_outputs/jax_outputs/ivy/utils/decorator_utils.py:219: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = jax_DType.INT64 | jax_DType.FLOAT16 | jax_DType.FLOAT32 | jax_DType.FLOAT64, name = '2'

    def __getitem__(cls, name):
>       return cls._member_map_[name]
E       KeyError: '2'

/opt/miniconda/envs/multienv/lib/python3.10/enum.py:432: KeyError

During handling of the above exception, another exception occurred:

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_RandomMosaic(target_framework, mode, backend_compile):
        print("kornia.augmentation.RandomMosaic")
    
        init_args = ((300, 300),)
        init_kwargs = {"data_keys": ["input", "bbox_xyxy"]}
        call_args = (
            torch.randn(8, 3, 224, 224),
            torch.tensor([[
                [70, 5, 150, 100],
                [60, 180, 175, 220],
            ]]).repeat(8, 1, 1),
        )
        call_kwargs = {}
    
>       _test_augmentation_class(
            kornia.augmentation.RandomMosaic,
            target_framework,
            init_args,
            init_kwargs,
            call_args,
            call_kwargs,
            deterministic_output=False,
            backend_compile=backend_compile,
        )

kornia/augmentation/test_augmentation4.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

augmentation_cls = <class 'kornia.augmentation._2d.mix.mosaic.RandomMosaic'>, target = 'jax', init_args = ((300, 300),), init_kwargs = {'data_keys': ['input', 'bbox_xyxy']}
call_args = (tensor([[[[ 9.7376e-01, -1.9182e+00,  1.9938e+00,  ..., -6.0811e-01,
            1.6932e+00,  1.6620e+00],
          ...[ 70,   5, 150, 100],
         [ 60, 180, 175, 220]],

        [[ 70,   5, 150, 100],
         [ 60, 180, 175, 220]]]))
call_kwargs = {}, deterministic_output = False, backend_compile = False, tolerance = 0.001

    def _test_augmentation_class(
        augmentation_cls,
        target,
        init_args=(),
        init_kwargs={},
        call_args=(),
        call_kwargs={},
        deterministic_output=True,
        backend_compile=False,
        tolerance=1e-3,
    ):
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_cls = ivy.transpile(augmentation_cls, source="torch", target=target)
    
        torch_aug = augmentation_cls(*init_args, **init_kwargs)
        transpiled_init_args = _nest_torch_tensor_to_new_framework(init_args, target)
        transpiled_init_kwargs = _nest_torch_tensor_to_new_framework(init_kwargs, target)
        transpiled_aug = transpiled_cls(*transpiled_init_args, **transpiled_init_kwargs)
    
        # assert dir(torch_aug) == dir(transpiled_aug), f"attributes/methods of transpiled object do not align with the original - orig: {dir(torch_aug)} != transpiled: {dir(transpiled_aug)}"
    
        torch_out = torch_aug(*call_args, **call_kwargs)
        transpiled_call_args = _nest_torch_tensor_to_new_framework(call_args, target)
        transpiled_call_kwargs = _nest_torch_tensor_to_new_framework(call_kwargs, target)
>       transpiled_out = transpiled_aug(*transpiled_call_args, **transpiled_call_kwargs)

kornia/augmentation/test_augmentation4.py:43: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_RandomMosaic(output_size=(300, 300), mosaic_grid=(2, 2), start_ratio_range=(0.3, 0.7), p=0.7, p_batch=1.0, same_on..._size=(300, 300), min_bbox_size=0.0, padding_mode=constant, resample=bilinear, align_corners=True, cropping_mode=slice)
params = None, data_keys = None
input = (Array([[[[ 9.73760605e-01, -1.91816711e+00,  1.99377298e+00, ...,
          -6.08113348e-01,  1.69319880e+00,  1.6619... 150, 100],
        [ 60, 180, 175, 220]],

       [[ 70,   5, 150, 100],
        [ 60, 180, 175, 220]]], dtype=int64))
tensor = <function jax_tensor_frnt at 0x7f1e757436d0>

    def __call__(self, *input, params=None, data_keys=None):
        from ....core._backend import tensor
        from .....ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ....geometry.boxes import jax_Boxes
        from .....ivy.functional.backends.jax.general import jax_get_item
        from ....constants import jax_DType
        from ....core.check import jax_KORNIA_UNWRAP
    
        keys: typing.Any
        if data_keys is None:
            keys = self.data_keys
        else:
            keys = [jax_DataKey.get(inp) for inp in data_keys]
        if params is None:
            in_tensor_idx: typing.Any = keys.index(jax_DataKey.INPUT)
            in_tensor: typing.Any = jax_get_item(input, in_tensor_idx)
            in_tensor = self.transform_tensor(in_tensor)
            self._params = self.forward_parameters(jax_shape_frnt_(in_tensor))
>           self._params.update({"dtype": tensor(jax_DType.get(in_tensor.dtype).value)})

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/_2d/mix/base.py:193: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = jax_DType.INT64 | jax_DType.FLOAT16 | jax_DType.FLOAT32 | jax_DType.FLOAT64, value = dtype('float32')

    @classmethod
    def get(cls, value):
        from ..ivy.functional.backends.jax.general import jax_get_item
        from ..ivy.functional.frontends.torch.tensor import jax_item_frnt_
    
        if isinstance(value, (np.dtype,)):
>           return jax_get_item(cls, str(value).upper()[6:])

ivy_transpiled_outputs/jax_outputs/kornia/constants.py:87: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

inp = jax_DType.INT64 | jax_DType.FLOAT16 | jax_DType.FLOAT32 | jax_DType.FLOAT64, query = '2', kwargs = {}

    @functools.wraps(fn)
    def wrapper(inp, query, **kwargs):
        try:
            res = inp.__getitem__(query)
        except Exception:
>           res = fn(inp, query, **kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/utils/decorator_utils.py:221: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (jax_DType.INT64 | jax_DType.FLOAT16 | jax_DType.FLOAT32 | jax_DType.FLOAT64, '2'), kwargs = {}, handle_mixed_in_backend = True

    @functools.wraps(fn)
    def _handle_partial_mixed_function(*args, **kwargs):
        handle_mixed_in_backend = False
        if not hasattr(fn, "partial_mixed_handler"):
            handle_mixed_in_backend = True
        else:
            compos = getattr(fn, "compos")
            condition = getattr(fn, "partial_mixed_handler")
        if handle_mixed_in_backend or condition(*args, **kwargs):
>           return fn(*args, **kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/func_wrapper.py:160: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = jax_DType.INT64 | jax_DType.FLOAT16 | jax_DType.FLOAT32 | jax_DType.FLOAT64, query = '2'

    @jax_handle_get_item
    @jax_handle_partial_mixed_function
    def jax_get_item(
        x: jax.Array, /, query: Union[jax.Array, Tuple], *, copy: Optional[bool] = None
    ):
        from ...ivy.general import jax_is_array_bknd
        from ...ivy.data_type import jax_is_bool_dtype_bknd
    
        if copy:
            x = x.copy()
        if jax_is_array_bknd(query) and jax_is_bool_dtype_bknd(query):
            if not len(query.shape):
                if not query:
                    return jax.numpy.array([], dtype=x.dtype)
                else:
                    return jax.numpy.expand_dims(x, 0)
            query = jax__mask_to_index(query, x)
        elif isinstance(query, list):
            query = (query,)
>       return x.__getitem__(query)

ivy_transpiled_outputs/jax_outputs/ivy/functional/backends/jax/general.py:86: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = jax_DType.INT64 | jax_DType.FLOAT16 | jax_DType.FLOAT32 | jax_DType.FLOAT64, name = '2'

    def __getitem__(cls, name):
>       return cls._member_map_[name]
E       KeyError: '2'

/opt/miniconda/envs/multienv/lib/python3.10/enum.py:432: KeyError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.RandomMosaic
_________________________________________________________________________________ test_RandomRotation3D[jax-s2s-False] _________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_RandomRotation3D(target_framework, mode, backend_compile):
        print("kornia.augmentation.RandomRotation3D")
    
        init_args = ((15., 20., 20.),)
        init_kwargs = {"p": 1.}
        call_args = (torch.rand(1, 1, 3, 3, 3),)
        call_kwargs = {}
    
>       _test_augmentation_class(
            kornia.augmentation.RandomRotation3D,
            target_framework,
            init_args,
            init_kwargs,
            call_args,
            call_kwargs,
            deterministic_output=False,
            backend_compile=backend_compile,
        )

kornia/augmentation/test_augmentation4.py:219: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

augmentation_cls = <class 'kornia.augmentation._3d.geometric.rotation.RandomRotation3D'>, target = 'jax', init_args = ((15.0, 20.0, 20.0),), init_kwargs = {'p': 1.0}
call_args = (tensor([[[[[0.5353, 0.1174, 0.5160],
           [0.6633, 0.9023, 0.1648],
           [0.8373, 0.9418, 0.2788]],

    ...,

          [[0.3021, 0.7839, 0.6877],
           [0.3055, 0.2079, 0.2304],
           [0.7443, 0.3946, 0.3462]]]]]),)
call_kwargs = {}, deterministic_output = False, backend_compile = False, tolerance = 0.001

    def _test_augmentation_class(
        augmentation_cls,
        target,
        init_args=(),
        init_kwargs={},
        call_args=(),
        call_kwargs={},
        deterministic_output=True,
        backend_compile=False,
        tolerance=1e-3,
    ):
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_cls = ivy.transpile(augmentation_cls, source="torch", target=target)
    
        torch_aug = augmentation_cls(*init_args, **init_kwargs)
        transpiled_init_args = _nest_torch_tensor_to_new_framework(init_args, target)
        transpiled_init_kwargs = _nest_torch_tensor_to_new_framework(init_kwargs, target)
        transpiled_aug = transpiled_cls(*transpiled_init_args, **transpiled_init_kwargs)
    
        # assert dir(torch_aug) == dir(transpiled_aug), f"attributes/methods of transpiled object do not align with the original - orig: {dir(torch_aug)} != transpiled: {dir(transpiled_aug)}"
    
        torch_out = torch_aug(*call_args, **call_kwargs)
        transpiled_call_args = _nest_torch_tensor_to_new_framework(call_args, target)
        transpiled_call_kwargs = _nest_torch_tensor_to_new_framework(call_kwargs, target)
>       transpiled_out = transpiled_aug(*transpiled_call_args, **transpiled_call_kwargs)

kornia/augmentation/test_augmentation4.py:43: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_RandomRotation3D(degrees=(15.0, 20.0, 20.0), p=1.0, p_batch=1.0, same_on_batch=False, resample=bilinear, align_corners=False)
input = Array([[[[[0.5353063 , 0.11742461, 0.5160469 ],
          [0.66334784, 0.9022783 , 0.16476536],
          [0.83728015,...67],
          [0.30546904, 0.20793456, 0.2303806 ],
          [0.74425113, 0.39462137, 0.34617573]]]]], dtype=float32)
params = {'batch_prob': Array([1.], dtype=float32), 'forward_input_shape': Array([1, 1, 3, 3, 3], dtype=int64), 'pitch': Array([-8.851233], dtype=float32), 'roll': Array([7.4675026], dtype=float32), ...}
kwargs = {}, jax_shape_frnt_ = <function jax_shape_frnt_ at 0x7f1e770bc3a0>, jax_set_item = <function jax_set_item at 0x7f1e75878430>, tensor = <function jax_tensor_frnt at 0x7f1e44c6fbe0>
in_tensor = Array([[[[[0.5353063 , 0.11742461, 0.5160469 ],
          [0.66334784, 0.9022783 , 0.16476536],
          [0.83728015,...67],
          [0.30546904, 0.20793456, 0.2303806 ],
          [0.74425113, 0.39462137, 0.34617573]]]]], dtype=float32)
input_shape = ivy.frontends.torch.Size([1, 1, 3, 3, 3]), batch_shape = ivy.frontends.torch.Size([1, 1, 3, 3, 3]), flags = {'align_corners': False, 'resample': <jax_Resample.BILINEAR: 1>}

    def __call__(self, input, params=None, **kwargs):
        from ...ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ...ivy.functional.backends.jax.general import jax_set_item
        from ..core._backend import tensor
    
        in_tensor = self.__unpack_input__(input)
        input_shape = jax_shape_frnt_(in_tensor)
        in_tensor = self.transform_tensor(in_tensor)
        batch_shape = jax_shape_frnt_(in_tensor)
        if params is None:
            params = self.forward_parameters(batch_shape)
        if "batch_prob" not in params:
            params = jax_set_item(params, "batch_prob", tensor([True] * batch_shape[0]))
        params, flags = self._process_kwargs_to_params_and_flags(
            params, self.flags, **kwargs
        )
>       output = self.apply_func(in_tensor, params, flags)

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/base.py:219: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_RandomRotation3D(degrees=(15.0, 20.0, 20.0), p=1.0, p_batch=1.0, same_on_batch=False, resample=bilinear, align_corners=False)
in_tensor = Array([[[[[0.5353063 , 0.11742461, 0.5160469 ],
          [0.66334784, 0.9022783 , 0.16476536],
          [0.83728015,...67],
          [0.30546904, 0.20793456, 0.2303806 ],
          [0.74425113, 0.39462137, 0.34617573]]]]], dtype=float32)
params = {'batch_prob': Array([1.], dtype=float32), 'forward_input_shape': Array([1, 1, 3, 3, 3], dtype=int64), 'pitch': Array([-8.851233], dtype=float32), 'roll': Array([7.4675026], dtype=float32), ...}
flags = {'align_corners': False, 'resample': <jax_Resample.BILINEAR: 1>}

    def apply_func(self, in_tensor, params, flags=None):
        if flags is None:
            flags = self.flags
>       trans_matrix = self.generate_transformation_matrix(in_tensor, params, flags)

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/_3d/base.py:118: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_RandomRotation3D(degrees=(15.0, 20.0, 20.0), p=1.0, p_batch=1.0, same_on_batch=False, resample=bilinear, align_corners=False)
input = Array([[[[[0.5353063 , 0.11742461, 0.5160469 ],
          [0.66334784, 0.9022783 , 0.16476536],
          [0.83728015,...67],
          [0.30546904, 0.20793456, 0.2303806 ],
          [0.74425113, 0.39462137, 0.34617573]]]]], dtype=float32)
params = {'batch_prob': Array([1.], dtype=float32), 'forward_input_shape': Array([1, 1, 3, 3, 3], dtype=int64), 'pitch': Array([-8.851233], dtype=float32), 'roll': Array([7.4675026], dtype=float32), ...}
flags = {'align_corners': False, 'resample': <jax_Resample.BILINEAR: 1>}

    def generate_transformation_matrix(self, input, params, flags):
        from ....ivy.functional.frontends.torch.tensor import jax_any_frnt_
        from ....ivy.functional.frontends.torch.tensor import jax_all_frnt_
        from ....ivy.functional.frontends.torch.tensor import jax_index_put_frnt_
        from ....ivy.functional.backends.jax.general import jax_get_item
    
        batch_prob = params["batch_prob"]
        to_apply = batch_prob > 0.5
        in_tensor = self.transform_tensor(input)
        if not jax_any_frnt_(to_apply):
            trans_matrix = self.identity_matrix(in_tensor)
        elif jax_all_frnt_(to_apply):
>           trans_matrix = self.compute_transformation(
                in_tensor, params=params, flags=flags
            )

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/_3d/base.py:86: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_RandomRotation3D(degrees=(15.0, 20.0, 20.0), p=1.0, p_batch=1.0, same_on_batch=False, resample=bilinear, align_corners=False)
input = Array([[[[[0.5353063 , 0.11742461, 0.5160469 ],
          [0.66334784, 0.9022783 , 0.16476536],
          [0.83728015,...67],
          [0.30546904, 0.20793456, 0.2303806 ],
          [0.74425113, 0.39462137, 0.34617573]]]]], dtype=float32)
params = {'batch_prob': Array([1.], dtype=float32), 'forward_input_shape': Array([1, 1, 3, 3, 3], dtype=int64), 'pitch': Array([-8.851233], dtype=float32), 'roll': Array([7.4675026], dtype=float32), ...}
flags = {'align_corners': False, 'resample': <jax_Resample.BILINEAR: 1>}

    def compute_transformation(self, input, params, flags):
        from .....ivy.functional.frontends.torch.tensor import jax_to_frnt_
        from ....geometry.transform.affwarp import jax__compute_tensor_center3d
        from ....geometry.transform.affwarp import jax__compute_rotation_matrix3d
        from .....ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ....utils.misc import jax_eye_like
        from .....ivy.functional.backends.jax.general import jax_set_item
    
        yaw: typing.Any = jax_to_frnt_(params["yaw"], input)
        pitch: typing.Any = jax_to_frnt_(params["pitch"], input)
        roll: typing.Any = jax_to_frnt_(params["roll"], input)
        center: typing.Any = jax__compute_tensor_center3d(input)
        rotation_mat: typing.Any = jax__compute_rotation_matrix3d(
>           yaw, pitch, roll, center.expand(jax_shape_frnt_(yaw)[0], -1)
        )
E       AttributeError: 'jaxlib.xla_extension.ArrayImpl' object has no attribute 'expand'

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/_3d/geometric/rotation.py:66: AttributeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.RandomRotation3D
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/augmentation/test_augmentation4.py::test_RandomMosaic[jax-s2s-False] - KeyError: '2'
FAILED kornia/augmentation/test_augmentation4.py::test_RandomRotation3D[jax-s2s-False] - AttributeError: 'jaxlib.xla_extension.ArrayImpl' object has no attribute 'expand'
============================================================================== 2 failed, 15 passed in 3412.00s (0:56:51) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 39 items

kornia/test_enhance.py ..............F.............F..........                                                                                                                                   [100%]

=============================================================================================== FAILURES ===============================================================================================
__________________________________________________________________________________ test_equalize_clahe[jax-s2s-False] __________________________________________________________________________________

arrays = []

    def jax_stack(
        arrays: Union[Tuple[jax.Array], List[jax.Array]],
        /,
        *,
        axis: int = 0,
        out: Optional[jax.Array] = None,
    ):
        try:
>           return jax.numpy.stack(arrays, axis=axis)

ivy_transpiled_outputs/jax_outputs/ivy/functional/backends/jax/manipulation.py:125: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

arrays = [], axis = 2, out = None, dtype = None

    def stack(arrays: np.ndarray | Array | Sequence[ArrayLike],
              axis: int = 0, out: None = None, dtype: DTypeLike | None = None) -> Array:
      """Join arrays along a new axis.
    
      JAX implementation of :func:`numpy.stack`.
    
      Args:
        arrays: a sequence of arrays to stack; each must have the same shape. If a
          single array is given it will be treated equivalently to
          `arrays = unstack(arrays)`, but the implementation will avoid explicit
          unstacking.
        axis: specify the axis along which to stack.
        out: unused by JAX
        dtype: optional dtype of the resulting array. If not specified, the dtype
          will be determined via type promotion rules described in :ref:`type-promotion`.
    
      Returns:
        the stacked result.
    
      See also:
        - :func:`jax.numpy.unstack`: inverse of ``stack``.
        - :func:`jax.numpy.concatenate`: concatenation along existing axes.
        - :func:`jax.numpy.vstack`: stack vertically, i.e. along axis 0.
        - :func:`jax.numpy.hstack`: stack horizontally, i.e. along axis 1.
        - :func:`jax.numpy.dstack`: stack depth-wise, i.e. along axis 2.
        - :func:`jax.numpy.column_stack`: stack columns.
    
      Examples:
        >>> x = jnp.array([1, 2, 3])
        >>> y = jnp.array([4, 5, 6])
        >>> jnp.stack([x, y])
        Array([[1, 2, 3],
               [4, 5, 6]], dtype=int32)
        >>> jnp.stack([x, y], axis=1)
        Array([[1, 4],
               [2, 5],
               [3, 6]], dtype=int32)
    
        :func:`~jax.numpy.unstack` performs the inverse operation:
    
        >>> arr = jnp.stack([x, y], axis=1)
        >>> x, y = jnp.unstack(arr, axis=1)
        >>> x
        Array([1, 2, 3], dtype=int32)
        >>> y
        Array([4, 5, 6], dtype=int32)
      """
      if not len(arrays):
>       raise ValueError("Need at least one array to stack.")
E       ValueError: Need at least one array to stack.

/opt/fw/jax/jax/_src/numpy/lax_numpy.py:4094: ValueError

The above exception was the direct cause of the following exception:

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_equalize_clahe(target_framework, mode, backend_compile):
        trace_args = (torch.rand(1, 10, 20),)
        trace_kwargs = {
            "clip_limit": 40.0,
            "grid_size": (8, 8),
            "slow_and_differentiable": False,
        }
        test_args = (torch.rand(2, 3, 10, 20),)
        test_kwargs = {
            "clip_limit": 20.0,
            "grid_size": (4, 4),
            "slow_and_differentiable": False,
        }
>       _test_function(
            kornia.enhance.equalize_clahe,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
            skip=True,
        )

kornia/test_enhance.py:363: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function equalize_clahe at 0x7f8379885480>
trace_args = (tensor([[[0.5380, 0.8300, 0.8760, 0.7031, 0.5277, 0.9642, 0.2888, 0.6899,
          0.6382, 0.6047, 0.9391, 0.0137, 0...         0.4778, 0.3851, 0.5184, 0.5208, 0.2134, 0.2922, 0.4058, 0.1902,
          0.5893, 0.2901, 0.8485, 0.2520]]]),)
trace_kwargs = {'clip_limit': 40.0, 'grid_size': (8, 8), 'slow_and_differentiable': False}
test_args = (tensor([[[[0.8829, 0.0787, 0.6974,  ..., 0.9527, 0.3450, 0.5425],
          [0.5350, 0.0582, 0.9277,  ..., 0.3475, 0...., 0.5165, 0.3019,  ..., 0.5799, 0.6119, 0.5694],
          [0.5860, 0.7752, 0.7840,  ..., 0.6748, 0.8498, 0.4545]]]]),)
test_kwargs = {'clip_limit': 20.0, 'grid_size': (4, 4), 'slow_and_differentiable': False}, target = 'jax', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = True, deterministic = True
class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function equalize_clahe at 0x7f8379885480>, fn_name = 'kornia.enhance.equalize_clahe'
trace_args = (tensor([[[0.5380, 0.8300, 0.8760, 0.7031, 0.5277, 0.9642, 0.2888, 0.6899,
          0.6382, 0.6047, 0.9391, 0.0137, 0...         0.4778, 0.3851, 0.5184, 0.5208, 0.2134, 0.2922, 0.4058, 0.1902,
          0.5893, 0.2901, 0.8485, 0.2520]]]),)
trace_kwargs = {'clip_limit': 40.0, 'grid_size': (8, 8), 'slow_and_differentiable': False}
test_args = (tensor([[[[0.8829, 0.0787, 0.6974,  ..., 0.9527, 0.3450, 0.5425],
          [0.5350, 0.0582, 0.9277,  ..., 0.3475, 0...., 0.5165, 0.3019,  ..., 0.5799, 0.6119, 0.5694],
          [0.5860, 0.7752, 0.7840,  ..., 0.6748, 0.8498, 0.4545]]]]),)
test_kwargs = {'clip_limit': 20.0, 'grid_size': (4, 4), 'slow_and_differentiable': False}, target = 'jax', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = Array([[[[0.53798753, 0.83000624, 0.8759871 , 0.703111  , 0.5276589 ,
          0.96420336, 0.28876847, 0.68988013, 0...., 0.29221052, 0.40576148,
          0.19023132, 0.58931196, 0.2901345 , 0.84852415, 0.25201976]]]],      dtype=float32)
args = (), kwargs = {'clip_limit': 40.0, 'grid_size': (8, 8), 'slow_and_differentiable': False}, jax_numel_frnt_ = <function jax_numel_frnt_ at 0x7f82f44facb0>
jax_shape_frnt_ = <function jax_shape_frnt_ at 0x7f82f44f9ea0>, jax_view_frnt_ = <function jax_view_frnt_ at 0x7f82f44f8820>, input_shape = ivy.frontends.torch.Size([1, 10, 20])

    @wraps(f)
    def _wrapper(input, *args, **kwargs):
        from ...ivy.functional.frontends.torch.tensor import jax_numel_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_view_frnt_
    
        if not isinstance(input, (jax.Array, nnx.Param)):
            raise TypeError(f"Input input type is not a Tensor. Got {type(input)}")
        if jax_numel_frnt_(input) == 0:
            raise ValueError("Invalid input tensor, it is empty.")
        input_shape = jax_shape_frnt_(input)
        input = jax__to_bchw(input)
>       output = f(input, *args, **kwargs)

ivy_transpiled_outputs/jax_outputs/kornia/utils/image.py:71: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = Array([[[[0.53798753, 0.83000624, 0.8759871 , 0.703111  , 0.5276589 ,
          0.96420336, 0.28876847, 0.68988013, 0...., 0.29221052, 0.40576148,
          0.19023132, 0.58931196, 0.2901345 , 0.84852415, 0.25201976]]]],      dtype=float32)
clip_limit = 40.0, grid_size = (8, 8), slow_and_differentiable = False

    @jax_perform_keep_shape_image
    def jax_equalize_clahe(
        input, clip_limit=40.0, grid_size=(8, 8), slow_and_differentiable=False
    ):
        from ...ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_reshape_as_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_permute_frnt_
        from ...ivy.functional.backends.jax.general import jax_get_item
        from ...ivy.functional.frontends.torch.tensor import jax_dim_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_squeeze_frnt_
    
        if not isinstance(clip_limit, (float,)):
            raise TypeError(f"Input clip_limit type is not float. Got {type(clip_limit)}")
        if not isinstance(grid_size, (tuple,)):
            raise TypeError(f"Input grid_size type is not Tuple. Got {type(grid_size)}")
        if len(grid_size) != 2:
            raise TypeError(
                f"Input grid_size is not a Tuple with 2 elements. Got {len(grid_size)}"
            )
        if isinstance(grid_size[0], (float,)) or isinstance(grid_size[1], (float,)):
            raise TypeError("Input grid_size type is not valid, must be a Tuple[int, int].")
        if grid_size[0] <= 0 or grid_size[1] <= 0:
            raise ValueError(f"Input grid_size elements must be positive. Got {grid_size}")
        imgs: typing.Any = input
>       hist_tiles, img_padded = jax__compute_tiles(imgs, grid_size, True)

ivy_transpiled_outputs/jax_outputs/kornia/enhance/equalization.py:485: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

imgs = Array([[[[0.53798753, 0.83000624, 0.8759871 , 0.703111  , 0.5276589 ,
          0.96420336, 0.28876847, 0.68988013, 0...., 0.29221052, 0.40576148,
          0.19023132, 0.58931196, 0.2901345 , 0.84852415, 0.25201976]]]],      dtype=float32)
grid_size = (8, 8), even_tile_size = True

    def jax__compute_tiles(imgs, grid_size, even_tile_size=False):
        from ...ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ...ivy.functional.frontends.torch.nn.functional.vision_functions import (
            jax_pad_frnt,
        )
        from ...ivy.functional.frontends.torch.tensor import jax_contiguous_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_squeeze_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_unfold_frnt_
    
        batch: typing.Any = imgs
        h, w = jax_shape_frnt_(batch)[-2:][0], jax_shape_frnt_(batch)[-2:][1]
        kernel_vert: typing.Any = math.ceil(h / grid_size[0])
        kernel_horz: typing.Any = math.ceil(w / grid_size[1])
        if even_tile_size:
            kernel_vert = kernel_vert + (1 if kernel_vert % 2 else 0)
            kernel_horz = kernel_horz + (1 if kernel_horz % 2 else 0)
        pad_vert = kernel_vert * grid_size[0] - h
        pad_horz = kernel_horz * grid_size[1] - w
        if pad_vert > jax_shape_frnt_(batch)[-2] or pad_horz > jax_shape_frnt_(batch)[-1]:
            raise ValueError(
                "Cannot compute tiles on the image according to the given grid size"
            )
        if pad_vert > 0 or pad_horz > 0:
            batch = jax_pad_frnt(batch, [0, pad_horz, 0, pad_vert], mode="reflect")
        c: typing.Any = jax_shape_frnt_(batch)[-3]
        tiles: typing.Any = jax_contiguous_frnt_(
            jax_squeeze_frnt_(
                jax_unfold_frnt_(
>                   jax_unfold_frnt_(
                        jax_unfold_frnt_(batch, 1, c, c), 2, kernel_vert, kernel_vert
                    ),
                    3,
                    kernel_horz,
                    kernel_horz,
                ),
                1,
            )
        )

ivy_transpiled_outputs/jax_outputs/kornia/enhance/equalization.py:61: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (Array([[[[[0.53798753, 0.36771315, 0.9314057 , 0.70001346, 0.7354006 ,
           0.2725011 , 0.6669419 , 0.82184947,...       0.55887985, 0.32670873, 0.73709416, 0.016927  , 0.02535367,
           0.7685733 ]]]]], dtype=float32), 2, 2, 2)
kwargs = {}, jax_is_array_bknd = <function jax_is_array_bknd at 0x7f82dab230a0>
array_like = Array([[[[[0.53798753, 0.36771315, 0.9314057 , 0.70001346, 0.7354006 ,
           0.2725011 , 0.6669419 , 0.82184947, ...1465,
           0.55887985, 0.32670873, 0.73709416, 0.016927  , 0.02535367,
           0.7685733 ]]]]], dtype=float32)

    @functools.wraps(fn)
    def wrapper(*args, **kwargs):
        from ..functional.ivy.general import jax_is_array_bknd
    
        array_like = args[0]
        if hasattr(array_like, "__class__") and array_like.__class__.__name__ in [
            "list",
            "tuple",
        ]:
            array_like = array_like[0]
        if jax_is_array_bknd(array_like):
>           return fn(*args, **kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/utils/decorator_utils.py:200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = Array([[[[[0.53798753, 0.36771315, 0.9314057 , 0.70001346, 0.7354006 ,
           0.2725011 , 0.6669419 , 0.82184947, ...1465,
           0.55887985, 0.32670873, 0.73709416, 0.016927  , 0.02535367,
           0.7685733 ]]]]], dtype=float32)
dimension = 2, size = 2, step = 2

    @jax_handle_methods
    def jax_unfold_frnt_(tensor, dimension, size, step):
        from ...backends.jax.general import jax_get_item
        from ...backends.jax.general import jax_set_item
        from .indexing_slicing_joining_mutating_ops import jax_stack_frnt
    
        slices = []
        self_shape = tuple(jax_shape_frnt_(tensor))
        for i in range(0, jax_get_item(self_shape, dimension) - size + 1, step):
            slicing = [slice(None)] * len(jax_shape_frnt_(tensor))
            slicing = jax_set_item(slicing, dimension, slice(i, i + size))
            slices.append(jax_get_item(tensor, tuple(slicing)))
>       stacked = jax_stack_frnt(slices, dim=dimension)

ivy_transpiled_outputs/jax_outputs/ivy/functional/frontends/torch/tensor.py:256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensors = [], dim = 2

    def jax_stack_frnt(tensors, dim=0, *, out=None):
        from ...backends.jax.manipulation import jax_stack
    
>       return jax_stack(tensors, axis=dim, out=out)

ivy_transpiled_outputs/jax_outputs/ivy/functional/frontends/torch/indexing_slicing_joining_mutating_ops.py:119: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

arrays = []

    def jax_stack(
        arrays: Union[Tuple[jax.Array], List[jax.Array]],
        /,
        *,
        axis: int = 0,
        out: Optional[jax.Array] = None,
    ):
        try:
            return jax.numpy.stack(arrays, axis=axis)
        except ValueError as error:
>           raise Exception(error) from error
E           Exception: Need at least one array to stack.

ivy_transpiled_outputs/jax_outputs/ivy/functional/backends/jax/manipulation.py:127: Exception
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.enhance.equalization.equalize_clahe
___________________________________________________________________________________ test_ZCAWhitening[jax-s2s-False] ___________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_ZCAWhitening(target_framework, mode, backend_compile):
        print("kornia.enhance.ZCAWhitening")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledZCAWhitening = ivy.transpile(kornia.enhance.ZCAWhitening, source="torch", target=target_framework)
    
        x = torch.tensor([[0,1],[1,0],[-1,0],[0,-1]], dtype = torch.float32)
        zca = kornia.enhance.ZCAWhitening().fit(x)
        torch_out = zca(x)
    
        transpiled_x = _nest_torch_tensor_to_new_framework(x, target_framework)
        transpiled_zca = TranspiledZCAWhitening().fit(transpiled_x)
>       transpiled_out = transpiled_zca(x)

kornia/test_enhance.py:697: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_ZCAWhitening(), x = tensor([[ 0.,  1.],
        [ 1.,  0.],
        [-1.,  0.],
        [ 0., -1.]]), include_fit = False

    def __call__(self, x, include_fit=False):
        if include_fit:
            self.fit(x)
        if not self.fitted:
            raise RuntimeError(
                "Needs to be fitted first before running. Please call fit or set include_fit to True."
            )
>       x_whiten = jax_linear_transform(
            x, self.transform_matrix, self.mean_vector, self.dim
        )

ivy_transpiled_outputs/jax_outputs/kornia/enhance/zca.py:85: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

inp = tensor([[ 0.,  1.],
        [ 1.,  0.],
        [-1.,  0.],
        [ 0., -1.]]), transform_matrix = Array([[1.224744, 0.      ],
       [0.      , 1.224744]], dtype=float32)
mean_vector = Array([[0., 0.]], dtype=float32), dim = 0

    def jax_linear_transform(inp, transform_matrix, mean_vector, dim=0):
        from ...ivy.functional.frontends.torch.tensor import jax_size_frnt_
        from ...ivy.functional.frontends.torch.creation_ops import jax_arange_frnt
        from ...ivy.functional.frontends.torch.comparison_ops import jax_argsort_frnt
        from ...ivy.functional.frontends.torch.tensor import jax_tolist_frnt_
        from ...ivy.functional.backends.jax.general import jax_get_item
        from ...ivy.functional.frontends.torch.tensor import jax_item_frnt_
        from ...ivy.functional.frontends.torch.reduction_ops import jax_prod_frnt
        from ...ivy.functional.frontends.torch.tensor import jax_permute_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_reshape_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_mm_frnt_
        from ..core._backend import concatenate
        from ..core._backend import tensor
    
        inp_size = jax_size_frnt_(inp)
        if dim >= len(inp_size) or dim < -len(inp_size):
            raise IndexError(
                f"Dimension out of range (expected to be in range of [{-len(inp_size)},{len(inp_size) - 1}], but got {dim}"
            )
        if dim < 0:
            dim = len(inp_size) + dim
        feat_dims = concatenate(
            [jax_arange_frnt(0, dim), jax_arange_frnt(dim + 1, len(inp_size))]
        )
        perm = concatenate([tensor([dim]), feat_dims])
        perm_inv = jax_argsort_frnt(perm)
        new_order: typing.Any = jax_tolist_frnt_(perm)
        inv_order: typing.Any = jax_tolist_frnt_(perm_inv)
        feature_sizes = tensor(
            jax_get_item(inp_size, slice(0, dim, None))
            + jax_get_item(inp_size, slice(dim + 1, None, None))
        )
        num_features: typing.Any = int(jax_item_frnt_(jax_prod_frnt(feature_sizes)))
        inp_permute = jax_permute_frnt_(inp, new_order)
        inp_flat = jax_reshape_frnt_(inp_permute, (-1, num_features))
>       inp_center = inp_flat - mean_vector
E       TypeError: unsupported operand type(s) for -: 'Tensor' and 'jaxlib.xla_extension.ArrayImpl'

ivy_transpiled_outputs/jax_outputs/kornia/enhance/zca.py:318: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.enhance.ZCAWhitening
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/test_enhance.py::test_equalize_clahe[jax-s2s-False] - Exception: Need at least one array to stack.
FAILED kornia/test_enhance.py::test_ZCAWhitening[jax-s2s-False] - TypeError: unsupported operand type(s) for -: 'Tensor' and 'jaxlib.xla_extension.ArrayImpl'
============================================================================== 2 failed, 37 passed in 2622.88s (0:43:42) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 26 items

kornia/geometry/test_epipolar.py F......F.......FF.........                                                                                                                                      [100%]

=============================================================================================== FAILURES ===============================================================================================
_________________________________________________________________________________ test_find_essential[numpy-s2s-False] _________________________________________________________________________________

target_framework = 'numpy', mode = 's2s', backend_compile = False

    def test_find_essential(target_framework, mode, backend_compile):
        trace_args = (
            torch.rand(1, 8, 2),
            torch.rand(1, 8, 2),
        )
        trace_kwargs = {'weights': torch.rand(1, 8)}
        test_args = (
            torch.rand(5, 8, 2),
            torch.rand(5, 8, 2),
        )
        test_kwargs = {'weights': torch.rand(5, 8)}
>       _test_function(
            kornia.geometry.epipolar.find_essential,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
            # NOTE: numerical instability in svd()/lu() leads to logits not being allclose
            deterministic=False,
        )

kornia/geometry/test_epipolar.py:20: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function find_essential at 0x7f9c602a40d0>
trace_args = (tensor([[[0.7243, 0.7929],
         [0.0694, 0.6896],
         [0.5882, 0.2264],
         [0.6931, 0.9180],
         ...0.6923],
         [0.1376, 0.4141],
         [0.8181, 0.9112],
         [0.0351, 0.8938],
         [0.8142, 0.9049]]]))
trace_kwargs = {'weights': tensor([[0.1439, 0.5930, 0.2520, 0.5092, 0.1700, 0.4823, 0.6003, 0.7992]])}
test_args = (tensor([[[0.4259, 0.4544],
         [0.8481, 0.3707],
         [0.8078, 0.9689],
         [0.4893, 0.4979],
         ...0.1018],
         [0.2468, 0.2142],
         [0.6138, 0.0594],
         [0.7966, 0.7272],
         [0.3190, 0.9875]]]))
test_kwargs = {'weights': tensor([[0.7824, 0.9500, 0.8758, 0.2604, 0.6658, 0.5421, 0.5730, 0.6697],
        [0.2349, 0.4713, 0.9836,...1, 0.4195, 0.2779, 0.1841, 0.9015, 0.9748],
        [0.6752, 0.5798, 0.2439, 0.1092, 0.7049, 0.5282, 0.0292, 0.5599]])}
target = 'numpy', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = False, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function find_essential at 0x7f9c602a40d0>, fn_name = 'kornia.geometry.epipolar.find_essential'
trace_args = (tensor([[[0.7243, 0.7929],
         [0.0694, 0.6896],
         [0.5882, 0.2264],
         [0.6931, 0.9180],
         ...0.6923],
         [0.1376, 0.4141],
         [0.8181, 0.9112],
         [0.0351, 0.8938],
         [0.8142, 0.9049]]]))
trace_kwargs = {'weights': tensor([[0.1439, 0.5930, 0.2520, 0.5092, 0.1700, 0.4823, 0.6003, 0.7992]])}
test_args = (tensor([[[0.4259, 0.4544],
         [0.8481, 0.3707],
         [0.8078, 0.9689],
         [0.4893, 0.4979],
         ...0.1018],
         [0.2468, 0.2142],
         [0.6138, 0.0594],
         [0.7966, 0.7272],
         [0.3190, 0.9875]]]))
test_kwargs = {'weights': tensor([[0.7824, 0.9500, 0.8758, 0.2604, 0.6658, 0.5421, 0.5730, 0.6697],
        [0.2349, 0.4713, 0.9836,...1, 0.4195, 0.2779, 0.1841, 0.9015, 0.9748],
        [0.6752, 0.5798, 0.2439, 0.1092, 0.7049, 0.5282, 0.0292, 0.5599]])}
target = 'numpy', backend_compile = False, tolerance = 0.001, deterministic = False, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

points1 = array([[[0.7243157 , 0.7928598 ],
        [0.06940222, 0.6895522 ],
        [0.58815354, 0.22639889],
        [0.69309...
        [0.5818633 , 0.2906587 ],
        [0.71522963, 0.10790133],
        [0.94630283, 0.3246464 ]]], dtype=float32)
points2 = array([[[0.33717132, 0.22893298],
        [0.28714406, 0.084966  ],
        [0.01091826, 0.25651592],
        [0.96684...
        [0.81811106, 0.9112035 ],
        [0.03509611, 0.89381194],
        [0.81423616, 0.90494704]]], dtype=float32)
weights = array([[0.14388543, 0.592963  , 0.25200546, 0.50918394, 0.1699993 ,
        0.48233616, 0.60033995, 0.7991952 ]], dtype=float32)

    def numpy_find_essential(points1, points2, weights=None):
        from ....ivy.functional.frontends.torch.tensor import numpy_to_frnt_
    
>       E = numpy_to_frnt_(numpy_run_5point(points1, points2, weights), points1.dtype)

ivy_transpiled_outputs/numpy_outputs/kornia/geometry/epipolar/essential.py:455: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

points1 = array([[[0.7243157 , 0.7928598 ],
        [0.06940222, 0.6895522 ],
        [0.58815354, 0.22639889],
        [0.69309...
        [0.5818633 , 0.2906587 ],
        [0.71522963, 0.10790133],
        [0.94630283, 0.3246464 ]]], dtype=float32)
points2 = array([[[0.33717132, 0.22893298],
        [0.28714406, 0.084966  ],
        [0.01091826, 0.25651592],
        [0.96684...
        [0.81811106, 0.9112035 ],
        [0.03509611, 0.89381194],
        [0.81423616, 0.90494704]]], dtype=float32)
weights = array([[0.14388543, 0.592963  , 0.25200546, 0.50918394, 0.1699993 ,
        0.48233616, 0.60033995, 0.7991952 ]], dtype=float32)

    def numpy_run_5point(points1, points2, weights=None):
        from ...core.check import numpy_KORNIA_CHECK_SHAPE
        from ...core.check import numpy_KORNIA_CHECK_SAME_SHAPE
        from ...core.check import numpy_KORNIA_CHECK
        from ....ivy.functional.frontends.torch.tensor import numpy_shape_frnt_
        from ....ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            numpy_chunk_frnt,
        )
        from ....ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            numpy_cat_frnt,
        )
        from ....ivy.functional.frontends.torch.tensor import numpy_transpose_frnt_
        from ....ivy.functional.frontends.torch.miscellaneous_ops import (
            numpy_diag_embed_frnt,
        )
        from ...core._backend import ones_like
    
        numpy_KORNIA_CHECK_SHAPE(points1, ["B", "N", "2"])
        numpy_KORNIA_CHECK_SAME_SHAPE(points1, points2)
        numpy_KORNIA_CHECK(
            numpy_shape_frnt_(points1)[1] >= 5, "Number of points should be >=5"
        )
        if weights is not None:
            numpy_KORNIA_CHECK_SAME_SHAPE(points1[:, :, 0], weights)
        batch_size, _, _ = numpy_shape_frnt_(points1)
        x1, y1 = numpy_chunk_frnt(points1, dim=-1, chunks=2)
        x2, y2 = numpy_chunk_frnt(points2, dim=-1, chunks=2)
        ones = ones_like(x1)
        X = numpy_cat_frnt(
            [x1 * x2, x1 * y2, x1, y1 * x2, y1 * y2, y1, x2, y2, ones], dim=-1
        )
        if weights is None:
            X = numpy_transpose_frnt_(X, -2, -1) @ X
        else:
>           w_diag = numpy_diag_embed_frnt(weights)

ivy_transpiled_outputs/numpy_outputs/kornia/geometry/epipolar/essential.py:62: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = array([[[0.14388543, 0.592963  , 0.25200546, 0.50918394, 0.1699993 ,
         0.48233616, 0.60033995, 0.7991952 ]]], dtype=float32), offset = 0, dim1 = 1, dim2 = 2

    def numpy_diag_embed_frnt(input, offset=0, dim1=-2, dim2=-1):
        from ...backends.numpy.data_type import numpy_dtype
        from .tensor import numpy_ndim_frnt_
        from .tensor import numpy_shape_frnt_
        from ...backends.numpy.general import numpy_set_item
        from ...backends.numpy.creation import numpy_zeros
        from ...backends.numpy.manipulation import numpy_concat
        from ....data_classes.array.experimental.manipulation import numpy_moveaxis_bknd_
        from ....data_classes.array.manipulation import numpy_expand_dims_bknd_
        from ...backends.numpy.creation import numpy_arange
        from .tensor import numpy_reshape_frnt_
        from .tensor import numpy_logical_and_frnt_
        from ...backends.numpy.searching import numpy_where
        from ....data_classes.array.data_type import numpy_astype_bknd_
    
        def _handle_dim(rank, idx):
            if idx >= 0 and idx < rank:
                return idx
            if idx < 0:
                idx = idx + rank
            if idx < 0 or idx >= rank:
                raise IndexError
            return idx
    
        input_type = numpy_dtype(input)
        rank = numpy_ndim_frnt_(input) + 1
        dim1 = _handle_dim(rank, dim1)
        dim2 = _handle_dim(rank, dim2)
        if dim1 > dim2:
            dim1, dim2 = dim2, dim1
            offset = -offset
        last_dim = list(numpy_shape_frnt_(input))[-1]
        if offset != 0:
            t_shape = list(numpy_shape_frnt_(input))
            t_shape = numpy_set_item(t_shape, -1, abs(offset))
            z = numpy_zeros(t_shape, dtype=input.dtype, device=None)
            pair = (z, input) if offset > 0 else (input, z)
            input = numpy_concat(pair, axis=-1)
            last_dim = last_dim + abs(offset)
        input = numpy_moveaxis_bknd_(numpy_expand_dims_bknd_(input, axis=dim1), -1, dim2)
        a_range = numpy_arange(last_dim, device=None, dtype=np.int64)
        b_range = numpy_arange(offset, last_dim + offset, device=None, dtype=np.int64)
        cond = a_range == numpy_expand_dims_bknd_(b_range, axis=-1)
        ag__result_list_0 = []
        for i in range(len(numpy_shape_frnt_(input))):
            res = last_dim if i in (dim1, dim2) else 1
            ag__result_list_0.append(res)
        cond_shape = ag__result_list_0
        cond = numpy_reshape_frnt_(cond, cond_shape)
>       if input.dtype == np.bool:

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/miscellaneous_ops.py:80: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

attr = 'bool'

    def __getattr__(attr):
        # Warn for expired attributes, and return a dummy function
        # that always raises an exception.
        import warnings
        import math
        try:
            msg = __expired_functions__[attr]
        except KeyError:
            pass
        else:
            warnings.warn(msg, DeprecationWarning, stacklevel=2)
    
            def _expired(*args, **kwds):
                raise RuntimeError(msg)
    
            return _expired
    
        # Emit warnings for deprecated attributes
        try:
            val, msg = __deprecated_attrs__[attr]
        except KeyError:
            pass
        else:
            warnings.warn(msg, DeprecationWarning, stacklevel=2)
            return val
    
        if attr in __future_scalars__:
            # And future warnings for those that will change, but also give
            # the AttributeError
            warnings.warn(
                f"In the future `np.{attr}` will be defined as the "
                "corresponding NumPy scalar.", FutureWarning, stacklevel=2)
    
        if attr in __former_attrs__:
>           raise AttributeError(__former_attrs__[attr])
E           AttributeError: module 'numpy' has no attribute 'bool'.
E           `np.bool` was a deprecated alias for the builtin `bool`. To avoid this error in existing code, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
E           The aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:
E               https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations. Did you mean: 'bool_'?

/opt/fw/mxnet/numpy/__init__.py:324: AttributeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.epipolar.essential.find_essential
----------------------------------------------------------------------------------------- Captured stderr call -----------------------------------------------------------------------------------------
/ivy/ivy-integration-tests/ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/miscellaneous_ops.py:80: FutureWarning: In the future `np.bool` will be defined as the corresponding NumPy scalar.
  if input.dtype == np.bool:
________________________________________________________________________________ test_find_fundamental[numpy-s2s-False] ________________________________________________________________________________

target_framework = 'numpy', mode = 's2s', backend_compile = False

    def test_find_fundamental(target_framework, mode, backend_compile):
        trace_args = (
            torch.rand(2, 8, 2),
            torch.rand(2, 8, 2),
        )
        trace_kwargs = {'weights': torch.rand(2, 8), 'method': '8POINT'}
        test_args = (
            torch.rand(5, 8, 2),
            torch.rand(5, 8, 2),
        )
        test_kwargs = {'weights': torch.rand(5, 8), 'method': '8POINT'}
>       _test_function(
            kornia.geometry.epipolar.find_fundamental,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=3e-2,
            mode=mode,
        )

kornia/geometry/test_epipolar.py:206: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function find_fundamental at 0x7f9c602a4670>
trace_args = (tensor([[[0.9606, 0.1674],
         [0.9133, 0.1348],
         [0.1993, 0.9581],
         [0.4058, 0.9906],
         ...0.2779],
         [0.1307, 0.3443],
         [0.6073, 0.9665],
         [0.7303, 0.2311],
         [0.2225, 0.9522]]]))
trace_kwargs = {'method': '8POINT', 'weights': tensor([[0.7532, 0.0508, 0.8199, 0.8894, 0.2269, 0.3381, 0.7236, 0.0336],
        [0.2014, 0.4073, 0.0118, 0.0983, 0.6885, 0.9609, 0.0655, 0.7789]])}
test_args = (tensor([[[0.2738, 0.8845],
         [0.5387, 0.3156],
         [0.2896, 0.6187],
         [0.2408, 0.2794],
         ...0.0758],
         [0.0291, 0.4504],
         [0.8186, 0.2387],
         [0.8948, 0.5985],
         [0.3755, 0.8434]]]))
test_kwargs = {'method': '8POINT', 'weights': tensor([[0.5764, 0.3995, 0.6571, 0.0665, 0.0013, 0.5063, 0.0108, 0.9317],
        [0.8...9, 0.3708, 0.7667, 0.8104, 0.0114, 0.6184],
        [0.8577, 0.3161, 0.3550, 0.4355, 0.0374, 0.9252, 0.2172, 0.8448]])}
target = 'numpy', backend_compile = False, tolerance = 0.03, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function find_fundamental at 0x7f9c602a4670>, fn_name = 'kornia.geometry.epipolar.find_fundamental'
trace_args = (tensor([[[0.9606, 0.1674],
         [0.9133, 0.1348],
         [0.1993, 0.9581],
         [0.4058, 0.9906],
         ...0.2779],
         [0.1307, 0.3443],
         [0.6073, 0.9665],
         [0.7303, 0.2311],
         [0.2225, 0.9522]]]))
trace_kwargs = {'method': '8POINT', 'weights': tensor([[0.7532, 0.0508, 0.8199, 0.8894, 0.2269, 0.3381, 0.7236, 0.0336],
        [0.2014, 0.4073, 0.0118, 0.0983, 0.6885, 0.9609, 0.0655, 0.7789]])}
test_args = (tensor([[[0.2738, 0.8845],
         [0.5387, 0.3156],
         [0.2896, 0.6187],
         [0.2408, 0.2794],
         ...0.0758],
         [0.0291, 0.4504],
         [0.8186, 0.2387],
         [0.8948, 0.5985],
         [0.3755, 0.8434]]]))
test_kwargs = {'method': '8POINT', 'weights': tensor([[0.5764, 0.3995, 0.6571, 0.0665, 0.0013, 0.5063, 0.0108, 0.9317],
        [0.8...9, 0.3708, 0.7667, 0.8104, 0.0114, 0.6184],
        [0.8577, 0.3161, 0.3550, 0.4355, 0.0374, 0.9252, 0.2172, 0.8448]])}
target = 'numpy', backend_compile = False, tolerance = 0.03, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

points1 = array([[[0.96061665, 0.16742808],
        [0.91332436, 0.13475114],
        [0.19927984, 0.9580513 ],
        [0.40583...
        [0.68992215, 0.5910343 ],
        [0.10908115, 0.41192347],
        [0.5522995 , 0.65552145]]], dtype=float32)
points2 = array([[[0.5614789 , 0.79796237],
        [0.4533584 , 0.27370983],
        [0.03659409, 0.6080616 ],
        [0.16292...
        [0.607264  , 0.9664508 ],
        [0.7302593 , 0.23106259],
        [0.22250086, 0.95224166]]], dtype=float32)
weights = array([[0.753228  , 0.05077136, 0.8198946 , 0.88939583, 0.22687066,
        0.33807302, 0.7236087 , 0.03359628],
     ....20139617, 0.40733677, 0.01181406, 0.09826541, 0.6884582 ,
        0.9609319 , 0.06547701, 0.77894366]], dtype=float32)
method = '8POINT'

    def numpy_find_fundamental(points1, points2, weights=None, method="8POINT"):
        if method.upper() == "7POINT":
            result = numpy_run_7point(points1, points2)
        elif method.upper() == "8POINT":
>           result = numpy_run_8point(points1, points2, weights)

ivy_transpiled_outputs/numpy_outputs/kornia/geometry/epipolar/fundamental.py:259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

points1 = array([[[0.96061665, 0.16742808],
        [0.91332436, 0.13475114],
        [0.19927984, 0.9580513 ],
        [0.40583...
        [0.68992215, 0.5910343 ],
        [0.10908115, 0.41192347],
        [0.5522995 , 0.65552145]]], dtype=float32)
points2 = array([[[0.5614789 , 0.79796237],
        [0.4533584 , 0.27370983],
        [0.03659409, 0.6080616 ],
        [0.16292...
        [0.607264  , 0.9664508 ],
        [0.7302593 , 0.23106259],
        [0.22250086, 0.95224166]]], dtype=float32)
weights = array([[0.753228  , 0.05077136, 0.8198946 , 0.88939583, 0.22687066,
        0.33807302, 0.7236087 , 0.03359628],
     ....20139617, 0.40733677, 0.01181406, 0.09826541, 0.6884582 ,
        0.9609319 , 0.06547701, 0.77894366]], dtype=float32)

    def numpy_run_8point(points1, points2, weights=None):
        from ....ivy.functional.frontends.torch.tensor import numpy_shape_frnt_
        from ....ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            numpy_chunk_frnt,
        )
        from ....ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            numpy_cat_frnt,
        )
        from ....ivy.functional.frontends.torch.tensor import numpy_transpose_frnt_
        from ....ivy.functional.frontends.torch.miscellaneous_ops import (
            numpy_diag_embed_frnt,
        )
        from ...utils.helpers import numpy__torch_svd_cast
        from ....ivy.functional.frontends.torch.tensor import numpy_view_frnt_
        from ....ivy.functional.frontends.torch.creation_ops import numpy_tensor_frnt
        from ...core._backend import ones_like
    
        if numpy_shape_frnt_(points1) != numpy_shape_frnt_(points2):
            raise AssertionError(numpy_shape_frnt_(points1), numpy_shape_frnt_(points2))
        if numpy_shape_frnt_(points1)[1] < 8:
            raise AssertionError(numpy_shape_frnt_(points1))
        if weights is not None:
            if not (
                len(numpy_shape_frnt_(weights)) == 2
                and numpy_shape_frnt_(weights)[1] == numpy_shape_frnt_(points1)[1]
            ):
                raise AssertionError(numpy_shape_frnt_(weights))
        points1_norm, transform1 = numpy_normalize_points(points1)
        points2_norm, transform2 = numpy_normalize_points(points2)
        x1, y1 = numpy_chunk_frnt(points1_norm, dim=-1, chunks=2)
        x2, y2 = numpy_chunk_frnt(points2_norm, dim=-1, chunks=2)
        ones = ones_like(x1)
        X = numpy_cat_frnt(
            [x2 * x1, x2 * y1, x2, y2 * x1, y2 * y1, y2, x1, y1, ones], dim=-1
        )
        if weights is None:
            X = numpy_transpose_frnt_(X, -2, -1) @ X
        else:
>           w_diag = numpy_diag_embed_frnt(weights)

ivy_transpiled_outputs/numpy_outputs/kornia/geometry/epipolar/fundamental.py:242: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = array([[[0.753228  , 0.05077136, 0.8198946 , 0.88939583, 0.22687066,
         0.33807302, 0.7236087 , 0.03359628]],

 ...0139617, 0.40733677, 0.01181406, 0.09826541, 0.6884582 ,
         0.9609319 , 0.06547701, 0.77894366]]], dtype=float32)
offset = 0, dim1 = 1, dim2 = 2

    def numpy_diag_embed_frnt(input, offset=0, dim1=-2, dim2=-1):
        from ...backends.numpy.data_type import numpy_dtype
        from .tensor import numpy_ndim_frnt_
        from .tensor import numpy_shape_frnt_
        from ...backends.numpy.general import numpy_set_item
        from ...backends.numpy.creation import numpy_zeros
        from ...backends.numpy.manipulation import numpy_concat
        from ....data_classes.array.experimental.manipulation import numpy_moveaxis_bknd_
        from ....data_classes.array.manipulation import numpy_expand_dims_bknd_
        from ...backends.numpy.creation import numpy_arange
        from .tensor import numpy_reshape_frnt_
        from .tensor import numpy_logical_and_frnt_
        from ...backends.numpy.searching import numpy_where
        from ....data_classes.array.data_type import numpy_astype_bknd_
    
        def _handle_dim(rank, idx):
            if idx >= 0 and idx < rank:
                return idx
            if idx < 0:
                idx = idx + rank
            if idx < 0 or idx >= rank:
                raise IndexError
            return idx
    
        input_type = numpy_dtype(input)
        rank = numpy_ndim_frnt_(input) + 1
        dim1 = _handle_dim(rank, dim1)
        dim2 = _handle_dim(rank, dim2)
        if dim1 > dim2:
            dim1, dim2 = dim2, dim1
            offset = -offset
        last_dim = list(numpy_shape_frnt_(input))[-1]
        if offset != 0:
            t_shape = list(numpy_shape_frnt_(input))
            t_shape = numpy_set_item(t_shape, -1, abs(offset))
            z = numpy_zeros(t_shape, dtype=input.dtype, device=None)
            pair = (z, input) if offset > 0 else (input, z)
            input = numpy_concat(pair, axis=-1)
            last_dim = last_dim + abs(offset)
        input = numpy_moveaxis_bknd_(numpy_expand_dims_bknd_(input, axis=dim1), -1, dim2)
        a_range = numpy_arange(last_dim, device=None, dtype=np.int64)
        b_range = numpy_arange(offset, last_dim + offset, device=None, dtype=np.int64)
        cond = a_range == numpy_expand_dims_bknd_(b_range, axis=-1)
        ag__result_list_0 = []
        for i in range(len(numpy_shape_frnt_(input))):
            res = last_dim if i in (dim1, dim2) else 1
            ag__result_list_0.append(res)
        cond_shape = ag__result_list_0
        cond = numpy_reshape_frnt_(cond, cond_shape)
>       if input.dtype == np.bool:

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/miscellaneous_ops.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

attr = 'bool'

    def __getattr__(attr):
        # Warn for expired attributes, and return a dummy function
        # that always raises an exception.
        import warnings
        import math
        try:
            msg = __expired_functions__[attr]
        except KeyError:
            pass
        else:
            warnings.warn(msg, DeprecationWarning, stacklevel=2)
    
            def _expired(*args, **kwds):
                raise RuntimeError(msg)
    
            return _expired
    
        # Emit warnings for deprecated attributes
        try:
            val, msg = __deprecated_attrs__[attr]
        except KeyError:
            pass
        else:
            warnings.warn(msg, DeprecationWarning, stacklevel=2)
            return val
    
        if attr in __future_scalars__:
            # And future warnings for those that will change, but also give
            # the AttributeError
            warnings.warn(
                f"In the future `np.{attr}` will be defined as the "
                "corresponding NumPy scalar.", FutureWarning, stacklevel=2)
    
        if attr in __former_attrs__:
>           raise AttributeError(__former_attrs__[attr])
E           AttributeError: module 'numpy' has no attribute 'bool'.
E           `np.bool` was a deprecated alias for the builtin `bool`. To avoid this error in existing code, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
E           The aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:
E               https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations. Did you mean: 'bool_'?

/opt/fw/mxnet/numpy/__init__.py:324: AttributeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.epipolar.fundamental.find_fundamental
----------------------------------------------------------------------------------------- Captured stderr call -----------------------------------------------------------------------------------------
/ivy/ivy-integration-tests/ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/miscellaneous_ops.py:79: FutureWarning: In the future `np.bool` will be defined as the corresponding NumPy scalar.
  cond = numpy_reshape_frnt_(cond, cond_shape)
___________________________________________________________________________ test_sampson_epipolar_distance[numpy-s2s-False] ____________________________________________________________________________

target_framework = 'numpy', mode = 's2s', backend_compile = False

    def test_sampson_epipolar_distance(target_framework, mode, backend_compile):
        trace_args = (
            torch.rand(1, 4, 2),
            torch.rand(1, 4, 2),
            torch.rand(1, 3, 3),
        )
        trace_kwargs = {'squared': True, 'eps': 1e-8}
        test_args = (
            torch.rand(5, 4, 2),
            torch.rand(5, 4, 2),
            torch.rand(5, 3, 3),
        )
        test_kwargs = {'squared': True, 'eps': 1e-8}
>       _test_function(
            kornia.geometry.epipolar.sampson_epipolar_distance,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/geometry/test_epipolar.py:400: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function sampson_epipolar_distance at 0x7f9c6028a440>
trace_args = (tensor([[[0.7599, 0.9021],
         [0.5093, 0.2167],
         [0.3247, 0.9808],
         [0.4154, 0.6145]]]), tensor...0.9332]]]), tensor([[[0.0476, 0.9456, 0.8710],
         [0.1428, 0.3301, 0.8222],
         [0.4999, 0.8863, 0.1116]]]))
trace_kwargs = {'eps': 1e-08, 'squared': True}
test_args = (tensor([[[0.4473, 0.1917],
         [0.4495, 0.3945],
         [0.0615, 0.3508],
         [0.3182, 0.2148]],

       ... 0.5438]],

        [[0.9846, 0.0693, 0.4022],
         [0.2185, 0.7031, 0.3732],
         [0.3886, 0.4540, 0.2704]]]))
test_kwargs = {'eps': 1e-08, 'squared': True}, target = 'numpy', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function sampson_epipolar_distance at 0x7f9c6028a440>, fn_name = 'kornia.geometry.epipolar.sampson_epipolar_distance'
trace_args = (tensor([[[0.7599, 0.9021],
         [0.5093, 0.2167],
         [0.3247, 0.9808],
         [0.4154, 0.6145]]]), tensor...0.9332]]]), tensor([[[0.0476, 0.9456, 0.8710],
         [0.1428, 0.3301, 0.8222],
         [0.4999, 0.8863, 0.1116]]]))
trace_kwargs = {'eps': 1e-08, 'squared': True}
test_args = (tensor([[[0.4473, 0.1917],
         [0.4495, 0.3945],
         [0.0615, 0.3508],
         [0.3182, 0.2148]],

       ... 0.5438]],

        [[0.9846, 0.0693, 0.4022],
         [0.2185, 0.7031, 0.3732],
         [0.3886, 0.4540, 0.2704]]]))
test_kwargs = {'eps': 1e-08, 'squared': True}, target = 'numpy', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pts1 = array([[[0.7598643 , 0.9021491 , 1.        ],
        [0.50928026, 0.21666288, 1.        ],
        [0.3247248 , 0.9808353 , 1.        ],
        [0.4153809 , 0.61453694, 1.        ]]], dtype=float32)
pts2 = array([[[0.8887943 , 0.76819575, 1.        ],
        [0.68401104, 0.29109538, 1.        ],
        [0.24665403, 0.6740677 , 1.        ],
        [0.08028096, 0.93319565, 1.        ]]], dtype=float32)
Fm = array([[[0.0476054 , 0.9455839 , 0.87103176],
        [0.14275962, 0.3300749 , 0.8221816 ],
        [0.49991906, 0.8862618 , 0.11159259]]], dtype=float32), squared = True, eps = 1e-08

    def numpy_sampson_epipolar_distance(pts1, pts2, Fm, squared=True, eps=1e-08):
        from ....ivy.functional.frontends.torch.tensor import numpy_shape_frnt_
        from ..conversions import numpy_convert_points_to_homogeneous
        from ....ivy.functional.frontends.torch.tensor import numpy_transpose_frnt_
        from ....ivy.functional.frontends.torch.tensor import numpy_pow_frnt_
        from ....ivy.functional.frontends.torch.tensor import numpy_sum_frnt_
        from ....ivy.functional.frontends.torch.tensor import numpy_norm_frnt_
        from ....ivy.functional.frontends.torch.tensor import numpy_sqrt_frnt_
    
        if not isinstance(Fm, (numpy.ndarray, numpy.ndarray)):
            raise TypeError(f"Fm type is not a torch.Tensor. Got {type(Fm)}")
        if len(numpy_shape_frnt_(Fm)) < 3 or not numpy_shape_frnt_(Fm)[-2:] == (3, 3):
            raise ValueError(f"Fm must be a (*, 3, 3) tensor. Got {numpy_shape_frnt_(Fm)}")
        if numpy_shape_frnt_(pts1)[-1] == 2:
            pts1 = numpy_convert_points_to_homogeneous(pts1)
        if numpy_shape_frnt_(pts2)[-1] == 2:
            pts2 = numpy_convert_points_to_homogeneous(pts2)
        F_t: typing.Any = numpy_transpose_frnt_(Fm, dim0=-2, dim1=-1)
        line1_in_2: typing.Any = pts1 @ F_t
        line2_in_1: typing.Any = pts2 @ Fm
>       numerator: typing.Any = numpy_pow_frnt_(
            numpy_sum_frnt_(pts2 * line1_in_2, dim=-1), 2
        )

ivy_transpiled_outputs/numpy_outputs/kornia/geometry/epipolar/_metrics.py:51: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (array([[3.7991946, 1.5920407, 2.3943074, 1.9939426]], dtype=float32), 2), kwargs = {}, numpy_is_array_bknd = <function numpy_is_array_bknd at 0x7f9c06b94790>
array_like = array([[3.7991946, 1.5920407, 2.3943074, 1.9939426]], dtype=float32)

    @functools.wraps(fn)
    def wrapper(*args, **kwargs):
        from ..functional.ivy.general import numpy_is_array_bknd
    
        array_like = args[0]
        if hasattr(array_like, "__class__") and array_like.__class__.__name__ in [
            "list",
            "tuple",
        ]:
            array_like = array_like[0]
        if numpy_is_array_bknd(array_like):
>           return fn(*args, **kwargs)

ivy_transpiled_outputs/numpy_outputs/ivy/utils/decorator_utils.py:200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = array([[3.7991946, 1.5920407, 2.3943074, 1.9939426]], dtype=float32), exponent = 2

    @numpy_handle_methods
    def numpy_pow_frnt_(tensor, exponent):
        from .pointwise_ops import numpy_pow_frnt
    
>       return numpy_pow_frnt(tensor, exponent)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/tensor.py:140: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (array([[3.7991946, 1.5920407, 2.3943074, 1.9939426]], dtype=float32), 2), kwargs = {}, numpy_is_array_bknd = <function numpy_is_array_bknd at 0x7f9c06b94790>
array_like = array([[3.7991946, 1.5920407, 2.3943074, 1.9939426]], dtype=float32)

    @functools.wraps(fn)
    def wrapper(*args, **kwargs):
        from ..functional.ivy.general import numpy_is_array_bknd
    
        array_like = args[0]
        if hasattr(array_like, "__class__") and array_like.__class__.__name__ in [
            "list",
            "tuple",
        ]:
            array_like = array_like[0]
        if numpy_is_array_bknd(array_like):
>           return fn(*args, **kwargs)

ivy_transpiled_outputs/numpy_outputs/ivy/utils/decorator_utils.py:200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = array([[3.7991946, 1.5920407, 2.3943074, 1.9939426]], dtype=float32), exponent = array(2)

    @numpy_handle_methods
    def numpy_pow_frnt(input, exponent, *, out=None):
        from ...ivy.general import numpy_is_array_bknd
        from .creation_ops import numpy_as_tensor_frnt
        from ...backends.numpy.creation import numpy_asarray
        from .__init__ import numpy_promote_types_of_torch_inputs_frnt
        from ...ivy.data_type import numpy_is_int_dtype_bknd
        from ...backends.numpy.elementwise import numpy_pow
        from ...backends.numpy.utility import numpy_any
        from ...backends.numpy.searching import numpy_where
        from ...backends.numpy.elementwise import numpy_bitwise_and
        from ....data_classes.array.data_type import numpy_astype_bknd_
    
        if not numpy_is_array_bknd(input):
            input = numpy_as_tensor_frnt(input)
        if not numpy_is_array_bknd(exponent):
            if (
                any(dtype in str(input.dtype) for dtype in ["int8", "int16"])
                and isinstance(exponent, (int,))
                or "float16" in str(input.dtype)
                and isinstance(exponent, (float,))
            ):
                exponent = numpy_asarray(exponent, dtype=input.dtype)
            else:
                exponent = numpy_as_tensor_frnt(exponent)
>       input, exponent = numpy_promote_types_of_torch_inputs_frnt(input, exponent)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/pointwise_ops.py:91: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x1 = array([[3.7991946, 1.5920407, 2.3943074, 1.9939426]], dtype=float32), x2 = array(2)

    def numpy_promote_types_of_torch_inputs_frnt(x1, x2, /):
        from ...ivy.general import numpy_isscalar_bknd
        from ...ivy.data_type import numpy_is_int_dtype_bknd
        from ...backends.numpy.creation import numpy_asarray
        from ...ivy.data_type import numpy_default_dtype_bknd
        from .tensor import numpy_shape_frnt_
        from ...ivy.device import numpy_default_device_bknd
        from ....data_classes.array.data_type import numpy_astype_bknd_
    
        """Promote the dtype of the given native array inputs to a common dtype
        based on type promotion rules.
    
        While passing float or integer values or any other non-array input
        to this function, it should be noted that the return will be an
        array-like object. Therefore, outputs from this function should be
        used as inputs only for those functions that expect an array-like or
        tensor-like objects, otherwise it might give unexpected results.
        """
        if (
            numpy_isscalar_bknd(x1) or isinstance(x1, (list, tuple))
        ) and numpy_is_int_dtype_bknd(x1):
            x1 = numpy_asarray(x1, dtype="int64")
        elif numpy_isscalar_bknd(x1) or isinstance(x1, (list, tuple)):
            x1 = numpy_asarray(x1)
        if (
            numpy_isscalar_bknd(x2) or isinstance(x2, (list, tuple))
        ) and numpy_is_int_dtype_bknd(x2):
            x2 = numpy_asarray(x2, dtype="int64")
        elif numpy_isscalar_bknd(x2) or isinstance(x2, (list, tuple)):
            x2 = numpy_asarray(x2)
        type1 = numpy_default_dtype_bknd(item=x1).strip("u123456789")
        type2 = numpy_default_dtype_bknd(item=x2).strip("u123456789")
        if numpy_shape_frnt_(x1) != () and numpy_shape_frnt_(x2) == () and type1 == type2:
            x2 = numpy_asarray(
                x2,
                dtype=x1.dtype,
                device=numpy_default_device_bknd(item=x1, as_native=False),
            )
        elif numpy_shape_frnt_(x1) == () and numpy_shape_frnt_(x2) != () and type1 == type2:
            x1 = numpy_asarray(
                x1,
                dtype=x2.dtype,
                device=numpy_default_device_bknd(item=x2, as_native=False),
            )
        elif x1.dtype != x2.dtype:
>           promoted = numpy_promote_types_torch_frnt(x1.dtype, x2.dtype)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/__init__.py:87: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

type1 = dtype('float32'), type2 = dtype('int64')

    def numpy_promote_types_torch_frnt(type1, type2, /):
        from ...backends.numpy.general import numpy_get_item
        from ...backends.numpy.data_type import numpy_as_ivy_dtype
    
        try:
            ret = numpy_get_item(
>               torch_promotion_table,
                (numpy_as_ivy_dtype(type1), numpy_as_ivy_dtype(type2)),
            )
E           NameError: name 'torch_promotion_table' is not defined

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/__init__.py:34: NameError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.epipolar._metrics.sampson_epipolar_distance
_________________________________________________________________________ test_symmetrical_epipolar_distance[numpy-s2s-False] __________________________________________________________________________

target_framework = 'numpy', mode = 's2s', backend_compile = False

    def test_symmetrical_epipolar_distance(target_framework, mode, backend_compile):
        trace_args = (
            torch.rand(1, 4, 2),
            torch.rand(1, 4, 2),
            torch.rand(1, 3, 3),
        )
        trace_kwargs = {'squared': True, 'eps': 1e-8}
        test_args = (
            torch.rand(5, 4, 2),
            torch.rand(5, 4, 2),
            torch.rand(5, 3, 3),
        )
        test_kwargs = {'squared': True, 'eps': 1e-8}
>       _test_function(
            kornia.geometry.epipolar.symmetrical_epipolar_distance,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/geometry/test_epipolar.py:426: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function symmetrical_epipolar_distance at 0x7f9c6028a560>
trace_args = (tensor([[[0.4602, 0.8294],
         [0.4006, 0.7464],
         [0.7262, 0.8351],
         [0.5744, 0.4631]]]), tensor...0.4243]]]), tensor([[[0.7976, 0.7074, 0.8173],
         [0.7254, 0.6897, 0.5912],
         [0.9753, 0.1307, 0.9461]]]))
trace_kwargs = {'eps': 1e-08, 'squared': True}
test_args = (tensor([[[0.1941, 0.8438],
         [0.0390, 0.0688],
         [0.4320, 0.8371],
         [0.9789, 0.4753]],

       ... 0.0187]],

        [[0.9832, 0.2335, 0.4657],
         [0.8489, 0.9645, 0.3640],
         [0.7356, 0.1719, 0.8736]]]))
test_kwargs = {'eps': 1e-08, 'squared': True}, target = 'numpy', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function symmetrical_epipolar_distance at 0x7f9c6028a560>, fn_name = 'kornia.geometry.epipolar.symmetrical_epipolar_distance'
trace_args = (tensor([[[0.4602, 0.8294],
         [0.4006, 0.7464],
         [0.7262, 0.8351],
         [0.5744, 0.4631]]]), tensor...0.4243]]]), tensor([[[0.7976, 0.7074, 0.8173],
         [0.7254, 0.6897, 0.5912],
         [0.9753, 0.1307, 0.9461]]]))
trace_kwargs = {'eps': 1e-08, 'squared': True}
test_args = (tensor([[[0.1941, 0.8438],
         [0.0390, 0.0688],
         [0.4320, 0.8371],
         [0.9789, 0.4753]],

       ... 0.0187]],

        [[0.9832, 0.2335, 0.4657],
         [0.8489, 0.9645, 0.3640],
         [0.7356, 0.1719, 0.8736]]]))
test_kwargs = {'eps': 1e-08, 'squared': True}, target = 'numpy', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pts1 = array([[[0.4602282 , 0.8293585 , 1.        ],
        [0.40064412, 0.74643224, 1.        ],
        [0.7261514 , 0.8350932 , 1.        ],
        [0.57436544, 0.46307993, 1.        ]]], dtype=float32)
pts2 = array([[[0.27666318, 0.34860426, 1.        ],
        [0.4159745 , 0.881541  , 1.        ],
        [0.45412385, 0.7903137 , 1.        ],
        [0.55564   , 0.42429668, 1.        ]]], dtype=float32)
Fm = array([[[0.7975887 , 0.70739615, 0.81734467],
        [0.72538894, 0.6896548 , 0.59118956],
        [0.97534436, 0.13066137, 0.94614047]]], dtype=float32), squared = True, eps = 1e-08

    def numpy_symmetrical_epipolar_distance(pts1, pts2, Fm, squared=True, eps=1e-08):
        from ....ivy.functional.frontends.torch.tensor import numpy_shape_frnt_
        from ..conversions import numpy_convert_points_to_homogeneous
        from ....ivy.functional.frontends.torch.tensor import numpy_transpose_frnt_
        from ....ivy.functional.frontends.torch.tensor import numpy_pow_frnt_
        from ....ivy.functional.frontends.torch.tensor import numpy_sum_frnt_
        from ....ivy.functional.frontends.torch.tensor import numpy_norm_frnt_
        from ....ivy.functional.frontends.torch.tensor import numpy_sqrt_frnt_
    
        if not isinstance(Fm, (numpy.ndarray, numpy.ndarray)):
            raise TypeError(f"Fm type is not a torch.Tensor. Got {type(Fm)}")
        if len(numpy_shape_frnt_(Fm)) < 3 or not numpy_shape_frnt_(Fm)[-2:] == (3, 3):
            raise ValueError(f"Fm must be a (*, 3, 3) tensor. Got {numpy_shape_frnt_(Fm)}")
        if numpy_shape_frnt_(pts1)[-1] == 2:
            pts1 = numpy_convert_points_to_homogeneous(pts1)
        if numpy_shape_frnt_(pts2)[-1] == 2:
            pts2 = numpy_convert_points_to_homogeneous(pts2)
        F_t: typing.Any = numpy_transpose_frnt_(Fm, dim0=-2, dim1=-1)
        line1_in_2: typing.Any = pts1 @ F_t
        line2_in_1: typing.Any = pts2 @ Fm
>       numerator: typing.Any = numpy_pow_frnt_(
            numpy_sum_frnt_(pts2 * line1_in_2, dim=-1), 2
        )

ivy_transpiled_outputs/numpy_outputs/kornia/geometry/epipolar/_metrics.py:51: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (array([[2.5152478, 3.3581533, 4.0046425, 3.0206842]], dtype=float32), 2), kwargs = {}, numpy_is_array_bknd = <function numpy_is_array_bknd at 0x7f9c06b24280>
array_like = array([[2.5152478, 3.3581533, 4.0046425, 3.0206842]], dtype=float32)

    @functools.wraps(fn)
    def wrapper(*args, **kwargs):
        from ..functional.ivy.general import numpy_is_array_bknd
    
        array_like = args[0]
        if hasattr(array_like, "__class__") and array_like.__class__.__name__ in [
            "list",
            "tuple",
        ]:
            array_like = array_like[0]
        if numpy_is_array_bknd(array_like):
>           return fn(*args, **kwargs)

ivy_transpiled_outputs/numpy_outputs/ivy/utils/decorator_utils.py:200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = array([[2.5152478, 3.3581533, 4.0046425, 3.0206842]], dtype=float32), exponent = 2

    @numpy_handle_methods
    def numpy_pow_frnt_(tensor, exponent):
        from .pointwise_ops import numpy_pow_frnt
    
>       return numpy_pow_frnt(tensor, exponent)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/tensor.py:140: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (array([[2.5152478, 3.3581533, 4.0046425, 3.0206842]], dtype=float32), 2), kwargs = {}, numpy_is_array_bknd = <function numpy_is_array_bknd at 0x7f9c06b24280>
array_like = array([[2.5152478, 3.3581533, 4.0046425, 3.0206842]], dtype=float32)

    @functools.wraps(fn)
    def wrapper(*args, **kwargs):
        from ..functional.ivy.general import numpy_is_array_bknd
    
        array_like = args[0]
        if hasattr(array_like, "__class__") and array_like.__class__.__name__ in [
            "list",
            "tuple",
        ]:
            array_like = array_like[0]
        if numpy_is_array_bknd(array_like):
>           return fn(*args, **kwargs)

ivy_transpiled_outputs/numpy_outputs/ivy/utils/decorator_utils.py:200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = array([[2.5152478, 3.3581533, 4.0046425, 3.0206842]], dtype=float32), exponent = array(2)

    @numpy_handle_methods
    def numpy_pow_frnt(input, exponent, *, out=None):
        from ...ivy.general import numpy_is_array_bknd
        from .creation_ops import numpy_as_tensor_frnt
        from ...backends.numpy.creation import numpy_asarray
        from .__init__ import numpy_promote_types_of_torch_inputs_frnt
        from ...ivy.data_type import numpy_is_int_dtype_bknd
        from ...backends.numpy.elementwise import numpy_pow
        from ...backends.numpy.utility import numpy_any
        from ...backends.numpy.searching import numpy_where
        from ...backends.numpy.elementwise import numpy_bitwise_and
        from ....data_classes.array.data_type import numpy_astype_bknd_
    
        if not numpy_is_array_bknd(input):
            input = numpy_as_tensor_frnt(input)
        if not numpy_is_array_bknd(exponent):
            if (
                any(dtype in str(input.dtype) for dtype in ["int8", "int16"])
                and isinstance(exponent, (int,))
                or "float16" in str(input.dtype)
                and isinstance(exponent, (float,))
            ):
                exponent = numpy_asarray(exponent, dtype=input.dtype)
            else:
                exponent = numpy_as_tensor_frnt(exponent)
>       input, exponent = numpy_promote_types_of_torch_inputs_frnt(input, exponent)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/pointwise_ops.py:91: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x1 = array([[2.5152478, 3.3581533, 4.0046425, 3.0206842]], dtype=float32), x2 = array(2)

    def numpy_promote_types_of_torch_inputs_frnt(x1, x2, /):
        from ...ivy.general import numpy_isscalar_bknd
        from ...ivy.data_type import numpy_is_int_dtype_bknd
        from ...backends.numpy.creation import numpy_asarray
        from ...ivy.data_type import numpy_default_dtype_bknd
        from .tensor import numpy_shape_frnt_
        from ...ivy.device import numpy_default_device_bknd
        from ....data_classes.array.data_type import numpy_astype_bknd_
    
        """Promote the dtype of the given native array inputs to a common dtype
        based on type promotion rules.
    
        While passing float or integer values or any other non-array input
        to this function, it should be noted that the return will be an
        array-like object. Therefore, outputs from this function should be
        used as inputs only for those functions that expect an array-like or
        tensor-like objects, otherwise it might give unexpected results.
        """
        if (
            numpy_isscalar_bknd(x1) or isinstance(x1, (list, tuple))
        ) and numpy_is_int_dtype_bknd(x1):
            x1 = numpy_asarray(x1, dtype="int64")
        elif numpy_isscalar_bknd(x1) or isinstance(x1, (list, tuple)):
            x1 = numpy_asarray(x1)
        if (
            numpy_isscalar_bknd(x2) or isinstance(x2, (list, tuple))
        ) and numpy_is_int_dtype_bknd(x2):
            x2 = numpy_asarray(x2, dtype="int64")
        elif numpy_isscalar_bknd(x2) or isinstance(x2, (list, tuple)):
            x2 = numpy_asarray(x2)
        type1 = numpy_default_dtype_bknd(item=x1).strip("u123456789")
        type2 = numpy_default_dtype_bknd(item=x2).strip("u123456789")
        if numpy_shape_frnt_(x1) != () and numpy_shape_frnt_(x2) == () and type1 == type2:
            x2 = numpy_asarray(
                x2,
                dtype=x1.dtype,
                device=numpy_default_device_bknd(item=x1, as_native=False),
            )
        elif numpy_shape_frnt_(x1) == () and numpy_shape_frnt_(x2) != () and type1 == type2:
            x1 = numpy_asarray(
                x1,
                dtype=x2.dtype,
                device=numpy_default_device_bknd(item=x2, as_native=False),
            )
        elif x1.dtype != x2.dtype:
>           promoted = numpy_promote_types_torch_frnt(x1.dtype, x2.dtype)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/__init__.py:87: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

type1 = dtype('float32'), type2 = dtype('int64')

    def numpy_promote_types_torch_frnt(type1, type2, /):
        from ...backends.numpy.general import numpy_get_item
        from ...backends.numpy.data_type import numpy_as_ivy_dtype
    
        try:
            ret = numpy_get_item(
>               torch_promotion_table,
                (numpy_as_ivy_dtype(type1), numpy_as_ivy_dtype(type2)),
            )
E           NameError: name 'torch_promotion_table' is not defined

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/__init__.py:34: NameError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.epipolar._metrics.symmetrical_epipolar_distance
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/geometry/test_epipolar.py::test_find_essential[numpy-s2s-False] - AttributeError: module 'numpy' has no attribute 'bool'.
FAILED kornia/geometry/test_epipolar.py::test_find_fundamental[numpy-s2s-False] - AttributeError: module 'numpy' has no attribute 'bool'.
FAILED kornia/geometry/test_epipolar.py::test_sampson_epipolar_distance[numpy-s2s-False] - NameError: name 'torch_promotion_table' is not defined
FAILED kornia/geometry/test_epipolar.py::test_symmetrical_epipolar_distance[numpy-s2s-False] - NameError: name 'torch_promotion_table' is not defined
============================================================================== 4 failed, 22 passed in 1703.44s (0:28:23) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 18 items

kornia/augmentation/test_augmentation1.py .......F..........                                                                                                                                     [100%]

=============================================================================================== FAILURES ===============================================================================================
________________________________________________________________________________ test_RandomClahe[tensorflow-s2s-False] ________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_RandomClahe(target_framework, mode, backend_compile):
        print("kornia.augmentation.RandomClahe")
    
        init_args = ()
        init_kwargs = {}
        call_args = (torch.rand(2, 3, 10, 20),)
        call_kwargs = {}
    
>       _test_augmentation_class(
            kornia.augmentation.RandomClahe,
            target_framework,
            init_args,
            init_kwargs,
            call_args,
            call_kwargs,
            deterministic_output=False,
            backend_compile=backend_compile,
        )

kornia/augmentation/test_augmentation1.py:215: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

augmentation_cls = <class 'kornia.augmentation._2d.intensity.clahe.RandomClahe'>, target = 'tensorflow', init_args = (), init_kwargs = {}
call_args = (tensor([[[[5.4852e-01, 2.5221e-02, 6.0264e-01,  ..., 6.0486e-01,
           6.5143e-01, 2.1166e-01],
          [4.933... 1.0529e-01],
          [5.2223e-01, 5.7030e-01, 8.0960e-01,  ..., 9.2843e-01,
           1.7037e-01, 9.5747e-02]]]]),)
call_kwargs = {}, deterministic_output = False, backend_compile = False, tolerance = 0.001

    def _test_augmentation_class(
        augmentation_cls,
        target,
        init_args=(),
        init_kwargs={},
        call_args=(),
        call_kwargs={},
        deterministic_output=True,
        backend_compile=False,
        tolerance=1e-3,
    ):
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_cls = ivy.transpile(augmentation_cls, source="torch", target=target)
    
        torch_aug = augmentation_cls(*init_args, **init_kwargs)
        transpiled_init_args = _nest_torch_tensor_to_new_framework(init_args, target)
        transpiled_init_kwargs = _nest_torch_tensor_to_new_framework(init_kwargs, target)
        transpiled_aug = transpiled_cls(*transpiled_init_args, **transpiled_init_kwargs)
    
        # assert dir(torch_aug) == dir(transpiled_aug), f"attributes/methods of transpiled object do not align with the original - orig: {dir(torch_aug)} != transpiled: {dir(transpiled_aug)}"
    
        torch_out = torch_aug(*call_args, **call_kwargs)
        transpiled_call_args = _nest_torch_tensor_to_new_framework(call_args, target)
        transpiled_call_kwargs = _nest_torch_tensor_to_new_framework(call_kwargs, target)
>       transpiled_out = transpiled_aug(*transpiled_call_args, **transpiled_call_kwargs)

kornia/augmentation/test_augmentation1.py:43: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomClahe(clip_limit_factor=(40.0, 40.0), p=0.5, p_batch=1.0, same_on_batch=False, grid_size=(8, 8), slow_and_differentiable=False)
args = (<tf.Tensor: shape=(2, 3, 10, 20), dtype=float32, numpy=
array([[[[5.48515677e-01, 2.52210498e-02, 6.02638125e-01, ......0300460e-01, 8.09603333e-01, ...,
          9.28432524e-01, 1.70369148e-01, 9.57465768e-02]]]],
      dtype=float32)>,)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x7f89e99d9e40, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...kexec', code_context=['        return self._inner_hookexec(hook_name, methods, kwargs, firstresult)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomClahe(clip_limit_factor=(40.0, 40.0), p=0.5, p_batch=1.0, same_on_batch=False, grid_size=(8, 8), slo...70300460e-01, 8.09603333e-01, ...,
          9.28432524e-01, 1.70369148e-01, 9.57465768e-02]]]],
      dtype=float32)>)
kwargs = {}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomClahe(clip_limit_factor=(40.0, 40.0), p=0.5, p_batch=1.0, same_on_batch=False, grid_size=(8, 8), slow_and_differentiable=False), v = None, buffers = None
args = (<tf.Tensor: shape=(2, 3, 10, 20), dtype=float32, numpy=
array([[[[5.48515677e-01, 2.52210498e-02, 6.02638125e-01, ......0300460e-01, 8.09603333e-01, ...,
          9.28432524e-01, 1.70369148e-01, 9.57465768e-02]]]],
      dtype=float32)>,)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomClahe(clip_limit_factor=(40.0, 40.0), p=0.5, p_batch=1.0, same_on_batch=False, grid_size=(8, 8), slo...70300460e-01, 8.09603333e-01, ...,
          9.28432524e-01, 1.70369148e-01, 9.57465768e-02]]]],
      dtype=float32)>)
kwargs = {'buffers': None, 'v': None}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomClahe(clip_limit_factor=(40.0, 40.0), p=0.5, p_batch=1.0, same_on_batch=False, grid_size=(8, 8), slow_and_differentiable=False), v = None, buffers = None
args = (<tf.Tensor: shape=(2, 3, 10, 20), dtype=float32, numpy=
array([[[[5.48515677e-01, 2.52210498e-02, 6.02638125e-01, ......0300460e-01, 8.09603333e-01, ...,
          9.28432524e-01, 1.70369148e-01, 9.57465768e-02]]]],
      dtype=float32)>,)
kwargs = {}
first_arr = <tf.Tensor: shape=(2, 3, 10, 20), dtype=float32, numpy=
array([[[[5.48515677e-01, 2.52210498e-02, 6.02638125e-01, ...,....70300460e-01, 8.09603333e-01, ...,
          9.28432524e-01, 1.70369148e-01, 9.57465768e-02]]]],
      dtype=float32)>
replace_v = False, replace_buffers = False, call_signature = <Signature (input, params=None, **kwargs)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Layer, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Layer, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Layer, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomClahe(clip_limit_factor=(40.0, 40.0), p=0.5, p_batch=1.0, same_on_batch=False, grid_size=(8, 8), slow_and_differentiable=False),)
kwargs = {'input': <tf.Tensor: shape=(2, 3, 10, 20), dtype=float32, numpy=
array([[[[5.48515677e-01, 2.52210498e-02, 6.02638125...70300460e-01, 8.09603333e-01, ...,
          9.28432524e-01, 1.70369148e-01, 9.57465768e-02]]]],
      dtype=float32)>}

    @wraps(fn)
    def error_handler(*args, **kwargs):
        if not is_traceback_filtering_enabled():
            return fn(*args, **kwargs)
    
        filtered_tb = None
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            filtered_tb = _process_traceback_frames(e.__traceback__)
            # To get the full stack trace, call:
            # `keras.config.disable_traceback_filtering()`
>           raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/keras/src/utils/traceback_utils.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomClahe(clip_limit_factor=(40.0, 40.0), p=0.5, p_batch=1.0, same_on_batch=False, grid_size=(8, 8), slow_and_differentiable=False)
input = <tf.Tensor: shape=(2, 3, 10, 20), dtype=float32, numpy=
array([[[[5.48515677e-01, 2.52210498e-02, 6.02638125e-01, ...,....70300460e-01, 8.09603333e-01, ...,
          9.28432524e-01, 1.70369148e-01, 9.57465768e-02]]]],
      dtype=float32)>
params = {'batch_prob': <tf.Tensor: shape=(2,), dtype=float32, numpy=array([0., 1.], dtype=float32)>, 'clip_limit_factor': <tf....ray([40.], dtype=float32)>, 'forward_input_shape': <tf.Tensor: shape=(4,), dtype=int64, numpy=array([ 2,  3, 10, 20])>}
kwargs = {}, tensorflow_shape_frnt_ = <function tensorflow_shape_frnt_ at 0x7f89ef796e60>, tensorflow_set_item = <function tensorflow_set_item at 0x7f89e87b8820>
tensor = <function tensorflow_tensor_frnt at 0x7f89ef855990>
in_tensor = <tf.Tensor: shape=(2, 3, 10, 20), dtype=float32, numpy=
array([[[[5.48515677e-01, 2.52210498e-02, 6.02638125e-01, ...,....70300460e-01, 8.09603333e-01, ...,
          9.28432524e-01, 1.70369148e-01, 9.57465768e-02]]]],
      dtype=float32)>
input_shape = ivy.frontends.torch.Size([2, 3, 10, 20]), batch_shape = ivy.frontends.torch.Size([2, 3, 10, 20]), flags = {'grid_size': (8, 8), 'slow_and_differentiable': False}

    def call(self, input, params=None, **kwargs):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ...ivy.functional.backends.tensorflow.general import tensorflow_set_item
        from ..core._backend import tensor
    
        in_tensor = self.__unpack_input__(input)
        input_shape = tensorflow_shape_frnt_(in_tensor)
        in_tensor = self.transform_tensor(in_tensor)
        batch_shape = tensorflow_shape_frnt_(in_tensor)
        if params is None:
            params = self.forward_parameters(batch_shape)
        if "batch_prob" not in params:
            params = tensorflow_set_item(
                params, "batch_prob", tensor([True] * batch_shape[0])
            )
        params, flags = self._process_kwargs_to_params_and_flags(
            params, self.flags, **kwargs
        )
>       output = self.apply_func(in_tensor, params, flags)

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/base.py:236: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomClahe(clip_limit_factor=(40.0, 40.0), p=0.5, p_batch=1.0, same_on_batch=False, grid_size=(8, 8), slow_and_differentiable=False)
in_tensor = <tf.Tensor: shape=(2, 3, 10, 20), dtype=float32, numpy=
array([[[[5.48515677e-01, 2.52210498e-02, 6.02638125e-01, ...,....70300460e-01, 8.09603333e-01, ...,
          9.28432524e-01, 1.70369148e-01, 9.57465768e-02]]]],
      dtype=float32)>
params = {'batch_prob': <tf.Tensor: shape=(2,), dtype=float32, numpy=array([0., 1.], dtype=float32)>, 'clip_limit_factor': <tf....ray([40.], dtype=float32)>, 'forward_input_shape': <tf.Tensor: shape=(4,), dtype=int64, numpy=array([ 2,  3, 10, 20])>}
flags = {'grid_size': (8, 8), 'slow_and_differentiable': False}

    def apply_func(self, in_tensor, params, flags=None):
        if flags is None:
            flags = self.flags
        trans_matrix = self.generate_transformation_matrix(in_tensor, params, flags)
>       output = self.transform_inputs(in_tensor, params, flags, trans_matrix)

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/_2d/base.py:127: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomClahe(clip_limit_factor=(40.0, 40.0), p=0.5, p_batch=1.0, same_on_batch=False, grid_size=(8, 8), slow_and_differentiable=False)
input = <tf.Tensor: shape=(2, 3, 10, 20), dtype=float32, numpy=
array([[[[5.48515677e-01, 2.52210498e-02, 6.02638125e-01, ...,....70300460e-01, 8.09603333e-01, ...,
          9.28432524e-01, 1.70369148e-01, 9.57465768e-02]]]],
      dtype=float32)>
params = {'batch_prob': <tf.Tensor: shape=(2,), dtype=float32, numpy=array([0., 1.], dtype=float32)>, 'clip_limit_factor': <tf....ray([40.], dtype=float32)>, 'forward_input_shape': <tf.Tensor: shape=(4,), dtype=int64, numpy=array([ 2,  3, 10, 20])>}
flags = {'grid_size': (8, 8), 'slow_and_differentiable': False}
transform = <tf.Tensor: shape=(2, 3, 3), dtype=float32, numpy=
array([[[1., 0., 0.],
        [0., 1., 0.],
        [0., 0., 1.]],

       [[1., 0., 0.],
        [0., 1., 0.],
        [0., 0., 1.]]], dtype=float32)>
kwargs = {}, tensorflow_shape_frnt_ = <function tensorflow_shape_frnt_ at 0x7f89ef796e60>, tensorflow_all_frnt_ = <function tensorflow_all_frnt_ at 0x7f89efc4fd00>
tensorflow_any_frnt_ = <function tensorflow_any_frnt_ at 0x7f89ef7a8820>, tensorflow_get_item = <function tensorflow_get_item at 0x7f89e87b8670>
tensorflow_is_autocast_enabled = <function tensorflow_is_autocast_enabled at 0x7f89e39536d0>, tensorflow_type_frnt_ = <function tensorflow_type_frnt_ at 0x7f89ef7a8700>
tensorflow_index_put_frnt_ = <function tensorflow_index_put_frnt_ at 0x7f89ef7a8310>

    def transform_inputs(self, input, params, flags, transform=None, **kwargs):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_all_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_any_frnt_
        from ...ivy.functional.backends.tensorflow.general import tensorflow_get_item
        from ..utils.helpers import tensorflow_is_autocast_enabled
        from ...ivy.functional.frontends.torch.tensor import tensorflow_type_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_index_put_frnt_
        from .utils.helpers import tensorflow__transform_output_shape
    
        params, flags = self._process_kwargs_to_params_and_flags(
            self._params if params is None else params, flags, **kwargs
        )
        batch_prob = params["batch_prob"]
        to_apply = batch_prob > 0.5
        ori_shape = tensorflow_shape_frnt_(input)
        in_tensor = self.transform_tensor(input)
        self.validate_tensor(in_tensor)
        if tensorflow_all_frnt_(to_apply):
            output = self.apply_transform(in_tensor, params, flags, transform=transform)
        elif not tensorflow_any_frnt_(to_apply):
            output = self.apply_non_transform(
                in_tensor, params, flags, transform=transform
            )
        else:
            output = self.apply_non_transform(
                in_tensor, params, flags, transform=transform
            )
>           applied = self.apply_transform(
                tensorflow_get_item(in_tensor, to_apply),
                params,
                flags,
                transform=transform
                if transform is None
                else tensorflow_get_item(transform, to_apply),
            )

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/base.py:363: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomClahe(clip_limit_factor=(40.0, 40.0), p=0.5, p_batch=1.0, same_on_batch=False, grid_size=(8, 8), slow_and_differentiable=False)
input = <tf.Tensor: shape=(1, 3, 10, 20), dtype=float32, numpy=
array([[[[2.43157864e-01, 1.95821822e-01, 1.94095969e-01,
    ...          7.89927125e-01, 3.72058272e-01, 9.28432524e-01,
          1.70369148e-01, 9.57465768e-02]]]], dtype=float32)>
params = {'batch_prob': <tf.Tensor: shape=(2,), dtype=float32, numpy=array([0., 1.], dtype=float32)>, 'clip_limit_factor': <tf....ray([40.], dtype=float32)>, 'forward_input_shape': <tf.Tensor: shape=(4,), dtype=int64, numpy=array([ 2,  3, 10, 20])>}
flags = {'grid_size': (8, 8), 'slow_and_differentiable': False}
transform = <tf.Tensor: shape=(1, 3, 3), dtype=float32, numpy=
array([[[1., 0., 0.],
        [0., 1., 0.],
        [0., 0., 1.]]], dtype=float32)>

    def apply_transform(self, input, params, flags, transform=None):
        from ....enhance.equalization import tensorflow_equalize_clahe
    
        clip_limit = float(params["clip_limit_factor"][0])
>       return tensorflow_equalize_clahe(
            input, clip_limit, flags["grid_size"], flags["slow_and_differentiable"]
        )

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/_2d/intensity/clahe.py:61: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = <tf.Tensor: shape=(1, 3, 10, 20), dtype=float32, numpy=
array([[[[2.43157864e-01, 1.95821822e-01, 1.94095969e-01,
    ...          7.89927125e-01, 3.72058272e-01, 9.28432524e-01,
          1.70369148e-01, 9.57465768e-02]]]], dtype=float32)>
args = (40.0, (8, 8), False), kwargs = {}, tensorflow_numel_frnt_ = <function tensorflow_numel_frnt_ at 0x7f89efc4c0d0>, tensorflow_shape_frnt_ = <function tensorflow_shape_frnt_ at 0x7f89ef796e60>
tensorflow_view_frnt_ = <function tensorflow_view_frnt_ at 0x7f89e88bb910>, input_shape = ivy.frontends.torch.Size([1, 3, 10, 20])

    @wraps(f)
    def _wrapper(input, *args, **kwargs):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_numel_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_view_frnt_
    
        if not isinstance(input, (tensorflow.Tensor, tensorflow.Variable)):
            raise TypeError(f"Input input type is not a Tensor. Got {type(input)}")
        if tensorflow_numel_frnt_(input) == 0:
            raise ValueError("Invalid input tensor, it is empty.")
        input_shape = tensorflow_shape_frnt_(input)
        input = tensorflow__to_bchw(input)
>       output = f(input, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/kornia/utils/image.py:73: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = <tf.Tensor: shape=(1, 3, 10, 20), dtype=float32, numpy=
array([[[[2.43157864e-01, 1.95821822e-01, 1.94095969e-01,
    ...          7.89927125e-01, 3.72058272e-01, 9.28432524e-01,
          1.70369148e-01, 9.57465768e-02]]]], dtype=float32)>
clip_limit = 40.0, grid_size = (8, 8), slow_and_differentiable = False

    @tensorflow_perform_keep_shape_image
    def tensorflow_equalize_clahe(
        input, clip_limit=40.0, grid_size=(8, 8), slow_and_differentiable=False
    ):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_reshape_as_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_permute_frnt_
        from ...ivy.functional.backends.tensorflow.general import tensorflow_get_item
        from ...ivy.functional.frontends.torch.tensor import tensorflow_dim_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_squeeze_frnt_
    
        if not isinstance(clip_limit, (float,)):
            raise TypeError(f"Input clip_limit type is not float. Got {type(clip_limit)}")
        if not isinstance(grid_size, (tuple,)):
            raise TypeError(f"Input grid_size type is not Tuple. Got {type(grid_size)}")
        if len(grid_size) != 2:
            raise TypeError(
                f"Input grid_size is not a Tuple with 2 elements. Got {len(grid_size)}"
            )
        if isinstance(grid_size[0], (float,)) or isinstance(grid_size[1], (float,)):
            raise TypeError("Input grid_size type is not valid, must be a Tuple[int, int].")
        if grid_size[0] <= 0 or grid_size[1] <= 0:
            raise ValueError(f"Input grid_size elements must be positive. Got {grid_size}")
        imgs: typing.Any = input
>       hist_tiles, img_padded = tensorflow__compute_tiles(imgs, grid_size, True)

ivy_transpiled_outputs/tensorflow_outputs/kornia/enhance/equalization.py:518: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

imgs = <tf.Tensor: shape=(1, 3, 10, 20), dtype=float32, numpy=
array([[[[2.43157864e-01, 1.95821822e-01, 1.94095969e-01,
    ...          7.89927125e-01, 3.72058272e-01, 9.28432524e-01,
          1.70369148e-01, 9.57465768e-02]]]], dtype=float32)>
grid_size = (8, 8), even_tile_size = True

    def tensorflow__compute_tiles(imgs, grid_size, even_tile_size=False):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ...ivy.functional.frontends.torch.nn.functional.vision_functions import (
            tensorflow_pad_frnt,
        )
        from ...ivy.functional.frontends.torch.tensor import tensorflow_contiguous_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_squeeze_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_unfold_frnt_
    
        batch: typing.Any = imgs
        h, w = tensorflow_shape_frnt_(batch)[-2:][0], tensorflow_shape_frnt_(batch)[-2:][1]
        kernel_vert: typing.Any = math.ceil(h / grid_size[0])
        kernel_horz: typing.Any = math.ceil(w / grid_size[1])
        if even_tile_size:
            kernel_vert = kernel_vert + (1 if kernel_vert % 2 else 0)
            kernel_horz = kernel_horz + (1 if kernel_horz % 2 else 0)
        pad_vert = kernel_vert * grid_size[0] - h
        pad_horz = kernel_horz * grid_size[1] - w
        if (
            pad_vert > tensorflow_shape_frnt_(batch)[-2]
            or pad_horz > tensorflow_shape_frnt_(batch)[-1]
        ):
            raise ValueError(
                "Cannot compute tiles on the image according to the given grid size"
            )
        if pad_vert > 0 or pad_horz > 0:
            batch = tensorflow_pad_frnt(batch, [0, pad_horz, 0, pad_vert], mode="reflect")
        c: typing.Any = tensorflow_shape_frnt_(batch)[-3]
        tiles: typing.Any = tensorflow_contiguous_frnt_(
            tensorflow_squeeze_frnt_(
>               tensorflow_unfold_frnt_(
                    tensorflow_unfold_frnt_(
                        tensorflow_unfold_frnt_(batch, 1, c, c), 2, kernel_vert, kernel_vert
                    ),
                    3,
                    kernel_horz,
                    kernel_horz,
                ),
                1,
            )
        )

ivy_transpiled_outputs/tensorflow_outputs/kornia/enhance/equalization.py:65: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (<tf.Tensor: shape=(1, 1, 1, 2, 16, 32), dtype=float32, numpy=
array([[[[[[0.24315786, 0.19582182, 0.19409597, ..., 0.....02158093, 0.43994337, 0.6119042 , ..., 0.3086232 ,
            0.5098639 , 0.6578222 ]]]]]], dtype=float32)>, 3, 4, 4)
kwargs = {}, tensorflow_is_array_bknd = <function tensorflow_is_array_bknd at 0x7f89ef76b910>
array_like = <tf.Tensor: shape=(1, 1, 1, 2, 16, 32), dtype=float32, numpy=
array([[[[[[0.24315786, 0.19582182, 0.19409597, ..., 0.1...        [0.02158093, 0.43994337, 0.6119042 , ..., 0.3086232 ,
            0.5098639 , 0.6578222 ]]]]]], dtype=float32)>

    @functools.wraps(fn)
    def wrapper(*args, **kwargs):
        from ..functional.ivy.general import tensorflow_is_array_bknd
    
        array_like = args[0]
        if hasattr(array_like, "__class__") and array_like.__class__.__name__ in [
            "list",
            "tuple",
        ]:
            array_like = array_like[0]
        if tensorflow_is_array_bknd(array_like):
>           return fn(*args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:202: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = <tf.Tensor: shape=(1, 1, 1, 2, 16, 32), dtype=float32, numpy=
array([[[[[[0.24315786, 0.19582182, 0.19409597, ..., 0.1...        [0.02158093, 0.43994337, 0.6119042 , ..., 0.3086232 ,
            0.5098639 , 0.6578222 ]]]]]], dtype=float32)>
dimension = 3, size = 4, step = 4

    @tensorflow_handle_methods
    def tensorflow_unfold_frnt_(tensor, dimension, size, step):
        from ...backends.tensorflow.general import tensorflow_get_item
        from ...backends.tensorflow.general import tensorflow_set_item
        from .indexing_slicing_joining_mutating_ops import tensorflow_stack_frnt
    
        slices = []
        self_shape = tuple(tensorflow_shape_frnt_(tensor))
        for i in range(0, tensorflow_get_item(self_shape, dimension) - size + 1, step):
            slicing = [slice(None)] * len(tensorflow_shape_frnt_(tensor))
            slicing = tensorflow_set_item(slicing, dimension, slice(i, i + size))
            slices.append(tensorflow_get_item(tensor, tuple(slicing)))
>       stacked = tensorflow_stack_frnt(slices, dim=dimension)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/tensor.py:660: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensors = [], dim = 3

    def tensorflow_stack_frnt(tensors, dim=0, *, out=None):
        from ...backends.tensorflow.manipulation import tensorflow_stack
    
>       return tensorflow_stack(tensors, axis=dim, out=out)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/indexing_slicing_joining_mutating_ops.py:147: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

arrays = []

    def tensorflow_stack(
        arrays: Union[Tuple[tensorflow.Tensor], List[tensorflow.Tensor]],
        /,
        *,
        axis: int = 0,
        out: Optional[Union[tensorflow.Tensor, tensorflow.Variable]] = None,
    ):
        try:
>           return tensorflow.experimental.numpy.stack(arrays, axis)
E           IndexError: Exception encountered when calling tensorflow_RandomClahe.call().
E           
E           [1mlist index out of range[0m
E           
E           Arguments received by tensorflow_RandomClahe.call():
E              input=tf.Tensor(shape=(2, 3, 10, 20), dtype=float32)
E              params=None
E              kwargs=<class 'inspect._empty'>

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/backends/tensorflow/manipulation.py:260: IndexError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.RandomClahe
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/augmentation/test_augmentation1.py::test_RandomClahe[tensorflow-s2s-False] - IndexError: Exception encountered when calling tensorflow_RandomClahe.call().
============================================================================== 1 failed, 17 passed in 3776.45s (1:02:56) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 1 item

kornia/geometry/test_ransac.py s                                                                                                                                                                 [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
========================================================================================== 1 skipped in 4.87s ==========================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 2 items

kornia/geometry/test_line.py ..                                                                                                                                                                  [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
===================================================================================== 2 passed in 77.11s (0:01:17) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 6 items

kornia/augmentation/test_container.py ssssss                                                                                                                                                     [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
========================================================================================== 6 skipped in 5.08s ==========================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 7 items

kornia/test_morphology.py .......                                                                                                                                                                [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
==================================================================================== 7 passed in 450.71s (0:07:30) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 3 items

kornia/augmentation/test_auto.py sss                                                                                                                                                             [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
========================================================================================== 3 skipped in 5.15s ==========================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 5 items

kornia/geometry/test_calibration.py ....F                                                                                                                                                        [100%]

=============================================================================================== FAILURES ===============================================================================================
_________________________________________________________________________________ test_solve_pnp_dlt[numpy-s2s-False] __________________________________________________________________________________

target_framework = 'numpy', mode = 's2s', backend_compile = False

    def test_solve_pnp_dlt(target_framework, mode, backend_compile):
        trace_args = (
            torch.tensor([[
                [5.0, -5.0, 0.0], [0.0, 0.0, 1.5],
                [2.5, 3.0, 6.0], [9.0, -2.0, 3.0],
                [-4.0, 5.0, 2.0], [-5.0, 5.0, 1.0]
            ]], dtype=torch.float64),
            torch.tensor([[
                [1409.1504, -800.936], [407.0207, -182.1229],
                [392.7021, 177.9428], [1016.838, -2.9416],
                [-63.1116, 142.9204], [-219.3874, 99.666]
            ]], dtype=torch.float64),
            torch.tensor([[
                [500.0, 0.0, 250.0],
                [0.0, 500.0, 250.0],
                [0.0, 0.0, 1.0]
            ]], dtype=torch.float64),
        )
        trace_kwargs = {'svd_eps': 1e-3}
        test_args = (
            torch.tensor([[
                [10.0, -10.0, 0.0], [0.0, 0.0, 3.0],
                [5.0, 6.0, 12.0], [18.0, -4.0, 6.0],
                [-8.0, 10.0, 4.0], [-10.0, 10.0, 2.0]
            ]], dtype=torch.float64),
            torch.tensor([[
                [2818.3008, -1601.872], [814.0414, -364.2458],
                [785.4042, 355.8856], [2033.676, -5.8832],
                [-126.2232, 285.8408], [-438.7748, 199.332]
            ]], dtype=torch.float64),
            torch.tensor([[
                [1000.0, 0.0, 500.0],
                [0.0, 1000.0, 500.0],
                [0.0, 0.0, 1.0]
            ]], dtype=torch.float64),
        )
        test_kwargs = {'svd_eps': 1e-3}
>       _test_function(
            kornia.geometry.calibration.solve_pnp_dlt,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/geometry/test_calibration.py:148: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function solve_pnp_dlt at 0x7f77b8af6950>
trace_args = (tensor([[[ 5.0000, -5.0000,  0.0000],
         [ 0.0000,  0.0000,  1.5000],
         [ 2.5000,  3.0000,  6.0000],
   ...loat64), tensor([[[500.,   0., 250.],
         [  0., 500., 250.],
         [  0.,   0.,   1.]]], dtype=torch.float64))
trace_kwargs = {'svd_eps': 0.001}
test_args = (tensor([[[ 10., -10.,   0.],
         [  0.,   0.,   3.],
         [  5.,   6.,  12.],
         [ 18.,  -4.,   6.],
 ...tensor([[[1000.,    0.,  500.],
         [   0., 1000.,  500.],
         [   0.,    0.,    1.]]], dtype=torch.float64))
test_kwargs = {'svd_eps': 0.001}, target = 'numpy', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function solve_pnp_dlt at 0x7f77b8af6950>, fn_name = 'kornia.geometry.calibration.solve_pnp_dlt'
trace_args = (tensor([[[ 5.0000, -5.0000,  0.0000],
         [ 0.0000,  0.0000,  1.5000],
         [ 2.5000,  3.0000,  6.0000],
   ...loat64), tensor([[[500.,   0., 250.],
         [  0., 500., 250.],
         [  0.,   0.,   1.]]], dtype=torch.float64))
trace_kwargs = {'svd_eps': 0.001}
test_args = (tensor([[[ 10., -10.,   0.],
         [  0.,   0.,   3.],
         [  5.,   6.,  12.],
         [ 18.,  -4.,   6.],
 ...tensor([[[1000.,    0.,  500.],
         [   0., 1000.,  500.],
         [   0.,    0.,    1.]]], dtype=torch.float64))
test_kwargs = {'svd_eps': 0.001}, target = 'numpy', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

world_points = array([[[ 5. , -5. ,  0. ],
        [ 0. ,  0. ,  1.5],
        [ 2.5,  3. ,  6. ],
        [ 9. , -2. ,  3. ],
        [-4. ,  5. ,  2. ],
        [-5. ,  5. ,  1. ]]])
img_points = array([[[1409.1504, -800.936 ],
        [ 407.0207, -182.1229],
        [ 392.7021,  177.9428],
        [1016.838 ,   -2.9416],
        [ -63.1116,  142.9204],
        [-219.3874,   99.666 ]]])
intrinsics = array([[[500.,   0., 250.],
        [  0., 500., 250.],
        [  0.,   0.,   1.]]]), weights = None, svd_eps = 0.001

    def numpy_solve_pnp_dlt(
        world_points, img_points, intrinsics, weights=None, svd_eps=0.0001
    ):
        from ....ivy.functional.frontends.torch.tensor import numpy_shape_frnt_
        from ...utils.helpers import numpy__torch_linalg_svdvals
        from ....ivy.functional.frontends.torch.reduction_ops import numpy_any_frnt
        from ....ivy.functional.frontends.torch.blas_and_lapack_ops import (
            numpy_inverse_frnt,
        )
        from ..conversions import numpy_convert_points_to_homogeneous
        from ..linalg import numpy_transform_points
        from ....ivy.functional.backends.numpy.general import numpy_set_item
        from ....ivy.functional.frontends.torch.blas_and_lapack_ops import (
            numpy_svd_frnt_base_count_1_frnt,
        )
        from ....ivy.functional.frontends.torch.tensor import numpy_reshape_frnt_
        from ...utils.misc import numpy_eye_like
        from ....ivy.functional.frontends.torch.blas_and_lapack_ops import numpy_bmm_frnt
        from ....ivy.functional.frontends.torch.blas_and_lapack_ops import numpy_det_frnt
        from ....ivy.functional.frontends.torch.reduction_ops import numpy_norm_frnt
        from ....ivy.functional.frontends.torch.linalg import numpy_qr_frnt
        from ....ivy.functional.frontends.torch.pointwise_ops import numpy_sign_frnt
        from ....ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            numpy_cat_frnt,
        )
        from ...core._backend import zeros
        from ...core._backend import ones_like
        from ...core._backend import where
    
        if not isinstance(world_points, (numpy.ndarray, numpy.ndarray)):
            raise AssertionError(
                f"world_points is not an instance of torch.Tensor. Type of world_points is {type(world_points)}"
            )
        if not isinstance(img_points, (numpy.ndarray, numpy.ndarray)):
            raise AssertionError(
                f"img_points is not an instance of torch.Tensor. Type of img_points is {type(img_points)}"
            )
        if not isinstance(intrinsics, (numpy.ndarray, numpy.ndarray)):
            raise AssertionError(
                f"intrinsics is not an instance of torch.Tensor. Type of intrinsics is {type(intrinsics)}"
            )
        if weights is not None and not isinstance(weights, (numpy.ndarray, numpy.ndarray)):
            raise AssertionError(
                f"If weights is not None, then weights should be an instance of torch.Tensor. Type of weights is {type(weights)}"
            )
        if not isinstance(svd_eps, (float,)):
            raise AssertionError(f"Type of svd_eps is not float. Got {type(svd_eps)}")
        accepted_dtypes = np.float32, np.float64
        if world_points.dtype not in accepted_dtypes:
            raise AssertionError(
                f"world_points must have one of the following dtypes {accepted_dtypes}. Currently it has {world_points.dtype}."
            )
        if img_points.dtype not in accepted_dtypes:
            raise AssertionError(
                f"img_points must have one of the following dtypes {accepted_dtypes}. Currently it has {img_points.dtype}."
            )
        if intrinsics.dtype not in accepted_dtypes:
            raise AssertionError(
                f"intrinsics must have one of the following dtypes {accepted_dtypes}. Currently it has {intrinsics.dtype}."
            )
        if (
            len(numpy_shape_frnt_(world_points)) != 3
            or numpy_shape_frnt_(world_points)[2] != 3
        ):
            raise AssertionError(
                f"world_points must be of shape (B, N, 3). Got shape {numpy_shape_frnt_(world_points)}."
            )
        if len(numpy_shape_frnt_(img_points)) != 3 or numpy_shape_frnt_(img_points)[2] != 2:
            raise AssertionError(
                f"img_points must be of shape (B, N, 2). Got shape {numpy_shape_frnt_(img_points)}."
            )
        if len(numpy_shape_frnt_(intrinsics)) != 3 or numpy_shape_frnt_(intrinsics)[1:] != (
            3,
            3,
        ):
            raise AssertionError(
                f"intrinsics must be of shape (B, 3, 3). Got shape {numpy_shape_frnt_(intrinsics)}."
            )
        if numpy_shape_frnt_(world_points)[1] != numpy_shape_frnt_(img_points)[1]:
            raise AssertionError(
                "world_points and img_points must have equal number of points."
            )
        if (
            numpy_shape_frnt_(world_points)[0] != numpy_shape_frnt_(img_points)[0]
            or numpy_shape_frnt_(world_points)[0] != numpy_shape_frnt_(intrinsics)[0]
        ):
            raise AssertionError(
                "world_points, img_points and intrinsics must have the same batch size."
            )
        if numpy_shape_frnt_(world_points)[1] < 6:
            raise AssertionError(
                f"At least 6 points are required to use this function. Got {numpy_shape_frnt_(world_points)[1]} points."
            )
        B, N = (
            numpy_shape_frnt_(world_points)[:2][0],
            numpy_shape_frnt_(world_points)[:2][1],
        )
        world_points_norm, world_transform_norm = numpy__mean_isotropic_scale_normalize(
            world_points
        )
        s = numpy__torch_linalg_svdvals(world_points_norm)
        if numpy_any_frnt(s[:, -1] < svd_eps):
            raise AssertionError(
                f"The last singular value of one/more of the elements of the batch is smaller than {svd_eps}. This function cannot be used if all world_points (of any element of the batch) lie on a line or if all world_points (of any element of the batch) lie on a plane."
            )
        intrinsics_inv = numpy_inverse_frnt(intrinsics)
        world_points_norm_h = numpy_convert_points_to_homogeneous(world_points_norm)
        img_points_inv = numpy_transform_points(intrinsics_inv, img_points)
        img_points_norm, img_transform_norm = numpy__mean_isotropic_scale_normalize(
            img_points_inv
        )
        inv_img_transform_norm = numpy_inverse_frnt(img_transform_norm)
        system = zeros((B, 2 * N, 12), dtype=world_points.dtype, device=None)
        system = numpy_set_item(
            system,
            (slice(None, None, None), slice(0, None, 2), slice(0, 4, None)),
            world_points_norm_h,
        )
        system = numpy_set_item(
            system,
            (slice(None, None, None), slice(1, None, 2), slice(4, 8, None)),
            world_points_norm_h,
        )
        system = numpy_set_item(
            system,
            (slice(None, None, None), slice(0, None, 2), slice(8, 12, None)),
            world_points_norm_h * -1 * img_points_norm[..., 0:1],
        )
        system = numpy_set_item(
            system,
            (slice(None, None, None), slice(1, None, 2), slice(8, 12, None)),
            world_points_norm_h * -1 * img_points_norm[..., 1:2],
        )
        _, _, v = numpy_svd_frnt_base_count_1_frnt(system)
        solution = v[..., -1]
        solution = numpy_reshape_frnt_(solution, B, 3, 4)
        solution_4x4 = numpy_eye_like(4, solution)
        solution_4x4 = numpy_set_item(
            solution_4x4,
            (slice(None, None, None), slice(None, 3, None), slice(None, None, None)),
            solution,
        )
        intermediate = numpy_bmm_frnt(solution_4x4, world_transform_norm)
        solution = numpy_bmm_frnt(inv_img_transform_norm, intermediate[:, :3, :])
        det = numpy_det_frnt(solution[:, :3, :3])
        ones = ones_like(det)
        sign_fix = where(det < 0, ones * -1, ones)
        solution = solution * sign_fix[:, None, None]
>       norm_col = numpy_norm_frnt(input=solution[:, :3, 0], p=2, dim=1)

ivy_transpiled_outputs/numpy_outputs/kornia/geometry/calibration/pnp.py:225: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (), kwargs = {'dim': 1, 'input': array([[0.0754885 , 0.02388223, 0.0574928 ]]), 'p': 2}, numpy_is_array_bknd = <function numpy_is_array_bknd at 0x7f775b61ce50>

    @functools.wraps(fn)
    def wrapper(*args, **kwargs):
        from ..functional.ivy.general import numpy_is_array_bknd
    
>       array_like = args[0]
E       IndexError: tuple index out of range

ivy_transpiled_outputs/numpy_outputs/ivy/utils/decorator_utils.py:193: IndexError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.calibration.pnp.solve_pnp_dlt
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/geometry/test_calibration.py::test_solve_pnp_dlt[numpy-s2s-False] - IndexError: tuple index out of range
=============================================================================== 1 failed, 4 passed in 301.90s (0:05:01) ================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 44 items

kornia/test_filters.py ............................................                                                                                                                              [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
=================================================================================== 44 passed in 3875.03s (1:04:35) ====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 26 items

kornia/geometry/test_epipolar.py ..........................                                                                                                                                      [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
=================================================================================== 26 passed in 1714.00s (0:28:34) ====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 26 items

kornia/geometry/test_epipolar.py ..........................                                                                                                                                      [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
=================================================================================== 26 passed in 1836.28s (0:30:36) ====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 39 items

kornia/test_enhance.py ..............F........................                                                                                                                                   [100%]

=============================================================================================== FAILURES ===============================================================================================
______________________________________________________________________________ test_equalize_clahe[tensorflow-s2s-False] _______________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_equalize_clahe(target_framework, mode, backend_compile):
        trace_args = (torch.rand(1, 10, 20),)
        trace_kwargs = {
            "clip_limit": 40.0,
            "grid_size": (8, 8),
            "slow_and_differentiable": False,
        }
        test_args = (torch.rand(2, 3, 10, 20),)
        test_kwargs = {
            "clip_limit": 20.0,
            "grid_size": (4, 4),
            "slow_and_differentiable": False,
        }
>       _test_function(
            kornia.enhance.equalize_clahe,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
            skip=True,
        )

kornia/test_enhance.py:363: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function equalize_clahe at 0x7f5bf6459480>
trace_args = (tensor([[[0.7411, 0.1622, 0.5920, 0.7587, 0.8705, 0.1903, 0.8657, 0.2380,
          0.7183, 0.5176, 0.9607, 0.0538, 0...         0.3191, 0.7722, 0.8274, 0.3985, 0.0956, 0.8614, 0.3874, 0.0670,
          0.7985, 0.7462, 0.6029, 0.5178]]]),)
trace_kwargs = {'clip_limit': 40.0, 'grid_size': (8, 8), 'slow_and_differentiable': False}
test_args = (tensor([[[[0.4999, 0.0508, 0.6470,  ..., 0.5489, 0.3702, 0.0132],
          [0.4449, 0.7969, 0.8927,  ..., 0.7752, 0...., 0.1395, 0.7916,  ..., 0.0237, 0.7382, 0.9178],
          [0.3930, 0.8233, 0.6115,  ..., 0.9526, 0.6686, 0.1838]]]]),)
test_kwargs = {'clip_limit': 20.0, 'grid_size': (4, 4), 'slow_and_differentiable': False}, target = 'tensorflow', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = True
deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function equalize_clahe at 0x7f5bf6459480>, fn_name = 'kornia.enhance.equalize_clahe'
trace_args = (tensor([[[0.7411, 0.1622, 0.5920, 0.7587, 0.8705, 0.1903, 0.8657, 0.2380,
          0.7183, 0.5176, 0.9607, 0.0538, 0...         0.3191, 0.7722, 0.8274, 0.3985, 0.0956, 0.8614, 0.3874, 0.0670,
          0.7985, 0.7462, 0.6029, 0.5178]]]),)
trace_kwargs = {'clip_limit': 40.0, 'grid_size': (8, 8), 'slow_and_differentiable': False}
test_args = (tensor([[[[0.4999, 0.0508, 0.6470,  ..., 0.5489, 0.3702, 0.0132],
          [0.4449, 0.7969, 0.8927,  ..., 0.7752, 0...., 0.1395, 0.7916,  ..., 0.0237, 0.7382, 0.9178],
          [0.3930, 0.8233, 0.6115,  ..., 0.9526, 0.6686, 0.1838]]]]),)
test_kwargs = {'clip_limit': 20.0, 'grid_size': (4, 4), 'slow_and_differentiable': False}, target = 'tensorflow', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
>           graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:326: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = <tf.Tensor: shape=(1, 1, 10, 20), dtype=float32, numpy=
array([[[[0.74106854, 0.16222286, 0.5920406 , 0.7587206 , 0.87...0.8613807 , 0.38741553,
          0.06701976, 0.7985138 , 0.74620074, 0.6029271 , 0.5177983 ]]]],
      dtype=float32)>
args = (), kwargs = {'clip_limit': 40.0, 'grid_size': (8, 8), 'slow_and_differentiable': False}, tensorflow_numel_frnt_ = <function tensorflow_numel_frnt_ at 0x7f5b80d8c9d0>
tensorflow_shape_frnt_ = <function tensorflow_shape_frnt_ at 0x7f5b80d8d5a0>, tensorflow_view_frnt_ = <function tensorflow_view_frnt_ at 0x7f5b80d8f760>
input_shape = ivy.frontends.torch.Size([1, 10, 20])

    @wraps(f)
    def _wrapper(input, *args, **kwargs):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_numel_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_view_frnt_
    
        if not isinstance(input, (tensorflow.Tensor, tensorflow.Variable)):
            raise TypeError(f"Input input type is not a Tensor. Got {type(input)}")
        if tensorflow_numel_frnt_(input) == 0:
            raise ValueError("Invalid input tensor, it is empty.")
        input_shape = tensorflow_shape_frnt_(input)
        input = tensorflow__to_bchw(input)
>       output = f(input, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/kornia/utils/image.py:73: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = <tf.Tensor: shape=(1, 1, 10, 20), dtype=float32, numpy=
array([[[[0.74106854, 0.16222286, 0.5920406 , 0.7587206 , 0.87...0.8613807 , 0.38741553,
          0.06701976, 0.7985138 , 0.74620074, 0.6029271 , 0.5177983 ]]]],
      dtype=float32)>
clip_limit = 40.0, grid_size = (8, 8), slow_and_differentiable = False

    @tensorflow_perform_keep_shape_image
    def tensorflow_equalize_clahe(
        input, clip_limit=40.0, grid_size=(8, 8), slow_and_differentiable=False
    ):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_reshape_as_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_permute_frnt_
        from ...ivy.functional.backends.tensorflow.general import tensorflow_get_item
        from ...ivy.functional.frontends.torch.tensor import tensorflow_dim_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_squeeze_frnt_
    
        if not isinstance(clip_limit, (float,)):
            raise TypeError(f"Input clip_limit type is not float. Got {type(clip_limit)}")
        if not isinstance(grid_size, (tuple,)):
            raise TypeError(f"Input grid_size type is not Tuple. Got {type(grid_size)}")
        if len(grid_size) != 2:
            raise TypeError(
                f"Input grid_size is not a Tuple with 2 elements. Got {len(grid_size)}"
            )
        if isinstance(grid_size[0], (float,)) or isinstance(grid_size[1], (float,)):
            raise TypeError("Input grid_size type is not valid, must be a Tuple[int, int].")
        if grid_size[0] <= 0 or grid_size[1] <= 0:
            raise ValueError(f"Input grid_size elements must be positive. Got {grid_size}")
        imgs: typing.Any = input
>       hist_tiles, img_padded = tensorflow__compute_tiles(imgs, grid_size, True)

ivy_transpiled_outputs/tensorflow_outputs/kornia/enhance/equalization.py:518: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

imgs = <tf.Tensor: shape=(1, 1, 10, 20), dtype=float32, numpy=
array([[[[0.74106854, 0.16222286, 0.5920406 , 0.7587206 , 0.87...0.8613807 , 0.38741553,
          0.06701976, 0.7985138 , 0.74620074, 0.6029271 , 0.5177983 ]]]],
      dtype=float32)>
grid_size = (8, 8), even_tile_size = True

    def tensorflow__compute_tiles(imgs, grid_size, even_tile_size=False):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ...ivy.functional.frontends.torch.nn.functional.vision_functions import (
            tensorflow_pad_frnt,
        )
        from ...ivy.functional.frontends.torch.tensor import tensorflow_contiguous_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_squeeze_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_unfold_frnt_
    
        batch: typing.Any = imgs
        h, w = tensorflow_shape_frnt_(batch)[-2:][0], tensorflow_shape_frnt_(batch)[-2:][1]
        kernel_vert: typing.Any = math.ceil(h / grid_size[0])
        kernel_horz: typing.Any = math.ceil(w / grid_size[1])
        if even_tile_size:
            kernel_vert = kernel_vert + (1 if kernel_vert % 2 else 0)
            kernel_horz = kernel_horz + (1 if kernel_horz % 2 else 0)
        pad_vert = kernel_vert * grid_size[0] - h
        pad_horz = kernel_horz * grid_size[1] - w
        if (
            pad_vert > tensorflow_shape_frnt_(batch)[-2]
            or pad_horz > tensorflow_shape_frnt_(batch)[-1]
        ):
            raise ValueError(
                "Cannot compute tiles on the image according to the given grid size"
            )
        if pad_vert > 0 or pad_horz > 0:
            batch = tensorflow_pad_frnt(batch, [0, pad_horz, 0, pad_vert], mode="reflect")
        c: typing.Any = tensorflow_shape_frnt_(batch)[-3]
        tiles: typing.Any = tensorflow_contiguous_frnt_(
            tensorflow_squeeze_frnt_(
                tensorflow_unfold_frnt_(
>                   tensorflow_unfold_frnt_(
                        tensorflow_unfold_frnt_(batch, 1, c, c), 2, kernel_vert, kernel_vert
                    ),
                    3,
                    kernel_horz,
                    kernel_horz,
                ),
                1,
            )
        )

ivy_transpiled_outputs/tensorflow_outputs/kornia/enhance/equalization.py:66: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (<tf.Tensor: shape=(1, 1, 1, 32, 16), dtype=float32, numpy=
array([[[[[0.74106854, 0.96652067, 0.873136  , 0.09470111,...      0.21158987, 0.4841057 , 0.11774218, 0.4095543 , 0.7653877 ,
           0.02313513]]]]], dtype=float32)>, 2, 2, 2)
kwargs = {}, tensorflow_is_array_bknd = <function tensorflow_is_array_bknd at 0x7f5b71e4d630>
array_like = <tf.Tensor: shape=(1, 1, 1, 32, 16), dtype=float32, numpy=
array([[[[[0.74106854, 0.96652067, 0.873136  , 0.09470111, ...19 ,
           0.21158987, 0.4841057 , 0.11774218, 0.4095543 , 0.7653877 ,
           0.02313513]]]]], dtype=float32)>

    @functools.wraps(fn)
    def wrapper(*args, **kwargs):
        from ..functional.ivy.general import tensorflow_is_array_bknd
    
        array_like = args[0]
        if hasattr(array_like, "__class__") and array_like.__class__.__name__ in [
            "list",
            "tuple",
        ]:
            array_like = array_like[0]
        if tensorflow_is_array_bknd(array_like):
>           return fn(*args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:202: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = <tf.Tensor: shape=(1, 1, 1, 32, 16), dtype=float32, numpy=
array([[[[[0.74106854, 0.96652067, 0.873136  , 0.09470111, ...19 ,
           0.21158987, 0.4841057 , 0.11774218, 0.4095543 , 0.7653877 ,
           0.02313513]]]]], dtype=float32)>
dimension = 2, size = 2, step = 2

    @tensorflow_handle_methods
    def tensorflow_unfold_frnt_(tensor, dimension, size, step):
        from ...backends.tensorflow.general import tensorflow_get_item
        from ...backends.tensorflow.general import tensorflow_set_item
        from .indexing_slicing_joining_mutating_ops import tensorflow_stack_frnt
    
        slices = []
        self_shape = tuple(tensorflow_shape_frnt_(tensor))
        for i in range(0, tensorflow_get_item(self_shape, dimension) - size + 1, step):
            slicing = [slice(None)] * len(tensorflow_shape_frnt_(tensor))
            slicing = tensorflow_set_item(slicing, dimension, slice(i, i + size))
            slices.append(tensorflow_get_item(tensor, tuple(slicing)))
>       stacked = tensorflow_stack_frnt(slices, dim=dimension)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/tensor.py:263: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensors = [], dim = 2

    def tensorflow_stack_frnt(tensors, dim=0, *, out=None):
        from ...backends.tensorflow.manipulation import tensorflow_stack
    
>       return tensorflow_stack(tensors, axis=dim, out=out)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/indexing_slicing_joining_mutating_ops.py:130: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

arrays = []

    def tensorflow_stack(
        arrays: Union[Tuple[tensorflow.Tensor], List[tensorflow.Tensor]],
        /,
        *,
        axis: int = 0,
        out: Optional[Union[tensorflow.Tensor, tensorflow.Variable]] = None,
    ):
        try:
>           return tensorflow.experimental.numpy.stack(arrays, axis)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/backends/tensorflow/manipulation.py:224: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

arrays = [], axis = 2

    @tf_export.tf_export('experimental.numpy.stack', v1=[])
    @np_utils.np_doc('stack')
    def stack(arrays, axis=0):  # pylint: disable=missing-function-docstring
      if isinstance(arrays, (np_arrays.ndarray, tensor_lib.Tensor)):
        arrays = asarray(arrays)
        if axis == 0:
          return arrays
        else:
          return swapaxes(arrays, 0, axis)
      arrays = _promote_dtype(*arrays)  # pylint: disable=protected-access
      unwrapped_arrays = [
          a if isinstance(a, np_arrays.ndarray) else a for a in arrays
      ]
>     return asarray(array_ops_stack.stack(unwrapped_arrays, axis))

/opt/fw/tensorflow/tensorflow/python/ops/numpy_ops/np_array_ops.py:1211: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = ([], 2), kwargs = {}

    def error_handler(*args, **kwargs):
      try:
        if not is_traceback_filtering_enabled():
          return fn(*args, **kwargs)
      except NameError:
        # In some very rare cases,
        # `is_traceback_filtering_enabled` (from the outer scope) may not be
        # accessible from inside this function
        return fn(*args, **kwargs)
    
      filtered_tb = None
      try:
        return fn(*args, **kwargs)
      except Exception as e:
        filtered_tb = _process_traceback_frames(e.__traceback__)
>       raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/tensorflow/python/util/traceback_utils.py:153: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

values = [], axis = 2, name = 'stack'

    @tf_export("stack")
    @dispatch.add_dispatch_support
    def stack(values, axis=0, name="stack"):
      """Stacks a list of rank-`R` tensors into one rank-`(R+1)` tensor.
    
      See also `tf.concat`, `tf.tile`, `tf.repeat`.
    
      Packs the list of tensors in `values` into a tensor with rank one higher than
      each tensor in `values`, by packing them along the `axis` dimension.
      Given a list of length `N` of tensors of shape `(A, B, C)`;
    
      if `axis == 0` then the `output` tensor will have the shape `(N, A, B, C)`.
      if `axis == 1` then the `output` tensor will have the shape `(A, N, B, C)`.
      Etc.
    
      For example:
    
      >>> x = tf.constant([1, 4])
      >>> y = tf.constant([2, 5])
      >>> z = tf.constant([3, 6])
      >>> tf.stack([x, y, z])
      <tf.Tensor: shape=(3, 2), dtype=int32, numpy=
      array([[1, 4],
             [2, 5],
             [3, 6]], dtype=int32)>
      >>> tf.stack([x, y, z], axis=1)
      <tf.Tensor: shape=(2, 3), dtype=int32, numpy=
      array([[1, 2, 3],
             [4, 5, 6]], dtype=int32)>
    
      This is the opposite of unstack.  The numpy equivalent is `np.stack`
    
      >>> np.array_equal(np.stack([x, y, z]), tf.stack([x, y, z]))
      True
    
      Args:
        values: A list of `Tensor` objects with the same shape and type.
        axis: An `int`. The axis to stack along. Defaults to the first dimension.
          Negative values wrap around, so the valid range is `[-(R+1), R+1)`.
        name: A name for this operation (optional).
    
      Returns:
        output: A stacked `Tensor` with the same type as `values`.
    
      Raises:
        ValueError: If `axis` is out of the range [-(R+1), R+1).
      """
      if axis == 0:
        try:
          # If the input is a constant list, it can be converted to a constant op
          return ops.convert_to_tensor(values, name=name)
        except (TypeError, ValueError, NotImplementedError):
          pass  # Input list contains non-constant tensors
    
>     value_shape = ops.convert_to_tensor(values[0], name=name)._shape_tuple()  # pylint: disable=protected-access
E     IndexError: list index out of range

/opt/fw/tensorflow/tensorflow/python/ops/array_ops_stack.py:78: IndexError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.enhance.equalization.equalize_clahe
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/test_enhance.py::test_equalize_clahe[tensorflow-s2s-False] - IndexError: list index out of range
============================================================================== 1 failed, 38 passed in 2674.80s (0:44:34) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 69 items

kornia/test_color.py ...........F...........F.........sssssssssssssssssssssssssssssssss.ss                                                                                                       [100%]

=============================================================================================== FAILURES ===============================================================================================
___________________________________________________________________________________ test_rgb_to_hls[numpy-s2s-False] ___________________________________________________________________________________

target_framework = 'numpy', mode = 's2s', backend_compile = False

    def test_rgb_to_hls(target_framework, mode, backend_compile):
        # Note: We test this function with requires_grad=True,
        # because otherwise we simply get an empty_like tensor
        # with garbage values on each run leading to test failures
        trace_args = (
            torch.rand(1, 3, 4, 5).requires_grad_(True),
        )
        trace_kwargs = {'eps': 1e-8}
        test_args = (
            torch.rand(5, 3, 4, 5).requires_grad_(True),
        )
        test_kwargs = {'eps': 1e-8}
>       _test_function(
            kornia.color.rgb_to_hls,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/test_color.py:291: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function rgb_to_hls at 0x7f851dec5ea0>
trace_args = (tensor([[[[0.8116, 0.8173, 0.9703, 0.2563, 0.2832],
          [0.1068, 0.3046, 0.6955, 0.6922, 0.8964],
          [0.... [0.5380, 0.7159, 0.1852, 0.5405, 0.3039],
          [0.5016, 0.6075, 0.7028, 0.0627, 0.4034]]]], requires_grad=True),)
trace_kwargs = {'eps': 1e-08}
test_args = (tensor([[[[0.1146, 0.0907, 0.1562, 0.9313, 0.7727],
          [0.8085, 0.9847, 0.8695, 0.1744, 0.0897],
          [0.... [0.2106, 0.3489, 0.5549, 0.1759, 0.2367],
          [0.1831, 0.3403, 0.5244, 0.6219, 0.8040]]]], requires_grad=True),)
test_kwargs = {'eps': 1e-08}, target = 'numpy', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function rgb_to_hls at 0x7f851dec5ea0>, fn_name = 'kornia.color.rgb_to_hls'
trace_args = (tensor([[[[0.8116, 0.8173, 0.9703, 0.2563, 0.2832],
          [0.1068, 0.3046, 0.6955, 0.6922, 0.8964],
          [0.... [0.5380, 0.7159, 0.1852, 0.5405, 0.3039],
          [0.5016, 0.6075, 0.7028, 0.0627, 0.4034]]]], requires_grad=True),)
trace_kwargs = {'eps': 1e-08}
test_args = (tensor([[[[0.1146, 0.0907, 0.1562, 0.9313, 0.7727],
          [0.8085, 0.9847, 0.8695, 0.1744, 0.0897],
          [0.... [0.2106, 0.3489, 0.5549, 0.1759, 0.2367],
          [0.1831, 0.3403, 0.5244, 0.6219, 0.8040]]]], requires_grad=True),)
test_kwargs = {'eps': 1e-08}, target = 'numpy', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

image = array([[[[0.8116322 , 0.8172737 , 0.970254  , 0.25630933, 0.28322375],
         [0.10684615, 0.3046491 , 0.69551545, 0...0.5405011 , 0.30393708],
         [0.5015963 , 0.60746425, 0.7027781 , 0.06268072, 0.4034493 ]]]],
      dtype=float32)
eps = 1e-08

    def numpy_rgb_to_hls(image, eps=1e-08):
        from ..core._backend import tensor
        from ...ivy.functional.frontends.torch.pointwise_ops import sub
        from ..core._backend import where
        from ..core._backend import stack
        from ...ivy.functional.frontends.torch.tensor import numpy_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_max_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_min_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_requires_grad_frnt_
        from ...ivy.functional.frontends.torch.creation_ops import numpy_empty_like_frnt
        from ...ivy.functional.frontends.torch.pointwise_ops import numpy_add_frnt
        from ...ivy.functional.frontends.torch.tensor import numpy_unsqueeze_frnt_
        from ...ivy.functional.frontends.torch.pointwise_ops import numpy_mul_frnt
    
        if not isinstance(image, (numpy.ndarray, numpy.ndarray)):
            raise TypeError(f"Input type is not a Tensor. Got {type(image)}")
        if len(numpy_shape_frnt_(image)) < 3 or numpy_shape_frnt_(image)[-3] != 3:
            raise ValueError(
                f"Input size must have a shape of (*, 3, H, W). Got {numpy_shape_frnt_(image)}"
            )
        _RGB2HSL_IDX = tensor([[[0.0]], [[1.0]], [[2.0]]], device=None, dtype=image.dtype)
        _img_max: typing.Any = numpy_max_frnt_(image, -3)
        maxc = _img_max[0]
        imax = _img_max[1]
        minc: typing.Any = numpy_min_frnt_(image, -3)[0]
        if numpy_requires_grad_frnt_(image):
            l_ = maxc + minc
            s = maxc - minc
            h = l_
            image_hls = l_
        else:
            image_hls = numpy_empty_like_frnt(image)
            h, l_, s = (
                image_hls[..., 0, :, :],
                image_hls[..., 1, :, :],
                image_hls[..., 2, :, :],
            )
            numpy_add_frnt(maxc, minc, out=l_)
            sub(maxc, minc, out=s)
        im = image / numpy_unsqueeze_frnt_(s + eps, -3)
        s = s / (where(l_ < 1.0, l_, 2.0 - l_) + eps)
        l_ = l_ / 2
        r, g, b = im[..., 0, :, :], im[..., 1, :, :], im[..., 2, :, :]
        cond = imax[..., None, :, :] == _RGB2HSL_IDX
        if numpy_requires_grad_frnt_(image):
            h = (g - b) % 6 * cond[..., 0, :, :]
        else:
>           numpy_mul_frnt((g - b) % 6, cond[..., 0, :, :], out=h)

ivy_transpiled_outputs/numpy_outputs/kornia/color/hls.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = array([[[1.        , 5.0731125 , 5.5924134 , 5.        , 5.        ],
        [5.0750365 , 1.        , 5.        , 0.8..., 0.9999999 , 5.7834053 ],
        [1.        , 0.34688544, 5.6400957 , 0.03503517, 5.433894  ]]],
      dtype=float32)
other = array([[[False,  True,  True, False, False],
        [False, False, False,  True,  True],
        [ True, False, False, False,  True],
        [False, False, False,  True, False]]])

    def numpy_mul_frnt(input, other, *, out=None):
        from .__init__ import numpy_promote_types_of_torch_inputs_frnt
        from ...backends.numpy.elementwise import numpy_multiply
    
>       input, other = numpy_promote_types_of_torch_inputs_frnt(input, other)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/pointwise_ops.py:60: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x1 = array([[[1.        , 5.0731125 , 5.5924134 , 5.        , 5.        ],
        [5.0750365 , 1.        , 5.        , 0.8..., 0.9999999 , 5.7834053 ],
        [1.        , 0.34688544, 5.6400957 , 0.03503517, 5.433894  ]]],
      dtype=float32)
x2 = array([[[False,  True,  True, False, False],
        [False, False, False,  True,  True],
        [ True, False, False, False,  True],
        [False, False, False,  True, False]]])

    def numpy_promote_types_of_torch_inputs_frnt(x1, x2, /):
        from ...ivy.general import numpy_isscalar_bknd
        from ...ivy.data_type import numpy_is_int_dtype_bknd
        from ...backends.numpy.creation import numpy_asarray
        from ...ivy.data_type import numpy_default_dtype_bknd
        from .tensor import numpy_shape_frnt_
        from ...ivy.device import numpy_default_device_bknd
        from ....data_classes.array.data_type import numpy_astype_bknd_
    
        """Promote the dtype of the given native array inputs to a common dtype
        based on type promotion rules.
    
        While passing float or integer values or any other non-array input
        to this function, it should be noted that the return will be an
        array-like object. Therefore, outputs from this function should be
        used as inputs only for those functions that expect an array-like or
        tensor-like objects, otherwise it might give unexpected results.
        """
        if (
            numpy_isscalar_bknd(x1) or isinstance(x1, (list, tuple))
        ) and numpy_is_int_dtype_bknd(x1):
            x1 = numpy_asarray(x1, dtype="int64")
        elif numpy_isscalar_bknd(x1) or isinstance(x1, (list, tuple)):
            x1 = numpy_asarray(x1)
        if (
            numpy_isscalar_bknd(x2) or isinstance(x2, (list, tuple))
        ) and numpy_is_int_dtype_bknd(x2):
            x2 = numpy_asarray(x2, dtype="int64")
        elif numpy_isscalar_bknd(x2) or isinstance(x2, (list, tuple)):
            x2 = numpy_asarray(x2)
        type1 = numpy_default_dtype_bknd(item=x1).strip("u123456789")
        type2 = numpy_default_dtype_bknd(item=x2).strip("u123456789")
        if numpy_shape_frnt_(x1) != () and numpy_shape_frnt_(x2) == () and type1 == type2:
            x2 = numpy_asarray(
                x2,
                dtype=x1.dtype,
                device=numpy_default_device_bknd(item=x1, as_native=False),
            )
        elif numpy_shape_frnt_(x1) == () and numpy_shape_frnt_(x2) != () and type1 == type2:
            x1 = numpy_asarray(
                x1,
                dtype=x2.dtype,
                device=numpy_default_device_bknd(item=x2, as_native=False),
            )
        elif x1.dtype != x2.dtype:
>           promoted = numpy_promote_types_torch_frnt(x1.dtype, x2.dtype)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/__init__.py:87: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

type1 = dtype('float32'), type2 = dtype('bool')

    def numpy_promote_types_torch_frnt(type1, type2, /):
        from ...backends.numpy.general import numpy_get_item
        from ...backends.numpy.data_type import numpy_as_ivy_dtype
    
        try:
            ret = numpy_get_item(
>               torch_promotion_table,
                (numpy_as_ivy_dtype(type1), numpy_as_ivy_dtype(type2)),
            )
E           NameError: name 'torch_promotion_table' is not defined

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/__init__.py:34: NameError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.color.hls.rgb_to_hls
_________________________________________________________________________________ test_rgb_to_yuv420[numpy-s2s-False] __________________________________________________________________________________

target_framework = 'numpy', mode = 's2s', backend_compile = False

    def test_rgb_to_yuv420(target_framework, mode, backend_compile):
        trace_args = (
            torch.rand(1, 3, 4, 6),
        )
        trace_kwargs = {}
        test_args = (
            torch.rand(5, 3, 4, 6),
        )
        test_kwargs = {}
>       _test_function(
            kornia.color.rgb_to_yuv420,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/test_color.py:559: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function rgb_to_yuv420 at 0x7f851dec7be0>
trace_args = (tensor([[[[0.0365, 0.2899, 0.4071, 0.1000, 0.6457, 0.8494],
          [0.7439, 0.5145, 0.0326, 0.3900, 0.7882, 0.3390...     [0.8491, 0.0537, 0.0569, 0.3161, 0.7189, 0.9429],
          [0.1801, 0.9374, 0.6847, 0.5721, 0.3786, 0.4317]]]]),)
trace_kwargs = {}
test_args = (tensor([[[[7.9692e-01, 7.1820e-01, 6.8690e-01, 5.4050e-01, 1.0329e-01,
           1.5107e-01],
          [4.9593e-01,...       8.4750e-01],
          [2.4493e-01, 9.8277e-01, 5.2048e-01, 6.7821e-01, 3.3762e-01,
           8.8687e-01]]]]),)
test_kwargs = {}, target = 'numpy', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function rgb_to_yuv420 at 0x7f851dec7be0>, fn_name = 'kornia.color.rgb_to_yuv420'
trace_args = (tensor([[[[0.0365, 0.2899, 0.4071, 0.1000, 0.6457, 0.8494],
          [0.7439, 0.5145, 0.0326, 0.3900, 0.7882, 0.3390...     [0.8491, 0.0537, 0.0569, 0.3161, 0.7189, 0.9429],
          [0.1801, 0.9374, 0.6847, 0.5721, 0.3786, 0.4317]]]]),)
trace_kwargs = {}
test_args = (tensor([[[[7.9692e-01, 7.1820e-01, 6.8690e-01, 5.4050e-01, 1.0329e-01,
           1.5107e-01],
          [4.9593e-01,...       8.4750e-01],
          [2.4493e-01, 9.8277e-01, 5.2048e-01, 6.7821e-01, 3.3762e-01,
           8.8687e-01]]]]),)
test_kwargs = {}, target = 'numpy', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
        graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
    
        if deterministic:
>           _to_numpy_and_allclose(orig_out, graph_out, tolerance=tolerance)

helpers.py:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

torch_x = (tensor([[[[0.4667, 0.6160, 0.3614, 0.2971, 0.7869, 0.4934],
          [0.6730, 0.2425, 0.1665, 0.6708, 0.5214, 0.3652...       [-0.0440, -0.0345, -0.0109]],

         [[-0.0907, -0.1242,  0.0999],
          [ 0.1431,  0.1121,  0.0868]]]]))
transpiled_x = (array([[[[0.46666178, 0.61602545, 0.36143196, 0.2970721 , 0.78689873,
          0.4933748 ],
         [0.67303866, 0....
        [[-0.0771073 , -0.02565768,  0.15219654],
         [ 0.15821679,  0.07494757, -0.05564619]]]], dtype=float32))
tolerance = 0.001

    def _to_numpy_and_allclose(torch_x, transpiled_x, tolerance=1e-3):
        orig_data = _nest_array_to_numpy(torch_x)
        transpiled_data = _nest_array_to_numpy(transpiled_x)
>       _check_allclose(orig_data, transpiled_data, tolerance=tolerance)

helpers.py:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = (array([[[[0.46666178, 0.61602545, 0.36143196, 0.2970721 , 0.78689873,
          0.4933748 ],
         [0.67303866, 0....
        [[-0.09068806, -0.1241581 ,  0.09986137],
         [ 0.1430572 ,  0.11211824,  0.08675906]]]], dtype=float32))
y = (array([[[[0.46666178, 0.61602545, 0.36143196, 0.2970721 , 0.78689873,
          0.4933748 ],
         [0.67303866, 0....
        [[-0.0771073 , -0.02565768,  0.15219654],
         [ 0.15821679,  0.07494757, -0.05564619]]]], dtype=float32))
tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
            assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
            return
    
        if isinstance(x, (list, set, tuple)):
>           all([
                _check_allclose(element_x, element_y, tolerance=tolerance) for element_x, element_y in zip(x, y)
            ])

helpers.py:30: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

.0 = <zip object at 0x7f84c529a5c0>

    all([
>       _check_allclose(element_x, element_y, tolerance=tolerance) for element_x, element_y in zip(x, y)
    ])

helpers.py:31: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[[ 0.00692886,  0.12052331, -0.08505642],
         [-0.04402824, -0.03447521, -0.01085451]],

        [[-0.09068806, -0.1241581 ,  0.09986137],
         [ 0.1430572 ,  0.11211824,  0.08675906]]]], dtype=float32)
y = array([[[[-0.0166922 , -0.09040594,  0.03578698],
         [ 0.00910964, -0.05976795,  0.07500724]],

        [[-0.0771073 , -0.02565768,  0.15219654],
         [ 0.15821679,  0.07494757, -0.05564619]]]], dtype=float32)
tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
>           assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
E           AssertionError: numpy array values are not all close

helpers.py:26: AssertionError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.color.yuv.rgb_to_yuv420
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/test_color.py::test_rgb_to_hls[numpy-s2s-False] - NameError: name 'torch_promotion_table' is not defined
FAILED kornia/test_color.py::test_rgb_to_yuv420[numpy-s2s-False] - AssertionError: numpy array values are not all close
======================================================================== 2 failed, 32 passed, 35 skipped in 1597.50s (0:26:37) =========================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 1 item

transformers/test_vision.py F                                                                                                                                                                    [100%]

=============================================================================================== FAILURES ===============================================================================================
_____________________________________________________________________________________ test_Swin2SR[jax-s2s-False] ______________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_Swin2SR(target_framework, mode, backend_compile):
        # NOTE: this is in the form `integration.subsection.model`, the class submodule would just be transformers.Swin2SRModel
        print("transformers.vision.Swin2SRModel")
    
        ivy.set_backend(target_framework)
        dataset = load_dataset("huggingface/cats-image", trust_remote_code=True)
        image = dataset["test"]["image"][0]
        image_processor = AutoImageProcessor.from_pretrained(
            "caidas/swin2SR-classical-sr-x2-64"
        )
    
        # modify the config to avoid OOM issues
        swin2sr_config = Swin2SRConfig()
        swin2sr_config.embed_dim = 2
        swin2sr_config.depths = [2, 2]
        swin2sr_config.num_heads = [2, 2]
    
        torch_model = Swin2SRModel.from_pretrained(
            "caidas/swin2SR-classical-sr-x2-64",
            config=swin2sr_config,
            ignore_mismatched_sizes=True,
        )
        torch_inputs = image_processor(image, return_tensors="pt")
        with torch.no_grad():
            torch_outputs = torch_model(**torch_inputs)
        torch_last_hidden_states = torch_outputs.last_hidden_state
    
>       TranslatedSwin2SRModel = ivy.transpile(
            Swin2SRModel, source="torch", target=target_framework
        )

transformers/test_vision.py:279: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

object = <class 'transformers.models.swin2sr.modeling_swin2sr.Swin2SRModel'>, source = 'torch', target = 'jax', reuse_existing = True

    def transpile(
        object,
        source: str = "torch",
        target: str = "tensorflow",
        reuse_existing: bool = True,
    ):
        """Converts a given object (class/function) from one framework to another.
    
        This function performs source-to-source translation of a given object from the source framework
        to the target framework.
    
        The object can be translated between two frameworks or between the Ivy IR as well
        e.g. (source="torch_frontend", target="ivy") or (source="torch_frontend", target="tensorflow") etc.
    
        Args:
            object: The object (class/function) to be translated.
            source (str, optional): The source framework. Defaults to 'torch'.
            target (str, optional): The target framework. Defaults to 'tensorflow'.
            reuse_existing (bool, optional): If True, the function will check if `object`
                                             already exists in the translated directory and reuse it.
                                             If False, it will re-translate `object`,
                                             even if it already exists in the directory, and overwrite
                                             the old implementation. Defaults to 'True'.
    
        Returns:
            The translated object."""
    
        from ._compiler import transpile as _transpile
    
>       return _transpile(
            object=object,
            source=source,
            target=target,
            reuse_existing=reuse_existing,
        )

../ivy/ivy/compiler/compiler.py:201: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   ivy.utils.exceptions.IvyException: Invalid api key. If you did not mean to use an api key, ensure you do not have an IVY_KEY environment variable set, and have no ivy-key.pem file in your working directory. If your api key should be valid, feel free to reach out to contact@ivy.dev for support.

IXC.pyx:379: IvyException
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
transformers.vision.Swin2SRModel
----------------------------------------------------------------------------------------- Captured stderr call -----------------------------------------------------------------------------------------

Downloading data:   0%|          | 0.00/173k [00:00<?, ?B/s]
Downloading data: 100%|| 173k/173k [00:00<00:00, 3.66MB/s]

Generating test split: 0 examples [00:00, ? examples/s]
Generating test split: 1 examples [00:00, 111.74 examples/s]
Some weights of Swin2SRModel were not initialized from the model checkpoint at caidas/swin2SR-classical-sr-x2-64 and are newly initialized because the shapes did not match:
- swin2sr.conv_after_body.bias: found shape torch.Size([180]) in the checkpoint and torch.Size([2]) in the model instantiated
- swin2sr.conv_after_body.weight: found shape torch.Size([180, 180, 3, 3]) in the checkpoint and torch.Size([2, 2, 3, 3]) in the model instantiated
- swin2sr.embeddings.patch_embeddings.layernorm.bias: found shape torch.Size([180]) in the checkpoint and torch.Size([2]) in the model instantiated
- swin2sr.embeddings.patch_embeddings.layernorm.weight: found shape torch.Size([180]) in the checkpoint and torch.Size([2]) in the model instantiated
- swin2sr.embeddings.patch_embeddings.projection.bias: found shape torch.Size([180]) in the checkpoint and torch.Size([2]) in the model instantiated
- swin2sr.embeddings.patch_embeddings.projection.weight: found shape torch.Size([180, 180, 1, 1]) in the checkpoint and torch.Size([2, 2, 1, 1]) in the model instantiated
- swin2sr.encoder.stages.0.conv.bias: found shape torch.Size([180]) in the checkpoint and torch.Size([2]) in the model instantiated
- swin2sr.encoder.stages.0.conv.weight: found shape torch.Size([180, 180, 3, 3]) in the checkpoint and torch.Size([2, 2, 3, 3]) in the model instantiated
- swin2sr.encoder.stages.0.layers.0.attention.output.dense.bias: found shape torch.Size([180]) in the checkpoint and torch.Size([2]) in the model instantiated
- swin2sr.encoder.stages.0.layers.0.attention.output.dense.weight: found shape torch.Size([180, 180]) in the checkpoint and torch.Size([2, 2]) in the model instantiated
- swin2sr.encoder.stages.0.layers.0.attention.self.continuous_position_bias_mlp.2.weight: found shape torch.Size([6, 512]) in the checkpoint and torch.Size([2, 512]) in the model instantiated
- swin2sr.encoder.stages.0.layers.0.attention.self.key.weight: found shape torch.Size([180, 180]) in the checkpoint and torch.Size([2, 2]) in the model instantiated
- swin2sr.encoder.stages.0.layers.0.attention.self.logit_scale: found shape torch.Size([6, 1, 1]) in the checkpoint and torch.Size([2, 1, 1]) in the model instantiated
- swin2sr.encoder.stages.0.layers.0.attention.self.query.bias: found shape torch.Size([180]) in the checkpoint and torch.Size([2]) in the model instantiated
- swin2sr.encoder.stages.0.layers.0.attention.self.query.weight: found shape torch.Size([180, 180]) in the checkpoint and torch.Size([2, 2]) in the model instantiated
- swin2sr.encoder.stages.0.layers.0.attention.self.value.bias: found shape torch.Size([180]) in the checkpoint and torch.Size([2]) in the model instantiated
- swin2sr.encoder.stages.0.layers.0.attention.self.value.weight: found shape torch.Size([180, 180]) in the checkpoint and torch.Size([2, 2]) in the model instantiated
- swin2sr.encoder.stages.0.layers.0.intermediate.dense.bias: found shape torch.Size([360]) in the checkpoint and torch.Size([4]) in the model instantiated
- swin2sr.encoder.stages.0.layers.0.intermediate.dense.weight: found shape torch.Size([360, 180]) in the checkpoint and torch.Size([4, 2]) in the model instantiated
- swin2sr.encoder.stages.0.layers.0.layernorm_after.bias: found shape torch.Size([180]) in the checkpoint and torch.Size([2]) in the model instantiated
- swin2sr.encoder.stages.0.layers.0.layernorm_after.weight: found shape torch.Size([180]) in the checkpoint and torch.Size([2]) in the model instantiated
- swin2sr.encoder.stages.0.layers.0.layernorm_before.bias: found shape torch.Size([180]) in the checkpoint and torch.Size([2]) in the model instantiated
- swin2sr.encoder.stages.0.layers.0.layernorm_before.weight: found shape torch.Size([180]) in the checkpoint and torch.Size([2]) in the model instantiated
- swin2sr.encoder.stages.0.layers.0.output.dense.bias: found shape torch.Size([180]) in the checkpoint and torch.Size([2]) in the model instantiated
- swin2sr.encoder.stages.0.layers.0.output.dense.weight: found shape torch.Size([180, 360]) in the checkpoint and torch.Size([2, 4]) in the model instantiated
- swin2sr.encoder.stages.0.layers.1.attention.output.dense.bias: found shape torch.Size([180]) in the checkpoint and torch.Size([2]) in the model instantiated
- swin2sr.encoder.stages.0.layers.1.attention.output.dense.weight: found shape torch.Size([180, 180]) in the checkpoint and torch.Size([2, 2]) in the model instantiated
- swin2sr.encoder.stages.0.layers.1.attention.self.continuous_position_bias_mlp.2.weight: found shape torch.Size([6, 512]) in the checkpoint and torch.Size([2, 512]) in the model instantiated
- swin2sr.encoder.stages.0.layers.1.attention.self.key.weight: found shape torch.Size([180, 180]) in the checkpoint and torch.Size([2, 2]) in the model instantiated
- swin2sr.encoder.stages.0.layers.1.attention.self.logit_scale: found shape torch.Size([6, 1, 1]) in the checkpoint and torch.Size([2, 1, 1]) in the model instantiated
- swin2sr.encoder.stages.0.layers.1.attention.self.query.bias: found shape torch.Size([180]) in the checkpoint and torch.Size([2]) in the model instantiated
- swin2sr.encoder.stages.0.layers.1.attention.self.query.weight: found shape torch.Size([180, 180]) in the checkpoint and torch.Size([2, 2]) in the model instantiated
- swin2sr.encoder.stages.0.layers.1.attention.self.value.bias: found shape torch.Size([180]) in the checkpoint and torch.Size([2]) in the model instantiated
- swin2sr.encoder.stages.0.layers.1.attention.self.value.weight: found shape torch.Size([180, 180]) in the checkpoint and torch.Size([2, 2]) in the model instantiated
- swin2sr.encoder.stages.0.layers.1.intermediate.dense.bias: found shape torch.Size([360]) in the checkpoint and torch.Size([4]) in the model instantiated
- swin2sr.encoder.stages.0.layers.1.intermediate.dense.weight: found shape torch.Size([360, 180]) in the checkpoint and torch.Size([4, 2]) in the model instantiated
- swin2sr.encoder.stages.0.layers.1.layernorm_after.bias: found shape torch.Size([180]) in the checkpoint and torch.Size([2]) in the model instantiated
- swin2sr.encoder.stages.0.layers.1.layernorm_after.weight: found shape torch.Size([180]) in the checkpoint and torch.Size([2]) in the model instantiated
- swin2sr.encoder.stages.0.layers.1.layernorm_before.bias: found shape torch.Size([180]) in the checkpoint and torch.Size([2]) in the model instantiated
- swin2sr.encoder.stages.0.layers.1.layernorm_before.weight: found shape torch.Size([180]) in the checkpoint and torch.Size([2]) in the model instantiated
- swin2sr.encoder.stages.0.layers.1.output.dense.bias: found shape torch.Size([180]) in the checkpoint and torch.Size([2]) in the model instantiated
- swin2sr.encoder.stages.0.layers.1.output.dense.weight: found shape torch.Size([180, 360]) in the checkpoint and torch.Size([2, 4]) in the model instantiated
- swin2sr.encoder.stages.0.patch_embed.projection.bias: found shape torch.Size([180]) in the checkpoint and torch.Size([2]) in the model instantiated
- swin2sr.encoder.stages.0.patch_embed.projection.weight: found shape torch.Size([180, 180, 1, 1]) in the checkpoint and torch.Size([2, 2, 1, 1]) in the model instantiated
- swin2sr.encoder.stages.1.conv.bias: found shape torch.Size([180]) in the checkpoint and torch.Size([2]) in the model instantiated
- swin2sr.encoder.stages.1.conv.weight: found shape torch.Size([180, 180, 3, 3]) in the checkpoint and torch.Size([2, 2, 3, 3]) in the model instantiated
- swin2sr.encoder.stages.1.layers.0.attention.output.dense.bias: found shape torch.Size([180]) in the checkpoint and torch.Size([2]) in the model instantiated
- swin2sr.encoder.stages.1.layers.0.attention.output.dense.weight: found shape torch.Size([180, 180]) in the checkpoint and torch.Size([2, 2]) in the model instantiated
- swin2sr.encoder.stages.1.layers.0.attention.self.continuous_position_bias_mlp.2.weight: found shape torch.Size([6, 512]) in the checkpoint and torch.Size([2, 512]) in the model instantiated
- swin2sr.encoder.stages.1.layers.0.attention.self.key.weight: found shape torch.Size([180, 180]) in the checkpoint and torch.Size([2, 2]) in the model instantiated
- swin2sr.encoder.stages.1.layers.0.attention.self.logit_scale: found shape torch.Size([6, 1, 1]) in the checkpoint and torch.Size([2, 1, 1]) in the model instantiated
- swin2sr.encoder.stages.1.layers.0.attention.self.query.bias: found shape torch.Size([180]) in the checkpoint and torch.Size([2]) in the model instantiated
- swin2sr.encoder.stages.1.layers.0.attention.self.query.weight: found shape torch.Size([180, 180]) in the checkpoint and torch.Size([2, 2]) in the model instantiated
- swin2sr.encoder.stages.1.layers.0.attention.self.value.bias: found shape torch.Size([180]) in the checkpoint and torch.Size([2]) in the model instantiated
- swin2sr.encoder.stages.1.layers.0.attention.self.value.weight: found shape torch.Size([180, 180]) in the checkpoint and torch.Size([2, 2]) in the model instantiated
- swin2sr.encoder.stages.1.layers.0.intermediate.dense.bias: found shape torch.Size([360]) in the checkpoint and torch.Size([4]) in the model instantiated
- swin2sr.encoder.stages.1.layers.0.intermediate.dense.weight: found shape torch.Size([360, 180]) in the checkpoint and torch.Size([4, 2]) in the model instantiated
- swin2sr.encoder.stages.1.layers.0.layernorm_after.bias: found shape torch.Size([180]) in the checkpoint and torch.Size([2]) in the model instantiated
- swin2sr.encoder.stages.1.layers.0.layernorm_after.weight: found shape torch.Size([180]) in the checkpoint and torch.Size([2]) in the model instantiated
- swin2sr.encoder.stages.1.layers.0.layernorm_before.bias: found shape torch.Size([180]) in the checkpoint and torch.Size([2]) in the model instantiated
- swin2sr.encoder.stages.1.layers.0.layernorm_before.weight: found shape torch.Size([180]) in the checkpoint and torch.Size([2]) in the model instantiated
- swin2sr.encoder.stages.1.layers.0.output.dense.bias: found shape torch.Size([180]) in the checkpoint and torch.Size([2]) in the model instantiated
- swin2sr.encoder.stages.1.layers.0.output.dense.weight: found shape torch.Size([180, 360]) in the checkpoint and torch.Size([2, 4]) in the model instantiated
- swin2sr.encoder.stages.1.layers.1.attention.output.dense.bias: found shape torch.Size([180]) in the checkpoint and torch.Size([2]) in the model instantiated
- swin2sr.encoder.stages.1.layers.1.attention.output.dense.weight: found shape torch.Size([180, 180]) in the checkpoint and torch.Size([2, 2]) in the model instantiated
- swin2sr.encoder.stages.1.layers.1.attention.self.continuous_position_bias_mlp.2.weight: found shape torch.Size([6, 512]) in the checkpoint and torch.Size([2, 512]) in the model instantiated
- swin2sr.encoder.stages.1.layers.1.attention.self.key.weight: found shape torch.Size([180, 180]) in the checkpoint and torch.Size([2, 2]) in the model instantiated
- swin2sr.encoder.stages.1.layers.1.attention.self.logit_scale: found shape torch.Size([6, 1, 1]) in the checkpoint and torch.Size([2, 1, 1]) in the model instantiated
- swin2sr.encoder.stages.1.layers.1.attention.self.query.bias: found shape torch.Size([180]) in the checkpoint and torch.Size([2]) in the model instantiated
- swin2sr.encoder.stages.1.layers.1.attention.self.query.weight: found shape torch.Size([180, 180]) in the checkpoint and torch.Size([2, 2]) in the model instantiated
- swin2sr.encoder.stages.1.layers.1.attention.self.value.bias: found shape torch.Size([180]) in the checkpoint and torch.Size([2]) in the model instantiated
- swin2sr.encoder.stages.1.layers.1.attention.self.value.weight: found shape torch.Size([180, 180]) in the checkpoint and torch.Size([2, 2]) in the model instantiated
- swin2sr.encoder.stages.1.layers.1.intermediate.dense.bias: found shape torch.Size([360]) in the checkpoint and torch.Size([4]) in the model instantiated
- swin2sr.encoder.stages.1.layers.1.intermediate.dense.weight: found shape torch.Size([360, 180]) in the checkpoint and torch.Size([4, 2]) in the model instantiated
- swin2sr.encoder.stages.1.layers.1.layernorm_after.bias: found shape torch.Size([180]) in the checkpoint and torch.Size([2]) in the model instantiated
- swin2sr.encoder.stages.1.layers.1.layernorm_after.weight: found shape torch.Size([180]) in the checkpoint and torch.Size([2]) in the model instantiated
- swin2sr.encoder.stages.1.layers.1.layernorm_before.bias: found shape torch.Size([180]) in the checkpoint and torch.Size([2]) in the model instantiated
- swin2sr.encoder.stages.1.layers.1.layernorm_before.weight: found shape torch.Size([180]) in the checkpoint and torch.Size([2]) in the model instantiated
- swin2sr.encoder.stages.1.layers.1.output.dense.bias: found shape torch.Size([180]) in the checkpoint and torch.Size([2]) in the model instantiated
- swin2sr.encoder.stages.1.layers.1.output.dense.weight: found shape torch.Size([180, 360]) in the checkpoint and torch.Size([2, 4]) in the model instantiated
- swin2sr.encoder.stages.1.patch_embed.projection.bias: found shape torch.Size([180]) in the checkpoint and torch.Size([2]) in the model instantiated
- swin2sr.encoder.stages.1.patch_embed.projection.weight: found shape torch.Size([180, 180, 1, 1]) in the checkpoint and torch.Size([2, 2, 1, 1]) in the model instantiated
- swin2sr.first_convolution.bias: found shape torch.Size([180]) in the checkpoint and torch.Size([2]) in the model instantiated
- swin2sr.first_convolution.weight: found shape torch.Size([180, 3, 3, 3]) in the checkpoint and torch.Size([2, 3, 3, 3]) in the model instantiated
- swin2sr.layernorm.bias: found shape torch.Size([180]) in the checkpoint and torch.Size([2]) in the model instantiated
- swin2sr.layernorm.weight: found shape torch.Size([180]) in the checkpoint and torch.Size([2]) in the model instantiated
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED transformers/test_vision.py::test_Swin2SR[jax-s2s-False] - ivy.utils.exceptions.IvyException: Invalid api key. If you did not mean to use an api key, ensure you do not have an IVY_KEY enviro...
========================================================================================== 1 failed in 9.21s ===========================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 14 items

kornia/test_feature4.py ssssssssssssss                                                                                                                                                           [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
========================================================================================= 14 skipped in 5.07s ==========================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 6 items

kornia/test_nerf.py ssssss                                                                                                                                                                       [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
========================================================================================== 6 skipped in 5.22s ==========================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 5 items

kornia/geometry/test_solvers.py .....                                                                                                                                                            [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
==================================================================================== 5 passed in 285.35s (0:04:45) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 13 items

kornia/test_utils.py .............                                                                                                                                                               [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
==================================================================================== 13 passed in 749.70s (0:12:29) ====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 4 items

kornia/test_sensors.py ....                                                                                                                                                                      [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
===================================================================================== 4 passed in 87.14s (0:01:27) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 2 items

kornia/geometry/test_line.py ..                                                                                                                                                                  [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
===================================================================================== 2 passed in 82.25s (0:01:22) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 4 items

kornia/geometry/test_liegroup.py ..F.                                                                                                                                                            [100%]

=============================================================================================== FAILURES ===============================================================================================
_______________________________________________________________________________________ test_So2[jax-s2s-False] ________________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_So2(target_framework, mode, backend_compile):
        print("kornia.geometry.liegroup.So2")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        real_part = torch.tensor([1.0], requires_grad=True)
        imaginary_part = torch.tensor([2.0], requires_grad=True)
        complex_number = torch.complex(real_part, imaginary_part)
        torch_so2 = kornia.geometry.liegroup.So2(complex_number)
    
        TranspiledSo2 = ivy.transpile(kornia.geometry.liegroup.So2, source="torch", target=target_framework)
        transpiled_complex_number = _nest_torch_tensor_to_new_framework(complex_number, target_framework)
        transpiled_so2 = TranspiledSo2(transpiled_complex_number)
    
        # Test .matrix()
        torch_matrix = torch_so2.matrix()
        transpiled_matrix = transpiled_so2.matrix()
        _to_numpy_and_allclose(torch_matrix, transpiled_matrix)
    
        # Test .inverse()
        torch_inverse = torch_so2.inverse()
        transpiled_inverse = transpiled_so2.inverse()
        _to_numpy_and_allclose(torch_inverse.z, transpiled_inverse.z)
    
        # Test .log()
        torch_log = torch_so2.log()
        transpiled_log = transpiled_so2.log()
        _to_numpy_and_allclose(torch_log, transpiled_log)
    
        # Test .__mul__()
        other_real_part = torch.tensor([0.5], requires_grad=True)
        other_imaginary_part = torch.tensor([0.5], requires_grad=True)
        other_complex_number = torch.complex(other_real_part, other_imaginary_part)
        other_torch_so2 = kornia.geometry.liegroup.So2(other_complex_number)
    
        transpiled_other_complex_number = _nest_torch_tensor_to_new_framework(other_complex_number, target_framework)
        transpiled_other_so2 = TranspiledSo2(transpiled_other_complex_number)
    
        torch_composed_so2 = torch_so2 * other_torch_so2
        transpiled_composed_so2 = transpiled_so2 * transpiled_other_so2
        _to_numpy_and_allclose(torch_composed_so2.z, transpiled_composed_so2.z)
    
        # Test .adjoint()
        torch_adjoint = torch_so2.adjoint()
>       transpiled_adjoint = transpiled_so2.adjoint()

kornia/geometry/test_liegroup.py:202: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = Param(
  value=Array([1.+2.j], dtype=complex64)
)

    def adjoint(self):
        from ....ivy.functional.frontends.torch.tensor import jax_real_frnt_
        from ....ivy.functional.frontends.torch.tensor import jax_shape_frnt_
    
>       batch_size = len(self.z) if len(jax_shape_frnt_(self.z)) > 0 else None
E       TypeError: object of type 'Param' has no len()

ivy_transpiled_outputs/jax_outputs/kornia/geometry/liegroup/so2.py:186: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.liegroup.So2
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/geometry/test_liegroup.py::test_So2[jax-s2s-False] - TypeError: object of type 'Param' has no len()
=============================================================================== 1 failed, 3 passed in 427.91s (0:07:07) ================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 5 items

kornia/test_x.py sssss                                                                                                                                                                           [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
==================================================================================== 5 skipped in 291.59s (0:04:51) ====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 8 items

kornia/geometry/test_linalg.py ........                                                                                                                                                          [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
==================================================================================== 8 passed in 280.44s (0:04:40) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 1 item

transformers/test_vision.py F                                                                                                                                                                    [100%]

=============================================================================================== FAILURES ===============================================================================================
__________________________________________________________________________________ test_Swin2SR[tensorflow-s2s-False] __________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_Swin2SR(target_framework, mode, backend_compile):
        # NOTE: this is in the form `integration.subsection.model`, the class submodule would just be transformers.Swin2SRModel
        print("transformers.vision.Swin2SRModel")
    
        ivy.set_backend(target_framework)
        dataset = load_dataset("huggingface/cats-image", trust_remote_code=True)
        image = dataset["test"]["image"][0]
        image_processor = AutoImageProcessor.from_pretrained(
            "caidas/swin2SR-classical-sr-x2-64"
        )
    
        # modify the config to avoid OOM issues
        swin2sr_config = Swin2SRConfig()
        swin2sr_config.embed_dim = 2
        swin2sr_config.depths = [2, 2]
        swin2sr_config.num_heads = [2, 2]
    
        torch_model = Swin2SRModel.from_pretrained(
            "caidas/swin2SR-classical-sr-x2-64",
            config=swin2sr_config,
            ignore_mismatched_sizes=True,
        )
        torch_inputs = image_processor(image, return_tensors="pt")
        with torch.no_grad():
            torch_outputs = torch_model(**torch_inputs)
        torch_last_hidden_states = torch_outputs.last_hidden_state
    
>       TranslatedSwin2SRModel = ivy.transpile(
            Swin2SRModel, source="torch", target=target_framework
        )

transformers/test_vision.py:279: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

object = <class 'transformers.models.swin2sr.modeling_swin2sr.Swin2SRModel'>, source = 'torch', target = 'tensorflow', reuse_existing = True

    def transpile(
        object,
        source: str = "torch",
        target: str = "tensorflow",
        reuse_existing: bool = True,
    ):
        """Converts a given object (class/function) from one framework to another.
    
        This function performs source-to-source translation of a given object from the source framework
        to the target framework.
    
        The object can be translated between two frameworks or between the Ivy IR as well
        e.g. (source="torch_frontend", target="ivy") or (source="torch_frontend", target="tensorflow") etc.
    
        Args:
            object: The object (class/function) to be translated.
            source (str, optional): The source framework. Defaults to 'torch'.
            target (str, optional): The target framework. Defaults to 'tensorflow'.
            reuse_existing (bool, optional): If True, the function will check if `object`
                                             already exists in the translated directory and reuse it.
                                             If False, it will re-translate `object`,
                                             even if it already exists in the directory, and overwrite
                                             the old implementation. Defaults to 'True'.
    
        Returns:
            The translated object."""
    
        from ._compiler import transpile as _transpile
    
>       return _transpile(
            object=object,
            source=source,
            target=target,
            reuse_existing=reuse_existing,
        )

../ivy/ivy/compiler/compiler.py:201: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   ivy.utils.exceptions.IvyException: Invalid api key. If you did not mean to use an api key, ensure you do not have an IVY_KEY environment variable set, and have no ivy-key.pem file in your working directory. If your api key should be valid, feel free to reach out to contact@ivy.dev for support.

IXC.pyx:379: IvyException
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
transformers.vision.Swin2SRModel
----------------------------------------------------------------------------------------- Captured stderr call -----------------------------------------------------------------------------------------

Downloading data:   0%|          | 0.00/173k [00:00<?, ?B/s]
Downloading data: 100%|| 173k/173k [00:00<00:00, 4.41MB/s]

Generating test split: 0 examples [00:00, ? examples/s]
Generating test split: 1 examples [00:00, 107.27 examples/s]
Some weights of Swin2SRModel were not initialized from the model checkpoint at caidas/swin2SR-classical-sr-x2-64 and are newly initialized because the shapes did not match:
- swin2sr.conv_after_body.bias: found shape torch.Size([180]) in the checkpoint and torch.Size([2]) in the model instantiated
- swin2sr.conv_after_body.weight: found shape torch.Size([180, 180, 3, 3]) in the checkpoint and torch.Size([2, 2, 3, 3]) in the model instantiated
- swin2sr.embeddings.patch_embeddings.layernorm.bias: found shape torch.Size([180]) in the checkpoint and torch.Size([2]) in the model instantiated
- swin2sr.embeddings.patch_embeddings.layernorm.weight: found shape torch.Size([180]) in the checkpoint and torch.Size([2]) in the model instantiated
- swin2sr.embeddings.patch_embeddings.projection.bias: found shape torch.Size([180]) in the checkpoint and torch.Size([2]) in the model instantiated
- swin2sr.embeddings.patch_embeddings.projection.weight: found shape torch.Size([180, 180, 1, 1]) in the checkpoint and torch.Size([2, 2, 1, 1]) in the model instantiated
- swin2sr.encoder.stages.0.conv.bias: found shape torch.Size([180]) in the checkpoint and torch.Size([2]) in the model instantiated
- swin2sr.encoder.stages.0.conv.weight: found shape torch.Size([180, 180, 3, 3]) in the checkpoint and torch.Size([2, 2, 3, 3]) in the model instantiated
- swin2sr.encoder.stages.0.layers.0.attention.output.dense.bias: found shape torch.Size([180]) in the checkpoint and torch.Size([2]) in the model instantiated
- swin2sr.encoder.stages.0.layers.0.attention.output.dense.weight: found shape torch.Size([180, 180]) in the checkpoint and torch.Size([2, 2]) in the model instantiated
- swin2sr.encoder.stages.0.layers.0.attention.self.continuous_position_bias_mlp.2.weight: found shape torch.Size([6, 512]) in the checkpoint and torch.Size([2, 512]) in the model instantiated
- swin2sr.encoder.stages.0.layers.0.attention.self.key.weight: found shape torch.Size([180, 180]) in the checkpoint and torch.Size([2, 2]) in the model instantiated
- swin2sr.encoder.stages.0.layers.0.attention.self.logit_scale: found shape torch.Size([6, 1, 1]) in the checkpoint and torch.Size([2, 1, 1]) in the model instantiated
- swin2sr.encoder.stages.0.layers.0.attention.self.query.bias: found shape torch.Size([180]) in the checkpoint and torch.Size([2]) in the model instantiated
- swin2sr.encoder.stages.0.layers.0.attention.self.query.weight: found shape torch.Size([180, 180]) in the checkpoint and torch.Size([2, 2]) in the model instantiated
- swin2sr.encoder.stages.0.layers.0.attention.self.value.bias: found shape torch.Size([180]) in the checkpoint and torch.Size([2]) in the model instantiated
- swin2sr.encoder.stages.0.layers.0.attention.self.value.weight: found shape torch.Size([180, 180]) in the checkpoint and torch.Size([2, 2]) in the model instantiated
- swin2sr.encoder.stages.0.layers.0.intermediate.dense.bias: found shape torch.Size([360]) in the checkpoint and torch.Size([4]) in the model instantiated
- swin2sr.encoder.stages.0.layers.0.intermediate.dense.weight: found shape torch.Size([360, 180]) in the checkpoint and torch.Size([4, 2]) in the model instantiated
- swin2sr.encoder.stages.0.layers.0.layernorm_after.bias: found shape torch.Size([180]) in the checkpoint and torch.Size([2]) in the model instantiated
- swin2sr.encoder.stages.0.layers.0.layernorm_after.weight: found shape torch.Size([180]) in the checkpoint and torch.Size([2]) in the model instantiated
- swin2sr.encoder.stages.0.layers.0.layernorm_before.bias: found shape torch.Size([180]) in the checkpoint and torch.Size([2]) in the model instantiated
- swin2sr.encoder.stages.0.layers.0.layernorm_before.weight: found shape torch.Size([180]) in the checkpoint and torch.Size([2]) in the model instantiated
- swin2sr.encoder.stages.0.layers.0.output.dense.bias: found shape torch.Size([180]) in the checkpoint and torch.Size([2]) in the model instantiated
- swin2sr.encoder.stages.0.layers.0.output.dense.weight: found shape torch.Size([180, 360]) in the checkpoint and torch.Size([2, 4]) in the model instantiated
- swin2sr.encoder.stages.0.layers.1.attention.output.dense.bias: found shape torch.Size([180]) in the checkpoint and torch.Size([2]) in the model instantiated
- swin2sr.encoder.stages.0.layers.1.attention.output.dense.weight: found shape torch.Size([180, 180]) in the checkpoint and torch.Size([2, 2]) in the model instantiated
- swin2sr.encoder.stages.0.layers.1.attention.self.continuous_position_bias_mlp.2.weight: found shape torch.Size([6, 512]) in the checkpoint and torch.Size([2, 512]) in the model instantiated
- swin2sr.encoder.stages.0.layers.1.attention.self.key.weight: found shape torch.Size([180, 180]) in the checkpoint and torch.Size([2, 2]) in the model instantiated
- swin2sr.encoder.stages.0.layers.1.attention.self.logit_scale: found shape torch.Size([6, 1, 1]) in the checkpoint and torch.Size([2, 1, 1]) in the model instantiated
- swin2sr.encoder.stages.0.layers.1.attention.self.query.bias: found shape torch.Size([180]) in the checkpoint and torch.Size([2]) in the model instantiated
- swin2sr.encoder.stages.0.layers.1.attention.self.query.weight: found shape torch.Size([180, 180]) in the checkpoint and torch.Size([2, 2]) in the model instantiated
- swin2sr.encoder.stages.0.layers.1.attention.self.value.bias: found shape torch.Size([180]) in the checkpoint and torch.Size([2]) in the model instantiated
- swin2sr.encoder.stages.0.layers.1.attention.self.value.weight: found shape torch.Size([180, 180]) in the checkpoint and torch.Size([2, 2]) in the model instantiated
- swin2sr.encoder.stages.0.layers.1.intermediate.dense.bias: found shape torch.Size([360]) in the checkpoint and torch.Size([4]) in the model instantiated
- swin2sr.encoder.stages.0.layers.1.intermediate.dense.weight: found shape torch.Size([360, 180]) in the checkpoint and torch.Size([4, 2]) in the model instantiated
- swin2sr.encoder.stages.0.layers.1.layernorm_after.bias: found shape torch.Size([180]) in the checkpoint and torch.Size([2]) in the model instantiated
- swin2sr.encoder.stages.0.layers.1.layernorm_after.weight: found shape torch.Size([180]) in the checkpoint and torch.Size([2]) in the model instantiated
- swin2sr.encoder.stages.0.layers.1.layernorm_before.bias: found shape torch.Size([180]) in the checkpoint and torch.Size([2]) in the model instantiated
- swin2sr.encoder.stages.0.layers.1.layernorm_before.weight: found shape torch.Size([180]) in the checkpoint and torch.Size([2]) in the model instantiated
- swin2sr.encoder.stages.0.layers.1.output.dense.bias: found shape torch.Size([180]) in the checkpoint and torch.Size([2]) in the model instantiated
- swin2sr.encoder.stages.0.layers.1.output.dense.weight: found shape torch.Size([180, 360]) in the checkpoint and torch.Size([2, 4]) in the model instantiated
- swin2sr.encoder.stages.0.patch_embed.projection.bias: found shape torch.Size([180]) in the checkpoint and torch.Size([2]) in the model instantiated
- swin2sr.encoder.stages.0.patch_embed.projection.weight: found shape torch.Size([180, 180, 1, 1]) in the checkpoint and torch.Size([2, 2, 1, 1]) in the model instantiated
- swin2sr.encoder.stages.1.conv.bias: found shape torch.Size([180]) in the checkpoint and torch.Size([2]) in the model instantiated
- swin2sr.encoder.stages.1.conv.weight: found shape torch.Size([180, 180, 3, 3]) in the checkpoint and torch.Size([2, 2, 3, 3]) in the model instantiated
- swin2sr.encoder.stages.1.layers.0.attention.output.dense.bias: found shape torch.Size([180]) in the checkpoint and torch.Size([2]) in the model instantiated
- swin2sr.encoder.stages.1.layers.0.attention.output.dense.weight: found shape torch.Size([180, 180]) in the checkpoint and torch.Size([2, 2]) in the model instantiated
- swin2sr.encoder.stages.1.layers.0.attention.self.continuous_position_bias_mlp.2.weight: found shape torch.Size([6, 512]) in the checkpoint and torch.Size([2, 512]) in the model instantiated
- swin2sr.encoder.stages.1.layers.0.attention.self.key.weight: found shape torch.Size([180, 180]) in the checkpoint and torch.Size([2, 2]) in the model instantiated
- swin2sr.encoder.stages.1.layers.0.attention.self.logit_scale: found shape torch.Size([6, 1, 1]) in the checkpoint and torch.Size([2, 1, 1]) in the model instantiated
- swin2sr.encoder.stages.1.layers.0.attention.self.query.bias: found shape torch.Size([180]) in the checkpoint and torch.Size([2]) in the model instantiated
- swin2sr.encoder.stages.1.layers.0.attention.self.query.weight: found shape torch.Size([180, 180]) in the checkpoint and torch.Size([2, 2]) in the model instantiated
- swin2sr.encoder.stages.1.layers.0.attention.self.value.bias: found shape torch.Size([180]) in the checkpoint and torch.Size([2]) in the model instantiated
- swin2sr.encoder.stages.1.layers.0.attention.self.value.weight: found shape torch.Size([180, 180]) in the checkpoint and torch.Size([2, 2]) in the model instantiated
- swin2sr.encoder.stages.1.layers.0.intermediate.dense.bias: found shape torch.Size([360]) in the checkpoint and torch.Size([4]) in the model instantiated
- swin2sr.encoder.stages.1.layers.0.intermediate.dense.weight: found shape torch.Size([360, 180]) in the checkpoint and torch.Size([4, 2]) in the model instantiated
- swin2sr.encoder.stages.1.layers.0.layernorm_after.bias: found shape torch.Size([180]) in the checkpoint and torch.Size([2]) in the model instantiated
- swin2sr.encoder.stages.1.layers.0.layernorm_after.weight: found shape torch.Size([180]) in the checkpoint and torch.Size([2]) in the model instantiated
- swin2sr.encoder.stages.1.layers.0.layernorm_before.bias: found shape torch.Size([180]) in the checkpoint and torch.Size([2]) in the model instantiated
- swin2sr.encoder.stages.1.layers.0.layernorm_before.weight: found shape torch.Size([180]) in the checkpoint and torch.Size([2]) in the model instantiated
- swin2sr.encoder.stages.1.layers.0.output.dense.bias: found shape torch.Size([180]) in the checkpoint and torch.Size([2]) in the model instantiated
- swin2sr.encoder.stages.1.layers.0.output.dense.weight: found shape torch.Size([180, 360]) in the checkpoint and torch.Size([2, 4]) in the model instantiated
- swin2sr.encoder.stages.1.layers.1.attention.output.dense.bias: found shape torch.Size([180]) in the checkpoint and torch.Size([2]) in the model instantiated
- swin2sr.encoder.stages.1.layers.1.attention.output.dense.weight: found shape torch.Size([180, 180]) in the checkpoint and torch.Size([2, 2]) in the model instantiated
- swin2sr.encoder.stages.1.layers.1.attention.self.continuous_position_bias_mlp.2.weight: found shape torch.Size([6, 512]) in the checkpoint and torch.Size([2, 512]) in the model instantiated
- swin2sr.encoder.stages.1.layers.1.attention.self.key.weight: found shape torch.Size([180, 180]) in the checkpoint and torch.Size([2, 2]) in the model instantiated
- swin2sr.encoder.stages.1.layers.1.attention.self.logit_scale: found shape torch.Size([6, 1, 1]) in the checkpoint and torch.Size([2, 1, 1]) in the model instantiated
- swin2sr.encoder.stages.1.layers.1.attention.self.query.bias: found shape torch.Size([180]) in the checkpoint and torch.Size([2]) in the model instantiated
- swin2sr.encoder.stages.1.layers.1.attention.self.query.weight: found shape torch.Size([180, 180]) in the checkpoint and torch.Size([2, 2]) in the model instantiated
- swin2sr.encoder.stages.1.layers.1.attention.self.value.bias: found shape torch.Size([180]) in the checkpoint and torch.Size([2]) in the model instantiated
- swin2sr.encoder.stages.1.layers.1.attention.self.value.weight: found shape torch.Size([180, 180]) in the checkpoint and torch.Size([2, 2]) in the model instantiated
- swin2sr.encoder.stages.1.layers.1.intermediate.dense.bias: found shape torch.Size([360]) in the checkpoint and torch.Size([4]) in the model instantiated
- swin2sr.encoder.stages.1.layers.1.intermediate.dense.weight: found shape torch.Size([360, 180]) in the checkpoint and torch.Size([4, 2]) in the model instantiated
- swin2sr.encoder.stages.1.layers.1.layernorm_after.bias: found shape torch.Size([180]) in the checkpoint and torch.Size([2]) in the model instantiated
- swin2sr.encoder.stages.1.layers.1.layernorm_after.weight: found shape torch.Size([180]) in the checkpoint and torch.Size([2]) in the model instantiated
- swin2sr.encoder.stages.1.layers.1.layernorm_before.bias: found shape torch.Size([180]) in the checkpoint and torch.Size([2]) in the model instantiated
- swin2sr.encoder.stages.1.layers.1.layernorm_before.weight: found shape torch.Size([180]) in the checkpoint and torch.Size([2]) in the model instantiated
- swin2sr.encoder.stages.1.layers.1.output.dense.bias: found shape torch.Size([180]) in the checkpoint and torch.Size([2]) in the model instantiated
- swin2sr.encoder.stages.1.layers.1.output.dense.weight: found shape torch.Size([180, 360]) in the checkpoint and torch.Size([2, 4]) in the model instantiated
- swin2sr.encoder.stages.1.patch_embed.projection.bias: found shape torch.Size([180]) in the checkpoint and torch.Size([2]) in the model instantiated
- swin2sr.encoder.stages.1.patch_embed.projection.weight: found shape torch.Size([180, 180, 1, 1]) in the checkpoint and torch.Size([2, 2, 1, 1]) in the model instantiated
- swin2sr.first_convolution.bias: found shape torch.Size([180]) in the checkpoint and torch.Size([2]) in the model instantiated
- swin2sr.first_convolution.weight: found shape torch.Size([180, 3, 3, 3]) in the checkpoint and torch.Size([2, 3, 3, 3]) in the model instantiated
- swin2sr.layernorm.bias: found shape torch.Size([180]) in the checkpoint and torch.Size([2]) in the model instantiated
- swin2sr.layernorm.weight: found shape torch.Size([180]) in the checkpoint and torch.Size([2]) in the model instantiated
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED transformers/test_vision.py::test_Swin2SR[tensorflow-s2s-False] - ivy.utils.exceptions.IvyException: Invalid api key. If you did not mean to use an api key, ensure you do not have an IVY_KEY...
========================================================================================== 1 failed in 9.21s ===========================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 5 items

kornia/geometry/test_solvers.py .....                                                                                                                                                            [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
==================================================================================== 5 passed in 289.86s (0:04:49) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 18 items

kornia/augmentation/test_augmentation1.py ssssssssssssssssss                                                                                                                                     [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
========================================================================================= 18 skipped in 5.32s ==========================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 2 items

kornia/test_io.py ..                                                                                                                                                                             [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
==================================================================================== 2 passed in 124.69s (0:02:04) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 15 items

kornia/geometry/test_subpix.py ..F.........F..                                                                                                                                                   [100%]

=============================================================================================== FAILURES ===============================================================================================
________________________________________________________________________________ test_conv_quad_interp3d[jax-s2s-False] ________________________________________________________________________________
jax.errors.SimplifiedTraceback: For simplicity, JAX has removed its internal frames from the traceback of the following exception. Set JAX_TRACEBACK_FILTERING=off to include these.

The above exception was the direct cause of the following exception:

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_conv_quad_interp3d(target_framework, mode, backend_compile):
        trace_args = (
            torch.rand(2, 2, 2, 5, 5),
        )
        trace_kwargs = {
            'strict_maxima_bonus': 10.0,
            'eps': 1e-7,
        }
        test_args = (
            torch.rand(1, 2, 2, 5, 5),
        )
        test_kwargs = {
            'strict_maxima_bonus': 5.0,
            'eps': 1e-7,
        }
>       _test_function(
            kornia.geometry.subpix.conv_quad_interp3d,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/geometry/test_subpix.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function conv_quad_interp3d at 0x7fbf3a668ca0>
trace_args = (tensor([[[[[0.1495, 0.2055, 0.5147, 0.2470, 0.0891],
           [0.0905, 0.1492, 0.3839, 0.7708, 0.5223],
           ....7055],
           [0.4026, 0.8184, 0.8731, 0.2131, 0.4234],
           [0.3094, 0.2737, 0.6182, 0.4243, 0.5820]]]]]),)
trace_kwargs = {'eps': 1e-07, 'strict_maxima_bonus': 10.0}
test_args = (tensor([[[[[0.7301, 0.6500, 0.5966, 0.7833, 0.5580],
           [0.4011, 0.0390, 0.2265, 0.4163, 0.1179],
           ....1885],
           [0.6426, 0.2493, 0.5403, 0.2620, 0.8317],
           [0.1851, 0.2729, 0.4265, 0.5024, 0.8192]]]]]),)
test_kwargs = {'eps': 1e-07, 'strict_maxima_bonus': 5.0}, target = 'jax', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function conv_quad_interp3d at 0x7fbf3a668ca0>, fn_name = 'kornia.geometry.subpix.conv_quad_interp3d'
trace_args = (tensor([[[[[0.1495, 0.2055, 0.5147, 0.2470, 0.0891],
           [0.0905, 0.1492, 0.3839, 0.7708, 0.5223],
           ....7055],
           [0.4026, 0.8184, 0.8731, 0.2131, 0.4234],
           [0.3094, 0.2737, 0.6182, 0.4243, 0.5820]]]]]),)
trace_kwargs = {'eps': 1e-07, 'strict_maxima_bonus': 10.0}
test_args = (tensor([[[[[0.7301, 0.6500, 0.5966, 0.7833, 0.5580],
           [0.4011, 0.0390, 0.2265, 0.4163, 0.1179],
           ....1885],
           [0.6426, 0.2493, 0.5403, 0.2620, 0.8317],
           [0.1851, 0.2729, 0.4265, 0.5024, 0.8192]]]]]),)
test_kwargs = {'eps': 1e-07, 'strict_maxima_bonus': 5.0}, target = 'jax', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = Array([[[[[0.14945084, 0.20553362, 0.5146814 , 0.24697495, 0.08906436],
          [0.09054452, 0.14920563, 0.38385445,....21306413, 0.42342126],
          [0.30944657, 0.27371097, 0.6181807 , 0.42431277, 0.5820401 ]]]]],      dtype=float32)
strict_maxima_bonus = 10.0, eps = 1e-07

    def jax_conv_quad_interp3d(input, strict_maxima_bonus=10.0, eps=1e-07):
        from ...core._backend import stack
        from ...core._backend import rand
        from ...core._backend import zeros_like
        from ...core._backend import where
        from ....ivy.functional.frontends.torch.tensor_functions import jax_is_tensor_frnt_
        from ....ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ....ivy.functional.frontends.torch.tensor import jax_permute_frnt_
        from ...utils.grid import jax_create_meshgrid3d
        from ....ivy.functional.frontends.torch.tensor import jax_to_frnt_
        from ...filters.sobel import jax_spatial_gradient3d
        from ....ivy.functional.frontends.torch.tensor import jax_reshape_frnt_
        from ....ivy.functional.frontends.torch.tensor import jax_view_frnt_
        from ...utils._compat import jax_torch_version_ge
        from ....ivy.functional.frontends.torch.tensor import jax_abs_frnt_
        from ....ivy.functional.frontends.torch.tensor import jax_size_frnt_
        from .nms import jax_nms3d
        from ...utils.helpers import jax_safe_solve_with_mask
        from ....ivy.functional.backends.jax.general import jax_get_item
        from ....ivy.functional.frontends.torch.tensor import jax_masked_scatter_frnt_
        from ....ivy.functional.backends.jax.general import jax_set_item
        from ....ivy.functional.frontends.torch.tensor import jax_max_frnt_
        from ....ivy.functional.frontends.torch.tensor import jax_masked_fill__frnt_
        from ....ivy.functional.frontends.torch.tensor import jax_expand_as_frnt_
        from ....ivy.functional.frontends.torch.blas_and_lapack_ops import jax_bmm_frnt
        from ....ivy.functional.frontends.torch.tensor import jax_flip_frnt_
        from ....ivy.functional.frontends.torch.tensor import jax_unsqueeze_frnt_
        from ....ivy.functional.frontends.torch.tensor import jax_repeat_frnt_
    
        if not jax_is_tensor_frnt_(input):
            raise TypeError(f"Input type is not a Tensor. Got {type(input)}")
        if not len(jax_shape_frnt_(input)) == 5:
            raise ValueError(
                f"Invalid input shape, we expect BxCxDxHxW. Got: {jax_shape_frnt_(input)}"
            )
        B, CH, D, H, W = jax_shape_frnt_(input)
        grid_global: typing.Any = jax_permute_frnt_(
            jax_create_meshgrid3d(D, H, W, False, device=input.device), 0, 4, 1, 2, 3
        )
        grid_global = jax_to_frnt_(grid_global, input.dtype)
        b: typing.Any = jax_spatial_gradient3d(input, order=1, mode="diff")
        b = jax_reshape_frnt_(jax_permute_frnt_(b, 0, 1, 3, 4, 5, 2), -1, 3, 1)
        A: typing.Any = jax_spatial_gradient3d(input, order=2, mode="diff")
        A = jax_reshape_frnt_(jax_permute_frnt_(A, 0, 1, 3, 4, 5, 2), -1, 6)
        dxx = A[..., 0]
        dyy = A[..., 1]
        dss = A[..., 2]
        dxy = 0.25 * A[..., 3]
        dys = 0.25 * A[..., 4]
        dxs = 0.25 * A[..., 5]
        Hes = jax_view_frnt_(
            stack([dxx, dxy, dxs, dxy, dyy, dys, dxs, dys, dss], -1), -1, 3, 3
        )
        if not jax_torch_version_ge(1, 10):
            Hes = (
                Hes
                + jax_abs_frnt_(rand(jax_size_frnt_(Hes[0]), device=Hes.device))[None] * eps
            )
        nms_mask: typing.Any = jax_nms3d(input, (3, 3, 3), True)
        x_solved: typing.Any = zeros_like(b)
>       x_solved_masked, _, solved_correctly = jax_safe_solve_with_mask(
            jax_get_item(b, jax_view_frnt_(nms_mask, -1)),
            jax_get_item(Hes, jax_view_frnt_(nms_mask, -1)),
        )

ivy_transpiled_outputs/jax_outputs/kornia/geometry/subpix/spatial_soft_argmax.py:90: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

B = Array([], shape=(0, 3, 1), dtype=float32), A = Array([], shape=(0, 3, 3), dtype=float32)

    def jax_safe_solve_with_mask(B, A):
        from ._compat import jax_torch_version_ge
        from ...ivy.functional.frontends.torch.creation_ops import jax_ones_frnt
        from ...ivy.functional.frontends.torch.linalg import jax_lu_factor_ex_frnt
        from ...ivy.functional.frontends.torch.tensor import jax_to_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_unsqueeze_frnt_
        from ...ivy.functional.frontends.torch.linalg import jax_lu_solve_frnt
        from ...ivy.functional.frontends.torch.miscellaneous_ops import (
            jax_lu_solve_frnt_base_count_1_frnt,
        )
        from ...ivy.functional.frontends.torch.linalg import lu
    
        if not jax_torch_version_ge(1, 10):
            sol = jax__torch_solve_cast(A, B)
            warnings.warn(
                "PyTorch version < 1.10, solve validness mask maybe not correct",
                RuntimeWarning,
            )
            return sol, sol, jax_ones_frnt(len(A), dtype=jnp.bool, device=A.device)
        if not isinstance(B, (jax.Array, nnx.Param)):
            raise AssertionError(f"B must be Tensor. Got: {type(B)}.")
        dtype: typing.Any = B.dtype
        if dtype not in (jnp.float32, jnp.float64):
            dtype = jnp.float32
        if TYPE_CHECKING:
            A_LU: typing.Any
            pivots: typing.Any
            info: typing.Any
        elif jax_torch_version_ge(1, 13):
>           A_LU, pivots, info = jax_lu_factor_ex_frnt(jax_to_frnt_(A, dtype))

ivy_transpiled_outputs/jax_outputs/kornia/utils/helpers.py:73: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

A = Array([], shape=(0, 3, 3), dtype=float32)

    def jax_lu_factor_ex_frnt(A, *, pivot=True, check_errors=False, out=None):
        from ...backends.jax.experimental.linear_algebra import jax_lu_factor
        from ...backends.jax.creation import jax_zeros
        from .tensor import jax_shape_frnt_
        from ...backends.jax.creation import jax_full_like
        from ...backends.jax.creation import jax_ones
    
        try:
>           LU, pivots = jax_lu_factor(A, pivot=pivot, out=out)

ivy_transpiled_outputs/jax_outputs/ivy/functional/frontends/torch/linalg.py:48: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = [Array([], shape=(0, 3, 3), dtype=float32)], kwargs = {'out': None, 'pivot': True}, jax_is_array_bknd = <function jax_is_array_bknd at 0x7fbea5cded40>
jax_set_item = <function jax_set_item at 0x7fbea5182170>, jax_asarray = <function jax_asarray at 0x7fbea5cdfbe0>, jax_get_item = <function jax_get_item at 0x7fbea5181fc0>, num_args = 1
type_hints = mappingproxy(OrderedDict([('x', <Parameter "x: jax.Array">), ('pivot', <Parameter "pivot: Optional[bool] = True">), ('out', <Parameter "out: Optional[jax.Array] = None">)]))
parameters = ['x', 'pivot', 'out'], annotations = [<class 'jax.Array'>, typing.Optional[bool], typing.Optional[jax.Array]], device = CpuDevice(id=0), i = 0

    @functools.wraps(fn)
    def _handle_array_like_without_promotion(*args, **kwargs):
        from .functional.ivy.general import jax_is_array_bknd
        from .functional.backends.jax.general import jax_set_item
        from .functional.backends.jax.creation import jax_asarray
        from .functional.backends.jax.general import jax_get_item
    
        args = list(args)
        num_args = len(args)
        try:
            type_hints = inspect.signature(fn).parameters
        except (TypeError, ValueError):
            return fn(*args, **kwargs)
        parameters = list(type_hints.keys())
        annotations = [param.annotation for param in type_hints.values()]
        device = jax__get_preferred_device(args, kwargs)
        for i, (annotation, parameter, arg) in enumerate(
            zip(annotations, parameters, args)
        ):
            annotation_str = str(annotation)
            if (
                ("rray" in annotation_str or "Tensor" in annotation_str)
                and parameter != "out"
                and all(
                    sq not in annotation_str
                    for sq in ["Sequence", "List", "Tuple", "float", "int", "bool"]
                )
            ):
                if i < num_args:
                    if arg is None or jax__check_in_nested_sequence(
                        arg, value=Ellipsis, _type=slice
                    ):
                        continue
                    if not jax_is_array_bknd(arg):
                        args = jax_set_item(args, i, jax_asarray(arg, device=device))
                elif parameters in kwargs:
                    kwarg = jax_get_item(kwargs, parameter)
                    if not jax_is_array_bknd(kwarg):
                        kwargs = jax_set_item(
                            kwargs, parameter, jax_asarray(kwarg, device=device)
                        )
>       return fn(*args, **kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/func_wrapper.py:130: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = Array([], shape=(0, 3, 3), dtype=float32)

    @jax_handle_array_like_without_promotion
    def jax_lu_factor(
        x: jax.Array, /, *, pivot: Optional[bool] = True, out: Optional[jax.Array] = None
    ):
>       ret = jax.scipy.linalg.lu(x)

ivy_transpiled_outputs/jax_outputs/ivy/functional/backends/jax/experimental/linear_algebra.py:38: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = Traced<ShapedArray(float32[0,3,3])>with<DynamicJaxprTrace(level=1/0)>, permute_l = False

    @partial(jit, static_argnames=('permute_l', 'overwrite_a', 'check_finite'))
    def lu(a: ArrayLike, permute_l: bool = False, overwrite_a: bool = False,
           check_finite: bool = True) -> tuple[Array, Array] | tuple[Array, Array, Array]:
      """Compute the LU decomposition
    
      JAX implementation of :func:`scipy.linalg.lu`.
    
      The LU decomposition of a matrix `A` is:
    
      .. math::
    
         A = P L U
    
      where `P` is a permutation matrix, `L` is lower-triangular and `U` is upper-triangular.
    
      Args:
        a: array of shape ``(..., M, N)`` to decompose.
        permute_l: if True, then permute ``L`` and return ``(P @ L, U)`` (default: False)
        overwrite_a: not used by JAX
        check_finite: not used by JAX
    
      Returns:
        A tuple of arrays ``(P @ L, U)`` if ``permute_l`` is True, else ``(P, L, U)``:
    
        - ``P`` is a permutation matrix of shape ``(..., M, M)``
        - ``L`` is a lower-triangular matrix of shape ``(... M, K)``
        - ``U`` is an upper-triangular matrix of shape ``(..., K, N)``
    
        with ``K = min(M, N)``
    
      See also:
        - :func:`jax.numpy.linalg.lu`: NumPy-style API for LU decomposition.
        - :func:`jax.lax.linalg.lu`: XLA-style API for LU decomposition.
        - :func:`jax.scipy.linalg.lu_solve`: LU-based linear solver.
    
      Examples:
        An LU decomposition of a 3x3 matrix:
    
        >>> a = jnp.array([[1., 2., 3.],
        ...                [5., 4., 2.],
        ...                [3., 2., 1.]])
        >>> P, L, U = jax.scipy.linalg.lu(a)
    
        ``P`` is a permutation matrix: i.e. each row and column has a single ``1``:
    
        >>> P
        Array([[0., 1., 0.],
               [1., 0., 0.],
               [0., 0., 1.]], dtype=float32)
    
        ``L`` and ``U`` are lower-triangular and upper-triangular matrices:
    
        >>> with jnp.printoptions(precision=3):
        ...   print(L)
        ...   print(U)
        [[ 1.     0.     0.   ]
         [ 0.2    1.     0.   ]
         [ 0.6   -0.333  1.   ]]
        [[5.    4.    2.   ]
         [0.    1.2   2.6  ]
         [0.    0.    0.667]]
    
        The original matrix can be reconstructed by multiplying the three together:
    
        >>> a_reconstructed = P @ L @ U
        >>> jnp.allclose(a, a_reconstructed)
        Array(True, dtype=bool)
      """
      del overwrite_a, check_finite  # unused
>     return _lu(a, permute_l)

/opt/fw/jax/jax/_src/scipy/linalg.py:821: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = Traced<ShapedArray(float32[0,3,3])>with<DynamicJaxprTrace(level=2/0)>, permute_l = False

    @partial(jit, static_argnums=(1,))
    def _lu(a: ArrayLike, permute_l: bool) -> tuple[Array, Array] | tuple[Array, Array, Array]:
      a, = promote_dtypes_inexact(jnp.asarray(a))
      lu, _, permutation = lax_linalg.lu(a)
      dtype = lax.dtype(a)
>     m, n = jnp.shape(a)
E     ValueError: too many values to unpack (expected 2)

/opt/fw/jax/jax/_src/scipy/linalg.py:729: ValueError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.subpix.spatial_soft_argmax.conv_quad_interp3d
_________________________________________________________________________________ test_ConvQuadInterp3d[jax-s2s-False] _________________________________________________________________________________
jax.errors.SimplifiedTraceback: For simplicity, JAX has removed its internal frames from the traceback of the following exception. Set JAX_TRACEBACK_FILTERING=off to include these.

The above exception was the direct cause of the following exception:

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_ConvQuadInterp3d(target_framework, mode, backend_compile):
        print("kornia.geometry.subpix.ConvQuadInterp3d")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledConvQuadInterp3d = ivy.transpile(
            kornia.geometry.subpix.ConvQuadInterp3d, source="torch", target=target_framework
        )
    
        conv_quad_interp3d = kornia.geometry.subpix.ConvQuadInterp3d()
        transpiled_conv_quad_interp3d = TranspiledConvQuadInterp3d()
    
        heatmap = torch.randn(1, 1, 3, 5, 5, requires_grad=True)
        transpiled_heatmap = _nest_torch_tensor_to_new_framework(heatmap, target_framework)
    
        torch_output = conv_quad_interp3d(heatmap)
>       transpiled_output = transpiled_conv_quad_interp3d(transpiled_heatmap)

kornia/geometry/test_subpix.py:371: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_ConvQuadInterp3d(strict_maxima_bonus=10.0)
x = Array([[[[[ 0.3293132 , -0.56167084, -0.10927603,  1.6270009 ,
            1.2201802 ],
          [-1.8945147 ,  2.001...0.39195493],
          [-0.8480544 ,  0.31802803, -0.55238676, -0.36239582,
           -0.97028   ]]]]], dtype=float32)

    def __call__(self, x):
>       return jax_conv_quad_interp3d(x, self.strict_maxima_bonus, self.eps)

ivy_transpiled_outputs/jax_outputs/kornia/geometry/subpix/spatial_soft_argmax.py:143: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = Array([[[[[ 0.3293132 , -0.56167084, -0.10927603,  1.6270009 ,
            1.2201802 ],
          [-1.8945147 ,  2.001...0.39195493],
          [-0.8480544 ,  0.31802803, -0.55238676, -0.36239582,
           -0.97028   ]]]]], dtype=float32)
strict_maxima_bonus = 10.0, eps = 1e-07

    def jax_conv_quad_interp3d(input, strict_maxima_bonus=10.0, eps=1e-07):
        from ...core._backend import stack
        from ...core._backend import rand
        from ...core._backend import zeros_like
        from ...core._backend import where
        from ....ivy.functional.frontends.torch.tensor_functions import jax_is_tensor_frnt_
        from ....ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ....ivy.functional.frontends.torch.tensor import jax_permute_frnt_
        from ...utils.grid import jax_create_meshgrid3d
        from ....ivy.functional.frontends.torch.tensor import jax_to_frnt_
        from ...filters.sobel import jax_spatial_gradient3d
        from ....ivy.functional.frontends.torch.tensor import jax_reshape_frnt_
        from ....ivy.functional.frontends.torch.tensor import jax_view_frnt_
        from ...utils._compat import jax_torch_version_ge
        from ....ivy.functional.frontends.torch.tensor import jax_abs_frnt_
        from ....ivy.functional.frontends.torch.tensor import jax_size_frnt_
        from .nms import jax_nms3d
        from ...utils.helpers import jax_safe_solve_with_mask
        from ....ivy.functional.backends.jax.general import jax_get_item
        from ....ivy.functional.frontends.torch.tensor import jax_masked_scatter_frnt_
        from ....ivy.functional.backends.jax.general import jax_set_item
        from ....ivy.functional.frontends.torch.tensor import jax_max_frnt_
        from ....ivy.functional.frontends.torch.tensor import jax_masked_fill__frnt_
        from ....ivy.functional.frontends.torch.tensor import jax_expand_as_frnt_
        from ....ivy.functional.frontends.torch.blas_and_lapack_ops import jax_bmm_frnt
        from ....ivy.functional.frontends.torch.tensor import jax_flip_frnt_
        from ....ivy.functional.frontends.torch.tensor import jax_unsqueeze_frnt_
        from ....ivy.functional.frontends.torch.tensor import jax_repeat_frnt_
    
        if not jax_is_tensor_frnt_(input):
            raise TypeError(f"Input type is not a Tensor. Got {type(input)}")
        if not len(jax_shape_frnt_(input)) == 5:
            raise ValueError(
                f"Invalid input shape, we expect BxCxDxHxW. Got: {jax_shape_frnt_(input)}"
            )
        B, CH, D, H, W = jax_shape_frnt_(input)
        grid_global: typing.Any = jax_permute_frnt_(
            jax_create_meshgrid3d(D, H, W, False, device=input.device), 0, 4, 1, 2, 3
        )
        grid_global = jax_to_frnt_(grid_global, input.dtype)
        b: typing.Any = jax_spatial_gradient3d(input, order=1, mode="diff")
        b = jax_reshape_frnt_(jax_permute_frnt_(b, 0, 1, 3, 4, 5, 2), -1, 3, 1)
        A: typing.Any = jax_spatial_gradient3d(input, order=2, mode="diff")
        A = jax_reshape_frnt_(jax_permute_frnt_(A, 0, 1, 3, 4, 5, 2), -1, 6)
        dxx = A[..., 0]
        dyy = A[..., 1]
        dss = A[..., 2]
        dxy = 0.25 * A[..., 3]
        dys = 0.25 * A[..., 4]
        dxs = 0.25 * A[..., 5]
        Hes = jax_view_frnt_(
            stack([dxx, dxy, dxs, dxy, dyy, dys, dxs, dys, dss], -1), -1, 3, 3
        )
        if not jax_torch_version_ge(1, 10):
            Hes = (
                Hes
                + jax_abs_frnt_(rand(jax_size_frnt_(Hes[0]), device=Hes.device))[None] * eps
            )
        nms_mask: typing.Any = jax_nms3d(input, (3, 3, 3), True)
        x_solved: typing.Any = zeros_like(b)
>       x_solved_masked, _, solved_correctly = jax_safe_solve_with_mask(
            jax_get_item(b, jax_view_frnt_(nms_mask, -1)),
            jax_get_item(Hes, jax_view_frnt_(nms_mask, -1)),
        )

ivy_transpiled_outputs/jax_outputs/kornia/geometry/subpix/spatial_soft_argmax.py:93: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

B = Array([], shape=(0, 3, 1), dtype=float32), A = Array([], shape=(0, 3, 3), dtype=float32)

    def jax_safe_solve_with_mask(B, A):
        from ._compat import jax_torch_version_ge
        from ...ivy.functional.frontends.torch.creation_ops import jax_ones_frnt
        from ...ivy.functional.frontends.torch.linalg import jax_lu_factor_ex_frnt
        from ...ivy.functional.frontends.torch.tensor import jax_to_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_unsqueeze_frnt_
        from ...ivy.functional.frontends.torch.linalg import jax_lu_solve_frnt
        from ...ivy.functional.frontends.torch.miscellaneous_ops import (
            jax_lu_solve_frnt_base_count_1_frnt,
        )
        from ...ivy.functional.frontends.torch.linalg import lu
    
        if not jax_torch_version_ge(1, 10):
            sol = jax__torch_solve_cast(A, B)
            warnings.warn(
                "PyTorch version < 1.10, solve validness mask maybe not correct",
                RuntimeWarning,
            )
            return sol, sol, jax_ones_frnt(len(A), dtype=jnp.bool, device=A.device)
        if not isinstance(B, (jax.Array, nnx.Param)):
            raise AssertionError(f"B must be Tensor. Got: {type(B)}.")
        dtype: typing.Any = B.dtype
        if dtype not in (jnp.float32, jnp.float64):
            dtype = jnp.float32
        if TYPE_CHECKING:
            A_LU: typing.Any
            pivots: typing.Any
            info: typing.Any
        elif jax_torch_version_ge(1, 13):
>           A_LU, pivots, info = jax_lu_factor_ex_frnt(jax_to_frnt_(A, dtype))

ivy_transpiled_outputs/jax_outputs/kornia/utils/helpers.py:73: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

A = Array([], shape=(0, 3, 3), dtype=float32)

    def jax_lu_factor_ex_frnt(A, *, pivot=True, check_errors=False, out=None):
        from ...backends.jax.experimental.linear_algebra import jax_lu_factor
        from ...backends.jax.creation import jax_zeros
        from .tensor import jax_shape_frnt_
        from ...backends.jax.creation import jax_full_like
        from ...backends.jax.creation import jax_ones
    
        try:
>           LU, pivots = jax_lu_factor(A, pivot=pivot, out=out)

ivy_transpiled_outputs/jax_outputs/ivy/functional/frontends/torch/linalg.py:48: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = [Array([], shape=(0, 3, 3), dtype=float32)], kwargs = {'out': None, 'pivot': True}, jax_is_array_bknd = <function jax_is_array_bknd at 0x7fbea4fbbbe0>
jax_set_item = <function jax_set_item at 0x7fbe9a52f010>, jax_asarray = <function jax_asarray at 0x7fbe9a52caf0>, jax_get_item = <function jax_get_item at 0x7fbe9a52ee60>, num_args = 1
type_hints = mappingproxy(OrderedDict([('x', <Parameter "x: jax.Array">), ('pivot', <Parameter "pivot: Optional[bool] = True">), ('out', <Parameter "out: Optional[jax.Array] = None">)]))
parameters = ['x', 'pivot', 'out'], annotations = [<class 'jax.Array'>, typing.Optional[bool], typing.Optional[jax.Array]], device = CpuDevice(id=0), i = 0

    @functools.wraps(fn)
    def _handle_array_like_without_promotion(*args, **kwargs):
        from .functional.ivy.general import jax_is_array_bknd
        from .functional.backends.jax.general import jax_set_item
        from .functional.backends.jax.creation import jax_asarray
        from .functional.backends.jax.general import jax_get_item
    
        args = list(args)
        num_args = len(args)
        try:
            type_hints = inspect.signature(fn).parameters
        except (TypeError, ValueError):
            return fn(*args, **kwargs)
        parameters = list(type_hints.keys())
        annotations = [param.annotation for param in type_hints.values()]
        device = jax__get_preferred_device(args, kwargs)
        for i, (annotation, parameter, arg) in enumerate(
            zip(annotations, parameters, args)
        ):
            annotation_str = str(annotation)
            if (
                ("rray" in annotation_str or "Tensor" in annotation_str)
                and parameter != "out"
                and all(
                    sq not in annotation_str
                    for sq in ["Sequence", "List", "Tuple", "float", "int", "bool"]
                )
            ):
                if i < num_args:
                    if arg is None or jax__check_in_nested_sequence(
                        arg, value=Ellipsis, _type=slice
                    ):
                        continue
                    if not jax_is_array_bknd(arg):
                        args = jax_set_item(args, i, jax_asarray(arg, device=device))
                elif parameters in kwargs:
                    kwarg = jax_get_item(kwargs, parameter)
                    if not jax_is_array_bknd(kwarg):
                        kwargs = jax_set_item(
                            kwargs, parameter, jax_asarray(kwarg, device=device)
                        )
>       return fn(*args, **kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/func_wrapper.py:130: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = Array([], shape=(0, 3, 3), dtype=float32)

    @jax_handle_array_like_without_promotion
    def jax_lu_factor(
        x: jax.Array, /, *, pivot: Optional[bool] = True, out: Optional[jax.Array] = None
    ):
>       ret = jax.scipy.linalg.lu(x)

ivy_transpiled_outputs/jax_outputs/ivy/functional/backends/jax/experimental/linear_algebra.py:38: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = Traced<ShapedArray(float32[0,3,3])>with<DynamicJaxprTrace(level=1/0)>, permute_l = False

    @partial(jit, static_argnames=('permute_l', 'overwrite_a', 'check_finite'))
    def lu(a: ArrayLike, permute_l: bool = False, overwrite_a: bool = False,
           check_finite: bool = True) -> tuple[Array, Array] | tuple[Array, Array, Array]:
      """Compute the LU decomposition
    
      JAX implementation of :func:`scipy.linalg.lu`.
    
      The LU decomposition of a matrix `A` is:
    
      .. math::
    
         A = P L U
    
      where `P` is a permutation matrix, `L` is lower-triangular and `U` is upper-triangular.
    
      Args:
        a: array of shape ``(..., M, N)`` to decompose.
        permute_l: if True, then permute ``L`` and return ``(P @ L, U)`` (default: False)
        overwrite_a: not used by JAX
        check_finite: not used by JAX
    
      Returns:
        A tuple of arrays ``(P @ L, U)`` if ``permute_l`` is True, else ``(P, L, U)``:
    
        - ``P`` is a permutation matrix of shape ``(..., M, M)``
        - ``L`` is a lower-triangular matrix of shape ``(... M, K)``
        - ``U`` is an upper-triangular matrix of shape ``(..., K, N)``
    
        with ``K = min(M, N)``
    
      See also:
        - :func:`jax.numpy.linalg.lu`: NumPy-style API for LU decomposition.
        - :func:`jax.lax.linalg.lu`: XLA-style API for LU decomposition.
        - :func:`jax.scipy.linalg.lu_solve`: LU-based linear solver.
    
      Examples:
        An LU decomposition of a 3x3 matrix:
    
        >>> a = jnp.array([[1., 2., 3.],
        ...                [5., 4., 2.],
        ...                [3., 2., 1.]])
        >>> P, L, U = jax.scipy.linalg.lu(a)
    
        ``P`` is a permutation matrix: i.e. each row and column has a single ``1``:
    
        >>> P
        Array([[0., 1., 0.],
               [1., 0., 0.],
               [0., 0., 1.]], dtype=float32)
    
        ``L`` and ``U`` are lower-triangular and upper-triangular matrices:
    
        >>> with jnp.printoptions(precision=3):
        ...   print(L)
        ...   print(U)
        [[ 1.     0.     0.   ]
         [ 0.2    1.     0.   ]
         [ 0.6   -0.333  1.   ]]
        [[5.    4.    2.   ]
         [0.    1.2   2.6  ]
         [0.    0.    0.667]]
    
        The original matrix can be reconstructed by multiplying the three together:
    
        >>> a_reconstructed = P @ L @ U
        >>> jnp.allclose(a, a_reconstructed)
        Array(True, dtype=bool)
      """
      del overwrite_a, check_finite  # unused
>     return _lu(a, permute_l)

/opt/fw/jax/jax/_src/scipy/linalg.py:821: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = Traced<ShapedArray(float32[0,3,3])>with<DynamicJaxprTrace(level=2/0)>, permute_l = False

    @partial(jit, static_argnums=(1,))
    def _lu(a: ArrayLike, permute_l: bool) -> tuple[Array, Array] | tuple[Array, Array, Array]:
      a, = promote_dtypes_inexact(jnp.asarray(a))
      lu, _, permutation = lax_linalg.lu(a)
      dtype = lax.dtype(a)
>     m, n = jnp.shape(a)
E     ValueError: too many values to unpack (expected 2)

/opt/fw/jax/jax/_src/scipy/linalg.py:729: ValueError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.subpix.ConvQuadInterp3d
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/geometry/test_subpix.py::test_conv_quad_interp3d[jax-s2s-False] - ValueError: too many values to unpack (expected 2)
FAILED kornia/geometry/test_subpix.py::test_ConvQuadInterp3d[jax-s2s-False] - ValueError: too many values to unpack (expected 2)
============================================================================== 2 failed, 13 passed in 1174.30s (0:19:34) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 56 items

kornia/geometry/test_transform.py ........................................ssssssssssssssss                                                                                                       [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
============================================================================= 40 passed, 16 skipped in 3171.68s (0:52:51) ==============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 19 items

kornia/test_feature1.py .....F.............                                                                                                                                                      [100%]

=============================================================================================== FAILURES ===============================================================================================
______________________________________________________________________________ test_get_laf_descriptors[numpy-s2s-False] _______________________________________________________________________________

target_framework = 'numpy', mode = 's2s', backend_compile = False

    def test_get_laf_descriptors(target_framework, mode, backend_compile):
        trace_args = (
            torch.rand(1, 1, 32, 32),
            torch.rand(1, 3, 2, 3),
            kornia.feature.OriNet(pretrained=False),
        )
        trace_kwargs = {'patch_size': 32, 'grayscale_descriptor': True}
        test_args = (
            torch.rand(5, 1, 32, 32),
            torch.rand(5, 3, 2, 3),
            kornia.feature.OriNet(pretrained=False),
        )
        test_kwargs = {'patch_size': 32, 'grayscale_descriptor': True}
        class_info = {
            'trace_args': {
                2: {'object': kornia.feature.OriNet, 'kwargs': {'pretrained': False}}
            },
            'test_args': {
                2: {'object': kornia.feature.OriNet, 'kwargs': {'pretrained': False}}
            }
        }
>       _test_function(
            kornia.feature.get_laf_descriptors,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
            class_info=class_info,
        )

kornia/test_feature1.py:148: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function get_laf_descriptors at 0x7f385f7ab9a0>
trace_args = (tensor([[[[0.5325, 0.7194, 0.9930,  ..., 0.8600, 0.4352, 0.3176],
          [0.0463, 0.3929, 0.0022,  ..., 0.6447, 0...., kernel_size=(8, 8), stride=(1, 1), padding=(1, 1))
    (20): Tanh()
    (21): AdaptiveAvgPool2d(output_size=1)
  )
))
trace_kwargs = {'grayscale_descriptor': True, 'patch_size': 32}
test_args = (tensor([[[[0.4047, 0.3532, 0.1141,  ..., 0.4308, 0.9728, 0.0121],
          [0.7250, 0.4126, 0.2431,  ..., 0.3248, 0...., kernel_size=(8, 8), stride=(1, 1), padding=(1, 1))
    (20): Tanh()
    (21): AdaptiveAvgPool2d(output_size=1)
  )
))
test_kwargs = {'grayscale_descriptor': True, 'patch_size': 32}, target = 'numpy', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = True
class_info = {'test_args': {2: {'kwargs': {'pretrained': False}, 'object': <class 'kornia.feature.orientation.OriNet'>}}, 'trace_args': {2: {'kwargs': {'pretrained': False}, 'object': <class 'kornia.feature.orientation.OriNet'>}}}

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function get_laf_descriptors at 0x7f385f7ab9a0>, fn_name = 'kornia.feature.get_laf_descriptors'
trace_args = (tensor([[[[0.5325, 0.7194, 0.9930,  ..., 0.8600, 0.4352, 0.3176],
          [0.0463, 0.3929, 0.0022,  ..., 0.6447, 0...., kernel_size=(8, 8), stride=(1, 1), padding=(1, 1))
    (20): Tanh()
    (21): AdaptiveAvgPool2d(output_size=1)
  )
))
trace_kwargs = {'grayscale_descriptor': True, 'patch_size': 32}
test_args = (tensor([[[[0.4047, 0.3532, 0.1141,  ..., 0.4308, 0.9728, 0.0121],
          [0.7250, 0.4126, 0.2431,  ..., 0.3248, 0...., kernel_size=(8, 8), stride=(1, 1), padding=(1, 1))
    (20): Tanh()
    (21): AdaptiveAvgPool2d(output_size=1)
  )
))
test_kwargs = {'grayscale_descriptor': True, 'patch_size': 32}, target = 'numpy', backend_compile = False, tolerance = 0.001, deterministic = True
class_info = {'test_args': {2: {'kwargs': {'pretrained': False}, 'object': <class 'kornia.feature.orientation.OriNet'>}}, 'trace_args': {2: {'kwargs': {'pretrained': False}, 'object': <class 'kornia.feature.orientation.OriNet'>}}}

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
>       transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]

helpers.py:305: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

.0 = <enumerate object at 0x7f38054bfcc0>

    transpiled_trace_args = [
>       transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
        for i, arg in enumerate(trace_args)
    ]

helpers.py:306: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

arg = OriNet(
  (features): Sequential(
    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False...2, kernel_size=(8, 8), stride=(1, 1), padding=(1, 1))
    (20): Tanh()
    (21): AdaptiveAvgPool2d(output_size=1)
  )
)
arg_class_info = {'kwargs': {'pretrained': False}, 'object': <class 'kornia.feature.orientation.OriNet'>}

    def transpile_and_instantiate(arg, arg_class_info=None):
        if arg_class_info:
            # If we have class info, transpile the class and instantiate it
>           transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)

helpers.py:277: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

object = <class 'kornia.feature.orientation.OriNet'>, source = 'torch', target = 'numpy', reuse_existing = True

    def transpile(
        object,
        source: str = "torch",
        target: str = "tensorflow",
        reuse_existing: bool = True,
    ):
        """Converts a given object (class/function) from one framework to another.
    
        This function performs source-to-source translation of a given object from the source framework
        to the target framework.
    
        The object can be translated between two frameworks or between the Ivy IR as well
        e.g. (source="torch_frontend", target="ivy") or (source="torch_frontend", target="tensorflow") etc.
    
        Args:
            object: The object (class/function) to be translated.
            source (str, optional): The source framework. Defaults to 'torch'.
            target (str, optional): The target framework. Defaults to 'tensorflow'.
            reuse_existing (bool, optional): If True, the function will check if `object`
                                             already exists in the translated directory and reuse it.
                                             If False, it will re-translate `object`,
                                             even if it already exists in the directory, and overwrite
                                             the old implementation. Defaults to 'True'.
    
        Returns:
            The translated object."""
    
        from ._compiler import transpile as _transpile
    
>       return _transpile(
            object=object,
            source=source,
            target=target,
            reuse_existing=reuse_existing,
        )

../ivy/ivy/compiler/compiler.py:201: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   ivy.utils.exceptions.IvyException: Cannot transpile the object '<class 'ivy_transpiled_outputs.ivy_outputs.kornia.feature.orientation.ivy_OriNet'>' to `numpy` because it is an instance of a stateful class.

IXC.pyx:379: IvyException
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.integrated.get_laf_descriptors
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/test_feature1.py::test_get_laf_descriptors[numpy-s2s-False] - ivy.utils.exceptions.IvyException: Cannot transpile the object '<class 'ivy_transpiled_outputs.ivy_outputs.kornia.feature...
============================================================================== 1 failed, 18 passed in 1257.73s (0:20:57) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 69 items

kornia/test_color.py ...........F...........F......F.............F...........F.....F..F..F                                                                                                       [100%]

=============================================================================================== FAILURES ===============================================================================================
________________________________________________________________________________ test_rgb_to_hls[tensorflow-s2s-False] _________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_rgb_to_hls(target_framework, mode, backend_compile):
        # Note: We test this function with requires_grad=True,
        # because otherwise we simply get an empty_like tensor
        # with garbage values on each run leading to test failures
        trace_args = (
            torch.rand(1, 3, 4, 5).requires_grad_(True),
        )
        trace_kwargs = {'eps': 1e-8}
        test_args = (
            torch.rand(5, 3, 4, 5).requires_grad_(True),
        )
        test_kwargs = {'eps': 1e-8}
>       _test_function(
            kornia.color.rgb_to_hls,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/test_color.py:291: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function rgb_to_hls at 0x7fb1640a9ea0>
trace_args = (tensor([[[[0.5408, 0.0417, 0.3484, 0.2410, 0.8113],
          [0.1273, 0.7962, 0.6929, 0.7667, 0.4819],
          [0.... [0.9709, 0.4254, 0.3291, 0.3478, 0.1697],
          [0.6040, 0.1861, 0.0961, 0.8094, 0.9323]]]], requires_grad=True),)
trace_kwargs = {'eps': 1e-08}
test_args = (tensor([[[[0.3539, 0.4949, 0.9628, 0.9754, 0.6948],
          [0.3619, 0.3763, 0.1023, 0.5479, 0.1037],
          [0.... [0.9377, 0.5472, 0.3077, 0.7601, 0.3242],
          [0.2274, 0.2213, 0.5934, 0.7291, 0.3052]]]], requires_grad=True),)
test_kwargs = {'eps': 1e-08}, target = 'tensorflow', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function rgb_to_hls at 0x7fb1640a9ea0>, fn_name = 'kornia.color.rgb_to_hls'
trace_args = (tensor([[[[0.5408, 0.0417, 0.3484, 0.2410, 0.8113],
          [0.1273, 0.7962, 0.6929, 0.7667, 0.4819],
          [0.... [0.9709, 0.4254, 0.3291, 0.3478, 0.1697],
          [0.6040, 0.1861, 0.0961, 0.8094, 0.9323]]]], requires_grad=True),)
trace_kwargs = {'eps': 1e-08}
test_args = (tensor([[[[0.3539, 0.4949, 0.9628, 0.9754, 0.6948],
          [0.3619, 0.3763, 0.1023, 0.5479, 0.1037],
          [0.... [0.9377, 0.5472, 0.3077, 0.7601, 0.3242],
          [0.2274, 0.2213, 0.5934, 0.7291, 0.3052]]]], requires_grad=True),)
test_kwargs = {'eps': 1e-08}, target = 'tensorflow', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
        graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
    
        if deterministic:
>           _to_numpy_and_allclose(orig_out, graph_out, tolerance=tolerance)

helpers.py:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

torch_x = tensor([[[[4.1832, 3.5214, 4.0212, 4.3638, 0.4355],
          [2.9562, 5.8235, 5.0350, 5.3114, 3.4034],
          [3.5....8974, 0.9995, 0.7748, 0.9252],
          [0.8914, 0.4880, 0.5421, 0.9461, 0.8552]]]],
       grad_fn=<StackBackward0>)
transpiled_x = <tf.Tensor: shape=(1, 3, 4, 5), dtype=float32, numpy=
array([[[[0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.],
  ...., 0.],
         [0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.]]]], dtype=float32)>
tolerance = 0.001

    def _to_numpy_and_allclose(torch_x, transpiled_x, tolerance=1e-3):
        orig_data = _nest_array_to_numpy(torch_x)
        transpiled_data = _nest_array_to_numpy(transpiled_x)
>       _check_allclose(orig_data, transpiled_data, tolerance=tolerance)

helpers.py:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[[4.1831713 , 3.5213804 , 4.021176  , 4.363828  , 0.4355208 ],
         [2.9562278 , 5.823467  , 5.0349703 , 5...0.7747781 , 0.92518187],
         [0.89141744, 0.4879821 , 0.5420506 , 0.9460663 , 0.8551538 ]]]],
      dtype=float32)
y = array([[[[0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.],
         [0., 0., 0., 0.,...0., 0.],
         [0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.]]]], dtype=float32)
tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
>           assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
E           AssertionError: numpy array values are not all close

helpers.py:26: AssertionError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.color.hls.rgb_to_hls
_______________________________________________________________________________ test_rgb_to_yuv420[tensorflow-s2s-False] _______________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_rgb_to_yuv420(target_framework, mode, backend_compile):
        trace_args = (
            torch.rand(1, 3, 4, 6),
        )
        trace_kwargs = {}
        test_args = (
            torch.rand(5, 3, 4, 6),
        )
        test_kwargs = {}
>       _test_function(
            kornia.color.rgb_to_yuv420,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/test_color.py:559: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function rgb_to_yuv420 at 0x7fb1640abbe0>
trace_args = (tensor([[[[0.9400, 0.1728, 0.9366, 0.7602, 0.3668, 0.5448],
          [0.5414, 0.1813, 0.8720, 0.6796, 0.4667, 0.9975...     [0.2980, 0.2968, 0.8972, 0.1957, 0.4514, 0.5927],
          [0.7752, 0.5338, 0.8428, 0.8996, 0.1890, 0.7455]]]]),)
trace_kwargs = {}
test_args = (tensor([[[[0.5862, 0.0629, 0.7951, 0.9270, 0.2799, 0.0307],
          [0.8671, 0.1064, 0.9914, 0.0837, 0.7687, 0.9708...     [0.6131, 0.2835, 0.1486, 0.6383, 0.6344, 0.0436],
          [0.9006, 0.3152, 0.7988, 0.0411, 0.0277, 0.3945]]]]),)
test_kwargs = {}, target = 'tensorflow', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function rgb_to_yuv420 at 0x7fb1640abbe0>, fn_name = 'kornia.color.rgb_to_yuv420'
trace_args = (tensor([[[[0.9400, 0.1728, 0.9366, 0.7602, 0.3668, 0.5448],
          [0.5414, 0.1813, 0.8720, 0.6796, 0.4667, 0.9975...     [0.2980, 0.2968, 0.8972, 0.1957, 0.4514, 0.5927],
          [0.7752, 0.5338, 0.8428, 0.8996, 0.1890, 0.7455]]]]),)
trace_kwargs = {}
test_args = (tensor([[[[0.5862, 0.0629, 0.7951, 0.9270, 0.2799, 0.0307],
          [0.8671, 0.1064, 0.9914, 0.0837, 0.7687, 0.9708...     [0.6131, 0.2835, 0.1486, 0.6383, 0.6344, 0.0436],
          [0.9006, 0.3152, 0.7988, 0.0411, 0.0277, 0.3945]]]]),)
test_kwargs = {}, target = 'tensorflow', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
        graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
    
        if deterministic:
>           _to_numpy_and_allclose(orig_out, graph_out, tolerance=tolerance)

helpers.py:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

torch_x = (tensor([[[[0.5396, 0.3840, 0.5470, 0.8662, 0.4434, 0.7362],
          [0.2576, 0.2558, 0.5389, 0.8877, 0.5734, 0.8685...       [-0.0098,  0.1630, -0.1389]],

         [[ 0.0874,  0.0896, -0.0539],
          [ 0.0371, -0.1697, -0.0897]]]]))
transpiled_x = (<tf.Tensor: shape=(1, 1, 4, 6), dtype=float32, numpy=
array([[[[0.53958744, 0.38399878, 0.54699385, 0.8661614 , 0.443...        [[ 0.21935143, -0.11842278, -0.07851572],
         [ 0.04517327, -0.08036526, -0.08643068]]]], dtype=float32)>)
tolerance = 0.001

    def _to_numpy_and_allclose(torch_x, transpiled_x, tolerance=1e-3):
        orig_data = _nest_array_to_numpy(torch_x)
        transpiled_data = _nest_array_to_numpy(transpiled_x)
>       _check_allclose(orig_data, transpiled_data, tolerance=tolerance)

helpers.py:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = (array([[[[0.53958744, 0.38399878, 0.54699385, 0.8661614 , 0.44343397,
          0.73621166],
         [0.2575644 , 0....
        [[ 0.08739973,  0.08962996, -0.05391151],
         [ 0.03706746, -0.1697306 , -0.08966477]]]], dtype=float32))
y = (array([[[[0.53958744, 0.38399878, 0.54699385, 0.8661614 , 0.44343397,
          0.73621166],
         [0.2575644 , 0....
        [[ 0.21935143, -0.11842278, -0.07851572],
         [ 0.04517327, -0.08036526, -0.08643068]]]], dtype=float32))
tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
            assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
            return
    
        if isinstance(x, (list, set, tuple)):
>           all([
                _check_allclose(element_x, element_y, tolerance=tolerance) for element_x, element_y in zip(x, y)
            ])

helpers.py:30: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

.0 = <zip object at 0x7fb0ec9a0180>

    all([
>       _check_allclose(element_x, element_y, tolerance=tolerance) for element_x, element_y in zip(x, y)
    ])

helpers.py:31: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[[ 0.03918256, -0.07600781, -0.14126602],
         [-0.00982377,  0.16299856, -0.13889807]],

        [[ 0.08739973,  0.08962996, -0.05391151],
         [ 0.03706746, -0.1697306 , -0.08966477]]]], dtype=float32)
y = array([[[[-0.06972153, -0.15952143, -0.04803651],
         [ 0.14206906, -0.01030605, -0.01829811]],

        [[ 0.21935143, -0.11842278, -0.07851572],
         [ 0.04517327, -0.08036526, -0.08643068]]]], dtype=float32)
tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
>           assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
E           AssertionError: numpy array values are not all close

helpers.py:26: AssertionError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.color.yuv.rgb_to_yuv420
________________________________________________________________________________ test_raw_to_rgb[tensorflow-s2s-False] _________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_raw_to_rgb(target_framework, mode, backend_compile):
        print("kornia.color.raw_to_rgb")
    
        transpiled_raw_to_rgb = ivy.transpile(kornia.color.raw_to_rgb, source="torch", target=target_framework)
        TranspiledCFA = ivy.transpile(kornia.color.CFA, source="torch", target=target_framework)
    
        torch_x = torch.rand(5, 1, 4, 6)
        transpiled_x = _array_to_new_backend(torch_x, target_framework)
    
        torch_out = kornia.color.raw_to_rgb(torch_x, kornia.color.CFA.RG)
        transpiled_out = transpiled_raw_to_rgb(transpiled_x, TranspiledCFA.RG)
    
>       _to_numpy_and_allclose(torch_out, transpiled_out)

kornia/test_color.py:713: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

torch_x = tensor([[[[0.2686, 0.2686, 0.3848, 0.5010, 0.6395, 0.7780],
          [0.2686, 0.2686, 0.3848, 0.5010, 0.6395, 0.7780]...       [0.1795, 0.2241, 0.2686, 0.3303, 0.3920, 0.3920],
          [0.1795, 0.2241, 0.2686, 0.3303, 0.3920, 0.3920]]]])
transpiled_x = <tf.Tensor: shape=(5, 3, 4, 6), dtype=float32, numpy=
array([[[[0.26857853, 0.26857853, 0.3847693 , 0.5207483 , 0.6790...9605 ],
         [0.17949241, 0.21132118, 0.26224717, 0.3302867 , 0.3919605 ,
          0.3919605 ]]]], dtype=float32)>
tolerance = 0.001

    def _to_numpy_and_allclose(torch_x, transpiled_x, tolerance=1e-3):
        orig_data = _nest_array_to_numpy(torch_x)
        transpiled_data = _nest_array_to_numpy(transpiled_x)
>       _check_allclose(orig_data, transpiled_data, tolerance=tolerance)

helpers.py:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[[0.26857853, 0.26857853, 0.38476932, 0.50096005, 0.63947755,
          0.77799505],
         [0.26857853, 0.2...19605 ],
         [0.17949241, 0.22405267, 0.26861292, 0.3302867 , 0.3919605 ,
          0.3919605 ]]]], dtype=float32)
y = array([[[[0.26857853, 0.26857853, 0.3847693 , 0.5207483 , 0.679054  ,
          0.77799505],
         [0.26857853, 0.2...19605 ],
         [0.17949241, 0.21132118, 0.26224717, 0.3302867 , 0.3919605 ,
          0.3919605 ]]]], dtype=float32)
tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
>           assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
E           AssertionError: numpy array values are not all close

helpers.py:26: AssertionError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.color.raw_to_rgb
_________________________________________________________________________________ test_RgbToHls[tensorflow-s2s-False] __________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_RgbToHls(target_framework, mode, backend_compile):
        args = (
            torch.rand(2, 3, 4, 5),
        )
>       _test_color_class(
            kornia.color.RgbToHls,
            args,
            target_framework,
            backend_compile,
            tolerance=1e-3,
        )

kornia/test_color.py:908: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'kornia.color.hls.RgbToHls'>
args = (tensor([[[[0.8433, 0.8507, 0.7723, 0.4468, 0.8076],
          [0.3349, 0.6034, 0.8988, 0.2577, 0.4487],
          [0...., 0.4669],
          [0.1810, 0.2306, 0.2596, 0.5588, 0.6131],
          [0.3789, 0.5773, 0.2288, 0.6582, 0.1438]]]]),)
target = 'tensorflow', backend_compile = False, tolerance = 0.001, init_args = ()

    def _test_color_class(
        cls,
        args,
        target,
        backend_compile=False,
        tolerance=1e-3,
        init_args=(),
    ):
        print(f"{cls.__module__}.{cls.__name__}")
    
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
    
        torch_obj = cls(*init_args)
        transpiled_obj = eval("transpiled_" + f"{cls.__module__}.{cls.__name__}")(*init_args)
    
        torch_out = torch_obj(*args)
        transpile_args = _nest_torch_tensor_to_new_framework(args, target)
        transpiled_out = transpiled_obj(*transpile_args)
    
        orig_np = _nest_array_to_numpy(torch_out)
        graph_np = _nest_array_to_numpy(transpiled_out)
    
>       _check_allclose(orig_np, graph_np, tolerance=tolerance)

kornia/test_color.py:43: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[[5.5137224 , 5.6921444 , 1.0979587 , 4.6499453 , 0.21075553],
         [1.7106203 , 4.801522  , 0.8547037 , 3...0.3565204 , 0.05374902],
         [0.5230487 , 0.48568007, 0.6658483 , 0.12572253, 0.83771116]]]],
      dtype=float32)
y = array([[[[0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.],
         [0., 0., 0., 0.,...0., 0.],
         [0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.]]]], dtype=float32)
tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
>           assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
E           AssertionError: numpy array values are not all close

helpers.py:26: AssertionError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.color.hls.RgbToHls
________________________________________________________________________________ test_RgbToYuv420[tensorflow-s2s-False] ________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_RgbToYuv420(target_framework, mode, backend_compile):
        args = (
            torch.rand(2, 3, 4, 6),
        )
>       _test_color_class(
            kornia.color.RgbToYuv420,
            args,
            target_framework,
            backend_compile,
            tolerance=1e-3,
        )

kornia/test_color.py:1064: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'kornia.color.yuv.RgbToYuv420'>
args = (tensor([[[[0.5125, 0.5815, 0.9226, 0.2209, 0.8530, 0.9536],
          [0.7203, 0.6274, 0.9464, 0.2382, 0.8096, 0.1753...     [0.2497, 0.5052, 0.3115, 0.2503, 0.5798, 0.7851],
          [0.0379, 0.6264, 0.8318, 0.3844, 0.1113, 0.8504]]]]),)
target = 'tensorflow', backend_compile = False, tolerance = 0.001, init_args = ()

    def _test_color_class(
        cls,
        args,
        target,
        backend_compile=False,
        tolerance=1e-3,
        init_args=(),
    ):
        print(f"{cls.__module__}.{cls.__name__}")
    
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
    
        torch_obj = cls(*init_args)
        transpiled_obj = eval("transpiled_" + f"{cls.__module__}.{cls.__name__}")(*init_args)
    
        torch_out = torch_obj(*args)
        transpile_args = _nest_torch_tensor_to_new_framework(args, target)
        transpiled_out = transpiled_obj(*transpile_args)
    
        orig_np = _nest_array_to_numpy(torch_out)
        graph_np = _nest_array_to_numpy(transpiled_out)
    
>       _check_allclose(orig_np, graph_np, tolerance=tolerance)

kornia/test_color.py:43: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = (array([[[[0.7038454 , 0.5961757 , 0.34123027, 0.67485195, 0.42295477,
          0.68221104],
         [0.39316684, 0....
        [[ 0.07947345,  0.13307956,  0.02390089],
         [ 0.1187121 , -0.05786043, -0.11214044]]]], dtype=float32))
y = (array([[[[0.7038454 , 0.5961757 , 0.34123027, 0.67485195, 0.42295477,
          0.68221104],
         [0.39316684, 0....
        [[ 0.19704518, -0.03373517,  0.02945124],
         [-0.12249363,  0.1319958 , -0.0170983 ]]]], dtype=float32))
tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
            assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
            return
    
        if isinstance(x, (list, set, tuple)):
>           all([
                _check_allclose(element_x, element_y, tolerance=tolerance) for element_x, element_y in zip(x, y)
            ])

helpers.py:30: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

.0 = <zip object at 0x7fb0d916b840>

    all([
>       _check_allclose(element_x, element_y, tolerance=tolerance) for element_x, element_y in zip(x, y)
    ])

helpers.py:31: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[[-0.10340762, -0.10428397,  0.02198511],
         [-0.05543281, -0.0706791 ,  0.01118141]],

        [[-0.006...

        [[ 0.07947345,  0.13307956,  0.02390089],
         [ 0.1187121 , -0.05786043, -0.11214044]]]], dtype=float32)
y = array([[[[-0.01444233, -0.08448534, -0.07533159],
         [-0.12951341, -0.03108347,  0.03421916]],

        [[ 0.160...

        [[ 0.19704518, -0.03373517,  0.02945124],
         [-0.12249363,  0.1319958 , -0.0170983 ]]]], dtype=float32)
tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
>           assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
E           AssertionError: numpy array values are not all close

helpers.py:26: AssertionError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.color.yuv.RgbToYuv420
_________________________________________________________________________________ test_RawToRgb[tensorflow-s2s-False] __________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_RawToRgb(target_framework, mode, backend_compile):
        print("kornia.color.RawToRgb")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_RawToRgb = ivy.transpile(kornia.color.RawToRgb, source="torch", target=target_framework)
        TranspiledCFA = ivy.transpile(kornia.color.CFA, source="torch", target=target_framework)
    
        torch_x = torch.rand(2, 1, 4, 6)
        transpiled_x = _array_to_new_backend(torch_x, target_framework)
    
        torch_out = kornia.color.RawToRgb(kornia.color.CFA.RG)(torch_x)
        transpiled_out = transpiled_RawToRgb(TranspiledCFA.RG)(transpiled_x)
    
>       _to_numpy_and_allclose(torch_out, transpiled_out)

kornia/test_color.py:1155: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

torch_x = tensor([[[[0.6979, 0.6979, 0.7707, 0.8435, 0.7825, 0.7215],
          [0.6979, 0.6979, 0.7707, 0.8435, 0.7825, 0.7215]...       [0.1967, 0.2943, 0.3918, 0.5926, 0.7933, 0.7933],
          [0.1967, 0.2943, 0.3918, 0.5926, 0.7933, 0.7933]]]])
transpiled_x = <tf.Tensor: shape=(2, 3, 4, 6), dtype=float32, numpy=
array([[[[0.69787914, 0.69787914, 0.7706978 , 0.8347976 , 0.7650...31344],
         [0.19669002, 0.2663763 , 0.3778743 , 0.5925625 , 0.79331344,
          0.79331344]]]], dtype=float32)>
tolerance = 0.001

    def _to_numpy_and_allclose(torch_x, transpiled_x, tolerance=1e-3):
        orig_data = _nest_array_to_numpy(torch_x)
        transpiled_data = _nest_array_to_numpy(transpiled_x)
>       _check_allclose(orig_data, transpiled_data, tolerance=tolerance)

helpers.py:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[[0.69787914, 0.69787914, 0.7706978 , 0.8435164 , 0.78248507,
          0.7214537 ],
         [0.69787914, 0.6...331344],
         [0.19669002, 0.2942508 , 0.39181155, 0.5925625 , 0.79331344,
          0.79331344]]]], dtype=float32)
y = array([[[[0.69787914, 0.69787914, 0.7706978 , 0.8347976 , 0.76504755,
          0.7214537 ],
         [0.69787914, 0.6...331344],
         [0.19669002, 0.2663763 , 0.3778743 , 0.5925625 , 0.79331344,
          0.79331344]]]], dtype=float32)
tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
>           assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
E           AssertionError: numpy array values are not all close

helpers.py:26: AssertionError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.color.RawToRgb
___________________________________________________________________________________ test_Sepia[tensorflow-s2s-False] ___________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_Sepia(target_framework, mode, backend_compile):
        args = (
            torch.ones(3, 1, 1),
        )
>       _test_color_class(
            kornia.color.Sepia,
            args,
            target_framework,
            backend_compile,
            tolerance=1e-3,
        )

kornia/test_color.py:1198: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'kornia.color.sepia.Sepia'>, args = (tensor([[[1.]],

        [[1.]],

        [[1.]]]),), target = 'tensorflow', backend_compile = False, tolerance = 0.001, init_args = ()

    def _test_color_class(
        cls,
        args,
        target,
        backend_compile=False,
        tolerance=1e-3,
        init_args=(),
    ):
        print(f"{cls.__module__}.{cls.__name__}")
    
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
    
        torch_obj = cls(*init_args)
>       transpiled_obj = eval("transpiled_" + f"{cls.__module__}.{cls.__name__}")(*init_args)

kornia/test_color.py:34: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   AttributeError: '_cython_3_0_11.cython_function_or_method' object has no attribute 'Sepia'

<string>:1: AttributeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.color.sepia.Sepia
______________________________________________________________________________ test_apply_colormap[tensorflow-s2s-False] _______________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_apply_colormap(target_framework, mode, backend_compile):
        print("kornia.color.ColorMap")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledColorMapType = ivy.transpile(kornia.color.ColorMapType, source="torch", target=target_framework)
        TranspiledColorMap = ivy.transpile(kornia.color.ColorMap, source="torch", target=target_framework)
        transpiled_apply_colormap = ivy.transpile(kornia.color.apply_colormap, source="torch", target=target_framework)
    
        torch_x = torch.tensor([[[0, 1, 2], [15, 25, 33], [128, 158, 188]]])
        transpiled_x = _array_to_new_backend(torch_x, target_framework)
    
        colormap = kornia.color.ColorMap(base=kornia.color.ColorMapType.autumn)
        torch_out = kornia.color.apply_colormap(torch_x, colormap)
    
>       colormap = TranspiledColorMap(base=TranspiledColorMapType.autumn)

kornia/test_color.py:1258: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <ivy_transpiled_outputs.tensorflow_outputs.kornia.color.colormap.tensorflow_ColorMap object at 0x7fb0ec850dc0>, base = <tensorflow_ColorMapType.autumn: 1>, num_colors = 64, device = None
dtype = None

>   ???

ivy_transpiled_outputs/tensorflow_outputs/kornia/color/colormap.py:124: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <tensorflow_ColorMapType.autumn: 1>

        f"`input_tensor` must be a Tensor. Got: {type(input_tensor)}",
    )
>   valid_types = [
        tf.float16,
        tf.float32,
        tf.float64,
        tf.uint8,
        tf.int32,
        tf.int64,
        tf.int16,
    ]
E   ModuleNotFoundError: No module named 'ivy_transpiled_outputs.tensorflow_outputs.kornia.color._colormap_data'

ivy_transpiled_outputs/tensorflow_outputs/kornia/color/colormap.py:56: ModuleNotFoundError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.color.ColorMap
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/test_color.py::test_rgb_to_hls[tensorflow-s2s-False] - AssertionError: numpy array values are not all close
FAILED kornia/test_color.py::test_rgb_to_yuv420[tensorflow-s2s-False] - AssertionError: numpy array values are not all close
FAILED kornia/test_color.py::test_raw_to_rgb[tensorflow-s2s-False] - AssertionError: numpy array values are not all close
FAILED kornia/test_color.py::test_RgbToHls[tensorflow-s2s-False] - AssertionError: numpy array values are not all close
FAILED kornia/test_color.py::test_RgbToYuv420[tensorflow-s2s-False] - AssertionError: numpy array values are not all close
FAILED kornia/test_color.py::test_RawToRgb[tensorflow-s2s-False] - AssertionError: numpy array values are not all close
FAILED kornia/test_color.py::test_Sepia[tensorflow-s2s-False] - AttributeError: '_cython_3_0_11.cython_function_or_method' object has no attribute 'Sepia'
FAILED kornia/test_color.py::test_apply_colormap[tensorflow-s2s-False] - ModuleNotFoundError: No module named 'ivy_transpiled_outputs.tensorflow_outputs.kornia.color._colormap_data'
============================================================================== 8 failed, 61 passed in 3831.79s (1:03:51) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 1 item

kornia/geometry/test_ransac.py .                                                                                                                                                                 [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
==================================================================================== 1 passed in 166.80s (0:02:46) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 1 item

kornia/test_tracking.py s                                                                                                                                                                        [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
========================================================================================== 1 skipped in 4.93s ==========================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 13 items

kornia/test_utils.py .............                                                                                                                                                               [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
==================================================================================== 13 passed in 787.18s (0:13:07) ====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 7 items

kornia/test_morphology.py .......                                                                                                                                                                [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
==================================================================================== 7 passed in 478.37s (0:07:58) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 35 items

kornia/test_losses.py .................ssssssssssssssssss                                                                                                                                        [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
============================================================================= 17 passed, 18 skipped in 1005.23s (0:16:45) ==============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 15 items

kornia/geometry/test_subpix.py .FF....FFssssss                                                                                                                                                   [100%]

=============================================================================================== FAILURES ===============================================================================================
_______________________________________________________________________________ test_conv_soft_argmax3d[numpy-s2s-False] _______________________________________________________________________________

target_framework = 'numpy', mode = 's2s', backend_compile = False

    def test_conv_soft_argmax3d(target_framework, mode, backend_compile):
        trace_args = (
            torch.rand(20, 16, 3, 50, 32),
        )
        trace_kwargs = {
            'kernel_size': (3, 3, 3),
            'stride': (1, 1, 1),
            'padding': (1, 1, 1),
            'temperature': torch.tensor(1.0),
            'normalized_coordinates': False,
            'eps': 1e-8,
            'output_value': True,
            'strict_maxima_bonus': 0.0,
        }
        test_args = (
            torch.rand(10, 16, 5, 50, 32),
        )
        test_kwargs = {
            'kernel_size': (3, 3, 3),
            'stride': (1, 1, 1),
            'padding': (1, 1, 1),
            'temperature': torch.tensor(0.5),
            'normalized_coordinates': False,
            'eps': 1e-8,
            'output_value': True,
            'strict_maxima_bonus': 0.0,
        }
>       _test_function(
            kornia.geometry.subpix.conv_soft_argmax3d,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/geometry/test_subpix.py:81: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function conv_soft_argmax3d at 0x7fc291f38b80>
trace_args = (tensor([[[[[7.7565e-01, 4.5463e-01, 9.7462e-01,  ..., 3.0597e-01,
            2.0631e-01, 8.4810e-01],
           [4....7364e-01],
           [6.2830e-01, 3.8780e-01, 7.3759e-01,  ..., 7.0106e-01,
            1.0336e-01, 8.0057e-01]]]]]),)
trace_kwargs = {'eps': 1e-08, 'kernel_size': (3, 3, 3), 'normalized_coordinates': False, 'output_value': True, ...}
test_args = (tensor([[[[[2.4680e-02, 9.1644e-01, 7.2392e-01,  ..., 6.7319e-01,
            8.8058e-01, 9.0530e-01],
           [2....6462e-02],
           [4.8262e-01, 4.9258e-01, 6.3304e-02,  ..., 1.5036e-01,
            5.2747e-01, 5.0650e-01]]]]]),)
test_kwargs = {'eps': 1e-08, 'kernel_size': (3, 3, 3), 'normalized_coordinates': False, 'output_value': True, ...}, target = 'numpy', backend_compile = False, tolerance = 0.001, mode = 's2s'
skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function conv_soft_argmax3d at 0x7fc291f38b80>, fn_name = 'kornia.geometry.subpix.conv_soft_argmax3d'
trace_args = (tensor([[[[[7.7565e-01, 4.5463e-01, 9.7462e-01,  ..., 3.0597e-01,
            2.0631e-01, 8.4810e-01],
           [4....7364e-01],
           [6.2830e-01, 3.8780e-01, 7.3759e-01,  ..., 7.0106e-01,
            1.0336e-01, 8.0057e-01]]]]]),)
trace_kwargs = {'eps': 1e-08, 'kernel_size': (3, 3, 3), 'normalized_coordinates': False, 'output_value': True, ...}
test_args = (tensor([[[[[2.4680e-02, 9.1644e-01, 7.2392e-01,  ..., 6.7319e-01,
            8.8058e-01, 9.0530e-01],
           [2....6462e-02],
           [4.8262e-01, 4.9258e-01, 6.3304e-02,  ..., 1.5036e-01,
            5.2747e-01, 5.0650e-01]]]]]),)
test_kwargs = {'eps': 1e-08, 'kernel_size': (3, 3, 3), 'normalized_coordinates': False, 'output_value': True, ...}, target = 'numpy', backend_compile = False, tolerance = 0.001, deterministic = True
class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:136: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   ivy.utils.exceptions.IvyException: Cannot transpile the object '<class 'ivy_transpiled_outputs.ivy_outputs.kornia.geometry.subpix.nms.ivy_NonMaximaSuppression3d'>' to `numpy` because it is an instance of a stateful class.

IXC.pyx:379: IvyException
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.subpix.spatial_soft_argmax.conv_soft_argmax3d
_______________________________________________________________________________ test_conv_quad_interp3d[numpy-s2s-False] _______________________________________________________________________________

target_framework = 'numpy', mode = 's2s', backend_compile = False

    def test_conv_quad_interp3d(target_framework, mode, backend_compile):
        trace_args = (
            torch.rand(2, 2, 2, 5, 5),
        )
        trace_kwargs = {
            'strict_maxima_bonus': 10.0,
            'eps': 1e-7,
        }
        test_args = (
            torch.rand(1, 2, 2, 5, 5),
        )
        test_kwargs = {
            'strict_maxima_bonus': 5.0,
            'eps': 1e-7,
        }
>       _test_function(
            kornia.geometry.subpix.conv_quad_interp3d,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/geometry/test_subpix.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function conv_quad_interp3d at 0x7fc291f38ca0>
trace_args = (tensor([[[[[1.4944e-01, 5.4964e-01, 8.4463e-01, 2.2058e-01, 9.4558e-01],
           [7.2606e-01, 9.7544e-01, 8.4881e-...01, 2.7456e-01, 7.5240e-01, 4.7866e-01],
           [9.5522e-04, 3.0940e-01, 3.9712e-01, 5.4734e-01, 1.6927e-02]]]]]),)
trace_kwargs = {'eps': 1e-07, 'strict_maxima_bonus': 10.0}
test_args = (tensor([[[[[0.7850, 0.8668, 0.7101, 0.2452, 0.0057],
           [0.3635, 0.5452, 0.9480, 0.7099, 0.1305],
           ....9528],
           [0.5554, 0.1480, 0.0554, 0.2853, 0.3056],
           [0.0182, 0.3062, 0.9637, 0.8291, 0.9562]]]]]),)
test_kwargs = {'eps': 1e-07, 'strict_maxima_bonus': 5.0}, target = 'numpy', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function conv_quad_interp3d at 0x7fc291f38ca0>, fn_name = 'kornia.geometry.subpix.conv_quad_interp3d'
trace_args = (tensor([[[[[1.4944e-01, 5.4964e-01, 8.4463e-01, 2.2058e-01, 9.4558e-01],
           [7.2606e-01, 9.7544e-01, 8.4881e-...01, 2.7456e-01, 7.5240e-01, 4.7866e-01],
           [9.5522e-04, 3.0940e-01, 3.9712e-01, 5.4734e-01, 1.6927e-02]]]]]),)
trace_kwargs = {'eps': 1e-07, 'strict_maxima_bonus': 10.0}
test_args = (tensor([[[[[0.7850, 0.8668, 0.7101, 0.2452, 0.0057],
           [0.3635, 0.5452, 0.9480, 0.7099, 0.1305],
           ....9528],
           [0.5554, 0.1480, 0.0554, 0.2853, 0.3056],
           [0.0182, 0.3062, 0.9637, 0.8291, 0.9562]]]]]),)
test_kwargs = {'eps': 1e-07, 'strict_maxima_bonus': 5.0}, target = 'numpy', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:136: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   ivy.utils.exceptions.IvyException: Cannot transpile the object '<class 'ivy_transpiled_outputs.ivy_outputs.kornia.geometry.subpix.nms.ivy_NonMaximaSuppression3d'>' to `numpy` because it is an instance of a stateful class.

IXC.pyx:379: IvyException
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.subpix.spatial_soft_argmax.conv_quad_interp3d
_____________________________________________________________________________________ test_nms2d[numpy-s2s-False] ______________________________________________________________________________________

target_framework = 'numpy', mode = 's2s', backend_compile = False

    def test_nms2d(target_framework, mode, backend_compile):
        trace_args = (
            torch.rand(1, 1, 5, 5),
            (3, 3),
        )
        trace_kwargs = {
            'mask_only': False,
        }
        test_args = (
            torch.rand(10, 1, 5, 5),
            (3, 3),
        )
        test_kwargs = {
            'mask_only': False,
        }
>       _test_function(
            kornia.geometry.subpix.nms2d,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/geometry/test_subpix.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function nms2d at 0x7fc29211be20>
trace_args = (tensor([[[[0.9538, 0.7489, 0.9602, 0.2401, 0.4841],
          [0.0566, 0.2689, 0.7183, 0.6226, 0.6257],
          [0....0],
          [0.5666, 0.3673, 0.0602, 0.3276, 0.3646],
          [0.7153, 0.4376, 0.5524, 0.1536, 0.1308]]]]), (3, 3))
trace_kwargs = {'mask_only': False}
test_args = (tensor([[[[0.8606, 0.5563, 0.1505, 0.1531, 0.0789],
          [0.3333, 0.7413, 0.2530, 0.8321, 0.6610],
          [0....1],
          [0.3947, 0.7001, 0.4571, 0.9460, 0.1846],
          [0.5389, 0.1384, 0.1603, 0.2842, 0.7644]]]]), (3, 3))
test_kwargs = {'mask_only': False}, target = 'numpy', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function nms2d at 0x7fc29211be20>, fn_name = 'kornia.geometry.subpix.nms2d'
trace_args = (tensor([[[[0.9538, 0.7489, 0.9602, 0.2401, 0.4841],
          [0.0566, 0.2689, 0.7183, 0.6226, 0.6257],
          [0....0],
          [0.5666, 0.3673, 0.0602, 0.3276, 0.3646],
          [0.7153, 0.4376, 0.5524, 0.1536, 0.1308]]]]), (3, 3))
trace_kwargs = {'mask_only': False}
test_args = (tensor([[[[0.8606, 0.5563, 0.1505, 0.1531, 0.0789],
          [0.3333, 0.7413, 0.2530, 0.8321, 0.6610],
          [0....1],
          [0.3947, 0.7001, 0.4571, 0.9460, 0.1846],
          [0.5389, 0.1384, 0.1603, 0.2842, 0.7644]]]]), (3, 3))
test_kwargs = {'mask_only': False}, target = 'numpy', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:136: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   ivy.utils.exceptions.IvyException: Cannot transpile the object '<class 'ivy_transpiled_outputs.ivy_outputs.kornia.geometry.subpix.nms.ivy_NonMaximaSuppression2d'>' to `numpy` because it is an instance of a stateful class.

IXC.pyx:379: IvyException
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.subpix.nms.nms2d
_____________________________________________________________________________________ test_nms3d[numpy-s2s-False] ______________________________________________________________________________________

target_framework = 'numpy', mode = 's2s', backend_compile = False

    def test_nms3d(target_framework, mode, backend_compile):
        trace_args = (
            torch.rand(1, 1, 5, 5, 5),
            (3, 3, 3),
        )
        trace_kwargs = {
            'mask_only': False,
        }
        test_args = (
            torch.rand(10, 1, 5, 5, 5),
            (3, 3, 3),
        )
        test_kwargs = {
            'mask_only': False,
        }
>       _test_function(
            kornia.geometry.subpix.nms3d,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/geometry/test_subpix.py:275: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function nms3d at 0x7fc291f38280>
trace_args = (tensor([[[[[4.6394e-01, 4.4524e-01, 5.0110e-01, 5.8581e-02, 7.3100e-01],
           [7.0705e-02, 5.7215e-01, 5.8923e-...e-01, 1.6326e-01, 5.8499e-01],
           [3.5965e-01, 8.0455e-01, 3.3763e-01, 2.5304e-01, 7.3483e-01]]]]]), (3, 3, 3))
trace_kwargs = {'mask_only': False}
test_args = (tensor([[[[[0.9652, 0.6201, 0.4787, 0.1663, 0.2366],
           [0.6115, 0.3878, 0.4521, 0.5919, 0.4999],
           ...         [0.3455, 0.5963, 0.4730, 0.2847, 0.0125],
           [0.3103, 0.0237, 0.1364, 0.1908, 0.8531]]]]]), (3, 3, 3))
test_kwargs = {'mask_only': False}, target = 'numpy', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function nms3d at 0x7fc291f38280>, fn_name = 'kornia.geometry.subpix.nms3d'
trace_args = (tensor([[[[[4.6394e-01, 4.4524e-01, 5.0110e-01, 5.8581e-02, 7.3100e-01],
           [7.0705e-02, 5.7215e-01, 5.8923e-...e-01, 1.6326e-01, 5.8499e-01],
           [3.5965e-01, 8.0455e-01, 3.3763e-01, 2.5304e-01, 7.3483e-01]]]]]), (3, 3, 3))
trace_kwargs = {'mask_only': False}
test_args = (tensor([[[[[0.9652, 0.6201, 0.4787, 0.1663, 0.2366],
           [0.6115, 0.3878, 0.4521, 0.5919, 0.4999],
           ...         [0.3455, 0.5963, 0.4730, 0.2847, 0.0125],
           [0.3103, 0.0237, 0.1364, 0.1908, 0.8531]]]]]), (3, 3, 3))
test_kwargs = {'mask_only': False}, target = 'numpy', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:136: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   ivy.utils.exceptions.IvyException: Cannot transpile the object '<class 'ivy_transpiled_outputs.ivy_outputs.kornia.geometry.subpix.nms.ivy_NonMaximaSuppression3d'>' to `numpy` because it is an instance of a stateful class.

IXC.pyx:379: IvyException
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.subpix.nms.nms3d
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/geometry/test_subpix.py::test_conv_soft_argmax3d[numpy-s2s-False] - ivy.utils.exceptions.IvyException: Cannot transpile the object '<class 'ivy_transpiled_outputs.ivy_outputs.kornia.g...
FAILED kornia/geometry/test_subpix.py::test_conv_quad_interp3d[numpy-s2s-False] - ivy.utils.exceptions.IvyException: Cannot transpile the object '<class 'ivy_transpiled_outputs.ivy_outputs.kornia.g...
FAILED kornia/geometry/test_subpix.py::test_nms2d[numpy-s2s-False] - ivy.utils.exceptions.IvyException: Cannot transpile the object '<class 'ivy_transpiled_outputs.ivy_outputs.kornia.geometry.subpi...
FAILED kornia/geometry/test_subpix.py::test_nms3d[numpy-s2s-False] - ivy.utils.exceptions.IvyException: Cannot transpile the object '<class 'ivy_transpiled_outputs.ivy_outputs.kornia.geometry.subpi...
========================================================================== 4 failed, 5 passed, 6 skipped in 623.63s (0:10:23) ==========================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 19 items

kornia/geometry/test_camera.py ...................                                                                                                                                               [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
=================================================================================== 19 passed in 1100.07s (0:18:20) ====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 1 item

kornia/test_tracking.py F                                                                                                                                                                        [100%]

=============================================================================================== FAILURES ===============================================================================================
________________________________________________________________________________ test_HomographyTracker[jax-s2s-False] _________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_HomographyTracker(target_framework, mode, backend_compile):
        print("kornia.tracking.HomographyTracker")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledHomographyTracker = ivy.transpile(kornia.tracking.HomographyTracker, source="torch", target=target_framework)
    
        tracker = kornia.tracking.HomographyTracker()
>       transpiled_tracker = TranspiledHomographyTracker()

kornia/test_tracking.py:33: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.tracking.planar_tracker.jax_HomographyTracker'>, args = (), kwargs = {}

    def __call__(cls, *args: Any, **kwargs: Any) -> Any:
>     return _graph_node_meta_call(cls, *args, **kwargs)

/opt/fw/jax/flax/nnx/nnx/object.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.tracking.planar_tracker.jax_HomographyTracker'>, args = (), kwargs = {}
node = jax_HomographyTracker(
  (initial_matcher): jax_LocalFeatureMatcher(
    (local_feature): jax_GFTTAffNetHardNet(
     ...alse, 
        )
      ), patch_size=32, grayscale_descriptor='True)
    )
    (matcher): jax_DescriptorMatcher()
  )
)

    def _graph_node_meta_call(cls: tp.Type[G], *args, **kwargs) -> G:
      node = cls.__new__(cls, *args, **kwargs)
      vars(node)['_object__state'] = ObjectState()
>     cls._object_meta_construct(node, *args, **kwargs)

/opt/fw/jax/flax/nnx/nnx/object.py:88: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.tracking.planar_tracker.jax_HomographyTracker'>
self = jax_HomographyTracker(
  (initial_matcher): jax_LocalFeatureMatcher(
    (local_feature): jax_GFTTAffNetHardNet(
     ...alse, 
        )
      ), patch_size=32, grayscale_descriptor='True)
    )
    (matcher): jax_DescriptorMatcher()
  )
)
args = (), kwargs = {}

    def _object_meta_construct(cls, self, *args, **kwargs):
>     self.__init__(*args, **kwargs)

/opt/fw/jax/flax/nnx/nnx/object.py:82: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_HomographyTracker(
  (initial_matcher): jax_LocalFeatureMatcher(
    (local_feature): jax_GFTTAffNetHardNet(
     ...alse, 
        )
      ), patch_size=32, grayscale_descriptor='True)
    )
    (matcher): jax_DescriptorMatcher()
  )
)
initial_matcher = None, fast_matcher = None, ransac = None, minimum_inliers_num = 30

    def __init__(
        self,
        initial_matcher=None,
        fast_matcher=None,
        ransac=None,
        minimum_inliers_num=30,
    ):
        from ..feature.integrated import jax_LocalFeatureMatcher
        from ..feature.integrated import jax_GFTTAffNetHardNet
        from ..feature.matching import jax_DescriptorMatcher
        from ..feature.loftr.loftr import jax_LoFTR
        from ..geometry.ransac import jax_RANSAC
    
        self.super___init__(
            initial_matcher=initial_matcher,
            fast_matcher=fast_matcher,
            ransac=ransac,
            minimum_inliers_num=minimum_inliers_num,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        self.initial_matcher = initial_matcher or jax_LocalFeatureMatcher(
            jax_GFTTAffNetHardNet(3000), jax_DescriptorMatcher("smnn", 0.95)
        )
>       self.fast_matcher = fast_matcher or jax_LoFTR("outdoor")

ivy_transpiled_outputs/jax_outputs/kornia/tracking/planar_tracker.py:59: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.loftr.loftr.jax_LoFTR'>, args = ('outdoor',), kwargs = {}

    def __call__(cls, *args: Any, **kwargs: Any) -> Any:
>     return _graph_node_meta_call(cls, *args, **kwargs)

/opt/fw/jax/flax/nnx/nnx/object.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.loftr.loftr.jax_LoFTR'>, args = ('outdoor',), kwargs = {}, node = jax_LoFTR()

    def _graph_node_meta_call(cls: tp.Type[G], *args, **kwargs) -> G:
      node = cls.__new__(cls, *args, **kwargs)
      vars(node)['_object__state'] = ObjectState()
>     cls._object_meta_construct(node, *args, **kwargs)

/opt/fw/jax/flax/nnx/nnx/object.py:88: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.loftr.loftr.jax_LoFTR'>, self = jax_LoFTR(), args = ('outdoor',), kwargs = {}

    def _object_meta_construct(cls, self, *args, **kwargs):
>     self.__init__(*args, **kwargs)

/opt/fw/jax/flax/nnx/nnx/object.py:82: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_LoFTR(), args = ('outdoor',), kwargs = {}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/utils/decorator_utils.py:245: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_LoFTR(), pretrained = 'outdoor'
config = {'backbone_type': 'ResNetFPN', 'coarse': {'attention': 'linear', 'd_ffn': 256, 'd_model': 256, 'layer_names': ['self',...: 'linear', 'd_ffn': 128, 'd_model': 128, 'layer_names': ['self', 'cross'], ...}, 'fine_concat_coarse_feat': True, ...}

    @jax_store_config_info
    def __init__(self, pretrained="outdoor", config=default_cfg):
        from ....ivy.functional.backends.jax.general import jax_set_item
        from .backbone.__init__ import jax_build_backbone
        from .utils.position_encoding import jax_PositionEncodingSine
        from .loftr_module.transformer import jax_LocalFeatureTransformer
        from .utils.coarse_matching import jax_CoarseMatching
        from .loftr_module.fine_preprocess import jax_FinePreprocess
        from .utils.fine_matching import jax_FineMatching
        from ....ivy.functional.frontends.torch.hub.hub import (
            jax_load_state_dict_from_url_frnt,
        )
        from ....ivy.functional.backends.jax.general import jax_get_item
        from ...utils.helpers import jax_map_location_to_cpu
    
        self.super___init__(
            pretrained=pretrained,
            config=config,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        self.config = config
        if pretrained == "indoor_new":
            self.config["coarse"] = jax_set_item(
                self.config["coarse"], "temp_bug_fix", True
            )
>       self.backbone = jax_build_backbone(config)

ivy_transpiled_outputs/jax_outputs/kornia/feature/loftr/loftr.py:110: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

config = {'backbone_type': 'ResNetFPN', 'coarse': {'attention': 'linear', 'd_ffn': 256, 'd_model': 256, 'layer_names': ['self',...: 'linear', 'd_ffn': 128, 'd_model': 128, 'layer_names': ['self', 'cross'], ...}, 'fine_concat_coarse_feat': True, ...}

    def jax_build_backbone(config):
        if config["backbone_type"] == "ResNetFPN":
            if config["resolution"] == (8, 2):
>               return kornia.feature.loftr.resnet_fpn.ResNetFPN_8_2(config["resnetfpn"])
E               NameError: name 'kornia' is not defined

ivy_transpiled_outputs/jax_outputs/kornia/feature/loftr/backbone/__init__.py:42: NameError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.tracking.HomographyTracker
----------------------------------------------------------------------------------------- Captured stderr call -----------------------------------------------------------------------------------------
Downloading: "https://github.com/ducha-aiki/affnet/raw/master/pretrained/AffNet.pth" to /root/.cache/torch/hub/checkpoints/AffNet.pth

  0%|          | 0.00/332k [00:00<?, ?B/s]
100%|| 332k/332k [00:00<00:00, 20.3MB/s]
Downloading: "https://github.com/DagnyT/hardnet/raw/master/pretrained/train_liberty_with_aug/checkpoint_liberty_with_aug.pth" to /root/.cache/torch/hub/checkpoints/checkpoint_liberty_with_aug.pth

  0%|          | 0.00/5.10M [00:00<?, ?B/s]
100%|| 5.10M/5.10M [00:00<00:00, 116MB/s]
Downloading: "http://cmp.felk.cvut.cz/~mishkdmy/models/loftr_outdoor.ckpt" to /root/.cache/torch/hub/checkpoints/loftr_outdoor.ckpt

  0%|          | 0.00/44.2M [00:00<?, ?B/s]
  0%|          | 128k/44.2M [00:00<01:47, 432kB/s]
  1%|          | 256k/44.2M [00:00<01:04, 710kB/s]
  1%|          | 512k/44.2M [00:00<00:35, 1.30MB/s]
  2%|         | 896k/44.2M [00:00<00:21, 2.11MB/s]
  4%|         | 1.75M/44.2M [00:00<00:10, 4.25MB/s]
  8%|         | 3.50M/44.2M [00:00<00:05, 8.49MB/s]
 15%|        | 6.50M/44.2M [00:00<00:02, 15.4MB/s]
 21%|        | 9.38M/44.2M [00:01<00:01, 19.7MB/s]
 28%|       | 12.4M/44.2M [00:01<00:01, 23.1MB/s]
 34%|      | 15.1M/44.2M [00:01<00:01, 24.7MB/s]
 41%|      | 18.1M/44.2M [00:01<00:01, 26.6MB/s]
 48%|     | 21.1M/44.2M [00:01<00:00, 27.9MB/s]
 54%|    | 24.0M/44.2M [00:01<00:00, 28.6MB/s]
 61%|    | 27.0M/44.2M [00:01<00:00, 29.3MB/s]
 68%|   | 30.0M/44.2M [00:01<00:00, 29.8MB/s]
 74%|  | 32.9M/44.2M [00:01<00:00, 29.9MB/s]
 81%|  | 35.9M/44.2M [00:01<00:00, 30.2MB/s]
 88%| | 38.9M/44.2M [00:02<00:00, 30.5MB/s]
 95%|| 41.9M/44.2M [00:02<00:00, 30.7MB/s]
100%|| 44.2M/44.2M [00:02<00:00, 21.6MB/s]
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/test_tracking.py::test_HomographyTracker[jax-s2s-False] - NameError: name 'kornia' is not defined
==================================================================================== 1 failed in 467.80s (0:07:47) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 13 items

kornia/test_metrics.py ...F.........                                                                                                                                                             [100%]

=============================================================================================== FAILURES ===============================================================================================
__________________________________________________________________________ test_mean_average_precision[tensorflow-s2s-False] ___________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_mean_average_precision(target_framework, mode, backend_compile):
        trace_args = (
            [torch.tensor([[100, 50, 150, 100.]])],
            [torch.tensor([1.])],
            [torch.tensor([0.7])],
            [torch.tensor([[100, 50, 150, 100.]])],
            [torch.tensor([1.])],
            2,
        )
        trace_kwargs = {}
        test_args = (
            [torch.tensor([[50, 25, 75, 50], [100, 50, 150, 100.]])],
            [torch.tensor([1, 2.])],
            [torch.tensor([0.6, 0.8])],
            [torch.tensor([[50, 25, 75, 50], [100, 50, 150, 100.]])],
            [torch.tensor([1, 2.])],
            3,
        )
        kornia.metrics.mean_average_precision(*trace_args)
        kornia.metrics.mean_average_precision(*test_args)
        test_kwargs = {}
    
        # NOTE: this test fails due to the use of dynamic control flow; skipping
>       _test_function(
            kornia.metrics.mean_average_precision,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
            skip=True,
        )

kornia/test_metrics.py:118: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function mean_average_precision at 0x7fa1882cca60>
trace_args = ([<tf.Tensor: shape=(1, 4), dtype=float32, numpy=array([[100.,  50., 150., 100.]], dtype=float32)>], [<tf.Tensor: shap....,  50., 150., 100.]], dtype=float32)>], [<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>], 2)
trace_kwargs = {}
test_args = ([<tf.Tensor: shape=(2, 4), dtype=float32, numpy=
array([[ 50.,  25.,  75.,  50.],
       [100.,  50., 150., 100.]], d...50., 150., 100.]], dtype=float32)>], [<tf.Tensor: shape=(2,), dtype=float32, numpy=array([1., 2.], dtype=float32)>], 3)
test_kwargs = {}, target = 'tensorflow', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = True, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function mean_average_precision at 0x7fa1882cca60>, fn_name = 'kornia.metrics.mean_average_precision'
trace_args = ([<tf.Tensor: shape=(1, 4), dtype=float32, numpy=array([[100.,  50., 150., 100.]], dtype=float32)>], [<tf.Tensor: shap....,  50., 150., 100.]], dtype=float32)>], [<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>], 2)
trace_kwargs = {}
test_args = ([<tf.Tensor: shape=(2, 4), dtype=float32, numpy=
array([[ 50.,  25.,  75.,  50.],
       [100.,  50., 150., 100.]], d...50., 150., 100.]], dtype=float32)>], [<tf.Tensor: shape=(2,), dtype=float32, numpy=array([1., 2.], dtype=float32)>], 3)
test_kwargs = {}, target = 'tensorflow', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
>       orig_out = fn(*trace_args, **trace_kwargs)

helpers.py:335: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred_boxes = [<tf.Tensor: shape=(1, 4), dtype=float32, numpy=array([[100.,  50., 150., 100.]], dtype=float32)>]
pred_labels = [<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>], pred_scores = [<tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.7], dtype=float32)>]
gt_boxes = [<tf.Tensor: shape=(1, 4), dtype=float32, numpy=array([[100.,  50., 150., 100.]], dtype=float32)>], gt_labels = [<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>]
n_classes = 2, threshold = 0.5

    def mean_average_precision(
        pred_boxes: List[Tensor],
        pred_labels: List[Tensor],
        pred_scores: List[Tensor],
        gt_boxes: List[Tensor],
        gt_labels: List[Tensor],
        n_classes: int,
        threshold: float = 0.5,
    ) -> Tuple[Tensor, Dict[int, float]]:
        """Calculate the Mean Average Precision (mAP) of detected objects.
    
        Code altered from https://github.com/sgrvinod/a-PyTorch-Tutorial-to-Object-Detection/blob/master/utils.py#L271.
        Background class (0 index) is excluded.
    
        Args:
            pred_boxes: a tensor list of predicted bounding boxes.
            pred_labels: a tensor list of predicted labels.
            pred_scores: a tensor list of predicted labels' scores.
            gt_boxes: a tensor list of ground truth bounding boxes.
            gt_labels: a tensor list of ground truth labels.
            n_classes: the number of classes.
            threshold: count as a positive if the overlap is greater than the threshold.
    
        Returns:
            mean average precision (mAP), list of average precisions for each class.
    
        Examples:
            >>> boxes, labels, scores = torch.tensor([[100, 50, 150, 100.]]), torch.tensor([1]), torch.tensor([.7])
            >>> gt_boxes, gt_labels = torch.tensor([[100, 50, 150, 100.]]), torch.tensor([1])
            >>> mean_average_precision([boxes], [labels], [scores], [gt_boxes], [gt_labels], 2)
            (tensor(1.), {1: 1.0})
        """
        # these are all lists of tensors of the same length, i.e. number of images
        if not len(pred_boxes) == len(pred_labels) == len(pred_scores) == len(gt_boxes) == len(gt_labels):
            raise AssertionError
    
        # Store all (true) objects in a single continuous tensor while keeping track of the image it is from
        gt_images = []
        for i, labels in enumerate(gt_labels):
>           gt_images.extend([i] * labels.size(0))
E           TypeError: 'numpy.int64' object is not callable

/opt/miniconda/envs/multienv/lib/python3.10/site-packages/kornia/metrics/mean_average_precision.py:49: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.metrics.mean_average_precision.mean_average_precision
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/test_metrics.py::test_mean_average_precision[tensorflow-s2s-False] - TypeError: 'numpy.int64' object is not callable
=============================================================================== 1 failed, 12 passed in 814.64s (0:13:34) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 5 items

kornia/geometry/test_calibration.py ....F                                                                                                                                                        [100%]

=============================================================================================== FAILURES ===============================================================================================
_______________________________________________________________________________ test_solve_pnp_dlt[tensorflow-s2s-False] _______________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_solve_pnp_dlt(target_framework, mode, backend_compile):
        trace_args = (
            torch.tensor([[
                [5.0, -5.0, 0.0], [0.0, 0.0, 1.5],
                [2.5, 3.0, 6.0], [9.0, -2.0, 3.0],
                [-4.0, 5.0, 2.0], [-5.0, 5.0, 1.0]
            ]], dtype=torch.float64),
            torch.tensor([[
                [1409.1504, -800.936], [407.0207, -182.1229],
                [392.7021, 177.9428], [1016.838, -2.9416],
                [-63.1116, 142.9204], [-219.3874, 99.666]
            ]], dtype=torch.float64),
            torch.tensor([[
                [500.0, 0.0, 250.0],
                [0.0, 500.0, 250.0],
                [0.0, 0.0, 1.0]
            ]], dtype=torch.float64),
        )
        trace_kwargs = {'svd_eps': 1e-3}
        test_args = (
            torch.tensor([[
                [10.0, -10.0, 0.0], [0.0, 0.0, 3.0],
                [5.0, 6.0, 12.0], [18.0, -4.0, 6.0],
                [-8.0, 10.0, 4.0], [-10.0, 10.0, 2.0]
            ]], dtype=torch.float64),
            torch.tensor([[
                [2818.3008, -1601.872], [814.0414, -364.2458],
                [785.4042, 355.8856], [2033.676, -5.8832],
                [-126.2232, 285.8408], [-438.7748, 199.332]
            ]], dtype=torch.float64),
            torch.tensor([[
                [1000.0, 0.0, 500.0],
                [0.0, 1000.0, 500.0],
                [0.0, 0.0, 1.0]
            ]], dtype=torch.float64),
        )
        test_kwargs = {'svd_eps': 1e-3}
>       _test_function(
            kornia.geometry.calibration.solve_pnp_dlt,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/geometry/test_calibration.py:148: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function solve_pnp_dlt at 0x7fc4d4a3e950>
trace_args = (tensor([[[ 5.0000, -5.0000,  0.0000],
         [ 0.0000,  0.0000,  1.5000],
         [ 2.5000,  3.0000,  6.0000],
   ...loat64), tensor([[[500.,   0., 250.],
         [  0., 500., 250.],
         [  0.,   0.,   1.]]], dtype=torch.float64))
trace_kwargs = {'svd_eps': 0.001}
test_args = (tensor([[[ 10., -10.,   0.],
         [  0.,   0.,   3.],
         [  5.,   6.,  12.],
         [ 18.,  -4.,   6.],
 ...tensor([[[1000.,    0.,  500.],
         [   0., 1000.,  500.],
         [   0.,    0.,    1.]]], dtype=torch.float64))
test_kwargs = {'svd_eps': 0.001}, target = 'tensorflow', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function solve_pnp_dlt at 0x7fc4d4a3e950>, fn_name = 'kornia.geometry.calibration.solve_pnp_dlt'
trace_args = (tensor([[[ 5.0000, -5.0000,  0.0000],
         [ 0.0000,  0.0000,  1.5000],
         [ 2.5000,  3.0000,  6.0000],
   ...loat64), tensor([[[500.,   0., 250.],
         [  0., 500., 250.],
         [  0.,   0.,   1.]]], dtype=torch.float64))
trace_kwargs = {'svd_eps': 0.001}
test_args = (tensor([[[ 10., -10.,   0.],
         [  0.,   0.,   3.],
         [  5.,   6.,  12.],
         [ 18.,  -4.,   6.],
 ...tensor([[[1000.,    0.,  500.],
         [   0., 1000.,  500.],
         [   0.,    0.,    1.]]], dtype=torch.float64))
test_kwargs = {'svd_eps': 0.001}, target = 'tensorflow', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
>           graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:326: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

world_points = <tf.Tensor: shape=(1, 6, 3), dtype=float64, numpy=
array([[[ 5. , -5. ,  0. ],
        [ 0. ,  0. ,  1.5],
        [ 2.5,  3. ,  6. ],
        [ 9. , -2. ,  3. ],
        [-4. ,  5. ,  2. ],
        [-5. ,  5. ,  1. ]]])>
img_points = <tf.Tensor: shape=(1, 6, 2), dtype=float64, numpy=
array([[[1409.1504, -800.936 ],
        [ 407.0207, -182.1229],
   ...92.7021,  177.9428],
        [1016.838 ,   -2.9416],
        [ -63.1116,  142.9204],
        [-219.3874,   99.666 ]]])>
intrinsics = <tf.Tensor: shape=(1, 3, 3), dtype=float64, numpy=
array([[[500.,   0., 250.],
        [  0., 500., 250.],
        [  0.,   0.,   1.]]])>, weights = None, svd_eps = 0.001

    def tensorflow_solve_pnp_dlt(
        world_points, img_points, intrinsics, weights=None, svd_eps=0.0001
    ):
        from ....ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ...utils.helpers import tensorflow__torch_linalg_svdvals
        from ....ivy.functional.frontends.torch.reduction_ops import tensorflow_any_frnt
        from ....ivy.functional.frontends.torch.blas_and_lapack_ops import (
            tensorflow_inverse_frnt,
        )
        from ..conversions import tensorflow_convert_points_to_homogeneous
        from ..linalg import tensorflow_transform_points
        from ....ivy.functional.backends.tensorflow.general import tensorflow_set_item
        from ....ivy.functional.frontends.torch.blas_and_lapack_ops import (
            tensorflow_svd_frnt_base_count_1_frnt,
        )
        from ....ivy.functional.frontends.torch.tensor import tensorflow_reshape_frnt_
        from ...utils.misc import tensorflow_eye_like
        from ....ivy.functional.frontends.torch.blas_and_lapack_ops import (
            tensorflow_bmm_frnt,
        )
        from ....ivy.functional.frontends.torch.blas_and_lapack_ops import (
            tensorflow_det_frnt,
        )
        from ....ivy.functional.frontends.torch.reduction_ops import tensorflow_norm_frnt
        from ....ivy.functional.frontends.torch.linalg import tensorflow_qr_frnt
        from ....ivy.functional.frontends.torch.pointwise_ops import tensorflow_sign_frnt
        from ....ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            tensorflow_cat_frnt,
        )
        from ...core._backend import zeros
        from ...core._backend import ones_like
        from ...core._backend import where
    
        if not isinstance(world_points, (tensorflow.Tensor, tensorflow.Variable)):
            raise AssertionError(
                f"world_points is not an instance of torch.Tensor. Type of world_points is {type(world_points)}"
            )
        if not isinstance(img_points, (tensorflow.Tensor, tensorflow.Variable)):
            raise AssertionError(
                f"img_points is not an instance of torch.Tensor. Type of img_points is {type(img_points)}"
            )
        if not isinstance(intrinsics, (tensorflow.Tensor, tensorflow.Variable)):
            raise AssertionError(
                f"intrinsics is not an instance of torch.Tensor. Type of intrinsics is {type(intrinsics)}"
            )
        if weights is not None and not isinstance(
            weights, (tensorflow.Tensor, tensorflow.Variable)
        ):
            raise AssertionError(
                f"If weights is not None, then weights should be an instance of torch.Tensor. Type of weights is {type(weights)}"
            )
        if not isinstance(svd_eps, (float,)):
            raise AssertionError(f"Type of svd_eps is not float. Got {type(svd_eps)}")
        accepted_dtypes = tf.float32, tf.float64
        if world_points.dtype not in accepted_dtypes:
            raise AssertionError(
                f"world_points must have one of the following dtypes {accepted_dtypes}. Currently it has {world_points.dtype}."
            )
        if img_points.dtype not in accepted_dtypes:
            raise AssertionError(
                f"img_points must have one of the following dtypes {accepted_dtypes}. Currently it has {img_points.dtype}."
            )
        if intrinsics.dtype not in accepted_dtypes:
            raise AssertionError(
                f"intrinsics must have one of the following dtypes {accepted_dtypes}. Currently it has {intrinsics.dtype}."
            )
        if (
            len(tensorflow_shape_frnt_(world_points)) != 3
            or tensorflow_shape_frnt_(world_points)[2] != 3
        ):
            raise AssertionError(
                f"world_points must be of shape (B, N, 3). Got shape {tensorflow_shape_frnt_(world_points)}."
            )
        if (
            len(tensorflow_shape_frnt_(img_points)) != 3
            or tensorflow_shape_frnt_(img_points)[2] != 2
        ):
            raise AssertionError(
                f"img_points must be of shape (B, N, 2). Got shape {tensorflow_shape_frnt_(img_points)}."
            )
        if len(tensorflow_shape_frnt_(intrinsics)) != 3 or tensorflow_shape_frnt_(
            intrinsics
        )[1:] != (3, 3):
            raise AssertionError(
                f"intrinsics must be of shape (B, 3, 3). Got shape {tensorflow_shape_frnt_(intrinsics)}."
            )
        if tensorflow_shape_frnt_(world_points)[1] != tensorflow_shape_frnt_(img_points)[1]:
            raise AssertionError(
                "world_points and img_points must have equal number of points."
            )
        if (
            tensorflow_shape_frnt_(world_points)[0] != tensorflow_shape_frnt_(img_points)[0]
            or tensorflow_shape_frnt_(world_points)[0]
            != tensorflow_shape_frnt_(intrinsics)[0]
        ):
            raise AssertionError(
                "world_points, img_points and intrinsics must have the same batch size."
            )
        if tensorflow_shape_frnt_(world_points)[1] < 6:
            raise AssertionError(
                f"At least 6 points are required to use this function. Got {tensorflow_shape_frnt_(world_points)[1]} points."
            )
        B, N = (
            tensorflow_shape_frnt_(world_points)[:2][0],
            tensorflow_shape_frnt_(world_points)[:2][1],
        )
        world_points_norm, world_transform_norm = (
            tensorflow__mean_isotropic_scale_normalize(world_points)
        )
        s = tensorflow__torch_linalg_svdvals(world_points_norm)
        if tensorflow_any_frnt(s[:, -1] < svd_eps):
            raise AssertionError(
                f"The last singular value of one/more of the elements of the batch is smaller than {svd_eps}. This function cannot be used if all world_points (of any element of the batch) lie on a line or if all world_points (of any element of the batch) lie on a plane."
            )
        intrinsics_inv = tensorflow_inverse_frnt(intrinsics)
        world_points_norm_h = tensorflow_convert_points_to_homogeneous(world_points_norm)
        img_points_inv = tensorflow_transform_points(intrinsics_inv, img_points)
        img_points_norm, img_transform_norm = tensorflow__mean_isotropic_scale_normalize(
            img_points_inv
        )
        inv_img_transform_norm = tensorflow_inverse_frnt(img_transform_norm)
        system = zeros((B, 2 * N, 12), dtype=world_points.dtype, device=world_points.device)
        system = tensorflow_set_item(
            system,
            (slice(None, None, None), slice(0, None, 2), slice(0, 4, None)),
            world_points_norm_h,
        )
        system = tensorflow_set_item(
            system,
            (slice(None, None, None), slice(1, None, 2), slice(4, 8, None)),
            world_points_norm_h,
        )
        system = tensorflow_set_item(
            system,
            (slice(None, None, None), slice(0, None, 2), slice(8, 12, None)),
            world_points_norm_h * -1 * img_points_norm[..., 0:1],
        )
        system = tensorflow_set_item(
            system,
            (slice(None, None, None), slice(1, None, 2), slice(8, 12, None)),
            world_points_norm_h * -1 * img_points_norm[..., 1:2],
        )
        _, _, v = tensorflow_svd_frnt_base_count_1_frnt(system)
        solution = v[..., -1]
        solution = tensorflow_reshape_frnt_(solution, B, 3, 4)
        solution_4x4 = tensorflow_eye_like(4, solution)
        solution_4x4 = tensorflow_set_item(
            solution_4x4,
            (slice(None, None, None), slice(None, 3, None), slice(None, None, None)),
            solution,
        )
        intermediate = tensorflow_bmm_frnt(solution_4x4, world_transform_norm)
        solution = tensorflow_bmm_frnt(inv_img_transform_norm, intermediate[:, :3, :])
        det = tensorflow_det_frnt(solution[:, :3, :3])
        ones = ones_like(det)
        sign_fix = where(det < 0, ones * -1, ones)
        solution = solution * sign_fix[:, None, None]
>       norm_col = tensorflow_norm_frnt(input=solution[:, :3, 0], p=2, dim=1)

ivy_transpiled_outputs/tensorflow_outputs/kornia/geometry/calibration/pnp.py:239: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (), kwargs = {'dim': 1, 'input': <tf.Tensor: shape=(1, 3), dtype=float64, numpy=array([[-0.02017229,  0.02388222,  0.0574928 ]])>, 'p': 2}
tensorflow_is_array_bknd = <function tensorflow_is_array_bknd at 0x7fc464e7b6d0>

    @functools.wraps(fn)
    def wrapper(*args, **kwargs):
        from ..functional.ivy.general import tensorflow_is_array_bknd
    
>       array_like = args[0]
E       IndexError: tuple index out of range

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:195: IndexError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.calibration.pnp.solve_pnp_dlt
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/geometry/test_calibration.py::test_solve_pnp_dlt[tensorflow-s2s-False] - IndexError: tuple index out of range
=============================================================================== 1 failed, 4 passed in 367.73s (0:06:07) ================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 38 items

kornia/geometry/test_conversions.py ......................................                                                                                                                       [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
=================================================================================== 38 passed in 2020.32s (0:33:40) ====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 15 items

kornia/test_contrib.py ....FF..F...FF.                                                                                                                                                           [100%]

=============================================================================================== FAILURES ===============================================================================================
______________________________________________________________________________ test_diamond_square[tensorflow-s2s-False] _______________________________________________________________________________

self = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
rhs = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def impl(self, rhs):
        try:
>           return original_method(self, rhs)

ivy_transpiled_outputs/tensorflow_outputs/__init__.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (<tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>, tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]]))
kwargs = {}, arg = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def rep_method(*args, **kwargs):
        for arg in args:
            if ivy.is_ivy_array(arg):
                return NotImplemented
>       return func(*args, **kwargs)

../ivy/ivy/functional/backends/tensorflow/__init__.py:40: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (<tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>, tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]]))
kwargs = {}

    def error_handler(*args, **kwargs):
      try:
        if not is_traceback_filtering_enabled():
          return fn(*args, **kwargs)
      except NameError:
        # In some very rare cases,
        # `is_traceback_filtering_enabled` (from the outer scope) may not be
        # accessible from inside this function
        return fn(*args, **kwargs)
    
      filtered_tb = None
      try:
        return fn(*args, **kwargs)
      except Exception as e:
        filtered_tb = _process_traceback_frames(e.__traceback__)
>       raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/tensorflow/python/util/traceback_utils.py:153: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

arrays_and_dtypes = [<class 'numpy.float32'>, tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])]

    def _result_type(*arrays_and_dtypes):
      """Returns the resulting type given a set of arrays."""
    
      def preprocess_float(x):
        if is_prefer_float32():
          if isinstance(x, float):
            return np.float32(x)
          elif isinstance(x, complex):
            return np.complex64(x)
        return x
    
      arrays_and_dtypes = [preprocess_float(x) for x in arrays_and_dtypes]
>     dtype = np.result_type(*arrays_and_dtypes)
E     TypeError: Cannot interpret 'tensor([[[[0.3333, 1.0000, 0.3333],
E               [1.0000, 0.3333, 1.0000],
E               [0.3333, 1.0000, 0.3333]]]])' as a data type

/opt/fw/tensorflow/tensorflow/python/ops/numpy_ops/np_dtypes.py:190: TypeError

During handling of the above exception, another exception occurred:

self = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
rhs = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def impl(self, rhs):
        try:
>           return original_method(self, rhs)

ivy_transpiled_outputs/tensorflow_outputs/__init__.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
rhs = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def impl(self, rhs):
        try:
            return original_method(self, rhs)
        except Exception:
>           return patched_method(self, rhs)

ivy_transpiled_outputs/tensorflow_outputs/__init__.py:65: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
other = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

>   ???

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/tensor.py:94: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
other = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_mul_frnt(input, other, *, out=None):
        from .__init__ import tensorflow_promote_types_of_torch_inputs_frnt
        from ...backends.tensorflow.elementwise import tensorflow_multiply
    
>       input, other = tensorflow_promote_types_of_torch_inputs_frnt(input, other)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/pointwise_ops.py:74: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x1 = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
x2 = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_promote_types_of_torch_inputs_frnt(x1, x2, /):
        from ...ivy.general import tensorflow_isscalar_bknd
        from ...ivy.data_type import tensorflow_is_int_dtype_bknd
        from ...backends.tensorflow.creation import tensorflow_asarray
        from ...ivy.data_type import tensorflow_default_dtype_bknd
        from .tensor import tensorflow_shape_frnt_
        from ...ivy.device import tensorflow_default_device_bknd
        from ....data_classes.array.data_type import tensorflow_astype_bknd_
    
        """Promote the dtype of the given native array inputs to a common dtype
        based on type promotion rules.
    
        While passing float or integer values or any other non-array input
        to this function, it should be noted that the return will be an
        array-like object. Therefore, outputs from this function should be
        used as inputs only for those functions that expect an array-like or
        tensor-like objects, otherwise it might give unexpected results.
        """
        if (
            tensorflow_isscalar_bknd(x1) or isinstance(x1, (list, tuple))
        ) and tensorflow_is_int_dtype_bknd(x1):
            x1 = tensorflow_asarray(x1, dtype="int64")
        elif tensorflow_isscalar_bknd(x1) or isinstance(x1, (list, tuple)):
            x1 = tensorflow_asarray(x1)
        if (
            tensorflow_isscalar_bknd(x2) or isinstance(x2, (list, tuple))
        ) and tensorflow_is_int_dtype_bknd(x2):
            x2 = tensorflow_asarray(x2, dtype="int64")
        elif tensorflow_isscalar_bknd(x2) or isinstance(x2, (list, tuple)):
            x2 = tensorflow_asarray(x2)
        type1 = tensorflow_default_dtype_bknd(item=x1).strip("u123456789")
>       type2 = tensorflow_default_dtype_bknd(item=x2).strip("u123456789")

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/__init__.py:220: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def tensorflow_default_dtype_bknd(
        *,
        dtype: Optional[Union[str, str]] = None,
        item: Optional[Union[tensorflow.Tensor, tf.Tensor]] = None,
        as_native: bool = False,
    ):
        from ..backends.tensorflow.data_type import tensorflow_as_ivy_dtype
        from ..backends.tensorflow.data_type import tensorflow_as_native_dtype
        from .general import tensorflow_exists_bknd
        from .general import tensorflow_default_bknd
    
        if tensorflow_exists_bknd(dtype):
            if as_native is True:
                return tensorflow_as_native_dtype(dtype)
            return tensorflow_as_ivy_dtype(dtype)
        as_native = tensorflow_default_bknd(as_native, False)
        if tensorflow_exists_bknd(item):
            if hasattr(item, "override_dtype_check"):
                return item.override_dtype_check()
            elif isinstance(item, (list, tuple, dict)) and len(item) == 0:
                pass
>           elif tensorflow_is_complex_dtype_bknd(item):

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:185: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_is_complex_dtype_bknd(
        dtype_in: Union[str, str, tensorflow.Tensor, tf.Tensor, Number], /
    ):
        from ..backends.tensorflow.data_type import tensorflow_dtype
        from .general import tensorflow_is_array_bknd
        from .nest import tensorflow_nested_argwhere_bknd
    
        if tensorflow_is_array_bknd(dtype_in):
            dtype_in = tensorflow_dtype(dtype_in)
        elif isinstance(dtype_in, tuple):
            dtype_in = tensorflow_default_int_dtype_bknd()
        elif isinstance(dtype_in, np.ndarray):
            return "complex" in dtype_in.dtype.name
        elif isinstance(dtype_in, Number):
            return isinstance(dtype_in, (complex, np.complexfloating))
        elif isinstance(dtype_in, (list, tuple, dict)):
            return tensorflow_nested_argwhere_bknd(
                dtype_in,
                lambda x: isinstance(x, (complex, np.complexfloating))
                or tensorflow_is_array_bknd(x)
                and "complex" in tensorflow_dtype(x),
            )
>       return "complex" in tensorflow_as_ivy_dtype_bknd(dtype_in)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:562: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_as_ivy_dtype_bknd(dtype_in: Union[str, str], /):
        from ..backends.tensorflow.data_type import tensorflow_as_ivy_dtype
    
>       return tensorflow_as_ivy_dtype(dtype_in)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:49: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_as_ivy_dtype(
        dtype_in: Union[tensorflow.DType, str, int, float, complex, bool, np.dtype], /
    ):
        from ...ivy.data_type import tensorflow_default_int_dtype_bknd
        from ...ivy.data_type import tensorflow_default_float_dtype_bknd
        from ...ivy.data_type import tensorflow_default_complex_dtype_bknd
    
        if dtype_in is int:
            return tensorflow_default_int_dtype_bknd()
        if dtype_in is float:
            return tensorflow_default_float_dtype_bknd()
        if dtype_in is complex:
            return tensorflow_default_complex_dtype_bknd()
        if dtype_in is bool:
            return str("bool")
        if isinstance(dtype_in, np.dtype):
            dtype_in = dtype_in.name
        if isinstance(dtype_in, str):
            if dtype_in in native_dtype_dict:
                dtype_str = dtype_in
            else:
                raise Exception(
                    f"Cannot convert to ivy dtype. {dtype_in} is not supported by TensorFlow backend."
                )
        else:
>           dtype_str = ivy_dtype_dict[dtype_in]
E           KeyError: tensor([[[[0.3333, 1.0000, 0.3333],
E                     [1.0000, 0.3333, 1.0000],
E                     [0.3333, 1.0000, 0.3333]]]])

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/backends/tensorflow/data_type.py:184: KeyError

During handling of the above exception, another exception occurred:

self = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
rhs = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def impl(self, rhs):
        try:
>           return original_method(self, rhs)

ivy_transpiled_outputs/tensorflow_outputs/__init__.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
rhs = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def impl(self, rhs):
        try:
            return original_method(self, rhs)
        except Exception:
>           return patched_method(self, rhs)

ivy_transpiled_outputs/tensorflow_outputs/__init__.py:65: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
other = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

>   ???

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/tensor.py:94: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
other = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_mul_frnt(input, other, *, out=None):
        from .__init__ import tensorflow_promote_types_of_torch_inputs_frnt
        from ...backends.tensorflow.elementwise import tensorflow_multiply
    
>       input, other = tensorflow_promote_types_of_torch_inputs_frnt(input, other)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/pointwise_ops.py:74: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x1 = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
x2 = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_promote_types_of_torch_inputs_frnt(x1, x2, /):
        from ...ivy.general import tensorflow_isscalar_bknd
        from ...ivy.data_type import tensorflow_is_int_dtype_bknd
        from ...backends.tensorflow.creation import tensorflow_asarray
        from ...ivy.data_type import tensorflow_default_dtype_bknd
        from .tensor import tensorflow_shape_frnt_
        from ...ivy.device import tensorflow_default_device_bknd
        from ....data_classes.array.data_type import tensorflow_astype_bknd_
    
        """Promote the dtype of the given native array inputs to a common dtype
        based on type promotion rules.
    
        While passing float or integer values or any other non-array input
        to this function, it should be noted that the return will be an
        array-like object. Therefore, outputs from this function should be
        used as inputs only for those functions that expect an array-like or
        tensor-like objects, otherwise it might give unexpected results.
        """
        if (
            tensorflow_isscalar_bknd(x1) or isinstance(x1, (list, tuple))
        ) and tensorflow_is_int_dtype_bknd(x1):
            x1 = tensorflow_asarray(x1, dtype="int64")
        elif tensorflow_isscalar_bknd(x1) or isinstance(x1, (list, tuple)):
            x1 = tensorflow_asarray(x1)
        if (
            tensorflow_isscalar_bknd(x2) or isinstance(x2, (list, tuple))
        ) and tensorflow_is_int_dtype_bknd(x2):
            x2 = tensorflow_asarray(x2, dtype="int64")
        elif tensorflow_isscalar_bknd(x2) or isinstance(x2, (list, tuple)):
            x2 = tensorflow_asarray(x2)
        type1 = tensorflow_default_dtype_bknd(item=x1).strip("u123456789")
>       type2 = tensorflow_default_dtype_bknd(item=x2).strip("u123456789")

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/__init__.py:220: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def tensorflow_default_dtype_bknd(
        *,
        dtype: Optional[Union[str, str]] = None,
        item: Optional[Union[tensorflow.Tensor, tf.Tensor]] = None,
        as_native: bool = False,
    ):
        from ..backends.tensorflow.data_type import tensorflow_as_ivy_dtype
        from ..backends.tensorflow.data_type import tensorflow_as_native_dtype
        from .general import tensorflow_exists_bknd
        from .general import tensorflow_default_bknd
    
        if tensorflow_exists_bknd(dtype):
            if as_native is True:
                return tensorflow_as_native_dtype(dtype)
            return tensorflow_as_ivy_dtype(dtype)
        as_native = tensorflow_default_bknd(as_native, False)
        if tensorflow_exists_bknd(item):
            if hasattr(item, "override_dtype_check"):
                return item.override_dtype_check()
            elif isinstance(item, (list, tuple, dict)) and len(item) == 0:
                pass
>           elif tensorflow_is_complex_dtype_bknd(item):

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:185: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_is_complex_dtype_bknd(
        dtype_in: Union[str, str, tensorflow.Tensor, tf.Tensor, Number], /
    ):
        from ..backends.tensorflow.data_type import tensorflow_dtype
        from .general import tensorflow_is_array_bknd
        from .nest import tensorflow_nested_argwhere_bknd
    
        if tensorflow_is_array_bknd(dtype_in):
            dtype_in = tensorflow_dtype(dtype_in)
        elif isinstance(dtype_in, tuple):
            dtype_in = tensorflow_default_int_dtype_bknd()
        elif isinstance(dtype_in, np.ndarray):
            return "complex" in dtype_in.dtype.name
        elif isinstance(dtype_in, Number):
            return isinstance(dtype_in, (complex, np.complexfloating))
        elif isinstance(dtype_in, (list, tuple, dict)):
            return tensorflow_nested_argwhere_bknd(
                dtype_in,
                lambda x: isinstance(x, (complex, np.complexfloating))
                or tensorflow_is_array_bknd(x)
                and "complex" in tensorflow_dtype(x),
            )
>       return "complex" in tensorflow_as_ivy_dtype_bknd(dtype_in)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:562: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_as_ivy_dtype_bknd(dtype_in: Union[str, str], /):
        from ..backends.tensorflow.data_type import tensorflow_as_ivy_dtype
    
>       return tensorflow_as_ivy_dtype(dtype_in)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:49: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_as_ivy_dtype(
        dtype_in: Union[tensorflow.DType, str, int, float, complex, bool, np.dtype], /
    ):
        from ...ivy.data_type import tensorflow_default_int_dtype_bknd
        from ...ivy.data_type import tensorflow_default_float_dtype_bknd
        from ...ivy.data_type import tensorflow_default_complex_dtype_bknd
    
        if dtype_in is int:
            return tensorflow_default_int_dtype_bknd()
        if dtype_in is float:
            return tensorflow_default_float_dtype_bknd()
        if dtype_in is complex:
            return tensorflow_default_complex_dtype_bknd()
        if dtype_in is bool:
            return str("bool")
        if isinstance(dtype_in, np.dtype):
            dtype_in = dtype_in.name
        if isinstance(dtype_in, str):
            if dtype_in in native_dtype_dict:
                dtype_str = dtype_in
            else:
                raise Exception(
                    f"Cannot convert to ivy dtype. {dtype_in} is not supported by TensorFlow backend."
                )
        else:
>           dtype_str = ivy_dtype_dict[dtype_in]
E           KeyError: tensor([[[[0.3333, 1.0000, 0.3333],
E                     [1.0000, 0.3333, 1.0000],
E                     [0.3333, 1.0000, 0.3333]]]])

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/backends/tensorflow/data_type.py:184: KeyError

During handling of the above exception, another exception occurred:

self = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
rhs = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def impl(self, rhs):
        try:
>           return original_method(self, rhs)

ivy_transpiled_outputs/tensorflow_outputs/__init__.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
rhs = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def impl(self, rhs):
        try:
            return original_method(self, rhs)
        except Exception:
>           return patched_method(self, rhs)

ivy_transpiled_outputs/tensorflow_outputs/__init__.py:65: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
other = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

>   ???

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/tensor.py:94: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
other = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_mul_frnt(input, other, *, out=None):
        from .__init__ import tensorflow_promote_types_of_torch_inputs_frnt
        from ...backends.tensorflow.elementwise import tensorflow_multiply
    
>       input, other = tensorflow_promote_types_of_torch_inputs_frnt(input, other)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/pointwise_ops.py:74: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x1 = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
x2 = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_promote_types_of_torch_inputs_frnt(x1, x2, /):
        from ...ivy.general import tensorflow_isscalar_bknd
        from ...ivy.data_type import tensorflow_is_int_dtype_bknd
        from ...backends.tensorflow.creation import tensorflow_asarray
        from ...ivy.data_type import tensorflow_default_dtype_bknd
        from .tensor import tensorflow_shape_frnt_
        from ...ivy.device import tensorflow_default_device_bknd
        from ....data_classes.array.data_type import tensorflow_astype_bknd_
    
        """Promote the dtype of the given native array inputs to a common dtype
        based on type promotion rules.
    
        While passing float or integer values or any other non-array input
        to this function, it should be noted that the return will be an
        array-like object. Therefore, outputs from this function should be
        used as inputs only for those functions that expect an array-like or
        tensor-like objects, otherwise it might give unexpected results.
        """
        if (
            tensorflow_isscalar_bknd(x1) or isinstance(x1, (list, tuple))
        ) and tensorflow_is_int_dtype_bknd(x1):
            x1 = tensorflow_asarray(x1, dtype="int64")
        elif tensorflow_isscalar_bknd(x1) or isinstance(x1, (list, tuple)):
            x1 = tensorflow_asarray(x1)
        if (
            tensorflow_isscalar_bknd(x2) or isinstance(x2, (list, tuple))
        ) and tensorflow_is_int_dtype_bknd(x2):
            x2 = tensorflow_asarray(x2, dtype="int64")
        elif tensorflow_isscalar_bknd(x2) or isinstance(x2, (list, tuple)):
            x2 = tensorflow_asarray(x2)
        type1 = tensorflow_default_dtype_bknd(item=x1).strip("u123456789")
>       type2 = tensorflow_default_dtype_bknd(item=x2).strip("u123456789")

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/__init__.py:220: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def tensorflow_default_dtype_bknd(
        *,
        dtype: Optional[Union[str, str]] = None,
        item: Optional[Union[tensorflow.Tensor, tf.Tensor]] = None,
        as_native: bool = False,
    ):
        from ..backends.tensorflow.data_type import tensorflow_as_ivy_dtype
        from ..backends.tensorflow.data_type import tensorflow_as_native_dtype
        from .general import tensorflow_exists_bknd
        from .general import tensorflow_default_bknd
    
        if tensorflow_exists_bknd(dtype):
            if as_native is True:
                return tensorflow_as_native_dtype(dtype)
            return tensorflow_as_ivy_dtype(dtype)
        as_native = tensorflow_default_bknd(as_native, False)
        if tensorflow_exists_bknd(item):
            if hasattr(item, "override_dtype_check"):
                return item.override_dtype_check()
            elif isinstance(item, (list, tuple, dict)) and len(item) == 0:
                pass
>           elif tensorflow_is_complex_dtype_bknd(item):

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:185: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_is_complex_dtype_bknd(
        dtype_in: Union[str, str, tensorflow.Tensor, tf.Tensor, Number], /
    ):
        from ..backends.tensorflow.data_type import tensorflow_dtype
        from .general import tensorflow_is_array_bknd
        from .nest import tensorflow_nested_argwhere_bknd
    
        if tensorflow_is_array_bknd(dtype_in):
            dtype_in = tensorflow_dtype(dtype_in)
        elif isinstance(dtype_in, tuple):
            dtype_in = tensorflow_default_int_dtype_bknd()
        elif isinstance(dtype_in, np.ndarray):
            return "complex" in dtype_in.dtype.name
        elif isinstance(dtype_in, Number):
            return isinstance(dtype_in, (complex, np.complexfloating))
        elif isinstance(dtype_in, (list, tuple, dict)):
            return tensorflow_nested_argwhere_bknd(
                dtype_in,
                lambda x: isinstance(x, (complex, np.complexfloating))
                or tensorflow_is_array_bknd(x)
                and "complex" in tensorflow_dtype(x),
            )
>       return "complex" in tensorflow_as_ivy_dtype_bknd(dtype_in)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:562: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_as_ivy_dtype_bknd(dtype_in: Union[str, str], /):
        from ..backends.tensorflow.data_type import tensorflow_as_ivy_dtype
    
>       return tensorflow_as_ivy_dtype(dtype_in)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:49: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_as_ivy_dtype(
        dtype_in: Union[tensorflow.DType, str, int, float, complex, bool, np.dtype], /
    ):
        from ...ivy.data_type import tensorflow_default_int_dtype_bknd
        from ...ivy.data_type import tensorflow_default_float_dtype_bknd
        from ...ivy.data_type import tensorflow_default_complex_dtype_bknd
    
        if dtype_in is int:
            return tensorflow_default_int_dtype_bknd()
        if dtype_in is float:
            return tensorflow_default_float_dtype_bknd()
        if dtype_in is complex:
            return tensorflow_default_complex_dtype_bknd()
        if dtype_in is bool:
            return str("bool")
        if isinstance(dtype_in, np.dtype):
            dtype_in = dtype_in.name
        if isinstance(dtype_in, str):
            if dtype_in in native_dtype_dict:
                dtype_str = dtype_in
            else:
                raise Exception(
                    f"Cannot convert to ivy dtype. {dtype_in} is not supported by TensorFlow backend."
                )
        else:
>           dtype_str = ivy_dtype_dict[dtype_in]
E           KeyError: tensor([[[[0.3333, 1.0000, 0.3333],
E                     [1.0000, 0.3333, 1.0000],
E                     [0.3333, 1.0000, 0.3333]]]])

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/backends/tensorflow/data_type.py:184: KeyError

During handling of the above exception, another exception occurred:

self = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
rhs = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def impl(self, rhs):
        try:
>           return original_method(self, rhs)

ivy_transpiled_outputs/tensorflow_outputs/__init__.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
rhs = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def impl(self, rhs):
        try:
            return original_method(self, rhs)
        except Exception:
>           return patched_method(self, rhs)

ivy_transpiled_outputs/tensorflow_outputs/__init__.py:65: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
other = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

>   ???

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/tensor.py:94: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
other = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_mul_frnt(input, other, *, out=None):
        from .__init__ import tensorflow_promote_types_of_torch_inputs_frnt
        from ...backends.tensorflow.elementwise import tensorflow_multiply
    
>       input, other = tensorflow_promote_types_of_torch_inputs_frnt(input, other)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/pointwise_ops.py:74: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x1 = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
x2 = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_promote_types_of_torch_inputs_frnt(x1, x2, /):
        from ...ivy.general import tensorflow_isscalar_bknd
        from ...ivy.data_type import tensorflow_is_int_dtype_bknd
        from ...backends.tensorflow.creation import tensorflow_asarray
        from ...ivy.data_type import tensorflow_default_dtype_bknd
        from .tensor import tensorflow_shape_frnt_
        from ...ivy.device import tensorflow_default_device_bknd
        from ....data_classes.array.data_type import tensorflow_astype_bknd_
    
        """Promote the dtype of the given native array inputs to a common dtype
        based on type promotion rules.
    
        While passing float or integer values or any other non-array input
        to this function, it should be noted that the return will be an
        array-like object. Therefore, outputs from this function should be
        used as inputs only for those functions that expect an array-like or
        tensor-like objects, otherwise it might give unexpected results.
        """
        if (
            tensorflow_isscalar_bknd(x1) or isinstance(x1, (list, tuple))
        ) and tensorflow_is_int_dtype_bknd(x1):
            x1 = tensorflow_asarray(x1, dtype="int64")
        elif tensorflow_isscalar_bknd(x1) or isinstance(x1, (list, tuple)):
            x1 = tensorflow_asarray(x1)
        if (
            tensorflow_isscalar_bknd(x2) or isinstance(x2, (list, tuple))
        ) and tensorflow_is_int_dtype_bknd(x2):
            x2 = tensorflow_asarray(x2, dtype="int64")
        elif tensorflow_isscalar_bknd(x2) or isinstance(x2, (list, tuple)):
            x2 = tensorflow_asarray(x2)
        type1 = tensorflow_default_dtype_bknd(item=x1).strip("u123456789")
>       type2 = tensorflow_default_dtype_bknd(item=x2).strip("u123456789")

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/__init__.py:220: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def tensorflow_default_dtype_bknd(
        *,
        dtype: Optional[Union[str, str]] = None,
        item: Optional[Union[tensorflow.Tensor, tf.Tensor]] = None,
        as_native: bool = False,
    ):
        from ..backends.tensorflow.data_type import tensorflow_as_ivy_dtype
        from ..backends.tensorflow.data_type import tensorflow_as_native_dtype
        from .general import tensorflow_exists_bknd
        from .general import tensorflow_default_bknd
    
        if tensorflow_exists_bknd(dtype):
            if as_native is True:
                return tensorflow_as_native_dtype(dtype)
            return tensorflow_as_ivy_dtype(dtype)
        as_native = tensorflow_default_bknd(as_native, False)
        if tensorflow_exists_bknd(item):
            if hasattr(item, "override_dtype_check"):
                return item.override_dtype_check()
            elif isinstance(item, (list, tuple, dict)) and len(item) == 0:
                pass
>           elif tensorflow_is_complex_dtype_bknd(item):

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:185: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_is_complex_dtype_bknd(
        dtype_in: Union[str, str, tensorflow.Tensor, tf.Tensor, Number], /
    ):
        from ..backends.tensorflow.data_type import tensorflow_dtype
        from .general import tensorflow_is_array_bknd
        from .nest import tensorflow_nested_argwhere_bknd
    
        if tensorflow_is_array_bknd(dtype_in):
            dtype_in = tensorflow_dtype(dtype_in)
        elif isinstance(dtype_in, tuple):
            dtype_in = tensorflow_default_int_dtype_bknd()
        elif isinstance(dtype_in, np.ndarray):
            return "complex" in dtype_in.dtype.name
        elif isinstance(dtype_in, Number):
            return isinstance(dtype_in, (complex, np.complexfloating))
        elif isinstance(dtype_in, (list, tuple, dict)):
            return tensorflow_nested_argwhere_bknd(
                dtype_in,
                lambda x: isinstance(x, (complex, np.complexfloating))
                or tensorflow_is_array_bknd(x)
                and "complex" in tensorflow_dtype(x),
            )
>       return "complex" in tensorflow_as_ivy_dtype_bknd(dtype_in)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:562: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_as_ivy_dtype_bknd(dtype_in: Union[str, str], /):
        from ..backends.tensorflow.data_type import tensorflow_as_ivy_dtype
    
>       return tensorflow_as_ivy_dtype(dtype_in)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:49: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_as_ivy_dtype(
        dtype_in: Union[tensorflow.DType, str, int, float, complex, bool, np.dtype], /
    ):
        from ...ivy.data_type import tensorflow_default_int_dtype_bknd
        from ...ivy.data_type import tensorflow_default_float_dtype_bknd
        from ...ivy.data_type import tensorflow_default_complex_dtype_bknd
    
        if dtype_in is int:
            return tensorflow_default_int_dtype_bknd()
        if dtype_in is float:
            return tensorflow_default_float_dtype_bknd()
        if dtype_in is complex:
            return tensorflow_default_complex_dtype_bknd()
        if dtype_in is bool:
            return str("bool")
        if isinstance(dtype_in, np.dtype):
            dtype_in = dtype_in.name
        if isinstance(dtype_in, str):
            if dtype_in in native_dtype_dict:
                dtype_str = dtype_in
            else:
                raise Exception(
                    f"Cannot convert to ivy dtype. {dtype_in} is not supported by TensorFlow backend."
                )
        else:
>           dtype_str = ivy_dtype_dict[dtype_in]
E           KeyError: tensor([[[[0.3333, 1.0000, 0.3333],
E                     [1.0000, 0.3333, 1.0000],
E                     [0.3333, 1.0000, 0.3333]]]])

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/backends/tensorflow/data_type.py:184: KeyError

During handling of the above exception, another exception occurred:

self = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
rhs = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def impl(self, rhs):
        try:
>           return original_method(self, rhs)

ivy_transpiled_outputs/tensorflow_outputs/__init__.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
rhs = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def impl(self, rhs):
        try:
            return original_method(self, rhs)
        except Exception:
>           return patched_method(self, rhs)

ivy_transpiled_outputs/tensorflow_outputs/__init__.py:65: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
other = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

>   ???

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/tensor.py:94: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
other = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_mul_frnt(input, other, *, out=None):
        from .__init__ import tensorflow_promote_types_of_torch_inputs_frnt
        from ...backends.tensorflow.elementwise import tensorflow_multiply
    
>       input, other = tensorflow_promote_types_of_torch_inputs_frnt(input, other)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/pointwise_ops.py:74: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x1 = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
x2 = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_promote_types_of_torch_inputs_frnt(x1, x2, /):
        from ...ivy.general import tensorflow_isscalar_bknd
        from ...ivy.data_type import tensorflow_is_int_dtype_bknd
        from ...backends.tensorflow.creation import tensorflow_asarray
        from ...ivy.data_type import tensorflow_default_dtype_bknd
        from .tensor import tensorflow_shape_frnt_
        from ...ivy.device import tensorflow_default_device_bknd
        from ....data_classes.array.data_type import tensorflow_astype_bknd_
    
        """Promote the dtype of the given native array inputs to a common dtype
        based on type promotion rules.
    
        While passing float or integer values or any other non-array input
        to this function, it should be noted that the return will be an
        array-like object. Therefore, outputs from this function should be
        used as inputs only for those functions that expect an array-like or
        tensor-like objects, otherwise it might give unexpected results.
        """
        if (
            tensorflow_isscalar_bknd(x1) or isinstance(x1, (list, tuple))
        ) and tensorflow_is_int_dtype_bknd(x1):
            x1 = tensorflow_asarray(x1, dtype="int64")
        elif tensorflow_isscalar_bknd(x1) or isinstance(x1, (list, tuple)):
            x1 = tensorflow_asarray(x1)
        if (
            tensorflow_isscalar_bknd(x2) or isinstance(x2, (list, tuple))
        ) and tensorflow_is_int_dtype_bknd(x2):
            x2 = tensorflow_asarray(x2, dtype="int64")
        elif tensorflow_isscalar_bknd(x2) or isinstance(x2, (list, tuple)):
            x2 = tensorflow_asarray(x2)
        type1 = tensorflow_default_dtype_bknd(item=x1).strip("u123456789")
>       type2 = tensorflow_default_dtype_bknd(item=x2).strip("u123456789")

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/__init__.py:220: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def tensorflow_default_dtype_bknd(
        *,
        dtype: Optional[Union[str, str]] = None,
        item: Optional[Union[tensorflow.Tensor, tf.Tensor]] = None,
        as_native: bool = False,
    ):
        from ..backends.tensorflow.data_type import tensorflow_as_ivy_dtype
        from ..backends.tensorflow.data_type import tensorflow_as_native_dtype
        from .general import tensorflow_exists_bknd
        from .general import tensorflow_default_bknd
    
        if tensorflow_exists_bknd(dtype):
            if as_native is True:
                return tensorflow_as_native_dtype(dtype)
            return tensorflow_as_ivy_dtype(dtype)
        as_native = tensorflow_default_bknd(as_native, False)
        if tensorflow_exists_bknd(item):
            if hasattr(item, "override_dtype_check"):
                return item.override_dtype_check()
            elif isinstance(item, (list, tuple, dict)) and len(item) == 0:
                pass
>           elif tensorflow_is_complex_dtype_bknd(item):

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:185: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_is_complex_dtype_bknd(
        dtype_in: Union[str, str, tensorflow.Tensor, tf.Tensor, Number], /
    ):
        from ..backends.tensorflow.data_type import tensorflow_dtype
        from .general import tensorflow_is_array_bknd
        from .nest import tensorflow_nested_argwhere_bknd
    
        if tensorflow_is_array_bknd(dtype_in):
            dtype_in = tensorflow_dtype(dtype_in)
        elif isinstance(dtype_in, tuple):
            dtype_in = tensorflow_default_int_dtype_bknd()
        elif isinstance(dtype_in, np.ndarray):
            return "complex" in dtype_in.dtype.name
        elif isinstance(dtype_in, Number):
            return isinstance(dtype_in, (complex, np.complexfloating))
        elif isinstance(dtype_in, (list, tuple, dict)):
            return tensorflow_nested_argwhere_bknd(
                dtype_in,
                lambda x: isinstance(x, (complex, np.complexfloating))
                or tensorflow_is_array_bknd(x)
                and "complex" in tensorflow_dtype(x),
            )
>       return "complex" in tensorflow_as_ivy_dtype_bknd(dtype_in)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:562: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_as_ivy_dtype_bknd(dtype_in: Union[str, str], /):
        from ..backends.tensorflow.data_type import tensorflow_as_ivy_dtype
    
>       return tensorflow_as_ivy_dtype(dtype_in)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:49: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_as_ivy_dtype(
        dtype_in: Union[tensorflow.DType, str, int, float, complex, bool, np.dtype], /
    ):
        from ...ivy.data_type import tensorflow_default_int_dtype_bknd
        from ...ivy.data_type import tensorflow_default_float_dtype_bknd
        from ...ivy.data_type import tensorflow_default_complex_dtype_bknd
    
        if dtype_in is int:
            return tensorflow_default_int_dtype_bknd()
        if dtype_in is float:
            return tensorflow_default_float_dtype_bknd()
        if dtype_in is complex:
            return tensorflow_default_complex_dtype_bknd()
        if dtype_in is bool:
            return str("bool")
        if isinstance(dtype_in, np.dtype):
            dtype_in = dtype_in.name
        if isinstance(dtype_in, str):
            if dtype_in in native_dtype_dict:
                dtype_str = dtype_in
            else:
                raise Exception(
                    f"Cannot convert to ivy dtype. {dtype_in} is not supported by TensorFlow backend."
                )
        else:
>           dtype_str = ivy_dtype_dict[dtype_in]
E           KeyError: tensor([[[[0.3333, 1.0000, 0.3333],
E                     [1.0000, 0.3333, 1.0000],
E                     [0.3333, 1.0000, 0.3333]]]])

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/backends/tensorflow/data_type.py:184: KeyError

During handling of the above exception, another exception occurred:

self = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
rhs = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def impl(self, rhs):
        try:
>           return original_method(self, rhs)

ivy_transpiled_outputs/tensorflow_outputs/__init__.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
rhs = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def impl(self, rhs):
        try:
            return original_method(self, rhs)
        except Exception:
>           return patched_method(self, rhs)

ivy_transpiled_outputs/tensorflow_outputs/__init__.py:65: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
other = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

>   ???

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/tensor.py:94: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
other = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_mul_frnt(input, other, *, out=None):
        from .__init__ import tensorflow_promote_types_of_torch_inputs_frnt
        from ...backends.tensorflow.elementwise import tensorflow_multiply
    
>       input, other = tensorflow_promote_types_of_torch_inputs_frnt(input, other)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/pointwise_ops.py:74: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x1 = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
x2 = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_promote_types_of_torch_inputs_frnt(x1, x2, /):
        from ...ivy.general import tensorflow_isscalar_bknd
        from ...ivy.data_type import tensorflow_is_int_dtype_bknd
        from ...backends.tensorflow.creation import tensorflow_asarray
        from ...ivy.data_type import tensorflow_default_dtype_bknd
        from .tensor import tensorflow_shape_frnt_
        from ...ivy.device import tensorflow_default_device_bknd
        from ....data_classes.array.data_type import tensorflow_astype_bknd_
    
        """Promote the dtype of the given native array inputs to a common dtype
        based on type promotion rules.
    
        While passing float or integer values or any other non-array input
        to this function, it should be noted that the return will be an
        array-like object. Therefore, outputs from this function should be
        used as inputs only for those functions that expect an array-like or
        tensor-like objects, otherwise it might give unexpected results.
        """
        if (
            tensorflow_isscalar_bknd(x1) or isinstance(x1, (list, tuple))
        ) and tensorflow_is_int_dtype_bknd(x1):
            x1 = tensorflow_asarray(x1, dtype="int64")
        elif tensorflow_isscalar_bknd(x1) or isinstance(x1, (list, tuple)):
            x1 = tensorflow_asarray(x1)
        if (
            tensorflow_isscalar_bknd(x2) or isinstance(x2, (list, tuple))
        ) and tensorflow_is_int_dtype_bknd(x2):
            x2 = tensorflow_asarray(x2, dtype="int64")
        elif tensorflow_isscalar_bknd(x2) or isinstance(x2, (list, tuple)):
            x2 = tensorflow_asarray(x2)
        type1 = tensorflow_default_dtype_bknd(item=x1).strip("u123456789")
>       type2 = tensorflow_default_dtype_bknd(item=x2).strip("u123456789")

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/__init__.py:220: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def tensorflow_default_dtype_bknd(
        *,
        dtype: Optional[Union[str, str]] = None,
        item: Optional[Union[tensorflow.Tensor, tf.Tensor]] = None,
        as_native: bool = False,
    ):
        from ..backends.tensorflow.data_type import tensorflow_as_ivy_dtype
        from ..backends.tensorflow.data_type import tensorflow_as_native_dtype
        from .general import tensorflow_exists_bknd
        from .general import tensorflow_default_bknd
    
        if tensorflow_exists_bknd(dtype):
            if as_native is True:
                return tensorflow_as_native_dtype(dtype)
            return tensorflow_as_ivy_dtype(dtype)
        as_native = tensorflow_default_bknd(as_native, False)
        if tensorflow_exists_bknd(item):
            if hasattr(item, "override_dtype_check"):
                return item.override_dtype_check()
            elif isinstance(item, (list, tuple, dict)) and len(item) == 0:
                pass
>           elif tensorflow_is_complex_dtype_bknd(item):

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:185: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_is_complex_dtype_bknd(
        dtype_in: Union[str, str, tensorflow.Tensor, tf.Tensor, Number], /
    ):
        from ..backends.tensorflow.data_type import tensorflow_dtype
        from .general import tensorflow_is_array_bknd
        from .nest import tensorflow_nested_argwhere_bknd
    
        if tensorflow_is_array_bknd(dtype_in):
            dtype_in = tensorflow_dtype(dtype_in)
        elif isinstance(dtype_in, tuple):
            dtype_in = tensorflow_default_int_dtype_bknd()
        elif isinstance(dtype_in, np.ndarray):
            return "complex" in dtype_in.dtype.name
        elif isinstance(dtype_in, Number):
            return isinstance(dtype_in, (complex, np.complexfloating))
        elif isinstance(dtype_in, (list, tuple, dict)):
            return tensorflow_nested_argwhere_bknd(
                dtype_in,
                lambda x: isinstance(x, (complex, np.complexfloating))
                or tensorflow_is_array_bknd(x)
                and "complex" in tensorflow_dtype(x),
            )
>       return "complex" in tensorflow_as_ivy_dtype_bknd(dtype_in)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:562: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_as_ivy_dtype_bknd(dtype_in: Union[str, str], /):
        from ..backends.tensorflow.data_type import tensorflow_as_ivy_dtype
    
>       return tensorflow_as_ivy_dtype(dtype_in)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:49: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_as_ivy_dtype(
        dtype_in: Union[tensorflow.DType, str, int, float, complex, bool, np.dtype], /
    ):
        from ...ivy.data_type import tensorflow_default_int_dtype_bknd
        from ...ivy.data_type import tensorflow_default_float_dtype_bknd
        from ...ivy.data_type import tensorflow_default_complex_dtype_bknd
    
        if dtype_in is int:
            return tensorflow_default_int_dtype_bknd()
        if dtype_in is float:
            return tensorflow_default_float_dtype_bknd()
        if dtype_in is complex:
            return tensorflow_default_complex_dtype_bknd()
        if dtype_in is bool:
            return str("bool")
        if isinstance(dtype_in, np.dtype):
            dtype_in = dtype_in.name
        if isinstance(dtype_in, str):
            if dtype_in in native_dtype_dict:
                dtype_str = dtype_in
            else:
                raise Exception(
                    f"Cannot convert to ivy dtype. {dtype_in} is not supported by TensorFlow backend."
                )
        else:
>           dtype_str = ivy_dtype_dict[dtype_in]
E           KeyError: tensor([[[[0.3333, 1.0000, 0.3333],
E                     [1.0000, 0.3333, 1.0000],
E                     [0.3333, 1.0000, 0.3333]]]])

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/backends/tensorflow/data_type.py:184: KeyError

During handling of the above exception, another exception occurred:

self = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
rhs = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def impl(self, rhs):
        try:
>           return original_method(self, rhs)

ivy_transpiled_outputs/tensorflow_outputs/__init__.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
rhs = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def impl(self, rhs):
        try:
            return original_method(self, rhs)
        except Exception:
>           return patched_method(self, rhs)

ivy_transpiled_outputs/tensorflow_outputs/__init__.py:65: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
other = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow___mul___frnt_(tensor, other):
        from .pointwise_ops import tensorflow_mul_frnt
    
>       return tensorflow_mul_frnt(tensor, other)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/tensor.py:95: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
other = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_mul_frnt(input, other, *, out=None):
        from .__init__ import tensorflow_promote_types_of_torch_inputs_frnt
        from ...backends.tensorflow.elementwise import tensorflow_multiply
    
>       input, other = tensorflow_promote_types_of_torch_inputs_frnt(input, other)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/pointwise_ops.py:74: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x1 = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
x2 = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_promote_types_of_torch_inputs_frnt(x1, x2, /):
        from ...ivy.general import tensorflow_isscalar_bknd
        from ...ivy.data_type import tensorflow_is_int_dtype_bknd
        from ...backends.tensorflow.creation import tensorflow_asarray
        from ...ivy.data_type import tensorflow_default_dtype_bknd
        from .tensor import tensorflow_shape_frnt_
        from ...ivy.device import tensorflow_default_device_bknd
        from ....data_classes.array.data_type import tensorflow_astype_bknd_
    
        """Promote the dtype of the given native array inputs to a common dtype
        based on type promotion rules.
    
        While passing float or integer values or any other non-array input
        to this function, it should be noted that the return will be an
        array-like object. Therefore, outputs from this function should be
        used as inputs only for those functions that expect an array-like or
        tensor-like objects, otherwise it might give unexpected results.
        """
        if (
            tensorflow_isscalar_bknd(x1) or isinstance(x1, (list, tuple))
        ) and tensorflow_is_int_dtype_bknd(x1):
            x1 = tensorflow_asarray(x1, dtype="int64")
        elif tensorflow_isscalar_bknd(x1) or isinstance(x1, (list, tuple)):
            x1 = tensorflow_asarray(x1)
        if (
            tensorflow_isscalar_bknd(x2) or isinstance(x2, (list, tuple))
        ) and tensorflow_is_int_dtype_bknd(x2):
            x2 = tensorflow_asarray(x2, dtype="int64")
        elif tensorflow_isscalar_bknd(x2) or isinstance(x2, (list, tuple)):
            x2 = tensorflow_asarray(x2)
        type1 = tensorflow_default_dtype_bknd(item=x1).strip("u123456789")
>       type2 = tensorflow_default_dtype_bknd(item=x2).strip("u123456789")

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/__init__.py:220: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def tensorflow_default_dtype_bknd(
        *,
        dtype: Optional[Union[str, str]] = None,
        item: Optional[Union[tensorflow.Tensor, tf.Tensor]] = None,
        as_native: bool = False,
    ):
        from ..backends.tensorflow.data_type import tensorflow_as_ivy_dtype
        from ..backends.tensorflow.data_type import tensorflow_as_native_dtype
        from .general import tensorflow_exists_bknd
        from .general import tensorflow_default_bknd
    
        if tensorflow_exists_bknd(dtype):
            if as_native is True:
                return tensorflow_as_native_dtype(dtype)
            return tensorflow_as_ivy_dtype(dtype)
        as_native = tensorflow_default_bknd(as_native, False)
        if tensorflow_exists_bknd(item):
            if hasattr(item, "override_dtype_check"):
                return item.override_dtype_check()
            elif isinstance(item, (list, tuple, dict)) and len(item) == 0:
                pass
>           elif tensorflow_is_complex_dtype_bknd(item):

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:185: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_is_complex_dtype_bknd(
        dtype_in: Union[str, str, tensorflow.Tensor, tf.Tensor, Number], /
    ):
        from ..backends.tensorflow.data_type import tensorflow_dtype
        from .general import tensorflow_is_array_bknd
        from .nest import tensorflow_nested_argwhere_bknd
    
        if tensorflow_is_array_bknd(dtype_in):
            dtype_in = tensorflow_dtype(dtype_in)
        elif isinstance(dtype_in, tuple):
            dtype_in = tensorflow_default_int_dtype_bknd()
        elif isinstance(dtype_in, np.ndarray):
            return "complex" in dtype_in.dtype.name
        elif isinstance(dtype_in, Number):
            return isinstance(dtype_in, (complex, np.complexfloating))
        elif isinstance(dtype_in, (list, tuple, dict)):
            return tensorflow_nested_argwhere_bknd(
                dtype_in,
                lambda x: isinstance(x, (complex, np.complexfloating))
                or tensorflow_is_array_bknd(x)
                and "complex" in tensorflow_dtype(x),
            )
>       return "complex" in tensorflow_as_ivy_dtype_bknd(dtype_in)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:562: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_as_ivy_dtype_bknd(dtype_in: Union[str, str], /):
        from ..backends.tensorflow.data_type import tensorflow_as_ivy_dtype
    
>       return tensorflow_as_ivy_dtype(dtype_in)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:49: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_as_ivy_dtype(
        dtype_in: Union[tensorflow.DType, str, int, float, complex, bool, np.dtype], /
    ):
        from ...ivy.data_type import tensorflow_default_int_dtype_bknd
        from ...ivy.data_type import tensorflow_default_float_dtype_bknd
        from ...ivy.data_type import tensorflow_default_complex_dtype_bknd
    
        if dtype_in is int:
            return tensorflow_default_int_dtype_bknd()
        if dtype_in is float:
            return tensorflow_default_float_dtype_bknd()
        if dtype_in is complex:
            return tensorflow_default_complex_dtype_bknd()
        if dtype_in is bool:
            return str("bool")
        if isinstance(dtype_in, np.dtype):
            dtype_in = dtype_in.name
        if isinstance(dtype_in, str):
            if dtype_in in native_dtype_dict:
                dtype_str = dtype_in
            else:
                raise Exception(
                    f"Cannot convert to ivy dtype. {dtype_in} is not supported by TensorFlow backend."
                )
        else:
>           dtype_str = ivy_dtype_dict[dtype_in]
E           KeyError: tensor([[[[0.3333, 1.0000, 0.3333],
E                     [1.0000, 0.3333, 1.0000],
E                     [0.3333, 1.0000, 0.3333]]]])

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/backends/tensorflow/data_type.py:184: KeyError

During handling of the above exception, another exception occurred:

self = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
rhs = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def impl(self, rhs):
        try:
>           return original_method(self, rhs)

ivy_transpiled_outputs/tensorflow_outputs/__init__.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
rhs = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def impl(self, rhs):
        try:
            return original_method(self, rhs)
        except Exception:
>           return patched_method(self, rhs)

ivy_transpiled_outputs/tensorflow_outputs/__init__.py:65: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
other = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow___mul___frnt_(tensor, other):
        from .pointwise_ops import tensorflow_mul_frnt
    
>       return tensorflow_mul_frnt(tensor, other)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/tensor.py:95: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
other = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_mul_frnt(input, other, *, out=None):
        from .__init__ import tensorflow_promote_types_of_torch_inputs_frnt
        from ...backends.tensorflow.elementwise import tensorflow_multiply
    
>       input, other = tensorflow_promote_types_of_torch_inputs_frnt(input, other)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/pointwise_ops.py:74: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x1 = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
x2 = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_promote_types_of_torch_inputs_frnt(x1, x2, /):
        from ...ivy.general import tensorflow_isscalar_bknd
        from ...ivy.data_type import tensorflow_is_int_dtype_bknd
        from ...backends.tensorflow.creation import tensorflow_asarray
        from ...ivy.data_type import tensorflow_default_dtype_bknd
        from .tensor import tensorflow_shape_frnt_
        from ...ivy.device import tensorflow_default_device_bknd
        from ....data_classes.array.data_type import tensorflow_astype_bknd_
    
        """Promote the dtype of the given native array inputs to a common dtype
        based on type promotion rules.
    
        While passing float or integer values or any other non-array input
        to this function, it should be noted that the return will be an
        array-like object. Therefore, outputs from this function should be
        used as inputs only for those functions that expect an array-like or
        tensor-like objects, otherwise it might give unexpected results.
        """
        if (
            tensorflow_isscalar_bknd(x1) or isinstance(x1, (list, tuple))
        ) and tensorflow_is_int_dtype_bknd(x1):
            x1 = tensorflow_asarray(x1, dtype="int64")
        elif tensorflow_isscalar_bknd(x1) or isinstance(x1, (list, tuple)):
            x1 = tensorflow_asarray(x1)
        if (
            tensorflow_isscalar_bknd(x2) or isinstance(x2, (list, tuple))
        ) and tensorflow_is_int_dtype_bknd(x2):
            x2 = tensorflow_asarray(x2, dtype="int64")
        elif tensorflow_isscalar_bknd(x2) or isinstance(x2, (list, tuple)):
            x2 = tensorflow_asarray(x2)
        type1 = tensorflow_default_dtype_bknd(item=x1).strip("u123456789")
>       type2 = tensorflow_default_dtype_bknd(item=x2).strip("u123456789")

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/__init__.py:220: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def tensorflow_default_dtype_bknd(
        *,
        dtype: Optional[Union[str, str]] = None,
        item: Optional[Union[tensorflow.Tensor, tf.Tensor]] = None,
        as_native: bool = False,
    ):
        from ..backends.tensorflow.data_type import tensorflow_as_ivy_dtype
        from ..backends.tensorflow.data_type import tensorflow_as_native_dtype
        from .general import tensorflow_exists_bknd
        from .general import tensorflow_default_bknd
    
        if tensorflow_exists_bknd(dtype):
            if as_native is True:
                return tensorflow_as_native_dtype(dtype)
            return tensorflow_as_ivy_dtype(dtype)
        as_native = tensorflow_default_bknd(as_native, False)
        if tensorflow_exists_bknd(item):
            if hasattr(item, "override_dtype_check"):
                return item.override_dtype_check()
            elif isinstance(item, (list, tuple, dict)) and len(item) == 0:
                pass
>           elif tensorflow_is_complex_dtype_bknd(item):

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:185: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_is_complex_dtype_bknd(
        dtype_in: Union[str, str, tensorflow.Tensor, tf.Tensor, Number], /
    ):
        from ..backends.tensorflow.data_type import tensorflow_dtype
        from .general import tensorflow_is_array_bknd
        from .nest import tensorflow_nested_argwhere_bknd
    
        if tensorflow_is_array_bknd(dtype_in):
            dtype_in = tensorflow_dtype(dtype_in)
        elif isinstance(dtype_in, tuple):
            dtype_in = tensorflow_default_int_dtype_bknd()
        elif isinstance(dtype_in, np.ndarray):
            return "complex" in dtype_in.dtype.name
        elif isinstance(dtype_in, Number):
            return isinstance(dtype_in, (complex, np.complexfloating))
        elif isinstance(dtype_in, (list, tuple, dict)):
            return tensorflow_nested_argwhere_bknd(
                dtype_in,
                lambda x: isinstance(x, (complex, np.complexfloating))
                or tensorflow_is_array_bknd(x)
                and "complex" in tensorflow_dtype(x),
            )
>       return "complex" in tensorflow_as_ivy_dtype_bknd(dtype_in)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:562: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_as_ivy_dtype_bknd(dtype_in: Union[str, str], /):
        from ..backends.tensorflow.data_type import tensorflow_as_ivy_dtype
    
>       return tensorflow_as_ivy_dtype(dtype_in)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:49: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_as_ivy_dtype(
        dtype_in: Union[tensorflow.DType, str, int, float, complex, bool, np.dtype], /
    ):
        from ...ivy.data_type import tensorflow_default_int_dtype_bknd
        from ...ivy.data_type import tensorflow_default_float_dtype_bknd
        from ...ivy.data_type import tensorflow_default_complex_dtype_bknd
    
        if dtype_in is int:
            return tensorflow_default_int_dtype_bknd()
        if dtype_in is float:
            return tensorflow_default_float_dtype_bknd()
        if dtype_in is complex:
            return tensorflow_default_complex_dtype_bknd()
        if dtype_in is bool:
            return str("bool")
        if isinstance(dtype_in, np.dtype):
            dtype_in = dtype_in.name
        if isinstance(dtype_in, str):
            if dtype_in in native_dtype_dict:
                dtype_str = dtype_in
            else:
                raise Exception(
                    f"Cannot convert to ivy dtype. {dtype_in} is not supported by TensorFlow backend."
                )
        else:
>           dtype_str = ivy_dtype_dict[dtype_in]
E           KeyError: tensor([[[[0.3333, 1.0000, 0.3333],
E                     [1.0000, 0.3333, 1.0000],
E                     [0.3333, 1.0000, 0.3333]]]])

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/backends/tensorflow/data_type.py:184: KeyError

During handling of the above exception, another exception occurred:

self = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
rhs = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def impl(self, rhs):
        try:
>           return original_method(self, rhs)

ivy_transpiled_outputs/tensorflow_outputs/__init__.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
rhs = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def impl(self, rhs):
        try:
            return original_method(self, rhs)
        except Exception:
>           return patched_method(self, rhs)

ivy_transpiled_outputs/tensorflow_outputs/__init__.py:65: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
other = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow___mul___frnt_(tensor, other):
        from .pointwise_ops import tensorflow_mul_frnt
    
>       return tensorflow_mul_frnt(tensor, other)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/tensor.py:95: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
other = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_mul_frnt(input, other, *, out=None):
        from .__init__ import tensorflow_promote_types_of_torch_inputs_frnt
        from ...backends.tensorflow.elementwise import tensorflow_multiply
    
>       input, other = tensorflow_promote_types_of_torch_inputs_frnt(input, other)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/pointwise_ops.py:74: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x1 = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
x2 = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_promote_types_of_torch_inputs_frnt(x1, x2, /):
        from ...ivy.general import tensorflow_isscalar_bknd
        from ...ivy.data_type import tensorflow_is_int_dtype_bknd
        from ...backends.tensorflow.creation import tensorflow_asarray
        from ...ivy.data_type import tensorflow_default_dtype_bknd
        from .tensor import tensorflow_shape_frnt_
        from ...ivy.device import tensorflow_default_device_bknd
        from ....data_classes.array.data_type import tensorflow_astype_bknd_
    
        """Promote the dtype of the given native array inputs to a common dtype
        based on type promotion rules.
    
        While passing float or integer values or any other non-array input
        to this function, it should be noted that the return will be an
        array-like object. Therefore, outputs from this function should be
        used as inputs only for those functions that expect an array-like or
        tensor-like objects, otherwise it might give unexpected results.
        """
        if (
            tensorflow_isscalar_bknd(x1) or isinstance(x1, (list, tuple))
        ) and tensorflow_is_int_dtype_bknd(x1):
            x1 = tensorflow_asarray(x1, dtype="int64")
        elif tensorflow_isscalar_bknd(x1) or isinstance(x1, (list, tuple)):
            x1 = tensorflow_asarray(x1)
        if (
            tensorflow_isscalar_bknd(x2) or isinstance(x2, (list, tuple))
        ) and tensorflow_is_int_dtype_bknd(x2):
            x2 = tensorflow_asarray(x2, dtype="int64")
        elif tensorflow_isscalar_bknd(x2) or isinstance(x2, (list, tuple)):
            x2 = tensorflow_asarray(x2)
        type1 = tensorflow_default_dtype_bknd(item=x1).strip("u123456789")
>       type2 = tensorflow_default_dtype_bknd(item=x2).strip("u123456789")

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/__init__.py:220: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def tensorflow_default_dtype_bknd(
        *,
        dtype: Optional[Union[str, str]] = None,
        item: Optional[Union[tensorflow.Tensor, tf.Tensor]] = None,
        as_native: bool = False,
    ):
        from ..backends.tensorflow.data_type import tensorflow_as_ivy_dtype
        from ..backends.tensorflow.data_type import tensorflow_as_native_dtype
        from .general import tensorflow_exists_bknd
        from .general import tensorflow_default_bknd
    
        if tensorflow_exists_bknd(dtype):
            if as_native is True:
                return tensorflow_as_native_dtype(dtype)
            return tensorflow_as_ivy_dtype(dtype)
        as_native = tensorflow_default_bknd(as_native, False)
        if tensorflow_exists_bknd(item):
            if hasattr(item, "override_dtype_check"):
                return item.override_dtype_check()
            elif isinstance(item, (list, tuple, dict)) and len(item) == 0:
                pass
>           elif tensorflow_is_complex_dtype_bknd(item):

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:185: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_is_complex_dtype_bknd(
        dtype_in: Union[str, str, tensorflow.Tensor, tf.Tensor, Number], /
    ):
        from ..backends.tensorflow.data_type import tensorflow_dtype
        from .general import tensorflow_is_array_bknd
        from .nest import tensorflow_nested_argwhere_bknd
    
        if tensorflow_is_array_bknd(dtype_in):
            dtype_in = tensorflow_dtype(dtype_in)
        elif isinstance(dtype_in, tuple):
            dtype_in = tensorflow_default_int_dtype_bknd()
        elif isinstance(dtype_in, np.ndarray):
            return "complex" in dtype_in.dtype.name
        elif isinstance(dtype_in, Number):
            return isinstance(dtype_in, (complex, np.complexfloating))
        elif isinstance(dtype_in, (list, tuple, dict)):
            return tensorflow_nested_argwhere_bknd(
                dtype_in,
                lambda x: isinstance(x, (complex, np.complexfloating))
                or tensorflow_is_array_bknd(x)
                and "complex" in tensorflow_dtype(x),
            )
>       return "complex" in tensorflow_as_ivy_dtype_bknd(dtype_in)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:562: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_as_ivy_dtype_bknd(dtype_in: Union[str, str], /):
        from ..backends.tensorflow.data_type import tensorflow_as_ivy_dtype
    
>       return tensorflow_as_ivy_dtype(dtype_in)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:49: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_as_ivy_dtype(
        dtype_in: Union[tensorflow.DType, str, int, float, complex, bool, np.dtype], /
    ):
        from ...ivy.data_type import tensorflow_default_int_dtype_bknd
        from ...ivy.data_type import tensorflow_default_float_dtype_bknd
        from ...ivy.data_type import tensorflow_default_complex_dtype_bknd
    
        if dtype_in is int:
            return tensorflow_default_int_dtype_bknd()
        if dtype_in is float:
            return tensorflow_default_float_dtype_bknd()
        if dtype_in is complex:
            return tensorflow_default_complex_dtype_bknd()
        if dtype_in is bool:
            return str("bool")
        if isinstance(dtype_in, np.dtype):
            dtype_in = dtype_in.name
        if isinstance(dtype_in, str):
            if dtype_in in native_dtype_dict:
                dtype_str = dtype_in
            else:
                raise Exception(
                    f"Cannot convert to ivy dtype. {dtype_in} is not supported by TensorFlow backend."
                )
        else:
>           dtype_str = ivy_dtype_dict[dtype_in]
E           KeyError: tensor([[[[0.3333, 1.0000, 0.3333],
E                     [1.0000, 0.3333, 1.0000],
E                     [0.3333, 1.0000, 0.3333]]]])

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/backends/tensorflow/data_type.py:184: KeyError

During handling of the above exception, another exception occurred:

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_diamond_square(target_framework, mode, backend_compile):
        trace_args = ((1, 1, 8, 8),)
        trace_kwargs = {
            "roughness": 0.5,
            "random_scale": 1.0,
            "normalize_range": (0.0, 1.0),
            "random_fn": torch.ones,
        }
        test_args = ((5, 1, 8, 8),)
        test_kwargs = {
            "roughness": 0.7,
            "random_scale": 0.9,
            "normalize_range": (-1.0, 1.0),
            "random_fn": torch.ones,
        }
>       _test_function(
            kornia.contrib.diamond_square,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/test_contrib.py:141: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function diamond_square at 0x7f7ad2f63130>, trace_args = ((1, 1, 8, 8),)
trace_kwargs = {'normalize_range': (0.0, 1.0), 'random_fn': <built-in method ones of type object at 0x7f7aee84d900>, 'random_scale': 1.0, 'roughness': 0.5}, test_args = ((5, 1, 8, 8),)
test_kwargs = {'normalize_range': (-1.0, 1.0), 'random_fn': <built-in method ones of type object at 0x7f7aee84d900>, 'random_scale': 0.9, 'roughness': 0.7}, target = 'tensorflow'
backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function diamond_square at 0x7f7ad2f63130>, fn_name = 'kornia.contrib.diamond_square', trace_args = ((1, 1, 8, 8),)
trace_kwargs = {'normalize_range': (0.0, 1.0), 'random_fn': <built-in method ones of type object at 0x7f7aee84d900>, 'random_scale': 1.0, 'roughness': 0.5}, test_args = ((5, 1, 8, 8),)
test_kwargs = {'normalize_range': (-1.0, 1.0), 'random_fn': <built-in method ones of type object at 0x7f7aee84d900>, 'random_scale': 0.9, 'roughness': 0.7}, target = 'tensorflow'
backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
>           graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:326: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

output_size = (1, 1, 8, 8), roughness = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[0.5]]]], dtype=float32)>
random_scale = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>, random_fn = <built-in method ones of type object at 0x7f7aee84d900>, normalize_range = (0.0, 1.0)
device = None, dtype = None

    def tensorflow_diamond_square(
        output_size,
        roughness=0.5,
        random_scale=1.0,
        random_fn=tensorflow_rand_frnt,
        normalize_range=None,
        device=None,
        dtype=None,
    ):
        from ..core.check import tensorflow_KORNIA_CHECK
        from ...ivy.functional.frontends.torch.tensor import tensorflow_to_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_expand_frnt_
        from ..core.check import tensorflow_KORNIA_CHECK_IS_TENSOR
        from ...ivy.functional.frontends.torch.tensor import tensorflow_view_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_reshape_frnt_
        from ...ivy.functional.backends.tensorflow.general import tensorflow_get_item
        from ..enhance.normalize import tensorflow_normalize_min_max
        from ...ivy.functional.frontends.torch.tensor import tensorflow_contiguous_frnt_
    
        tensorflow_KORNIA_CHECK(len(output_size) == 4, "output_size must be (B,C,H,W)")
        if not isinstance(random_scale, (tensorflow.Tensor, tensorflow.Variable)):
            random_scale = tensorflow_to_frnt_(
                tensorflow.convert_to_tensor([[[[random_scale]]]]), device, dtype
            )
            random_scale = tensorflow_expand_frnt_(
                random_scale, [output_size[0] * output_size[1], 1, 1, 1]
            )
        else:
            tensorflow_KORNIA_CHECK_IS_TENSOR(random_scale)
            random_scale = tensorflow_view_frnt_(random_scale, -1, 1, 1, 1)
            random_scale = tensorflow_expand_frnt_(
                random_scale, [output_size[0], output_size[1], 1, 1]
            )
            random_scale = tensorflow_reshape_frnt_(random_scale, [-1, 1, 1, 1])
        if not isinstance(roughness, (tensorflow.Tensor, tensorflow.Variable)):
            roughness = tensorflow_to_frnt_(
                tensorflow.convert_to_tensor([[[[roughness]]]]), device, dtype
            )
            roughness = tensorflow_expand_frnt_(
                roughness, [output_size[0] * output_size[1], 1, 1, 1]
            )
        else:
            roughness = tensorflow_view_frnt_(roughness, -1, 1, 1, 1)
            roughness = tensorflow_expand_frnt_(
                roughness, [output_size[0], output_size[1], 1, 1]
            )
            roughness = tensorflow_reshape_frnt_(roughness, [-1, 1, 1, 1])
        width, height = output_size[-2:][0], output_size[-2:][1]
        num_samples: typing.Any = 1
        for x in output_size[:-2]:
            num_samples = num_samples * x
        p2_width: typing.Any = 2 ** math.ceil(math.log2(width - 1)) + 1
        p2_height: typing.Any = 2 ** math.ceil(math.log2(height - 1)) + 1
        recursion_depth: typing.Any = int(
            min(math.log2(p2_width - 1) - 1, math.log2(p2_height - 1) - 1)
        )
        seed_width: typing.Any = (p2_width - 1) // 2**recursion_depth + 1
        seed_height: typing.Any = (p2_height - 1) // 2**recursion_depth + 1
>       img: typing.Any = random_scale * tensorflow__diamond_square_seed(
            num_samples, seed_width, seed_height, random_fn, device, dtype
        )

ivy_transpiled_outputs/tensorflow_outputs/kornia/contrib/diamond_square.py:243: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
rhs = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def impl(self, rhs):
        try:
            return original_method(self, rhs)
        except Exception:
>           return patched_method(self, rhs)

ivy_transpiled_outputs/tensorflow_outputs/__init__.py:65: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
other = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow___mul___frnt_(tensor, other):
        from .pointwise_ops import tensorflow_mul_frnt
    
>       return tensorflow_mul_frnt(tensor, other)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/tensor.py:95: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
other = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_mul_frnt(input, other, *, out=None):
        from .__init__ import tensorflow_promote_types_of_torch_inputs_frnt
        from ...backends.tensorflow.elementwise import tensorflow_multiply
    
>       input, other = tensorflow_promote_types_of_torch_inputs_frnt(input, other)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/pointwise_ops.py:74: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x1 = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
x2 = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_promote_types_of_torch_inputs_frnt(x1, x2, /):
        from ...ivy.general import tensorflow_isscalar_bknd
        from ...ivy.data_type import tensorflow_is_int_dtype_bknd
        from ...backends.tensorflow.creation import tensorflow_asarray
        from ...ivy.data_type import tensorflow_default_dtype_bknd
        from .tensor import tensorflow_shape_frnt_
        from ...ivy.device import tensorflow_default_device_bknd
        from ....data_classes.array.data_type import tensorflow_astype_bknd_
    
        """Promote the dtype of the given native array inputs to a common dtype
        based on type promotion rules.
    
        While passing float or integer values or any other non-array input
        to this function, it should be noted that the return will be an
        array-like object. Therefore, outputs from this function should be
        used as inputs only for those functions that expect an array-like or
        tensor-like objects, otherwise it might give unexpected results.
        """
        if (
            tensorflow_isscalar_bknd(x1) or isinstance(x1, (list, tuple))
        ) and tensorflow_is_int_dtype_bknd(x1):
            x1 = tensorflow_asarray(x1, dtype="int64")
        elif tensorflow_isscalar_bknd(x1) or isinstance(x1, (list, tuple)):
            x1 = tensorflow_asarray(x1)
        if (
            tensorflow_isscalar_bknd(x2) or isinstance(x2, (list, tuple))
        ) and tensorflow_is_int_dtype_bknd(x2):
            x2 = tensorflow_asarray(x2, dtype="int64")
        elif tensorflow_isscalar_bknd(x2) or isinstance(x2, (list, tuple)):
            x2 = tensorflow_asarray(x2)
        type1 = tensorflow_default_dtype_bknd(item=x1).strip("u123456789")
>       type2 = tensorflow_default_dtype_bknd(item=x2).strip("u123456789")

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/__init__.py:220: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def tensorflow_default_dtype_bknd(
        *,
        dtype: Optional[Union[str, str]] = None,
        item: Optional[Union[tensorflow.Tensor, tf.Tensor]] = None,
        as_native: bool = False,
    ):
        from ..backends.tensorflow.data_type import tensorflow_as_ivy_dtype
        from ..backends.tensorflow.data_type import tensorflow_as_native_dtype
        from .general import tensorflow_exists_bknd
        from .general import tensorflow_default_bknd
    
        if tensorflow_exists_bknd(dtype):
            if as_native is True:
                return tensorflow_as_native_dtype(dtype)
            return tensorflow_as_ivy_dtype(dtype)
        as_native = tensorflow_default_bknd(as_native, False)
        if tensorflow_exists_bknd(item):
            if hasattr(item, "override_dtype_check"):
                return item.override_dtype_check()
            elif isinstance(item, (list, tuple, dict)) and len(item) == 0:
                pass
>           elif tensorflow_is_complex_dtype_bknd(item):

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:185: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_is_complex_dtype_bknd(
        dtype_in: Union[str, str, tensorflow.Tensor, tf.Tensor, Number], /
    ):
        from ..backends.tensorflow.data_type import tensorflow_dtype
        from .general import tensorflow_is_array_bknd
        from .nest import tensorflow_nested_argwhere_bknd
    
        if tensorflow_is_array_bknd(dtype_in):
            dtype_in = tensorflow_dtype(dtype_in)
        elif isinstance(dtype_in, tuple):
            dtype_in = tensorflow_default_int_dtype_bknd()
        elif isinstance(dtype_in, np.ndarray):
            return "complex" in dtype_in.dtype.name
        elif isinstance(dtype_in, Number):
            return isinstance(dtype_in, (complex, np.complexfloating))
        elif isinstance(dtype_in, (list, tuple, dict)):
            return tensorflow_nested_argwhere_bknd(
                dtype_in,
                lambda x: isinstance(x, (complex, np.complexfloating))
                or tensorflow_is_array_bknd(x)
                and "complex" in tensorflow_dtype(x),
            )
>       return "complex" in tensorflow_as_ivy_dtype_bknd(dtype_in)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:562: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_as_ivy_dtype_bknd(dtype_in: Union[str, str], /):
        from ..backends.tensorflow.data_type import tensorflow_as_ivy_dtype
    
>       return tensorflow_as_ivy_dtype(dtype_in)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:49: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_as_ivy_dtype(
        dtype_in: Union[tensorflow.DType, str, int, float, complex, bool, np.dtype], /
    ):
        from ...ivy.data_type import tensorflow_default_int_dtype_bknd
        from ...ivy.data_type import tensorflow_default_float_dtype_bknd
        from ...ivy.data_type import tensorflow_default_complex_dtype_bknd
    
        if dtype_in is int:
            return tensorflow_default_int_dtype_bknd()
        if dtype_in is float:
            return tensorflow_default_float_dtype_bknd()
        if dtype_in is complex:
            return tensorflow_default_complex_dtype_bknd()
        if dtype_in is bool:
            return str("bool")
        if isinstance(dtype_in, np.dtype):
            dtype_in = dtype_in.name
        if isinstance(dtype_in, str):
            if dtype_in in native_dtype_dict:
                dtype_str = dtype_in
            else:
                raise Exception(
                    f"Cannot convert to ivy dtype. {dtype_in} is not supported by TensorFlow backend."
                )
        else:
>           dtype_str = ivy_dtype_dict[dtype_in]
E           KeyError: tensor([[[[0.3333, 1.0000, 0.3333],
E                     [1.0000, 0.3333, 1.0000],
E                     [0.3333, 1.0000, 0.3333]]]])

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/backends/tensorflow/data_type.py:184: KeyError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.contrib.diamond_square.diamond_square
_______________________________________________________________________________ test_EdgeDetector[tensorflow-s2s-False] ________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_EdgeDetector(target_framework, mode, backend_compile):
        print("kornia.contrib.EdgeDetector")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledEdgeDetector = ivy.transpile(kornia.contrib.EdgeDetector, source="torch", target=target_framework)
    
        torch_detector = kornia.contrib.EdgeDetector()
>       transpiled_detector = TranspiledEdgeDetector()

kornia/test_contrib.py:163: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_EdgeDetector()

    def __init__(self):
        from ..filters.dexined import tensorflow_DexiNed
    
        self.super___init__(
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
>       self.model = tensorflow_DexiNed(pretrained=True)

ivy_transpiled_outputs/tensorflow_outputs/kornia/contrib/edge_detection.py:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_DexiNed(
  (block_1): tensorflow_DoubleConvBlock(
    (conv1): KerasConv2D()
    (bn1): KerasBatchNorm2D()
...e2d()
    )
  )
  (block_cat): tensorflow_SingleConvBlock(
    (conv): KerasConv2D()
    (bn): KerasBatchNorm2D()
  )
)
args = (), kwargs = {'pretrained': True}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_DexiNed(
  (block_1): tensorflow_DoubleConvBlock(
    (conv1): KerasConv2D()
    (bn1): KerasBatchNorm2D()
...e2d()
    )
  )
  (block_cat): tensorflow_SingleConvBlock(
    (conv): KerasConv2D()
    (bn): KerasBatchNorm2D()
  )
)
pretrained = True

    @tensorflow_store_config_info
    def __init__(self, pretrained):
        from ...torch.nn.modules.pooling import tensorflow_MaxPool2d
    
        self.super___init__(
            pretrained,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        self.block_1 = tensorflow_DoubleConvBlock(3, 32, 64, stride=2)
        self.block_2 = tensorflow_DoubleConvBlock(64, 128, use_act=False)
        self.dblock_3 = tensorflow__DenseBlock(2, 128, 256)
        self.dblock_4 = tensorflow__DenseBlock(3, 256, 512)
        self.dblock_5 = tensorflow__DenseBlock(3, 512, 512)
        self.dblock_6 = tensorflow__DenseBlock(3, 512, 256)
        self.maxpool = tensorflow_MaxPool2d(kernel_size=3, stride=2, padding=1)
        self.side_1 = tensorflow_SingleConvBlock(64, 128, 2)
        self.side_2 = tensorflow_SingleConvBlock(128, 256, 2)
        self.side_3 = tensorflow_SingleConvBlock(256, 512, 2)
        self.side_4 = tensorflow_SingleConvBlock(512, 512, 1)
        self.side_5 = tensorflow_SingleConvBlock(512, 256, 1)
        self.pre_dense_2 = tensorflow_SingleConvBlock(128, 256, 2)
        self.pre_dense_3 = tensorflow_SingleConvBlock(128, 256, 1)
        self.pre_dense_4 = tensorflow_SingleConvBlock(256, 512, 1)
        self.pre_dense_5 = tensorflow_SingleConvBlock(512, 512, 1)
        self.pre_dense_6 = tensorflow_SingleConvBlock(512, 256, 1)
        self.up_block_1 = tensorflow_UpConvBlock(64, 1)
        self.up_block_2 = tensorflow_UpConvBlock(128, 1)
        self.up_block_3 = tensorflow_UpConvBlock(256, 2)
        self.up_block_4 = tensorflow_UpConvBlock(512, 3)
        self.up_block_5 = tensorflow_UpConvBlock(512, 4)
        self.up_block_6 = tensorflow_UpConvBlock(256, 4)
        self.block_cat = tensorflow_SingleConvBlock(6, 1, stride=1, use_bs=False)
        if pretrained:
>           self.load_from_file(url)

ivy_transpiled_outputs/tensorflow_outputs/kornia/filters/dexined.py:600: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_DexiNed(
  (block_1): tensorflow_DoubleConvBlock(
    (conv1): KerasConv2D()
    (bn1): KerasBatchNorm2D()
...e2d()
    )
  )
  (block_cat): tensorflow_SingleConvBlock(
    (conv): KerasConv2D()
    (bn): KerasBatchNorm2D()
  )
)
path_file = 'http://cmp.felk.cvut.cz/~mishkdmy/models/DexiNed_BIPED_10.pth'

    def load_from_file(self, path_file):
        from ...ivy.functional.frontends.torch.hub.hub import (
            tensorflow_load_state_dict_from_url_frnt,
        )
        from ..utils.helpers import tensorflow_map_location_to_cpu
    
        pretrained_dict = tensorflow_load_state_dict_from_url_frnt(
            path_file, map_location=tensorflow_map_location_to_cpu
        )
>       self.load_state_dict(pretrained_dict, strict=True)

ivy_transpiled_outputs/tensorflow_outputs/kornia/filters/dexined.py:613: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_DexiNed(
  (block_1): tensorflow_DoubleConvBlock(
    (conv1): KerasConv2D()
    (bn1): KerasBatchNorm2D()
...e2d()
    )
  )
  (block_cat): tensorflow_SingleConvBlock(
    (conv): KerasConv2D()
    (bn): KerasBatchNorm2D()
  )
)
state_dict = OrderedDict([('block_1.conv1.weight', <tf.Tensor: shape=(32, 3, 3, 3), dtype=float32, numpy=
array([[[[ 2.31264587e-02...numpy=array([1.], dtype=float32)>), ('block_cat.bn.num_batches_tracked', <tf.Tensor: shape=(), dtype=int64, numpy=0>)])
strict = True, assign = False

    def load_state_dict(
        self,
        state_dict: typing.Mapping[str, Any],
        strict: bool = True,
        assign: bool = False,
    ):
        r"""Copy parameters and buffers from :attr:`state_dict` into this module and its descendants.
    
        If :attr:`strict` is ``True``, then
        the keys of :attr:`state_dict` must exactly match the keys returned
        by this module's :meth:`~Module.state_dict` function.
    
        Args:
            state_dict (dict): a dict containing parameters and
                persistent buffers.
            strict (bool, optional): whether to strictly enforce that the keys
                in :attr:`state_dict` match the keys returned by this module's
                :meth:`~Module.state_dict` function. Default: ``True``
    
        Returns:
            ``NamedTuple`` with ``missing_keys`` and ``unexpected_keys`` fields:
                * **missing_keys** is a list of str containing any keys that are expected
                    by this module but missing from the provided ``state_dict``.
                * **unexpected_keys** is a list of str containing the keys that are not
                    expected by this module but present in the provided ``state_dict``.
        """
        if not isinstance(state_dict, typing.Mapping):
            raise TypeError(
                f"Expected state_dict to be dict-like, got {type(state_dict)}."
            )
    
        missing_keys: List[str] = []
        unexpected_keys: List[str] = []
        error_msgs: List[str] = []
    
        state_dict = tf.nest.map_structure(
            lambda x: tf.convert_to_tensor(x.numpy()),
            state_dict,
        )
        state_dict = OrderedDict(state_dict)
    
        def load(module, local_state_dict, prefix=""):
            module._load_from_state_dict(
                local_state_dict,
                prefix,
                strict,
                missing_keys,
                unexpected_keys,
                error_msgs,
            )
            # TODO: maybe we should implement this similar to PT
            # and make this recursive.
    
>       load(self, state_dict)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:600: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

module = tensorflow_DexiNed(
  (block_1): tensorflow_DoubleConvBlock(
    (conv1): KerasConv2D()
    (bn1): KerasBatchNorm2D()
...e2d()
    )
  )
  (block_cat): tensorflow_SingleConvBlock(
    (conv): KerasConv2D()
    (bn): KerasBatchNorm2D()
  )
)
local_state_dict = OrderedDict([('block_1.conv1.weight', <tf.Tensor: shape=(32, 3, 3, 3), dtype=float32, numpy=
array([[[[ 2.31264587e-02...numpy=array([1.], dtype=float32)>), ('block_cat.bn.num_batches_tracked', <tf.Tensor: shape=(), dtype=int64, numpy=0>)])
prefix = ''

    def load(module, local_state_dict, prefix=""):
>       module._load_from_state_dict(
            local_state_dict,
            prefix,
            strict,
            missing_keys,
            unexpected_keys,
            error_msgs,
        )

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:589: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_DexiNed(
  (block_1): tensorflow_DoubleConvBlock(
    (conv1): KerasConv2D()
    (bn1): KerasBatchNorm2D()
...e2d()
    )
  )
  (block_cat): tensorflow_SingleConvBlock(
    (conv): KerasConv2D()
    (bn): KerasBatchNorm2D()
  )
)
state_dict = OrderedDict([('block_1.conv1.weight', <tf.Tensor: shape=(32, 3, 3, 3), dtype=float32, numpy=
array([[[[ 2.31264587e-02...numpy=array([1.], dtype=float32)>), ('block_cat.bn.num_batches_tracked', <tf.Tensor: shape=(), dtype=int64, numpy=0>)])
prefix = '', strict = True, missing_keys = [], unexpected_keys = [], error_msgs = []

    def _load_from_state_dict(
        self, state_dict, prefix, strict, missing_keys, unexpected_keys, error_msgs
    ):
        def _retrive_layer(model, key):
            if len(key.split(".")) == 1:
                return model, key
    
            module_path, weight_name = key.rsplit(".", 1)
    
            # Retrieve the layer using the module path
            layer = model
            for attr in module_path.split("."):
                layer = getattr(layer, attr)
    
            return layer, weight_name
    
        persistent_buffers = {k: v for k, v in self._buffers.items()}
        local_name_params = itertools.chain(
            self._parameters.items(), persistent_buffers.items()
        )
        local_state = {k: v for k, v in local_name_params if v is not None}
    
        for name, param in local_state.items():
            key = prefix + name
            if key in state_dict:
                input_param = state_dict[key]
                if not isinstance(input_param, tf.Tensor):
                    error_msgs.append(
                        f'While copying the parameter named "{key}", '
                        "expected ArrayLike object from checkpoint but "
                        f"received {type(input_param)}"
                    )
                    continue
    
                if not isinstance(input_param, KerasVariable):
>                   input_param = KerasVariable(input_param)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:522: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <KerasVariable shape=<unknown>, dtype=float32, path=variable_57>, initializer = <tf.Tensor: shape=(), dtype=int64, numpy=79200>, shape = None, dtype = 'float32', trainable = True
autocast = True, aggregation = 'mean', name = 'variable_57'

    def __init__(
        self,
        initializer,
        shape=None,
        dtype=None,
        trainable=True,
        autocast=True,
        aggregation="mean",
        name=None,
    ):
        name = name or auto_name(self.__class__.__name__)
        if not isinstance(name, str) or "/" in name:
            raise ValueError(
                "Argument `name` must be a string and "
                "cannot contain character `/`. "
                f"Received: name={name}"
            )
        if aggregation not in ("mean", "sum", "only_first_replica"):
            raise ValueError(
                "Invalid valid for argument `aggregation`. Expected "
                "one of {'mean', 'sum', 'only_first_replica'}. "
                f"Received: aggregation={aggregation}"
            )
        self.name = name
        parent_path = current_path()
        if parent_path:
            self.path = current_path() + "/" + self.name
        else:
            self.path = self.name
        dtype = standardize_dtype(dtype)
        self._dtype = dtype
        self._shape = None
        self._initializer = None
        self._regularizer = None
        self._constraint = None
        self._trainable = trainable
        self._autocast = autocast
        self._aggregation = aggregation
        # `self._overwrite_with_gradient` is an internal property to determine
        # whether this variable should be overwritten by the computed gradient.
        # Ref: https://github.com/google/flax/blob/main/flax/linen/fp8_ops.py
        self._overwrite_with_gradient = False
        if isinstance(initializer, str):
            from keras.src import initializers
    
            initializer = initializers.get(initializer)
        if callable(initializer):
            if shape is None:
                raise ValueError(
                    "When creating a Variable from an initializer, "
                    "the `shape` argument should be specified. "
                    f"Received: initializer={initializer} "
                    f"and shape={shape}"
                )
    
        if in_stateless_scope():
            if callable(initializer):
                self._value = None
                self._initializer = initializer
                self._shape = self._validate_shape(shape)
                register_uninitialized_variable(self)
            else:
                raise ValueError(
                    "You are attempting to create a variable "
                    "while in a stateless scope. This is disallowed. "
                    "Make sure that all variables are created "
                    "before you start using your layer/model objects.\n\n"
                    "In some cases, you might be seeing this error "
                    "because you need to "
                    "implement a `def build(self, input_shape)` method "
                    "on your layer/model, which will "
                    "create its variables.\n\n"
                    "In some other cases, you might be seeing this error "
                    "because you are instantiating a `Variable` and "
                    "assigning it to a layer without going through "
                    "self.add_variable()/self.add_weight(). Always prefer "
                    "using these methods "
                    "(with a `shape` and `initializer` argument)."
                )
        else:
            if callable(initializer):
                self._shape = self._validate_shape(shape)
                self._initialize_with_initializer(initializer)
            else:
>               self._initialize(initializer)

/opt/fw/tensorflow/keras/src/backend/common/variables.py:165: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <KerasVariable shape=<unknown>, dtype=float32, path=variable_57>, value = <tf.Tensor: shape=(), dtype=int64, numpy=79200>

    def _initialize(self, value):
>       self._value = tf.Variable(
            value, dtype=self._dtype, trainable=self.trainable, name=self.name
        )

/opt/fw/tensorflow/keras/src/backend/tensorflow/core.py:35: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (<class 'tensorflow.python.ops.variables.Variable'>, <tf.Tensor: shape=(), dtype=int64, numpy=79200>), kwargs = {'dtype': 'float32', 'name': 'variable_57', 'trainable': True}

    def error_handler(*args, **kwargs):
      try:
        if not is_traceback_filtering_enabled():
          return fn(*args, **kwargs)
      except NameError:
        # In some very rare cases,
        # `is_traceback_filtering_enabled` (from the outer scope) may not be
        # accessible from inside this function
        return fn(*args, **kwargs)
    
      filtered_tb = None
      try:
        return fn(*args, **kwargs)
      except Exception as e:
        filtered_tb = _process_traceback_frames(e.__traceback__)
>       raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/tensorflow/python/util/traceback_utils.py:153: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <tf.Tensor: shape=(), dtype=int64, numpy=79200>, dtype = tf.float32, name = 'initial_value'

    def __tf_tensor__(
        self, dtype: Optional[dtypes.DType] = None, name: Optional[str] = None
        ) -> "Tensor":
      if dtype is not None and not dtype.is_compatible_with(self.dtype):
>       raise ValueError(
            _add_error_prefix(
                f"Tensor conversion requested dtype {dtype.name} "
                f"for Tensor with dtype {self.dtype.name}: {self!r}",
                name=name))
E       ValueError: initial_value: Tensor conversion requested dtype float32 for Tensor with dtype int64: <tf.Tensor: shape=(), dtype=int64, numpy=79200>

/opt/fw/tensorflow/tensorflow/python/framework/tensor.py:761: ValueError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.contrib.EdgeDetector
----------------------------------------------------------------------------------------- Captured stderr call -----------------------------------------------------------------------------------------
Downloading: "http://cmp.felk.cvut.cz/~mishkdmy/models/DexiNed_BIPED_10.pth" to /root/.cache/torch/hub/checkpoints/DexiNed_BIPED_10.pth

  0%|          | 0.00/135M [00:00<?, ?B/s]
  0%|          | 128k/135M [00:00<08:34, 274kB/s]
  0%|          | 256k/135M [00:00<05:12, 450kB/s]
  0%|          | 512k/135M [00:00<02:50, 825kB/s]
  1%|          | 896k/135M [00:00<01:44, 1.34MB/s]
  1%|         | 1.75M/135M [00:01<00:51, 2.69MB/s]
  3%|         | 3.50M/135M [00:01<00:25, 5.38MB/s]
  5%|         | 6.50M/135M [00:01<00:13, 9.73MB/s]
  7%|         | 9.50M/135M [00:01<00:10, 12.7MB/s]
  9%|         | 12.4M/135M [00:01<00:08, 14.6MB/s]
 11%|        | 15.2M/135M [00:01<00:07, 15.8MB/s]
 14%|        | 18.2M/135M [00:02<00:07, 17.0MB/s]
 16%|        | 21.1M/135M [00:02<00:06, 17.6MB/s]
 18%|        | 23.9M/135M [00:02<00:06, 17.7MB/s]
 20%|        | 26.9M/135M [00:02<00:06, 18.3MB/s]
 22%|       | 29.9M/135M [00:02<00:05, 18.7MB/s]
 24%|       | 32.8M/135M [00:02<00:05, 18.7MB/s]
 26%|       | 35.6M/135M [00:03<00:05, 18.8MB/s]
 29%|       | 38.6M/135M [00:03<00:05, 19.1MB/s]
 31%|       | 41.6M/135M [00:03<00:05, 19.2MB/s]
 33%|      | 44.6M/135M [00:03<00:04, 19.4MB/s]
 35%|      | 47.6M/135M [00:03<00:04, 19.4MB/s]
 38%|      | 50.6M/135M [00:03<00:04, 19.5MB/s]
 40%|      | 53.5M/135M [00:03<00:04, 19.4MB/s]
 42%|     | 56.5M/135M [00:04<00:04, 19.5MB/s]
 44%|     | 59.5M/135M [00:04<00:04, 19.5MB/s]
 46%|     | 62.5M/135M [00:04<00:03, 19.5MB/s]
 49%|     | 65.5M/135M [00:04<00:03, 19.6MB/s]
 51%|     | 68.5M/135M [00:04<00:03, 19.6MB/s]
 53%|    | 71.1M/135M [00:04<00:03, 19.0MB/s]
 55%|    | 74.1M/135M [00:05<00:03, 19.2MB/s]
 57%|    | 77.0M/135M [00:05<00:03, 19.1MB/s]
 59%|    | 80.0M/135M [00:05<00:02, 19.2MB/s]
 62%|   | 82.9M/135M [00:05<00:02, 19.1MB/s]
 64%|   | 85.8M/135M [00:05<00:02, 19.1MB/s]
 66%|   | 88.8M/135M [00:05<00:02, 19.3MB/s]
 68%|   | 91.8M/135M [00:06<00:02, 19.3MB/s]
 70%|   | 94.8M/135M [00:06<00:02, 19.4MB/s]
 73%|  | 97.6M/135M [00:06<00:01, 19.4MB/s]
 75%|  | 100M/135M [00:06<00:01, 19.1MB/s] 
 77%|  | 104M/135M [00:06<00:01, 19.3MB/s]
 79%|  | 106M/135M [00:06<00:01, 19.2MB/s]
 81%| | 109M/135M [00:07<00:01, 19.3MB/s]
 83%| | 112M/135M [00:07<00:01, 18.9MB/s]
 86%| | 115M/135M [00:07<00:01, 19.1MB/s]
 88%| | 118M/135M [00:07<00:00, 19.1MB/s]
 90%| | 121M/135M [00:07<00:00, 19.3MB/s]
 92%|| 124M/135M [00:07<00:00, 19.4MB/s]
 94%|| 127M/135M [00:07<00:00, 19.0MB/s]
 96%|| 130M/135M [00:08<00:00, 18.9MB/s]
 99%|| 133M/135M [00:08<00:00, 19.1MB/s]
100%|| 135M/135M [00:08<00:00, 16.9MB/s]
__________________________________________________________________________________ test_KMeans[tensorflow-s2s-False] ___________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_KMeans(target_framework, mode, backend_compile):
        print("kornia.contrib.KMeans")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledKMeans = ivy.transpile(kornia.contrib.KMeans, source="torch", target=target_framework)
    
        torch_kmeans = kornia.contrib.KMeans(3, None, 10e-4, 100, 0)
        transpiled_kmeans = TranspiledKMeans(3, None, 10e-4, 100, 0)
    
        torch_x1 = torch.rand((1000, 5))
        torch_x2 = torch.rand((10, 5))
        transpiled_x1 = _array_to_new_backend(torch_x1, target_framework)
        transpiled_x2 = _array_to_new_backend(torch_x2, target_framework)
    
        torch_kmeans.fit(torch_x1)
        torch_predictions = torch_kmeans.predict(torch_x2)
    
>       transpiled_kmeans.fit(transpiled_x1)

kornia/test_contrib.py:245: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <ivy_transpiled_outputs.tensorflow_outputs.kornia.contrib.kmeans.tensorflow_KMeans object at 0x7f7a78971360>
X = <tf.Tensor: shape=(1000, 5), dtype=float32, numpy=
array([[0.4962566 , 0.7682218 , 0.08847743, 0.13203049, 0.30742282]...5, 0.49248123, 0.4287302 ],
       [0.3786084 , 0.04217941, 0.28761953, 0.5166052 , 0.11317676]],
      dtype=float32)>

    def fit(self, X):
        from ..core.check import tensorflow_KORNIA_CHECK
        from ..core.check import tensorflow_KORNIA_CHECK_SHAPE
        from ...ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_argmin_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_clone_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_squeeze_frnt_
        from ...ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            tensorflow_nonzero_frnt,
        )
        from ...ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            tensorflow_index_select_frnt,
        )
        from ...ivy.functional.frontends.torch.random_sampling import (
            tensorflow_randint_frnt,
        )
        from ...ivy.functional.frontends.torch.tensor import tensorflow_mean_frnt_
        from ...ivy.functional.frontends.torch.reduction_ops import tensorflow_sum_frnt
        from ...ivy.functional.frontends.torch.pointwise_ops import tensorflow_sqrt_frnt
    
        tensorflow_KORNIA_CHECK_SHAPE(X, ["N", "D"])
        if self._cluster_centers is None:
            self._cluster_centers = self._initialise_cluster_centers(
                X, self.num_clusters
            )
        else:
            tensorflow_KORNIA_CHECK(
                tensorflow_shape_frnt_(X)[1]
                == tensorflow_shape_frnt_(self._cluster_centers)[1],
                f"Dimensions at position 1 of X and cluster_centers do not match.                 {tensorflow_shape_frnt_(X)[1]} != {tensorflow_shape_frnt_(self._cluster_centers)[1]}",
            )
        current_centers = self._cluster_centers
        previous_centers: typing.Any = None
        iteration: typing.Any = 0
        while True:
            distance: typing.Any = self._pairwise_euclidean_distance(X, current_centers)
            cluster_assignment = tensorflow_argmin_frnt_(distance, -1)
            previous_centers = tensorflow_clone_frnt_(current_centers)
            for index in range(self.num_clusters):
                selected = tensorflow_squeeze_frnt_(
                    tensorflow_nonzero_frnt(cluster_assignment == index)
                )
                selected = tensorflow_index_select_frnt(X, 0, selected)
                if tensorflow_shape_frnt_(selected)[0] == 0:
                    selected = X[tensorflow_randint_frnt(len(X), (1,), device=X.device)]
>               current_centers[index] = tensorflow_mean_frnt_(selected, dim=0)
E               TypeError: 'tensorflow.python.framework.ops.EagerTensor' object does not support item assignment

ivy_transpiled_outputs/tensorflow_outputs/kornia/contrib/kmeans.py:146: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.contrib.KMeans
_______________________________________________________________________________ test_ImageStitcher[tensorflow-s2s-False] _______________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_ImageStitcher(target_framework, mode, backend_compile):
        print("kornia.contrib.ImageStitcher")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledLoFTR = ivy.transpile(kornia.feature.LoFTR, source="torch", target=target_framework)
        TranspiledImageStitcher = ivy.transpile(kornia.contrib.ImageStitcher, source="torch", target=target_framework)
    
        torch_matcher = kornia.feature.LoFTR(pretrained='outdoor')
>       transpiled_matcher = TranspiledLoFTR(pretrained='outdoor')

kornia/test_contrib.py:314: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_LoFTR(), pretrained = 'outdoor'
config = {'backbone_type': 'ResNetFPN', 'coarse': {'attention': 'linear', 'd_ffn': 256, 'd_model': 256, 'layer_names': ['self',...: 'linear', 'd_ffn': 128, 'd_model': 128, 'layer_names': ['self', 'cross'], ...}, 'fine_concat_coarse_feat': True, ...}

    def __init__(self, pretrained="outdoor", config=default_cfg):
        from ....ivy.functional.backends.tensorflow.general import tensorflow_set_item
        from .backbone.__init__ import tensorflow_build_backbone
        from .utils.position_encoding import tensorflow_PositionEncodingSine
        from .loftr_module.transformer import tensorflow_LocalFeatureTransformer
        from .utils.coarse_matching import tensorflow_CoarseMatching
        from .loftr_module.fine_preprocess import tensorflow_FinePreprocess
        from .utils.fine_matching import tensorflow_FineMatching
        from ....ivy.functional.frontends.torch.hub.hub import (
            tensorflow_load_state_dict_from_url_frnt,
        )
        from ....ivy.functional.backends.tensorflow.general import tensorflow_get_item
        from ...utils.helpers import tensorflow_map_location_to_cpu
    
        self.super___init__(
            pretrained=pretrained,
            config=config,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        self.config = config
        if pretrained == "indoor_new":
            self.config["coarse"] = tensorflow_set_item(
                self.config["coarse"], "temp_bug_fix", True
            )
>       self.backbone = tensorflow_build_backbone(config)

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/loftr/loftr.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

config = {'backbone_type': 'ResNetFPN', 'coarse': {'attention': 'linear', 'd_ffn': 256, 'd_model': 256, 'layer_names': ['self',...: 'linear', 'd_ffn': 128, 'd_model': 128, 'layer_names': ['self', 'cross'], ...}, 'fine_concat_coarse_feat': True, ...}

    def tensorflow_build_backbone(config):
        if config["backbone_type"] == "ResNetFPN":
            if config["resolution"] == (8, 2):
>               return kornia.feature.loftr.resnet_fpn.ResNetFPN_8_2(config["resnetfpn"])
E               NameError: name 'kornia' is not defined

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/loftr/backbone/__init__.py:41: NameError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.contrib.ImageStitcher
----------------------------------------------------------------------------------------- Captured stderr call -----------------------------------------------------------------------------------------
Downloading: "http://cmp.felk.cvut.cz/~mishkdmy/models/loftr_outdoor.ckpt" to /root/.cache/torch/hub/checkpoints/loftr_outdoor.ckpt

  0%|          | 0.00/44.2M [00:00<?, ?B/s]
  0%|          | 128k/44.2M [00:00<02:48, 274kB/s]
  1%|          | 256k/44.2M [00:00<01:42, 450kB/s]
  1%|          | 512k/44.2M [00:00<00:55, 825kB/s]
  2%|         | 896k/44.2M [00:00<00:33, 1.34MB/s]
  4%|         | 1.75M/44.2M [00:01<00:16, 2.70MB/s]
  8%|         | 3.50M/44.2M [00:01<00:07, 5.38MB/s]
 15%|        | 6.50M/44.2M [00:01<00:04, 9.73MB/s]
 21%|        | 9.38M/44.2M [00:01<00:02, 12.5MB/s]
 28%|       | 12.4M/44.2M [00:01<00:02, 14.7MB/s]
 34%|      | 14.9M/44.2M [00:01<00:02, 15.2MB/s]
 40%|      | 17.9M/44.2M [00:02<00:01, 16.5MB/s]
 47%|     | 20.8M/44.2M [00:02<00:01, 17.3MB/s]
 54%|    | 23.8M/44.2M [00:02<00:01, 17.9MB/s]
 61%|    | 26.8M/44.2M [00:02<00:00, 18.5MB/s]
 67%|   | 29.5M/44.2M [00:02<00:00, 18.3MB/s]
 73%|  | 32.4M/44.2M [00:02<00:00, 18.5MB/s]
 80%|  | 35.4M/44.2M [00:03<00:00, 18.9MB/s]
 87%| | 38.4M/44.2M [00:03<00:00, 19.1MB/s]
 94%|| 41.4M/44.2M [00:03<00:00, 19.3MB/s]
100%|| 44.2M/44.2M [00:03<00:00, 13.7MB/s]
__________________________________________________________________________________ test_Lambda[tensorflow-s2s-False] ___________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_Lambda(target_framework, mode, backend_compile):
        print("kornia.contrib.Lambda")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_fn = ivy.transpile(kornia.color.rgb_to_grayscale, source="torch", target=target_framework)
        TranspiledLambda = ivy.transpile(kornia.contrib.Lambda, source="torch", target=target_framework)
    
        x = torch.rand(1, 3, 5, 5)
        torch_out = kornia.contrib.Lambda(lambda x: kornia.color.rgb_to_grayscale(x))(x)
    
        transpiled_x = _nest_torch_tensor_to_new_framework(x, target_framework)
>       transpiled_out = TranspiledLambda(lambda x: transpiled_fn(x))(transpiled_x)

kornia/test_contrib.py:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Lambda()
args = (<tf.Tensor: shape=(1, 3, 5, 5), dtype=float32, numpy=
array([[[[0.24838495, 0.16381115, 0.9520681 , 0.86008495, 0.647...5066984, 0.3293057 ],
         [0.561671  , 0.05817503, 0.5122101 , 0.06966799, 0.7259842 ]]]],
      dtype=float32)>,)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x55aea3f5a260, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...ode_context=['        return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_Lambda(), <tf.Tensor: shape=(1, 3, 5, 5), dtype=float32, numpy=
array([[[[0.24838495, 0.16381115, 0.952068...75066984, 0.3293057 ],
         [0.561671  , 0.05817503, 0.5122101 , 0.06966799, 0.7259842 ]]]],
      dtype=float32)>)
kwargs = {}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Lambda(), v = None, buffers = None
args = (<tf.Tensor: shape=(1, 3, 5, 5), dtype=float32, numpy=
array([[[[0.24838495, 0.16381115, 0.9520681 , 0.86008495, 0.647...5066984, 0.3293057 ],
         [0.561671  , 0.05817503, 0.5122101 , 0.06966799, 0.7259842 ]]]],
      dtype=float32)>,)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:2013: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_Lambda(), <tf.Tensor: shape=(1, 3, 5, 5), dtype=float32, numpy=
array([[[[0.24838495, 0.16381115, 0.952068...75066984, 0.3293057 ],
         [0.561671  , 0.05817503, 0.5122101 , 0.06966799, 0.7259842 ]]]],
      dtype=float32)>)
kwargs = {'buffers': None, 'v': None}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Lambda(), v = None, buffers = None
args = (<tf.Tensor: shape=(1, 3, 5, 5), dtype=float32, numpy=
array([[[[0.24838495, 0.16381115, 0.9520681 , 0.86008495, 0.647...5066984, 0.3293057 ],
         [0.561671  , 0.05817503, 0.5122101 , 0.06966799, 0.7259842 ]]]],
      dtype=float32)>,)
kwargs = {}
first_arr = <tf.Tensor: shape=(1, 3, 5, 5), dtype=float32, numpy=
array([[[[0.24838495, 0.16381115, 0.9520681 , 0.86008495, 0.6474....75066984, 0.3293057 ],
         [0.561671  , 0.05817503, 0.5122101 , 0.06966799, 0.7259842 ]]]],
      dtype=float32)>
replace_v = False, replace_buffers = False, call_signature = <Signature (img, *args, **kwargs)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Model, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Model, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Model, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1783: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_Lambda(),)
kwargs = {'img': <tf.Tensor: shape=(1, 3, 5, 5), dtype=float32, numpy=
array([[[[0.24838495, 0.16381115, 0.9520681 , 0.86008495...75066984, 0.3293057 ],
         [0.561671  , 0.05817503, 0.5122101 , 0.06966799, 0.7259842 ]]]],
      dtype=float32)>}

    @wraps(fn)
    def error_handler(*args, **kwargs):
        if not is_traceback_filtering_enabled():
            return fn(*args, **kwargs)
    
        filtered_tb = None
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            filtered_tb = _process_traceback_frames(e.__traceback__)
            # To get the full stack trace, call:
            # `keras.config.disable_traceback_filtering()`
>           raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/keras/src/utils/traceback_utils.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Lambda()
img = <tf.Tensor: shape=(1, 3, 5, 5), dtype=float32, numpy=
array([[[[0.24838495, 0.16381115, 0.9520681 , 0.86008495, 0.6474....75066984, 0.3293057 ],
         [0.561671  , 0.05817503, 0.5122101 , 0.06966799, 0.7259842 ]]]],
      dtype=float32)>
args = (), kwargs = {}

    def call(self, img, *args, **kwargs):
>       return self.func(img, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/kornia/contrib/lambda_module.py:50: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = <tf.Tensor: shape=(1, 3, 5, 5), dtype=float32, numpy=
array([[[[0.24838495, 0.16381115, 0.9520681 , 0.86008495, 0.6474....75066984, 0.3293057 ],
         [0.561671  , 0.05817503, 0.5122101 , 0.06966799, 0.7259842 ]]]],
      dtype=float32)>

>   transpiled_out = TranspiledLambda(lambda x: transpiled_fn(x))(transpiled_x)

kornia/test_contrib.py:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

image = <tf.Tensor: shape=(1, 3, 5, 5), dtype=float32, numpy=
array([[[[0.24838495, 0.16381115, 0.9520681 , 0.86008495, 0.6474....75066984, 0.3293057 ],
         [0.561671  , 0.05817503, 0.5122101 , 0.06966799, 0.7259842 ]]]],
      dtype=float32)>
rgb_weights = None

>   ???
E   ModuleNotFoundError: Exception encountered when calling tensorflow_Lambda.call().
E   
E   [1mNo module named 'ivy_transpiled_outputs.tensorflow_outputs.kornia.core'[0m
E   
E   Arguments received by tensorflow_Lambda.call():
E      img=tf.Tensor(shape=(1, 3, 5, 5), dtype=float32)
E      args=<class 'inspect._empty'>
E      kwargs=<class 'inspect._empty'>

/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/kornia/color/gray.py:34: ModuleNotFoundError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.contrib.Lambda
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/test_contrib.py::test_diamond_square[tensorflow-s2s-False] - KeyError: tensor([[[[0.3333, 1.0000, 0.3333],
FAILED kornia/test_contrib.py::test_EdgeDetector[tensorflow-s2s-False] - ValueError: initial_value: Tensor conversion requested dtype float32 for Tensor with dtype int64: <tf.Tensor: shape=(), dtyp...
FAILED kornia/test_contrib.py::test_KMeans[tensorflow-s2s-False] - TypeError: 'tensorflow.python.framework.ops.EagerTensor' object does not support item assignment
FAILED kornia/test_contrib.py::test_ImageStitcher[tensorflow-s2s-False] - NameError: name 'kornia' is not defined
FAILED kornia/test_contrib.py::test_Lambda[tensorflow-s2s-False] - ModuleNotFoundError: Exception encountered when calling tensorflow_Lambda.call().
============================================================================== 5 failed, 10 passed in 1695.08s (0:28:15) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 44 items

kornia/test_filters.py ............................................                                                                                                                              [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
=================================================================================== 44 passed in 3390.82s (0:56:30) ====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 7 items

kornia/test_morphology.py .......                                                                                                                                                                [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
==================================================================================== 7 passed in 622.78s (0:10:22) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 69 items

kornia/test_color.py ...........F...........F..........F.........F...........F........F..F                                                                                                       [100%]

=============================================================================================== FAILURES ===============================================================================================
____________________________________________________________________________________ test_rgb_to_hls[jax-s2s-False] ____________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_rgb_to_hls(target_framework, mode, backend_compile):
        # Note: We test this function with requires_grad=True,
        # because otherwise we simply get an empty_like tensor
        # with garbage values on each run leading to test failures
        trace_args = (
            torch.rand(1, 3, 4, 5).requires_grad_(True),
        )
        trace_kwargs = {'eps': 1e-8}
        test_args = (
            torch.rand(5, 3, 4, 5).requires_grad_(True),
        )
        test_kwargs = {'eps': 1e-8}
>       _test_function(
            kornia.color.rgb_to_hls,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/test_color.py:291: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function rgb_to_hls at 0x7f5ecc9e5ea0>
trace_args = (tensor([[[[0.6232, 0.3623, 0.5460, 0.6901, 0.5656],
          [0.2692, 0.9665, 0.1648, 0.4626, 0.1901],
          [0.... [0.8547, 0.4699, 0.8839, 0.5832, 0.4930],
          [0.8085, 0.5107, 0.6594, 0.3401, 0.7774]]]], requires_grad=True),)
trace_kwargs = {'eps': 1e-08}
test_args = (tensor([[[[0.9828, 0.9744, 0.9103, 0.5388, 0.2407],
          [0.5704, 0.8554, 0.3400, 0.5302, 0.0863],
          [0.... [0.4673, 0.8275, 0.0578, 0.6968, 0.2704],
          [0.0739, 0.3264, 0.9141, 0.7903, 0.5921]]]], requires_grad=True),)
test_kwargs = {'eps': 1e-08}, target = 'jax', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function rgb_to_hls at 0x7f5ecc9e5ea0>, fn_name = 'kornia.color.rgb_to_hls'
trace_args = (tensor([[[[0.6232, 0.3623, 0.5460, 0.6901, 0.5656],
          [0.2692, 0.9665, 0.1648, 0.4626, 0.1901],
          [0.... [0.8547, 0.4699, 0.8839, 0.5832, 0.4930],
          [0.8085, 0.5107, 0.6594, 0.3401, 0.7774]]]], requires_grad=True),)
trace_kwargs = {'eps': 1e-08}
test_args = (tensor([[[[0.9828, 0.9744, 0.9103, 0.5388, 0.2407],
          [0.5704, 0.8554, 0.3400, 0.5302, 0.0863],
          [0.... [0.4673, 0.8275, 0.0578, 0.6968, 0.2704],
          [0.0739, 0.3264, 0.9141, 0.7903, 0.5921]]]], requires_grad=True),)
test_kwargs = {'eps': 1e-08}, target = 'jax', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
        graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
    
        if deterministic:
>           _to_numpy_and_allclose(orig_out, graph_out, tolerance=tolerance)

helpers.py:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

torch_x = tensor([[[[5.0848, 1.8031, 1.2664, 5.2498, 1.8968],
          [1.9617, 0.6092, 3.3498, 5.8157, 3.2525],
          [4.2....1934, 0.7397, 0.6277, 0.3313],
          [0.3603, 0.6133, 0.5113, 0.1317, 0.5123]]]],
       grad_fn=<StackBackward0>)
transpiled_x = Array([[[[0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.],
         [0., 0., 0., 0.,...0., 0.],
         [0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.]]]], dtype=float32)
tolerance = 0.001

    def _to_numpy_and_allclose(torch_x, transpiled_x, tolerance=1e-3):
        orig_data = _nest_array_to_numpy(torch_x)
        transpiled_data = _nest_array_to_numpy(transpiled_x)
>       _check_allclose(orig_data, transpiled_data, tolerance=tolerance)

helpers.py:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[[5.084774  , 1.803144  , 1.2663877 , 5.249795  , 1.8968122 ],
         [1.961702  , 0.6091763 , 3.3497849 , 5...0.62771386, 0.3312702 ],
         [0.36030322, 0.61325777, 0.51126957, 0.13173874, 0.5122645 ]]]],
      dtype=float32)
y = array([[[[0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.],
         [0., 0., 0., 0.,...0., 0.],
         [0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.]]]], dtype=float32)
tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
>           assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
E           AssertionError: numpy array values are not all close

helpers.py:26: AssertionError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.color.hls.rgb_to_hls
__________________________________________________________________________________ test_rgb_to_yuv420[jax-s2s-False] ___________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_rgb_to_yuv420(target_framework, mode, backend_compile):
        trace_args = (
            torch.rand(1, 3, 4, 6),
        )
        trace_kwargs = {}
        test_args = (
            torch.rand(5, 3, 4, 6),
        )
        test_kwargs = {}
>       _test_function(
            kornia.color.rgb_to_yuv420,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/test_color.py:559: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function rgb_to_yuv420 at 0x7f5ecc9e7be0>
trace_args = (tensor([[[[0.8297, 0.7748, 0.0814, 0.2623, 0.7822, 0.5434],
          [0.5107, 0.6072, 0.6311, 0.6611, 0.1122, 0.9767...     [0.4008, 0.7513, 0.5840, 0.6414, 0.9310, 0.4089],
          [0.8121, 0.8518, 0.5548, 0.1658, 0.7840, 0.9353]]]]),)
trace_kwargs = {}
test_args = (tensor([[[[0.5182, 0.1016, 0.6168, 0.1117, 0.1378, 0.9525],
          [0.8056, 0.6561, 0.0244, 0.4140, 0.3949, 0.1458...     [0.7931, 0.9035, 0.2235, 0.0089, 0.0405, 0.2050],
          [0.8391, 0.6250, 0.2165, 0.4707, 0.5645, 0.6700]]]]),)
test_kwargs = {}, target = 'jax', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function rgb_to_yuv420 at 0x7f5ecc9e7be0>, fn_name = 'kornia.color.rgb_to_yuv420'
trace_args = (tensor([[[[0.8297, 0.7748, 0.0814, 0.2623, 0.7822, 0.5434],
          [0.5107, 0.6072, 0.6311, 0.6611, 0.1122, 0.9767...     [0.4008, 0.7513, 0.5840, 0.6414, 0.9310, 0.4089],
          [0.8121, 0.8518, 0.5548, 0.1658, 0.7840, 0.9353]]]]),)
trace_kwargs = {}
test_args = (tensor([[[[0.5182, 0.1016, 0.6168, 0.1117, 0.1378, 0.9525],
          [0.8056, 0.6561, 0.0244, 0.4140, 0.3949, 0.1458...     [0.7931, 0.9035, 0.2235, 0.0089, 0.0405, 0.2050],
          [0.8391, 0.6250, 0.2165, 0.4707, 0.5645, 0.6700]]]]),)
test_kwargs = {}, target = 'jax', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
        graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
    
        if deterministic:
>           _to_numpy_and_allclose(orig_out, graph_out, tolerance=tolerance)

helpers.py:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

torch_x = (tensor([[[[0.9232, 0.3586, 0.1988, 0.2764, 0.5979, 0.4153],
          [0.1965, 0.4711, 0.5149, 0.4524, 0.4745, 0.4970...       [ 0.1393,  0.0377,  0.1183]],

         [[ 0.1695,  0.0424,  0.0943],
          [ 0.0241,  0.1034, -0.0534]]]]))
transpiled_x = (Array([[[[0.9232432 , 0.3586415 , 0.19875735, 0.27644932, 0.59791243,
          0.4152506 ],
         [0.19648626, 0....
        [[ 0.00555598,  0.20078099,  0.05629807],
         [ 0.09136092, -0.117849  ,  0.14420319]]]], dtype=float32))
tolerance = 0.001

    def _to_numpy_and_allclose(torch_x, transpiled_x, tolerance=1e-3):
        orig_data = _nest_array_to_numpy(torch_x)
        transpiled_data = _nest_array_to_numpy(transpiled_x)
>       _check_allclose(orig_data, transpiled_data, tolerance=tolerance)

helpers.py:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = (array([[[[0.9232432 , 0.3586415 , 0.19875735, 0.27644932, 0.59791243,
          0.4152506 ],
         [0.19648626, 0....
        [[ 0.16951147,  0.04242384,  0.09430189],
         [ 0.02410952,  0.10339606, -0.05339265]]]], dtype=float32))
y = (array([[[[0.9232432 , 0.3586415 , 0.19875735, 0.27644932, 0.59791243,
          0.4152506 ],
         [0.19648626, 0....
        [[ 0.00555598,  0.20078099,  0.05629807],
         [ 0.09136092, -0.117849  ,  0.14420319]]]], dtype=float32))
tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
            assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
            return
    
        if isinstance(x, (list, set, tuple)):
>           all([
                _check_allclose(element_x, element_y, tolerance=tolerance) for element_x, element_y in zip(x, y)
            ])

helpers.py:30: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

.0 = <zip object at 0x7f5e3169ea80>

    all([
>       _check_allclose(element_x, element_y, tolerance=tolerance) for element_x, element_y in zip(x, y)
    ])

helpers.py:31: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[[ 0.05106005,  0.06727172, -0.04628449],
         [ 0.13925968,  0.03768773,  0.11832815]],

        [[ 0.16951147,  0.04242384,  0.09430189],
         [ 0.02410952,  0.10339606, -0.05339265]]]], dtype=float32)
y = array([[[[ 0.02946056,  0.0559476 ,  0.07943299],
         [ 0.09975997,  0.0795882 ,  0.02313354]],

        [[ 0.00555598,  0.20078099,  0.05629807],
         [ 0.09136092, -0.117849  ,  0.14420319]]]], dtype=float32)
tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
>           assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
E           AssertionError: numpy array values are not all close

helpers.py:26: AssertionError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.color.yuv.rgb_to_yuv420
__________________________________________________________________________________ test_RgbToGrayscale[jax-s2s-False] __________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_RgbToGrayscale(target_framework, mode, backend_compile):
        args = (
            torch.rand(2, 3, 4, 5),
        )
>       _test_color_class(
            kornia.color.RgbToGrayscale,
            args,
            target_framework,
            backend_compile,
            tolerance=1e-3,
        )

kornia/test_color.py:776: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'kornia.color.gray.RgbToGrayscale'>
args = (tensor([[[[7.4828e-01, 1.5507e-01, 7.6514e-01, 8.9511e-01, 2.2257e-01],
          [5.0854e-02, 4.6591e-01, 2.3697e-01...e-01, 3.9125e-01, 3.3355e-01, 1.6532e-01],
          [8.1770e-01, 2.6811e-01, 8.3966e-01, 4.8491e-01, 2.9668e-01]]]]),)
target = 'jax', backend_compile = False, tolerance = 0.001, init_args = ()

    def _test_color_class(
        cls,
        args,
        target,
        backend_compile=False,
        tolerance=1e-3,
        init_args=(),
    ):
        print(f"{cls.__module__}.{cls.__name__}")
    
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
    
        torch_obj = cls(*init_args)
        transpiled_obj = eval("transpiled_" + f"{cls.__module__}.{cls.__name__}")(*init_args)
    
        torch_out = torch_obj(*args)
        transpile_args = _nest_torch_tensor_to_new_framework(args, target)
>       transpiled_out = transpiled_obj(*transpile_args)

kornia/test_color.py:38: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_RgbToGrayscale()
image = Array([[[[7.4828404e-01, 1.5507197e-01, 7.6514381e-01, 8.9510971e-01,
          2.2256893e-01],
         [5.0853908e-0...-01],
         [8.1769544e-01, 2.6810527e-01, 8.3966351e-01, 4.8491073e-01,
          2.9667586e-01]]]], dtype=float32)

    def __call__(self, image):
>       return jax_rgb_to_grayscale(image, rgb_weights=self.rgb_weights)

ivy_transpiled_outputs/jax_outputs/kornia/color/gray.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

image = Array([[[[7.4828404e-01, 1.5507197e-01, 7.6514381e-01, 8.9510971e-01,
          2.2256893e-01],
         [5.0853908e-0...-01],
         [8.1769544e-01, 2.6810527e-01, 8.3966351e-01, 4.8491073e-01,
          2.9667586e-01]]]], dtype=float32)
rgb_weights = Param(
  value=[0.299, 0.587, 0.114]
)

    def jax_rgb_to_grayscale(image, rgb_weights=None):
        from ..core.check import jax_KORNIA_CHECK_IS_TENSOR
        from ...ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ...ivy.functional.frontends.torch.creation_ops import jax_tensor_frnt
        from ...ivy.functional.frontends.torch.tensor import jax_to_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_unbind_frnt_
    
        jax_KORNIA_CHECK_IS_TENSOR(image)
        if len(jax_shape_frnt_(image)) < 3 or jax_shape_frnt_(image)[-3] != 3:
            raise ValueError(
                f"Input size must have a shape of (*, 3, H, W). Got {jax_shape_frnt_(image)}"
            )
        if rgb_weights is None:
            if image.dtype == jnp.uint8:
                rgb_weights = jax_tensor_frnt(
                    [76, 150, 29], device=image.device, dtype=jnp.uint8
                )
            elif image.dtype in (jnp.float16, jnp.float32, jnp.float64):
                rgb_weights = jax_tensor_frnt(
                    [0.299, 0.587, 0.114], device=image.device, dtype=image.dtype
                )
            else:
                raise TypeError(f"Unknown data type: {image.dtype}")
        else:
>           rgb_weights = jax_to_frnt_(rgb_weights, image)

ivy_transpiled_outputs/jax_outputs/kornia/color/gray.py:58: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (Param(
  value=[0.299, 0.587, 0.114]
), Array([[[[7.4828404e-01, 1.5507197e-01, 7.6514381e-01, 8.9510971e-01,
       ...01],
         [8.1769544e-01, 2.6810527e-01, 8.3966351e-01, 4.8491073e-01,
          2.9667586e-01]]]], dtype=float32))
kwargs = {}, jax_is_array_bknd = <function jax_is_array_bknd at 0x7f5e799f6d40>, array_like = Param(
  value=[0.299, 0.587, 0.114]
)

    @functools.wraps(fn)
    def wrapper(*args, **kwargs):
        from ..functional.ivy.general import jax_is_array_bknd
    
        array_like = args[0]
        if hasattr(array_like, "__class__") and array_like.__class__.__name__ in [
            "list",
            "tuple",
        ]:
            array_like = array_like[0]
        if jax_is_array_bknd(array_like):
>           return fn(*args, **kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/utils/decorator_utils.py:200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = Param(
  value=[0.299, 0.587, 0.114]
)
args = (Array([[[[7.4828404e-01, 1.5507197e-01, 7.6514381e-01, 8.9510971e-01,
          2.2256893e-01],
         [5.0853908e-...1],
         [8.1769544e-01, 2.6810527e-01, 8.3966351e-01, 4.8491073e-01,
          2.9667586e-01]]]], dtype=float32),)
kwargs = {}, jax_is_array_bknd = <function jax_is_array_bknd at 0x7f5e799f6d40>, jax_dev = <function jax_dev at 0x7f5e799f7be0>, jax_dtype = <function jax_dtype at 0x7f5e799f7a30>
jax_check_elem_in_list = <function jax_check_elem_in_list at 0x7f5e799f1870>, jax_as_ivy_dev = <function jax_as_ivy_dev at 0x7f5e799f7d00>, jax_asarray = <function jax_asarray at 0x7f5e799f7520>
_all_ivy_dtypes_str = ('int8', 'int16', 'int32', 'int64', 'uint8', 'uint16', ...), device = 'cpu', dtype = 'float32'
arg = Array([[[[7.4828404e-01, 1.5507197e-01, 7.6514381e-01, 8.9510971e-01,
          2.2256893e-01],
         [5.0853908e-0...-01],
         [8.1769544e-01, 2.6810527e-01, 8.3966351e-01, 4.8491073e-01,
          2.9667586e-01]]]], dtype=float32)

    @jax_handle_methods
    def jax_to_frnt_(tensor, *args, **kwargs):
        from ...ivy.general import jax_is_array_bknd
        from ...backends.jax.device import jax_dev
        from ...backends.jax.data_type import jax_dtype
        from ....utils.assertions import jax_check_elem_in_list
        from ...backends.jax.device import jax_as_ivy_dev
        from ...backends.jax.creation import jax_asarray
        from ....__init__ import _all_ivy_dtypes_str
    
        device = None
        dtype = None
        for arg in args:
            if hasattr(arg, "ivy_array") or jax_is_array_bknd(arg):
                device = jax_dev(arg)
                dtype = jax_dtype(arg)
            elif (
                isinstance(arg, (np.dtype,))
                or isinstance(arg, (str,))
                and hasattr(arg, "as_native_dtype")
                or arg in _all_ivy_dtypes_str
            ):
                dtype = arg
            elif isinstance(arg, (str, jax.Device, str)):
                if isinstance(arg, (str,)) and not isinstance(arg, (str, jax.Device)):
                    jax_check_elem_in_list(
                        arg,
                        [
                            "cpu",
                            "cuda",
                            "mps",
                            "xpu",
                            "mkldnn",
                            "opengl",
                            "opencl",
                            "ideep",
                            "hip",
                            "ve",
                            "ort",
                            "mlc",
                            "xla",
                            "lazy",
                            "vulkan",
                            "meta",
                            "hpu",
                        ],
                    )
                device = arg
        if "device" in kwargs:
            device = kwargs["device"]
        if "dtype" in kwargs:
            dtype = kwargs["dtype"]
>       if (dtype is None or tensor.dtype == dtype) and (
            device is None or tensor.device == jax_as_ivy_dev(device)
        ):

ivy_transpiled_outputs/jax_outputs/ivy/functional/frontends/torch/tensor.py:189: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = Param(
  value=[0.299, 0.587, 0.114]
), name = 'dtype'

    def custom_getattr(self, name):
        if name in ("shape", "device", "dtype", "ndim", "size", "itemsize", "T"):
            value = getattr(self, "value")
            if value is not None:
                # Attempt to retrieve the attribute from the wrapped object (`value`)
>               return getattr(value, name)
E               AttributeError: 'list' object has no attribute 'dtype'

ivy_transpiled_outputs/jax_outputs/__init__.py:90: AttributeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.color.gray.RgbToGrayscale
_____________________________________________________________________________________ test_RgbToHls[jax-s2s-False] _____________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_RgbToHls(target_framework, mode, backend_compile):
        args = (
            torch.rand(2, 3, 4, 5),
        )
>       _test_color_class(
            kornia.color.RgbToHls,
            args,
            target_framework,
            backend_compile,
            tolerance=1e-3,
        )

kornia/test_color.py:908: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'kornia.color.hls.RgbToHls'>
args = (tensor([[[[0.4059, 0.7956, 0.0991, 0.1594, 0.5018],
          [0.1643, 0.1561, 0.9857, 0.4338, 0.7308],
          [0...., 0.3616],
          [0.9311, 0.7134, 0.7961, 0.0783, 0.1865],
          [0.4479, 0.5880, 0.8218, 0.2551, 0.7720]]]]),)
target = 'jax', backend_compile = False, tolerance = 0.001, init_args = ()

    def _test_color_class(
        cls,
        args,
        target,
        backend_compile=False,
        tolerance=1e-3,
        init_args=(),
    ):
        print(f"{cls.__module__}.{cls.__name__}")
    
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
    
        torch_obj = cls(*init_args)
        transpiled_obj = eval("transpiled_" + f"{cls.__module__}.{cls.__name__}")(*init_args)
    
        torch_out = torch_obj(*args)
        transpile_args = _nest_torch_tensor_to_new_framework(args, target)
        transpiled_out = transpiled_obj(*transpile_args)
    
        orig_np = _nest_array_to_numpy(torch_out)
        graph_np = _nest_array_to_numpy(transpiled_out)
    
>       _check_allclose(orig_np, graph_np, tolerance=tolerance)

kornia/test_color.py:43: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[[0.66005224, 6.2462335 , 3.9330459 , 2.6767907 , 1.088836  ],
         [1.9641439 , 3.4662037 , 1.0007862 , 3...0.7582348 , 0.892772  ],
         [0.60310405, 0.4861145 , 0.68677264, 0.6971593 , 0.7393588 ]]]],
      dtype=float32)
y = array([[[[0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.],
         [0., 0., 0., 0.,...0., 0.],
         [0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.]]]], dtype=float32)
tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
>           assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
E           AssertionError: numpy array values are not all close

helpers.py:26: AssertionError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.color.hls.RgbToHls
___________________________________________________________________________________ test_RgbToYuv420[jax-s2s-False] ____________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_RgbToYuv420(target_framework, mode, backend_compile):
        args = (
            torch.rand(2, 3, 4, 6),
        )
>       _test_color_class(
            kornia.color.RgbToYuv420,
            args,
            target_framework,
            backend_compile,
            tolerance=1e-3,
        )

kornia/test_color.py:1064: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'kornia.color.yuv.RgbToYuv420'>
args = (tensor([[[[0.6913, 0.1068, 0.6644, 0.8308, 0.4133, 0.1951],
          [0.7455, 0.9739, 0.4520, 0.8408, 0.5627, 0.2414...     [0.1382, 0.1977, 0.2194, 0.6179, 0.9341, 0.7439],
          [0.6816, 0.4847, 0.4568, 0.6150, 0.2941, 0.0916]]]]),)
target = 'jax', backend_compile = False, tolerance = 0.001, init_args = ()

    def _test_color_class(
        cls,
        args,
        target,
        backend_compile=False,
        tolerance=1e-3,
        init_args=(),
    ):
        print(f"{cls.__module__}.{cls.__name__}")
    
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
    
        torch_obj = cls(*init_args)
        transpiled_obj = eval("transpiled_" + f"{cls.__module__}.{cls.__name__}")(*init_args)
    
        torch_out = torch_obj(*args)
        transpile_args = _nest_torch_tensor_to_new_framework(args, target)
        transpiled_out = transpiled_obj(*transpile_args)
    
        orig_np = _nest_array_to_numpy(torch_out)
        graph_np = _nest_array_to_numpy(transpiled_out)
    
>       _check_allclose(orig_np, graph_np, tolerance=tolerance)

kornia/test_color.py:43: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = (array([[[[0.86148536, 0.5650018 , 0.7993169 , 0.6432514 , 0.7531636 ,
          0.34523338],
         [0.73634267, 0....
        [[-0.14234981, -0.02705019,  0.1829776 ],
         [ 0.04854786, -0.03429345,  0.01172917]]]], dtype=float32))
y = (array([[[[0.86148536, 0.5650018 , 0.7993169 , 0.6432514 , 0.7531636 ,
          0.34523338],
         [0.73634267, 0.....01316638e-01,  3.70187685e-02],
         [-2.69055758e-02,  9.39048827e-03, -6.61966279e-02]]]],
      dtype=float32))
tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
            assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
            return
    
        if isinstance(x, (list, set, tuple)):
>           all([
                _check_allclose(element_x, element_y, tolerance=tolerance) for element_x, element_y in zip(x, y)
            ])

helpers.py:30: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

.0 = <zip object at 0x7f5e30aa6c00>

    all([
>       _check_allclose(element_x, element_y, tolerance=tolerance) for element_x, element_y in zip(x, y)
    ])

helpers.py:31: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[[-0.02801624, -0.08865402,  0.01308305],
         [-0.14630625, -0.02635356, -0.08682619]],

        [[-0.063...

        [[-0.14234981, -0.02705019,  0.1829776 ],
         [ 0.04854786, -0.03429345,  0.01172917]]]], dtype=float32)
y = array([[[[-1.04094245e-01, -6.95335418e-02, -1.71114832e-01],
         [ 7.62587860e-02, -4.92340587e-02, -4.53553312e...1.01316638e-01,  3.70187685e-02],
         [-2.69055758e-02,  9.39048827e-03, -6.61966279e-02]]]],
      dtype=float32)
tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
>           assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
E           AssertionError: numpy array values are not all close

helpers.py:26: AssertionError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.color.yuv.RgbToYuv420
______________________________________________________________________________________ test_Sepia[jax-s2s-False] _______________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_Sepia(target_framework, mode, backend_compile):
        args = (
            torch.ones(3, 1, 1),
        )
>       _test_color_class(
            kornia.color.Sepia,
            args,
            target_framework,
            backend_compile,
            tolerance=1e-3,
        )

kornia/test_color.py:1198: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'kornia.color.sepia.Sepia'>, args = (tensor([[[1.]],

        [[1.]],

        [[1.]]]),), target = 'jax', backend_compile = False, tolerance = 0.001, init_args = ()

    def _test_color_class(
        cls,
        args,
        target,
        backend_compile=False,
        tolerance=1e-3,
        init_args=(),
    ):
        print(f"{cls.__module__}.{cls.__name__}")
    
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
    
        torch_obj = cls(*init_args)
>       transpiled_obj = eval("transpiled_" + f"{cls.__module__}.{cls.__name__}")(*init_args)

kornia/test_color.py:34: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   AttributeError: '_cython_3_0_11.cython_function_or_method' object has no attribute 'Sepia'

<string>:1: AttributeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.color.sepia.Sepia
__________________________________________________________________________________ test_apply_colormap[jax-s2s-False] __________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_apply_colormap(target_framework, mode, backend_compile):
        print("kornia.color.ColorMap")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledColorMapType = ivy.transpile(kornia.color.ColorMapType, source="torch", target=target_framework)
        TranspiledColorMap = ivy.transpile(kornia.color.ColorMap, source="torch", target=target_framework)
        transpiled_apply_colormap = ivy.transpile(kornia.color.apply_colormap, source="torch", target=target_framework)
    
        torch_x = torch.tensor([[[0, 1, 2], [15, 25, 33], [128, 158, 188]]])
        transpiled_x = _array_to_new_backend(torch_x, target_framework)
    
        colormap = kornia.color.ColorMap(base=kornia.color.ColorMapType.autumn)
        torch_out = kornia.color.apply_colormap(torch_x, colormap)
    
>       colormap = TranspiledColorMap(base=TranspiledColorMapType.autumn)

kornia/test_color.py:1258: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <ivy_transpiled_outputs.jax_outputs.kornia.color.colormap.jax_ColorMap object at 0x7f5e30d80880>, base = <jax_ColorMapType.autumn: 1>, num_colors = 64, device = None, dtype = None

>   ???

ivy_transpiled_outputs/jax_outputs/kornia/color/colormap.py:119: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <jax_ColorMapType.autumn: 1>

        f"`input_tensor` must be a Tensor. Got: {type(input_tensor)}",
    )
>   valid_types = [
        jnp.float16,
        jnp.float32,
        jnp.float64,
        jnp.uint8,
        jnp.int32,
        jnp.int64,
        jnp.int16,
    ]
E   ModuleNotFoundError: No module named 'ivy_transpiled_outputs.jax_outputs.kornia.color._colormap_data'

ivy_transpiled_outputs/jax_outputs/kornia/color/colormap.py:53: ModuleNotFoundError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.color.ColorMap
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/test_color.py::test_rgb_to_hls[jax-s2s-False] - AssertionError: numpy array values are not all close
FAILED kornia/test_color.py::test_rgb_to_yuv420[jax-s2s-False] - AssertionError: numpy array values are not all close
FAILED kornia/test_color.py::test_RgbToGrayscale[jax-s2s-False] - AttributeError: 'list' object has no attribute 'dtype'
FAILED kornia/test_color.py::test_RgbToHls[jax-s2s-False] - AssertionError: numpy array values are not all close
FAILED kornia/test_color.py::test_RgbToYuv420[jax-s2s-False] - AssertionError: numpy array values are not all close
FAILED kornia/test_color.py::test_Sepia[jax-s2s-False] - AttributeError: '_cython_3_0_11.cython_function_or_method' object has no attribute 'Sepia'
FAILED kornia/test_color.py::test_apply_colormap[jax-s2s-False] - ModuleNotFoundError: No module named 'ivy_transpiled_outputs.jax_outputs.kornia.color._colormap_data'
============================================================================== 7 failed, 62 passed in 3857.61s (1:04:17) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 39 items

kornia/test_enhance.py ....F....F...FFFFF........sssssssssssss                                                                                                                                   [100%]

=============================================================================================== FAILURES ===============================================================================================
__________________________________________________________________________________ test_adjust_gamma[numpy-s2s-False] __________________________________________________________________________________

target_framework = 'numpy', mode = 's2s', backend_compile = False

    def test_adjust_gamma(target_framework, mode, backend_compile):
        trace_args = (
            torch.rand(1, 1, 2, 2),
            2.2,
        )
        trace_kwargs = {}
        test_args = (
            torch.rand(5, 1, 2, 2),
            0.4,
        )
        test_kwargs = {}
>       _test_function(
            kornia.enhance.adjust_gamma,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/test_enhance.py:128: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function adjust_gamma at 0x7f06a4e6eb00>, trace_args = (tensor([[[[0.5527, 0.8566],
          [0.9780, 0.6386]]]]), 2.2), trace_kwargs = {}
test_args = (tensor([[[[0.9693, 0.9028],
          [0.8328, 0.5747]]],


        [[[0.4003, 0.4147],
          [0.9439, 0.9290]]],...   [[[0.2342, 0.1575],
          [0.1226, 0.5123]]],


        [[[0.4057, 0.9693],
          [0.5296, 0.2737]]]]), 0.4)
test_kwargs = {}, target = 'numpy', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function adjust_gamma at 0x7f06a4e6eb00>, fn_name = 'kornia.enhance.adjust_gamma', trace_args = (tensor([[[[0.5527, 0.8566],
          [0.9780, 0.6386]]]]), 2.2), trace_kwargs = {}
test_args = (tensor([[[[0.9693, 0.9028],
          [0.8328, 0.5747]]],


        [[[0.4003, 0.4147],
          [0.9439, 0.9290]]],...   [[[0.2342, 0.1575],
          [0.1226, 0.5123]]],


        [[[0.4057, 0.9693],
          [0.5296, 0.2737]]]]), 0.4)
test_kwargs = {}, target = 'numpy', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = array([[[[0.55269104, 0.8565976 ],
         [0.97800785, 0.63859904]]]], dtype=float32), gamma = 2.2, gain = 1.0

    def numpy_adjust_gamma(input, gamma, gain=1.0):
        from ...ivy.functional.frontends.torch.tensor import numpy_to_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_any_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_shape_frnt_
        from ...ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            numpy_unsqueeze_frnt,
        )
        from ...ivy.functional.frontends.torch.pointwise_ops import numpy_pow_frnt
        from ...ivy.functional.frontends.torch.pointwise_ops import numpy_clamp_frnt
    
        if not isinstance(input, (numpy.ndarray, numpy.ndarray)):
            raise TypeError(f"Input type is not a Tensor. Got {type(input)}")
        if not isinstance(gamma, (float, numpy.ndarray, numpy.ndarray)):
            raise TypeError(
                f"The gamma should be a positive float or Tensor. Got {type(gamma)}"
            )
        if not isinstance(gain, (float, numpy.ndarray, numpy.ndarray)):
            raise TypeError(
                f"The gain should be a positive float or Tensor. Got {type(gain)}"
            )
        if isinstance(gamma, (float,)):
>           gamma = numpy.ndarray([gamma])
E           TypeError: 'float' object cannot be interpreted as an integer

ivy_transpiled_outputs/numpy_outputs/kornia/enhance/adjust.py:52: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.enhance.adjust.adjust_gamma
_____________________________________________________________________________________ test_invert[numpy-s2s-False] _____________________________________________________________________________________

target_framework = 'numpy', mode = 's2s', backend_compile = False

    def test_invert(target_framework, mode, backend_compile):
        trace_args = (torch.rand(1, 1, 2, 2),)
        trace_kwargs = {}
        test_args = (torch.rand(5, 1, 2, 2),)
        test_kwargs = {}
>       _test_function(
            kornia.enhance.invert,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/test_enhance.py:244: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function invert at 0x7f06a4e6f640>, trace_args = (tensor([[[[0.5583, 0.2343],
          [0.7222, 0.3790]]]]),), trace_kwargs = {}
test_args = (tensor([[[[0.8831, 0.3519],
          [0.5470, 0.6803]]],


        [[[0.7187, 0.2586],
          [0.4445, 0.9915]]],...       [[[0.5035, 0.5333],
          [0.3084, 0.3912]]],


        [[[0.2629, 0.1505],
          [0.0985, 0.3735]]]]),)
test_kwargs = {}, target = 'numpy', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function invert at 0x7f06a4e6f640>, fn_name = 'kornia.enhance.invert', trace_args = (tensor([[[[0.5583, 0.2343],
          [0.7222, 0.3790]]]]),), trace_kwargs = {}
test_args = (tensor([[[[0.8831, 0.3519],
          [0.5470, 0.6803]]],


        [[[0.7187, 0.2586],
          [0.4445, 0.9915]]],...       [[[0.5035, 0.5333],
          [0.3084, 0.3912]]],


        [[[0.2629, 0.1505],
          [0.0985, 0.3735]]]]),)
test_kwargs = {}, target = 'numpy', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:136: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   ivy.utils.exceptions.IvyException: Error loading module ivy_transpiled_outputs.numpy_outputs.kornia.enhance.adjust: 'float' object cannot be interpreted as an integer

IXC.pyx:379: IvyException
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.enhance.adjust.invert
____________________________________________________________________________________ test_equalize[numpy-s2s-False] ____________________________________________________________________________________

target_framework = 'numpy', mode = 's2s', backend_compile = False

    def test_equalize(target_framework, mode, backend_compile):
        trace_args = (torch.rand(1, 2, 3, 3),)
        trace_kwargs = {}
        test_args = (torch.rand(5, 2, 3, 3),)
        test_kwargs = {}
>       _test_function(
            kornia.enhance.equalize,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
            skip=True,
        )

kornia/test_enhance.py:335: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function equalize at 0x7f06a4e6f490>
trace_args = (tensor([[[[0.3545, 0.4457, 0.1064],
          [0.4623, 0.9201, 0.3711],
          [0.8000, 0.3334, 0.1131]],

         [[0.0058, 0.6266, 0.6893],
          [0.2570, 0.7450, 0.9659],
          [0.7924, 0.6665, 0.1609]]]]),)
trace_kwargs = {}
test_args = (tensor([[[[0.4006, 0.3409, 0.6597],
          [0.7376, 0.2715, 0.7633],
          [0.6241, 0.2226, 0.0653]],

       ...74]],

         [[0.0797, 0.9127, 0.7703],
          [0.5415, 0.7152, 0.9477],
          [0.3374, 0.1264, 0.8558]]]]),)
test_kwargs = {}, target = 'numpy', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = True, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function equalize at 0x7f06a4e6f490>, fn_name = 'kornia.enhance.equalize'
trace_args = (tensor([[[[0.3545, 0.4457, 0.1064],
          [0.4623, 0.9201, 0.3711],
          [0.8000, 0.3334, 0.1131]],

         [[0.0058, 0.6266, 0.6893],
          [0.2570, 0.7450, 0.9659],
          [0.7924, 0.6665, 0.1609]]]]),)
trace_kwargs = {}
test_args = (tensor([[[[0.4006, 0.3409, 0.6597],
          [0.7376, 0.2715, 0.7633],
          [0.6241, 0.2226, 0.0653]],

       ...74]],

         [[0.0797, 0.9127, 0.7703],
          [0.5415, 0.7152, 0.9477],
          [0.3374, 0.1264, 0.8558]]]]),)
test_kwargs = {}, target = 'numpy', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = array([[[[0.35453928, 0.44570303, 0.10637653],
         [0.4623434 , 0.92008114, 0.3711493 ],
         [0.800012  , 0....3012 ],
         [0.25697112, 0.74504733, 0.9658648 ],
         [0.7923575 , 0.6664622 , 0.16093856]]]], dtype=float32)
args = (), kwargs = {}, numpy_numel_frnt_ = <function numpy_numel_frnt_ at 0x7f06477c0ca0>, numpy_shape_frnt_ = <function numpy_shape_frnt_ at 0x7f06477c0430>
numpy_view_frnt_ = <function numpy_view_frnt_ at 0x7f06477c1000>, input_shape = ivy.frontends.torch.Size([1, 2, 3, 3])

    @wraps(f)
    def _wrapper(input, *args, **kwargs):
        from ...ivy.functional.frontends.torch.tensor import numpy_numel_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_view_frnt_
    
        if not isinstance(input, (numpy.ndarray, numpy.ndarray)):
            raise TypeError(f"Input input type is not a Tensor. Got {type(input)}")
        if numpy_numel_frnt_(input) == 0:
            raise ValueError("Invalid input tensor, it is empty.")
        input_shape = numpy_shape_frnt_(input)
        input = numpy__to_bchw(input)
>       output = f(input, *args, **kwargs)

ivy_transpiled_outputs/numpy_outputs/kornia/utils/image.py:70: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = array([[[[0.35453928, 0.44570303, 0.10637653],
         [0.4623434 , 0.92008114, 0.3711493 ],
         [0.800012  , 0....3012 ],
         [0.25697112, 0.74504733, 0.9658648 ],
         [0.7923575 , 0.6664622 , 0.16093856]]]], dtype=float32)

    @numpy_perform_keep_shape_image
    def numpy_equalize(input):
        from ...ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            numpy_stack_frnt,
        )
        from ...ivy.functional.backends.numpy.general import numpy_get_item
    
        res = []
        for image in input:
            scaled_image = numpy_stack_frnt(
>               [
                    numpy__scale_channel(
                        numpy_get_item(
                            image, (i, slice(None, None, None), slice(None, None, None))
                        )
                    )
                    for i in range(len(image))
                ]
            )

ivy_transpiled_outputs/numpy_outputs/kornia/enhance/adjust.py:111: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

.0 = <range_iterator object at 0x7f0647885530>

        [
>           numpy__scale_channel(
                numpy_get_item(
                    image, (i, slice(None, None, None), slice(None, None, None))
                )
            )
            for i in range(len(image))
        ]
    )

ivy_transpiled_outputs/numpy_outputs/kornia/enhance/adjust.py:112: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

im = array([[ 90.40752 , 113.654274,  27.126015],
       [117.89757 , 234.6207  ,  94.643074],
       [204.00305 ,  85.00747 ,  28.831606]], dtype=float32)

    def numpy__scale_channel(im):
        from ...ivy.functional.frontends.torch.tensor import numpy_min_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_max_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_item_frnt_
        from ...ivy.functional.frontends.torch.comparison_ops import numpy_isclose_frnt
        from ...ivy.functional.frontends.torch.creation_ops import numpy_as_tensor_frnt
        from ...ivy.functional.frontends.torch.tensor import numpy_shape_frnt_
        from ..utils.helpers import numpy__torch_histc_cast
        from ...ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            numpy_reshape_frnt,
        )
        from ...ivy.functional.backends.numpy.general import numpy_get_item
        from ...ivy.functional.frontends.torch.pointwise_ops import numpy_div_frnt
        from ...ivy.functional.frontends.torch.reduction_ops import numpy_sum_frnt
        from ...ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            numpy_gather_frnt,
        )
        from ...ivy.functional.frontends.torch.tensor import numpy_long_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_flatten_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_reshape_as_frnt_
    
        min_ = numpy_min_frnt_(im)
        max_ = numpy_max_frnt_(im)
        if numpy_item_frnt_(min_) < 0.0 and not numpy_isclose_frnt(
            min_, numpy_as_tensor_frnt(0.0, dtype=min_.dtype)
        ):
            raise ValueError(
                f"Values in the input tensor must greater or equal to 0.0. Found {numpy_item_frnt_(min_)}."
            )
        if numpy_item_frnt_(max_) > 1.0 and not numpy_isclose_frnt(
            max_, numpy_as_tensor_frnt(1.0, dtype=max_.dtype)
        ):
            raise ValueError(
                f"Values in the input tensor must lower or equal to 1.0. Found {numpy_item_frnt_(max_)}."
            )
        ndims = len(numpy_shape_frnt_(im))
        if ndims not in (2, 3):
            raise TypeError(f"Input tensor must have 2 or 3 dimensions. Found {ndims}.")
        im = im * 255.0
        histo = numpy__torch_histc_cast(im, bins=256, min=0, max=255)
        nonzero_histo = numpy_reshape_frnt(numpy_get_item(histo, histo != 0), [-1])
>       step = numpy_div_frnt(
            numpy_sum_frnt(nonzero_histo) - nonzero_histo[-1], 255, rounding_mode="trunc"
        )

ivy_transpiled_outputs/numpy_outputs/kornia/enhance/adjust.py:88: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = 8.0, other = 255

    def numpy_div_frnt(input, other, *, rounding_mode=None, out=None):
        from .__init__ import numpy_promote_types_of_torch_inputs_frnt
        from ...backends.numpy.data_type import numpy_astype
        from ...ivy.elementwise import numpy_trunc_divide_bknd
        from ...backends.numpy.elementwise import numpy_floor_divide
        from ...backends.numpy.elementwise import numpy_divide
    
>       input, other = numpy_promote_types_of_torch_inputs_frnt(input, other)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/pointwise_ops.py:55: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x1 = array(8., dtype=float32), x2 = array(255)

    def numpy_promote_types_of_torch_inputs_frnt(x1, x2, /):
        from ...ivy.general import numpy_isscalar_bknd
        from ...ivy.data_type import numpy_is_int_dtype_bknd
        from ...backends.numpy.creation import numpy_asarray
        from ...ivy.data_type import numpy_default_dtype_bknd
        from .tensor import numpy_shape_frnt_
        from ...ivy.device import numpy_default_device_bknd
        from ....data_classes.array.data_type import numpy_astype_bknd_
    
        """Promote the dtype of the given native array inputs to a common dtype
        based on type promotion rules.
    
        While passing float or integer values or any other non-array input
        to this function, it should be noted that the return will be an
        array-like object. Therefore, outputs from this function should be
        used as inputs only for those functions that expect an array-like or
        tensor-like objects, otherwise it might give unexpected results.
        """
        if (
            numpy_isscalar_bknd(x1) or isinstance(x1, (list, tuple))
        ) and numpy_is_int_dtype_bknd(x1):
            x1 = numpy_asarray(x1, dtype="int64")
        elif numpy_isscalar_bknd(x1) or isinstance(x1, (list, tuple)):
            x1 = numpy_asarray(x1)
        if (
            numpy_isscalar_bknd(x2) or isinstance(x2, (list, tuple))
        ) and numpy_is_int_dtype_bknd(x2):
            x2 = numpy_asarray(x2, dtype="int64")
        elif numpy_isscalar_bknd(x2) or isinstance(x2, (list, tuple)):
            x2 = numpy_asarray(x2)
        type1 = numpy_default_dtype_bknd(item=x1).strip("u123456789")
        type2 = numpy_default_dtype_bknd(item=x2).strip("u123456789")
        if numpy_shape_frnt_(x1) != () and numpy_shape_frnt_(x2) == () and type1 == type2:
            x2 = numpy_asarray(
                x2,
                dtype=x1.dtype,
                device=numpy_default_device_bknd(item=x1, as_native=False),
            )
        elif numpy_shape_frnt_(x1) == () and numpy_shape_frnt_(x2) != () and type1 == type2:
            x1 = numpy_asarray(
                x1,
                dtype=x2.dtype,
                device=numpy_default_device_bknd(item=x2, as_native=False),
            )
        elif x1.dtype != x2.dtype:
>           promoted = numpy_promote_types_torch_frnt(x1.dtype, x2.dtype)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/__init__.py:87: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

type1 = dtype('float32'), type2 = dtype('int64')

    def numpy_promote_types_torch_frnt(type1, type2, /):
        from ...backends.numpy.general import numpy_get_item
        from ...backends.numpy.data_type import numpy_as_ivy_dtype
    
        try:
            ret = numpy_get_item(
>               torch_promotion_table,
                (numpy_as_ivy_dtype(type1), numpy_as_ivy_dtype(type2)),
            )
E           NameError: name 'torch_promotion_table' is not defined

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/__init__.py:34: NameError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.enhance.adjust.equalize
_________________________________________________________________________________ test_equalize_clahe[numpy-s2s-False] _________________________________________________________________________________

target_framework = 'numpy', mode = 's2s', backend_compile = False

    def test_equalize_clahe(target_framework, mode, backend_compile):
        trace_args = (torch.rand(1, 10, 20),)
        trace_kwargs = {
            "clip_limit": 40.0,
            "grid_size": (8, 8),
            "slow_and_differentiable": False,
        }
        test_args = (torch.rand(2, 3, 10, 20),)
        test_kwargs = {
            "clip_limit": 20.0,
            "grid_size": (4, 4),
            "slow_and_differentiable": False,
        }
>       _test_function(
            kornia.enhance.equalize_clahe,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
            skip=True,
        )

kornia/test_enhance.py:363: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function equalize_clahe at 0x7f06a4e99480>
trace_args = (tensor([[[9.3047e-01, 7.2800e-01, 6.9576e-01, 8.6207e-01, 3.9860e-01,
          9.6629e-01, 1.4471e-01, 2.5383e-02, 7...985e-01, 4.2093e-03, 1.1434e-01, 7.8516e-01,
          3.4504e-01, 7.9453e-01, 7.5630e-01, 8.0761e-01, 7.9429e-01]]]),)
trace_kwargs = {'clip_limit': 40.0, 'grid_size': (8, 8), 'slow_and_differentiable': False}
test_args = (tensor([[[[0.2203, 0.4222, 0.0692,  ..., 0.5445, 0.2113, 0.9710],
          [0.9791, 0.5842, 0.0620,  ..., 0.1236, 0...., 0.1465, 0.3663,  ..., 0.9820, 0.3206, 0.4812],
          [0.2588, 0.6778, 0.4688,  ..., 0.8272, 0.5278, 0.2935]]]]),)
test_kwargs = {'clip_limit': 20.0, 'grid_size': (4, 4), 'slow_and_differentiable': False}, target = 'numpy', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = True, deterministic = True
class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function equalize_clahe at 0x7f06a4e99480>, fn_name = 'kornia.enhance.equalize_clahe'
trace_args = (tensor([[[9.3047e-01, 7.2800e-01, 6.9576e-01, 8.6207e-01, 3.9860e-01,
          9.6629e-01, 1.4471e-01, 2.5383e-02, 7...985e-01, 4.2093e-03, 1.1434e-01, 7.8516e-01,
          3.4504e-01, 7.9453e-01, 7.5630e-01, 8.0761e-01, 7.9429e-01]]]),)
trace_kwargs = {'clip_limit': 40.0, 'grid_size': (8, 8), 'slow_and_differentiable': False}
test_args = (tensor([[[[0.2203, 0.4222, 0.0692,  ..., 0.5445, 0.2113, 0.9710],
          [0.9791, 0.5842, 0.0620,  ..., 0.1236, 0...., 0.1465, 0.3663,  ..., 0.9820, 0.3206, 0.4812],
          [0.2588, 0.6778, 0.4688,  ..., 0.8272, 0.5278, 0.2935]]]]),)
test_kwargs = {'clip_limit': 20.0, 'grid_size': (4, 4), 'slow_and_differentiable': False}, target = 'numpy', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = array([[[[9.3047315e-01, 7.2800094e-01, 6.9575959e-01, 8.6206675e-01,
          3.9859849e-01, 9.6629465e-01, 1.447113...6203e-01, 3.4503800e-01,
          7.9452795e-01, 7.5629646e-01, 8.0760950e-01, 7.9429340e-01]]]],
      dtype=float32)
args = (), kwargs = {'clip_limit': 40.0, 'grid_size': (8, 8), 'slow_and_differentiable': False}, numpy_numel_frnt_ = <function numpy_numel_frnt_ at 0x7f06479db7f0>
numpy_shape_frnt_ = <function numpy_shape_frnt_ at 0x7f0647f92950>, numpy_view_frnt_ = <function numpy_view_frnt_ at 0x7f06479d96c0>, input_shape = ivy.frontends.torch.Size([1, 10, 20])

    @wraps(f)
    def _wrapper(input, *args, **kwargs):
        from ...ivy.functional.frontends.torch.tensor import numpy_numel_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_view_frnt_
    
        if not isinstance(input, (numpy.ndarray, numpy.ndarray)):
            raise TypeError(f"Input input type is not a Tensor. Got {type(input)}")
        if numpy_numel_frnt_(input) == 0:
            raise ValueError("Invalid input tensor, it is empty.")
        input_shape = numpy_shape_frnt_(input)
        input = numpy__to_bchw(input)
>       output = f(input, *args, **kwargs)

ivy_transpiled_outputs/numpy_outputs/kornia/utils/image.py:70: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = array([[[[9.3047315e-01, 7.2800094e-01, 6.9575959e-01, 8.6206675e-01,
          3.9859849e-01, 9.6629465e-01, 1.447113...6203e-01, 3.4503800e-01,
          7.9452795e-01, 7.5629646e-01, 8.0760950e-01, 7.9429340e-01]]]],
      dtype=float32)
clip_limit = 40.0, grid_size = (8, 8), slow_and_differentiable = False

    @numpy_perform_keep_shape_image
    def numpy_equalize_clahe(
        input, clip_limit=40.0, grid_size=(8, 8), slow_and_differentiable=False
    ):
        from ...ivy.functional.frontends.torch.tensor import numpy_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_reshape_as_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_permute_frnt_
        from ...ivy.functional.backends.numpy.general import numpy_get_item
        from ...ivy.functional.frontends.torch.tensor import numpy_dim_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_squeeze_frnt_
    
        if not isinstance(clip_limit, (float,)):
            raise TypeError(f"Input clip_limit type is not float. Got {type(clip_limit)}")
        if not isinstance(grid_size, (tuple,)):
            raise TypeError(f"Input grid_size type is not Tuple. Got {type(grid_size)}")
        if len(grid_size) != 2:
            raise TypeError(
                f"Input grid_size is not a Tuple with 2 elements. Got {len(grid_size)}"
            )
        if isinstance(grid_size[0], (float,)) or isinstance(grid_size[1], (float,)):
            raise TypeError("Input grid_size type is not valid, must be a Tuple[int, int].")
        if grid_size[0] <= 0 or grid_size[1] <= 0:
            raise ValueError(f"Input grid_size elements must be positive. Got {grid_size}")
        imgs: typing.Any = input
>       hist_tiles, img_padded = numpy__compute_tiles(imgs, grid_size, True)

ivy_transpiled_outputs/numpy_outputs/kornia/enhance/equalization.py:488: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

imgs = array([[[[9.3047315e-01, 7.2800094e-01, 6.9575959e-01, 8.6206675e-01,
          3.9859849e-01, 9.6629465e-01, 1.447113...6203e-01, 3.4503800e-01,
          7.9452795e-01, 7.5629646e-01, 8.0760950e-01, 7.9429340e-01]]]],
      dtype=float32)
grid_size = (8, 8), even_tile_size = True

    def numpy__compute_tiles(imgs, grid_size, even_tile_size=False):
        from ...ivy.functional.frontends.torch.tensor import numpy_shape_frnt_
        from ...ivy.functional.frontends.torch.nn.functional.vision_functions import (
            numpy_pad_frnt,
        )
        from ...ivy.functional.frontends.torch.tensor import numpy_contiguous_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_squeeze_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_unfold_frnt_
    
        batch: typing.Any = imgs
        h, w = numpy_shape_frnt_(batch)[-2:][0], numpy_shape_frnt_(batch)[-2:][1]
        kernel_vert: typing.Any = math.ceil(h / grid_size[0])
        kernel_horz: typing.Any = math.ceil(w / grid_size[1])
        if even_tile_size:
            kernel_vert = kernel_vert + (1 if kernel_vert % 2 else 0)
            kernel_horz = kernel_horz + (1 if kernel_horz % 2 else 0)
        pad_vert = kernel_vert * grid_size[0] - h
        pad_horz = kernel_horz * grid_size[1] - w
        if (
            pad_vert > numpy_shape_frnt_(batch)[-2]
            or pad_horz > numpy_shape_frnt_(batch)[-1]
        ):
            raise ValueError(
                "Cannot compute tiles on the image according to the given grid size"
            )
        if pad_vert > 0 or pad_horz > 0:
            batch = numpy_pad_frnt(batch, [0, pad_horz, 0, pad_vert], mode="reflect")
        c: typing.Any = numpy_shape_frnt_(batch)[-3]
        tiles: typing.Any = numpy_contiguous_frnt_(
            numpy_squeeze_frnt_(
                numpy_unfold_frnt_(
>                   numpy_unfold_frnt_(
                        numpy_unfold_frnt_(batch, 1, c, c), 2, kernel_vert, kernel_vert
                    ),
                    3,
                    kernel_horz,
                    kernel_horz,
                ),
                1,
            )
        )

ivy_transpiled_outputs/numpy_outputs/kornia/enhance/equalization.py:64: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (array([[[[[9.3047315e-01, 8.9184260e-01, 3.9377767e-01, 2.2156233e-01,
           8.0316341e-01, 4.3903714e-01, 4.044...9708257e-02,
           1.8299025e-01, 9.8831314e-01, 9.5295167e-01, 7.9369497e-01]]]]],
      dtype=float32), 2, 2, 2)
kwargs = {}, numpy_is_array_bknd = <function numpy_is_array_bknd at 0x7f0647aca9e0>
array_like = array([[[[[9.3047315e-01, 8.9184260e-01, 3.9377767e-01, 2.2156233e-01,
           8.0316341e-01, 4.3903714e-01, 4.0446...99e-01, 3.9708257e-02,
           1.8299025e-01, 9.8831314e-01, 9.5295167e-01, 7.9369497e-01]]]]],
      dtype=float32)

    @functools.wraps(fn)
    def wrapper(*args, **kwargs):
        from ..functional.ivy.general import numpy_is_array_bknd
    
        array_like = args[0]
        if hasattr(array_like, "__class__") and array_like.__class__.__name__ in [
            "list",
            "tuple",
        ]:
            array_like = array_like[0]
        if numpy_is_array_bknd(array_like):
>           return fn(*args, **kwargs)

ivy_transpiled_outputs/numpy_outputs/ivy/utils/decorator_utils.py:200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = array([[[[[9.3047315e-01, 8.9184260e-01, 3.9377767e-01, 2.2156233e-01,
           8.0316341e-01, 4.3903714e-01, 4.0446...99e-01, 3.9708257e-02,
           1.8299025e-01, 9.8831314e-01, 9.5295167e-01, 7.9369497e-01]]]]],
      dtype=float32)
dimension = 2, size = 2, step = 2

    @numpy_handle_methods
    def numpy_unfold_frnt_(tensor, dimension, size, step):
        from ...backends.numpy.general import numpy_get_item
        from ...backends.numpy.general import numpy_set_item
        from .indexing_slicing_joining_mutating_ops import numpy_stack_frnt
    
        slices = []
        self_shape = tuple(numpy_shape_frnt_(tensor))
        for i in range(0, numpy_get_item(self_shape, dimension) - size + 1, step):
            slicing = [slice(None)] * len(numpy_shape_frnt_(tensor))
            slicing = numpy_set_item(slicing, dimension, slice(i, i + size))
            slices.append(numpy_get_item(tensor, tuple(slicing)))
>       stacked = numpy_stack_frnt(slices, dim=dimension)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/tensor.py:257: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensors = [], dim = 2

    def numpy_stack_frnt(tensors, dim=0, *, out=None):
        from ...backends.numpy.manipulation import numpy_stack
    
>       return numpy_stack(tensors, axis=dim, out=out)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/indexing_slicing_joining_mutating_ops.py:119: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

arrays = []

    def numpy_stack(
        arrays: Union[Tuple[np.ndarray], List[np.ndarray]],
        /,
        *,
        axis: int = 0,
        out: Optional[np.ndarray] = None,
    ):
>       return np.stack(arrays, axis, out=out)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/backends/numpy/manipulation.py:117: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

arrays = [], axis = 2, out = None

    @array_function_dispatch(_stack_dispatcher)
    def stack(arrays, axis=0, out=None, *, dtype=None, casting="same_kind"):
        """
        Join a sequence of arrays along a new axis.
    
        The ``axis`` parameter specifies the index of the new axis in the
        dimensions of the result. For example, if ``axis=0`` it will be the first
        dimension and if ``axis=-1`` it will be the last dimension.
    
        .. versionadded:: 1.10.0
    
        Parameters
        ----------
        arrays : sequence of array_like
            Each array must have the same shape.
    
        axis : int, optional
            The axis in the result array along which the input arrays are stacked.
    
        out : ndarray, optional
            If provided, the destination to place the result. The shape must be
            correct, matching that of what stack would have returned if no
            out argument were specified.
    
        dtype : str or dtype
            If provided, the destination array will have this dtype. Cannot be
            provided together with `out`.
    
            .. versionadded:: 1.24
    
        casting : {'no', 'equiv', 'safe', 'same_kind', 'unsafe'}, optional
            Controls what kind of data casting may occur. Defaults to 'same_kind'.
    
            .. versionadded:: 1.24
    
    
        Returns
        -------
        stacked : ndarray
            The stacked array has one more dimension than the input arrays.
    
        See Also
        --------
        concatenate : Join a sequence of arrays along an existing axis.
        block : Assemble an nd-array from nested lists of blocks.
        split : Split array into a list of multiple sub-arrays of equal size.
    
        Examples
        --------
        >>> arrays = [np.random.randn(3, 4) for _ in range(10)]
        >>> np.stack(arrays, axis=0).shape
        (10, 3, 4)
    
        >>> np.stack(arrays, axis=1).shape
        (3, 10, 4)
    
        >>> np.stack(arrays, axis=2).shape
        (3, 4, 10)
    
        >>> a = np.array([1, 2, 3])
        >>> b = np.array([4, 5, 6])
        >>> np.stack((a, b))
        array([[1, 2, 3],
               [4, 5, 6]])
    
        >>> np.stack((a, b), axis=-1)
        array([[1, 4],
               [2, 5],
               [3, 6]])
    
        """
        arrays = [asanyarray(arr) for arr in arrays]
        if not arrays:
>           raise ValueError('need at least one array to stack')
E           ValueError: need at least one array to stack

/opt/fw/mxnet/numpy/core/shape_base.py:445: ValueError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.enhance.equalization.equalize_clahe
___________________________________________________________________________________ test_equalize3d[numpy-s2s-False] ___________________________________________________________________________________

target_framework = 'numpy', mode = 's2s', backend_compile = False

    def test_equalize3d(target_framework, mode, backend_compile):
        trace_args = (torch.rand(1, 2, 3, 3, 3),)
        trace_kwargs = {}
        test_args = (torch.rand(5, 2, 3, 3, 3),)
        test_kwargs = {}
>       _test_function(
            kornia.enhance.equalize3d,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
            skip=True,
        )

kornia/test_enhance.py:383: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function equalize3d at 0x7f06a4e6f5b0>
trace_args = (tensor([[[[[0.6978, 0.9521, 0.2694],
           [0.1398, 0.4177, 0.7870],
           [0.2077, 0.2679, 0.9696]],

    ...,

          [[0.8604, 0.0947, 0.4895],
           [0.4647, 0.2400, 0.9595],
           [0.3268, 0.2823, 0.1576]]]]]),)
trace_kwargs = {}
test_args = (tensor([[[[[0.3569, 0.1537, 0.3925],
           [0.5726, 0.6303, 0.2619],
           [0.8417, 0.7440, 0.1388]],

    ...,

          [[0.3308, 0.5764, 0.0645],
           [0.6357, 0.9875, 0.7531],
           [0.3025, 0.9585, 0.5893]]]]]),)
test_kwargs = {}, target = 'numpy', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = True, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function equalize3d at 0x7f06a4e6f5b0>, fn_name = 'kornia.enhance.equalize3d'
trace_args = (tensor([[[[[0.6978, 0.9521, 0.2694],
           [0.1398, 0.4177, 0.7870],
           [0.2077, 0.2679, 0.9696]],

    ...,

          [[0.8604, 0.0947, 0.4895],
           [0.4647, 0.2400, 0.9595],
           [0.3268, 0.2823, 0.1576]]]]]),)
trace_kwargs = {}
test_args = (tensor([[[[[0.3569, 0.1537, 0.3925],
           [0.5726, 0.6303, 0.2619],
           [0.8417, 0.7440, 0.1388]],

    ...,

          [[0.3308, 0.5764, 0.0645],
           [0.6357, 0.9875, 0.7531],
           [0.3025, 0.9585, 0.5893]]]]]),)
test_kwargs = {}, target = 'numpy', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = array([[[[[0.69784003, 0.95210403, 0.26941586],
          [0.13976198, 0.41774446, 0.78701806],
          [0.20772415,...32],
          [0.4646594 , 0.23996663, 0.9594951 ],
          [0.32678658, 0.28233236, 0.15760285]]]]], dtype=float32)
args = (), kwargs = {}, numpy_numel_frnt_ = <function numpy_numel_frnt_ at 0x7f064e068dc0>, numpy_shape_frnt_ = <function numpy_shape_frnt_ at 0x7f064e069cf0>
numpy_view_frnt_ = <function numpy_view_frnt_ at 0x7f064e06a4d0>, input_shape = ivy.frontends.torch.Size([1, 2, 3, 3, 3])

    @wraps(f)
    def _wrapper(input, *args, **kwargs):
        from ...ivy.functional.frontends.torch.tensor import numpy_numel_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_view_frnt_
    
        if not isinstance(input, (numpy.ndarray, numpy.ndarray)):
            raise TypeError(f"Input input type is not a Tensor. Got {type(input)}")
        if numpy_numel_frnt_(input) == 0:
            raise ValueError("Invalid input tensor, it is empty.")
        input_shape = numpy_shape_frnt_(input)
        input = numpy__to_bcdhw(input)
>       output = f(input, *args, **kwargs)

ivy_transpiled_outputs/numpy_outputs/kornia/utils/image.py:71: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = array([[[[[0.69784003, 0.95210403, 0.26941586],
          [0.13976198, 0.41774446, 0.78701806],
          [0.20772415,...32],
          [0.4646594 , 0.23996663, 0.9594951 ],
          [0.32678658, 0.28233236, 0.15760285]]]]], dtype=float32)

    @numpy_perform_keep_shape_video
    def numpy_equalize3d(input):
        from ...ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            numpy_stack_frnt,
        )
        from ...ivy.functional.backends.numpy.general import numpy_get_item
    
        res = []
        for volume in input:
            scaled_input = numpy_stack_frnt(
>               [
                    numpy__scale_channel(
                        numpy_get_item(
                            volume,
                            (
                                i,
                                slice(None, None, None),
                                slice(None, None, None),
                                slice(None, None, None),
                            ),
                        )
                    )
                    for i in range(len(volume))
                ]
            )

ivy_transpiled_outputs/numpy_outputs/kornia/enhance/adjust.py:111: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

.0 = <range_iterator object at 0x7f0650ce5e60>

        [
>           numpy__scale_channel(
                numpy_get_item(
                    volume,
                    (
                        i,
                        slice(None, None, None),
                        slice(None, None, None),
                        slice(None, None, None),
                    ),
                )
            )
            for i in range(len(volume))
        ]
    )

ivy_transpiled_outputs/numpy_outputs/kornia/enhance/adjust.py:112: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

im = array([[[177.9492  , 242.78653 ,  68.70104 ],
        [ 35.639305, 106.52483 , 200.6896  ],
        [ 52.969658,  68.3...7.25731 ],
        [169.51991 , 206.40009 , 249.1618  ],
        [118.77767 , 136.27248 , 177.4286  ]]], dtype=float32)

    def numpy__scale_channel(im):
        from ...ivy.functional.frontends.torch.tensor import numpy_min_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_max_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_item_frnt_
        from ...ivy.functional.frontends.torch.comparison_ops import numpy_isclose_frnt
        from ...ivy.functional.frontends.torch.creation_ops import numpy_as_tensor_frnt
        from ...ivy.functional.frontends.torch.tensor import numpy_shape_frnt_
        from ..utils.helpers import numpy__torch_histc_cast
        from ...ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            numpy_reshape_frnt,
        )
        from ...ivy.functional.backends.numpy.general import numpy_get_item
        from ...ivy.functional.frontends.torch.pointwise_ops import numpy_div_frnt
        from ...ivy.functional.frontends.torch.reduction_ops import numpy_sum_frnt
        from ...ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            numpy_gather_frnt,
        )
        from ...ivy.functional.frontends.torch.tensor import numpy_long_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_flatten_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_reshape_as_frnt_
    
        min_ = numpy_min_frnt_(im)
        max_ = numpy_max_frnt_(im)
        if numpy_item_frnt_(min_) < 0.0 and not numpy_isclose_frnt(
            min_, numpy_as_tensor_frnt(0.0, dtype=min_.dtype)
        ):
            raise ValueError(
                f"Values in the input tensor must greater or equal to 0.0. Found {numpy_item_frnt_(min_)}."
            )
        if numpy_item_frnt_(max_) > 1.0 and not numpy_isclose_frnt(
            max_, numpy_as_tensor_frnt(1.0, dtype=max_.dtype)
        ):
            raise ValueError(
                f"Values in the input tensor must lower or equal to 1.0. Found {numpy_item_frnt_(max_)}."
            )
        ndims = len(numpy_shape_frnt_(im))
        if ndims not in (2, 3):
            raise TypeError(f"Input tensor must have 2 or 3 dimensions. Found {ndims}.")
        im = im * 255.0
        histo = numpy__torch_histc_cast(im, bins=256, min=0, max=255)
        nonzero_histo = numpy_reshape_frnt(numpy_get_item(histo, histo != 0), [-1])
>       step = numpy_div_frnt(
            numpy_sum_frnt(nonzero_histo) - nonzero_histo[-1], 255, rounding_mode="trunc"
        )

ivy_transpiled_outputs/numpy_outputs/kornia/enhance/adjust.py:88: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = 26.0, other = 255

    def numpy_div_frnt(input, other, *, rounding_mode=None, out=None):
        from .__init__ import numpy_promote_types_of_torch_inputs_frnt
        from ...backends.numpy.data_type import numpy_astype
        from ...ivy.elementwise import numpy_trunc_divide_bknd
        from ...backends.numpy.elementwise import numpy_floor_divide
        from ...backends.numpy.elementwise import numpy_divide
    
>       input, other = numpy_promote_types_of_torch_inputs_frnt(input, other)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/pointwise_ops.py:55: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x1 = array(26., dtype=float32), x2 = array(255)

    def numpy_promote_types_of_torch_inputs_frnt(x1, x2, /):
        from ...ivy.general import numpy_isscalar_bknd
        from ...ivy.data_type import numpy_is_int_dtype_bknd
        from ...backends.numpy.creation import numpy_asarray
        from ...ivy.data_type import numpy_default_dtype_bknd
        from .tensor import numpy_shape_frnt_
        from ...ivy.device import numpy_default_device_bknd
        from ....data_classes.array.data_type import numpy_astype_bknd_
    
        """Promote the dtype of the given native array inputs to a common dtype
        based on type promotion rules.
    
        While passing float or integer values or any other non-array input
        to this function, it should be noted that the return will be an
        array-like object. Therefore, outputs from this function should be
        used as inputs only for those functions that expect an array-like or
        tensor-like objects, otherwise it might give unexpected results.
        """
        if (
            numpy_isscalar_bknd(x1) or isinstance(x1, (list, tuple))
        ) and numpy_is_int_dtype_bknd(x1):
            x1 = numpy_asarray(x1, dtype="int64")
        elif numpy_isscalar_bknd(x1) or isinstance(x1, (list, tuple)):
            x1 = numpy_asarray(x1)
        if (
            numpy_isscalar_bknd(x2) or isinstance(x2, (list, tuple))
        ) and numpy_is_int_dtype_bknd(x2):
            x2 = numpy_asarray(x2, dtype="int64")
        elif numpy_isscalar_bknd(x2) or isinstance(x2, (list, tuple)):
            x2 = numpy_asarray(x2)
        type1 = numpy_default_dtype_bknd(item=x1).strip("u123456789")
        type2 = numpy_default_dtype_bknd(item=x2).strip("u123456789")
        if numpy_shape_frnt_(x1) != () and numpy_shape_frnt_(x2) == () and type1 == type2:
            x2 = numpy_asarray(
                x2,
                dtype=x1.dtype,
                device=numpy_default_device_bknd(item=x1, as_native=False),
            )
        elif numpy_shape_frnt_(x1) == () and numpy_shape_frnt_(x2) != () and type1 == type2:
            x1 = numpy_asarray(
                x1,
                dtype=x2.dtype,
                device=numpy_default_device_bknd(item=x2, as_native=False),
            )
        elif x1.dtype != x2.dtype:
>           promoted = numpy_promote_types_torch_frnt(x1.dtype, x2.dtype)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/__init__.py:87: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

type1 = dtype('float32'), type2 = dtype('int64')

    def numpy_promote_types_torch_frnt(type1, type2, /):
        from ...backends.numpy.general import numpy_get_item
        from ...backends.numpy.data_type import numpy_as_ivy_dtype
    
        try:
            ret = numpy_get_item(
>               torch_promotion_table,
                (numpy_as_ivy_dtype(type1), numpy_as_ivy_dtype(type2)),
            )
E           NameError: name 'torch_promotion_table' is not defined

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/__init__.py:34: NameError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.enhance.adjust.equalize3d
___________________________________________________________________________________ test_histogram[numpy-s2s-False] ____________________________________________________________________________________

target_framework = 'numpy', mode = 's2s', backend_compile = False

    def test_histogram(target_framework, mode, backend_compile):
        trace_args = (
            torch.rand(1, 10),
            torch.linspace(0, 255, 128),
            torch.tensor(0.9),
        )
        trace_kwargs = {"epsilon": 1e-10}
        test_args = (
            torch.rand(5, 10),
            torch.linspace(0, 255, 128),
            torch.tensor(0.9),
        )
        test_kwargs = {"epsilon": 1e-10}
>       _test_function(
            kornia.enhance.histogram,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/test_enhance.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function histogram at 0x7f06a4e98ee0>
trace_args = (tensor([[0.1694, 0.5539, 0.7618, 0.6169, 0.3558, 0.4051, 0.5428, 0.1800, 0.6369,
         0.2304]]), tensor([  0.0000...    238.9370, 240.9449, 242.9528, 244.9606, 246.9685, 248.9764, 250.9843,
        252.9921, 255.0000]), tensor(0.9000))
trace_kwargs = {'epsilon': 1e-10}
test_args = (tensor([[0.3687, 0.8798, 0.6295, 0.3094, 0.4582, 0.6707, 0.1695, 0.4836, 0.5960,
         0.5606],
        [0.0333, 0...    238.9370, 240.9449, 242.9528, 244.9606, 246.9685, 248.9764, 250.9843,
        252.9921, 255.0000]), tensor(0.9000))
test_kwargs = {'epsilon': 1e-10}, target = 'numpy', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function histogram at 0x7f06a4e98ee0>, fn_name = 'kornia.enhance.histogram'
trace_args = (tensor([[0.1694, 0.5539, 0.7618, 0.6169, 0.3558, 0.4051, 0.5428, 0.1800, 0.6369,
         0.2304]]), tensor([  0.0000...    238.9370, 240.9449, 242.9528, 244.9606, 246.9685, 248.9764, 250.9843,
        252.9921, 255.0000]), tensor(0.9000))
trace_kwargs = {'epsilon': 1e-10}
test_args = (tensor([[0.3687, 0.8798, 0.6295, 0.3094, 0.4582, 0.6707, 0.1695, 0.4836, 0.5960,
         0.5606],
        [0.0333, 0...    238.9370, 240.9449, 242.9528, 244.9606, 246.9685, 248.9764, 250.9843,
        252.9921, 255.0000]), tensor(0.9000))
test_kwargs = {'epsilon': 1e-10}, target = 'numpy', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[0.16936082, 0.5538848 , 0.7617607 , 0.61689633, 0.35579515,
        0.40510774, 0.54281574, 0.17995304, 0.6368714 , 0.23041284]],
      dtype=float32)
bins = array([  0.      ,   2.007874,   4.015748,   6.023622,   8.031496,
        10.03937 ,  12.047244,  14.055119,  16.0629... 240.94489 , 242.95276 , 244.96063 , 246.9685  , 248.97638 ,
       250.98425 , 252.99213 , 255.      ], dtype=float32)
bandwidth = array(0.9, dtype=float32), epsilon = 1e-10

    def numpy_histogram(x, bins, bandwidth, epsilon=1e-10):
        from ...ivy.functional.frontends.torch.tensor import numpy_unsqueeze_frnt_
    
>       pdf, _ = numpy_marginal_pdf(numpy_unsqueeze_frnt_(x, 2), bins, bandwidth, epsilon)

ivy_transpiled_outputs/numpy_outputs/kornia/enhance/histogram.py:68: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

values = array([[[0.16936082],
        [0.5538848 ],
        [0.7617607 ],
        [0.61689633],
        [0.35579515],
        [0.40510774],
        [0.54281574],
        [0.17995304],
        [0.6368714 ],
        [0.23041284]]], dtype=float32)
bins = array([  0.      ,   2.007874,   4.015748,   6.023622,   8.031496,
        10.03937 ,  12.047244,  14.055119,  16.0629... 240.94489 , 242.95276 , 244.96063 , 246.9685  , 248.97638 ,
       250.98425 , 252.99213 , 255.      ], dtype=float32)
sigma = array(0.9, dtype=float32), epsilon = 1e-10

    def numpy_marginal_pdf(values, bins, sigma, epsilon=1e-10):
        from ...ivy.functional.frontends.torch.tensor import numpy_dim_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_unsqueeze_frnt_
        from ...ivy.functional.frontends.torch.pointwise_ops import numpy_exp_frnt
        from ...ivy.functional.frontends.torch.tensor import numpy_pow_frnt_
        from ...ivy.functional.frontends.torch.reduction_ops import numpy_mean_frnt
        from ...ivy.functional.frontends.torch.reduction_ops import numpy_sum_frnt
    
        if not isinstance(values, (numpy.ndarray, numpy.ndarray)):
            raise TypeError(f"Input values type is not a torch.Tensor. Got {type(values)}")
        if not isinstance(bins, (numpy.ndarray, numpy.ndarray)):
            raise TypeError(f"Input bins type is not a torch.Tensor. Got {type(bins)}")
        if not isinstance(sigma, (numpy.ndarray, numpy.ndarray)):
            raise TypeError(f"Input sigma type is not a torch.Tensor. Got {type(sigma)}")
        if not numpy_dim_frnt_(values) == 3:
            raise ValueError(
                f"Input values must be a of the shape BxNx1. Got {numpy_shape_frnt_(values)}"
            )
        if not numpy_dim_frnt_(bins) == 1:
            raise ValueError(
                f"Input bins must be a of the shape NUM_BINS. Got {numpy_shape_frnt_(bins)}"
            )
        if not numpy_dim_frnt_(sigma) == 0:
            raise ValueError(
                f"Input sigma must be a of the shape 1. Got {numpy_shape_frnt_(sigma)}"
            )
        residuals = values - numpy_unsqueeze_frnt_(numpy_unsqueeze_frnt_(bins, 0), 0)
>       kernel_values = numpy_exp_frnt(-0.5 * numpy_pow_frnt_(residuals / sigma, 2))

ivy_transpiled_outputs/numpy_outputs/kornia/enhance/histogram.py:58: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (array([[[ 1.8817869e-01, -2.0427923e+00, -4.2737637e+00, ...,
         -2.7868323e+02, -2.8091418e+02, -2.8314517e+02...01, -1.9749569e+00, -4.2059278e+00, ...,
         -2.7861539e+02, -2.8084637e+02, -2.8307733e+02]]], dtype=float32), 2)
kwargs = {}, numpy_is_array_bknd = <function numpy_is_array_bknd at 0x7f0647e7dfc0>
array_like = array([[[ 1.8817869e-01, -2.0427923e+00, -4.2737637e+00, ...,
         -2.7868323e+02, -2.8091418e+02, -2.8314517e+02]...29e-01, -1.9749569e+00, -4.2059278e+00, ...,
         -2.7861539e+02, -2.8084637e+02, -2.8307733e+02]]], dtype=float32)

    @functools.wraps(fn)
    def wrapper(*args, **kwargs):
        from ..functional.ivy.general import numpy_is_array_bknd
    
        array_like = args[0]
        if hasattr(array_like, "__class__") and array_like.__class__.__name__ in [
            "list",
            "tuple",
        ]:
            array_like = array_like[0]
        if numpy_is_array_bknd(array_like):
>           return fn(*args, **kwargs)

ivy_transpiled_outputs/numpy_outputs/ivy/utils/decorator_utils.py:200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = array([[[ 1.8817869e-01, -2.0427923e+00, -4.2737637e+00, ...,
         -2.7868323e+02, -2.8091418e+02, -2.8314517e+02]...29e-01, -1.9749569e+00, -4.2059278e+00, ...,
         -2.7861539e+02, -2.8084637e+02, -2.8307733e+02]]], dtype=float32)
exponent = 2

    @numpy_handle_methods
    def numpy_pow_frnt_(tensor, exponent):
        from .pointwise_ops import numpy_pow_frnt
    
>       return numpy_pow_frnt(tensor, exponent)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/tensor.py:145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (array([[[ 1.8817869e-01, -2.0427923e+00, -4.2737637e+00, ...,
         -2.7868323e+02, -2.8091418e+02, -2.8314517e+02...01, -1.9749569e+00, -4.2059278e+00, ...,
         -2.7861539e+02, -2.8084637e+02, -2.8307733e+02]]], dtype=float32), 2)
kwargs = {}, numpy_is_array_bknd = <function numpy_is_array_bknd at 0x7f0647e7dfc0>
array_like = array([[[ 1.8817869e-01, -2.0427923e+00, -4.2737637e+00, ...,
         -2.7868323e+02, -2.8091418e+02, -2.8314517e+02]...29e-01, -1.9749569e+00, -4.2059278e+00, ...,
         -2.7861539e+02, -2.8084637e+02, -2.8307733e+02]]], dtype=float32)

    @functools.wraps(fn)
    def wrapper(*args, **kwargs):
        from ..functional.ivy.general import numpy_is_array_bknd
    
        array_like = args[0]
        if hasattr(array_like, "__class__") and array_like.__class__.__name__ in [
            "list",
            "tuple",
        ]:
            array_like = array_like[0]
        if numpy_is_array_bknd(array_like):
>           return fn(*args, **kwargs)

ivy_transpiled_outputs/numpy_outputs/ivy/utils/decorator_utils.py:200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = array([[[ 1.8817869e-01, -2.0427923e+00, -4.2737637e+00, ...,
         -2.7868323e+02, -2.8091418e+02, -2.8314517e+02]...29e-01, -1.9749569e+00, -4.2059278e+00, ...,
         -2.7861539e+02, -2.8084637e+02, -2.8307733e+02]]], dtype=float32)
exponent = array(2)

    @numpy_handle_methods
    def numpy_pow_frnt(input, exponent, *, out=None):
        from ...ivy.general import numpy_is_array_bknd
        from .creation_ops import numpy_as_tensor_frnt
        from ...backends.numpy.creation import numpy_asarray
        from .__init__ import numpy_promote_types_of_torch_inputs_frnt
        from ...ivy.data_type import numpy_is_int_dtype_bknd
        from ...backends.numpy.elementwise import numpy_pow
        from ...backends.numpy.utility import numpy_any
        from ...backends.numpy.searching import numpy_where
        from ...backends.numpy.elementwise import numpy_bitwise_and
        from ....data_classes.array.data_type import numpy_astype_bknd_
    
        if not numpy_is_array_bknd(input):
            input = numpy_as_tensor_frnt(input)
        if not numpy_is_array_bknd(exponent):
            if (
                any(dtype in str(input.dtype) for dtype in ["int8", "int16"])
                and isinstance(exponent, (int,))
                or "float16" in str(input.dtype)
                and isinstance(exponent, (float,))
            ):
                exponent = numpy_asarray(exponent, dtype=input.dtype)
            else:
                exponent = numpy_as_tensor_frnt(exponent)
>       input, exponent = numpy_promote_types_of_torch_inputs_frnt(input, exponent)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/pointwise_ops.py:97: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x1 = array([[[ 1.8817869e-01, -2.0427923e+00, -4.2737637e+00, ...,
         -2.7868323e+02, -2.8091418e+02, -2.8314517e+02]...29e-01, -1.9749569e+00, -4.2059278e+00, ...,
         -2.7861539e+02, -2.8084637e+02, -2.8307733e+02]]], dtype=float32)
x2 = array(2)

    def numpy_promote_types_of_torch_inputs_frnt(x1, x2, /):
        from ...ivy.general import numpy_isscalar_bknd
        from ...ivy.data_type import numpy_is_int_dtype_bknd
        from ...backends.numpy.creation import numpy_asarray
        from ...ivy.data_type import numpy_default_dtype_bknd
        from .tensor import numpy_shape_frnt_
        from ...ivy.device import numpy_default_device_bknd
        from ....data_classes.array.data_type import numpy_astype_bknd_
    
        """Promote the dtype of the given native array inputs to a common dtype
        based on type promotion rules.
    
        While passing float or integer values or any other non-array input
        to this function, it should be noted that the return will be an
        array-like object. Therefore, outputs from this function should be
        used as inputs only for those functions that expect an array-like or
        tensor-like objects, otherwise it might give unexpected results.
        """
        if (
            numpy_isscalar_bknd(x1) or isinstance(x1, (list, tuple))
        ) and numpy_is_int_dtype_bknd(x1):
            x1 = numpy_asarray(x1, dtype="int64")
        elif numpy_isscalar_bknd(x1) or isinstance(x1, (list, tuple)):
            x1 = numpy_asarray(x1)
        if (
            numpy_isscalar_bknd(x2) or isinstance(x2, (list, tuple))
        ) and numpy_is_int_dtype_bknd(x2):
            x2 = numpy_asarray(x2, dtype="int64")
        elif numpy_isscalar_bknd(x2) or isinstance(x2, (list, tuple)):
            x2 = numpy_asarray(x2)
        type1 = numpy_default_dtype_bknd(item=x1).strip("u123456789")
        type2 = numpy_default_dtype_bknd(item=x2).strip("u123456789")
        if numpy_shape_frnt_(x1) != () and numpy_shape_frnt_(x2) == () and type1 == type2:
            x2 = numpy_asarray(
                x2,
                dtype=x1.dtype,
                device=numpy_default_device_bknd(item=x1, as_native=False),
            )
        elif numpy_shape_frnt_(x1) == () and numpy_shape_frnt_(x2) != () and type1 == type2:
            x1 = numpy_asarray(
                x1,
                dtype=x2.dtype,
                device=numpy_default_device_bknd(item=x2, as_native=False),
            )
        elif x1.dtype != x2.dtype:
>           promoted = numpy_promote_types_torch_frnt(x1.dtype, x2.dtype)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/__init__.py:87: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

type1 = dtype('float32'), type2 = dtype('int64')

    def numpy_promote_types_torch_frnt(type1, type2, /):
        from ...backends.numpy.general import numpy_get_item
        from ...backends.numpy.data_type import numpy_as_ivy_dtype
    
        try:
            ret = numpy_get_item(
>               torch_promotion_table,
                (numpy_as_ivy_dtype(type1), numpy_as_ivy_dtype(type2)),
            )
E           NameError: name 'torch_promotion_table' is not defined

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/__init__.py:34: NameError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.enhance.histogram.histogram
__________________________________________________________________________________ test_histogram2d[numpy-s2s-False] ___________________________________________________________________________________

target_framework = 'numpy', mode = 's2s', backend_compile = False

    def test_histogram2d(target_framework, mode, backend_compile):
        trace_args = (
            torch.rand(2, 32),
            torch.rand(2, 32),
            torch.linspace(0, 255, 128),
            torch.tensor(0.9),
        )
        trace_kwargs = {"epsilon": 1e-10}
        test_args = (
            torch.rand(5, 32),
            torch.rand(5, 32),
            torch.linspace(0, 255, 128),
            torch.tensor(0.9),
        )
        test_kwargs = {"epsilon": 1e-10}
>       _test_function(
            kornia.enhance.histogram2d,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/test_enhance.py:438: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function histogram2d at 0x7f06a4e99000>
trace_args = (tensor([[0.5935, 0.4437, 0.8028, 0.5038, 0.0436, 0.5235, 0.7435, 0.2882, 0.3265,
         0.8227, 0.8213, 0.9295, 0.7...    238.9370, 240.9449, 242.9528, 244.9606, 246.9685, 248.9764, 250.9843,
        252.9921, 255.0000]), tensor(0.9000))
trace_kwargs = {'epsilon': 1e-10}
test_args = (tensor([[0.7162, 0.4342, 0.2272, 0.7737, 0.7361, 0.9374, 0.0595, 0.7722, 0.6222,
         0.3907, 0.3824, 0.3576, 0.4...    238.9370, 240.9449, 242.9528, 244.9606, 246.9685, 248.9764, 250.9843,
        252.9921, 255.0000]), tensor(0.9000))
test_kwargs = {'epsilon': 1e-10}, target = 'numpy', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function histogram2d at 0x7f06a4e99000>, fn_name = 'kornia.enhance.histogram2d'
trace_args = (tensor([[0.5935, 0.4437, 0.8028, 0.5038, 0.0436, 0.5235, 0.7435, 0.2882, 0.3265,
         0.8227, 0.8213, 0.9295, 0.7...    238.9370, 240.9449, 242.9528, 244.9606, 246.9685, 248.9764, 250.9843,
        252.9921, 255.0000]), tensor(0.9000))
trace_kwargs = {'epsilon': 1e-10}
test_args = (tensor([[0.7162, 0.4342, 0.2272, 0.7737, 0.7361, 0.9374, 0.0595, 0.7722, 0.6222,
         0.3907, 0.3824, 0.3576, 0.4...    238.9370, 240.9449, 242.9528, 244.9606, 246.9685, 248.9764, 250.9843,
        252.9921, 255.0000]), tensor(0.9000))
test_kwargs = {'epsilon': 1e-10}, target = 'numpy', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x1 = array([[0.59350306, 0.44370896, 0.80279404, 0.5038328 , 0.04362452,
        0.5234893 , 0.74349076, 0.2882102 , 0.3265... ,
        0.4179756 , 0.16713583, 0.1377182 , 0.3914581 , 0.07144481,
        0.04509473, 0.17674726]], dtype=float32)
x2 = array([[0.22825128, 0.8473981 , 0.9040508 , 0.22444749, 0.08752447,
        0.5761726 , 0.5919081 , 0.7898954 , 0.7173...4,
        0.5974026 , 0.0637086 , 0.5182556 , 0.23042363, 0.8184433 ,
        0.45010763, 0.08349496]], dtype=float32)
bins = array([  0.      ,   2.007874,   4.015748,   6.023622,   8.031496,
        10.03937 ,  12.047244,  14.055119,  16.0629... 240.94489 , 242.95276 , 244.96063 , 246.9685  , 248.97638 ,
       250.98425 , 252.99213 , 255.      ], dtype=float32)
bandwidth = array(0.9, dtype=float32), epsilon = 1e-10

    def numpy_histogram2d(x1, x2, bins, bandwidth, epsilon=1e-10):
        from ...ivy.functional.frontends.torch.tensor import numpy_unsqueeze_frnt_
    
>       _, kernel_values1 = numpy_marginal_pdf(
            numpy_unsqueeze_frnt_(x1, 2), bins, bandwidth, epsilon
        )

ivy_transpiled_outputs/numpy_outputs/kornia/enhance/histogram.py:107: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

values = array([[[0.59350306],
        [0.44370896],
        [0.80279404],
        [0.5038328 ],
        [0.04362452],
        ... [0.1377182 ],
        [0.3914581 ],
        [0.07144481],
        [0.04509473],
        [0.17674726]]], dtype=float32)
bins = array([  0.      ,   2.007874,   4.015748,   6.023622,   8.031496,
        10.03937 ,  12.047244,  14.055119,  16.0629... 240.94489 , 242.95276 , 244.96063 , 246.9685  , 248.97638 ,
       250.98425 , 252.99213 , 255.      ], dtype=float32)
sigma = array(0.9, dtype=float32), epsilon = 1e-10

    def numpy_marginal_pdf(values, bins, sigma, epsilon=1e-10):
        from ...ivy.functional.frontends.torch.tensor import numpy_dim_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_unsqueeze_frnt_
        from ...ivy.functional.frontends.torch.pointwise_ops import numpy_exp_frnt
        from ...ivy.functional.frontends.torch.tensor import numpy_pow_frnt_
        from ...ivy.functional.frontends.torch.reduction_ops import numpy_mean_frnt
        from ...ivy.functional.frontends.torch.reduction_ops import numpy_sum_frnt
    
        if not isinstance(values, (numpy.ndarray, numpy.ndarray)):
            raise TypeError(f"Input values type is not a torch.Tensor. Got {type(values)}")
        if not isinstance(bins, (numpy.ndarray, numpy.ndarray)):
            raise TypeError(f"Input bins type is not a torch.Tensor. Got {type(bins)}")
        if not isinstance(sigma, (numpy.ndarray, numpy.ndarray)):
            raise TypeError(f"Input sigma type is not a torch.Tensor. Got {type(sigma)}")
        if not numpy_dim_frnt_(values) == 3:
            raise ValueError(
                f"Input values must be a of the shape BxNx1. Got {numpy_shape_frnt_(values)}"
            )
        if not numpy_dim_frnt_(bins) == 1:
            raise ValueError(
                f"Input bins must be a of the shape NUM_BINS. Got {numpy_shape_frnt_(bins)}"
            )
        if not numpy_dim_frnt_(sigma) == 0:
            raise ValueError(
                f"Input sigma must be a of the shape 1. Got {numpy_shape_frnt_(sigma)}"
            )
        residuals = values - numpy_unsqueeze_frnt_(numpy_unsqueeze_frnt_(bins, 0), 0)
>       kernel_values = numpy_exp_frnt(-0.5 * numpy_pow_frnt_(residuals / sigma, 2))

ivy_transpiled_outputs/numpy_outputs/kornia/enhance/histogram.py:58: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (array([[[ 6.5944785e-01, -1.5715234e+00, -3.8024945e+00, ...,
         -2.7821194e+02, -2.8044293e+02, -2.8267389e+02...01, -2.0345852e+00, -4.2655563e+00, ...,
         -2.7867502e+02, -2.8090598e+02, -2.8313696e+02]]], dtype=float32), 2)
kwargs = {}, numpy_is_array_bknd = <function numpy_is_array_bknd at 0x7f06477d1090>
array_like = array([[[ 6.5944785e-01, -1.5715234e+00, -3.8024945e+00, ...,
         -2.7821194e+02, -2.8044293e+02, -2.8267389e+02]...85e-01, -2.0345852e+00, -4.2655563e+00, ...,
         -2.7867502e+02, -2.8090598e+02, -2.8313696e+02]]], dtype=float32)

    @functools.wraps(fn)
    def wrapper(*args, **kwargs):
        from ..functional.ivy.general import numpy_is_array_bknd
    
        array_like = args[0]
        if hasattr(array_like, "__class__") and array_like.__class__.__name__ in [
            "list",
            "tuple",
        ]:
            array_like = array_like[0]
        if numpy_is_array_bknd(array_like):
>           return fn(*args, **kwargs)

ivy_transpiled_outputs/numpy_outputs/ivy/utils/decorator_utils.py:200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = array([[[ 6.5944785e-01, -1.5715234e+00, -3.8024945e+00, ...,
         -2.7821194e+02, -2.8044293e+02, -2.8267389e+02]...85e-01, -2.0345852e+00, -4.2655563e+00, ...,
         -2.7867502e+02, -2.8090598e+02, -2.8313696e+02]]], dtype=float32)
exponent = 2

    @numpy_handle_methods
    def numpy_pow_frnt_(tensor, exponent):
        from .pointwise_ops import numpy_pow_frnt
    
>       return numpy_pow_frnt(tensor, exponent)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/tensor.py:145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (array([[[ 6.5944785e-01, -1.5715234e+00, -3.8024945e+00, ...,
         -2.7821194e+02, -2.8044293e+02, -2.8267389e+02...01, -2.0345852e+00, -4.2655563e+00, ...,
         -2.7867502e+02, -2.8090598e+02, -2.8313696e+02]]], dtype=float32), 2)
kwargs = {}, numpy_is_array_bknd = <function numpy_is_array_bknd at 0x7f06477d1090>
array_like = array([[[ 6.5944785e-01, -1.5715234e+00, -3.8024945e+00, ...,
         -2.7821194e+02, -2.8044293e+02, -2.8267389e+02]...85e-01, -2.0345852e+00, -4.2655563e+00, ...,
         -2.7867502e+02, -2.8090598e+02, -2.8313696e+02]]], dtype=float32)

    @functools.wraps(fn)
    def wrapper(*args, **kwargs):
        from ..functional.ivy.general import numpy_is_array_bknd
    
        array_like = args[0]
        if hasattr(array_like, "__class__") and array_like.__class__.__name__ in [
            "list",
            "tuple",
        ]:
            array_like = array_like[0]
        if numpy_is_array_bknd(array_like):
>           return fn(*args, **kwargs)

ivy_transpiled_outputs/numpy_outputs/ivy/utils/decorator_utils.py:200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = array([[[ 6.5944785e-01, -1.5715234e+00, -3.8024945e+00, ...,
         -2.7821194e+02, -2.8044293e+02, -2.8267389e+02]...85e-01, -2.0345852e+00, -4.2655563e+00, ...,
         -2.7867502e+02, -2.8090598e+02, -2.8313696e+02]]], dtype=float32)
exponent = array(2)

    @numpy_handle_methods
    def numpy_pow_frnt(input, exponent, *, out=None):
        from ...ivy.general import numpy_is_array_bknd
        from .creation_ops import numpy_as_tensor_frnt
        from ...backends.numpy.creation import numpy_asarray
        from .__init__ import numpy_promote_types_of_torch_inputs_frnt
        from ...ivy.data_type import numpy_is_int_dtype_bknd
        from ...backends.numpy.elementwise import numpy_pow
        from ...backends.numpy.utility import numpy_any
        from ...backends.numpy.searching import numpy_where
        from ...backends.numpy.elementwise import numpy_bitwise_and
        from ....data_classes.array.data_type import numpy_astype_bknd_
    
        if not numpy_is_array_bknd(input):
            input = numpy_as_tensor_frnt(input)
        if not numpy_is_array_bknd(exponent):
            if (
                any(dtype in str(input.dtype) for dtype in ["int8", "int16"])
                and isinstance(exponent, (int,))
                or "float16" in str(input.dtype)
                and isinstance(exponent, (float,))
            ):
                exponent = numpy_asarray(exponent, dtype=input.dtype)
            else:
                exponent = numpy_as_tensor_frnt(exponent)
>       input, exponent = numpy_promote_types_of_torch_inputs_frnt(input, exponent)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/pointwise_ops.py:97: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x1 = array([[[ 6.5944785e-01, -1.5715234e+00, -3.8024945e+00, ...,
         -2.7821194e+02, -2.8044293e+02, -2.8267389e+02]...85e-01, -2.0345852e+00, -4.2655563e+00, ...,
         -2.7867502e+02, -2.8090598e+02, -2.8313696e+02]]], dtype=float32)
x2 = array(2)

    def numpy_promote_types_of_torch_inputs_frnt(x1, x2, /):
        from ...ivy.general import numpy_isscalar_bknd
        from ...ivy.data_type import numpy_is_int_dtype_bknd
        from ...backends.numpy.creation import numpy_asarray
        from ...ivy.data_type import numpy_default_dtype_bknd
        from .tensor import numpy_shape_frnt_
        from ...ivy.device import numpy_default_device_bknd
        from ....data_classes.array.data_type import numpy_astype_bknd_
    
        """Promote the dtype of the given native array inputs to a common dtype
        based on type promotion rules.
    
        While passing float or integer values or any other non-array input
        to this function, it should be noted that the return will be an
        array-like object. Therefore, outputs from this function should be
        used as inputs only for those functions that expect an array-like or
        tensor-like objects, otherwise it might give unexpected results.
        """
        if (
            numpy_isscalar_bknd(x1) or isinstance(x1, (list, tuple))
        ) and numpy_is_int_dtype_bknd(x1):
            x1 = numpy_asarray(x1, dtype="int64")
        elif numpy_isscalar_bknd(x1) or isinstance(x1, (list, tuple)):
            x1 = numpy_asarray(x1)
        if (
            numpy_isscalar_bknd(x2) or isinstance(x2, (list, tuple))
        ) and numpy_is_int_dtype_bknd(x2):
            x2 = numpy_asarray(x2, dtype="int64")
        elif numpy_isscalar_bknd(x2) or isinstance(x2, (list, tuple)):
            x2 = numpy_asarray(x2)
        type1 = numpy_default_dtype_bknd(item=x1).strip("u123456789")
        type2 = numpy_default_dtype_bknd(item=x2).strip("u123456789")
        if numpy_shape_frnt_(x1) != () and numpy_shape_frnt_(x2) == () and type1 == type2:
            x2 = numpy_asarray(
                x2,
                dtype=x1.dtype,
                device=numpy_default_device_bknd(item=x1, as_native=False),
            )
        elif numpy_shape_frnt_(x1) == () and numpy_shape_frnt_(x2) != () and type1 == type2:
            x1 = numpy_asarray(
                x1,
                dtype=x2.dtype,
                device=numpy_default_device_bknd(item=x2, as_native=False),
            )
        elif x1.dtype != x2.dtype:
>           promoted = numpy_promote_types_torch_frnt(x1.dtype, x2.dtype)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/__init__.py:87: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

type1 = dtype('float32'), type2 = dtype('int64')

    def numpy_promote_types_torch_frnt(type1, type2, /):
        from ...backends.numpy.general import numpy_get_item
        from ...backends.numpy.data_type import numpy_as_ivy_dtype
    
        try:
            ret = numpy_get_item(
>               torch_promotion_table,
                (numpy_as_ivy_dtype(type1), numpy_as_ivy_dtype(type2)),
            )
E           NameError: name 'torch_promotion_table' is not defined

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/__init__.py:34: NameError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.enhance.histogram.histogram2d
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/test_enhance.py::test_adjust_gamma[numpy-s2s-False] - TypeError: 'float' object cannot be interpreted as an integer
FAILED kornia/test_enhance.py::test_invert[numpy-s2s-False] - ivy.utils.exceptions.IvyException: Error loading module ivy_transpiled_outputs.numpy_outputs.kornia.enhance.adjust: 'float' object cann...
FAILED kornia/test_enhance.py::test_equalize[numpy-s2s-False] - NameError: name 'torch_promotion_table' is not defined
FAILED kornia/test_enhance.py::test_equalize_clahe[numpy-s2s-False] - ValueError: need at least one array to stack
FAILED kornia/test_enhance.py::test_equalize3d[numpy-s2s-False] - NameError: name 'torch_promotion_table' is not defined
FAILED kornia/test_enhance.py::test_histogram[numpy-s2s-False] - NameError: name 'torch_promotion_table' is not defined
FAILED kornia/test_enhance.py::test_histogram2d[numpy-s2s-False] - NameError: name 'torch_promotion_table' is not defined
======================================================================== 7 failed, 19 passed, 13 skipped in 1626.12s (0:27:06) =========================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 17 items

kornia/augmentation/test_augmentation4.py sssssssssssssssss                                                                                                                                      [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
========================================================================================= 17 skipped in 5.61s ==========================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 15 items

kornia/test_contrib.py ....Fssssssssss                                                                                                                                                           [100%]

=============================================================================================== FAILURES ===============================================================================================
_________________________________________________________________________________ test_diamond_square[numpy-s2s-False] _________________________________________________________________________________

target_framework = 'numpy', mode = 's2s', backend_compile = False

    def test_diamond_square(target_framework, mode, backend_compile):
        trace_args = ((1, 1, 8, 8),)
        trace_kwargs = {
            "roughness": 0.5,
            "random_scale": 1.0,
            "normalize_range": (0.0, 1.0),
            "random_fn": torch.ones,
        }
        test_args = ((5, 1, 8, 8),)
        test_kwargs = {
            "roughness": 0.7,
            "random_scale": 0.9,
            "normalize_range": (-1.0, 1.0),
            "random_fn": torch.ones,
        }
>       _test_function(
            kornia.contrib.diamond_square,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/test_contrib.py:141: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function diamond_square at 0x7f66b31cf130>, trace_args = ((1, 1, 8, 8),)
trace_kwargs = {'normalize_range': (0.0, 1.0), 'random_fn': <built-in method ones of type object at 0x7f66ceab5900>, 'random_scale': 1.0, 'roughness': 0.5}, test_args = ((5, 1, 8, 8),)
test_kwargs = {'normalize_range': (-1.0, 1.0), 'random_fn': <built-in method ones of type object at 0x7f66ceab5900>, 'random_scale': 0.9, 'roughness': 0.7}, target = 'numpy', backend_compile = False
tolerance = 0.001, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function diamond_square at 0x7f66b31cf130>, fn_name = 'kornia.contrib.diamond_square', trace_args = ((1, 1, 8, 8),)
trace_kwargs = {'normalize_range': (0.0, 1.0), 'random_fn': <built-in method ones of type object at 0x7f66ceab5900>, 'random_scale': 1.0, 'roughness': 0.5}, test_args = ((5, 1, 8, 8),)
test_kwargs = {'normalize_range': (-1.0, 1.0), 'random_fn': <built-in method ones of type object at 0x7f66ceab5900>, 'random_scale': 0.9, 'roughness': 0.7}, target = 'numpy', backend_compile = False
tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

output_size = (1, 1, 8, 8), roughness = 0.5, random_scale = 1.0, random_fn = <built-in method ones of type object at 0x7f66ceab5900>, normalize_range = (0.0, 1.0), device = None, dtype = None

    def numpy_diamond_square(
        output_size,
        roughness=0.5,
        random_scale=1.0,
        random_fn=numpy_rand_frnt,
        normalize_range=None,
        device=None,
        dtype=None,
    ):
        from ..core.check import numpy_KORNIA_CHECK
        from ...ivy.functional.frontends.torch.tensor import numpy_to_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_expand_frnt_
        from ..core.check import numpy_KORNIA_CHECK_IS_TENSOR
        from ...ivy.functional.frontends.torch.tensor import numpy_view_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_reshape_frnt_
        from ...ivy.functional.backends.numpy.general import numpy_get_item
        from ..enhance.normalize import numpy_normalize_min_max
        from ...ivy.functional.frontends.torch.tensor import numpy_contiguous_frnt_
    
        numpy_KORNIA_CHECK(len(output_size) == 4, "output_size must be (B,C,H,W)")
        if not isinstance(random_scale, (numpy.ndarray, numpy.ndarray)):
            random_scale = numpy_to_frnt_(
>               numpy.ndarray([[[[random_scale]]]]), device, dtype
            )
E           TypeError: 'list' object cannot be interpreted as an integer

ivy_transpiled_outputs/numpy_outputs/kornia/contrib/diamond_square.py:197: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.contrib.diamond_square.diamond_square
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/test_contrib.py::test_diamond_square[numpy-s2s-False] - TypeError: 'list' object cannot be interpreted as an integer
========================================================================= 1 failed, 4 passed, 10 skipped in 326.74s (0:05:26) ==========================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 4 items

kornia/test_sensors.py ssss                                                                                                                                                                      [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
========================================================================================== 4 skipped in 4.88s ==========================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 16 items

kornia/augmentation/test_augmentation3.py ssssssssssssssss                                                                                                                                       [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
========================================================================================= 16 skipped in 5.44s ==========================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 3 items

kornia/augmentation/test_auto.py FFF                                                                                                                                                             [100%]

=============================================================================================== FAILURES ===============================================================================================
________________________________________________________________________________ test_AutoAugment[tensorflow-s2s-False] ________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_AutoAugment(target_framework, mode, backend_compile):
        print("kornia.augmentation.auto.AutoAugment")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledAutoAugment = ivy.transpile(
            kornia.augmentation.auto.AutoAugment,
            source="torch",
            target=target_framework,
        )
    
        torch_aug = kornia.augmentation.auto.AutoAugment()
>       transpiled_aug = TranspiledAutoAugment()

kornia/augmentation/test_auto.py:29: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_AutoAugment object at 0x7fbc4fd170a0>, policy = 'imagenet', transformation_matrix_mode = 'silent'

    def __init__(self, policy="imagenet", transformation_matrix_mode="silent"):
        from ....core._backend import tensor
        from .....torch.distributions.categorical import tensorflow_Categorical
    
        if policy == "imagenet":
            _policy = imagenet_policy
        elif policy == "cifar10":
            _policy = cifar10_policy
        elif policy == "svhn":
            _policy = svhn_policy
        elif isinstance(policy, (list, tuple)):
            _policy = policy
        else:
            raise NotImplementedError(f"Invalid policy `{policy}`.")
>       super().__init__(_policy, transformation_matrix_mode=transformation_matrix_mode)

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/auto/autoaugment/autoaugment.py:129: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_AutoAugment object at 0x7fbc4fd170a0>
args = ([[('posterize', 0.4, 8), ('rotate', 0.6, 9)], [('solarize', 0.6, 5), ('auto_contrast', 0.6, None)], [('equalize', 0.8...rize', 0.6, 6)], [('equalize', 0.4, None), ('solarize', 0.2, 4)], [('equalize', 0.4, None), ('rotate', 0.8, 8)], ...],)
kwargs = {'transformation_matrix_mode': 'silent'}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_AutoAugment object at 0x7fbc4fd170a0>
policy = [[('posterize', 0.4, 8), ('rotate', 0.6, 9)], [('solarize', 0.6, 5), ('auto_contrast', 0.6, None)], [('equalize', 0.8,...terize', 0.6, 6)], [('equalize', 0.4, None), ('solarize', 0.2, 4)], [('equalize', 0.4, None), ('rotate', 0.8, 8)], ...]
transformation_matrix_mode = 'silent'

    @tensorflow_store_config_info
    def __init__(self, policy, transformation_matrix_mode="silence"):
        from .operations.policy import tensorflow_PolicySequential
    
>       policies = self.compose_policy(policy)

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/auto/base.py:46: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_AutoAugment object at 0x7fbc4fd170a0>
policy = [[('posterize', 0.4, 8), ('rotate', 0.6, 9)], [('solarize', 0.6, 5), ('auto_contrast', 0.6, None)], [('equalize', 0.8,...terize', 0.6, 6)], [('equalize', 0.4, None), ('solarize', 0.2, 4)], [('equalize', 0.4, None), ('rotate', 0.8, 8)], ...]

    def compose_policy(self, policy):
>       return [self.compose_subpolicy_sequential(subpolicy) for subpolicy in policy]

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/auto/base.py:61: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

.0 = <list_iterator object at 0x7fbc4fd144f0>

>   return [self.compose_subpolicy_sequential(subpolicy) for subpolicy in policy]

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/auto/base.py:61: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_AutoAugment object at 0x7fbc4fd170a0>, subpolicy = [('posterize', 0.4, 8), ('rotate', 0.6, 9)]

    def compose_subpolicy_sequential(self, subpolicy):
        from ..operations.policy import tensorflow_PolicySequential
    
        return tensorflow_PolicySequential(
>           *[
                getattr(kornia.augmentation.auto.autoaugment.ops, name)(prob, mag)
                for name, prob, mag in subpolicy
            ]
        )

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/auto/autoaugment/autoaugment.py:137: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

.0 = <list_iterator object at 0x7fbc4fd158a0>

        *[
>           getattr(kornia.augmentation.auto.autoaugment.ops, name)(prob, mag)
            for name, prob, mag in subpolicy
        ]
    )
E   NameError: name 'kornia' is not defined

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/auto/autoaugment/autoaugment.py:138: NameError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.auto.AutoAugment
________________________________________________________________________________ test_RandAugment[tensorflow-s2s-False] ________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_RandAugment(target_framework, mode, backend_compile):
        print("kornia.augmentation.auto.RandAugment")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledRandAugment = ivy.transpile(
            kornia.augmentation.auto.RandAugment,
            source="torch",
            target=target_framework,
        )
    
        torch_aug = kornia.augmentation.auto.RandAugment(n=2, m=10)
>       transpiled_aug = TranspiledRandAugment(n=2, m=10)

kornia/augmentation/test_auto.py:69: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_RandAugment object at 0x7fbc5056db70>, n = 2, m = 10, policy = None
transformation_matrix_mode = 'silent'

    def __init__(self, n, m, policy=None, transformation_matrix_mode="silent"):
        if m <= 0 or m >= 30:
            raise ValueError(f"Expect `m` in [0, 30]. Got {m}.")
        if policy is None:
            _policy = default_policy
        else:
            _policy = policy
>       super().__init__(_policy, transformation_matrix_mode=transformation_matrix_mode)

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/auto/rand_augment/rand_augment.py:60: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_RandAugment object at 0x7fbc5056db70>
args = ([[('auto_contrast', 0, 1)], [('equalize', 0, 1)], [('invert', 0, 1)], [('rotate', -30.0, 30.0)], [('posterize', 0.0, 4)], [('solarize', 0.0, 1.0)], ...],)
kwargs = {'transformation_matrix_mode': 'silent'}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_RandAugment object at 0x7fbc5056db70>
policy = [[('auto_contrast', 0, 1)], [('equalize', 0, 1)], [('invert', 0, 1)], [('rotate', -30.0, 30.0)], [('posterize', 0.0, 4)], [('solarize', 0.0, 1.0)], ...], transformation_matrix_mode = 'silent'

    @tensorflow_store_config_info
    def __init__(self, policy, transformation_matrix_mode="silence"):
        from .operations.policy import tensorflow_PolicySequential
    
>       policies = self.compose_policy(policy)

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/auto/base.py:46: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_RandAugment object at 0x7fbc5056db70>
policy = [[('auto_contrast', 0, 1)], [('equalize', 0, 1)], [('invert', 0, 1)], [('rotate', -30.0, 30.0)], [('posterize', 0.0, 4)], [('solarize', 0.0, 1.0)], ...]

    def compose_policy(self, policy):
>       return [self.compose_subpolicy_sequential(subpolicy) for subpolicy in policy]

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/auto/base.py:61: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

.0 = <list_iterator object at 0x7fbc5056d030>

>   return [self.compose_subpolicy_sequential(subpolicy) for subpolicy in policy]

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/auto/base.py:61: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_RandAugment object at 0x7fbc5056db70>, subpolicy = [('auto_contrast', 0, 1)]

    def compose_subpolicy_sequential(self, subpolicy):
        from ..operations.policy import tensorflow_PolicySequential
    
        if len(subpolicy) != 1:
            raise RuntimeError(
                f"Each policy must have only one operation for RandAugment. Got {len(subpolicy)}."
            )
        name, low, high = subpolicy[0][0], subpolicy[0][1], subpolicy[0][2]
        return tensorflow_PolicySequential(
>           *[getattr(kornia.augmentation.auto.rand_augment.ops, name)(low, high)]
        )
E       NameError: name 'kornia' is not defined

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/auto/rand_augment/rand_augment.py:83: NameError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.auto.RandAugment
______________________________________________________________________________ test_TrivialAugment[tensorflow-s2s-False] _______________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_TrivialAugment(target_framework, mode, backend_compile):
        print("kornia.augmentation.auto.TrivialAugment")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledTrivialAugment = ivy.transpile(
            kornia.augmentation.auto.TrivialAugment,
            source="torch",
            target=target_framework,
        )
    
        torch_aug = kornia.augmentation.auto.TrivialAugment()
>       transpiled_aug = TranspiledTrivialAugment()

kornia/augmentation/test_auto.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_TrivialAugment object at 0x7fbc5205f880>, policy = None, transformation_matrix_mode = 'silent'

    def __init__(self, policy=None, transformation_matrix_mode="silent"):
        from .....ivy.functional.frontends.torch.creation_ops import (
            tensorflow_tensor_frnt,
        )
        from .....torch.distributions.categorical import tensorflow_Categorical
    
        if policy is None:
            _policy = default_policy
        else:
            _policy = policy
>       super().__init__(_policy, transformation_matrix_mode=transformation_matrix_mode)

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/auto/trivial_augment/trivial_augment.py:58: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_TrivialAugment object at 0x7fbc5205f880>
args = ([[('auto_contrast', 0, 1)], [('equalize', 0, 1)], [('rotate', -30.0, 30.0)], [('posterize', 0.0, 4)], [('solarize', 0.0, 1.0)], [('contrast', 0.1, 1.9)], ...],)
kwargs = {'transformation_matrix_mode': 'silent'}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_TrivialAugment object at 0x7fbc5205f880>
policy = [[('auto_contrast', 0, 1)], [('equalize', 0, 1)], [('rotate', -30.0, 30.0)], [('posterize', 0.0, 4)], [('solarize', 0.0, 1.0)], [('contrast', 0.1, 1.9)], ...]
transformation_matrix_mode = 'silent'

    @tensorflow_store_config_info
    def __init__(self, policy, transformation_matrix_mode="silence"):
        from .operations.policy import tensorflow_PolicySequential
    
>       policies = self.compose_policy(policy)

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/auto/base.py:46: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_TrivialAugment object at 0x7fbc5205f880>
policy = [[('auto_contrast', 0, 1)], [('equalize', 0, 1)], [('rotate', -30.0, 30.0)], [('posterize', 0.0, 4)], [('solarize', 0.0, 1.0)], [('contrast', 0.1, 1.9)], ...]

    def compose_policy(self, policy):
>       return [self.compose_subpolicy_sequential(subpolicy) for subpolicy in policy]

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/auto/base.py:61: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

.0 = <list_iterator object at 0x7fbc5205ec50>

>   return [self.compose_subpolicy_sequential(subpolicy) for subpolicy in policy]

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/auto/base.py:61: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_TrivialAugment object at 0x7fbc5205f880>, subpolicy = [('auto_contrast', 0, 1)]

    def compose_subpolicy_sequential(self, subpolicy):
        from ..operations.policy import tensorflow_PolicySequential
    
        if len(subpolicy) != 1:
            raise RuntimeError(
                f"Each policy must have only one operation for TrivialAugment. Got {len(subpolicy)}."
            )
        name, low, high = subpolicy[0][0], subpolicy[0][1], subpolicy[0][2]
        return tensorflow_PolicySequential(
>           *[getattr(kornia.augmentation.auto.rand_augment.ops, name)(low, high)]
        )
E       NameError: name 'kornia' is not defined

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/auto/trivial_augment/trivial_augment.py:71: NameError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.auto.TrivialAugment
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/augmentation/test_auto.py::test_AutoAugment[tensorflow-s2s-False] - NameError: name 'kornia' is not defined
FAILED kornia/augmentation/test_auto.py::test_RandAugment[tensorflow-s2s-False] - NameError: name 'kornia' is not defined
FAILED kornia/augmentation/test_auto.py::test_TrivialAugment[tensorflow-s2s-False] - NameError: name 'kornia' is not defined
==================================================================================== 3 failed in 1473.64s (0:24:33) ====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 8 items

kornia/geometry/test_linalg.py .......F                                                                                                                                                          [100%]

=============================================================================================== FAILURES ===============================================================================================
_______________________________________________________________________________ test_euclidean_distance[numpy-s2s-False] _______________________________________________________________________________

target_framework = 'numpy', mode = 's2s', backend_compile = False

    def test_euclidean_distance(target_framework, mode, backend_compile):
        trace_args = (
            torch.rand(3, 5),
            torch.rand(3, 5),
        )
        trace_kwargs = {'keepdim': False, 'eps': 1e-6}
        test_args = (
            torch.rand(5, 3, 5),
            torch.rand(5, 3, 5),
        )
        test_kwargs = {'keepdim': False, 'eps': 1e-6}
>       _test_function(
            kornia.geometry.linalg.euclidean_distance,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/geometry/test_linalg.py:184: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function euclidean_distance at 0x7f4ad7c95cf0>
trace_args = (tensor([[0.6512, 0.2655, 0.3021, 0.4763, 0.6682],
        [0.4988, 0.7437, 0.2526, 0.4978, 0.5048],
        [0.3195, ... 0.2835, 0.6957],
        [0.1849, 0.9691, 0.6025, 0.7551, 0.4623],
        [0.8407, 0.6945, 0.8292, 0.7101, 0.9804]]))
trace_kwargs = {'eps': 1e-06, 'keepdim': False}
test_args = (tensor([[[0.8672, 0.8417, 0.7802, 0.6964, 0.1861],
         [0.6004, 0.4473, 0.0343, 0.7002, 0.4669],
         [0.337...5068, 0.2080],
         [0.5230, 0.0898, 0.2755, 0.7864, 0.6094],
         [0.1619, 0.6210, 0.0973, 0.3889, 0.5721]]]))
test_kwargs = {'eps': 1e-06, 'keepdim': False}, target = 'numpy', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function euclidean_distance at 0x7f4ad7c95cf0>, fn_name = 'kornia.geometry.linalg.euclidean_distance'
trace_args = (tensor([[0.6512, 0.2655, 0.3021, 0.4763, 0.6682],
        [0.4988, 0.7437, 0.2526, 0.4978, 0.5048],
        [0.3195, ... 0.2835, 0.6957],
        [0.1849, 0.9691, 0.6025, 0.7551, 0.4623],
        [0.8407, 0.6945, 0.8292, 0.7101, 0.9804]]))
trace_kwargs = {'eps': 1e-06, 'keepdim': False}
test_args = (tensor([[[0.8672, 0.8417, 0.7802, 0.6964, 0.1861],
         [0.6004, 0.4473, 0.0343, 0.7002, 0.4669],
         [0.337...5068, 0.2080],
         [0.5230, 0.0898, 0.2755, 0.7864, 0.6094],
         [0.1619, 0.6210, 0.0973, 0.3889, 0.5721]]]))
test_kwargs = {'eps': 1e-06, 'keepdim': False}, target = 'numpy', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[0.6511554 , 0.26545417, 0.3021322 , 0.4762929 , 0.6681538 ],
       [0.49875498, 0.7437279 , 0.2526375 , 0.4978022 , 0.50484544],
       [0.3194781 , 0.20717472, 0.72167444, 0.7639963 , 0.8377681 ]],
      dtype=float32)
y = array([[0.94005924, 0.5244456 , 0.82698756, 0.2834577 , 0.69568926],
       [0.18494421, 0.9690835 , 0.6025157 , 0.75506836, 0.4623261 ],
       [0.84074616, 0.6945061 , 0.8291702 , 0.71010697, 0.9803604 ]],
      dtype=float32)
keepdim = False, eps = 1e-06

    def numpy_euclidean_distance(x, y, keepdim=False, eps=1e-06):
        from ..core.check import numpy_KORNIA_CHECK_SHAPE
        from ...ivy.functional.frontends.torch.tensor import numpy_sqrt_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_sum_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_pow_frnt_
    
        numpy_KORNIA_CHECK_SHAPE(x, ["*", "N"])
        numpy_KORNIA_CHECK_SHAPE(y, ["*", "N"])
        return numpy_sqrt_frnt_(
>           numpy_sum_frnt_(numpy_pow_frnt_(x - y + eps, 2), -1, keepdim)
        )

ivy_transpiled_outputs/numpy_outputs/kornia/geometry/linalg.py:37: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (array([[-0.28890282, -0.2589904 , -0.52485436,  0.19283621, -0.02753444],
       [ 0.31381178, -0.22535457, -0.349877...6515,  0.04252033],
       [-0.52126706, -0.48733038, -0.10749479,  0.05389033, -0.14259131]],
      dtype=float32), 2)
kwargs = {}, numpy_is_array_bknd = <function numpy_is_array_bknd at 0x7f4a7ed25630>
array_like = array([[-0.28890282, -0.2589904 , -0.52485436,  0.19283621, -0.02753444],
       [ 0.31381178, -0.22535457, -0.3498771...25726515,  0.04252033],
       [-0.52126706, -0.48733038, -0.10749479,  0.05389033, -0.14259131]],
      dtype=float32)

    @functools.wraps(fn)
    def wrapper(*args, **kwargs):
        from ..functional.ivy.general import numpy_is_array_bknd
    
        array_like = args[0]
        if hasattr(array_like, "__class__") and array_like.__class__.__name__ in [
            "list",
            "tuple",
        ]:
            array_like = array_like[0]
        if numpy_is_array_bknd(array_like):
>           return fn(*args, **kwargs)

ivy_transpiled_outputs/numpy_outputs/ivy/utils/decorator_utils.py:200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = array([[-0.28890282, -0.2589904 , -0.52485436,  0.19283621, -0.02753444],
       [ 0.31381178, -0.22535457, -0.3498771...25726515,  0.04252033],
       [-0.52126706, -0.48733038, -0.10749479,  0.05389033, -0.14259131]],
      dtype=float32)
exponent = 2

    @numpy_handle_methods
    def numpy_pow_frnt_(tensor, exponent):
        from .pointwise_ops import numpy_pow_frnt
    
>       return numpy_pow_frnt(tensor, exponent)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/tensor.py:147: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (array([[-0.28890282, -0.2589904 , -0.52485436,  0.19283621, -0.02753444],
       [ 0.31381178, -0.22535457, -0.349877...6515,  0.04252033],
       [-0.52126706, -0.48733038, -0.10749479,  0.05389033, -0.14259131]],
      dtype=float32), 2)
kwargs = {}, numpy_is_array_bknd = <function numpy_is_array_bknd at 0x7f4a7ed25630>
array_like = array([[-0.28890282, -0.2589904 , -0.52485436,  0.19283621, -0.02753444],
       [ 0.31381178, -0.22535457, -0.3498771...25726515,  0.04252033],
       [-0.52126706, -0.48733038, -0.10749479,  0.05389033, -0.14259131]],
      dtype=float32)

    @functools.wraps(fn)
    def wrapper(*args, **kwargs):
        from ..functional.ivy.general import numpy_is_array_bknd
    
        array_like = args[0]
        if hasattr(array_like, "__class__") and array_like.__class__.__name__ in [
            "list",
            "tuple",
        ]:
            array_like = array_like[0]
        if numpy_is_array_bknd(array_like):
>           return fn(*args, **kwargs)

ivy_transpiled_outputs/numpy_outputs/ivy/utils/decorator_utils.py:200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = array([[-0.28890282, -0.2589904 , -0.52485436,  0.19283621, -0.02753444],
       [ 0.31381178, -0.22535457, -0.3498771...25726515,  0.04252033],
       [-0.52126706, -0.48733038, -0.10749479,  0.05389033, -0.14259131]],
      dtype=float32)
exponent = array(2)

    @numpy_handle_methods
    def numpy_pow_frnt(input, exponent, *, out=None):
        from ...ivy.general import numpy_is_array_bknd
        from .creation_ops import numpy_as_tensor_frnt
        from ...backends.numpy.creation import numpy_asarray
        from .__init__ import numpy_promote_types_of_torch_inputs_frnt
        from ...ivy.data_type import numpy_is_int_dtype_bknd
        from ...backends.numpy.elementwise import numpy_pow
        from ...backends.numpy.utility import numpy_any
        from ...backends.numpy.searching import numpy_where
        from ...backends.numpy.elementwise import numpy_bitwise_and
        from ....data_classes.array.data_type import numpy_astype_bknd_
    
        if not numpy_is_array_bknd(input):
            input = numpy_as_tensor_frnt(input)
        if not numpy_is_array_bknd(exponent):
            if (
                any(dtype in str(input.dtype) for dtype in ["int8", "int16"])
                and isinstance(exponent, (int,))
                or "float16" in str(input.dtype)
                and isinstance(exponent, (float,))
            ):
                exponent = numpy_asarray(exponent, dtype=input.dtype)
            else:
                exponent = numpy_as_tensor_frnt(exponent)
>       input, exponent = numpy_promote_types_of_torch_inputs_frnt(input, exponent)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/pointwise_ops.py:91: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x1 = array([[-0.28890282, -0.2589904 , -0.52485436,  0.19283621, -0.02753444],
       [ 0.31381178, -0.22535457, -0.3498771...25726515,  0.04252033],
       [-0.52126706, -0.48733038, -0.10749479,  0.05389033, -0.14259131]],
      dtype=float32)
x2 = array(2)

    def numpy_promote_types_of_torch_inputs_frnt(x1, x2, /):
        from ...ivy.general import numpy_isscalar_bknd
        from ...ivy.data_type import numpy_is_int_dtype_bknd
        from ...backends.numpy.creation import numpy_asarray
        from ...ivy.data_type import numpy_default_dtype_bknd
        from .tensor import numpy_shape_frnt_
        from ...ivy.device import numpy_default_device_bknd
        from ....data_classes.array.data_type import numpy_astype_bknd_
    
        """Promote the dtype of the given native array inputs to a common dtype
        based on type promotion rules.
    
        While passing float or integer values or any other non-array input
        to this function, it should be noted that the return will be an
        array-like object. Therefore, outputs from this function should be
        used as inputs only for those functions that expect an array-like or
        tensor-like objects, otherwise it might give unexpected results.
        """
        if (
            numpy_isscalar_bknd(x1) or isinstance(x1, (list, tuple))
        ) and numpy_is_int_dtype_bknd(x1):
            x1 = numpy_asarray(x1, dtype="int64")
        elif numpy_isscalar_bknd(x1) or isinstance(x1, (list, tuple)):
            x1 = numpy_asarray(x1)
        if (
            numpy_isscalar_bknd(x2) or isinstance(x2, (list, tuple))
        ) and numpy_is_int_dtype_bknd(x2):
            x2 = numpy_asarray(x2, dtype="int64")
        elif numpy_isscalar_bknd(x2) or isinstance(x2, (list, tuple)):
            x2 = numpy_asarray(x2)
        type1 = numpy_default_dtype_bknd(item=x1).strip("u123456789")
        type2 = numpy_default_dtype_bknd(item=x2).strip("u123456789")
        if numpy_shape_frnt_(x1) != () and numpy_shape_frnt_(x2) == () and type1 == type2:
            x2 = numpy_asarray(
                x2,
                dtype=x1.dtype,
                device=numpy_default_device_bknd(item=x1, as_native=False),
            )
        elif numpy_shape_frnt_(x1) == () and numpy_shape_frnt_(x2) != () and type1 == type2:
            x1 = numpy_asarray(
                x1,
                dtype=x2.dtype,
                device=numpy_default_device_bknd(item=x2, as_native=False),
            )
        elif x1.dtype != x2.dtype:
>           promoted = numpy_promote_types_torch_frnt(x1.dtype, x2.dtype)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/__init__.py:87: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

type1 = dtype('float32'), type2 = dtype('int64')

    def numpy_promote_types_torch_frnt(type1, type2, /):
        from ...backends.numpy.general import numpy_get_item
        from ...backends.numpy.data_type import numpy_as_ivy_dtype
    
        try:
            ret = numpy_get_item(
>               torch_promotion_table,
                (numpy_as_ivy_dtype(type1), numpy_as_ivy_dtype(type2)),
            )
E           NameError: name 'torch_promotion_table' is not defined

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/__init__.py:34: NameError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.linalg.euclidean_distance
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/geometry/test_linalg.py::test_euclidean_distance[numpy-s2s-False] - NameError: name 'torch_promotion_table' is not defined
=============================================================================== 1 failed, 7 passed in 271.43s (0:04:31) ================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 19 items

kornia/test_feature1.py .....F.............                                                                                                                                                      [100%]

=============================================================================================== FAILURES ===============================================================================================
____________________________________________________________________________ test_get_laf_descriptors[tensorflow-s2s-False] ____________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_get_laf_descriptors(target_framework, mode, backend_compile):
        trace_args = (
            torch.rand(1, 1, 32, 32),
            torch.rand(1, 3, 2, 3),
            kornia.feature.OriNet(pretrained=False),
        )
        trace_kwargs = {'patch_size': 32, 'grayscale_descriptor': True}
        test_args = (
            torch.rand(5, 1, 32, 32),
            torch.rand(5, 3, 2, 3),
            kornia.feature.OriNet(pretrained=False),
        )
        test_kwargs = {'patch_size': 32, 'grayscale_descriptor': True}
        class_info = {
            'trace_args': {
                2: {'object': kornia.feature.OriNet, 'kwargs': {'pretrained': False}}
            },
            'test_args': {
                2: {'object': kornia.feature.OriNet, 'kwargs': {'pretrained': False}}
            }
        }
>       _test_function(
            kornia.feature.get_laf_descriptors,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
            class_info=class_info,
        )

kornia/test_feature1.py:148: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function get_laf_descriptors at 0x7fca07dfb9a0>
trace_args = (tensor([[[[0.0615, 0.1522, 0.7385,  ..., 0.8131, 0.4597, 0.0893],
          [0.9989, 0.2939, 0.4240,  ..., 0.4314, 0...., kernel_size=(8, 8), stride=(1, 1), padding=(1, 1))
    (20): Tanh()
    (21): AdaptiveAvgPool2d(output_size=1)
  )
))
trace_kwargs = {'grayscale_descriptor': True, 'patch_size': 32}
test_args = (tensor([[[[0.4799, 0.3738, 0.5803,  ..., 0.2887, 0.8207, 0.6460],
          [0.3104, 0.9262, 0.3004,  ..., 0.4203, 0...., kernel_size=(8, 8), stride=(1, 1), padding=(1, 1))
    (20): Tanh()
    (21): AdaptiveAvgPool2d(output_size=1)
  )
))
test_kwargs = {'grayscale_descriptor': True, 'patch_size': 32}, target = 'tensorflow', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = True
class_info = {'test_args': {2: {'kwargs': {'pretrained': False}, 'object': <class 'kornia.feature.orientation.OriNet'>}}, 'trace_args': {2: {'kwargs': {'pretrained': False}, 'object': <class 'kornia.feature.orientation.OriNet'>}}}

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function get_laf_descriptors at 0x7fca07dfb9a0>, fn_name = 'kornia.feature.get_laf_descriptors'
trace_args = (tensor([[[[0.0615, 0.1522, 0.7385,  ..., 0.8131, 0.4597, 0.0893],
          [0.9989, 0.2939, 0.4240,  ..., 0.4314, 0...., kernel_size=(8, 8), stride=(1, 1), padding=(1, 1))
    (20): Tanh()
    (21): AdaptiveAvgPool2d(output_size=1)
  )
))
trace_kwargs = {'grayscale_descriptor': True, 'patch_size': 32}
test_args = (tensor([[[[0.4799, 0.3738, 0.5803,  ..., 0.2887, 0.8207, 0.6460],
          [0.3104, 0.9262, 0.3004,  ..., 0.4203, 0...., kernel_size=(8, 8), stride=(1, 1), padding=(1, 1))
    (20): Tanh()
    (21): AdaptiveAvgPool2d(output_size=1)
  )
))
test_kwargs = {'grayscale_descriptor': True, 'patch_size': 32}, target = 'tensorflow', backend_compile = False, tolerance = 0.001, deterministic = True
class_info = {'test_args': {2: {'kwargs': {'pretrained': False}, 'object': <class 'kornia.feature.orientation.OriNet'>}}, 'trace_args': {2: {'kwargs': {'pretrained': False}, 'object': <class 'kornia.feature.orientation.OriNet'>}}}

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
>       [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]

helpers.py:331: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

.0 = <zip object at 0x7fca329b2900>

>   [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]

helpers.py:331: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

original_model = OriNet(
  (features): Sequential(
    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False...2, kernel_size=(8, 8), stride=(1, 1), padding=(1, 1))
    (20): Tanh()
    (21): AdaptiveAvgPool2d(output_size=1)
  )
)
translated_model = tensorflow_OriNet(
  (features): tensorflow_Sequential(
    (0): KerasConv2D()
    (1): KerasBatchNorm2D()
    (2): te...tensorflow_Dropout()
    (19): KerasConv2D()
    (20): tensorflow_Tanh()
    (21): tensorflow_AdaptiveAvgPool2d()
  )
)

    def sync_models(
        original_model: "nn.Module",
        translated_model: Union["keras.Model", "KerasModel", "nnx.Module", "FlaxModel"],
    ):
        """Synchronizes the weights and buffers between a native PyTorch model
        (`torch.nn.Module`) and it's translated version in TensorFlow or Flax.
    
        Args:
        ----
            original_model (torch.nn.Module): The PyTorch model to synchronize from.
            translated_model (tf.keras.Model or nnx.Module): The target model to synchronize to,
                                                      either a TensorFlow or Flax model.
        """
        if not _is_submodule(original_model, "torch"):
            raise ivy.utils.exceptions.IvyException(
                "sync_models expected an instance of `nn.Module` as the first argument. got {}".format(
                    original_model
                )
            )
        if _is_submodule(translated_model, "keras"):
>           sync_models_torch_and_tf(original_model, translated_model)

../ivy/ivy/stateful/utilities.py:796: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

model_pt = OriNet(
  (features): Sequential(
    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False...2, kernel_size=(8, 8), stride=(1, 1), padding=(1, 1))
    (20): Tanh()
    (21): AdaptiveAvgPool2d(output_size=1)
  )
)
model_tf = tensorflow_OriNet(
  (features): tensorflow_Sequential(
    (0): KerasConv2D()
    (1): KerasBatchNorm2D()
    (2): te...tensorflow_Dropout()
    (19): KerasConv2D()
    (20): tensorflow_Tanh()
    (21): tensorflow_AdaptiveAvgPool2d()
  )
)

    def sync_models_torch_and_tf(
        model_pt: "nn.Module", model_tf: Union["keras.Model", "KerasModel"]
    ):
        """Synchronizes the weights and buffers between a PyTorch model
        (`torch.nn.Module`) and a TensorFlow model (`keras.Model`).
    
        This function ensures that both models have identical parameters and buffers by
        iterating through their submodules and synchronizing them. The TensorFlow model
        must either be an instance of `KerasModel` or have submodules that inherit from the
        translated `KerasModel`/`KerasLayer`, and expose interfaces similar to `torch.nn.Module`,
        including `named_parameters()` and `named_buffers()`.
    
        Args:
        ----
            model_pt (torch.nn.Module): The PyTorch model to synchronize from.
            model_tf (keras.Model): The TensorFlow model to synchronize to, with submodules
                                    inheriting from the custom `KerasModel`/`KerasLayer` class.
    
        Returns:
        -------
            None
    
    
        Example:
        -------
            ```python
            import torch.nn as nn
            import keras
    
            #`CustomKerasLinear` is a subclass of `Layer` that exposes a similar
            # interface to torch.nn.Module (with named_parameters and named_buffers).
            class CustomKerasLinear(Layer):
                def __init__(self, in_features, out_features):
                    super(CustomKerasLinear, self).__init__()
                    self.weight = tf.Variable(tf.random.normal([out_features, in_features]))
                    self.bias = tf.Variable(tf.random.normal([out_features]))
    
                def call(self, x):
                    return tf.matmul(x, self.weight) + self.bias
    
                def named_parameters(self):
                            return [("weight", self.weight), ("bias", self.bias)]
    
                def named_buffers(self):
                            return []
    
                def eval(self):
                    return False
    
            #`NativeKerasModel` is a subclass of keras.Model and does NOT exposes a similar
            # interface to torch.nn.Module (with named_parameters and named_buffers).
            class NativeKerasModel(keras.Model):
                def __init__(self):
                    super(NativeKerasModel, self).__init__()
                    self.linear = CustomKerasLinear(10, 5)
    
                def call(self, x):
                    return self.linear(x)
    
            class PyTorchModel(nn.Module):
                def __init__(self):
                    super(PyTorchModel, self).__init__()
                    self.linear = nn.Linear(10, 5)
    
                def forward(self, x):
                    return self.linear(x)
    
            # Instantiate both models
            model_pt = PyTorchModel()  # PyTorch model
            model_tf = NativeKerasModel()  # Native Keras model inheriting from keras.Model
    
            # Sync all submodules between the PyTorch and Keras models
            sync_models_torch_and_tf(model_pt, model_tf)
            ```
        """
    
        def _compute_module_dict_tf(model, prefix=""):
            _module_dict = dict()
            for key, value in model.__dict__.items():
                if isinstance(value, (tf.keras.Model, tf.keras.layers.Layer)):
                    if not hasattr(value, "named_parameters"):
                        _module_dict.update(
                            _compute_module_dict_tf(value, prefix=f"{key}.")
                        )
                    else:
                        _module_dict[prefix + key] = value
            return _module_dict
    
        try:
            pass
        except ModuleNotFoundError as exc:
            raise ModuleNotFoundError(
                "`torch` was not found installed on your system. Please proceed "
                "to install it and restart your interpreter to see the changes."
            ) from exc
    
        try:
            import tensorflow as tf
        except ModuleNotFoundError as exc:
            raise ModuleNotFoundError(
                "`tensorflow` was not found installed on your system. Please proceed "
                "to install it and restart your interpreter to see the changes."
            ) from exc
    
        if hasattr(model_tf, "named_parameters"):
>           _sync_models_torch_and_tf(model_pt, model_tf)

../ivy/ivy/stateful/utilities.py:626: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

model1 = OriNet(
  (features): Sequential(
    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False...2, kernel_size=(8, 8), stride=(1, 1), padding=(1, 1))
    (20): Tanh()
    (21): AdaptiveAvgPool2d(output_size=1)
  )
)
model2 = tensorflow_OriNet(
  (features): tensorflow_Sequential(
    (0): KerasConv2D()
    (1): KerasBatchNorm2D()
    (2): te...tensorflow_Dropout()
    (19): KerasConv2D()
    (20): tensorflow_Tanh()
    (21): tensorflow_AdaptiveAvgPool2d()
  )
)

    def _sync_models_torch_and_tf(model1: "nn.Module", model2: "KerasModel"):
        """Synchronizes the parameters and buffers of the original and the
        translated model.
    
        Args:
        ----
            model1 (torch.nn.Module): The original PyTorch model.
            model2 (ivy.Module converted keras.Model)): The converted ivy.Module converted keras.Model.
    
        Returns:
        -------
            None
        """
        def _pt_name_to_keras_name(layer, weight_name):
            if layer.__class__.__name__ in ("KerasConv2D", "KerasDense"):
                param_and_buff_map = {
                    "weight": "_kernel",
                    "bias": "bias",
                }
            elif layer.__class__.__name__ == "KerasDepthwiseConv2D":
                if parse(keras.__version__).major > 2:
                    param_and_buff_map = {
                        "weight": "kernel",
                        "bias": "bias",
                    }
                else:
                    param_and_buff_map = {
                        "weight": "depthwise_kernel",
                        "bias": "bias",
                    }
            elif layer.__class__.__name__ == "KerasBatchNorm2D":
                param_and_buff_map = {
                    "weight": "gamma",
                    "bias": "beta",
                    "running_mean": "moving_mean",
                    "running_var": "moving_variance",
                    "num_batches_tracked": "num_batches_tracked",
                }
            else:
                raise ValueError(f"Layer '{layer}' is not supported.")
    
            return param_and_buff_map[weight_name]
    
        def _maybe_update_keras_layer_weights(layer, weight_name, new_weight, original_weight):
            # Update the weight in the retrieved layer
            if hasattr(layer, weight_name):
                layer._is_built = True
                weight_var = getattr(layer, weight_name)
                if isinstance(weight_var, tf.Variable):
                    weight_var.assign(tf.Variable(new_weight, dtype=weight_var.dtype))
                elif isinstance(weight_var, KerasVariable):
                    weight_var.assign(
                        KerasVariable(
                            new_weight, dtype=weight_var.dtype, name=weight_var.name
                        )
                    )
                else:
                    setattr(
                        layer,
                        weight_name,
                        tf.convert_to_tensor(original_weight, dtype=weight_var.dtype),
                    )
                # now also update the PT placeholder weights for this layer
                layer._is_built = False
                pt_weight_name = (
                    "pt_weight"
                    if weight_name == "weight"
                    else "pt_bias" if weight_name == "bias" else weight_name
                )
                setattr(
                    layer,
                    pt_weight_name,
                    None if original_weight is None else tf.convert_to_tensor(original_weight, dtype=weight_var.dtype),
                )
            else:
                raise AttributeError(
                    f"Layer '{layer}' does not have a weight named '{weight_name}'"
                )
    
        import torch
        import tensorflow as tf
        import keras
    
        if parse(keras.__version__).major > 2:
            KerasVariable = keras.src.backend.Variable
        else:
            KerasVariable = tf.Variable
    
        has_keras_layers = os.environ.get("USE_NATIVE_FW_LAYERS", "true") == "true"
        transpose_weights = (
            has_keras_layers
            or os.environ.get("APPLY_TRANSPOSE_OPTIMIZATION", "true") == "true"
        )
    
        params1 = dict(model1.named_parameters())
        params2 = dict(model2.named_parameters())
        buffers1 = dict(model1.named_buffers())
        buffers2 = dict(model2.named_buffers())
        # TODO: remove this once the stateful attribute name-conflict has been resolved.
        key_mapping = {}
        for k in params2.keys():
            key_mapping[k.replace("pt_", "")] = k
    
        for k in buffers2.keys():
            key_mapping[k.replace("pt_", "")] = k
    
        params2 = {k.replace("pt_", ""): v for k, v in params2.items()}
        buffers2 = {k.replace("pt_", ""): v for k, v in buffers2.items()}
    
        # Check if both models have the same parameters and buffers
        assert params1.keys() == params2.keys()
        assert buffers1.keys() == buffers2.keys()
    
        # Set the parameters and buffers of the second model to be the same as the first model
        with torch.no_grad():
            for name in params1:
                layer, weight_name = _retrive_layer(model2, key_mapping[name])
    
                params1_np = params1[name].cpu().detach().numpy()
                # Transpose the parameters to match the TensorFlow format
                params1_np = transpose_weights_pt_to_tf_jax(layer, params1_np, transpose_weights, fw='tensorflow')
    
                # inplace update the native keras layer. This is done as the parameters in
                # self.v are a different copy than the parameters in self.weights. Hence, we
                # need to explicitly update self.weights, otherwise the changes won't reflect.
                if layer.__class__.__name__.startswith("Keras"):
                    keras_name = _pt_name_to_keras_name(layer, weight_name)
>                   _maybe_update_keras_layer_weights(
                        layer=layer, weight_name=weight_name, new_weight=params1_np, original_weight=params1[name].cpu().detach().numpy()
                    )

../ivy/ivy/stateful/utilities.py:460: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

layer = KerasConv2D(), weight_name = 'weight'
new_weight = array([[[[ 0.19941711,  0.04147383,  0.1464688 , -0.32656   ,
          -0.29231617, -0.02037748, -0.25977802,  0.0973...24904, -0.01686104, -0.11364174,
          -0.12521482, -0.07517612, -0.15021369, -0.05522215]]]],
      dtype=float32)
original_weight = array([[[[ 0.19941711,  0.25571105,  0.15580833],
         [-0.32986876, -0.21132383,  0.19736521],
         [ 0.27456...,
         [ 0.25430965, -0.00099079, -0.14564452],
         [-0.2014204 ,  0.3131469 , -0.05522215]]]], dtype=float32)

    def _maybe_update_keras_layer_weights(layer, weight_name, new_weight, original_weight):
        # Update the weight in the retrieved layer
        if hasattr(layer, weight_name):
            layer._is_built = True
>           weight_var = getattr(layer, weight_name)

../ivy/ivy/stateful/utilities.py:380: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = KerasConv2D(), name = 'weight'

    def __getattribute__(self, name):
        built = object.__getattribute__(self, "__dict__").get("_is_built", False)
        use_bias = object.__getattribute__(self, "__dict__").get("use_bias", True)
        if built:
            attr_map = {"weight": "_kernel", "bias": "bias"}
        else:
            attr_map = {"weight": "pt_weight", "bias": "pt_bias"}
        if not use_bias:
            attr_map["bias"] = "pt_bias"
        new_name = attr_map[name] if name in attr_map else name
>       return super().__getattribute__(new_name)
E       AttributeError: 'KerasConv2D' object has no attribute '_kernel'. Did you mean: 'weights'?

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful_layers.py:626: AttributeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.integrated.get_laf_descriptors
All parameters and buffers are now synced!
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/test_feature1.py::test_get_laf_descriptors[tensorflow-s2s-False] - AttributeError: 'KerasConv2D' object has no attribute '_kernel'. Did you mean: 'weights'?
============================================================================== 1 failed, 18 passed in 1588.60s (0:26:28) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 3 items

kornia/augmentation/test_auto.py FFF                                                                                                                                                             [100%]

=============================================================================================== FAILURES ===============================================================================================
___________________________________________________________________________________ test_AutoAugment[jax-s2s-False] ____________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_AutoAugment(target_framework, mode, backend_compile):
        print("kornia.augmentation.auto.AutoAugment")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledAutoAugment = ivy.transpile(
            kornia.augmentation.auto.AutoAugment,
            source="torch",
            target=target_framework,
        )
    
        torch_aug = kornia.augmentation.auto.AutoAugment()
>       transpiled_aug = TranspiledAutoAugment()

kornia/augmentation/test_auto.py:29: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.augmentation.auto.autoaugment.autoaugment.jax_AutoAugment'>, args = (), kwargs = {}

    def __call__(cls, *args: Any, **kwargs: Any) -> Any:
>     return _graph_node_meta_call(cls, *args, **kwargs)

/opt/fw/jax/flax/nnx/nnx/object.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.augmentation.auto.autoaugment.autoaugment.jax_AutoAugment'>, args = (), kwargs = {}
node = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] jax_AutoAugment object at 0x7f1941e019c0>

    def _graph_node_meta_call(cls: tp.Type[G], *args, **kwargs) -> G:
      node = cls.__new__(cls, *args, **kwargs)
      vars(node)['_object__state'] = ObjectState()
>     cls._object_meta_construct(node, *args, **kwargs)

/opt/fw/jax/flax/nnx/nnx/object.py:88: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.augmentation.auto.autoaugment.autoaugment.jax_AutoAugment'>
self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] jax_AutoAugment object at 0x7f1941e019c0>, args = (), kwargs = {}

    def _object_meta_construct(cls, self, *args, **kwargs):
>     self.__init__(*args, **kwargs)

/opt/fw/jax/flax/nnx/nnx/object.py:82: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] jax_AutoAugment object at 0x7f1941e019c0>, policy = 'imagenet', transformation_matrix_mode = 'silent'

    def __init__(self, policy="imagenet", transformation_matrix_mode="silent"):
        from ....core._backend import tensor
        from .....torch.distributions.categorical import jax_Categorical
    
        if policy == "imagenet":
            _policy = imagenet_policy
        elif policy == "cifar10":
            _policy = cifar10_policy
        elif policy == "svhn":
            _policy = svhn_policy
        elif isinstance(policy, (list, tuple)):
            _policy = policy
        else:
            raise NotImplementedError(f"Invalid policy `{policy}`.")
>       super().__init__(_policy, transformation_matrix_mode=transformation_matrix_mode)

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/auto/autoaugment/autoaugment.py:127: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] jax_AutoAugment object at 0x7f1941e019c0>
args = ([[('posterize', 0.4, 8), ('rotate', 0.6, 9)], [('solarize', 0.6, 5), ('auto_contrast', 0.6, None)], [('equalize', 0.8...rize', 0.6, 6)], [('equalize', 0.4, None), ('solarize', 0.2, 4)], [('equalize', 0.4, None), ('rotate', 0.8, 8)], ...],)
kwargs = {'transformation_matrix_mode': 'silent'}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/utils/decorator_utils.py:245: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] jax_AutoAugment object at 0x7f1941e019c0>
policy = [[('posterize', 0.4, 8), ('rotate', 0.6, 9)], [('solarize', 0.6, 5), ('auto_contrast', 0.6, None)], [('equalize', 0.8,...terize', 0.6, 6)], [('equalize', 0.4, None), ('solarize', 0.2, 4)], [('equalize', 0.4, None), ('rotate', 0.8, 8)], ...]
transformation_matrix_mode = 'silent'

    @jax_store_config_info
    def __init__(self, policy, transformation_matrix_mode="silence"):
        from .operations.policy import jax_PolicySequential
    
>       policies = self.compose_policy(policy)

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/auto/base.py:41: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] jax_AutoAugment object at 0x7f1941e019c0>
policy = [[('posterize', 0.4, 8), ('rotate', 0.6, 9)], [('solarize', 0.6, 5), ('auto_contrast', 0.6, None)], [('equalize', 0.8,...terize', 0.6, 6)], [('equalize', 0.4, None), ('solarize', 0.2, 4)], [('equalize', 0.4, None), ('rotate', 0.8, 8)], ...]

    def compose_policy(self, policy):
>       return [self.compose_subpolicy_sequential(subpolicy) for subpolicy in policy]

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/auto/base.py:54: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

.0 = <list_iterator object at 0x7f1941e010f0>

>   return [self.compose_subpolicy_sequential(subpolicy) for subpolicy in policy]

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/auto/base.py:54: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] jax_AutoAugment object at 0x7f1941e019c0>, subpolicy = [('posterize', 0.4, 8), ('rotate', 0.6, 9)]

    def compose_subpolicy_sequential(self, subpolicy):
        from ..operations.policy import jax_PolicySequential
    
        return jax_PolicySequential(
>           *[
                getattr(kornia.augmentation.auto.autoaugment.ops, name)(prob, mag)
                for name, prob, mag in subpolicy
            ]
        )

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/auto/autoaugment/autoaugment.py:135: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

.0 = <list_iterator object at 0x7f1941e01090>

        *[
>           getattr(kornia.augmentation.auto.autoaugment.ops, name)(prob, mag)
            for name, prob, mag in subpolicy
        ]
    )
E   NameError: name 'kornia' is not defined

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/auto/autoaugment/autoaugment.py:136: NameError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.auto.AutoAugment
___________________________________________________________________________________ test_RandAugment[jax-s2s-False] ____________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_RandAugment(target_framework, mode, backend_compile):
        print("kornia.augmentation.auto.RandAugment")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledRandAugment = ivy.transpile(
            kornia.augmentation.auto.RandAugment,
            source="torch",
            target=target_framework,
        )
    
        torch_aug = kornia.augmentation.auto.RandAugment(n=2, m=10)
>       transpiled_aug = TranspiledRandAugment(n=2, m=10)

kornia/augmentation/test_auto.py:69: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.augmentation.auto.rand_augment.rand_augment.jax_RandAugment'>, args = (), kwargs = {'m': 10, 'n': 2}

    def __call__(cls, *args: Any, **kwargs: Any) -> Any:
>     return _graph_node_meta_call(cls, *args, **kwargs)

/opt/fw/jax/flax/nnx/nnx/object.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.augmentation.auto.rand_augment.rand_augment.jax_RandAugment'>, args = (), kwargs = {'m': 10, 'n': 2}
node = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] jax_RandAugment object at 0x7f1942548af0>

    def _graph_node_meta_call(cls: tp.Type[G], *args, **kwargs) -> G:
      node = cls.__new__(cls, *args, **kwargs)
      vars(node)['_object__state'] = ObjectState()
>     cls._object_meta_construct(node, *args, **kwargs)

/opt/fw/jax/flax/nnx/nnx/object.py:88: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.augmentation.auto.rand_augment.rand_augment.jax_RandAugment'>
self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] jax_RandAugment object at 0x7f1942548af0>, args = (), kwargs = {'m': 10, 'n': 2}

    def _object_meta_construct(cls, self, *args, **kwargs):
>     self.__init__(*args, **kwargs)

/opt/fw/jax/flax/nnx/nnx/object.py:82: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] jax_RandAugment object at 0x7f1942548af0>, n = 2, m = 10, policy = None, transformation_matrix_mode = 'silent'

    def __init__(self, n, m, policy=None, transformation_matrix_mode="silent"):
        if m <= 0 or m >= 30:
            raise ValueError(f"Expect `m` in [0, 30]. Got {m}.")
        if policy is None:
            _policy = default_policy
        else:
            _policy = policy
>       super().__init__(_policy, transformation_matrix_mode=transformation_matrix_mode)

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/auto/rand_augment/rand_augment.py:58: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] jax_RandAugment object at 0x7f1942548af0>
args = ([[('auto_contrast', 0, 1)], [('equalize', 0, 1)], [('invert', 0, 1)], [('rotate', -30.0, 30.0)], [('posterize', 0.0, 4)], [('solarize', 0.0, 1.0)], ...],)
kwargs = {'transformation_matrix_mode': 'silent'}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/utils/decorator_utils.py:245: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] jax_RandAugment object at 0x7f1942548af0>
policy = [[('auto_contrast', 0, 1)], [('equalize', 0, 1)], [('invert', 0, 1)], [('rotate', -30.0, 30.0)], [('posterize', 0.0, 4)], [('solarize', 0.0, 1.0)], ...], transformation_matrix_mode = 'silent'

    @jax_store_config_info
    def __init__(self, policy, transformation_matrix_mode="silence"):
        from .operations.policy import jax_PolicySequential
    
>       policies = self.compose_policy(policy)

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/auto/base.py:41: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] jax_RandAugment object at 0x7f1942548af0>
policy = [[('auto_contrast', 0, 1)], [('equalize', 0, 1)], [('invert', 0, 1)], [('rotate', -30.0, 30.0)], [('posterize', 0.0, 4)], [('solarize', 0.0, 1.0)], ...]

    def compose_policy(self, policy):
>       return [self.compose_subpolicy_sequential(subpolicy) for subpolicy in policy]

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/auto/base.py:54: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

.0 = <list_iterator object at 0x7f1942f44d00>

>   return [self.compose_subpolicy_sequential(subpolicy) for subpolicy in policy]

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/auto/base.py:54: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] jax_RandAugment object at 0x7f1942548af0>, subpolicy = [('auto_contrast', 0, 1)]

    def compose_subpolicy_sequential(self, subpolicy):
        from ..operations.policy import jax_PolicySequential
    
        if len(subpolicy) != 1:
            raise RuntimeError(
                f"Each policy must have only one operation for RandAugment. Got {len(subpolicy)}."
            )
        name, low, high = subpolicy[0][0], subpolicy[0][1], subpolicy[0][2]
        return jax_PolicySequential(
>           *[getattr(kornia.augmentation.auto.rand_augment.ops, name)(low, high)]
        )
E       NameError: name 'kornia' is not defined

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/auto/rand_augment/rand_augment.py:81: NameError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.auto.RandAugment
__________________________________________________________________________________ test_TrivialAugment[jax-s2s-False] __________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_TrivialAugment(target_framework, mode, backend_compile):
        print("kornia.augmentation.auto.TrivialAugment")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledTrivialAugment = ivy.transpile(
            kornia.augmentation.auto.TrivialAugment,
            source="torch",
            target=target_framework,
        )
    
        torch_aug = kornia.augmentation.auto.TrivialAugment()
>       transpiled_aug = TranspiledTrivialAugment()

kornia/augmentation/test_auto.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.augmentation.auto.trivial_augment.trivial_augment.jax_TrivialAugment'>, args = (), kwargs = {}

    def __call__(cls, *args: Any, **kwargs: Any) -> Any:
>     return _graph_node_meta_call(cls, *args, **kwargs)

/opt/fw/jax/flax/nnx/nnx/object.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.augmentation.auto.trivial_augment.trivial_augment.jax_TrivialAugment'>, args = (), kwargs = {}
node = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] jax_TrivialAugment object at 0x7f1940f23d00>

    def _graph_node_meta_call(cls: tp.Type[G], *args, **kwargs) -> G:
      node = cls.__new__(cls, *args, **kwargs)
      vars(node)['_object__state'] = ObjectState()
>     cls._object_meta_construct(node, *args, **kwargs)

/opt/fw/jax/flax/nnx/nnx/object.py:88: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.augmentation.auto.trivial_augment.trivial_augment.jax_TrivialAugment'>
self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] jax_TrivialAugment object at 0x7f1940f23d00>, args = (), kwargs = {}

    def _object_meta_construct(cls, self, *args, **kwargs):
>     self.__init__(*args, **kwargs)

/opt/fw/jax/flax/nnx/nnx/object.py:82: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] jax_TrivialAugment object at 0x7f1940f23d00>, policy = None, transformation_matrix_mode = 'silent'

    def __init__(self, policy=None, transformation_matrix_mode="silent"):
        from .....ivy.functional.frontends.torch.creation_ops import jax_tensor_frnt
        from .....torch.distributions.categorical import jax_Categorical
    
        if policy is None:
            _policy = default_policy
        else:
            _policy = policy
>       super().__init__(_policy, transformation_matrix_mode=transformation_matrix_mode)

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/auto/trivial_augment/trivial_augment.py:54: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] jax_TrivialAugment object at 0x7f1940f23d00>
args = ([[('auto_contrast', 0, 1)], [('equalize', 0, 1)], [('rotate', -30.0, 30.0)], [('posterize', 0.0, 4)], [('solarize', 0.0, 1.0)], [('contrast', 0.1, 1.9)], ...],)
kwargs = {'transformation_matrix_mode': 'silent'}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/utils/decorator_utils.py:245: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] jax_TrivialAugment object at 0x7f1940f23d00>
policy = [[('auto_contrast', 0, 1)], [('equalize', 0, 1)], [('rotate', -30.0, 30.0)], [('posterize', 0.0, 4)], [('solarize', 0.0, 1.0)], [('contrast', 0.1, 1.9)], ...]
transformation_matrix_mode = 'silent'

    @jax_store_config_info
    def __init__(self, policy, transformation_matrix_mode="silence"):
        from .operations.policy import jax_PolicySequential
    
>       policies = self.compose_policy(policy)

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/auto/base.py:41: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] jax_TrivialAugment object at 0x7f1940f23d00>
policy = [[('auto_contrast', 0, 1)], [('equalize', 0, 1)], [('rotate', -30.0, 30.0)], [('posterize', 0.0, 4)], [('solarize', 0.0, 1.0)], [('contrast', 0.1, 1.9)], ...]

    def compose_policy(self, policy):
>       return [self.compose_subpolicy_sequential(subpolicy) for subpolicy in policy]

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/auto/base.py:54: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

.0 = <list_iterator object at 0x7f1940f23af0>

>   return [self.compose_subpolicy_sequential(subpolicy) for subpolicy in policy]

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/auto/base.py:54: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] jax_TrivialAugment object at 0x7f1940f23d00>, subpolicy = [('auto_contrast', 0, 1)]

    def compose_subpolicy_sequential(self, subpolicy):
        from ..operations.policy import jax_PolicySequential
    
        if len(subpolicy) != 1:
            raise RuntimeError(
                f"Each policy must have only one operation for TrivialAugment. Got {len(subpolicy)}."
            )
        name, low, high = subpolicy[0][0], subpolicy[0][1], subpolicy[0][2]
        return jax_PolicySequential(
>           *[getattr(kornia.augmentation.auto.rand_augment.ops, name)(low, high)]
        )
E       NameError: name 'kornia' is not defined

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/auto/trivial_augment/trivial_augment.py:67: NameError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.auto.TrivialAugment
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/augmentation/test_auto.py::test_AutoAugment[jax-s2s-False] - NameError: name 'kornia' is not defined
FAILED kornia/augmentation/test_auto.py::test_RandAugment[jax-s2s-False] - NameError: name 'kornia' is not defined
FAILED kornia/augmentation/test_auto.py::test_TrivialAugment[jax-s2s-False] - NameError: name 'kornia' is not defined
==================================================================================== 3 failed in 1387.69s (0:23:07) ====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 1 item

kornia/geometry/test_quaternion.py .                                                                                                                                                             [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
===================================================================================== 1 passed in 90.20s (0:01:30) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 38 items

kornia/geometry/test_conversions.py ......................................                                                                                                                       [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
=================================================================================== 38 passed in 2065.81s (0:34:25) ====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 6 items

kornia/augmentation/test_container.py FFFF.F                                                                                                                                                     [100%]

=============================================================================================== FAILURES ===============================================================================================
__________________________________________________________________________ test_AugmentationSequential[tensorflow-s2s-False] ___________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_AugmentationSequential(target_framework, mode, backend_compile):
        print("kornia.augmentation.container.AugmentationSequential")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledAugmentationSequential = ivy.transpile(
            kornia.augmentation.container.AugmentationSequential,
            source="torch",
            target=target_framework,
        )
        TranspiledColorJiggle = ivy.transpile(
            kornia.augmentation.ColorJiggle,
            source="torch",
            target=target_framework,
        )
        TranspiledRandomAffine = ivy.transpile(
            kornia.augmentation.RandomAffine,
            source="torch",
            target=target_framework,
        )
    
        torch_aug_list = kornia.augmentation.container.AugmentationSequential(
            kornia.augmentation.ColorJiggle(0.1, 0.1, 0.1, 0.1, p=1.0),
            kornia.augmentation.RandomAffine(360, p=1.0),
            data_keys=["input", "mask", "bbox", "keypoints"],
            same_on_batch=False,
            random_apply=10,
        )
        transpiled_aug_list = TranspiledAugmentationSequential(
            TranspiledColorJiggle(0.1, 0.1, 0.1, 0.1, p=1.0),
            TranspiledRandomAffine(360, p=1.0),
            data_keys=["input", "mask", "bbox", "keypoints"],
            same_on_batch=False,
            random_apply=10,
        )
    
        torch_args = (
            torch.randn(2, 3, 5, 6),
            torch.ones(2, 3, 5, 6),
            torch.tensor([[
                [1., 1.],
                [2., 1.],
                [2., 2.],
                [1., 2.],
            ]]).expand(2, 1, -1, -1),
            torch.tensor([[[1., 1.]]]).expand(2, -1, -1),
        )
        torch_out = torch_aug_list(*torch_args)
    
        transpiled_args = _nest_torch_tensor_to_new_framework(torch_args, target_framework)
>       transpiled_out = transpiled_aug_list(*transpiled_args)

kornia/augmentation/test_container.py:68: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_AugmentationSequential(
  (tensorflow_ColorJiggle_0): tensorflow_ColorJiggle(brightness=0.1, contrast=0.1, ...one, shear=None, p=1.0, p_batch=1.0, same_on_batch=False, resample=bilinear, padding_mode=zeros, align_corners=False)
)
args = (<tf.Tensor: shape=(2, 3, 5, 6), dtype=float32, numpy=
array([[[[ 1.5746349e+00,  6.5427810e-01, -7.7772647e-01,
     ...=float32)>, <tf.Tensor: shape=(2, 1, 2), dtype=float32, numpy=
array([[[1., 1.]],

       [[1., 1.]]], dtype=float32)>)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x7f33ba9db440, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...ode_context=['        return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_AugmentationSequential(
  (tensorflow_ColorJiggle_0): tensorflow_ColorJiggle(brightness=0.1, contrast=0.1,...=float32)>, <tf.Tensor: shape=(2, 1, 2), dtype=float32, numpy=
array([[[1., 1.]],

       [[1., 1.]]], dtype=float32)>)
kwargs = {}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_AugmentationSequential(
  (tensorflow_ColorJiggle_0): tensorflow_ColorJiggle(brightness=0.1, contrast=0.1, ...one, shear=None, p=1.0, p_batch=1.0, same_on_batch=False, resample=bilinear, padding_mode=zeros, align_corners=False)
)
v = None, buffers = None
args = (<tf.Tensor: shape=(2, 3, 5, 6), dtype=float32, numpy=
array([[[[ 1.5746349e+00,  6.5427810e-01, -7.7772647e-01,
     ...=float32)>, <tf.Tensor: shape=(2, 1, 2), dtype=float32, numpy=
array([[[1., 1.]],

       [[1., 1.]]], dtype=float32)>)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_AugmentationSequential(
  (tensorflow_ColorJiggle_0): tensorflow_ColorJiggle(brightness=0.1, contrast=0.1,...=float32)>, <tf.Tensor: shape=(2, 1, 2), dtype=float32, numpy=
array([[[1., 1.]],

       [[1., 1.]]], dtype=float32)>)
kwargs = {'buffers': None, 'v': None}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_AugmentationSequential(
  (tensorflow_ColorJiggle_0): tensorflow_ColorJiggle(brightness=0.1, contrast=0.1, ...one, shear=None, p=1.0, p_batch=1.0, same_on_batch=False, resample=bilinear, padding_mode=zeros, align_corners=False)
)
v = None, buffers = None
args = (<tf.Tensor: shape=(2, 3, 5, 6), dtype=float32, numpy=
array([[[[ 1.5746349e+00,  6.5427810e-01, -7.7772647e-01,
     ...=float32)>, <tf.Tensor: shape=(2, 1, 2), dtype=float32, numpy=
array([[[1., 1.]],

       [[1., 1.]]], dtype=float32)>)
kwargs = {}, replace_v = False, replace_buffers = False, call_signature = <Signature (*args, params=None, data_keys=None)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Layer, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Layer, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Layer, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_AugmentationSequential(
  (tensorflow_ColorJiggle_0): tensorflow_ColorJiggle(brightness=0.1, contrast=0.1,...e, shear=None, p=1.0, p_batch=1.0, same_on_batch=False, resample=bilinear, padding_mode=zeros, align_corners=False)
),)
kwargs = {'args': <tf.Tensor: shape=(2, 3, 5, 6), dtype=float32, numpy=
array([[[[ 1.5746349e+00,  6.5427810e-01, -7.7772647e-0...    [1., 1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1., 1.]]]], dtype=float32)>}

    @wraps(fn)
    def error_handler(*args, **kwargs):
        if not is_traceback_filtering_enabled():
            return fn(*args, **kwargs)
    
        filtered_tb = None
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            filtered_tb = _process_traceback_frames(e.__traceback__)
            # To get the full stack trace, call:
            # `keras.config.disable_traceback_filtering()`
>           raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/keras/src/utils/traceback_utils.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <Signature (*args, params=None, data_keys=None)>, args = ()
kwargs = {'args': <tf.Tensor: shape=(2, 3, 5, 6), dtype=float32, numpy=
array([[[[ 1.5746349e+00,  6.5427810e-01, -7.7772647e-0...1, -3.4862426e-01,  7.6648749e-02,
          -1.3362442e-01,  3.1483799e-01,  9.8382175e-01]]]],
      dtype=float32)>}

    def bind(self, /, *args, **kwargs):
        """Get a BoundArguments object, that maps the passed `args`
        and `kwargs` to the function's signature.  Raises `TypeError`
        if the passed arguments can not be bound.
        """
>       return self._bind(args, kwargs)

/opt/miniconda/envs/multienv/lib/python3.10/inspect.py:3177: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <Signature (*args, params=None, data_keys=None)>, args = ()
kwargs = {'args': <tf.Tensor: shape=(2, 3, 5, 6), dtype=float32, numpy=
array([[[[ 1.5746349e+00,  6.5427810e-01, -7.7772647e-0...1, -3.4862426e-01,  7.6648749e-02,
          -1.3362442e-01,  3.1483799e-01,  9.8382175e-01]]]],
      dtype=float32)>}

    def _bind(self, args, kwargs, *, partial=False):
        """Private method. Don't use directly."""
    
        arguments = {}
    
        parameters = iter(self.parameters.values())
        parameters_ex = ()
        arg_vals = iter(args)
    
        while True:
            # Let's iterate through the positional arguments and corresponding
            # parameters
            try:
                arg_val = next(arg_vals)
            except StopIteration:
                # No more positional arguments
                try:
                    param = next(parameters)
                except StopIteration:
                    # No more parameters. That's it. Just need to check that
                    # we have no `kwargs` after this while loop
                    break
                else:
                    if param.kind == _VAR_POSITIONAL:
                        # That's OK, just empty *args.  Let's start parsing
                        # kwargs
                        break
                    elif param.name in kwargs:
                        if param.kind == _POSITIONAL_ONLY:
                            msg = '{arg!r} parameter is positional only, ' \
                                  'but was passed as a keyword'
                            msg = msg.format(arg=param.name)
                            raise TypeError(msg) from None
                        parameters_ex = (param,)
                        break
                    elif (param.kind == _VAR_KEYWORD or
                                                param.default is not _empty):
                        # That's fine too - we have a default value for this
                        # parameter.  So, lets start parsing `kwargs`, starting
                        # with the current parameter
                        parameters_ex = (param,)
                        break
                    else:
                        # No default, not VAR_KEYWORD, not VAR_POSITIONAL,
                        # not in `kwargs`
                        if partial:
                            parameters_ex = (param,)
                            break
                        else:
                            msg = 'missing a required argument: {arg!r}'
                            msg = msg.format(arg=param.name)
                            raise TypeError(msg) from None
            else:
                # We have a positional argument to process
                try:
                    param = next(parameters)
                except StopIteration:
                    raise TypeError('too many positional arguments') from None
                else:
                    if param.kind in (_VAR_KEYWORD, _KEYWORD_ONLY):
                        # Looks like we have no parameter for this positional
                        # argument
                        raise TypeError(
                            'too many positional arguments') from None
    
                    if param.kind == _VAR_POSITIONAL:
                        # We have an '*args'-like argument, let's fill it with
                        # all positional arguments we have left and move on to
                        # the next phase
                        values = [arg_val]
                        values.extend(arg_vals)
                        arguments[param.name] = tuple(values)
                        break
    
                    if param.name in kwargs and param.kind != _POSITIONAL_ONLY:
                        raise TypeError(
                            'multiple values for argument {arg!r}'.format(
                                arg=param.name)) from None
    
                    arguments[param.name] = arg_val
    
        # Now, we iterate through the remaining parameters to process
        # keyword arguments
        kwargs_param = None
        for param in itertools.chain(parameters_ex, parameters):
            if param.kind == _VAR_KEYWORD:
                # Memorize that we have a '**kwargs'-like parameter
                kwargs_param = param
                continue
    
            if param.kind == _VAR_POSITIONAL:
                # Named arguments don't refer to '*args'-like parameters.
                # We only arrive here if the positional arguments ended
                # before reaching the last parameter before *args.
                continue
    
            param_name = param.name
            try:
                arg_val = kwargs.pop(param_name)
            except KeyError:
                # We have no value for this parameter.  It's fine though,
                # if it has a default value, or it is an '*args'-like
                # parameter, left alone by the processing of positional
                # arguments.
                if (not partial and param.kind != _VAR_POSITIONAL and
                                                    param.default is _empty):
                    raise TypeError('missing a required argument: {arg!r}'. \
                                    format(arg=param_name)) from None
    
            else:
                if param.kind == _POSITIONAL_ONLY:
                    # This should never happen in case of a properly built
                    # Signature object (but let's have this check here
                    # to ensure correct behaviour just in case)
                    raise TypeError('{arg!r} parameter is positional only, '
                                    'but was passed as a keyword'. \
                                    format(arg=param.name))
    
                arguments[param_name] = arg_val
    
        if kwargs:
            if kwargs_param is not None:
                # Process our '**kwargs'-like parameter
                arguments[kwargs_param.name] = kwargs
            else:
>               raise TypeError(
                    'got an unexpected keyword argument {arg!r}'.format(
                        arg=next(iter(kwargs))))
E               TypeError: got an unexpected keyword argument 'args'

/opt/miniconda/envs/multienv/lib/python3.10/inspect.py:3166: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.container.AugmentationSequential
______________________________________________________________________ test_ManyToManyAugmentationDispather[tensorflow-s2s-False] ______________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_ManyToManyAugmentationDispather(target_framework, mode, backend_compile):
        print("kornia.augmentation.container.ManyToManyAugmentationDispather")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledManyToManyAugmentationDispather = ivy.transpile(
            kornia.augmentation.container.ManyToManyAugmentationDispather,
            source="torch",
            target=target_framework,
        )
        TranspiledAugmentationSequential = ivy.transpile(
            kornia.augmentation.container.AugmentationSequential,
            source="torch",
            target=target_framework,
        )
        TranspiledColorJiggle = ivy.transpile(
            kornia.augmentation.ColorJiggle,
            source="torch",
            target=target_framework,
        )
        TranspiledRandomAffine = ivy.transpile(
            kornia.augmentation.RandomAffine,
            source="torch",
            target=target_framework,
        )
    
        torch_aug_list = kornia.augmentation.container.ManyToManyAugmentationDispather(
            kornia.augmentation.container.AugmentationSequential(
                kornia.augmentation.ColorJiggle(0.1, 0.1, 0.1, 0.1, p=1.0),
                kornia.augmentation.RandomAffine(360, p=1.0),
                data_keys=["input", "mask",],
            ),
            kornia.augmentation.container.AugmentationSequential(
                kornia.augmentation.ColorJiggle(0.1, 0.1, 0.1, 0.1, p=1.0),
                kornia.augmentation.RandomAffine(360, p=1.0),
                data_keys=["input", "mask",],
            )
        )
        transpiled_aug_list = TranspiledManyToManyAugmentationDispather(
            TranspiledAugmentationSequential(
                TranspiledColorJiggle(0.1, 0.1, 0.1, 0.1, p=1.0),
                TranspiledRandomAffine(360, p=1.0),
                data_keys=["input", "mask",],
            ),
            TranspiledAugmentationSequential(
                TranspiledColorJiggle(0.1, 0.1, 0.1, 0.1, p=1.0),
                TranspiledRandomAffine(360, p=1.0),
                data_keys=["input", "mask",],
            )
        )
    
        torch_args = (
            (torch.randn(2, 3, 5, 6), torch.ones(2, 3, 5, 6)),
            (torch.randn(2, 3, 5, 6), torch.ones(2, 3, 5, 6)),
        )
        torch_out = torch_aug_list(*torch_args)
    
        transpiled_args = _nest_torch_tensor_to_new_framework(torch_args, target_framework)
>       transpiled_out = transpiled_aug_list(*transpiled_args)

kornia/augmentation/test_container.py:134: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_ManyToManyAugmentationDispather()
args = ((<tf.Tensor: shape=(2, 3, 5, 6), dtype=float32, numpy=
array([[[[ 0.2208748 ,  0.15485705, -1.9144698 , -1.1971275 ,
...   [1., 1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1., 1.]]]], dtype=float32)>))
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x7f33ba794e40, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...ode_context=['        return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_ManyToManyAugmentationDispather(), (<tf.Tensor: shape=(2, 3, 5, 6), dtype=float32, numpy=
array([[[[ 0.220...   [1., 1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1., 1.]]]], dtype=float32)>))
kwargs = {}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_ManyToManyAugmentationDispather(), v = None, buffers = None
args = ((<tf.Tensor: shape=(2, 3, 5, 6), dtype=float32, numpy=
array([[[[ 0.2208748 ,  0.15485705, -1.9144698 , -1.1971275 ,
...   [1., 1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1., 1.]]]], dtype=float32)>))
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:2013: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_ManyToManyAugmentationDispather(), (<tf.Tensor: shape=(2, 3, 5, 6), dtype=float32, numpy=
array([[[[ 0.220...   [1., 1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1., 1.]]]], dtype=float32)>))
kwargs = {'buffers': None, 'v': None}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_ManyToManyAugmentationDispather(), v = None, buffers = None
args = ((<tf.Tensor: shape=(2, 3, 5, 6), dtype=float32, numpy=
array([[[[ 0.2208748 ,  0.15485705, -1.9144698 , -1.1971275 ,
...   [1., 1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1., 1.]]]], dtype=float32)>))
kwargs = {}
first_arr = <tf.Tensor: shape=(2, 3, 5, 6), dtype=float32, numpy=
array([[[[ 0.2208748 ,  0.15485705, -1.9144698 , -1.1971275 ,
  ...,
         [-0.06163028, -0.14722805,  1.7892895 , -1.5435112 ,
           1.0175384 , -1.8252003 ]]]], dtype=float32)>
replace_v = False, replace_buffers = False, call_signature = <Signature (*input)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Model, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Model, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Model, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1783: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_ManyToManyAugmentationDispather(),)
kwargs = {'input': (<tf.Tensor: shape=(2, 3, 5, 6), dtype=float32, numpy=
array([[[[ 0.2208748 ,  0.15485705, -1.9144698 , -1.1...   [1., 1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1., 1.]]]], dtype=float32)>)}

    @wraps(fn)
    def error_handler(*args, **kwargs):
        if not is_traceback_filtering_enabled():
            return fn(*args, **kwargs)
    
        filtered_tb = None
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            filtered_tb = _process_traceback_frames(e.__traceback__)
            # To get the full stack trace, call:
            # `keras.config.disable_traceback_filtering()`
>           raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/keras/src/utils/traceback_utils.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <Signature (*input)>, args = ()
kwargs = {'input': (<tf.Tensor: shape=(2, 3, 5, 6), dtype=float32, numpy=
array([[[[ 0.2208748 ,  0.15485705, -1.9144698 , -1.1...   [1., 1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1., 1.]]]], dtype=float32)>)}

    def bind(self, /, *args, **kwargs):
        """Get a BoundArguments object, that maps the passed `args`
        and `kwargs` to the function's signature.  Raises `TypeError`
        if the passed arguments can not be bound.
        """
>       return self._bind(args, kwargs)

/opt/miniconda/envs/multienv/lib/python3.10/inspect.py:3177: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <Signature (*input)>, args = ()
kwargs = {'input': (<tf.Tensor: shape=(2, 3, 5, 6), dtype=float32, numpy=
array([[[[ 0.2208748 ,  0.15485705, -1.9144698 , -1.1...   [1., 1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1., 1.]]]], dtype=float32)>)}

    def _bind(self, args, kwargs, *, partial=False):
        """Private method. Don't use directly."""
    
        arguments = {}
    
        parameters = iter(self.parameters.values())
        parameters_ex = ()
        arg_vals = iter(args)
    
        while True:
            # Let's iterate through the positional arguments and corresponding
            # parameters
            try:
                arg_val = next(arg_vals)
            except StopIteration:
                # No more positional arguments
                try:
                    param = next(parameters)
                except StopIteration:
                    # No more parameters. That's it. Just need to check that
                    # we have no `kwargs` after this while loop
                    break
                else:
                    if param.kind == _VAR_POSITIONAL:
                        # That's OK, just empty *args.  Let's start parsing
                        # kwargs
                        break
                    elif param.name in kwargs:
                        if param.kind == _POSITIONAL_ONLY:
                            msg = '{arg!r} parameter is positional only, ' \
                                  'but was passed as a keyword'
                            msg = msg.format(arg=param.name)
                            raise TypeError(msg) from None
                        parameters_ex = (param,)
                        break
                    elif (param.kind == _VAR_KEYWORD or
                                                param.default is not _empty):
                        # That's fine too - we have a default value for this
                        # parameter.  So, lets start parsing `kwargs`, starting
                        # with the current parameter
                        parameters_ex = (param,)
                        break
                    else:
                        # No default, not VAR_KEYWORD, not VAR_POSITIONAL,
                        # not in `kwargs`
                        if partial:
                            parameters_ex = (param,)
                            break
                        else:
                            msg = 'missing a required argument: {arg!r}'
                            msg = msg.format(arg=param.name)
                            raise TypeError(msg) from None
            else:
                # We have a positional argument to process
                try:
                    param = next(parameters)
                except StopIteration:
                    raise TypeError('too many positional arguments') from None
                else:
                    if param.kind in (_VAR_KEYWORD, _KEYWORD_ONLY):
                        # Looks like we have no parameter for this positional
                        # argument
                        raise TypeError(
                            'too many positional arguments') from None
    
                    if param.kind == _VAR_POSITIONAL:
                        # We have an '*args'-like argument, let's fill it with
                        # all positional arguments we have left and move on to
                        # the next phase
                        values = [arg_val]
                        values.extend(arg_vals)
                        arguments[param.name] = tuple(values)
                        break
    
                    if param.name in kwargs and param.kind != _POSITIONAL_ONLY:
                        raise TypeError(
                            'multiple values for argument {arg!r}'.format(
                                arg=param.name)) from None
    
                    arguments[param.name] = arg_val
    
        # Now, we iterate through the remaining parameters to process
        # keyword arguments
        kwargs_param = None
        for param in itertools.chain(parameters_ex, parameters):
            if param.kind == _VAR_KEYWORD:
                # Memorize that we have a '**kwargs'-like parameter
                kwargs_param = param
                continue
    
            if param.kind == _VAR_POSITIONAL:
                # Named arguments don't refer to '*args'-like parameters.
                # We only arrive here if the positional arguments ended
                # before reaching the last parameter before *args.
                continue
    
            param_name = param.name
            try:
                arg_val = kwargs.pop(param_name)
            except KeyError:
                # We have no value for this parameter.  It's fine though,
                # if it has a default value, or it is an '*args'-like
                # parameter, left alone by the processing of positional
                # arguments.
                if (not partial and param.kind != _VAR_POSITIONAL and
                                                    param.default is _empty):
                    raise TypeError('missing a required argument: {arg!r}'. \
                                    format(arg=param_name)) from None
    
            else:
                if param.kind == _POSITIONAL_ONLY:
                    # This should never happen in case of a properly built
                    # Signature object (but let's have this check here
                    # to ensure correct behaviour just in case)
                    raise TypeError('{arg!r} parameter is positional only, '
                                    'but was passed as a keyword'. \
                                    format(arg=param.name))
    
                arguments[param_name] = arg_val
    
        if kwargs:
            if kwargs_param is not None:
                # Process our '**kwargs'-like parameter
                arguments[kwargs_param.name] = kwargs
            else:
>               raise TypeError(
                    'got an unexpected keyword argument {arg!r}'.format(
                        arg=next(iter(kwargs))))
E               TypeError: got an unexpected keyword argument 'input'

/opt/miniconda/envs/multienv/lib/python3.10/inspect.py:3166: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.container.ManyToManyAugmentationDispather
______________________________________________________________________ test_ManyToOneAugmentationDispather[tensorflow-s2s-False] _______________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_ManyToOneAugmentationDispather(target_framework, mode, backend_compile):
        print("kornia.augmentation.container.ManyToOneAugmentationDispather")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledManyToOneAugmentationDispather = ivy.transpile(
            kornia.augmentation.container.ManyToOneAugmentationDispather,
            source="torch",
            target=target_framework,
        )
        TranspiledAugmentationSequential = ivy.transpile(
            kornia.augmentation.container.AugmentationSequential,
            source="torch",
            target=target_framework,
        )
        TranspiledColorJiggle = ivy.transpile(
            kornia.augmentation.ColorJiggle,
            source="torch",
            target=target_framework,
        )
        TranspiledRandomAffine = ivy.transpile(
            kornia.augmentation.RandomAffine,
            source="torch",
            target=target_framework,
        )
    
        torch_aug_list = kornia.augmentation.container.ManyToOneAugmentationDispather(
            kornia.augmentation.container.AugmentationSequential(
                kornia.augmentation.ColorJiggle(0.1, 0.1, 0.1, 0.1, p=1.0),
                kornia.augmentation.RandomAffine(360, p=1.0),
                data_keys=["input", "mask",],
            ),
            kornia.augmentation.container.AugmentationSequential(
                kornia.augmentation.ColorJiggle(0.1, 0.1, 0.1, 0.1, p=1.0),
                kornia.augmentation.RandomAffine(360, p=1.0),
                data_keys=["input", "mask",],
            )
        )
        transpiled_aug_list = TranspiledManyToOneAugmentationDispather(
            TranspiledAugmentationSequential(
                TranspiledColorJiggle(0.1, 0.1, 0.1, 0.1, p=1.0),
                TranspiledRandomAffine(360, p=1.0),
                data_keys=["input", "mask",],
            ),
            TranspiledAugmentationSequential(
                TranspiledColorJiggle(0.1, 0.1, 0.1, 0.1, p=1.0),
                TranspiledRandomAffine(360, p=1.0),
                data_keys=["input", "mask",],
            )
        )
    
        torch_args = (
            torch.randn(2, 3, 5, 6),
            torch.ones(2, 3, 5, 6),
        )
        torch_out = torch_aug_list(*torch_args)
    
        transpiled_args = _nest_torch_tensor_to_new_framework(torch_args, target_framework)
>       transpiled_out = transpiled_aug_list(*transpiled_args)

kornia/augmentation/test_container.py:200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_ManyToOneAugmentationDispather()
args = (<tf.Tensor: shape=(2, 3, 5, 6), dtype=float32, numpy=
array([[[[ 4.9511915e-01,  1.8549737e+00, -1.1425526e+00,
     ...    [1., 1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1., 1.]]]], dtype=float32)>)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x7f33d3056040, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...ode_context=['        return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_ManyToOneAugmentationDispather(), <tf.Tensor: shape=(2, 3, 5, 6), dtype=float32, numpy=
array([[[[ 4.95119...    [1., 1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1., 1.]]]], dtype=float32)>)
kwargs = {}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_ManyToOneAugmentationDispather(), v = None, buffers = None
args = (<tf.Tensor: shape=(2, 3, 5, 6), dtype=float32, numpy=
array([[[[ 4.9511915e-01,  1.8549737e+00, -1.1425526e+00,
     ...    [1., 1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1., 1.]]]], dtype=float32)>)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:2013: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_ManyToOneAugmentationDispather(), <tf.Tensor: shape=(2, 3, 5, 6), dtype=float32, numpy=
array([[[[ 4.95119...    [1., 1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1., 1.]]]], dtype=float32)>)
kwargs = {'buffers': None, 'v': None}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_ManyToOneAugmentationDispather(), v = None, buffers = None
args = (<tf.Tensor: shape=(2, 3, 5, 6), dtype=float32, numpy=
array([[[[ 4.9511915e-01,  1.8549737e+00, -1.1425526e+00,
     ...    [1., 1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1., 1.]]]], dtype=float32)>)
kwargs = {}
first_arr = <tf.Tensor: shape=(2, 3, 5, 6), dtype=float32, numpy=
array([[[[ 4.9511915e-01,  1.8549737e+00, -1.1425526e+00,
      ...01, -2.7776670e-01,  2.7913934e-01,
           6.2200022e-01, -3.1332797e-01, -1.9622728e+00]]]],
      dtype=float32)>
replace_v = False, replace_buffers = False, call_signature = <Signature (*input)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Model, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Model, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Model, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1783: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_ManyToOneAugmentationDispather(),)
kwargs = {'input': <tf.Tensor: shape=(2, 3, 5, 6), dtype=float32, numpy=
array([[[[ 4.9511915e-01,  1.8549737e+00, -1.1425526e+...1, -2.7776670e-01,  2.7913934e-01,
           6.2200022e-01, -3.1332797e-01, -1.9622728e+00]]]],
      dtype=float32)>}

    @wraps(fn)
    def error_handler(*args, **kwargs):
        if not is_traceback_filtering_enabled():
            return fn(*args, **kwargs)
    
        filtered_tb = None
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            filtered_tb = _process_traceback_frames(e.__traceback__)
            # To get the full stack trace, call:
            # `keras.config.disable_traceback_filtering()`
>           raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/keras/src/utils/traceback_utils.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <Signature (*input)>, args = ()
kwargs = {'input': <tf.Tensor: shape=(2, 3, 5, 6), dtype=float32, numpy=
array([[[[ 4.9511915e-01,  1.8549737e+00, -1.1425526e+...1, -2.7776670e-01,  2.7913934e-01,
           6.2200022e-01, -3.1332797e-01, -1.9622728e+00]]]],
      dtype=float32)>}

    def bind(self, /, *args, **kwargs):
        """Get a BoundArguments object, that maps the passed `args`
        and `kwargs` to the function's signature.  Raises `TypeError`
        if the passed arguments can not be bound.
        """
>       return self._bind(args, kwargs)

/opt/miniconda/envs/multienv/lib/python3.10/inspect.py:3177: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <Signature (*input)>, args = ()
kwargs = {'input': <tf.Tensor: shape=(2, 3, 5, 6), dtype=float32, numpy=
array([[[[ 4.9511915e-01,  1.8549737e+00, -1.1425526e+...1, -2.7776670e-01,  2.7913934e-01,
           6.2200022e-01, -3.1332797e-01, -1.9622728e+00]]]],
      dtype=float32)>}

    def _bind(self, args, kwargs, *, partial=False):
        """Private method. Don't use directly."""
    
        arguments = {}
    
        parameters = iter(self.parameters.values())
        parameters_ex = ()
        arg_vals = iter(args)
    
        while True:
            # Let's iterate through the positional arguments and corresponding
            # parameters
            try:
                arg_val = next(arg_vals)
            except StopIteration:
                # No more positional arguments
                try:
                    param = next(parameters)
                except StopIteration:
                    # No more parameters. That's it. Just need to check that
                    # we have no `kwargs` after this while loop
                    break
                else:
                    if param.kind == _VAR_POSITIONAL:
                        # That's OK, just empty *args.  Let's start parsing
                        # kwargs
                        break
                    elif param.name in kwargs:
                        if param.kind == _POSITIONAL_ONLY:
                            msg = '{arg!r} parameter is positional only, ' \
                                  'but was passed as a keyword'
                            msg = msg.format(arg=param.name)
                            raise TypeError(msg) from None
                        parameters_ex = (param,)
                        break
                    elif (param.kind == _VAR_KEYWORD or
                                                param.default is not _empty):
                        # That's fine too - we have a default value for this
                        # parameter.  So, lets start parsing `kwargs`, starting
                        # with the current parameter
                        parameters_ex = (param,)
                        break
                    else:
                        # No default, not VAR_KEYWORD, not VAR_POSITIONAL,
                        # not in `kwargs`
                        if partial:
                            parameters_ex = (param,)
                            break
                        else:
                            msg = 'missing a required argument: {arg!r}'
                            msg = msg.format(arg=param.name)
                            raise TypeError(msg) from None
            else:
                # We have a positional argument to process
                try:
                    param = next(parameters)
                except StopIteration:
                    raise TypeError('too many positional arguments') from None
                else:
                    if param.kind in (_VAR_KEYWORD, _KEYWORD_ONLY):
                        # Looks like we have no parameter for this positional
                        # argument
                        raise TypeError(
                            'too many positional arguments') from None
    
                    if param.kind == _VAR_POSITIONAL:
                        # We have an '*args'-like argument, let's fill it with
                        # all positional arguments we have left and move on to
                        # the next phase
                        values = [arg_val]
                        values.extend(arg_vals)
                        arguments[param.name] = tuple(values)
                        break
    
                    if param.name in kwargs and param.kind != _POSITIONAL_ONLY:
                        raise TypeError(
                            'multiple values for argument {arg!r}'.format(
                                arg=param.name)) from None
    
                    arguments[param.name] = arg_val
    
        # Now, we iterate through the remaining parameters to process
        # keyword arguments
        kwargs_param = None
        for param in itertools.chain(parameters_ex, parameters):
            if param.kind == _VAR_KEYWORD:
                # Memorize that we have a '**kwargs'-like parameter
                kwargs_param = param
                continue
    
            if param.kind == _VAR_POSITIONAL:
                # Named arguments don't refer to '*args'-like parameters.
                # We only arrive here if the positional arguments ended
                # before reaching the last parameter before *args.
                continue
    
            param_name = param.name
            try:
                arg_val = kwargs.pop(param_name)
            except KeyError:
                # We have no value for this parameter.  It's fine though,
                # if it has a default value, or it is an '*args'-like
                # parameter, left alone by the processing of positional
                # arguments.
                if (not partial and param.kind != _VAR_POSITIONAL and
                                                    param.default is _empty):
                    raise TypeError('missing a required argument: {arg!r}'. \
                                    format(arg=param_name)) from None
    
            else:
                if param.kind == _POSITIONAL_ONLY:
                    # This should never happen in case of a properly built
                    # Signature object (but let's have this check here
                    # to ensure correct behaviour just in case)
                    raise TypeError('{arg!r} parameter is positional only, '
                                    'but was passed as a keyword'. \
                                    format(arg=param.name))
    
                arguments[param_name] = arg_val
    
        if kwargs:
            if kwargs_param is not None:
                # Process our '**kwargs'-like parameter
                arguments[kwargs_param.name] = kwargs
            else:
>               raise TypeError(
                    'got an unexpected keyword argument {arg!r}'.format(
                        arg=next(iter(kwargs))))
E               TypeError: got an unexpected keyword argument 'input'

/opt/miniconda/envs/multienv/lib/python3.10/inspect.py:3166: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.container.ManyToOneAugmentationDispather
______________________________________________________________________________ test_ImageSequential[tensorflow-s2s-False] ______________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_ImageSequential(target_framework, mode, backend_compile):
        print("kornia.augmentation.container.ImageSequential")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledImageSequential = ivy.transpile(
            kornia.augmentation.container.ImageSequential,
            source="torch",
            target=target_framework,
        )
        TranspiledColorJiggle = ivy.transpile(
            kornia.augmentation.ColorJiggle,
            source="torch",
            target=target_framework,
        )
        TranspiledRandomAffine = ivy.transpile(
            kornia.augmentation.RandomAffine,
            source="torch",
            target=target_framework,
        )
        TranspiledBgrToRgb = ivy.transpile(
            kornia.color.BgrToRgb,
            source="torch",
            target=target_framework,
        )
        TranspiledMedianBlur = ivy.transpile(
            kornia.filters.MedianBlur,
            source="torch",
            target=target_framework,
        )
        TranspiledInvert = ivy.transpile(
            kornia.enhance.Invert,
            source="torch",
            target=target_framework,
        )
        TranspiledRandomMixUpV2 = ivy.transpile(
            kornia.augmentation.RandomMixUpV2,
            source="torch",
            target=target_framework,
        )
    
        torch_aug_list = kornia.augmentation.container.ImageSequential(
            kornia.color.BgrToRgb(),
            kornia.augmentation.ColorJiggle(0.1, 0.1, 0.1, 0.1, p=1.0),
            kornia.filters.MedianBlur((3, 3)),
            kornia.augmentation.RandomAffine(360, p=1.0),
            kornia.enhance.Invert(),
            kornia.augmentation.RandomMixUpV2(p=1.0),
            same_on_batch=True,
            random_apply=10,
        )
        transpiled_aug_list = TranspiledImageSequential(
            TranspiledBgrToRgb(),
>           TranspiledColorJiggle(0.1, 0.1, 0.1, 0.1, p=1.0),
            TranspiledMedianBlur((3, 3)),
            TranspiledRandomAffine(360, p=1.0),
            TranspiledInvert(),
            TranspiledRandomMixUpV2(p=1.0),
            same_on_batch=True,
            random_apply=10,
        )

kornia/augmentation/test_container.py:261: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'tensorflow_ColorJiggle' object has no attribute 'p'") raised in repr()] tensorflow_ColorJiggle object at 0x7f33b8260820>, args = (0.1, 0.1, 0.1, 0.1), kwargs = {'p': 1.0}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'tensorflow_ColorJiggle' object has no attribute 'p'") raised in repr()] tensorflow_ColorJiggle object at 0x7f33b8260820>, brightness = 0.1, contrast = 0.1, saturation = 0.1
hue = 0.1, same_on_batch = False, p = 1.0, keepdim = False

>   ???
E   ModuleNotFoundError: No module named 'ivy_transpiled_outputs.tensorflow_outputs.kornia.augmentation.random_generator._2d.color_jiggle'

/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/_2d/intensity/color_jiggle.py:46: ModuleNotFoundError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.container.ImageSequential
______________________________________________________________________________ test_VideoSequential[tensorflow-s2s-False] ______________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_VideoSequential(target_framework, mode, backend_compile):
        print("kornia.augmentation.container.VideoSequential")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledVideoSequential = ivy.transpile(
            kornia.augmentation.container.VideoSequential,
            source="torch",
            target=target_framework,
        )
        TranspiledColorJiggle = ivy.transpile(
            kornia.augmentation.ColorJiggle,
            source="torch",
            target=target_framework,
        )
        TranspiledRandomAffine = ivy.transpile(
            kornia.augmentation.RandomAffine,
            source="torch",
            target=target_framework,
        )
        TranspiledBgrToRgb = ivy.transpile(
            kornia.color.BgrToRgb,
            source="torch",
            target=target_framework,
        )
    
        torch_aug_list = kornia.augmentation.container.VideoSequential(
            kornia.augmentation.ColorJiggle(0.1, 0.1, 0.1, 0.1, p=1.0),
            kornia.color.BgrToRgb(),
            kornia.augmentation.RandomAffine(360, p=1.0),
            random_apply=10,
            data_format="BCTHW",
            same_on_frame=True
        )
        transpiled_aug_list =  TranspiledVideoSequential(
>           TranspiledColorJiggle(0.1, 0.1, 0.1, 0.1, p=1.0),
            TranspiledBgrToRgb(),
            TranspiledRandomAffine(360, p=1.0),
            random_apply=10,
            data_format="BCTHW",
            same_on_frame=True
        )

kornia/augmentation/test_container.py:406: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[ModuleNotFoundError("No module named 'ivy_transpiled_outputs.tensorflow_outputs.kornia.augmentation'") raised in repr()] tensorflow_ColorJiggle object at 0x7f33b2c08340>
args = (0.1, 0.1, 0.1, 0.1), kwargs = {'p': 1.0}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[ModuleNotFoundError("No module named 'ivy_transpiled_outputs.tensorflow_outputs.kornia.augmentation'") raised in repr()] tensorflow_ColorJiggle object at 0x7f33b2c08340>, brightness = 0.1
contrast = 0.1, saturation = 0.1, hue = 0.1, same_on_batch = False, p = 1.0, keepdim = False

>   ???
E   ModuleNotFoundError: No module named 'ivy_transpiled_outputs.tensorflow_outputs.kornia.augmentation'

/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/_2d/intensity/color_jiggle.py:46: ModuleNotFoundError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.container.VideoSequential
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/augmentation/test_container.py::test_AugmentationSequential[tensorflow-s2s-False] - TypeError: got an unexpected keyword argument 'args'
FAILED kornia/augmentation/test_container.py::test_ManyToManyAugmentationDispather[tensorflow-s2s-False] - TypeError: got an unexpected keyword argument 'input'
FAILED kornia/augmentation/test_container.py::test_ManyToOneAugmentationDispather[tensorflow-s2s-False] - TypeError: got an unexpected keyword argument 'input'
FAILED kornia/augmentation/test_container.py::test_ImageSequential[tensorflow-s2s-False] - ModuleNotFoundError: No module named 'ivy_transpiled_outputs.tensorflow_outputs.kornia.augmentation.random...
FAILED kornia/augmentation/test_container.py::test_VideoSequential[tensorflow-s2s-False] - ModuleNotFoundError: No module named 'ivy_transpiled_outputs.tensorflow_outputs.kornia.augmentation'
=============================================================================== 5 failed, 1 passed in 2410.99s (0:40:10) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 10 items

kornia/test_feature5.py ssssssssss                                                                                                                                                               [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
========================================================================================= 10 skipped in 4.97s ==========================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 2 items

kornia/geometry/test_boxes.py FF                                                                                                                                                                 [100%]

=============================================================================================== FAILURES ===============================================================================================
______________________________________________________________________________________ test_Boxes[jax-s2s-False] _______________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_Boxes(target_framework, mode, backend_compile):
        print("kornia.geometry.boxes.Boxes")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledBoxes = ivy.transpile(kornia.geometry.boxes.Boxes, source="torch", target=target_framework)
    
        torch_args = (
            torch.as_tensor([[0, 3, 1, 4], [5, 1, 8, 4]]),
        )
        transpiled_args = _nest_torch_tensor_to_new_framework(torch_args, target_framework)
    
        # test .from_tensor
        torch_boxes = kornia.geometry.boxes.Boxes.from_tensor(*torch_args, mode="xyxy")
        transpiled_boxes = TranspiledBoxes.from_tensor(*transpiled_args, mode="xyxy")
        _check_boxes_same(torch_boxes, transpiled_boxes)
    
        # test .compute_area
        torch_area = torch_boxes.compute_area()
        transpiled_area = transpiled_boxes.compute_area()
        _to_numpy_and_allclose(torch_area, transpiled_area)
    
        # test .get_boxes_shape
        torch_heights, torch_widths = torch_boxes.get_boxes_shape()
        transpiled_heights, transpiled_widths = transpiled_boxes.get_boxes_shape()
        _to_numpy_and_allclose(torch_heights, transpiled_heights)
        _to_numpy_and_allclose(torch_widths, transpiled_widths)
    
        # test .merge
        torch_x = torch.as_tensor([[6, 6, 10, 10], [6, 6, 10, 10]])
        transpiled_x = _nest_torch_tensor_to_new_framework(torch_x, target_framework)
        merge_boxes = kornia.geometry.boxes.Boxes.from_tensor(torch_x, mode="xyxy")
        transpiled_merge_boxes = TranspiledBoxes.from_tensor(transpiled_x, mode="xyxy")
        torch_merged_boxes = torch_boxes.merge(merge_boxes)
        transpiled_merged_boxes = transpiled_boxes.merge(transpiled_merge_boxes)
        _check_boxes_same(torch_merged_boxes, transpiled_merged_boxes)
    
        # test .to_mask
        height, width = 10, 10
        torch_mask = torch_boxes.to_mask(height, width)
        transpiled_mask = transpiled_boxes.to_mask(height, width)
>       _to_numpy_and_allclose(torch_mask, transpiled_mask)

kornia/geometry/test_boxes.py:70: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

torch_x = tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0....., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]])
transpiled_x = Array([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0...],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]], dtype=float32)
tolerance = 0.001

    def _to_numpy_and_allclose(torch_x, transpiled_x, tolerance=1e-3):
        orig_data = _nest_array_to_numpy(torch_x)
        transpiled_data = _nest_array_to_numpy(transpiled_x)
>       _check_allclose(orig_data, transpiled_data, tolerance=tolerance)

helpers.py:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0...],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]], dtype=float32)
y = array([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0...],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]], dtype=float32)
tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
>           assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
E           AssertionError: numpy array values are not all close

helpers.py:26: AssertionError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.boxes.Boxes
_____________________________________________________________________________________ test_Boxes3D[jax-s2s-False] ______________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_Boxes3D(target_framework, mode, backend_compile):
        print("kornia.geometry.boxes.Boxes3D")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledBoxes3D = ivy.transpile(kornia.geometry.boxes.Boxes3D, source="torch", target=target_framework)
    
        torch_args = (
            torch.as_tensor([[0, 3, 6, 1, 4, 8], [5, 1, 3, 8, 4, 9]]),
        )
        transpiled_args = _nest_torch_tensor_to_new_framework(torch_args, target_framework)
    
        # test .from_tensor
        torch_boxes3d = kornia.geometry.boxes.Boxes3D.from_tensor(*torch_args, mode="xyzxyz")
        transpiled_boxes3d = TranspiledBoxes3D.from_tensor(*transpiled_args, mode="xyzxyz")
        _check_boxes_same(torch_boxes3d, transpiled_boxes3d)
    
        # test .get_boxes_shape
        torch_depths, torch_heights, torch_widths = torch_boxes3d.get_boxes_shape()
        transpiled_depths, transpiled_heights, transpiled_widths = transpiled_boxes3d.get_boxes_shape()
        _to_numpy_and_allclose(torch_depths, transpiled_depths)
        _to_numpy_and_allclose(torch_heights, transpiled_heights)
        _to_numpy_and_allclose(torch_widths, transpiled_widths)
    
        # test .to_mask
        depth, height, width = 10, 10, 10
        torch_mask = torch_boxes3d.to_mask(depth, height, width)
        transpiled_mask = transpiled_boxes3d.to_mask(depth, height, width)
>       _to_numpy_and_allclose(torch_mask, transpiled_mask)

kornia/geometry/test_boxes.py:121: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

torch_x = tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0... [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]]]])
transpiled_x = Array([[[[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]...0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]]]], dtype=float32)
tolerance = 0.001

    def _to_numpy_and_allclose(torch_x, transpiled_x, tolerance=1e-3):
        orig_data = _nest_array_to_numpy(torch_x)
        transpiled_data = _nest_array_to_numpy(transpiled_x)
>       _check_allclose(orig_data, transpiled_data, tolerance=tolerance)

helpers.py:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]...0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]]]], dtype=float32)
y = array([[[[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]...0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]]]], dtype=float32)
tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
>           assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
E           AssertionError: numpy array values are not all close

helpers.py:26: AssertionError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.boxes.Boxes3D
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/geometry/test_boxes.py::test_Boxes[jax-s2s-False] - AssertionError: numpy array values are not all close
FAILED kornia/geometry/test_boxes.py::test_Boxes3D[jax-s2s-False] - AssertionError: numpy array values are not all close
==================================================================================== 2 failed in 207.35s (0:03:27) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 35 items

kornia/test_losses.py .................FF..F.............                                                                                                                                        [100%]

=============================================================================================== FAILURES ===============================================================================================
______________________________________________________________________________ test_HausdorffERLoss[tensorflow-s2s-False] ______________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_HausdorffERLoss(target_framework, mode, backend_compile):
        print("kornia.losses.HausdorffERLoss")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledHausdorffERLoss = ivy.transpile(kornia.losses.HausdorffERLoss, source="torch", target=target_framework)
    
        torch_loss_fn = kornia.losses.HausdorffERLoss()
        transpiled_loss_fn = TranspiledHausdorffERLoss()
    
        torch_args = (
            torch.randn(5, 3, 20, 20),
            (torch.rand(5, 1, 20, 20) * 2).long(),
        )
        transpiled_args = _nest_torch_tensor_to_new_framework(torch_args, target_framework)
    
        torch_res = torch_loss_fn(*torch_args)
>       transpiled_res = transpiled_loss_fn(*transpiled_args)

kornia/test_losses.py:446: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_HausdorffERLoss()
args = (<tf.Tensor: shape=(5, 3, 20, 20), dtype=float32, numpy=
array([[[[ 1.1297827 ,  2.0200572 , -0.87468207, ..., -1.2730...        ...,
         [0, 0, 0, ..., 1, 1, 0],
         [0, 1, 0, ..., 1, 1, 1],
         [0, 1, 1, ..., 0, 1, 1]]]])>)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x7f7ba896b840, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...ode_context=['        return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_HausdorffERLoss(), <tf.Tensor: shape=(5, 3, 20, 20), dtype=float32, numpy=
array([[[[ 1.1297827 ,  2.02005...        ...,
         [0, 0, 0, ..., 1, 1, 0],
         [0, 1, 0, ..., 1, 1, 1],
         [0, 1, 1, ..., 0, 1, 1]]]])>)
kwargs = {}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_HausdorffERLoss(), v = None, buffers = None
args = (<tf.Tensor: shape=(5, 3, 20, 20), dtype=float32, numpy=
array([[[[ 1.1297827 ,  2.0200572 , -0.87468207, ..., -1.2730...        ...,
         [0, 0, 0, ..., 1, 1, 0],
         [0, 1, 0, ..., 1, 1, 1],
         [0, 1, 1, ..., 0, 1, 1]]]])>)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_HausdorffERLoss(), <tf.Tensor: shape=(5, 3, 20, 20), dtype=float32, numpy=
array([[[[ 1.1297827 ,  2.02005...        ...,
         [0, 0, 0, ..., 1, 1, 0],
         [0, 1, 0, ..., 1, 1, 1],
         [0, 1, 1, ..., 0, 1, 1]]]])>)
kwargs = {'buffers': None, 'v': None}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_HausdorffERLoss(), v = None, buffers = None
args = (<tf.Tensor: shape=(5, 3, 20, 20), dtype=float32, numpy=
array([[[[ 1.1297827 ,  2.0200572 , -0.87468207, ..., -1.2730...        ...,
         [0, 0, 0, ..., 1, 1, 0],
         [0, 1, 0, ..., 1, 1, 1],
         [0, 1, 1, ..., 0, 1, 1]]]])>)
kwargs = {}
first_arr = <tf.Tensor: shape=(5, 3, 20, 20), dtype=float32, numpy=
array([[[[ 1.1297827 ,  2.0200572 , -0.87468207, ..., -1.27304...      [-0.8798734 ,  1.6810176 , -0.10615742, ..., -0.8699981 ,
           0.04231958,  0.8190396 ]]]], dtype=float32)>
replace_v = False, replace_buffers = False, call_signature = <Signature (pred, target)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Layer, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Layer, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Layer, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_HausdorffERLoss(),)
kwargs = {'pred': <tf.Tensor: shape=(5, 3, 20, 20), dtype=float32, numpy=
array([[[[ 1.1297827 ,  2.0200572 , -0.87468207, ...,...        ...,
         [0, 0, 0, ..., 1, 1, 0],
         [0, 1, 0, ..., 1, 1, 1],
         [0, 1, 1, ..., 0, 1, 1]]]])>}

    @wraps(fn)
    def error_handler(*args, **kwargs):
        if not is_traceback_filtering_enabled():
            return fn(*args, **kwargs)
    
        filtered_tb = None
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            filtered_tb = _process_traceback_frames(e.__traceback__)
            # To get the full stack trace, call:
            # `keras.config.disable_traceback_filtering()`
>           raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/keras/src/utils/traceback_utils.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_HausdorffERLoss()
pred = <tf.Tensor: shape=(5, 3, 20, 20), dtype=float32, numpy=
array([[[[ 1.1297827 ,  2.0200572 , -0.87468207, ..., -1.27304...      [-0.8798734 ,  1.6810176 , -0.10615742, ..., -0.8699981 ,
           0.04231958,  0.8190396 ]]]], dtype=float32)>
target = <tf.Tensor: shape=(5, 1, 20, 20), dtype=int64, numpy=
array([[[[1, 0, 0, ..., 0, 0, 1],
         [1, 1, 0, ..., 1, 0, ...         ...,
         [0, 0, 0, ..., 1, 1, 0],
         [0, 1, 0, ..., 1, 1, 1],
         [0, 1, 1, ..., 0, 1, 1]]]])>

    def call(self, pred, target):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_dim_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_max_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_size_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_min_frnt_
    
        if tensorflow_dim_frnt_(pred) != 4:
            raise ValueError(
                f"Only 2D images supported. Got {tensorflow_dim_frnt_(pred)}."
            )
        if not (
            tensorflow_max_frnt_(target) < tensorflow_size_frnt_(pred, 1)
            and tensorflow_min_frnt_(target) >= 0
            and target.dtype == tf.int64
        ):
            raise ValueError(
                f"Expect long type target value in range (0, {tensorflow_size_frnt_(pred, 1)}). ({tensorflow_min_frnt_(target)}, {tensorflow_max_frnt_(target)})"
            )
>       return super().call(pred, target)

ivy_transpiled_outputs/tensorflow_outputs/kornia/losses/hausdorff.py:289: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_HausdorffERLoss()
pred = <tf.Tensor: shape=(5, 3, 20, 20), dtype=float32, numpy=
array([[[[ 1.1297827 ,  2.0200572 , -0.87468207, ..., -1.27304...      [-0.8798734 ,  1.6810176 , -0.10615742, ..., -0.8699981 ,
           0.04231958,  0.8190396 ]]]], dtype=float32)>
target = <tf.Tensor: shape=(5, 1, 20, 20), dtype=int64, numpy=
array([[[[1, 0, 0, ..., 0, 0, 1],
         [1, 1, 0, ..., 1, 0, ...         ...,
         [0, 0, 0, ..., 1, 1, 0],
         [0, 1, 0, ..., 1, 1, 1],
         [0, 1, 1, ..., 0, 1, 1]]]])>

    def call(self, pred, target):
        from ..core._backend import where
        from ..core._backend import stack
        from ..core._backend import tensor
        from ...ivy.functional.frontends.torch.tensor import tensorflow_size_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_item_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_max_frnt_
        from ...ivy.functional.backends.tensorflow.general import tensorflow_get_item
        from ...ivy.functional.frontends.torch.tensor import tensorflow_mean_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_sum_frnt_
    
        if not (
            tensorflow_shape_frnt_(pred)[2:] == tensorflow_shape_frnt_(target)[2:]
            and tensorflow_size_frnt_(pred, 0) == tensorflow_size_frnt_(target, 0)
            and tensorflow_size_frnt_(target, 1) == 1
        ):
            raise ValueError(
                f"Prediction and target need to be of same size, and target should not be one-hot.Got {tensorflow_shape_frnt_(pred)} and {tensorflow_shape_frnt_(target)}."
            )
        if tensorflow_size_frnt_(pred, 1) < tensorflow_item_frnt_(
            tensorflow_max_frnt_(target)
        ):
            raise ValueError("Invalid target value.")
        out = stack(
>           [
                self.perform_erosion(
                    tensorflow_get_item(
                        pred, (slice(None, None, None), slice(i, i + 1, None))
                    ),
                    where(
                        target == i,
                        tensor(1, device=target.device, dtype=target.dtype),
                        tensor(0, device=target.device, dtype=target.dtype),
                    ),
                )
                for i in range(tensorflow_size_frnt_(pred, 1))
            ]
        )

ivy_transpiled_outputs/tensorflow_outputs/kornia/losses/hausdorff.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

.0 = <range_iterator object at 0x7f7b94430270>

        [
>           self.perform_erosion(
                tensorflow_get_item(
                    pred, (slice(None, None, None), slice(i, i + 1, None))
                ),
                where(
                    target == i,
                    tensor(1, device=target.device, dtype=target.dtype),
                    tensor(0, device=target.device, dtype=target.dtype),
                ),
            )
            for i in range(tensorflow_size_frnt_(pred, 1))
        ]
    )

ivy_transpiled_outputs/tensorflow_outputs/kornia/losses/hausdorff.py:123: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_HausdorffERLoss()
pred = <tf.Tensor: shape=(5, 1, 20, 20), dtype=float32, numpy=
array([[[[ 1.1297827 ,  2.0200572 , -0.87468207, ..., -1.27304...      [ 0.48096836, -0.98334616,  1.7603835 , ..., -1.1842389 ,
          -1.0492873 ,  0.7770887 ]]]], dtype=float32)>
target = <tf.Tensor: shape=(5, 1, 20, 20), dtype=int64, numpy=
array([[[[0, 1, 1, ..., 1, 1, 0],
         [0, 0, 1, ..., 0, 1, ...         ...,
         [1, 1, 1, ..., 0, 0, 1],
         [1, 0, 1, ..., 0, 0, 0],
         [1, 0, 0, ..., 1, 0, 0]]]])>

    def perform_erosion(self, pred, target):
        from ..core._backend import as_tensor
        from ..core._backend import zeros_like
        from ..core._backend import where
        from ...ivy.functional.frontends.torch.creation_ops import (
            tensorflow_ones_like_v_0p4p0_and_above_frnt,
        )
        from ...ivy.functional.frontends.torch.tensor import tensorflow_size_frnt_
        from ...ivy.functional.backends.tensorflow.general import tensorflow_set_item
        from ...ivy.functional.frontends.torch.tensor import tensorflow_squeeze_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_any_frnt_
    
        bound = (pred - target) ** 2
        kernel = as_tensor(self.kernel, device=pred.device, dtype=pred.dtype)
        eroded = zeros_like(bound, device=pred.device, dtype=pred.dtype)
        mask = tensorflow_ones_like_v_0p4p0_and_above_frnt(
            bound, device=pred.device, dtype=tf.bool
        )
        padding = (tensorflow_size_frnt_(kernel, -1) - 1) // 2
        for k in range(self.k):
>           dilation = self.conv(bound, weight=kernel, padding=padding, groups=1)
E           TypeError: Exception encountered when calling tensorflow_HausdorffERLoss.call().
E           
E           [1mtensorflow_conv2d_frnt() got multiple values for argument 'weight'[0m
E           
E           Arguments received by tensorflow_HausdorffERLoss.call():
E              pred=tf.Tensor(shape=(5, 3, 20, 20), dtype=float32)
E              target=tf.Tensor(shape=(5, 1, 20, 20), dtype=int64)

ivy_transpiled_outputs/tensorflow_outputs/kornia/losses/hausdorff.py:83: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.losses.HausdorffERLoss
_____________________________________________________________________________ test_HausdorffERLoss3D[tensorflow-s2s-False] _____________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_HausdorffERLoss3D(target_framework, mode, backend_compile):
        print("kornia.losses.HausdorffERLoss3D")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledHausdorffERLoss3D = ivy.transpile(kornia.losses.HausdorffERLoss3D, source="torch", target=target_framework)
    
        torch_loss_fn = kornia.losses.HausdorffERLoss3D()
        transpiled_loss_fn = TranspiledHausdorffERLoss3D()
    
        torch_args = (
            torch.randn(5, 3, 20, 20, 20),
            (torch.rand(5, 1, 20, 20, 20) * 2).long(),
        )
        transpiled_args = _nest_torch_tensor_to_new_framework(torch_args, target_framework)
    
        torch_res = torch_loss_fn(*torch_args)
>       transpiled_res = transpiled_loss_fn(*transpiled_args)

kornia/test_losses.py:471: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_HausdorffERLoss3D()
args = (<tf.Tensor: shape=(5, 3, 20, 20, 20), dtype=float32, numpy=
array([[[[[-3.39913219e-02, -1.40809739e+00,  7.05253899e...    ...,
          [1, 1, 0, ..., 0, 0, 1],
          [0, 0, 1, ..., 1, 1, 1],
          [1, 1, 1, ..., 0, 1, 0]]]]])>)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x7f7b945a0b20, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...ode_context=['        return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_HausdorffERLoss3D(), <tf.Tensor: shape=(5, 3, 20, 20, 20), dtype=float32, numpy=
array([[[[[-3.39913219e-0...    ...,
          [1, 1, 0, ..., 0, 0, 1],
          [0, 0, 1, ..., 1, 1, 1],
          [1, 1, 1, ..., 0, 1, 0]]]]])>)
kwargs = {}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_HausdorffERLoss3D(), v = None, buffers = None
args = (<tf.Tensor: shape=(5, 3, 20, 20, 20), dtype=float32, numpy=
array([[[[[-3.39913219e-02, -1.40809739e+00,  7.05253899e...    ...,
          [1, 1, 0, ..., 0, 0, 1],
          [0, 0, 1, ..., 1, 1, 1],
          [1, 1, 1, ..., 0, 1, 0]]]]])>)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_HausdorffERLoss3D(), <tf.Tensor: shape=(5, 3, 20, 20, 20), dtype=float32, numpy=
array([[[[[-3.39913219e-0...    ...,
          [1, 1, 0, ..., 0, 0, 1],
          [0, 0, 1, ..., 1, 1, 1],
          [1, 1, 1, ..., 0, 1, 0]]]]])>)
kwargs = {'buffers': None, 'v': None}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_HausdorffERLoss3D(), v = None, buffers = None
args = (<tf.Tensor: shape=(5, 3, 20, 20, 20), dtype=float32, numpy=
array([[[[[-3.39913219e-02, -1.40809739e+00,  7.05253899e...    ...,
          [1, 1, 0, ..., 0, 0, 1],
          [0, 0, 1, ..., 1, 1, 1],
          [1, 1, 1, ..., 0, 1, 0]]]]])>)
kwargs = {}
first_arr = <tf.Tensor: shape=(5, 3, 20, 20, 20), dtype=float32, numpy=
array([[[[[-3.39913219e-02, -1.40809739e+00,  7.05253899e-...003e-01,  1.84787595e+00, ...,
           -1.18967152e+00, -3.75764698e-01, -2.48144045e-02]]]]],
      dtype=float32)>
replace_v = False, replace_buffers = False, call_signature = <Signature (pred, target)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Layer, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Layer, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Layer, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_HausdorffERLoss3D(),)
kwargs = {'pred': <tf.Tensor: shape=(5, 3, 20, 20, 20), dtype=float32, numpy=
array([[[[[-3.39913219e-02, -1.40809739e+00,  7.0...    ...,
          [1, 1, 0, ..., 0, 0, 1],
          [0, 0, 1, ..., 1, 1, 1],
          [1, 1, 1, ..., 0, 1, 0]]]]])>}

    @wraps(fn)
    def error_handler(*args, **kwargs):
        if not is_traceback_filtering_enabled():
            return fn(*args, **kwargs)
    
        filtered_tb = None
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            filtered_tb = _process_traceback_frames(e.__traceback__)
            # To get the full stack trace, call:
            # `keras.config.disable_traceback_filtering()`
>           raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/keras/src/utils/traceback_utils.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_HausdorffERLoss3D()
pred = <tf.Tensor: shape=(5, 3, 20, 20, 20), dtype=float32, numpy=
array([[[[[-3.39913219e-02, -1.40809739e+00,  7.05253899e-...003e-01,  1.84787595e+00, ...,
           -1.18967152e+00, -3.75764698e-01, -2.48144045e-02]]]]],
      dtype=float32)>
target = <tf.Tensor: shape=(5, 1, 20, 20, 20), dtype=int64, numpy=
array([[[[[0, 0, 0, ..., 1, 1, 1],
          [0, 1, 0, ..., ...     ...,
          [1, 1, 0, ..., 0, 0, 1],
          [0, 0, 1, ..., 1, 1, 1],
          [1, 1, 1, ..., 0, 1, 0]]]]])>

    def call(self, pred, target):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_dim_frnt_
    
        if tensorflow_dim_frnt_(pred) != 5:
            raise ValueError(
                f"Only 3D images supported. Got {tensorflow_dim_frnt_(pred)}."
            )
>       return super().call(pred, target)

ivy_transpiled_outputs/tensorflow_outputs/kornia/losses/hausdorff.py:280: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_HausdorffERLoss3D()
pred = <tf.Tensor: shape=(5, 3, 20, 20, 20), dtype=float32, numpy=
array([[[[[-3.39913219e-02, -1.40809739e+00,  7.05253899e-...003e-01,  1.84787595e+00, ...,
           -1.18967152e+00, -3.75764698e-01, -2.48144045e-02]]]]],
      dtype=float32)>
target = <tf.Tensor: shape=(5, 1, 20, 20, 20), dtype=int64, numpy=
array([[[[[0, 0, 0, ..., 1, 1, 1],
          [0, 1, 0, ..., ...     ...,
          [1, 1, 0, ..., 0, 0, 1],
          [0, 0, 1, ..., 1, 1, 1],
          [1, 1, 1, ..., 0, 1, 0]]]]])>

    def call(self, pred, target):
        from ..core._backend import where
        from ..core._backend import stack
        from ..core._backend import tensor
        from ...ivy.functional.frontends.torch.tensor import tensorflow_size_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_item_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_max_frnt_
        from ...ivy.functional.backends.tensorflow.general import tensorflow_get_item
        from ...ivy.functional.frontends.torch.tensor import tensorflow_mean_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_sum_frnt_
    
        if not (
            tensorflow_shape_frnt_(pred)[2:] == tensorflow_shape_frnt_(target)[2:]
            and tensorflow_size_frnt_(pred, 0) == tensorflow_size_frnt_(target, 0)
            and tensorflow_size_frnt_(target, 1) == 1
        ):
            raise ValueError(
                f"Prediction and target need to be of same size, and target should not be one-hot.Got {tensorflow_shape_frnt_(pred)} and {tensorflow_shape_frnt_(target)}."
            )
        if tensorflow_size_frnt_(pred, 1) < tensorflow_item_frnt_(
            tensorflow_max_frnt_(target)
        ):
            raise ValueError("Invalid target value.")
        out = stack(
>           [
                self.perform_erosion(
                    tensorflow_get_item(
                        pred, (slice(None, None, None), slice(i, i + 1, None))
                    ),
                    where(
                        target == i,
                        tensor(1, device=target.device, dtype=target.dtype),
                        tensor(0, device=target.device, dtype=target.dtype),
                    ),
                )
                for i in range(tensorflow_size_frnt_(pred, 1))
            ]
        )

ivy_transpiled_outputs/tensorflow_outputs/kornia/losses/hausdorff.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

.0 = <range_iterator object at 0x7f7b94ff09f0>

        [
>           self.perform_erosion(
                tensorflow_get_item(
                    pred, (slice(None, None, None), slice(i, i + 1, None))
                ),
                where(
                    target == i,
                    tensor(1, device=target.device, dtype=target.dtype),
                    tensor(0, device=target.device, dtype=target.dtype),
                ),
            )
            for i in range(tensorflow_size_frnt_(pred, 1))
        ]
    )

ivy_transpiled_outputs/tensorflow_outputs/kornia/losses/hausdorff.py:123: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_HausdorffERLoss3D()
pred = <tf.Tensor: shape=(5, 1, 20, 20, 20), dtype=float32, numpy=
array([[[[[-3.39913219e-02, -1.40809739e+00,  7.05253899e-...503e-01, -1.06652772e+00, ...,
           -1.70539951e+00,  9.03142691e-01,  1.03975445e-01]]]]],
      dtype=float32)>
target = <tf.Tensor: shape=(5, 1, 20, 20, 20), dtype=int64, numpy=
array([[[[[1, 1, 1, ..., 0, 0, 0],
          [1, 0, 1, ..., ...     ...,
          [0, 0, 1, ..., 1, 1, 0],
          [1, 1, 0, ..., 0, 0, 0],
          [0, 0, 0, ..., 1, 0, 1]]]]])>

    def perform_erosion(self, pred, target):
        from ..core._backend import as_tensor
        from ..core._backend import zeros_like
        from ..core._backend import where
        from ...ivy.functional.frontends.torch.creation_ops import (
            tensorflow_ones_like_v_0p4p0_and_above_frnt,
        )
        from ...ivy.functional.frontends.torch.tensor import tensorflow_size_frnt_
        from ...ivy.functional.backends.tensorflow.general import tensorflow_set_item
        from ...ivy.functional.frontends.torch.tensor import tensorflow_squeeze_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_any_frnt_
    
        bound = (pred - target) ** 2
        kernel = as_tensor(self.kernel, device=pred.device, dtype=pred.dtype)
        eroded = zeros_like(bound, device=pred.device, dtype=pred.dtype)
        mask = tensorflow_ones_like_v_0p4p0_and_above_frnt(
            bound, device=pred.device, dtype=tf.bool
        )
        padding = (tensorflow_size_frnt_(kernel, -1) - 1) // 2
        for k in range(self.k):
>           dilation = self.conv(bound, weight=kernel, padding=padding, groups=1)
E           TypeError: Exception encountered when calling tensorflow_HausdorffERLoss3D.call().
E           
E           [1mtensorflow_conv3d_frnt() got multiple values for argument 'weight'[0m
E           
E           Arguments received by tensorflow_HausdorffERLoss3D.call():
E              pred=tf.Tensor(shape=(5, 3, 20, 20, 20), dtype=float32)
E              target=tf.Tensor(shape=(5, 1, 20, 20, 20), dtype=int64)

ivy_transpiled_outputs/tensorflow_outputs/kornia/losses/hausdorff.py:83: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.losses.HausdorffERLoss3D
________________________________________________________________________________ test_MS_SSIMLoss[tensorflow-s2s-False] ________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_MS_SSIMLoss(target_framework, mode, backend_compile):
        print("kornia.losses.MS_SSIMLoss")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledMS_SSIMLoss = ivy.transpile(kornia.losses.MS_SSIMLoss, source="torch", target=target_framework)
    
        torch_loss_fn = kornia.losses.MS_SSIMLoss()
        transpiled_loss_fn = TranspiledMS_SSIMLoss()
    
        torch_args = (
            torch.rand(1, 3, 5, 5),
            torch.rand(1, 3, 5, 5),
        )
        transpiled_args = _nest_torch_tensor_to_new_framework(torch_args, target_framework)
    
        torch_res = torch_loss_fn(*torch_args)
>       transpiled_res = transpiled_loss_fn(*transpiled_args)

kornia/test_losses.py:546: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_MS_SSIMLoss()
args = (<tf.Tensor: shape=(1, 3, 5, 5), dtype=float32, numpy=
array([[[[9.15944040e-01, 8.89489710e-01, 6.76547229e-01,
     ...1],
         [3.7748528e-01, 3.1949621e-01, 5.5674976e-01, 1.0822457e-01,
          1.9907868e-01]]]], dtype=float32)>)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x55ee7616fc20, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...ode_context=['        return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_MS_SSIMLoss(), <tf.Tensor: shape=(1, 3, 5, 5), dtype=float32, numpy=
array([[[[9.15944040e-01, 8.89489710e...1],
         [3.7748528e-01, 3.1949621e-01, 5.5674976e-01, 1.0822457e-01,
          1.9907868e-01]]]], dtype=float32)>)
kwargs = {}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_MS_SSIMLoss(), v = None, buffers = None
args = (<tf.Tensor: shape=(1, 3, 5, 5), dtype=float32, numpy=
array([[[[9.15944040e-01, 8.89489710e-01, 6.76547229e-01,
     ...1],
         [3.7748528e-01, 3.1949621e-01, 5.5674976e-01, 1.0822457e-01,
          1.9907868e-01]]]], dtype=float32)>)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:2013: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_MS_SSIMLoss(), <tf.Tensor: shape=(1, 3, 5, 5), dtype=float32, numpy=
array([[[[9.15944040e-01, 8.89489710e...1],
         [3.7748528e-01, 3.1949621e-01, 5.5674976e-01, 1.0822457e-01,
          1.9907868e-01]]]], dtype=float32)>)
kwargs = {'buffers': None, 'v': None}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_MS_SSIMLoss(), v = None, buffers = None
args = (<tf.Tensor: shape=(1, 3, 5, 5), dtype=float32, numpy=
array([[[[9.15944040e-01, 8.89489710e-01, 6.76547229e-01,
     ...1],
         [3.7748528e-01, 3.1949621e-01, 5.5674976e-01, 1.0822457e-01,
          1.9907868e-01]]]], dtype=float32)>)
kwargs = {}
first_arr = <tf.Tensor: shape=(1, 3, 5, 5), dtype=float32, numpy=
array([[[[9.15944040e-01, 8.89489710e-01, 6.76547229e-01,
      ...         [1.05957985e-02, 1.29267573e-01, 4.44155931e-02,
          2.74549723e-01, 9.10100460e-01]]]], dtype=float32)>
replace_v = False, replace_buffers = False, call_signature = <Signature (img1, img2)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Model, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Model, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Model, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1783: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_MS_SSIMLoss(),)
kwargs = {'img1': <tf.Tensor: shape=(1, 3, 5, 5), dtype=float32, numpy=
array([[[[9.15944040e-01, 8.89489710e-01, 6.76547229e-0...1],
         [3.7748528e-01, 3.1949621e-01, 5.5674976e-01, 1.0822457e-01,
          1.9907868e-01]]]], dtype=float32)>}

    @wraps(fn)
    def error_handler(*args, **kwargs):
        if not is_traceback_filtering_enabled():
            return fn(*args, **kwargs)
    
        filtered_tb = None
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            filtered_tb = _process_traceback_frames(e.__traceback__)
            # To get the full stack trace, call:
            # `keras.config.disable_traceback_filtering()`
>           raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/keras/src/utils/traceback_utils.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_MS_SSIMLoss()
img1 = <tf.Tensor: shape=(1, 3, 5, 5), dtype=float32, numpy=
array([[[[9.15944040e-01, 8.89489710e-01, 6.76547229e-01,
      ...         [1.05957985e-02, 1.29267573e-01, 4.44155931e-02,
          2.74549723e-01, 9.10100460e-01]]]], dtype=float32)>
img2 = <tf.Tensor: shape=(1, 3, 5, 5), dtype=float32, numpy=
array([[[[9.8302048e-01, 4.6195555e-01, 4.4961256e-01, 5.3784245...01],
         [3.7748528e-01, 3.1949621e-01, 5.5674976e-01, 1.0822457e-01,
          1.9907868e-01]]]], dtype=float32)>

    def call(self, img1, img2):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ...ivy.functional.frontends.torch._jit_internal import (
            tensorflow_annotate_frnt,
        )
        from ...ivy.functional.frontends.torch.nn.functional.convolution_functions import (
            tensorflow_conv2d_frnt,
        )
        from ...ivy.functional.frontends.torch.tensor import tensorflow_prod_frnt_
        from ...ivy.functional.frontends.torch.nn.functional.loss_functions import (
            tensorflow_l1_loss_frnt,
        )
        from ...ivy.functional.frontends.torch.tensor import tensorflow_mean_frnt_
        from ...ivy.functional.backends.tensorflow.general import tensorflow_get_item
        from ...ivy.functional.frontends.torch.reduction_ops import tensorflow_mean_frnt
        from ...ivy.functional.frontends.torch.reduction_ops import tensorflow_sum_frnt
    
        if not isinstance(img1, (tensorflow.Tensor, tensorflow.Variable)):
            raise TypeError(f"Input type is not a torch.Tensor. Got {type(img1)}")
        if not isinstance(img2, (tensorflow.Tensor, tensorflow.Variable)):
            raise TypeError(f"Output type is not a torch.Tensor. Got {type(img2)}")
        if not len(tensorflow_shape_frnt_(img1)) == len(tensorflow_shape_frnt_(img2)):
            raise ValueError(
                f"Input shapes should be same. Got {type(img1)} and {type(img2)}."
            )
        g_masks: typing.Any = tensorflow_annotate_frnt(
            tensorflow.Variable, self._g_masks
        )
        CH: typing.Any = tensorflow_shape_frnt_(img1)[-3]
>       mux = tensorflow_conv2d_frnt(img1, g_masks, groups=CH, padding=self.pad)

ivy_transpiled_outputs/tensorflow_outputs/kornia/losses/ms_ssim.py:138: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = <tf.Tensor: shape=(1, 3, 5, 5), dtype=float32, numpy=
array([[[[9.15944040e-01, 8.89489710e-01, 6.76547229e-01,
      ...         [1.05957985e-02, 1.29267573e-01, 4.44155931e-02,
          2.74549723e-01, 9.10100460e-01]]]], dtype=float32)>
weight = <tf.Tensor: shape=(15, 1, 33, 33), dtype=float32, numpy=
array([[[[0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
 ...2472e-05, 6.2838459e-05, 7.8817087e-05, ...,
          7.8817087e-05, 6.2838459e-05, 4.9322472e-05]]]], dtype=float32)>
bias = None, stride = 1, padding = 16, dilation = 1, groups = 3

    def tensorflow_conv2d_frnt(
        input, weight, bias=None, stride=1, padding=0, dilation=1, groups=1
    ):
>       return tensorflow__conv_frnt(
            input,
            weight,
            bias=bias,
            stride=stride,
            padding=padding,
            dilation=dilation,
            groups=groups,
        )

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/nn/functional/convolution_functions.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = <tf.Tensor: shape=(1, 3, 5, 5), dtype=float32, numpy=
array([[[[9.15944040e-01, 8.89489710e-01, 6.76547229e-01,
      ...         [1.05957985e-02, 1.29267573e-01, 4.44155931e-02,
          2.74549723e-01, 9.10100460e-01]]]], dtype=float32)>
weight = <tf.Tensor: shape=(15, 1, 33, 33), dtype=float32, numpy=
array([[[[0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
 ...2472e-05, 6.2838459e-05, 7.8817087e-05, ...,
          7.8817087e-05, 6.2838459e-05, 4.9322472e-05]]]], dtype=float32)>
bias = None, stride = 1, padding = [(16, 16), (16, 16)], dilation = 1, groups = 3

    def tensorflow__conv_frnt(
        input, weight, bias=None, stride=1, padding=0, dilation=1, groups=1
    ):
        from ...tensor import tensorflow_shape_frnt_
        from .....backends.tensorflow.layers import tensorflow_conv_general_dilated
    
        dims = len(tensorflow_shape_frnt_(input)) - 2
        if isinstance(padding, (str,)):
            padding = padding.upper()
        elif isinstance(padding, (int,)):
            padding = [*[(padding, padding) for _ in range(dims)]]
        else:
            padding = [*[(p, p) for p in padding]]
>       ret = tensorflow_conv_general_dilated(
            input,
            weight,
            stride,
            padding,
            dims=dims,
            data_format="channel_last",
            filter_format="channel_last",
            dilations=dilation,
            feature_group_count=groups,
            bias=bias,
        )

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/nn/functional/convolution_functions.py:45: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (<tf.Tensor: shape=(1, 3, 5, 5), dtype=float32, numpy=
array([[[[9.15944040e-01, 8.89489710e-01, 6.76547229e-01,
     ....8817087e-05, ...,
          7.8817087e-05, 6.2838459e-05, 4.9322472e-05]]]], dtype=float32)>, 1, [(16, 16), (16, 16)])
kwargs = {'bias': None, 'data_format': 'channel_first', 'dilations': 1, 'dims': 2, ...}, tensorflow_set_item = <function tensorflow_set_item at 0x7f7b94ce9990>
tensorflow_get_item = <function tensorflow_get_item at 0x7f7b94ce97e0>, DATA_FORMAT = 'channels_first', value_map = {'NHWC': 'NCHW', 'NSC': 'NCS', 'channel_last': 'channel_first'}

    @functools.wraps(fn)
    def transpose_wrapper(*args, **kwargs):
        from ..functional.backends.tensorflow.general import tensorflow_set_item
        from ..functional.backends.tensorflow.general import tensorflow_get_item
    
        DATA_FORMAT = os.environ.get("DATA_FORMAT", "channels_first")
        if DATA_FORMAT == "channels_first":
            value_map = {"channel_last": "channel_first", "NHWC": "NCHW", "NSC": "NCS"}
            if "data_format" in kwargs and kwargs["data_format"] in value_map:
                kwargs = tensorflow_set_item(
                    kwargs,
                    "data_format",
                    tensorflow_get_item(value_map, kwargs["data_format"]),
                )
            if "filter_format" in kwargs and kwargs["filter_format"] in value_map:
                kwargs = tensorflow_set_item(
                    kwargs,
                    "filter_format",
                    tensorflow_get_item(value_map, kwargs["filter_format"]),
                )
            os.environ = tensorflow_set_item(os.environ, "DATA_FORMAT", "channels_last")
>       res = fn(*args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:460: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = [<tf.Tensor: shape=(1, 3, 5, 5), dtype=float32, numpy=
array([[[[9.15944040e-01, 8.89489710e-01, 6.76547229e-01,
     ....8817087e-05, ...,
          7.8817087e-05, 6.2838459e-05, 4.9322472e-05]]]], dtype=float32)>, 1, [(16, 16), (16, 16)]]
kwargs = {'bias': None, 'data_format': 'channel_first', 'dilations': 1, 'dims': 2, ...}, tensorflow_is_array_bknd = <function tensorflow_is_array_bknd at 0x7f7b94ca7520>
tensorflow_set_item = <function tensorflow_set_item at 0x7f7b94ce9990>, tensorflow_asarray = <function tensorflow_asarray at 0x7f7b94ce81f0>
tensorflow_get_item = <function tensorflow_get_item at 0x7f7b94ce97e0>, num_args = 4
type_hints = mappingproxy(OrderedDict([('x', <Parameter "x: Union[tensorflow.python.framework.tensor.Tensor, tensorflow.python.ops...."out: Union[tensorflow.python.framework.tensor.Tensor, tensorflow.python.ops.variables.Variable, NoneType] = None">)]))
parameters = ['x', 'filters', 'strides', 'padding', 'dims', 'data_format', ...]
annotations = [typing.Union[tensorflow.python.framework.tensor.Tensor, tensorflow.python.ops.variables.Variable], typing.Union[tenso...le[int, int, int]], typing.Union[str, int, typing.Sequence[typing.Tuple[int, int]]], <class 'int'>, <class 'str'>, ...]
device = '/job:localhost/replica:0/task:0/device:CPU:0', i = 3

    @functools.wraps(fn)
    def _handle_array_like_without_promotion(*args, **kwargs):
        from .functional.ivy.general import tensorflow_is_array_bknd
        from .functional.backends.tensorflow.general import tensorflow_set_item
        from .functional.backends.tensorflow.creation import tensorflow_asarray
        from .functional.backends.tensorflow.general import tensorflow_get_item
    
        args = list(args)
        num_args = len(args)
        try:
            type_hints = inspect.signature(fn).parameters
        except (TypeError, ValueError):
            return fn(*args, **kwargs)
        parameters = list(type_hints.keys())
        annotations = [param.annotation for param in type_hints.values()]
        device = tensorflow__get_preferred_device(args, kwargs)
        for i, (annotation, parameter, arg) in enumerate(
            zip(annotations, parameters, args)
        ):
            annotation_str = str(annotation)
            if (
                ("rray" in annotation_str or "Tensor" in annotation_str)
                and parameter != "out"
                and all(
                    sq not in annotation_str
                    for sq in ["Sequence", "List", "Tuple", "float", "int", "bool"]
                )
            ):
                if i < num_args:
                    if arg is None or tensorflow__check_in_nested_sequence(
                        arg, value=Ellipsis, _type=slice
                    ):
                        continue
                    if not tensorflow_is_array_bknd(arg):
                        args = tensorflow_set_item(
                            args, i, tensorflow_asarray(arg, device=device)
                        )
                elif parameters in kwargs:
                    kwarg = tensorflow_get_item(kwargs, parameter)
                    if not tensorflow_is_array_bknd(kwarg):
                        kwargs = tensorflow_set_item(
                            kwargs, parameter, tensorflow_asarray(kwarg, device=device)
                        )
>       return fn(*args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/func_wrapper.py:139: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = <tf.Tensor: shape=(1, 5, 5, 3), dtype=float32, numpy=
array([[[[9.15944040e-01, 6.34582996e-01, 7.67700434e-01],
     ...1, 8.87400687e-01, 2.74549723e-01],
         [1.87282920e-01, 9.49978113e-01, 9.10100460e-01]]]],
      dtype=float32)>
filters = <tf.Tensor: shape=(33, 33, 1, 15), dtype=float32, numpy=
array([[[[0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
 ...0000e+00, 0.0000000e+00, 0.0000000e+00, ...,
          4.9322472e-05, 4.9322472e-05, 4.9322472e-05]]]], dtype=float32)>
strides = 1, padding = [(16, 16), (16, 16)]

    @tensorflow_handle_transpose_in_input_and_output_for_functions
    @tensorflow_handle_array_like_without_promotion
    def tensorflow_conv_general_dilated(
        x: Union[tensorflow.Tensor, tensorflow.Variable],
        filters: Union[tensorflow.Tensor, tensorflow.Variable],
        strides: Union[int, Tuple[int], Tuple[int, int], Tuple[int, int, int]],
        padding: Union[str, int, Sequence[Tuple[int, int]]],
        /,
        *,
        dims: int = 2,
        data_format: str = "channel_last",
        filter_format: str = "channel_last",
        feature_group_count: int = 1,
        x_dilations: Union[int, Tuple[int], Tuple[int, int], Tuple[int, int, int]] = 1,
        dilations: Union[int, Tuple[int], Tuple[int, int], Tuple[int, int, int]] = 1,
        bias: Optional[Union[tensorflow.Tensor, tensorflow.Variable]] = None,
        out: Optional[Union[tensorflow.Tensor, tensorflow.Variable]] = None,
    ):
        from .device import tensorflow_dev
        from ...ivy.layers import tensorflow__get_x_data_format_bknd
    
        if filter_format == "channel_first":
            filters = tensorflow.transpose(filters, (*range(2, dims + 2), 1, 0))
        num_channels = x.shape[1] if data_format == "channel_first" else x.shape[-1]
        if filters.shape[-2] != num_channels // feature_group_count:
            raise Exception(
                f"given feature_group_count {feature_group_count} expected input channel of the filter to be {num_channels // feature_group_count} but got {filters.shape[-2]}"
            )
        if num_channels % feature_group_count != 0:
            raise Exception(
                f"input channel should be divisible by feature group count {feature_group_count} but got input channel {num_channels}"
            )
        permuted_x = False
        if data_format == "channel_first" and (
            tensorflow_dev(x) == "cpu" or feature_group_count != 1
        ):
            x = tensorflow.transpose(x, (0, *range(2, dims + 2), 1))
            data_format = "channel_last"
            permuted_x = True
        data_format = tensorflow__get_x_data_format_bknd(dims, data_format)
        x = tensorflow__x_dil_before_conv(x, dims, x_dilations, data_format)
        if dims == 2:
            padding = tensorflow__extend_2d_padding(padding, data_format)
            if feature_group_count == 1:
                res = tensorflow.nn.conv2d(
                    x,
                    filters,
                    strides,
                    padding,
                    data_format=data_format,
                    dilations=dilations,
                )
            else:
                if not isinstance(padding, str):
                    padding = padding[1:-1]
>               res = tensorflow_depthwise_conv2d(
                    x,
                    tensorflow.transpose(filters, (0, 1, 3, 2)),
                    strides,
                    padding,
                    data_format=data_format,
                    dilations=dilations,
                )

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/backends/tensorflow/layers.py:200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (<tf.Tensor: shape=(1, 5, 5, 3), dtype=float32, numpy=
array([[[[9.15944040e-01, 6.34582996e-01, 7.67700434e-01],
    ...      [4.9322472e-05],
         [4.9322472e-05],
         [4.9322472e-05]]]], dtype=float32)>, 1, [(16, 16), (16, 16)])
kwargs = {'data_format': 'NHWC', 'dilations': 1}, tensorflow_set_item = <function tensorflow_set_item at 0x7f7b94ce9990>, tensorflow_get_item = <function tensorflow_get_item at 0x7f7b94ce97e0>
DATA_FORMAT = 'channels_last'

    @functools.wraps(fn)
    def transpose_wrapper(*args, **kwargs):
        from ..functional.backends.tensorflow.general import tensorflow_set_item
        from ..functional.backends.tensorflow.general import tensorflow_get_item
    
        DATA_FORMAT = os.environ.get("DATA_FORMAT", "channels_first")
        if DATA_FORMAT == "channels_first":
            value_map = {"channel_last": "channel_first", "NHWC": "NCHW", "NSC": "NCS"}
            if "data_format" in kwargs and kwargs["data_format"] in value_map:
                kwargs = tensorflow_set_item(
                    kwargs,
                    "data_format",
                    tensorflow_get_item(value_map, kwargs["data_format"]),
                )
            if "filter_format" in kwargs and kwargs["filter_format"] in value_map:
                kwargs = tensorflow_set_item(
                    kwargs,
                    "filter_format",
                    tensorflow_get_item(value_map, kwargs["filter_format"]),
                )
            os.environ = tensorflow_set_item(os.environ, "DATA_FORMAT", "channels_last")
>       res = fn(*args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:460: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = <tf.Tensor: shape=(1, 5, 5, 3), dtype=float32, numpy=
array([[[[9.15944040e-01, 6.34582996e-01, 7.67700434e-01],
     ...1, 8.87400687e-01, 2.74549723e-01],
         [1.87282920e-01, 9.49978113e-01, 9.10100460e-01]]]],
      dtype=float32)>
filters = <tf.Tensor: shape=(33, 33, 15, 1), dtype=float32, numpy=
array([[[[0.0000000e+00],
         [0.0000000e+00],
         ...00e+00],
         ...,
         [4.9322472e-05],
         [4.9322472e-05],
         [4.9322472e-05]]]], dtype=float32)>
strides = [1, 1, 1, 1], padding = [(0, 0), (16, 16), (16, 16), (0, 0)]

    @tensorflow_handle_transpose_in_input_and_output_for_functions
    def tensorflow_depthwise_conv2d(
        x: Union[tensorflow.Tensor, tensorflow.Variable],
        filters: Union[tensorflow.Tensor, tensorflow.Variable],
        strides: Union[int, Tuple[int, int]],
        padding: Union[str, int, Sequence[Tuple[int, int]]],
        /,
        *,
        data_format: str = "NHWC",
        dilations: Union[int, Tuple[int, int]] = 1,
        out: Optional[Union[tensorflow.Tensor, tensorflow.Variable]] = None,
    ):
        from .device import tensorflow_dev
    
        strides = [strides] * 2 if isinstance(strides, int) else strides
        dilations = [dilations] * 2 if isinstance(dilations, int) else dilations
        permuted_x = False
        if data_format == "NCHW" and tensorflow_dev(x) == "cpu":
            x = tensorflow.transpose(x, (0, 2, 3, 1))
            data_format = "NHWC"
            permuted_x = True
        if tensorflow.rank(filters) == 3:
            filters = tensorflow.expand_dims(filters, -1)
        padding = tensorflow__extend_2d_padding(padding, data_format)
        strides = [1, strides[0], strides[1], 1]
>       res = tensorflow.nn.depthwise_conv2d(
            x, filters, strides, padding, data_format, dilations
        )
E       tensorflow.python.framework.errors_impl.InvalidArgumentError: Exception encountered when calling tensorflow_MS_SSIMLoss.call().
E       
E       [1m{{function_node __wrapped__DepthwiseConv2dNative_device_/job:localhost/replica:0/task:0/device:CPU:0}} input and filter must have the same depth: 3 vs 15 [Op:DepthwiseConv2dNative] name: [0m
E       
E       Arguments received by tensorflow_MS_SSIMLoss.call():
E          img1=tf.Tensor(shape=(1, 3, 5, 5), dtype=float32)
E          img2=tf.Tensor(shape=(1, 3, 5, 5), dtype=float32)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/backends/tensorflow/layers.py:137: InvalidArgumentError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.losses.MS_SSIMLoss
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/test_losses.py::test_HausdorffERLoss[tensorflow-s2s-False] - TypeError: Exception encountered when calling tensorflow_HausdorffERLoss.call().
FAILED kornia/test_losses.py::test_HausdorffERLoss3D[tensorflow-s2s-False] - TypeError: Exception encountered when calling tensorflow_HausdorffERLoss3D.call().
FAILED kornia/test_losses.py::test_MS_SSIMLoss[tensorflow-s2s-False] - tensorflow.python.framework.errors_impl.InvalidArgumentError: Exception encountered when calling tensorflow_MS_SSIMLoss.call().
============================================================================== 3 failed, 32 passed in 2322.57s (0:38:42) ===============================================================================


========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 16 items

kornia/augmentation/test_augmentation3.py ........FF...FFF                                                                                                                                       [100%]

=============================================================================================== FAILURES ===============================================================================================
_____________________________________________________________________________ test_RandomResizedCrop[tensorflow-s2s-False] _____________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_RandomResizedCrop(target_framework, mode, backend_compile):
        print("kornia.augmentation.RandomResizedCrop")
    
        init_args = ()
        init_kwargs = {"size": (3, 3), "scale": (3., 3.), "ratio": (2., 2.), "p": 1., "cropping_mode": "resample"}
        call_args = (torch.tensor([[[0., 1., 2.],
                                    [3., 4., 5.],
                                    [6., 7., 8.]]]),)
        call_kwargs = {}
    
>       _test_augmentation_class(
            kornia.augmentation.RandomResizedCrop,
            target_framework,
            init_args,
            init_kwargs,
            call_args,
            call_kwargs,
            deterministic_output=False,
            backend_compile=backend_compile,
        )

kornia/augmentation/test_augmentation3.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

augmentation_cls = <class 'kornia.augmentation._2d.geometric.resized_crop.RandomResizedCrop'>, target = 'tensorflow', init_args = ()
init_kwargs = {'cropping_mode': 'resample', 'p': 1.0, 'ratio': (2.0, 2.0), 'scale': (3.0, 3.0), ...}, call_args = (tensor([[[0., 1., 2.],
         [3., 4., 5.],
         [6., 7., 8.]]]),)
call_kwargs = {}, deterministic_output = False, backend_compile = False, tolerance = 0.001

    def _test_augmentation_class(
        augmentation_cls,
        target,
        init_args=(),
        init_kwargs={},
        call_args=(),
        call_kwargs={},
        deterministic_output=True,
        backend_compile=False,
        tolerance=1e-3,
    ):
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_cls = ivy.transpile(augmentation_cls, source="torch", target=target)
    
        torch_aug = augmentation_cls(*init_args, **init_kwargs)
        transpiled_init_args = _nest_torch_tensor_to_new_framework(init_args, target)
        transpiled_init_kwargs = _nest_torch_tensor_to_new_framework(init_kwargs, target)
        transpiled_aug = transpiled_cls(*transpiled_init_args, **transpiled_init_kwargs)
    
        # assert dir(torch_aug) == dir(transpiled_aug), f"attributes/methods of transpiled object do not align with the original - orig: {dir(torch_aug)} != transpiled: {dir(transpiled_aug)}"
    
        torch_out = torch_aug(*call_args, **call_kwargs)
        transpiled_call_args = _nest_torch_tensor_to_new_framework(call_args, target)
        transpiled_call_kwargs = _nest_torch_tensor_to_new_framework(call_kwargs, target)
>       transpiled_out = transpiled_aug(*transpiled_call_args, **transpiled_call_kwargs)

kornia/augmentation/test_augmentation3.py:43: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomResizedCrop(scale=(3.0, 3.0), resize_to=(2.0, 2.0), output_size=(3, 3), p=1.0, p_batch=1.0, same_on_batch=False, size=(3, 3), resample=bilinear, align_corners=True, cropping_mode=resample, padding_mode=zeros)
args = (<tf.Tensor: shape=(1, 3, 3), dtype=float32, numpy=
array([[[0., 1., 2.],
        [3., 4., 5.],
        [6., 7., 8.]]], dtype=float32)>,), kwargs = {}
stack = [FrameInfo(frame=<frame at 0x7f302efa4640, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...kexec', code_context=['        return self._inner_hookexec(hook_name, methods, kwargs, firstresult)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomResizedCrop(scale=(3.0, 3.0), resize_to=(2.0, 2.0), output_size=(3, 3), p=1.0, p_batch=1.0, same_on_...e=(1, 3, 3), dtype=float32, numpy=
array([[[0., 1., 2.],
        [3., 4., 5.],
        [6., 7., 8.]]], dtype=float32)>)
kwargs = {}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomResizedCrop(scale=(3.0, 3.0), resize_to=(2.0, 2.0), output_size=(3, 3), p=1.0, p_batch=1.0, same_on_batch=False, size=(3, 3), resample=bilinear, align_corners=True, cropping_mode=resample, padding_mode=zeros)
v = None, buffers = None, args = (<tf.Tensor: shape=(1, 3, 3), dtype=float32, numpy=
array([[[0., 1., 2.],
        [3., 4., 5.],
        [6., 7., 8.]]], dtype=float32)>,), kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomResizedCrop(scale=(3.0, 3.0), resize_to=(2.0, 2.0), output_size=(3, 3), p=1.0, p_batch=1.0, same_on_...e=(1, 3, 3), dtype=float32, numpy=
array([[[0., 1., 2.],
        [3., 4., 5.],
        [6., 7., 8.]]], dtype=float32)>)
kwargs = {'buffers': None, 'v': None}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomResizedCrop(scale=(3.0, 3.0), resize_to=(2.0, 2.0), output_size=(3, 3), p=1.0, p_batch=1.0, same_on_batch=False, size=(3, 3), resample=bilinear, align_corners=True, cropping_mode=resample, padding_mode=zeros)
v = None, buffers = None, args = (<tf.Tensor: shape=(1, 3, 3), dtype=float32, numpy=
array([[[0., 1., 2.],
        [3., 4., 5.],
        [6., 7., 8.]]], dtype=float32)>,), kwargs = {}
first_arr = <tf.Tensor: shape=(1, 3, 3), dtype=float32, numpy=
array([[[0., 1., 2.],
        [3., 4., 5.],
        [6., 7., 8.]]], dtype=float32)>, replace_v = False, replace_buffers = False
call_signature = <Signature (input, params=None, **kwargs)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Layer, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Layer, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Layer, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomResizedCrop(scale=(3.0, 3.0), resize_to=(2.0, 2.0), output_size=(3, 3), p=1.0, p_batch=1.0, same_on_batch=False, size=(3, 3), resample=bilinear, align_corners=True, cropping_mode=resample, padding_mode=zeros),)
kwargs = {'input': <tf.Tensor: shape=(1, 3, 3), dtype=float32, numpy=
array([[[0., 1., 2.],
        [3., 4., 5.],
        [6., 7., 8.]]], dtype=float32)>}

    @wraps(fn)
    def error_handler(*args, **kwargs):
        if not is_traceback_filtering_enabled():
            return fn(*args, **kwargs)
    
        filtered_tb = None
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            filtered_tb = _process_traceback_frames(e.__traceback__)
            # To get the full stack trace, call:
            # `keras.config.disable_traceback_filtering()`
>           raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/keras/src/utils/traceback_utils.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomResizedCrop(scale=(3.0, 3.0), resize_to=(2.0, 2.0), output_size=(3, 3), p=1.0, p_batch=1.0, same_on_batch=False, size=(3, 3), resample=bilinear, align_corners=True, cropping_mode=resample, padding_mode=zeros)
input = <tf.Tensor: shape=(1, 3, 3), dtype=float32, numpy=
array([[[0., 1., 2.],
        [3., 4., 5.],
        [6., 7., 8.]]], dtype=float32)>, params = None, kwargs = {}
tensorflow_shape_frnt_ = <function tensorflow_shape_frnt_ at 0x7f302d88f640>, tensorflow_set_item = <function tensorflow_set_item at 0x7f302c0fa3b0>
tensor = <function tensorflow_tensor_frnt at 0x7f302d00fe20>
in_tensor = <tf.Tensor: shape=(1, 1, 3, 3), dtype=float32, numpy=
array([[[[0., 1., 2.],
         [3., 4., 5.],
         [6., 7., 8.]]]], dtype=float32)>
input_shape = ivy.frontends.torch.Size([1, 3, 3]), batch_shape = ivy.frontends.torch.Size([1, 1, 3, 3])

    def call(self, input, params=None, **kwargs):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ...ivy.functional.backends.tensorflow.general import tensorflow_set_item
        from ..core._backend import tensor
    
        in_tensor = self.__unpack_input__(input)
        input_shape = tensorflow_shape_frnt_(in_tensor)
        in_tensor = self.transform_tensor(in_tensor)
        batch_shape = tensorflow_shape_frnt_(in_tensor)
        if params is None:
>           params = self.forward_parameters(batch_shape)

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/base.py:228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomResizedCrop(scale=(3.0, 3.0), resize_to=(2.0, 2.0), output_size=(3, 3), p=1.0, p_batch=1.0, same_on_batch=False, size=(3, 3), resample=bilinear, align_corners=True, cropping_mode=resample, padding_mode=zeros)
batch_shape = ivy.frontends.torch.Size([1, 1, 3, 3])

    def forward_parameters(self, batch_shape):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_sum_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_item_frnt_
        from ...ivy.functional.backends.tensorflow.general import tensorflow_set_item
        from ..core._backend import tensor
    
        batch_prob = self.__batch_prob_generator__(
            batch_shape, self.p, self.p_batch, self.same_on_batch
        )
        to_apply = batch_prob > 0.5
>       _params = self.generate_parameters(
            tuple(
                (
                    int(tensorflow_item_frnt_(tensorflow_sum_frnt_(to_apply))),
                    *batch_shape[1:],
                )
            )
        )

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/base.py:200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomResizedCrop(scale=(3.0, 3.0), resize_to=(2.0, 2.0), output_size=(3, 3), p=1.0, p_batch=1.0, same_on_batch=False, size=(3, 3), resample=bilinear, align_corners=True, cropping_mode=resample, padding_mode=zeros)
batch_shape = (1, 1, 3, 3)

    def generate_parameters(self, batch_shape):
        if self._param_generator is not None:
>           return self._param_generator(batch_shape, self.same_on_batch)

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/base.py:123: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = scale=(3.0, 3.0), resize_to=(2.0, 2.0), output_size=(3, 3), args = ((1, 1, 3, 3), False), kwargs = {}
stack = [FrameInfo(frame=<frame at 0x7f302efa5e40, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...ion.py', lineno=46, function='__call__', code_context=['            return call_fn(*args, **kwargs)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = scale=(3.0, 3.0), resize_to=(2.0, 2.0), output_size=(3, 3), v = None, buffers = None, args = ((1, 1, 3, 3), False), kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = scale=(3.0, 3.0), resize_to=(2.0, 2.0), output_size=(3, 3), v = None, buffers = None, args = ((1, 1, 3, 3), False), kwargs = {}, replace_v = False, replace_buffers = False
call_signature = <Signature (batch_shape, same_on_batch=False)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Layer, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Layer, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Layer, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = scale=(3.0, 3.0), resize_to=(2.0, 2.0), output_size=(3, 3), batch_shape = (1, 1, 3, 3), same_on_batch = False

    def call(self, batch_shape, same_on_batch=False):
        from ....utils.helpers import tensorflow__extract_device_dtype
        from .....ivy.functional.frontends.torch.tensor import tensorflow_to_frnt_
        from ...utils.helpers import tensorflow__adapted_rsampling
        from .....ivy.functional.frontends.torch.pointwise_ops import (
            tensorflow_exp_frnt,
        )
        from .....ivy.functional.frontends.torch.tensor import tensorflow_floor_frnt_
        from .....ivy.functional.frontends.torch.tensor import tensorflow_round_frnt_
        from .....ivy.functional.frontends.torch.pointwise_ops import (
            tensorflow_sqrt_frnt,
        )
        from .....ivy.functional.frontends.torch.tensor import tensorflow_int_frnt_
        from .....ivy.functional.frontends.torch.tensor import tensorflow_max_frnt_
        from .....ivy.functional.frontends.torch.tensor import tensorflow_cumsum_frnt_
        from .....ivy.functional.frontends.torch.tensor import tensorflow_bool_frnt_
        from .....ivy.functional.backends.tensorflow.general import tensorflow_get_item
        from .....ivy.functional.frontends.torch.creation_ops import (
            tensorflow_arange_frnt,
        )
        from .....ivy.functional.frontends.torch.tensor import tensorflow_all_frnt_
        from .....ivy.functional.frontends.torch.tensor import tensorflow_min_frnt_
        from .....ivy.functional.frontends.torch.pointwise_ops import (
            tensorflow_round_frnt,
        )
        from .....ivy.functional.frontends.torch.tensor import tensorflow_where_frnt_
        from .....ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            tensorflow_stack_frnt,
        )
        from ....core._backend import tensor
        from ....core._backend import zeros
    
        batch_size = batch_shape[0]
        size = batch_shape[-2], batch_shape[-1]
        _device, _dtype = tensorflow__extract_device_dtype([self.scale, self.ratio])
        if batch_size == 0:
            return {
                "src": zeros([0, 4, 2], device=_device, dtype=_dtype),
                "dst": zeros([0, 4, 2], device=_device, dtype=_dtype),
                "size": zeros([0, 2], device=_device, dtype=_dtype),
            }
        rand = tensorflow_to_frnt_(
            tensorflow__adapted_rsampling(
                (batch_size, 10), self.rand_sampler, same_on_batch
            ),
            device=_device,
            dtype=_dtype,
        )
        area = (
            (rand * (self.scale[1] - self.scale[0]) + self.scale[0]) * size[0] * size[1]
        )
        log_ratio = tensorflow_to_frnt_(
            tensorflow__adapted_rsampling(
                (batch_size, 10), self.log_ratio_sampler, same_on_batch
            ),
            device=_device,
            dtype=_dtype,
        )
        aspect_ratio = tensorflow_exp_frnt(log_ratio)
        w = tensorflow_floor_frnt_(
            tensorflow_round_frnt_(tensorflow_sqrt_frnt(area * aspect_ratio))
        )
        h = tensorflow_floor_frnt_(
            tensorflow_round_frnt_(tensorflow_sqrt_frnt(area / aspect_ratio))
        )
>       cond = tensorflow_int_frnt_((0 < w) * (w < size[0]) * (0 < h) * (h < size[1]))

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/random_generator/_2d/crop.py:328: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <tf.Tensor: shape=(1, 10), dtype=bool, numpy=
array([[ True,  True,  True,  True,  True,  True,  True,  True,  True,
         True]])>
rhs = <tf.Tensor: shape=(1, 10), dtype=bool, numpy=
array([[False, False, False, False, False, False, False, False, False,
        False]])>

    def impl(self, rhs):
        try:
            return original_method(self, rhs)
        except Exception:
>           return patched_method(self, rhs)

ivy_transpiled_outputs/tensorflow_outputs/__init__.py:65: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = <tf.Tensor: shape=(1, 10), dtype=bool, numpy=
array([[ True,  True,  True,  True,  True,  True,  True,  True,  True,
         True]])>
other = <tf.Tensor: shape=(1, 10), dtype=bool, numpy=
array([[False, False, False, False, False, False, False, False, False,
        False]])>

    def tensorflow___mul___frnt_(tensor, other):
        from .pointwise_ops import tensorflow_mul_frnt
    
>       return tensorflow_mul_frnt(tensor, other)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/tensor.py:125: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = <tf.Tensor: shape=(1, 10), dtype=bool, numpy=
array([[ True,  True,  True,  True,  True,  True,  True,  True,  True,
         True]])>
other = <tf.Tensor: shape=(1, 10), dtype=bool, numpy=
array([[False, False, False, False, False, False, False, False, False,
        False]])>

    def tensorflow_mul_frnt(input, other, *, out=None):
        from .__init__ import tensorflow_promote_types_of_torch_inputs_frnt
        from ...backends.tensorflow.elementwise import tensorflow_multiply
    
        input, other = tensorflow_promote_types_of_torch_inputs_frnt(input, other)
>       return tensorflow_multiply(input, other, out=out)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/pointwise_ops.py:118: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x1 = <tf.Tensor: shape=(1, 10), dtype=bool, numpy=
array([[ True,  True,  True,  True,  True,  True,  True,  True,  True,
         True]])>
x2 = <tf.Tensor: shape=(1, 10), dtype=bool, numpy=
array([[False, False, False, False, False, False, False, False, False,
        False]])>

    def tensorflow_multiply(
        x1: Union[float, tensorflow.Tensor, tensorflow.Variable],
        x2: Union[float, tensorflow.Tensor, tensorflow.Variable],
        /,
        *,
        out: Optional[Union[tensorflow.Tensor, tensorflow.Variable]] = None,
    ):
        from ...ivy.data_type import tensorflow_promote_types_of_inputs_bknd
    
        x1, x2 = tensorflow_promote_types_of_inputs_bknd(x1, x2)
>       return tensorflow.math.multiply(x1, x2)
E       tensorflow.python.framework.errors_impl.InvalidArgumentError: Exception encountered when calling tensorflow_ResizedCropGenerator.call().
E       
E       [1mValue for attr 'T' of bool is not in the list of allowed values: bfloat16, half, float, double, uint8, int8, uint16, int16, int32, uint32, uint64, int64, complex64, complex128
E       	; NodeDef: {{node Mul}}; Op<name=Mul; signature=x:T, y:T -> z:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE, DT_UINT8, DT_INT8, DT_UINT16, DT_INT16, DT_INT32, DT_UINT32, DT_UINT64, DT_INT64, DT_COMPLEX64, DT_COMPLEX128]; is_commutative=true> [Op:Mul] name: [0m
E       
E       Arguments received by tensorflow_ResizedCropGenerator.call():
E          batch_shape=('1', '1', '3', '3')
E          same_on_batch=False

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/backends/tensorflow/elementwise.py:353: InvalidArgumentError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.RandomResizedCrop
______________________________________________________________________________ test_RandomRotation[tensorflow-s2s-False] _______________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_RandomRotation(target_framework, mode, backend_compile):
        print("kornia.augmentation.RandomRotation")
    
        init_args = ()
        init_kwargs = {"degrees": 45.0, "p": 1.}
        call_args = (torch.tensor([[1., 0., 0., 2.],
                                   [0., 0., 0., 0.],
                                   [0., 1., 2., 0.],
                                   [0., 0., 1., 2.]]),)
        call_kwargs = {}
    
>       _test_augmentation_class(
            kornia.augmentation.RandomRotation,
            target_framework,
            init_args,
            init_kwargs,
            call_args,
            call_kwargs,
            deterministic_output=False,
            backend_compile=backend_compile,
        )

kornia/augmentation/test_augmentation3.py:270: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

augmentation_cls = <class 'kornia.augmentation._2d.geometric.rotation.RandomRotation'>, target = 'tensorflow', init_args = (), init_kwargs = {'degrees': 45.0, 'p': 1.0}
call_args = (tensor([[1., 0., 0., 2.],
        [0., 0., 0., 0.],
        [0., 1., 2., 0.],
        [0., 0., 1., 2.]]),), call_kwargs = {}, deterministic_output = False, backend_compile = False
tolerance = 0.001

    def _test_augmentation_class(
        augmentation_cls,
        target,
        init_args=(),
        init_kwargs={},
        call_args=(),
        call_kwargs={},
        deterministic_output=True,
        backend_compile=False,
        tolerance=1e-3,
    ):
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_cls = ivy.transpile(augmentation_cls, source="torch", target=target)
    
        torch_aug = augmentation_cls(*init_args, **init_kwargs)
        transpiled_init_args = _nest_torch_tensor_to_new_framework(init_args, target)
        transpiled_init_kwargs = _nest_torch_tensor_to_new_framework(init_kwargs, target)
        transpiled_aug = transpiled_cls(*transpiled_init_args, **transpiled_init_kwargs)
    
        # assert dir(torch_aug) == dir(transpiled_aug), f"attributes/methods of transpiled object do not align with the original - orig: {dir(torch_aug)} != transpiled: {dir(transpiled_aug)}"
    
        torch_out = torch_aug(*call_args, **call_kwargs)
        transpiled_call_args = _nest_torch_tensor_to_new_framework(call_args, target)
        transpiled_call_kwargs = _nest_torch_tensor_to_new_framework(call_kwargs, target)
>       transpiled_out = transpiled_aug(*transpiled_call_args, **transpiled_call_kwargs)

kornia/augmentation/test_augmentation3.py:43: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomRotation(degrees=45.0, p=1.0, p_batch=1.0, same_on_batch=False, resample=bilinear, align_corners=True)
args = (<tf.Tensor: shape=(4, 4), dtype=float32, numpy=
array([[1., 0., 0., 2.],
       [0., 0., 0., 0.],
       [0., 1., 2., 0.],
       [0., 0., 1., 2.]], dtype=float32)>,), kwargs = {}
stack = [FrameInfo(frame=<frame at 0x7f302d720240, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...kexec', code_context=['        return self._inner_hookexec(hook_name, methods, kwargs, firstresult)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomRotation(degrees=45.0, p=1.0, p_batch=1.0, same_on_batch=False, resample=bilinear, align_corners=Tru...=
array([[1., 0., 0., 2.],
       [0., 0., 0., 0.],
       [0., 1., 2., 0.],
       [0., 0., 1., 2.]], dtype=float32)>)
kwargs = {}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomRotation(degrees=45.0, p=1.0, p_batch=1.0, same_on_batch=False, resample=bilinear, align_corners=True), v = None, buffers = None
args = (<tf.Tensor: shape=(4, 4), dtype=float32, numpy=
array([[1., 0., 0., 2.],
       [0., 0., 0., 0.],
       [0., 1., 2., 0.],
       [0., 0., 1., 2.]], dtype=float32)>,), kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomRotation(degrees=45.0, p=1.0, p_batch=1.0, same_on_batch=False, resample=bilinear, align_corners=Tru...=
array([[1., 0., 0., 2.],
       [0., 0., 0., 0.],
       [0., 1., 2., 0.],
       [0., 0., 1., 2.]], dtype=float32)>)
kwargs = {'buffers': None, 'v': None}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomRotation(degrees=45.0, p=1.0, p_batch=1.0, same_on_batch=False, resample=bilinear, align_corners=True), v = None, buffers = None
args = (<tf.Tensor: shape=(4, 4), dtype=float32, numpy=
array([[1., 0., 0., 2.],
       [0., 0., 0., 0.],
       [0., 1., 2., 0.],
       [0., 0., 1., 2.]], dtype=float32)>,), kwargs = {}
first_arr = <tf.Tensor: shape=(4, 4), dtype=float32, numpy=
array([[1., 0., 0., 2.],
       [0., 0., 0., 0.],
       [0., 1., 2., 0.],
       [0., 0., 1., 2.]], dtype=float32)>, replace_v = False
replace_buffers = False, call_signature = <Signature (input, params=None, **kwargs)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Layer, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Layer, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Layer, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomRotation(degrees=45.0, p=1.0, p_batch=1.0, same_on_batch=False, resample=bilinear, align_corners=True),)
kwargs = {'input': <tf.Tensor: shape=(4, 4), dtype=float32, numpy=
array([[1., 0., 0., 2.],
       [0., 0., 0., 0.],
       [0., 1., 2., 0.],
       [0., 0., 1., 2.]], dtype=float32)>}

    @wraps(fn)
    def error_handler(*args, **kwargs):
        if not is_traceback_filtering_enabled():
            return fn(*args, **kwargs)
    
        filtered_tb = None
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            filtered_tb = _process_traceback_frames(e.__traceback__)
            # To get the full stack trace, call:
            # `keras.config.disable_traceback_filtering()`
>           raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/keras/src/utils/traceback_utils.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomRotation(degrees=45.0, p=1.0, p_batch=1.0, same_on_batch=False, resample=bilinear, align_corners=True)
input = <tf.Tensor: shape=(4, 4), dtype=float32, numpy=
array([[1., 0., 0., 2.],
       [0., 0., 0., 0.],
       [0., 1., 2., 0.],
       [0., 0., 1., 2.]], dtype=float32)>
params = {'batch_prob': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>, 'degrees': <tf.Tensor: shape=...([-22.226694], dtype=float32)>, 'forward_input_shape': <tf.Tensor: shape=(4,), dtype=int64, numpy=array([1, 1, 4, 4])>}
kwargs = {}, tensorflow_shape_frnt_ = <function tensorflow_shape_frnt_ at 0x7f303419ff40>, tensorflow_set_item = <function tensorflow_set_item at 0x7f302c2a4ee0>
tensor = <function tensorflow_tensor_frnt at 0x7f302d035fc0>
in_tensor = <tf.Tensor: shape=(1, 1, 4, 4), dtype=float32, numpy=
array([[[[1., 0., 0., 2.],
         [0., 0., 0., 0.],
         [0., 1., 2., 0.],
         [0., 0., 1., 2.]]]], dtype=float32)>
input_shape = ivy.frontends.torch.Size([4, 4]), batch_shape = ivy.frontends.torch.Size([1, 1, 4, 4]), flags = {'align_corners': True, 'resample': <tensorflow_Resample.BILINEAR: 1>}

    def call(self, input, params=None, **kwargs):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ...ivy.functional.backends.tensorflow.general import tensorflow_set_item
        from ..core._backend import tensor
    
        in_tensor = self.__unpack_input__(input)
        input_shape = tensorflow_shape_frnt_(in_tensor)
        in_tensor = self.transform_tensor(in_tensor)
        batch_shape = tensorflow_shape_frnt_(in_tensor)
        if params is None:
            params = self.forward_parameters(batch_shape)
        if "batch_prob" not in params:
            params = tensorflow_set_item(
                params, "batch_prob", tensor([True] * batch_shape[0])
            )
        params, flags = self._process_kwargs_to_params_and_flags(
            params, self.flags, **kwargs
        )
>       output = self.apply_func(in_tensor, params, flags)

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/base.py:236: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomRotation(degrees=45.0, p=1.0, p_batch=1.0, same_on_batch=False, resample=bilinear, align_corners=True)
in_tensor = <tf.Tensor: shape=(1, 1, 4, 4), dtype=float32, numpy=
array([[[[1., 0., 0., 2.],
         [0., 0., 0., 0.],
         [0., 1., 2., 0.],
         [0., 0., 1., 2.]]]], dtype=float32)>
params = {'batch_prob': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>, 'degrees': <tf.Tensor: shape=...([-22.226694], dtype=float32)>, 'forward_input_shape': <tf.Tensor: shape=(4,), dtype=int64, numpy=array([1, 1, 4, 4])>}
flags = {'align_corners': True, 'resample': <tensorflow_Resample.BILINEAR: 1>}

    def apply_func(self, in_tensor, params, flags=None):
        if flags is None:
            flags = self.flags
>       trans_matrix = self.generate_transformation_matrix(in_tensor, params, flags)

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/_2d/base.py:126: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomRotation(degrees=45.0, p=1.0, p_batch=1.0, same_on_batch=False, resample=bilinear, align_corners=True)
input = <tf.Tensor: shape=(1, 1, 4, 4), dtype=float32, numpy=
array([[[[1., 0., 0., 2.],
         [0., 0., 0., 0.],
         [0., 1., 2., 0.],
         [0., 0., 1., 2.]]]], dtype=float32)>
params = {'batch_prob': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>, 'degrees': <tf.Tensor: shape=...([-22.226694], dtype=float32)>, 'forward_input_shape': <tf.Tensor: shape=(4,), dtype=int64, numpy=array([1, 1, 4, 4])>}
flags = {'align_corners': True, 'resample': <tensorflow_Resample.BILINEAR: 1>}

    def generate_transformation_matrix(self, input, params, flags):
        from ....ivy.functional.frontends.torch.tensor import tensorflow_any_frnt_
        from ....ivy.functional.frontends.torch.tensor import tensorflow_all_frnt_
        from ....ivy.functional.backends.tensorflow.general import tensorflow_get_item
        from ...utils.helpers import tensorflow_is_autocast_enabled
        from ....ivy.functional.frontends.torch.tensor import tensorflow_type_frnt_
        from ....ivy.functional.frontends.torch.tensor import tensorflow_index_put_frnt_
    
        batch_prob = params["batch_prob"]
        to_apply = batch_prob > 0.5
        in_tensor = self.transform_tensor(input)
        if not tensorflow_any_frnt_(to_apply):
            trans_matrix = self.identity_matrix(in_tensor)
        elif tensorflow_all_frnt_(to_apply):
>           trans_matrix = self.compute_transformation(
                in_tensor, params=params, flags=flags
            )

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/_2d/base.py:92: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomRotation(degrees=45.0, p=1.0, p_batch=1.0, same_on_batch=False, resample=bilinear, align_corners=True)
input = <tf.Tensor: shape=(1, 1, 4, 4), dtype=float32, numpy=
array([[[[1., 0., 0., 2.],
         [0., 0., 0., 0.],
         [0., 1., 2., 0.],
         [0., 0., 1., 2.]]]], dtype=float32)>
params = {'batch_prob': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>, 'degrees': <tf.Tensor: shape=...([-22.226694], dtype=float32)>, 'forward_input_shape': <tf.Tensor: shape=(4,), dtype=int64, numpy=array([1, 1, 4, 4])>}
flags = {'align_corners': True, 'resample': <tensorflow_Resample.BILINEAR: 1>}

    def compute_transformation(self, input, params, flags):
        from .....ivy.functional.frontends.torch.tensor import tensorflow_to_frnt_
        from ....geometry.transform.affwarp import tensorflow__compute_tensor_center
        from ....geometry.transform.affwarp import tensorflow__compute_rotation_matrix
        from .....ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ....utils.misc import tensorflow_eye_like
        from .....ivy.functional.backends.tensorflow.general import tensorflow_set_item
    
        angles: typing.Any = tensorflow_to_frnt_(params["degrees"], input)
        center: typing.Any = tensorflow__compute_tensor_center(input)
        rotation_mat: typing.Any = tensorflow__compute_rotation_matrix(
>           angles, center.expand(tensorflow_shape_frnt_(angles)[0], -1)
        )
E       AttributeError: Exception encountered when calling tensorflow_RandomRotation.call().
E       
E       [1m'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'expand'[0m
E       
E       Arguments received by tensorflow_RandomRotation.call():
E          input=tf.Tensor(shape=(4, 4), dtype=float32)
E          params=None
E          kwargs=<class 'inspect._empty'>

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/_2d/geometric/rotation.py:70: AttributeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.RandomRotation
______________________________________________________________________________ test_RandomCutMixV2[tensorflow-s2s-False] _______________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_RandomCutMixV2(target_framework, mode, backend_compile):
        print("kornia.augmentation.RandomCutMixV2")
    
        input = torch.rand(2, 1, 3, 3)
        input[0] = torch.ones((1, 3, 3))
        label = torch.tensor([0, 1])
    
        init_args = ()
        init_kwargs = {"data_keys": ["input", "class"]}
        call_args = (input, label)
        call_kwargs = {}
    
>       _test_augmentation_class(
            kornia.augmentation.RandomCutMixV2,
            target_framework,
            init_args,
            init_kwargs,
            call_args,
            call_kwargs,
            deterministic_output=False,
            backend_compile=backend_compile,
        )

kornia/augmentation/test_augmentation3.py:354: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

augmentation_cls = <class 'kornia.augmentation._2d.mix.cutmix.RandomCutMixV2'>, target = 'tensorflow', init_args = (), init_kwargs = {'data_keys': ['input', 'class']}
call_args = (tensor([[[[1.0000, 1.0000, 1.0000],
          [1.0000, 1.0000, 1.0000],
          [1.0000, 1.0000, 1.0000]]],


        [[[0.6127, 0.1504, 0.6998],
          [0.9205, 0.1706, 0.9693],
          [0.0779, 0.9529, 0.1575]]]]), tensor([0, 1]))
call_kwargs = {}, deterministic_output = False, backend_compile = False, tolerance = 0.001

    def _test_augmentation_class(
        augmentation_cls,
        target,
        init_args=(),
        init_kwargs={},
        call_args=(),
        call_kwargs={},
        deterministic_output=True,
        backend_compile=False,
        tolerance=1e-3,
    ):
        if backend_compile or target == "numpy":
            pytest.skip()
    
>       transpiled_cls = ivy.transpile(augmentation_cls, source="torch", target=target)

kornia/augmentation/test_augmentation3.py:31: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

object = <class 'kornia.augmentation._2d.mix.cutmix.RandomCutMixV2'>, source = 'torch', target = 'tensorflow', reuse_existing = True

    def transpile(
        object,
        source: str = "torch",
        target: str = "tensorflow",
        reuse_existing: bool = True,
    ):
        """Converts a given object (class/function) from one framework to another.
    
        This function performs source-to-source translation of a given object from the source framework
        to the target framework.
    
        The object can be translated between two frameworks or between the Ivy IR as well
        e.g. (source="torch_frontend", target="ivy") or (source="torch_frontend", target="tensorflow") etc.
    
        Args:
            object: The object (class/function) to be translated.
            source (str, optional): The source framework. Defaults to 'torch'.
            target (str, optional): The target framework. Defaults to 'tensorflow'.
            reuse_existing (bool, optional): If True, the function will check if `object`
                                             already exists in the translated directory and reuse it.
                                             If False, it will re-translate `object`,
                                             even if it already exists in the directory, and overwrite
                                             the old implementation. Defaults to 'True'.
    
        Returns:
            The translated object."""
    
        from ._compiler import transpile as _transpile
    
>       return _transpile(
            object=object,
            source=source,
            target=target,
            reuse_existing=reuse_existing,
        )

../ivy/ivy/compiler/compiler.py:201: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   ivy.utils.exceptions.IvyException: source code not available

IXC.pyx:379: IvyException
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.RandomCutMixV2
_______________________________________________________________________________ test_RandomJigsaw[tensorflow-s2s-False] ________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_RandomJigsaw(target_framework, mode, backend_compile):
        print("kornia.augmentation.RandomJigsaw")
    
        init_args = ((4, 4),)
        init_kwargs = {}
        call_args = (torch.randn(8, 3, 256, 256),)
        call_kwargs = {}
    
>       _test_augmentation_class(
            kornia.augmentation.RandomJigsaw,
            target_framework,
            init_args,
            init_kwargs,
            call_args,
            call_kwargs,
            deterministic_output=False,
            backend_compile=backend_compile,
        )

kornia/augmentation/test_augmentation3.py:374: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

augmentation_cls = <class 'kornia.augmentation._2d.mix.jigsaw.RandomJigsaw'>, target = 'tensorflow', init_args = ((4, 4),), init_kwargs = {}
call_args = (tensor([[[[ 3.3395e-01,  1.1593e+00, -1.2024e+00,  ..., -1.9237e-01,
           -1.7309e-01, -2.4524e+00],
          ...1e-02],
          [ 5.1913e-01, -2.0960e+00, -8.8354e-01,  ..., -1.6756e+00,
            1.5050e+00,  6.1065e-01]]]]),)
call_kwargs = {}, deterministic_output = False, backend_compile = False, tolerance = 0.001

    def _test_augmentation_class(
        augmentation_cls,
        target,
        init_args=(),
        init_kwargs={},
        call_args=(),
        call_kwargs={},
        deterministic_output=True,
        backend_compile=False,
        tolerance=1e-3,
    ):
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_cls = ivy.transpile(augmentation_cls, source="torch", target=target)
    
        torch_aug = augmentation_cls(*init_args, **init_kwargs)
        transpiled_init_args = _nest_torch_tensor_to_new_framework(init_args, target)
        transpiled_init_kwargs = _nest_torch_tensor_to_new_framework(init_kwargs, target)
        transpiled_aug = transpiled_cls(*transpiled_init_args, **transpiled_init_kwargs)
    
        # assert dir(torch_aug) == dir(transpiled_aug), f"attributes/methods of transpiled object do not align with the original - orig: {dir(torch_aug)} != transpiled: {dir(transpiled_aug)}"
    
        torch_out = torch_aug(*call_args, **call_kwargs)
        transpiled_call_args = _nest_torch_tensor_to_new_framework(call_args, target)
        transpiled_call_kwargs = _nest_torch_tensor_to_new_framework(call_kwargs, target)
>       transpiled_out = transpiled_aug(*transpiled_call_args, **transpiled_call_kwargs)

kornia/augmentation/test_augmentation3.py:43: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomJigsaw(grid=(4, 4), p=0.5, p_batch=1.0, same_on_batch=False, grid=(4, 4))
args = (<tf.Tensor: shape=(8, 3, 256, 256), dtype=float32, numpy=
array([[[[ 3.33945394e-01,  1.15928376e+00, -1.20238006e+00...900e+00, -8.83538723e-01, ...,
          -1.67555034e+00,  1.50495243e+00,  6.10648036e-01]]]],
      dtype=float32)>,)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x7f30240a7640, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...kexec', code_context=['        return self._inner_hookexec(hook_name, methods, kwargs, firstresult)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomJigsaw(grid=(4, 4), p=0.5, p_batch=1.0, same_on_batch=False, grid=(4, 4)), <tf.Tensor: shape=(8, 3, ...9900e+00, -8.83538723e-01, ...,
          -1.67555034e+00,  1.50495243e+00,  6.10648036e-01]]]],
      dtype=float32)>)
kwargs = {}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomJigsaw(grid=(4, 4), p=0.5, p_batch=1.0, same_on_batch=False, grid=(4, 4)), v = None, buffers = None
args = (<tf.Tensor: shape=(8, 3, 256, 256), dtype=float32, numpy=
array([[[[ 3.33945394e-01,  1.15928376e+00, -1.20238006e+00...900e+00, -8.83538723e-01, ...,
          -1.67555034e+00,  1.50495243e+00,  6.10648036e-01]]]],
      dtype=float32)>,)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomJigsaw(grid=(4, 4), p=0.5, p_batch=1.0, same_on_batch=False, grid=(4, 4)), <tf.Tensor: shape=(8, 3, ...9900e+00, -8.83538723e-01, ...,
          -1.67555034e+00,  1.50495243e+00,  6.10648036e-01]]]],
      dtype=float32)>)
kwargs = {'buffers': None, 'v': None}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomJigsaw(grid=(4, 4), p=0.5, p_batch=1.0, same_on_batch=False, grid=(4, 4)), v = None, buffers = None
args = (<tf.Tensor: shape=(8, 3, 256, 256), dtype=float32, numpy=
array([[[[ 3.33945394e-01,  1.15928376e+00, -1.20238006e+00...900e+00, -8.83538723e-01, ...,
          -1.67555034e+00,  1.50495243e+00,  6.10648036e-01]]]],
      dtype=float32)>,)
kwargs = {}
first_arr = <tf.Tensor: shape=(8, 3, 256, 256), dtype=float32, numpy=
array([[[[ 3.33945394e-01,  1.15928376e+00, -1.20238006e+00,...99900e+00, -8.83538723e-01, ...,
          -1.67555034e+00,  1.50495243e+00,  6.10648036e-01]]]],
      dtype=float32)>
replace_v = False, replace_buffers = False, call_signature = <Signature (*input, params=None, data_keys=None)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Layer, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Layer, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Layer, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomJigsaw(grid=(4, 4), p=0.5, p_batch=1.0, same_on_batch=False, grid=(4, 4)),)
kwargs = {'input': <tf.Tensor: shape=(8, 3, 256, 256), dtype=float32, numpy=
array([[[[ 3.33945394e-01,  1.15928376e+00, -1.202...9900e+00, -8.83538723e-01, ...,
          -1.67555034e+00,  1.50495243e+00,  6.10648036e-01]]]],
      dtype=float32)>}

    @wraps(fn)
    def error_handler(*args, **kwargs):
        if not is_traceback_filtering_enabled():
            return fn(*args, **kwargs)
    
        filtered_tb = None
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            filtered_tb = _process_traceback_frames(e.__traceback__)
            # To get the full stack trace, call:
            # `keras.config.disable_traceback_filtering()`
>           raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/keras/src/utils/traceback_utils.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <Signature (*input, params=None, data_keys=None)>, args = ()
kwargs = {'input': <tf.Tensor: shape=(8, 3, 256, 256), dtype=float32, numpy=
array([[[[ 3.33945394e-01,  1.15928376e+00, -1.202...9900e+00, -8.83538723e-01, ...,
          -1.67555034e+00,  1.50495243e+00,  6.10648036e-01]]]],
      dtype=float32)>}

    def bind(self, /, *args, **kwargs):
        """Get a BoundArguments object, that maps the passed `args`
        and `kwargs` to the function's signature.  Raises `TypeError`
        if the passed arguments can not be bound.
        """
>       return self._bind(args, kwargs)

/opt/miniconda/envs/multienv/lib/python3.10/inspect.py:3177: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <Signature (*input, params=None, data_keys=None)>, args = ()
kwargs = {'input': <tf.Tensor: shape=(8, 3, 256, 256), dtype=float32, numpy=
array([[[[ 3.33945394e-01,  1.15928376e+00, -1.202...9900e+00, -8.83538723e-01, ...,
          -1.67555034e+00,  1.50495243e+00,  6.10648036e-01]]]],
      dtype=float32)>}

    def _bind(self, args, kwargs, *, partial=False):
        """Private method. Don't use directly."""
    
        arguments = {}
    
        parameters = iter(self.parameters.values())
        parameters_ex = ()
        arg_vals = iter(args)
    
        while True:
            # Let's iterate through the positional arguments and corresponding
            # parameters
            try:
                arg_val = next(arg_vals)
            except StopIteration:
                # No more positional arguments
                try:
                    param = next(parameters)
                except StopIteration:
                    # No more parameters. That's it. Just need to check that
                    # we have no `kwargs` after this while loop
                    break
                else:
                    if param.kind == _VAR_POSITIONAL:
                        # That's OK, just empty *args.  Let's start parsing
                        # kwargs
                        break
                    elif param.name in kwargs:
                        if param.kind == _POSITIONAL_ONLY:
                            msg = '{arg!r} parameter is positional only, ' \
                                  'but was passed as a keyword'
                            msg = msg.format(arg=param.name)
                            raise TypeError(msg) from None
                        parameters_ex = (param,)
                        break
                    elif (param.kind == _VAR_KEYWORD or
                                                param.default is not _empty):
                        # That's fine too - we have a default value for this
                        # parameter.  So, lets start parsing `kwargs`, starting
                        # with the current parameter
                        parameters_ex = (param,)
                        break
                    else:
                        # No default, not VAR_KEYWORD, not VAR_POSITIONAL,
                        # not in `kwargs`
                        if partial:
                            parameters_ex = (param,)
                            break
                        else:
                            msg = 'missing a required argument: {arg!r}'
                            msg = msg.format(arg=param.name)
                            raise TypeError(msg) from None
            else:
                # We have a positional argument to process
                try:
                    param = next(parameters)
                except StopIteration:
                    raise TypeError('too many positional arguments') from None
                else:
                    if param.kind in (_VAR_KEYWORD, _KEYWORD_ONLY):
                        # Looks like we have no parameter for this positional
                        # argument
                        raise TypeError(
                            'too many positional arguments') from None
    
                    if param.kind == _VAR_POSITIONAL:
                        # We have an '*args'-like argument, let's fill it with
                        # all positional arguments we have left and move on to
                        # the next phase
                        values = [arg_val]
                        values.extend(arg_vals)
                        arguments[param.name] = tuple(values)
                        break
    
                    if param.name in kwargs and param.kind != _POSITIONAL_ONLY:
                        raise TypeError(
                            'multiple values for argument {arg!r}'.format(
                                arg=param.name)) from None
    
                    arguments[param.name] = arg_val
    
        # Now, we iterate through the remaining parameters to process
        # keyword arguments
        kwargs_param = None
        for param in itertools.chain(parameters_ex, parameters):
            if param.kind == _VAR_KEYWORD:
                # Memorize that we have a '**kwargs'-like parameter
                kwargs_param = param
                continue
    
            if param.kind == _VAR_POSITIONAL:
                # Named arguments don't refer to '*args'-like parameters.
                # We only arrive here if the positional arguments ended
                # before reaching the last parameter before *args.
                continue
    
            param_name = param.name
            try:
                arg_val = kwargs.pop(param_name)
            except KeyError:
                # We have no value for this parameter.  It's fine though,
                # if it has a default value, or it is an '*args'-like
                # parameter, left alone by the processing of positional
                # arguments.
                if (not partial and param.kind != _VAR_POSITIONAL and
                                                    param.default is _empty):
                    raise TypeError('missing a required argument: {arg!r}'. \
                                    format(arg=param_name)) from None
    
            else:
                if param.kind == _POSITIONAL_ONLY:
                    # This should never happen in case of a properly built
                    # Signature object (but let's have this check here
                    # to ensure correct behaviour just in case)
                    raise TypeError('{arg!r} parameter is positional only, '
                                    'but was passed as a keyword'. \
                                    format(arg=param.name))
    
                arguments[param_name] = arg_val
    
        if kwargs:
            if kwargs_param is not None:
                # Process our '**kwargs'-like parameter
                arguments[kwargs_param.name] = kwargs
            else:
>               raise TypeError(
                    'got an unexpected keyword argument {arg!r}'.format(
                        arg=next(iter(kwargs))))
E               TypeError: got an unexpected keyword argument 'input'

/opt/miniconda/envs/multienv/lib/python3.10/inspect.py:3166: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.RandomJigsaw
_______________________________________________________________________________ test_RandomMixUpV2[tensorflow-s2s-False] _______________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_RandomMixUpV2(target_framework, mode, backend_compile):
        print("kornia.augmentation.RandomMixUpV2")
    
        init_args = ()
        init_kwargs = {"data_keys": ["input", "class"]}
        call_args = (torch.rand(2, 1, 3, 3), torch.tensor([0, 1]))
        call_kwargs = {}
    
>       _test_augmentation_class(
            kornia.augmentation.RandomMixUpV2,
            target_framework,
            init_args,
            init_kwargs,
            call_args,
            call_kwargs,
            deterministic_output=False,
            backend_compile=backend_compile,
        )

kornia/augmentation/test_augmentation3.py:394: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

augmentation_cls = <class 'kornia.augmentation._2d.mix.mixup.RandomMixUpV2'>, target = 'tensorflow', init_args = (), init_kwargs = {'data_keys': ['input', 'class']}
call_args = (tensor([[[[0.8820, 0.7584, 0.7379],
          [0.2683, 0.9096, 0.1350],
          [0.0844, 0.3612, 0.1248]]],


        [[[0.5366, 0.5573, 0.2277],
          [0.4302, 0.8973, 0.1842],
          [0.0330, 0.0263, 0.2998]]]]), tensor([0, 1]))
call_kwargs = {}, deterministic_output = False, backend_compile = False, tolerance = 0.001

    def _test_augmentation_class(
        augmentation_cls,
        target,
        init_args=(),
        init_kwargs={},
        call_args=(),
        call_kwargs={},
        deterministic_output=True,
        backend_compile=False,
        tolerance=1e-3,
    ):
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_cls = ivy.transpile(augmentation_cls, source="torch", target=target)
    
        torch_aug = augmentation_cls(*init_args, **init_kwargs)
        transpiled_init_args = _nest_torch_tensor_to_new_framework(init_args, target)
        transpiled_init_kwargs = _nest_torch_tensor_to_new_framework(init_kwargs, target)
        transpiled_aug = transpiled_cls(*transpiled_init_args, **transpiled_init_kwargs)
    
        # assert dir(torch_aug) == dir(transpiled_aug), f"attributes/methods of transpiled object do not align with the original - orig: {dir(torch_aug)} != transpiled: {dir(transpiled_aug)}"
    
        torch_out = torch_aug(*call_args, **call_kwargs)
        transpiled_call_args = _nest_torch_tensor_to_new_framework(call_args, target)
        transpiled_call_kwargs = _nest_torch_tensor_to_new_framework(call_kwargs, target)
>       transpiled_out = transpiled_aug(*transpiled_call_args, **transpiled_call_kwargs)

kornia/augmentation/test_augmentation3.py:43: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomMixUpV2(lambda_val=None, p=1.0, p_batch=1.0, same_on_batch=False)
args = (<tf.Tensor: shape=(2, 1, 3, 3), dtype=float32, numpy=
array([[[[0.88202935, 0.7583611 , 0.73787206],
         [0.2682...   [0.03298759, 0.02626336, 0.2998268 ]]]], dtype=float32)>, <tf.Tensor: shape=(2,), dtype=int64, numpy=array([0, 1])>)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x564d3a311da0, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...kexec', code_context=['        return self._inner_hookexec(hook_name, methods, kwargs, firstresult)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomMixUpV2(lambda_val=None, p=1.0, p_batch=1.0, same_on_batch=False), <tf.Tensor: shape=(2, 1, 3, 3), d...   [0.03298759, 0.02626336, 0.2998268 ]]]], dtype=float32)>, <tf.Tensor: shape=(2,), dtype=int64, numpy=array([0, 1])>)
kwargs = {}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomMixUpV2(lambda_val=None, p=1.0, p_batch=1.0, same_on_batch=False), v = None, buffers = None
args = (<tf.Tensor: shape=(2, 1, 3, 3), dtype=float32, numpy=
array([[[[0.88202935, 0.7583611 , 0.73787206],
         [0.2682...   [0.03298759, 0.02626336, 0.2998268 ]]]], dtype=float32)>, <tf.Tensor: shape=(2,), dtype=int64, numpy=array([0, 1])>)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomMixUpV2(lambda_val=None, p=1.0, p_batch=1.0, same_on_batch=False), <tf.Tensor: shape=(2, 1, 3, 3), d...   [0.03298759, 0.02626336, 0.2998268 ]]]], dtype=float32)>, <tf.Tensor: shape=(2,), dtype=int64, numpy=array([0, 1])>)
kwargs = {'buffers': None, 'v': None}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomMixUpV2(lambda_val=None, p=1.0, p_batch=1.0, same_on_batch=False), v = None, buffers = None
args = (<tf.Tensor: shape=(2, 1, 3, 3), dtype=float32, numpy=
array([[[[0.88202935, 0.7583611 , 0.73787206],
         [0.2682...   [0.03298759, 0.02626336, 0.2998268 ]]]], dtype=float32)>, <tf.Tensor: shape=(2,), dtype=int64, numpy=array([0, 1])>)
kwargs = {}
first_arr = <tf.Tensor: shape=(2, 1, 3, 3), dtype=float32, numpy=
array([[[[0.88202935, 0.7583611 , 0.73787206],
         [0.26825...4273],
         [0.43024755, 0.8973208 , 0.18415505],
         [0.03298759, 0.02626336, 0.2998268 ]]]], dtype=float32)>
replace_v = False, replace_buffers = False, call_signature = <Signature (*input, params=None, data_keys=None)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Layer, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Layer, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Layer, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomMixUpV2(lambda_val=None, p=1.0, p_batch=1.0, same_on_batch=False),)
kwargs = {'input': <tf.Tensor: shape=(2, 1, 3, 3), dtype=float32, numpy=
array([[[[0.88202935, 0.7583611 , 0.73787206],
       ...8759, 0.02626336, 0.2998268 ]]]], dtype=float32)>, 'params': <tf.Tensor: shape=(2,), dtype=int64, numpy=array([0, 1])>}

    @wraps(fn)
    def error_handler(*args, **kwargs):
        if not is_traceback_filtering_enabled():
            return fn(*args, **kwargs)
    
        filtered_tb = None
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            filtered_tb = _process_traceback_frames(e.__traceback__)
            # To get the full stack trace, call:
            # `keras.config.disable_traceback_filtering()`
>           raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/keras/src/utils/traceback_utils.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <Signature (*input, params=None, data_keys=None)>, args = ()
kwargs = {'input': <tf.Tensor: shape=(2, 1, 3, 3), dtype=float32, numpy=
array([[[[0.88202935, 0.7583611 , 0.73787206],
       ...273],
         [0.43024755, 0.8973208 , 0.18415505],
         [0.03298759, 0.02626336, 0.2998268 ]]]], dtype=float32)>}

    def bind(self, /, *args, **kwargs):
        """Get a BoundArguments object, that maps the passed `args`
        and `kwargs` to the function's signature.  Raises `TypeError`
        if the passed arguments can not be bound.
        """
>       return self._bind(args, kwargs)

/opt/miniconda/envs/multienv/lib/python3.10/inspect.py:3177: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <Signature (*input, params=None, data_keys=None)>, args = ()
kwargs = {'input': <tf.Tensor: shape=(2, 1, 3, 3), dtype=float32, numpy=
array([[[[0.88202935, 0.7583611 , 0.73787206],
       ...273],
         [0.43024755, 0.8973208 , 0.18415505],
         [0.03298759, 0.02626336, 0.2998268 ]]]], dtype=float32)>}

    def _bind(self, args, kwargs, *, partial=False):
        """Private method. Don't use directly."""
    
        arguments = {}
    
        parameters = iter(self.parameters.values())
        parameters_ex = ()
        arg_vals = iter(args)
    
        while True:
            # Let's iterate through the positional arguments and corresponding
            # parameters
            try:
                arg_val = next(arg_vals)
            except StopIteration:
                # No more positional arguments
                try:
                    param = next(parameters)
                except StopIteration:
                    # No more parameters. That's it. Just need to check that
                    # we have no `kwargs` after this while loop
                    break
                else:
                    if param.kind == _VAR_POSITIONAL:
                        # That's OK, just empty *args.  Let's start parsing
                        # kwargs
                        break
                    elif param.name in kwargs:
                        if param.kind == _POSITIONAL_ONLY:
                            msg = '{arg!r} parameter is positional only, ' \
                                  'but was passed as a keyword'
                            msg = msg.format(arg=param.name)
                            raise TypeError(msg) from None
                        parameters_ex = (param,)
                        break
                    elif (param.kind == _VAR_KEYWORD or
                                                param.default is not _empty):
                        # That's fine too - we have a default value for this
                        # parameter.  So, lets start parsing `kwargs`, starting
                        # with the current parameter
                        parameters_ex = (param,)
                        break
                    else:
                        # No default, not VAR_KEYWORD, not VAR_POSITIONAL,
                        # not in `kwargs`
                        if partial:
                            parameters_ex = (param,)
                            break
                        else:
                            msg = 'missing a required argument: {arg!r}'
                            msg = msg.format(arg=param.name)
                            raise TypeError(msg) from None
            else:
                # We have a positional argument to process
                try:
                    param = next(parameters)
                except StopIteration:
                    raise TypeError('too many positional arguments') from None
                else:
                    if param.kind in (_VAR_KEYWORD, _KEYWORD_ONLY):
                        # Looks like we have no parameter for this positional
                        # argument
                        raise TypeError(
                            'too many positional arguments') from None
    
                    if param.kind == _VAR_POSITIONAL:
                        # We have an '*args'-like argument, let's fill it with
                        # all positional arguments we have left and move on to
                        # the next phase
                        values = [arg_val]
                        values.extend(arg_vals)
                        arguments[param.name] = tuple(values)
                        break
    
                    if param.name in kwargs and param.kind != _POSITIONAL_ONLY:
                        raise TypeError(
                            'multiple values for argument {arg!r}'.format(
                                arg=param.name)) from None
    
                    arguments[param.name] = arg_val
    
        # Now, we iterate through the remaining parameters to process
        # keyword arguments
        kwargs_param = None
        for param in itertools.chain(parameters_ex, parameters):
            if param.kind == _VAR_KEYWORD:
                # Memorize that we have a '**kwargs'-like parameter
                kwargs_param = param
                continue
    
            if param.kind == _VAR_POSITIONAL:
                # Named arguments don't refer to '*args'-like parameters.
                # We only arrive here if the positional arguments ended
                # before reaching the last parameter before *args.
                continue
    
            param_name = param.name
            try:
                arg_val = kwargs.pop(param_name)
            except KeyError:
                # We have no value for this parameter.  It's fine though,
                # if it has a default value, or it is an '*args'-like
                # parameter, left alone by the processing of positional
                # arguments.
                if (not partial and param.kind != _VAR_POSITIONAL and
                                                    param.default is _empty):
                    raise TypeError('missing a required argument: {arg!r}'. \
                                    format(arg=param_name)) from None
    
            else:
                if param.kind == _POSITIONAL_ONLY:
                    # This should never happen in case of a properly built
                    # Signature object (but let's have this check here
                    # to ensure correct behaviour just in case)
                    raise TypeError('{arg!r} parameter is positional only, '
                                    'but was passed as a keyword'. \
                                    format(arg=param.name))
    
                arguments[param_name] = arg_val
    
        if kwargs:
            if kwargs_param is not None:
                # Process our '**kwargs'-like parameter
                arguments[kwargs_param.name] = kwargs
            else:
>               raise TypeError(
                    'got an unexpected keyword argument {arg!r}'.format(
                        arg=next(iter(kwargs))))
E               TypeError: got an unexpected keyword argument 'input'

/opt/miniconda/envs/multienv/lib/python3.10/inspect.py:3166: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.RandomMixUpV2
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/augmentation/test_augmentation3.py::test_RandomResizedCrop[tensorflow-s2s-False] - tensorflow.python.framework.errors_impl.InvalidArgumentError: Exception encountered when calling ten...
FAILED kornia/augmentation/test_augmentation3.py::test_RandomRotation[tensorflow-s2s-False] - AttributeError: Exception encountered when calling tensorflow_RandomRotation.call().
FAILED kornia/augmentation/test_augmentation3.py::test_RandomCutMixV2[tensorflow-s2s-False] - ivy.utils.exceptions.IvyException: source code not available
FAILED kornia/augmentation/test_augmentation3.py::test_RandomJigsaw[tensorflow-s2s-False] - TypeError: got an unexpected keyword argument 'input'
FAILED kornia/augmentation/test_augmentation3.py::test_RandomMixUpV2[tensorflow-s2s-False] - TypeError: got an unexpected keyword argument 'input'
============================================================================== 5 failed, 11 passed in 3547.94s (0:59:07) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 16 items

kornia/augmentation/test_augmentation3.py .........F...FFF                                                                                                                                       [100%]

=============================================================================================== FAILURES ===============================================================================================
__________________________________________________________________________________ test_RandomRotation[jax-s2s-False] __________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_RandomRotation(target_framework, mode, backend_compile):
        print("kornia.augmentation.RandomRotation")
    
        init_args = ()
        init_kwargs = {"degrees": 45.0, "p": 1.}
        call_args = (torch.tensor([[1., 0., 0., 2.],
                                   [0., 0., 0., 0.],
                                   [0., 1., 2., 0.],
                                   [0., 0., 1., 2.]]),)
        call_kwargs = {}
    
>       _test_augmentation_class(
            kornia.augmentation.RandomRotation,
            target_framework,
            init_args,
            init_kwargs,
            call_args,
            call_kwargs,
            deterministic_output=False,
            backend_compile=backend_compile,
        )

kornia/augmentation/test_augmentation3.py:270: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

augmentation_cls = <class 'kornia.augmentation._2d.geometric.rotation.RandomRotation'>, target = 'jax', init_args = (), init_kwargs = {'degrees': 45.0, 'p': 1.0}
call_args = (tensor([[1., 0., 0., 2.],
        [0., 0., 0., 0.],
        [0., 1., 2., 0.],
        [0., 0., 1., 2.]]),), call_kwargs = {}, deterministic_output = False, backend_compile = False
tolerance = 0.001

    def _test_augmentation_class(
        augmentation_cls,
        target,
        init_args=(),
        init_kwargs={},
        call_args=(),
        call_kwargs={},
        deterministic_output=True,
        backend_compile=False,
        tolerance=1e-3,
    ):
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_cls = ivy.transpile(augmentation_cls, source="torch", target=target)
    
        torch_aug = augmentation_cls(*init_args, **init_kwargs)
        transpiled_init_args = _nest_torch_tensor_to_new_framework(init_args, target)
        transpiled_init_kwargs = _nest_torch_tensor_to_new_framework(init_kwargs, target)
        transpiled_aug = transpiled_cls(*transpiled_init_args, **transpiled_init_kwargs)
    
        # assert dir(torch_aug) == dir(transpiled_aug), f"attributes/methods of transpiled object do not align with the original - orig: {dir(torch_aug)} != transpiled: {dir(transpiled_aug)}"
    
        torch_out = torch_aug(*call_args, **call_kwargs)
        transpiled_call_args = _nest_torch_tensor_to_new_framework(call_args, target)
        transpiled_call_kwargs = _nest_torch_tensor_to_new_framework(call_kwargs, target)
>       transpiled_out = transpiled_aug(*transpiled_call_args, **transpiled_call_kwargs)

kornia/augmentation/test_augmentation3.py:43: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_RandomRotation(degrees=45.0, p=1.0, p_batch=1.0, same_on_batch=False, resample=bilinear, align_corners=True)
input = Array([[1., 0., 0., 2.],
       [0., 0., 0., 0.],
       [0., 1., 2., 0.],
       [0., 0., 1., 2.]], dtype=float32)
params = {'batch_prob': Array([1.], dtype=float32), 'degrees': Array([-35.516792], dtype=float32), 'forward_input_shape': Array([1, 1, 4, 4], dtype=int64)}, kwargs = {}
jax_shape_frnt_ = <function jax_shape_frnt_ at 0x7fd886396e60>, jax_set_item = <function jax_set_item at 0x7fd886ab1900>, tensor = <function jax_tensor_frnt at 0x7fd88646e830>
in_tensor = Array([[[[1., 0., 0., 2.],
         [0., 0., 0., 0.],
         [0., 1., 2., 0.],
         [0., 0., 1., 2.]]]], dtype=float32), input_shape = ivy.frontends.torch.Size([4, 4])
batch_shape = ivy.frontends.torch.Size([1, 1, 4, 4]), flags = {'align_corners': True, 'resample': <jax_Resample.BILINEAR: 1>}

    def __call__(self, input, params=None, **kwargs):
        from ...ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ...ivy.functional.backends.jax.general import jax_set_item
        from ..core._backend import tensor
    
        in_tensor = self.__unpack_input__(input)
        input_shape = jax_shape_frnt_(in_tensor)
        in_tensor = self.transform_tensor(in_tensor)
        batch_shape = jax_shape_frnt_(in_tensor)
        if params is None:
            params = self.forward_parameters(batch_shape)
        if "batch_prob" not in params:
            params = jax_set_item(params, "batch_prob", tensor([True] * batch_shape[0]))
        params, flags = self._process_kwargs_to_params_and_flags(
            params, self.flags, **kwargs
        )
>       output = self.apply_func(in_tensor, params, flags)

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/base.py:219: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_RandomRotation(degrees=45.0, p=1.0, p_batch=1.0, same_on_batch=False, resample=bilinear, align_corners=True)
in_tensor = Array([[[[1., 0., 0., 2.],
         [0., 0., 0., 0.],
         [0., 1., 2., 0.],
         [0., 0., 1., 2.]]]], dtype=float32)
params = {'batch_prob': Array([1.], dtype=float32), 'degrees': Array([-35.516792], dtype=float32), 'forward_input_shape': Array([1, 1, 4, 4], dtype=int64)}
flags = {'align_corners': True, 'resample': <jax_Resample.BILINEAR: 1>}

    def apply_func(self, in_tensor, params, flags=None):
        if flags is None:
            flags = self.flags
>       trans_matrix = self.generate_transformation_matrix(in_tensor, params, flags)

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/_2d/base.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_RandomRotation(degrees=45.0, p=1.0, p_batch=1.0, same_on_batch=False, resample=bilinear, align_corners=True)
input = Array([[[[1., 0., 0., 2.],
         [0., 0., 0., 0.],
         [0., 1., 2., 0.],
         [0., 0., 1., 2.]]]], dtype=float32)
params = {'batch_prob': Array([1.], dtype=float32), 'degrees': Array([-35.516792], dtype=float32), 'forward_input_shape': Array([1, 1, 4, 4], dtype=int64)}
flags = {'align_corners': True, 'resample': <jax_Resample.BILINEAR: 1>}

    def generate_transformation_matrix(self, input, params, flags):
        from ....ivy.functional.frontends.torch.tensor import jax_any_frnt_
        from ....ivy.functional.frontends.torch.tensor import jax_all_frnt_
        from ....ivy.functional.backends.jax.general import jax_get_item
        from ...utils.helpers import jax_is_autocast_enabled
        from ....ivy.functional.frontends.torch.tensor import jax_type_frnt_
        from ....ivy.functional.frontends.torch.tensor import jax_index_put_frnt_
    
        batch_prob = params["batch_prob"]
        to_apply = batch_prob > 0.5
        in_tensor = self.transform_tensor(input)
        if not jax_any_frnt_(to_apply):
            trans_matrix = self.identity_matrix(in_tensor)
        elif jax_all_frnt_(to_apply):
>           trans_matrix = self.compute_transformation(
                in_tensor, params=params, flags=flags
            )

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/_2d/base.py:88: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_RandomRotation(degrees=45.0, p=1.0, p_batch=1.0, same_on_batch=False, resample=bilinear, align_corners=True)
input = Array([[[[1., 0., 0., 2.],
         [0., 0., 0., 0.],
         [0., 1., 2., 0.],
         [0., 0., 1., 2.]]]], dtype=float32)
params = {'batch_prob': Array([1.], dtype=float32), 'degrees': Array([-35.516792], dtype=float32), 'forward_input_shape': Array([1, 1, 4, 4], dtype=int64)}
flags = {'align_corners': True, 'resample': <jax_Resample.BILINEAR: 1>}

    def compute_transformation(self, input, params, flags):
        from .....ivy.functional.frontends.torch.tensor import jax_to_frnt_
        from ....geometry.transform.affwarp import jax__compute_tensor_center
        from ....geometry.transform.affwarp import jax__compute_rotation_matrix
        from .....ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ....utils.misc import jax_eye_like
        from .....ivy.functional.backends.jax.general import jax_set_item
    
        angles: typing.Any = jax_to_frnt_(params["degrees"], input)
        center: typing.Any = jax__compute_tensor_center(input)
        rotation_mat: typing.Any = jax__compute_rotation_matrix(
>           angles, center.expand(jax_shape_frnt_(angles)[0], -1)
        )
E       AttributeError: 'jaxlib.xla_extension.ArrayImpl' object has no attribute 'expand'

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/_2d/geometric/rotation.py:66: AttributeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.RandomRotation
__________________________________________________________________________________ test_RandomCutMixV2[jax-s2s-False] __________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_RandomCutMixV2(target_framework, mode, backend_compile):
        print("kornia.augmentation.RandomCutMixV2")
    
        input = torch.rand(2, 1, 3, 3)
        input[0] = torch.ones((1, 3, 3))
        label = torch.tensor([0, 1])
    
        init_args = ()
        init_kwargs = {"data_keys": ["input", "class"]}
        call_args = (input, label)
        call_kwargs = {}
    
>       _test_augmentation_class(
            kornia.augmentation.RandomCutMixV2,
            target_framework,
            init_args,
            init_kwargs,
            call_args,
            call_kwargs,
            deterministic_output=False,
            backend_compile=backend_compile,
        )

kornia/augmentation/test_augmentation3.py:354: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

augmentation_cls = <class 'kornia.augmentation._2d.mix.cutmix.RandomCutMixV2'>, target = 'jax', init_args = (), init_kwargs = {'data_keys': ['input', 'class']}
call_args = (tensor([[[[1.0000, 1.0000, 1.0000],
          [1.0000, 1.0000, 1.0000],
          [1.0000, 1.0000, 1.0000]]],


        [[[0.3384, 0.2634, 0.7657],
          [0.0173, 0.7658, 0.0812],
          [0.8481, 0.4555, 0.9087]]]]), tensor([0, 1]))
call_kwargs = {}, deterministic_output = False, backend_compile = False, tolerance = 0.001

    def _test_augmentation_class(
        augmentation_cls,
        target,
        init_args=(),
        init_kwargs={},
        call_args=(),
        call_kwargs={},
        deterministic_output=True,
        backend_compile=False,
        tolerance=1e-3,
    ):
        if backend_compile or target == "numpy":
            pytest.skip()
    
>       transpiled_cls = ivy.transpile(augmentation_cls, source="torch", target=target)

kornia/augmentation/test_augmentation3.py:31: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

object = <class 'kornia.augmentation._2d.mix.cutmix.RandomCutMixV2'>, source = 'torch', target = 'jax', reuse_existing = True

    def transpile(
        object,
        source: str = "torch",
        target: str = "tensorflow",
        reuse_existing: bool = True,
    ):
        """Converts a given object (class/function) from one framework to another.
    
        This function performs source-to-source translation of a given object from the source framework
        to the target framework.
    
        The object can be translated between two frameworks or between the Ivy IR as well
        e.g. (source="torch_frontend", target="ivy") or (source="torch_frontend", target="tensorflow") etc.
    
        Args:
            object: The object (class/function) to be translated.
            source (str, optional): The source framework. Defaults to 'torch'.
            target (str, optional): The target framework. Defaults to 'tensorflow'.
            reuse_existing (bool, optional): If True, the function will check if `object`
                                             already exists in the translated directory and reuse it.
                                             If False, it will re-translate `object`,
                                             even if it already exists in the directory, and overwrite
                                             the old implementation. Defaults to 'True'.
    
        Returns:
            The translated object."""
    
        from ._compiler import transpile as _transpile
    
>       return _transpile(
            object=object,
            source=source,
            target=target,
            reuse_existing=reuse_existing,
        )

../ivy/ivy/compiler/compiler.py:201: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   ivy.utils.exceptions.IvyException: source code not available

IXC.pyx:379: IvyException
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.RandomCutMixV2
___________________________________________________________________________________ test_RandomJigsaw[jax-s2s-False] ___________________________________________________________________________________

inp = jax_DType.INT64 | jax_DType.FLOAT16 | jax_DType.FLOAT32 | jax_DType.FLOAT64, query = '2', kwargs = {}

    @functools.wraps(fn)
    def wrapper(inp, query, **kwargs):
        try:
>           res = inp.__getitem__(query)

ivy_transpiled_outputs/jax_outputs/ivy/utils/decorator_utils.py:219: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = jax_DType.INT64 | jax_DType.FLOAT16 | jax_DType.FLOAT32 | jax_DType.FLOAT64, name = '2'

    def __getitem__(cls, name):
>       return cls._member_map_[name]
E       KeyError: '2'

/opt/miniconda/envs/multienv/lib/python3.10/enum.py:432: KeyError

During handling of the above exception, another exception occurred:

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_RandomJigsaw(target_framework, mode, backend_compile):
        print("kornia.augmentation.RandomJigsaw")
    
        init_args = ((4, 4),)
        init_kwargs = {}
        call_args = (torch.randn(8, 3, 256, 256),)
        call_kwargs = {}
    
>       _test_augmentation_class(
            kornia.augmentation.RandomJigsaw,
            target_framework,
            init_args,
            init_kwargs,
            call_args,
            call_kwargs,
            deterministic_output=False,
            backend_compile=backend_compile,
        )

kornia/augmentation/test_augmentation3.py:374: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

augmentation_cls = <class 'kornia.augmentation._2d.mix.jigsaw.RandomJigsaw'>, target = 'jax', init_args = ((4, 4),), init_kwargs = {}
call_args = (tensor([[[[-6.3045e-01,  1.0565e+00, -5.4284e-01,  ..., -4.2372e-01,
           -3.6639e-01,  3.3574e-01],
          ...7e-01],
          [ 1.6237e+00,  7.6656e-01, -1.6112e+00,  ...,  1.0082e-01,
            7.6385e-01, -4.4559e-01]]]]),)
call_kwargs = {}, deterministic_output = False, backend_compile = False, tolerance = 0.001

    def _test_augmentation_class(
        augmentation_cls,
        target,
        init_args=(),
        init_kwargs={},
        call_args=(),
        call_kwargs={},
        deterministic_output=True,
        backend_compile=False,
        tolerance=1e-3,
    ):
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_cls = ivy.transpile(augmentation_cls, source="torch", target=target)
    
        torch_aug = augmentation_cls(*init_args, **init_kwargs)
        transpiled_init_args = _nest_torch_tensor_to_new_framework(init_args, target)
        transpiled_init_kwargs = _nest_torch_tensor_to_new_framework(init_kwargs, target)
        transpiled_aug = transpiled_cls(*transpiled_init_args, **transpiled_init_kwargs)
    
        # assert dir(torch_aug) == dir(transpiled_aug), f"attributes/methods of transpiled object do not align with the original - orig: {dir(torch_aug)} != transpiled: {dir(transpiled_aug)}"
    
        torch_out = torch_aug(*call_args, **call_kwargs)
        transpiled_call_args = _nest_torch_tensor_to_new_framework(call_args, target)
        transpiled_call_kwargs = _nest_torch_tensor_to_new_framework(call_kwargs, target)
>       transpiled_out = transpiled_aug(*transpiled_call_args, **transpiled_call_kwargs)

kornia/augmentation/test_augmentation3.py:43: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_RandomJigsaw(grid=(4, 4), p=0.5, p_batch=1.0, same_on_batch=False, grid=(4, 4)), params = None, data_keys = None
input = (Array([[[[-6.30445600e-01,  1.05645072e+00, -5.42844474e-01, ...,
          -4.23722953e-01, -3.66389036e-01,  3.3574...59303e-01, -1.61117721e+00, ...,
           1.00815378e-01,  7.63846099e-01, -4.45586145e-01]]]],      dtype=float32),)
tensor = <function jax_tensor_frnt at 0x7fd89918a7a0>

    def __call__(self, *input, params=None, data_keys=None):
        from ....core._backend import tensor
        from .....ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ....geometry.boxes import jax_Boxes
        from .....ivy.functional.backends.jax.general import jax_get_item
        from ....constants import jax_DType
        from ....core.check import jax_KORNIA_UNWRAP
    
        keys: typing.Any
        if data_keys is None:
            keys = self.data_keys
        else:
            keys = [jax_DataKey.get(inp) for inp in data_keys]
        if params is None:
            in_tensor_idx: typing.Any = keys.index(jax_DataKey.INPUT)
            in_tensor: typing.Any = jax_get_item(input, in_tensor_idx)
            in_tensor = self.transform_tensor(in_tensor)
            self._params = self.forward_parameters(jax_shape_frnt_(in_tensor))
>           self._params.update({"dtype": tensor(jax_DType.get(in_tensor.dtype).value)})

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/_2d/mix/base.py:193: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = jax_DType.INT64 | jax_DType.FLOAT16 | jax_DType.FLOAT32 | jax_DType.FLOAT64, value = dtype('float32')

    @classmethod
    def get(cls, value):
        from ..ivy.functional.backends.jax.general import jax_get_item
        from ..ivy.functional.frontends.torch.tensor import jax_item_frnt_
    
        if isinstance(value, (np.dtype,)):
>           return jax_get_item(cls, str(value).upper()[6:])

ivy_transpiled_outputs/jax_outputs/kornia/constants.py:77: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

inp = jax_DType.INT64 | jax_DType.FLOAT16 | jax_DType.FLOAT32 | jax_DType.FLOAT64, query = '2', kwargs = {}

    @functools.wraps(fn)
    def wrapper(inp, query, **kwargs):
        try:
            res = inp.__getitem__(query)
        except Exception:
>           res = fn(inp, query, **kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/utils/decorator_utils.py:221: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (jax_DType.INT64 | jax_DType.FLOAT16 | jax_DType.FLOAT32 | jax_DType.FLOAT64, '2'), kwargs = {}, handle_mixed_in_backend = True

    @functools.wraps(fn)
    def _handle_partial_mixed_function(*args, **kwargs):
        handle_mixed_in_backend = False
        if not hasattr(fn, "partial_mixed_handler"):
            handle_mixed_in_backend = True
        else:
            compos = getattr(fn, "compos")
            condition = getattr(fn, "partial_mixed_handler")
        if handle_mixed_in_backend or condition(*args, **kwargs):
>           return fn(*args, **kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/func_wrapper.py:160: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = jax_DType.INT64 | jax_DType.FLOAT16 | jax_DType.FLOAT32 | jax_DType.FLOAT64, query = '2'

    @jax_handle_get_item
    @jax_handle_partial_mixed_function
    def jax_get_item(
        x: jax.Array, /, query: Union[jax.Array, Tuple], *, copy: Optional[bool] = None
    ):
        from ...ivy.general import jax_is_array_bknd
        from ...ivy.data_type import jax_is_bool_dtype_bknd
    
        if copy:
            x = x.copy()
        if jax_is_array_bknd(query) and jax_is_bool_dtype_bknd(query):
            if not len(query.shape):
                if not query:
                    return jax.numpy.array([], dtype=x.dtype)
                else:
                    return jax.numpy.expand_dims(x, 0)
            query = jax__mask_to_index(query, x)
        elif isinstance(query, list):
            query = (query,)
>       return x.__getitem__(query)

ivy_transpiled_outputs/jax_outputs/ivy/functional/backends/jax/general.py:86: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = jax_DType.INT64 | jax_DType.FLOAT16 | jax_DType.FLOAT32 | jax_DType.FLOAT64, name = '2'

    def __getitem__(cls, name):
>       return cls._member_map_[name]
E       KeyError: '2'

/opt/miniconda/envs/multienv/lib/python3.10/enum.py:432: KeyError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.RandomJigsaw
__________________________________________________________________________________ test_RandomMixUpV2[jax-s2s-False] ___________________________________________________________________________________

inp = jax_DType.INT64 | jax_DType.FLOAT16 | jax_DType.FLOAT32 | jax_DType.FLOAT64, query = '2', kwargs = {}

    @functools.wraps(fn)
    def wrapper(inp, query, **kwargs):
        try:
>           res = inp.__getitem__(query)

ivy_transpiled_outputs/jax_outputs/ivy/utils/decorator_utils.py:219: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = jax_DType.INT64 | jax_DType.FLOAT16 | jax_DType.FLOAT32 | jax_DType.FLOAT64, name = '2'

    def __getitem__(cls, name):
>       return cls._member_map_[name]
E       KeyError: '2'

/opt/miniconda/envs/multienv/lib/python3.10/enum.py:432: KeyError

During handling of the above exception, another exception occurred:

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_RandomMixUpV2(target_framework, mode, backend_compile):
        print("kornia.augmentation.RandomMixUpV2")
    
        init_args = ()
        init_kwargs = {"data_keys": ["input", "class"]}
        call_args = (torch.rand(2, 1, 3, 3), torch.tensor([0, 1]))
        call_kwargs = {}
    
>       _test_augmentation_class(
            kornia.augmentation.RandomMixUpV2,
            target_framework,
            init_args,
            init_kwargs,
            call_args,
            call_kwargs,
            deterministic_output=False,
            backend_compile=backend_compile,
        )

kornia/augmentation/test_augmentation3.py:394: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

augmentation_cls = <class 'kornia.augmentation._2d.mix.mixup.RandomMixUpV2'>, target = 'jax', init_args = (), init_kwargs = {'data_keys': ['input', 'class']}
call_args = (tensor([[[[0.3563, 0.6665, 0.2938],
          [0.8030, 0.5310, 0.1615],
          [0.8123, 0.8288, 0.3962]]],


        [[[0.7557, 0.6248, 0.0705],
          [0.3517, 0.3616, 0.5995],
          [0.0178, 0.9666, 0.3833]]]]), tensor([0, 1]))
call_kwargs = {}, deterministic_output = False, backend_compile = False, tolerance = 0.001

    def _test_augmentation_class(
        augmentation_cls,
        target,
        init_args=(),
        init_kwargs={},
        call_args=(),
        call_kwargs={},
        deterministic_output=True,
        backend_compile=False,
        tolerance=1e-3,
    ):
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_cls = ivy.transpile(augmentation_cls, source="torch", target=target)
    
        torch_aug = augmentation_cls(*init_args, **init_kwargs)
        transpiled_init_args = _nest_torch_tensor_to_new_framework(init_args, target)
        transpiled_init_kwargs = _nest_torch_tensor_to_new_framework(init_kwargs, target)
        transpiled_aug = transpiled_cls(*transpiled_init_args, **transpiled_init_kwargs)
    
        # assert dir(torch_aug) == dir(transpiled_aug), f"attributes/methods of transpiled object do not align with the original - orig: {dir(torch_aug)} != transpiled: {dir(transpiled_aug)}"
    
        torch_out = torch_aug(*call_args, **call_kwargs)
        transpiled_call_args = _nest_torch_tensor_to_new_framework(call_args, target)
        transpiled_call_kwargs = _nest_torch_tensor_to_new_framework(call_kwargs, target)
>       transpiled_out = transpiled_aug(*transpiled_call_args, **transpiled_call_kwargs)

kornia/augmentation/test_augmentation3.py:43: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_RandomMixUpV2(lambda_val=None, p=1.0, p_batch=1.0, same_on_batch=False), params = None, data_keys = None
input = (Array([[[[0.35628146, 0.66649544, 0.29376185],
         [0.8029844 , 0.5309778 , 0.16150957],
         [0.8123236 , 0... 0.36164355, 0.5994901 ],
         [0.0177862 , 0.9666002 , 0.38328743]]]], dtype=float32), Array([0, 1], dtype=int64))
tensor = <function jax_tensor_frnt at 0x7fd899c96320>

    def __call__(self, *input, params=None, data_keys=None):
        from ....core._backend import tensor
        from .....ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ....geometry.boxes import jax_Boxes
        from .....ivy.functional.backends.jax.general import jax_get_item
        from ....constants import jax_DType
        from ....core.check import jax_KORNIA_UNWRAP
    
        keys: typing.Any
        if data_keys is None:
            keys = self.data_keys
        else:
            keys = [jax_DataKey.get(inp) for inp in data_keys]
        if params is None:
            in_tensor_idx: typing.Any = keys.index(jax_DataKey.INPUT)
            in_tensor: typing.Any = jax_get_item(input, in_tensor_idx)
            in_tensor = self.transform_tensor(in_tensor)
            self._params = self.forward_parameters(jax_shape_frnt_(in_tensor))
>           self._params.update({"dtype": tensor(jax_DType.get(in_tensor.dtype).value)})

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/_2d/mix/base.py:193: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = jax_DType.INT64 | jax_DType.FLOAT16 | jax_DType.FLOAT32 | jax_DType.FLOAT64, value = dtype('float32')

    @classmethod
    def get(cls, value):
        from ..ivy.functional.backends.jax.general import jax_get_item
        from ..ivy.functional.frontends.torch.tensor import jax_item_frnt_
    
        if isinstance(value, (np.dtype,)):
>           return jax_get_item(cls, str(value).upper()[6:])

ivy_transpiled_outputs/jax_outputs/kornia/constants.py:77: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

inp = jax_DType.INT64 | jax_DType.FLOAT16 | jax_DType.FLOAT32 | jax_DType.FLOAT64, query = '2', kwargs = {}

    @functools.wraps(fn)
    def wrapper(inp, query, **kwargs):
        try:
            res = inp.__getitem__(query)
        except Exception:
>           res = fn(inp, query, **kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/utils/decorator_utils.py:221: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (jax_DType.INT64 | jax_DType.FLOAT16 | jax_DType.FLOAT32 | jax_DType.FLOAT64, '2'), kwargs = {}, handle_mixed_in_backend = True

    @functools.wraps(fn)
    def _handle_partial_mixed_function(*args, **kwargs):
        handle_mixed_in_backend = False
        if not hasattr(fn, "partial_mixed_handler"):
            handle_mixed_in_backend = True
        else:
            compos = getattr(fn, "compos")
            condition = getattr(fn, "partial_mixed_handler")
        if handle_mixed_in_backend or condition(*args, **kwargs):
>           return fn(*args, **kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/func_wrapper.py:160: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = jax_DType.INT64 | jax_DType.FLOAT16 | jax_DType.FLOAT32 | jax_DType.FLOAT64, query = '2'

    @jax_handle_get_item
    @jax_handle_partial_mixed_function
    def jax_get_item(
        x: jax.Array, /, query: Union[jax.Array, Tuple], *, copy: Optional[bool] = None
    ):
        from ...ivy.general import jax_is_array_bknd
        from ...ivy.data_type import jax_is_bool_dtype_bknd
    
        if copy:
            x = x.copy()
        if jax_is_array_bknd(query) and jax_is_bool_dtype_bknd(query):
            if not len(query.shape):
                if not query:
                    return jax.numpy.array([], dtype=x.dtype)
                else:
                    return jax.numpy.expand_dims(x, 0)
            query = jax__mask_to_index(query, x)
        elif isinstance(query, list):
            query = (query,)
>       return x.__getitem__(query)

ivy_transpiled_outputs/jax_outputs/ivy/functional/backends/jax/general.py:86: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = jax_DType.INT64 | jax_DType.FLOAT16 | jax_DType.FLOAT32 | jax_DType.FLOAT64, name = '2'

    def __getitem__(cls, name):
>       return cls._member_map_[name]
E       KeyError: '2'

/opt/miniconda/envs/multienv/lib/python3.10/enum.py:432: KeyError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.RandomMixUpV2
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/augmentation/test_augmentation3.py::test_RandomRotation[jax-s2s-False] - AttributeError: 'jaxlib.xla_extension.ArrayImpl' object has no attribute 'expand'
FAILED kornia/augmentation/test_augmentation3.py::test_RandomCutMixV2[jax-s2s-False] - ivy.utils.exceptions.IvyException: source code not available
FAILED kornia/augmentation/test_augmentation3.py::test_RandomJigsaw[jax-s2s-False] - KeyError: '2'
FAILED kornia/augmentation/test_augmentation3.py::test_RandomMixUpV2[jax-s2s-False] - KeyError: '2'
============================================================================== 4 failed, 12 passed in 3198.41s (0:53:18) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 56 items

kornia/geometry/test_transform.py ........................F..................F............                                                                                                       [100%]

=============================================================================================== FAILURES ===============================================================================================
__________________________________________________________________________________ test_upscale_double[jax-s2s-False] __________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_upscale_double(target_framework, mode, backend_compile):
        trace_args = (
            torch.rand(1, 3, 4, 4),
        )
        trace_kwargs = {}
        test_args = (
            torch.rand(5, 3, 8, 8),
        )
        test_kwargs = {}
>       _test_function(
            kornia.geometry.transform.upscale_double,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/geometry/test_transform.py:612: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function upscale_double at 0x7f4f38356440>
trace_args = (tensor([[[[7.1985e-01, 2.5993e-01, 2.5130e-01, 2.5171e-01],
          [8.2950e-01, 4.1691e-01, 7.1781e-01, 6.8377e-01...     [8.4871e-01, 3.3344e-01, 9.9600e-01, 5.7987e-01],
          [1.7064e-01, 1.5834e-01, 4.1345e-01, 3.5059e-01]]]]),)
trace_kwargs = {}
test_args = (tensor([[[[2.3515e-01, 7.8014e-02, 1.2824e-01, 7.0006e-01, 9.6828e-02,
           5.3484e-01, 3.5696e-01, 3.0171e-01]...      [3.7070e-01, 3.8147e-03, 4.1569e-01, 3.4899e-01, 9.2283e-01,
           3.3135e-01, 7.2280e-01, 8.0558e-02]]]]),)
test_kwargs = {}, target = 'jax', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function upscale_double at 0x7f4f38356440>, fn_name = 'kornia.geometry.transform.upscale_double'
trace_args = (tensor([[[[7.1985e-01, 2.5993e-01, 2.5130e-01, 2.5171e-01],
          [8.2950e-01, 4.1691e-01, 7.1781e-01, 6.8377e-01...     [8.4871e-01, 3.3344e-01, 9.9600e-01, 5.7987e-01],
          [1.7064e-01, 1.5834e-01, 4.1345e-01, 3.5059e-01]]]]),)
trace_kwargs = {}
test_args = (tensor([[[[2.3515e-01, 7.8014e-02, 1.2824e-01, 7.0006e-01, 9.6828e-02,
           5.3484e-01, 3.5696e-01, 3.0171e-01]...      [3.7070e-01, 3.8147e-03, 4.1569e-01, 3.4899e-01, 9.2283e-01,
           3.3135e-01, 7.2280e-01, 8.0558e-02]]]]),)
test_kwargs = {}, target = 'jax', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = Array([[[[7.1984994e-01, 2.5992608e-01, 2.5129747e-01, 2.5170511e-01],
         [8.2949883e-01, 4.1690654e-01, 7.17812...9797e-01, 5.7987100e-01],
         [1.7064214e-01, 1.5833682e-01, 4.1345072e-01, 3.5058928e-01]]]],      dtype=float32)

    def jax_upscale_double(x):
        from ...core._backend import zeros
        from ...core.check import jax_KORNIA_CHECK_IS_TENSOR
        from ...core.check import jax_KORNIA_CHECK_SHAPE
        from ....ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ....ivy.functional.backends.jax.general import jax_set_item
    
        jax_KORNIA_CHECK_IS_TENSOR(x)
        jax_KORNIA_CHECK_SHAPE(x, ["*", "H", "W"])
        double_shape = jax_shape_frnt_(x)[:-2] + (
            jax_shape_frnt_(x)[-2] * 2,
            jax_shape_frnt_(x)[-1] * 2,
        )
        upscaled = zeros(double_shape, device=x.device, dtype=x.dtype)
        upscaled = jax_set_item(
            upscaled, (..., slice(None, None, 2), slice(None, None, 2)), x
        )
>       upscaled[..., ::2, 1::2] = jax_set_item(
            upscaled[..., ::2, 1::2],
            (..., slice(None, -1, None)),
            (upscaled[..., ::2, ::2][..., :-1] + upscaled[..., ::2, 2::2]) / 2,
        )

ivy_transpiled_outputs/jax_outputs/kornia/geometry/transform/pyramid.py:45: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = Array([[[[7.1984994e-01, 0.0000000e+00, 2.5992608e-01, 0.0000000e+00,
          2.5129747e-01, 0.0000000e+00, 2.517051...00000e+00, 0.0000000e+00,
          0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00]]]],      dtype=float32)
i = (Ellipsis, slice(None, None, 2), slice(1, None, 2))
x = Array([[[[0.489888  , 0.25561178, 0.2515013 , 0.        ],
         [0.6232027 , 0.5673595 , 0.70079225, 0.        ],
... 0.6647188 , 0.7879345 , 0.        ],
         [0.16448948, 0.28589377, 0.38202   , 0.        ]]]],      dtype=float32)

    def _unimplemented_setitem(self, i, x):
      msg = ("'{}' object does not support item assignment. JAX arrays are "
             "immutable. Instead of ``x[idx] = y``, use ``x = x.at[idx].set(y)`` "
             "or another .at[] method: "
             "https://jax.readthedocs.io/en/latest/_autosummary/jax.numpy.ndarray.at.html")
>     raise TypeError(msg.format(type(self)))
E     TypeError: '<class 'jaxlib.xla_extension.ArrayImpl'>' object does not support item assignment. JAX arrays are immutable. Instead of ``x[idx] = y``, use ``x = x.at[idx].set(y)`` or another .at[] method: https://jax.readthedocs.io/en/latest/_autosummary/jax.numpy.ndarray.at.html

/opt/fw/jax/jax/_src/numpy/array_methods.py:587: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.transform.pyramid.upscale_double
______________________________________________________________________________________ test_Shear[jax-s2s-False] _______________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_Shear(target_framework, mode, backend_compile):
        print("kornia.geometry.transform.Shear")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledShear = ivy.transpile(kornia.geometry.transform.Shear, source="torch", target=target_framework)
    
        x = torch.rand(2, 3, 4, 4)
        shear = torch.tensor([[0.5, 0.0], [0.0, 0.5]])
        torch_out = kornia.geometry.transform.Shear(shear)(x)
    
        transpiled_x = _nest_torch_tensor_to_new_framework(x, target_framework)
        transpiled_shear = _nest_torch_tensor_to_new_framework(shear, target_framework)
>       transpiled_out = TranspiledShear(transpiled_shear)(transpiled_x)

kornia/geometry/test_transform.py:1156: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_Shear()
input = Array([[[[0.01095188, 0.0601756 , 0.05077767, 0.32277012],
         [0.6666105 , 0.6835883 , 0.12661201, 0.8802613 ],
... 0.35046262, 0.85852414, 0.38285798],
         [0.0651955 , 0.36587632, 0.47101676, 0.88226384]]]],      dtype=float32)

    def __call__(self, input):
>       return shear(
            input, self.shear, self.mode, self.padding_mode, self.align_corners
        )
E       NameError: name 'shear' is not defined

ivy_transpiled_outputs/jax_outputs/kornia/geometry/transform/affwarp.py:52: NameError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.transform.Shear
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/geometry/test_transform.py::test_upscale_double[jax-s2s-False] - TypeError: '<class 'jaxlib.xla_extension.ArrayImpl'>' object does not support item assignment. JAX arrays are immutabl...
FAILED kornia/geometry/test_transform.py::test_Shear[jax-s2s-False] - NameError: name 'shear' is not defined
============================================================================== 2 failed, 54 passed in 5198.52s (1:26:38) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 2 items

kornia/geometry/test_vector.py ..                                                                                                                                                                [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
==================================================================================== 2 passed in 143.18s (0:02:23) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 8 items

kornia/geometry/test_homography.py FFFF.F.F                                                                                                                                                      [100%]

=============================================================================================== FAILURES ===============================================================================================
______________________________________________________________________________ test_find_homography_dlt[numpy-s2s-False] _______________________________________________________________________________

target_framework = 'numpy', mode = 's2s', backend_compile = False

    def test_find_homography_dlt(target_framework, mode, backend_compile):
        trace_args = (
            torch.rand(1, 4, 2),
            torch.rand(1, 4, 2),
        )
        trace_kwargs = {'weights': torch.rand(1, 4), 'solver': 'svd'}
        test_args = (
            torch.rand(5, 4, 2),
            torch.rand(5, 4, 2),
        )
        test_kwargs = {'weights': torch.rand(5, 4), 'solver': 'svd'}
>       _test_function(
            kornia.geometry.homography.find_homography_dlt,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=5e-2,
            mode=mode,
            # NOTE: numerical instability in svd()/lu() leads to logits not being allclose
            deterministic=False,
        )

kornia/geometry/test_homography.py:20: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function find_homography_dlt at 0x7fbf7fac5000>
trace_args = (tensor([[[0.5714, 0.5765],
         [0.3298, 0.2976],
         [0.5012, 0.9563],
         [0.0619, 0.4175]]]), tensor([[[0.5761, 0.1421],
         [0.0106, 0.6541],
         [0.8671, 0.1405],
         [0.0273, 0.4535]]]))
trace_kwargs = {'solver': 'svd', 'weights': tensor([[0.7978, 0.9942, 0.1014, 0.3885]])}
test_args = (tensor([[[0.5110, 0.7435],
         [0.2005, 0.2087],
         [0.4745, 0.4695],
         [0.9486, 0.4470]],

       ...9782]],

        [[0.3533, 0.2425],
         [0.2474, 0.8875],
         [0.4315, 0.9206],
         [0.9742, 0.5333]]]))
test_kwargs = {'solver': 'svd', 'weights': tensor([[0.3472, 0.7929, 0.5505, 0.9921],
        [0.7720, 0.5845, 0.2314, 0.5558],
        [0.6134, 0.5658, 0.5805, 0.4806],
        [0.5120, 0.4940, 0.9562, 0.1386],
        [0.4550, 0.2470, 0.6582, 0.5117]])}
target = 'numpy', backend_compile = False, tolerance = 0.05, mode = 's2s', skip = False, deterministic = False, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function find_homography_dlt at 0x7fbf7fac5000>, fn_name = 'kornia.geometry.homography.find_homography_dlt'
trace_args = (tensor([[[0.5714, 0.5765],
         [0.3298, 0.2976],
         [0.5012, 0.9563],
         [0.0619, 0.4175]]]), tensor([[[0.5761, 0.1421],
         [0.0106, 0.6541],
         [0.8671, 0.1405],
         [0.0273, 0.4535]]]))
trace_kwargs = {'solver': 'svd', 'weights': tensor([[0.7978, 0.9942, 0.1014, 0.3885]])}
test_args = (tensor([[[0.5110, 0.7435],
         [0.2005, 0.2087],
         [0.4745, 0.4695],
         [0.9486, 0.4470]],

       ...9782]],

        [[0.3533, 0.2425],
         [0.2474, 0.8875],
         [0.4315, 0.9206],
         [0.9742, 0.5333]]]))
test_kwargs = {'solver': 'svd', 'weights': tensor([[0.3472, 0.7929, 0.5505, 0.9921],
        [0.7720, 0.5845, 0.2314, 0.5558],
        [0.6134, 0.5658, 0.5805, 0.4806],
        [0.5120, 0.4940, 0.9562, 0.1386],
        [0.4550, 0.2470, 0.6582, 0.5117]])}
target = 'numpy', backend_compile = False, tolerance = 0.05, deterministic = False, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

points1 = array([[[0.5714476 , 0.5765153 ],
        [0.32980758, 0.29763907],
        [0.50119376, 0.95633847],
        [0.06185526, 0.41754878]]], dtype=float32)
points2 = array([[[0.57613385, 0.14211988],
        [0.01060241, 0.65413207],
        [0.86707205, 0.14049906],
        [0.0272972 , 0.45351052]]], dtype=float32)
weights = array([[0.79781216, 0.99420744, 0.10144269, 0.3885135 ]], dtype=float32), solver = 'svd'

    def numpy_find_homography_dlt(points1, points2, weights=None, solver="lu"):
        from ...ivy.functional.frontends.torch.tensor import numpy_shape_frnt_
        from ..core.check import numpy_KORNIA_CHECK_SHAPE
        from ..utils.helpers import numpy__extract_device_dtype
        from .epipolar.fundamental import numpy_normalize_points
        from ...ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            numpy_chunk_frnt,
        )
        from ...ivy.functional.frontends.torch.creation_ops import (
            numpy_ones_like_v_0p4p0_and_above_frnt,
        )
        from ...ivy.functional.frontends.torch.creation_ops import numpy_zeros_like_frnt
        from ...ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            numpy_cat_frnt,
        )
        from ...ivy.functional.frontends.torch.tensor import numpy_reshape_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_transpose_frnt_
        from ...ivy.functional.frontends.torch.miscellaneous_ops import (
            numpy_diag_embed_frnt,
        )
        from ...ivy.functional.frontends.torch.tensor import numpy_repeat_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_unsqueeze_frnt_
        from ..utils.helpers import numpy__torch_svd_cast
        from ...ivy.functional.frontends.torch.creation_ops import numpy_empty_frnt
        from ...ivy.functional.frontends.torch.tensor import numpy_size_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_view_frnt_
        from ...ivy.functional.frontends.torch.creation_ops import numpy_ones_frnt
        from ..utils.helpers import numpy_safe_solve_with_mask
        from ..utils.helpers import numpy_safe_inverse_with_mask
    
        if numpy_shape_frnt_(points1) != numpy_shape_frnt_(points2):
            raise AssertionError(numpy_shape_frnt_(points1))
        if numpy_shape_frnt_(points1)[1] < 4:
            raise AssertionError(numpy_shape_frnt_(points1))
        numpy_KORNIA_CHECK_SHAPE(points1, ["B", "N", "2"])
        numpy_KORNIA_CHECK_SHAPE(points2, ["B", "N", "2"])
        device, dtype = numpy__extract_device_dtype([points1, points2])
        eps: typing.Any = 1e-08
        points1_norm, transform1 = numpy_normalize_points(points1)
        points2_norm, transform2 = numpy_normalize_points(points2)
        x1, y1 = numpy_chunk_frnt(points1_norm, dim=-1, chunks=2)
        x2, y2 = numpy_chunk_frnt(points2_norm, dim=-1, chunks=2)
        ones, zeros = numpy_ones_like_v_0p4p0_and_above_frnt(x1), numpy_zeros_like_frnt(x1)
        ax = numpy_cat_frnt(
            [zeros, zeros, zeros, -x1, -y1, -ones, y2 * x1, y2 * y1, y2], dim=-1
        )
        ay = numpy_cat_frnt(
            [x1, y1, ones, zeros, zeros, zeros, -x2 * x1, -x2 * y1, -x2], dim=-1
        )
        A = numpy_reshape_frnt_(
            numpy_cat_frnt((ax, ay), dim=-1),
            numpy_shape_frnt_(ax)[0],
            -1,
            numpy_shape_frnt_(ax)[-1],
        )
        if weights is None:
            A = numpy_transpose_frnt_(A, -2, -1) @ A
        else:
            if not (
                len(numpy_shape_frnt_(weights)) == 2
                and numpy_shape_frnt_(weights) == numpy_shape_frnt_(points1)[:2]
            ):
                raise AssertionError(numpy_shape_frnt_(weights))
>           w_diag = numpy_diag_embed_frnt(
                numpy_reshape_frnt_(
                    numpy_repeat_frnt_(numpy_unsqueeze_frnt_(weights, dim=-1), 1, 1, 2),
                    numpy_shape_frnt_(weights)[0],
                    -1,
                )
            )

ivy_transpiled_outputs/numpy_outputs/kornia/geometry/homography.py:94: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = array([[[0.79781216, 0.79781216, 0.99420744, 0.99420744, 0.10144269,
         0.10144269, 0.3885135 , 0.3885135 ]]], dtype=float32), offset = 0, dim1 = 1, dim2 = 2

    def numpy_diag_embed_frnt(input, offset=0, dim1=-2, dim2=-1):
        from ...backends.numpy.data_type import numpy_dtype
        from .tensor import numpy_ndim_frnt_
        from .tensor import numpy_shape_frnt_
        from ...backends.numpy.general import numpy_set_item
        from ...backends.numpy.creation import numpy_zeros
        from ...backends.numpy.manipulation import numpy_concat
        from ....data_classes.array.experimental.manipulation import numpy_moveaxis_bknd_
        from ....data_classes.array.manipulation import numpy_expand_dims_bknd_
        from ...backends.numpy.creation import numpy_arange
        from .tensor import numpy_reshape_frnt_
        from .tensor import numpy_logical_and_frnt_
        from ...backends.numpy.searching import numpy_where
        from ....data_classes.array.data_type import numpy_astype_bknd_
    
        def _handle_dim(rank, idx):
            if idx >= 0 and idx < rank:
                return idx
            if idx < 0:
                idx = idx + rank
            if idx < 0 or idx >= rank:
                raise IndexError
            return idx
    
        input_type = numpy_dtype(input)
        rank = numpy_ndim_frnt_(input) + 1
        dim1 = _handle_dim(rank, dim1)
        dim2 = _handle_dim(rank, dim2)
        if dim1 > dim2:
            dim1, dim2 = dim2, dim1
            offset = -offset
        last_dim = list(numpy_shape_frnt_(input))[-1]
        if offset != 0:
            t_shape = list(numpy_shape_frnt_(input))
            t_shape = numpy_set_item(t_shape, -1, abs(offset))
            z = numpy_zeros(t_shape, dtype=input.dtype, device=None)
            pair = (z, input) if offset > 0 else (input, z)
            input = numpy_concat(pair, axis=-1)
            last_dim = last_dim + abs(offset)
        input = numpy_moveaxis_bknd_(numpy_expand_dims_bknd_(input, axis=dim1), -1, dim2)
        a_range = numpy_arange(last_dim, device=None, dtype=np.int64)
        b_range = numpy_arange(offset, last_dim + offset, device=None, dtype=np.int64)
        cond = a_range == numpy_expand_dims_bknd_(b_range, axis=-1)
        ag__result_list_0 = []
        for i in range(len(numpy_shape_frnt_(input))):
            res = last_dim if i in (dim1, dim2) else 1
            ag__result_list_0.append(res)
        cond_shape = ag__result_list_0
        cond = numpy_reshape_frnt_(cond, cond_shape)
>       if input.dtype == np.bool:

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/miscellaneous_ops.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

attr = 'bool'

    def __getattr__(attr):
        # Warn for expired attributes, and return a dummy function
        # that always raises an exception.
        import warnings
        import math
        try:
            msg = __expired_functions__[attr]
        except KeyError:
            pass
        else:
            warnings.warn(msg, DeprecationWarning, stacklevel=2)
    
            def _expired(*args, **kwds):
                raise RuntimeError(msg)
    
            return _expired
    
        # Emit warnings for deprecated attributes
        try:
            val, msg = __deprecated_attrs__[attr]
        except KeyError:
            pass
        else:
            warnings.warn(msg, DeprecationWarning, stacklevel=2)
            return val
    
        if attr in __future_scalars__:
            # And future warnings for those that will change, but also give
            # the AttributeError
            warnings.warn(
                f"In the future `np.{attr}` will be defined as the "
                "corresponding NumPy scalar.", FutureWarning, stacklevel=2)
    
        if attr in __former_attrs__:
>           raise AttributeError(__former_attrs__[attr])
E           AttributeError: module 'numpy' has no attribute 'bool'.
E           `np.bool` was a deprecated alias for the builtin `bool`. To avoid this error in existing code, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
E           The aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:
E               https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations. Did you mean: 'bool_'?

/opt/fw/mxnet/numpy/__init__.py:324: AttributeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.homography.find_homography_dlt
----------------------------------------------------------------------------------------- Captured stderr call -----------------------------------------------------------------------------------------
/ivy/ivy-integration-tests/ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/miscellaneous_ops.py:79: FutureWarning: In the future `np.bool` will be defined as the corresponding NumPy scalar.
  if input.dtype == np.bool:
__________________________________________________________________________ test_find_homography_dlt_iterated[numpy-s2s-False] __________________________________________________________________________

target_framework = 'numpy', mode = 's2s', backend_compile = False

    def test_find_homography_dlt_iterated(target_framework, mode, backend_compile):
        trace_args = (
            torch.rand(1, 4, 2),
            torch.rand(1, 4, 2),
            torch.rand(1, 4),
        )
        trace_kwargs = {'soft_inl_th': 3.0, 'n_iter': 5}
        test_args = (
            torch.rand(5, 4, 2),
            torch.rand(5, 4, 2),
            torch.rand(5, 4),
        )
        test_kwargs = {'soft_inl_th': 4.0, 'n_iter': 5}
>       _test_function(
            kornia.geometry.homography.find_homography_dlt_iterated,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=5e-2,
            mode=mode,
            # NOTE: numerical instability in svd()/lu() leads to logits not being allclose
            deterministic=False,
        )

kornia/geometry/test_homography.py:48: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function find_homography_dlt_iterated at 0x7fbf7fac5120>
trace_args = (tensor([[[0.8717, 0.6450],
         [0.4105, 0.8544],
         [0.5544, 0.5780],
         [0.7839, 0.4279]]]), tensor... [0.6952, 0.3678],
         [0.3589, 0.9284],
         [0.8740, 0.7237]]]), tensor([[0.6367, 0.3343, 0.9451, 0.2279]]))
trace_kwargs = {'n_iter': 5, 'soft_inl_th': 3.0}
test_args = (tensor([[[0.4753, 0.7371],
         [0.0028, 0.9429],
         [0.2944, 0.3329],
         [0.3229, 0.7267]],

       ...[0.4305, 0.7496, 0.8198, 0.4736],
        [0.1619, 0.3570, 0.3490, 0.4479],
        [0.3007, 0.4870, 0.7016, 0.2800]]))
test_kwargs = {'n_iter': 5, 'soft_inl_th': 4.0}, target = 'numpy', backend_compile = False, tolerance = 0.05, mode = 's2s', skip = False, deterministic = False, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function find_homography_dlt_iterated at 0x7fbf7fac5120>, fn_name = 'kornia.geometry.homography.find_homography_dlt_iterated'
trace_args = (tensor([[[0.8717, 0.6450],
         [0.4105, 0.8544],
         [0.5544, 0.5780],
         [0.7839, 0.4279]]]), tensor... [0.6952, 0.3678],
         [0.3589, 0.9284],
         [0.8740, 0.7237]]]), tensor([[0.6367, 0.3343, 0.9451, 0.2279]]))
trace_kwargs = {'n_iter': 5, 'soft_inl_th': 3.0}
test_args = (tensor([[[0.4753, 0.7371],
         [0.0028, 0.9429],
         [0.2944, 0.3329],
         [0.3229, 0.7267]],

       ...[0.4305, 0.7496, 0.8198, 0.4736],
        [0.1619, 0.3570, 0.3490, 0.4479],
        [0.3007, 0.4870, 0.7016, 0.2800]]))
test_kwargs = {'n_iter': 5, 'soft_inl_th': 4.0}, target = 'numpy', backend_compile = False, tolerance = 0.05, deterministic = False, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

points1 = array([[[0.8716789 , 0.6449632 ],
        [0.41047877, 0.8543593 ],
        [0.55442107, 0.57795566],
        [0.7839362 , 0.42789108]]], dtype=float32)
points2 = array([[[0.98402226, 0.3672983 ],
        [0.69518846, 0.36778784],
        [0.35889733, 0.92838013],
        [0.87397754, 0.72372365]]], dtype=float32)
weights = array([[0.63666993, 0.3342734 , 0.94505906, 0.22786355]], dtype=float32), soft_inl_th = 3.0, n_iter = 5

    def numpy_find_homography_dlt_iterated(
        points1, points2, weights, soft_inl_th=3.0, n_iter=5
    ):
        from ...ivy.functional.frontends.torch.pointwise_ops import numpy_exp_frnt
    
>       H: typing.Any = numpy_find_homography_dlt(points1, points2, weights)

ivy_transpiled_outputs/numpy_outputs/kornia/geometry/homography.py:183: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

points1 = array([[[0.8716789 , 0.6449632 ],
        [0.41047877, 0.8543593 ],
        [0.55442107, 0.57795566],
        [0.7839362 , 0.42789108]]], dtype=float32)
points2 = array([[[0.98402226, 0.3672983 ],
        [0.69518846, 0.36778784],
        [0.35889733, 0.92838013],
        [0.87397754, 0.72372365]]], dtype=float32)
weights = array([[0.63666993, 0.3342734 , 0.94505906, 0.22786355]], dtype=float32), solver = 'lu'

    def numpy_find_homography_dlt(points1, points2, weights=None, solver="lu"):
        from ...ivy.functional.frontends.torch.tensor import numpy_shape_frnt_
        from ..core.check import numpy_KORNIA_CHECK_SHAPE
        from ..utils.helpers import numpy__extract_device_dtype
        from .epipolar.fundamental import numpy_normalize_points
        from ...ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            numpy_chunk_frnt,
        )
        from ...ivy.functional.frontends.torch.creation_ops import (
            numpy_ones_like_v_0p4p0_and_above_frnt,
        )
        from ...ivy.functional.frontends.torch.creation_ops import numpy_zeros_like_frnt
        from ...ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            numpy_cat_frnt,
        )
        from ...ivy.functional.frontends.torch.tensor import numpy_reshape_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_transpose_frnt_
        from ...ivy.functional.frontends.torch.miscellaneous_ops import (
            numpy_diag_embed_frnt,
        )
        from ...ivy.functional.frontends.torch.tensor import numpy_repeat_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_unsqueeze_frnt_
        from ..utils.helpers import numpy__torch_svd_cast
        from ...ivy.functional.frontends.torch.creation_ops import numpy_empty_frnt
        from ...ivy.functional.frontends.torch.tensor import numpy_size_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_view_frnt_
        from ...ivy.functional.frontends.torch.creation_ops import numpy_ones_frnt
        from ..utils.helpers import numpy_safe_solve_with_mask
        from ..utils.helpers import numpy_safe_inverse_with_mask
    
        if numpy_shape_frnt_(points1) != numpy_shape_frnt_(points2):
            raise AssertionError(numpy_shape_frnt_(points1))
        if numpy_shape_frnt_(points1)[1] < 4:
            raise AssertionError(numpy_shape_frnt_(points1))
        numpy_KORNIA_CHECK_SHAPE(points1, ["B", "N", "2"])
        numpy_KORNIA_CHECK_SHAPE(points2, ["B", "N", "2"])
        device, dtype = numpy__extract_device_dtype([points1, points2])
        eps: typing.Any = 1e-08
        points1_norm, transform1 = numpy_normalize_points(points1)
        points2_norm, transform2 = numpy_normalize_points(points2)
        x1, y1 = numpy_chunk_frnt(points1_norm, dim=-1, chunks=2)
        x2, y2 = numpy_chunk_frnt(points2_norm, dim=-1, chunks=2)
        ones, zeros = numpy_ones_like_v_0p4p0_and_above_frnt(x1), numpy_zeros_like_frnt(x1)
        ax = numpy_cat_frnt(
            [zeros, zeros, zeros, -x1, -y1, -ones, y2 * x1, y2 * y1, y2], dim=-1
        )
        ay = numpy_cat_frnt(
            [x1, y1, ones, zeros, zeros, zeros, -x2 * x1, -x2 * y1, -x2], dim=-1
        )
        A = numpy_reshape_frnt_(
            numpy_cat_frnt((ax, ay), dim=-1),
            numpy_shape_frnt_(ax)[0],
            -1,
            numpy_shape_frnt_(ax)[-1],
        )
        if weights is None:
            A = numpy_transpose_frnt_(A, -2, -1) @ A
        else:
            if not (
                len(numpy_shape_frnt_(weights)) == 2
                and numpy_shape_frnt_(weights) == numpy_shape_frnt_(points1)[:2]
            ):
                raise AssertionError(numpy_shape_frnt_(weights))
>           w_diag = numpy_diag_embed_frnt(
                numpy_reshape_frnt_(
                    numpy_repeat_frnt_(numpy_unsqueeze_frnt_(weights, dim=-1), 1, 1, 2),
                    numpy_shape_frnt_(weights)[0],
                    -1,
                )
            )

ivy_transpiled_outputs/numpy_outputs/kornia/geometry/homography.py:148: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = array([[[0.63666993, 0.63666993, 0.3342734 , 0.3342734 , 0.94505906,
         0.94505906, 0.22786355, 0.22786355]]], dtype=float32), offset = 0, dim1 = 1, dim2 = 2

    def numpy_diag_embed_frnt(input, offset=0, dim1=-2, dim2=-1):
        from ...backends.numpy.data_type import numpy_dtype
        from .tensor import numpy_ndim_frnt_
        from .tensor import numpy_shape_frnt_
        from ...backends.numpy.general import numpy_set_item
        from ...backends.numpy.creation import numpy_zeros
        from ...backends.numpy.manipulation import numpy_concat
        from ....data_classes.array.experimental.manipulation import numpy_moveaxis_bknd_
        from ....data_classes.array.manipulation import numpy_expand_dims_bknd_
        from ...backends.numpy.creation import numpy_arange
        from .tensor import numpy_reshape_frnt_
        from .tensor import numpy_logical_and_frnt_
        from ...backends.numpy.searching import numpy_where
        from ....data_classes.array.data_type import numpy_astype_bknd_
    
        def _handle_dim(rank, idx):
            if idx >= 0 and idx < rank:
                return idx
            if idx < 0:
                idx = idx + rank
            if idx < 0 or idx >= rank:
                raise IndexError
            return idx
    
        input_type = numpy_dtype(input)
        rank = numpy_ndim_frnt_(input) + 1
        dim1 = _handle_dim(rank, dim1)
        dim2 = _handle_dim(rank, dim2)
        if dim1 > dim2:
            dim1, dim2 = dim2, dim1
            offset = -offset
        last_dim = list(numpy_shape_frnt_(input))[-1]
        if offset != 0:
            t_shape = list(numpy_shape_frnt_(input))
            t_shape = numpy_set_item(t_shape, -1, abs(offset))
            z = numpy_zeros(t_shape, dtype=input.dtype, device=None)
            pair = (z, input) if offset > 0 else (input, z)
            input = numpy_concat(pair, axis=-1)
            last_dim = last_dim + abs(offset)
        input = numpy_moveaxis_bknd_(numpy_expand_dims_bknd_(input, axis=dim1), -1, dim2)
        a_range = numpy_arange(last_dim, device=None, dtype=np.int64)
        b_range = numpy_arange(offset, last_dim + offset, device=None, dtype=np.int64)
        cond = a_range == numpy_expand_dims_bknd_(b_range, axis=-1)
        ag__result_list_0 = []
        for i in range(len(numpy_shape_frnt_(input))):
            res = last_dim if i in (dim1, dim2) else 1
            ag__result_list_0.append(res)
        cond_shape = ag__result_list_0
        cond = numpy_reshape_frnt_(cond, cond_shape)
>       if input.dtype == np.bool:

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/miscellaneous_ops.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

attr = 'bool'

    def __getattr__(attr):
        # Warn for expired attributes, and return a dummy function
        # that always raises an exception.
        import warnings
        import math
        try:
            msg = __expired_functions__[attr]
        except KeyError:
            pass
        else:
            warnings.warn(msg, DeprecationWarning, stacklevel=2)
    
            def _expired(*args, **kwds):
                raise RuntimeError(msg)
    
            return _expired
    
        # Emit warnings for deprecated attributes
        try:
            val, msg = __deprecated_attrs__[attr]
        except KeyError:
            pass
        else:
            warnings.warn(msg, DeprecationWarning, stacklevel=2)
            return val
    
        if attr in __future_scalars__:
            # And future warnings for those that will change, but also give
            # the AttributeError
            warnings.warn(
                f"In the future `np.{attr}` will be defined as the "
                "corresponding NumPy scalar.", FutureWarning, stacklevel=2)
    
        if attr in __former_attrs__:
>           raise AttributeError(__former_attrs__[attr])
E           AttributeError: module 'numpy' has no attribute 'bool'.
E           `np.bool` was a deprecated alias for the builtin `bool`. To avoid this error in existing code, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
E           The aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:
E               https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations. Did you mean: 'bool_'?

/opt/fw/mxnet/numpy/__init__.py:324: AttributeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.homography.find_homography_dlt_iterated
----------------------------------------------------------------------------------------- Captured stderr call -----------------------------------------------------------------------------------------
/ivy/ivy-integration-tests/ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/miscellaneous_ops.py:79: FutureWarning: In the future `np.bool` will be defined as the corresponding NumPy scalar.
  if input.dtype == np.bool:
___________________________________________________________________________ test_find_homography_lines_dlt[numpy-s2s-False] ____________________________________________________________________________

target_framework = 'numpy', mode = 's2s', backend_compile = False

    def test_find_homography_lines_dlt(target_framework, mode, backend_compile):
        trace_args = (
            torch.rand(1, 4, 2, 2),
            torch.rand(1, 4, 2, 2),
        )
        trace_kwargs = {'weights': torch.rand(1, 4)}
        test_args = (
            torch.rand(5, 4, 2, 2),
            torch.rand(5, 4, 2, 2),
        )
        test_kwargs = {'weights': torch.rand(5, 4)}
>       _test_function(
            kornia.geometry.homography.find_homography_lines_dlt,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=5e-2,
            mode=mode,
            # NOTE: numerical instability in svd()/lu() leads to logits not being allclose
            deterministic=False,
        )

kornia/geometry/test_homography.py:74: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function find_homography_lines_dlt at 0x7fbf7fac5240>
trace_args = (tensor([[[[0.7787, 0.8796],
          [0.3447, 0.6320]],

         [[0.2943, 0.1006],
          [0.1116, 0.2560]],

 ...

         [[0.9038, 0.8705],
          [0.7163, 0.4558]],

         [[0.9791, 0.1160],
          [0.1893, 0.4524]]]]))
trace_kwargs = {'weights': tensor([[0.9661, 0.6312, 0.3653, 0.1306]])}
test_args = (tensor([[[[0.8265, 0.5157],
          [0.0831, 0.9474]],

         [[0.1400, 0.5097],
          [0.4332, 0.9028]],

 ...

         [[0.1049, 0.4307],
          [0.0287, 0.1174]],

         [[0.2054, 0.6814],
          [0.7174, 0.1832]]]]))
test_kwargs = {'weights': tensor([[6.4352e-01, 2.2722e-02, 9.5574e-01, 7.0648e-01],
        [1.7190e-01, 4.6233e-01, 9.5321e-01, 4.9...,
        [1.9877e-01, 2.6249e-01, 7.7198e-01, 7.5971e-01],
        [1.8346e-01, 4.7319e-01, 6.7800e-02, 1.8501e-01]])}
target = 'numpy', backend_compile = False, tolerance = 0.05, mode = 's2s', skip = False, deterministic = False, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function find_homography_lines_dlt at 0x7fbf7fac5240>, fn_name = 'kornia.geometry.homography.find_homography_lines_dlt'
trace_args = (tensor([[[[0.7787, 0.8796],
          [0.3447, 0.6320]],

         [[0.2943, 0.1006],
          [0.1116, 0.2560]],

 ...

         [[0.9038, 0.8705],
          [0.7163, 0.4558]],

         [[0.9791, 0.1160],
          [0.1893, 0.4524]]]]))
trace_kwargs = {'weights': tensor([[0.9661, 0.6312, 0.3653, 0.1306]])}
test_args = (tensor([[[[0.8265, 0.5157],
          [0.0831, 0.9474]],

         [[0.1400, 0.5097],
          [0.4332, 0.9028]],

 ...

         [[0.1049, 0.4307],
          [0.0287, 0.1174]],

         [[0.2054, 0.6814],
          [0.7174, 0.1832]]]]))
test_kwargs = {'weights': tensor([[6.4352e-01, 2.2722e-02, 9.5574e-01, 7.0648e-01],
        [1.7190e-01, 4.6233e-01, 9.5321e-01, 4.9...,
        [1.9877e-01, 2.6249e-01, 7.7198e-01, 7.5971e-01],
        [1.8346e-01, 4.7319e-01, 6.7800e-02, 1.8501e-01]])}
target = 'numpy', backend_compile = False, tolerance = 0.05, deterministic = False, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

ls1 = array([[[[0.7787262 , 0.8796424 ],
         [0.34472162, 0.6319532 ]],

        [[0.294268  , 0.10056424],
         [0...    [0.09318668, 0.1606757 ]],

        [[0.29938096, 0.51975286],
         [0.39184773, 0.10033631]]]], dtype=float32)
ls2 = array([[[[0.6422936 , 0.4305094 ],
         [0.16250461, 0.05871403]],

        [[0.21733093, 0.5989208 ],
         [0...    [0.71626955, 0.45582718]],

        [[0.97911435, 0.11600155],
         [0.18928349, 0.45239598]]]], dtype=float32)
weights = array([[0.966089  , 0.6312103 , 0.36531305, 0.13064402]], dtype=float32)

    def numpy_find_homography_lines_dlt(ls1, ls2, weights=None):
        from ...ivy.functional.frontends.torch.tensor import numpy_shape_frnt_
        from ..core.check import numpy_KORNIA_CHECK_SHAPE
        from ..utils.helpers import numpy__extract_device_dtype
        from ...ivy.functional.frontends.torch.tensor import numpy_reshape_frnt_
        from .epipolar.fundamental import numpy_normalize_points
        from ...ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            numpy_chunk_frnt,
        )
        from ...ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            numpy_cat_frnt,
        )
        from ...ivy.functional.frontends.torch.tensor import numpy_transpose_frnt_
        from ...ivy.functional.frontends.torch.miscellaneous_ops import (
            numpy_diag_embed_frnt,
        )
        from ...ivy.functional.frontends.torch.tensor import numpy_repeat_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_unsqueeze_frnt_
        from ..utils.helpers import numpy__torch_svd_cast
        from ...ivy.functional.frontends.torch.creation_ops import numpy_empty_frnt
        from ...ivy.functional.frontends.torch.tensor import numpy_size_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_view_frnt_
        from ..utils.helpers import numpy_safe_inverse_with_mask
    
        if len(numpy_shape_frnt_(ls1)) == 3:
            ls1 = ls1[None]
        if len(numpy_shape_frnt_(ls2)) == 3:
            ls2 = ls2[None]
        numpy_KORNIA_CHECK_SHAPE(ls1, ["B", "N", "2", "2"])
        numpy_KORNIA_CHECK_SHAPE(ls2, ["B", "N", "2", "2"])
        BS, N = numpy_shape_frnt_(ls1)[:2][0], numpy_shape_frnt_(ls1)[:2][1]
        device, dtype = numpy__extract_device_dtype([ls1, ls2])
        points1 = numpy_reshape_frnt_(ls1, BS, 2 * N, 2)
        points2 = numpy_reshape_frnt_(ls2, BS, 2 * N, 2)
        points1_norm, transform1 = numpy_normalize_points(points1)
        points2_norm, transform2 = numpy_normalize_points(points2)
        lst1, le1 = numpy_chunk_frnt(points1_norm, dim=1, chunks=2)
        lst2, le2 = numpy_chunk_frnt(points2_norm, dim=1, chunks=2)
        xs1, ys1 = numpy_chunk_frnt(lst1, dim=-1, chunks=2)
        xs2, ys2 = numpy_chunk_frnt(lst2, dim=-1, chunks=2)
        xe1, ye1 = numpy_chunk_frnt(le1, dim=-1, chunks=2)
        xe2, ye2 = numpy_chunk_frnt(le2, dim=-1, chunks=2)
        A = ys2 - ye2
        B = xe2 - xs2
        C = xs2 * ye2 - xe2 * ys2
        eps: typing.Any = 1e-08
        ax = numpy_cat_frnt(
            [A * xs1, A * ys1, A, B * xs1, B * ys1, B, C * xs1, C * ys1, C], dim=-1
        )
        ay = numpy_cat_frnt(
            [A * xe1, A * ye1, A, B * xe1, B * ye1, B, C * xe1, C * ye1, C], dim=-1
        )
        A = numpy_reshape_frnt_(
            numpy_cat_frnt((ax, ay), dim=-1),
            numpy_shape_frnt_(ax)[0],
            -1,
            numpy_shape_frnt_(ax)[-1],
        )
        if weights is None:
            A = numpy_transpose_frnt_(A, -2, -1) @ A
        else:
            if not (
                len(numpy_shape_frnt_(weights)) == 2
                and numpy_shape_frnt_(weights) == numpy_shape_frnt_(ls1)[:2]
            ):
                raise AssertionError(numpy_shape_frnt_(weights))
>           w_diag = numpy_diag_embed_frnt(
                numpy_reshape_frnt_(
                    numpy_repeat_frnt_(numpy_unsqueeze_frnt_(weights, dim=-1), 1, 1, 2),
                    numpy_shape_frnt_(weights)[0],
                    -1,
                )
            )

ivy_transpiled_outputs/numpy_outputs/kornia/geometry/homography.py:97: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = array([[[0.966089  , 0.966089  , 0.6312103 , 0.6312103 , 0.36531305,
         0.36531305, 0.13064402, 0.13064402]]], dtype=float32), offset = 0, dim1 = 1, dim2 = 2

    def numpy_diag_embed_frnt(input, offset=0, dim1=-2, dim2=-1):
        from ...backends.numpy.data_type import numpy_dtype
        from .tensor import numpy_ndim_frnt_
        from .tensor import numpy_shape_frnt_
        from ...backends.numpy.general import numpy_set_item
        from ...backends.numpy.creation import numpy_zeros
        from ...backends.numpy.manipulation import numpy_concat
        from ....data_classes.array.experimental.manipulation import numpy_moveaxis_bknd_
        from ....data_classes.array.manipulation import numpy_expand_dims_bknd_
        from ...backends.numpy.creation import numpy_arange
        from .tensor import numpy_reshape_frnt_
        from .tensor import numpy_logical_and_frnt_
        from ...backends.numpy.searching import numpy_where
        from ....data_classes.array.data_type import numpy_astype_bknd_
    
        def _handle_dim(rank, idx):
            if idx >= 0 and idx < rank:
                return idx
            if idx < 0:
                idx = idx + rank
            if idx < 0 or idx >= rank:
                raise IndexError
            return idx
    
        input_type = numpy_dtype(input)
        rank = numpy_ndim_frnt_(input) + 1
        dim1 = _handle_dim(rank, dim1)
        dim2 = _handle_dim(rank, dim2)
        if dim1 > dim2:
            dim1, dim2 = dim2, dim1
            offset = -offset
        last_dim = list(numpy_shape_frnt_(input))[-1]
        if offset != 0:
            t_shape = list(numpy_shape_frnt_(input))
            t_shape = numpy_set_item(t_shape, -1, abs(offset))
            z = numpy_zeros(t_shape, dtype=input.dtype, device=None)
            pair = (z, input) if offset > 0 else (input, z)
            input = numpy_concat(pair, axis=-1)
            last_dim = last_dim + abs(offset)
        input = numpy_moveaxis_bknd_(numpy_expand_dims_bknd_(input, axis=dim1), -1, dim2)
        a_range = numpy_arange(last_dim, device=None, dtype=np.int64)
        b_range = numpy_arange(offset, last_dim + offset, device=None, dtype=np.int64)
        cond = a_range == numpy_expand_dims_bknd_(b_range, axis=-1)
        ag__result_list_0 = []
        for i in range(len(numpy_shape_frnt_(input))):
            res = last_dim if i in (dim1, dim2) else 1
            ag__result_list_0.append(res)
        cond_shape = ag__result_list_0
        cond = numpy_reshape_frnt_(cond, cond_shape)
>       if input.dtype == np.bool:

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/miscellaneous_ops.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

attr = 'bool'

    def __getattr__(attr):
        # Warn for expired attributes, and return a dummy function
        # that always raises an exception.
        import warnings
        import math
        try:
            msg = __expired_functions__[attr]
        except KeyError:
            pass
        else:
            warnings.warn(msg, DeprecationWarning, stacklevel=2)
    
            def _expired(*args, **kwds):
                raise RuntimeError(msg)
    
            return _expired
    
        # Emit warnings for deprecated attributes
        try:
            val, msg = __deprecated_attrs__[attr]
        except KeyError:
            pass
        else:
            warnings.warn(msg, DeprecationWarning, stacklevel=2)
            return val
    
        if attr in __future_scalars__:
            # And future warnings for those that will change, but also give
            # the AttributeError
            warnings.warn(
                f"In the future `np.{attr}` will be defined as the "
                "corresponding NumPy scalar.", FutureWarning, stacklevel=2)
    
        if attr in __former_attrs__:
>           raise AttributeError(__former_attrs__[attr])
E           AttributeError: module 'numpy' has no attribute 'bool'.
E           `np.bool` was a deprecated alias for the builtin `bool`. To avoid this error in existing code, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
E           The aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:
E               https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations. Did you mean: 'bool_'?

/opt/fw/mxnet/numpy/__init__.py:324: AttributeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.homography.find_homography_lines_dlt
----------------------------------------------------------------------------------------- Captured stderr call -----------------------------------------------------------------------------------------
/ivy/ivy-integration-tests/ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/miscellaneous_ops.py:79: FutureWarning: In the future `np.bool` will be defined as the corresponding NumPy scalar.
  if input.dtype == np.bool:
_______________________________________________________________________ test_find_homography_lines_dlt_iterated[numpy-s2s-False] _______________________________________________________________________

target_framework = 'numpy', mode = 's2s', backend_compile = False

    def test_find_homography_lines_dlt_iterated(target_framework, mode, backend_compile):
        trace_args = (
            torch.rand(1, 4, 2, 2),
            torch.rand(1, 4, 2, 2),
            torch.rand(1, 4),
        )
        trace_kwargs = {'soft_inl_th': 4.0, 'n_iter': 5}
        test_args = (
            torch.rand(5, 4, 2, 2),
            torch.rand(5, 4, 2, 2),
            torch.rand(5, 4),
        )
        test_kwargs = {'soft_inl_th': 3.0, 'n_iter': 5}
>       _test_function(
            kornia.geometry.homography.find_homography_lines_dlt_iterated,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=5e-2,
            mode=mode,
            # NOTE: numerical instability in svd()/lu() leads to logits not being allclose
            deterministic=False,
        )

kornia/geometry/test_homography.py:102: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function find_homography_lines_dlt_iterated at 0x7fbf7fac5360>
trace_args = (tensor([[[[0.8235, 0.4719],
          [0.0362, 0.7583]],

         [[0.9131, 0.6939],
          [0.4755, 0.4625]],

 ...010, 0.7711]],

         [[0.7945, 0.6926],
          [0.3807, 0.3791]]]]), tensor([[0.4610, 0.8013, 0.4787, 0.9278]]))
trace_kwargs = {'n_iter': 5, 'soft_inl_th': 4.0}
test_args = (tensor([[[[0.2551, 0.9040],
          [0.8597, 0.0957]],

         [[0.4169, 0.5279],
          [0.9000, 0.3368]],

 ...[0.7936, 0.2950, 0.5257, 0.9207],
        [0.9833, 0.4489, 0.8023, 0.1190],
        [0.8754, 0.5288, 0.7490, 0.1886]]))
test_kwargs = {'n_iter': 5, 'soft_inl_th': 3.0}, target = 'numpy', backend_compile = False, tolerance = 0.05, mode = 's2s', skip = False, deterministic = False, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function find_homography_lines_dlt_iterated at 0x7fbf7fac5360>, fn_name = 'kornia.geometry.homography.find_homography_lines_dlt_iterated'
trace_args = (tensor([[[[0.8235, 0.4719],
          [0.0362, 0.7583]],

         [[0.9131, 0.6939],
          [0.4755, 0.4625]],

 ...010, 0.7711]],

         [[0.7945, 0.6926],
          [0.3807, 0.3791]]]]), tensor([[0.4610, 0.8013, 0.4787, 0.9278]]))
trace_kwargs = {'n_iter': 5, 'soft_inl_th': 4.0}
test_args = (tensor([[[[0.2551, 0.9040],
          [0.8597, 0.0957]],

         [[0.4169, 0.5279],
          [0.9000, 0.3368]],

 ...[0.7936, 0.2950, 0.5257, 0.9207],
        [0.9833, 0.4489, 0.8023, 0.1190],
        [0.8754, 0.5288, 0.7490, 0.1886]]))
test_kwargs = {'n_iter': 5, 'soft_inl_th': 3.0}, target = 'numpy', backend_compile = False, tolerance = 0.05, deterministic = False, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

ls1 = array([[[[0.8235131 , 0.47191185],
         [0.03624719, 0.75829315]],

        [[0.91311854, 0.69390345],
         [0...    [0.7993547 , 0.9594772 ]],

        [[0.6242079 , 0.21815753],
         [0.7606606 , 0.12783253]]]], dtype=float32)
ls2 = array([[[[0.26453066, 0.76029617],
         [0.5336867 , 0.43892926]],

        [[0.938549  , 0.78343844],
         [0...    [0.10103065, 0.7711163 ]],

        [[0.7944755 , 0.6926189 ],
         [0.38074005, 0.379126  ]]]], dtype=float32)
weights = array([[0.46104223, 0.80126655, 0.47873807, 0.9277615 ]], dtype=float32), soft_inl_th = 4.0, n_iter = 5

    def numpy_find_homography_lines_dlt_iterated(
        ls1, ls2, weights, soft_inl_th=4.0, n_iter=5
    ):
        from ...ivy.functional.frontends.torch.pointwise_ops import numpy_exp_frnt
    
>       H: typing.Any = numpy_find_homography_lines_dlt(ls1, ls2, weights)

ivy_transpiled_outputs/numpy_outputs/kornia/geometry/homography.py:159: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

ls1 = array([[[[0.8235131 , 0.47191185],
         [0.03624719, 0.75829315]],

        [[0.91311854, 0.69390345],
         [0...    [0.7993547 , 0.9594772 ]],

        [[0.6242079 , 0.21815753],
         [0.7606606 , 0.12783253]]]], dtype=float32)
ls2 = array([[[[0.26453066, 0.76029617],
         [0.5336867 , 0.43892926]],

        [[0.938549  , 0.78343844],
         [0...    [0.10103065, 0.7711163 ]],

        [[0.7944755 , 0.6926189 ],
         [0.38074005, 0.379126  ]]]], dtype=float32)
weights = array([[0.46104223, 0.80126655, 0.47873807, 0.9277615 ]], dtype=float32)

    def numpy_find_homography_lines_dlt(ls1, ls2, weights=None):
        from ...ivy.functional.frontends.torch.tensor import numpy_shape_frnt_
        from ..core.check import numpy_KORNIA_CHECK_SHAPE
        from ..utils.helpers import numpy__extract_device_dtype
        from ...ivy.functional.frontends.torch.tensor import numpy_reshape_frnt_
        from .epipolar.fundamental import numpy_normalize_points
        from ...ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            numpy_chunk_frnt,
        )
        from ...ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            numpy_cat_frnt,
        )
        from ...ivy.functional.frontends.torch.tensor import numpy_transpose_frnt_
        from ...ivy.functional.frontends.torch.miscellaneous_ops import (
            numpy_diag_embed_frnt,
        )
        from ...ivy.functional.frontends.torch.tensor import numpy_repeat_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_unsqueeze_frnt_
        from ..utils.helpers import numpy__torch_svd_cast
        from ...ivy.functional.frontends.torch.creation_ops import numpy_empty_frnt
        from ...ivy.functional.frontends.torch.tensor import numpy_size_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_view_frnt_
        from ..utils.helpers import numpy_safe_inverse_with_mask
    
        if len(numpy_shape_frnt_(ls1)) == 3:
            ls1 = ls1[None]
        if len(numpy_shape_frnt_(ls2)) == 3:
            ls2 = ls2[None]
        numpy_KORNIA_CHECK_SHAPE(ls1, ["B", "N", "2", "2"])
        numpy_KORNIA_CHECK_SHAPE(ls2, ["B", "N", "2", "2"])
        BS, N = numpy_shape_frnt_(ls1)[:2][0], numpy_shape_frnt_(ls1)[:2][1]
        device, dtype = numpy__extract_device_dtype([ls1, ls2])
        points1 = numpy_reshape_frnt_(ls1, BS, 2 * N, 2)
        points2 = numpy_reshape_frnt_(ls2, BS, 2 * N, 2)
        points1_norm, transform1 = numpy_normalize_points(points1)
        points2_norm, transform2 = numpy_normalize_points(points2)
        lst1, le1 = numpy_chunk_frnt(points1_norm, dim=1, chunks=2)
        lst2, le2 = numpy_chunk_frnt(points2_norm, dim=1, chunks=2)
        xs1, ys1 = numpy_chunk_frnt(lst1, dim=-1, chunks=2)
        xs2, ys2 = numpy_chunk_frnt(lst2, dim=-1, chunks=2)
        xe1, ye1 = numpy_chunk_frnt(le1, dim=-1, chunks=2)
        xe2, ye2 = numpy_chunk_frnt(le2, dim=-1, chunks=2)
        A = ys2 - ye2
        B = xe2 - xs2
        C = xs2 * ye2 - xe2 * ys2
        eps: typing.Any = 1e-08
        ax = numpy_cat_frnt(
            [A * xs1, A * ys1, A, B * xs1, B * ys1, B, C * xs1, C * ys1, C], dim=-1
        )
        ay = numpy_cat_frnt(
            [A * xe1, A * ye1, A, B * xe1, B * ye1, B, C * xe1, C * ye1, C], dim=-1
        )
        A = numpy_reshape_frnt_(
            numpy_cat_frnt((ax, ay), dim=-1),
            numpy_shape_frnt_(ax)[0],
            -1,
            numpy_shape_frnt_(ax)[-1],
        )
        if weights is None:
            A = numpy_transpose_frnt_(A, -2, -1) @ A
        else:
            if not (
                len(numpy_shape_frnt_(weights)) == 2
                and numpy_shape_frnt_(weights) == numpy_shape_frnt_(ls1)[:2]
            ):
                raise AssertionError(numpy_shape_frnt_(weights))
>           w_diag = numpy_diag_embed_frnt(
                numpy_reshape_frnt_(
                    numpy_repeat_frnt_(numpy_unsqueeze_frnt_(weights, dim=-1), 1, 1, 2),
                    numpy_shape_frnt_(weights)[0],
                    -1,
                )
            )

ivy_transpiled_outputs/numpy_outputs/kornia/geometry/homography.py:133: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = array([[[0.46104223, 0.46104223, 0.80126655, 0.80126655, 0.47873807,
         0.47873807, 0.9277615 , 0.9277615 ]]], dtype=float32), offset = 0, dim1 = 1, dim2 = 2

    def numpy_diag_embed_frnt(input, offset=0, dim1=-2, dim2=-1):
        from ...backends.numpy.data_type import numpy_dtype
        from .tensor import numpy_ndim_frnt_
        from .tensor import numpy_shape_frnt_
        from ...backends.numpy.general import numpy_set_item
        from ...backends.numpy.creation import numpy_zeros
        from ...backends.numpy.manipulation import numpy_concat
        from ....data_classes.array.experimental.manipulation import numpy_moveaxis_bknd_
        from ....data_classes.array.manipulation import numpy_expand_dims_bknd_
        from ...backends.numpy.creation import numpy_arange
        from .tensor import numpy_reshape_frnt_
        from .tensor import numpy_logical_and_frnt_
        from ...backends.numpy.searching import numpy_where
        from ....data_classes.array.data_type import numpy_astype_bknd_
    
        def _handle_dim(rank, idx):
            if idx >= 0 and idx < rank:
                return idx
            if idx < 0:
                idx = idx + rank
            if idx < 0 or idx >= rank:
                raise IndexError
            return idx
    
        input_type = numpy_dtype(input)
        rank = numpy_ndim_frnt_(input) + 1
        dim1 = _handle_dim(rank, dim1)
        dim2 = _handle_dim(rank, dim2)
        if dim1 > dim2:
            dim1, dim2 = dim2, dim1
            offset = -offset
        last_dim = list(numpy_shape_frnt_(input))[-1]
        if offset != 0:
            t_shape = list(numpy_shape_frnt_(input))
            t_shape = numpy_set_item(t_shape, -1, abs(offset))
            z = numpy_zeros(t_shape, dtype=input.dtype, device=None)
            pair = (z, input) if offset > 0 else (input, z)
            input = numpy_concat(pair, axis=-1)
            last_dim = last_dim + abs(offset)
        input = numpy_moveaxis_bknd_(numpy_expand_dims_bknd_(input, axis=dim1), -1, dim2)
        a_range = numpy_arange(last_dim, device=None, dtype=np.int64)
        b_range = numpy_arange(offset, last_dim + offset, device=None, dtype=np.int64)
        cond = a_range == numpy_expand_dims_bknd_(b_range, axis=-1)
        ag__result_list_0 = []
        for i in range(len(numpy_shape_frnt_(input))):
            res = last_dim if i in (dim1, dim2) else 1
            ag__result_list_0.append(res)
        cond_shape = ag__result_list_0
        cond = numpy_reshape_frnt_(cond, cond_shape)
>       if input.dtype == np.bool:

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/miscellaneous_ops.py:91: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

attr = 'bool'

    def __getattr__(attr):
        # Warn for expired attributes, and return a dummy function
        # that always raises an exception.
        import warnings
        import math
        try:
            msg = __expired_functions__[attr]
        except KeyError:
            pass
        else:
            warnings.warn(msg, DeprecationWarning, stacklevel=2)
    
            def _expired(*args, **kwds):
                raise RuntimeError(msg)
    
            return _expired
    
        # Emit warnings for deprecated attributes
        try:
            val, msg = __deprecated_attrs__[attr]
        except KeyError:
            pass
        else:
            warnings.warn(msg, DeprecationWarning, stacklevel=2)
            return val
    
        if attr in __future_scalars__:
            # And future warnings for those that will change, but also give
            # the AttributeError
            warnings.warn(
                f"In the future `np.{attr}` will be defined as the "
                "corresponding NumPy scalar.", FutureWarning, stacklevel=2)
    
        if attr in __former_attrs__:
>           raise AttributeError(__former_attrs__[attr])
E           AttributeError: module 'numpy' has no attribute 'bool'.
E           `np.bool` was a deprecated alias for the builtin `bool`. To avoid this error in existing code, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
E           The aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:
E               https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations. Did you mean: 'bool_'?

/opt/fw/mxnet/numpy/__init__.py:324: AttributeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.homography.find_homography_lines_dlt_iterated
----------------------------------------------------------------------------------------- Captured stderr call -----------------------------------------------------------------------------------------
/ivy/ivy-integration-tests/ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/miscellaneous_ops.py:91: FutureWarning: In the future `np.bool` will be defined as the corresponding NumPy scalar.
_____________________________________________________________________________ test_oneway_transfer_error[numpy-s2s-False] ______________________________________________________________________________

target_framework = 'numpy', mode = 's2s', backend_compile = False

    def test_oneway_transfer_error(target_framework, mode, backend_compile):
        trace_args = (
            torch.rand(1, 4, 2),
            torch.rand(1, 4, 2),
            torch.rand(1, 3, 3),
        )
        trace_kwargs = {'squared': False, 'eps': 1e-8}
        test_args = (
            torch.rand(5, 4, 2),
            torch.rand(5, 4, 2),
            torch.rand(5, 3, 3),
        )
        test_kwargs = {'squared': False, 'eps': 1e-7}
>       _test_function(
            kornia.geometry.homography.oneway_transfer_error,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/geometry/test_homography.py:156: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function oneway_transfer_error at 0x7fbf7fac4dc0>
trace_args = (tensor([[[0.2467, 0.2509],
         [0.8756, 0.0126],
         [0.9700, 0.9412],
         [0.0965, 0.6452]]]), tensor...0.2214]]]), tensor([[[0.1062, 0.7395, 0.9366],
         [0.4186, 0.2571, 0.0845],
         [0.2222, 0.8994, 0.2475]]]))
trace_kwargs = {'eps': 1e-08, 'squared': False}
test_args = (tensor([[[0.4903, 0.4377],
         [0.8756, 0.9550],
         [0.8884, 0.7339],
         [0.1496, 0.0029]],

       ... 0.9192]],

        [[0.0146, 0.9696, 0.3475],
         [0.8131, 0.4475, 0.6719],
         [0.9780, 0.5422, 0.0696]]]))
test_kwargs = {'eps': 1e-07, 'squared': False}, target = 'numpy', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function oneway_transfer_error at 0x7fbf7fac4dc0>, fn_name = 'kornia.geometry.homography.oneway_transfer_error'
trace_args = (tensor([[[0.2467, 0.2509],
         [0.8756, 0.0126],
         [0.9700, 0.9412],
         [0.0965, 0.6452]]]), tensor...0.2214]]]), tensor([[[0.1062, 0.7395, 0.9366],
         [0.4186, 0.2571, 0.0845],
         [0.2222, 0.8994, 0.2475]]]))
trace_kwargs = {'eps': 1e-08, 'squared': False}
test_args = (tensor([[[0.4903, 0.4377],
         [0.8756, 0.9550],
         [0.8884, 0.7339],
         [0.1496, 0.0029]],

       ... 0.9192]],

        [[0.0146, 0.9696, 0.3475],
         [0.8131, 0.4475, 0.6719],
         [0.9780, 0.5422, 0.0696]]]))
test_kwargs = {'eps': 1e-07, 'squared': False}, target = 'numpy', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pts1 = array([[[0.24673367, 0.250933  ],
        [0.875557  , 0.0126428 ],
        [0.9700111 , 0.9411514 ],
        [0.09652436, 0.6452431 ]]], dtype=float32)
pts2 = array([[[0.33258384, 0.47630215],
        [0.90261453, 0.0348621 ],
        [0.88485646, 0.14822131],
        [0.03889483, 0.22136152]]], dtype=float32)
H = array([[[0.10615098, 0.7395199 , 0.9365833 ],
        [0.41859013, 0.25705677, 0.08448583],
        [0.22218603, 0.8994206 , 0.24745613]]], dtype=float32), squared = False, eps = 1e-08

    def numpy_oneway_transfer_error(pts1, pts2, H, squared=True, eps=1e-08):
        from ..core.check import numpy_KORNIA_CHECK_SHAPE
        from ...ivy.functional.frontends.torch.tensor import numpy_size_frnt_
        from .conversions import numpy_convert_points_from_homogeneous
        from .linalg import numpy_transform_points
        from ...ivy.functional.frontends.torch.tensor import numpy_sum_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_pow_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_sqrt_frnt_
    
        numpy_KORNIA_CHECK_SHAPE(H, ["B", "3", "3"])
        if numpy_size_frnt_(pts1, -1) == 3:
            pts1 = numpy_convert_points_from_homogeneous(pts1)
        if numpy_size_frnt_(pts2, -1) == 3:
            pts2 = numpy_convert_points_from_homogeneous(pts2)
        pts1_in_2: typing.Any = numpy_transform_points(H, pts1)
        error_squared: typing.Any = numpy_sum_frnt_(
>           numpy_pow_frnt_(pts1_in_2 - pts2, 2), dim=-1
        )

ivy_transpiled_outputs/numpy_outputs/kornia/geometry/homography.py:46: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (array([[[1.8424292e+00, 1.5082657e-03],
        [1.3888652e+00, 9.6705991e-01],
        [4.4052804e-01, 4.1112882e-01],
        [1.6378834e+00, 1.2100524e-01]]], dtype=float32), 2)
kwargs = {}, numpy_is_array_bknd = <function numpy_is_array_bknd at 0x7fbf26a976d0>
array_like = array([[[1.8424292e+00, 1.5082657e-03],
        [1.3888652e+00, 9.6705991e-01],
        [4.4052804e-01, 4.1112882e-01],
        [1.6378834e+00, 1.2100524e-01]]], dtype=float32)

    @functools.wraps(fn)
    def wrapper(*args, **kwargs):
        from ..functional.ivy.general import numpy_is_array_bknd
    
        array_like = args[0]
        if hasattr(array_like, "__class__") and array_like.__class__.__name__ in [
            "list",
            "tuple",
        ]:
            array_like = array_like[0]
        if numpy_is_array_bknd(array_like):
>           return fn(*args, **kwargs)

ivy_transpiled_outputs/numpy_outputs/ivy/utils/decorator_utils.py:200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = array([[[1.8424292e+00, 1.5082657e-03],
        [1.3888652e+00, 9.6705991e-01],
        [4.4052804e-01, 4.1112882e-01],
        [1.6378834e+00, 1.2100524e-01]]], dtype=float32), exponent = 2

    @numpy_handle_methods
    def numpy_pow_frnt_(tensor, exponent):
        from .pointwise_ops import numpy_pow_frnt
    
>       return numpy_pow_frnt(tensor, exponent)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/tensor.py:201: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (array([[[1.8424292e+00, 1.5082657e-03],
        [1.3888652e+00, 9.6705991e-01],
        [4.4052804e-01, 4.1112882e-01],
        [1.6378834e+00, 1.2100524e-01]]], dtype=float32), 2)
kwargs = {}, numpy_is_array_bknd = <function numpy_is_array_bknd at 0x7fbf26a976d0>
array_like = array([[[1.8424292e+00, 1.5082657e-03],
        [1.3888652e+00, 9.6705991e-01],
        [4.4052804e-01, 4.1112882e-01],
        [1.6378834e+00, 1.2100524e-01]]], dtype=float32)

    @functools.wraps(fn)
    def wrapper(*args, **kwargs):
        from ..functional.ivy.general import numpy_is_array_bknd
    
        array_like = args[0]
        if hasattr(array_like, "__class__") and array_like.__class__.__name__ in [
            "list",
            "tuple",
        ]:
            array_like = array_like[0]
        if numpy_is_array_bknd(array_like):
>           return fn(*args, **kwargs)

ivy_transpiled_outputs/numpy_outputs/ivy/utils/decorator_utils.py:200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = array([[[1.8424292e+00, 1.5082657e-03],
        [1.3888652e+00, 9.6705991e-01],
        [4.4052804e-01, 4.1112882e-01],
        [1.6378834e+00, 1.2100524e-01]]], dtype=float32)
exponent = array(2)

    @numpy_handle_methods
    def numpy_pow_frnt(input, exponent, *, out=None):
        from ...ivy.general import numpy_is_array_bknd
        from .creation_ops import numpy_as_tensor_frnt
        from ...backends.numpy.creation import numpy_asarray
        from .__init__ import numpy_promote_types_of_torch_inputs_frnt
        from ...ivy.data_type import numpy_is_int_dtype_bknd
        from ...backends.numpy.elementwise import numpy_pow
        from ...backends.numpy.utility import numpy_any
        from ...backends.numpy.searching import numpy_where
        from ...backends.numpy.elementwise import numpy_bitwise_and
        from ....data_classes.array.data_type import numpy_astype_bknd_
    
        if not numpy_is_array_bknd(input):
            input = numpy_as_tensor_frnt(input)
        if not numpy_is_array_bknd(exponent):
            if (
                any(dtype in str(input.dtype) for dtype in ["int8", "int16"])
                and isinstance(exponent, (int,))
                or "float16" in str(input.dtype)
                and isinstance(exponent, (float,))
            ):
                exponent = numpy_asarray(exponent, dtype=input.dtype)
            else:
                exponent = numpy_as_tensor_frnt(exponent)
>       input, exponent = numpy_promote_types_of_torch_inputs_frnt(input, exponent)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/pointwise_ops.py:97: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x1 = array([[[1.8424292e+00, 1.5082657e-03],
        [1.3888652e+00, 9.6705991e-01],
        [4.4052804e-01, 4.1112882e-01],
        [1.6378834e+00, 1.2100524e-01]]], dtype=float32), x2 = array(2)

    def numpy_promote_types_of_torch_inputs_frnt(x1, x2, /):
        from ...ivy.general import numpy_isscalar_bknd
        from ...ivy.data_type import numpy_is_int_dtype_bknd
        from ...backends.numpy.creation import numpy_asarray
        from ...ivy.data_type import numpy_default_dtype_bknd
        from .tensor import numpy_shape_frnt_
        from ...ivy.device import numpy_default_device_bknd
        from ....data_classes.array.data_type import numpy_astype_bknd_
    
        """Promote the dtype of the given native array inputs to a common dtype
        based on type promotion rules.
    
        While passing float or integer values or any other non-array input
        to this function, it should be noted that the return will be an
        array-like object. Therefore, outputs from this function should be
        used as inputs only for those functions that expect an array-like or
        tensor-like objects, otherwise it might give unexpected results.
        """
        if (
            numpy_isscalar_bknd(x1) or isinstance(x1, (list, tuple))
        ) and numpy_is_int_dtype_bknd(x1):
            x1 = numpy_asarray(x1, dtype="int64")
        elif numpy_isscalar_bknd(x1) or isinstance(x1, (list, tuple)):
            x1 = numpy_asarray(x1)
        if (
            numpy_isscalar_bknd(x2) or isinstance(x2, (list, tuple))
        ) and numpy_is_int_dtype_bknd(x2):
            x2 = numpy_asarray(x2, dtype="int64")
        elif numpy_isscalar_bknd(x2) or isinstance(x2, (list, tuple)):
            x2 = numpy_asarray(x2)
        type1 = numpy_default_dtype_bknd(item=x1).strip("u123456789")
        type2 = numpy_default_dtype_bknd(item=x2).strip("u123456789")
        if numpy_shape_frnt_(x1) != () and numpy_shape_frnt_(x2) == () and type1 == type2:
            x2 = numpy_asarray(
                x2,
                dtype=x1.dtype,
                device=numpy_default_device_bknd(item=x1, as_native=False),
            )
        elif numpy_shape_frnt_(x1) == () and numpy_shape_frnt_(x2) != () and type1 == type2:
            x1 = numpy_asarray(
                x1,
                dtype=x2.dtype,
                device=numpy_default_device_bknd(item=x2, as_native=False),
            )
        elif x1.dtype != x2.dtype:
>           promoted = numpy_promote_types_torch_frnt(x1.dtype, x2.dtype)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/__init__.py:87: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

type1 = dtype('float32'), type2 = dtype('int64')

    def numpy_promote_types_torch_frnt(type1, type2, /):
        from ...backends.numpy.general import numpy_get_item
        from ...backends.numpy.data_type import numpy_as_ivy_dtype
    
        try:
            ret = numpy_get_item(
>               torch_promotion_table,
                (numpy_as_ivy_dtype(type1), numpy_as_ivy_dtype(type2)),
            )
E           NameError: name 'torch_promotion_table' is not defined

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/__init__.py:34: NameError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.homography.oneway_transfer_error
____________________________________________________________________________ test_symmetric_transfer_error[numpy-s2s-False] ____________________________________________________________________________

target_framework = 'numpy', mode = 's2s', backend_compile = False

    def test_symmetric_transfer_error(target_framework, mode, backend_compile):
        trace_args = (
            torch.rand(1, 4, 2),
            torch.rand(1, 4, 2),
            torch.rand(1, 3, 3),
        )
        trace_kwargs = {'squared': True, 'eps': 1e-8}
        test_args = (
            torch.rand(5, 4, 2),
            torch.rand(5, 4, 2),
            torch.rand(5, 3, 3),
        )
        test_kwargs = {'squared': True, 'eps': 1e-7}
>       _test_function(
            kornia.geometry.homography.symmetric_transfer_error,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/geometry/test_homography.py:206: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function symmetric_transfer_error at 0x7fbf7fac4ee0>
trace_args = (tensor([[[0.5866, 0.5763],
         [0.3537, 0.4506],
         [0.9955, 0.3143],
         [0.5844, 0.2560]]]), tensor...0.0413]]]), tensor([[[0.5907, 0.9588, 0.0549],
         [0.7045, 0.6174, 0.1814],
         [0.3389, 0.3032, 0.5037]]]))
trace_kwargs = {'eps': 1e-08, 'squared': True}
test_args = (tensor([[[0.1275, 0.4140],
         [0.9155, 0.5918],
         [0.0188, 0.7009],
         [0.2332, 0.2935]],

       ... 0.2732]],

        [[0.8275, 0.2528, 0.4900],
         [0.9767, 0.6924, 0.9629],
         [0.8230, 0.7881, 0.9292]]]))
test_kwargs = {'eps': 1e-07, 'squared': True}, target = 'numpy', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function symmetric_transfer_error at 0x7fbf7fac4ee0>, fn_name = 'kornia.geometry.homography.symmetric_transfer_error'
trace_args = (tensor([[[0.5866, 0.5763],
         [0.3537, 0.4506],
         [0.9955, 0.3143],
         [0.5844, 0.2560]]]), tensor...0.0413]]]), tensor([[[0.5907, 0.9588, 0.0549],
         [0.7045, 0.6174, 0.1814],
         [0.3389, 0.3032, 0.5037]]]))
trace_kwargs = {'eps': 1e-08, 'squared': True}
test_args = (tensor([[[0.1275, 0.4140],
         [0.9155, 0.5918],
         [0.0188, 0.7009],
         [0.2332, 0.2935]],

       ... 0.2732]],

        [[0.8275, 0.2528, 0.4900],
         [0.9767, 0.6924, 0.9629],
         [0.8230, 0.7881, 0.9292]]]))
test_kwargs = {'eps': 1e-07, 'squared': True}, target = 'numpy', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pts1 = array([[[0.58664334, 0.5763237 ],
        [0.35373425, 0.4506089 ],
        [0.9954733 , 0.31429255],
        [0.5843975 , 0.2559877 ]]], dtype=float32)
pts2 = array([[[0.81938726, 0.34269172],
        [0.47870165, 0.2267946 ],
        [0.530423  , 0.43791676],
        [0.8651018 , 0.04129702]]], dtype=float32)
H = array([[[0.59073275, 0.9588163 , 0.05490428],
        [0.7045313 , 0.6174492 , 0.18143576],
        [0.33885396, 0.30324167, 0.50372875]]], dtype=float32), squared = True, eps = 1e-08

    def numpy_symmetric_transfer_error(pts1, pts2, H, squared=True, eps=1e-08):
        from ..core.check import numpy_KORNIA_CHECK_SHAPE
        from ...ivy.functional.frontends.torch.tensor import numpy_size_frnt_
        from .conversions import numpy_convert_points_from_homogeneous
        from ...ivy.functional.frontends.torch.miscellaneous_ops import numpy_finfo_frnt
        from ..utils.helpers import numpy_safe_inverse_with_mask
        from ...ivy.functional.frontends.torch.tensor import numpy_expand_as_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_view_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_to_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_sqrt_frnt_
    
        numpy_KORNIA_CHECK_SHAPE(H, ["B", "3", "3"])
        if numpy_size_frnt_(pts1, -1) == 3:
            pts1 = numpy_convert_points_from_homogeneous(pts1)
        if numpy_size_frnt_(pts2, -1) == 3:
            pts2 = numpy_convert_points_from_homogeneous(pts2)
        max_num = numpy_finfo_frnt(pts1.dtype).max
        H_inv, good_H = numpy_safe_inverse_with_mask(H)
>       there: typing.Any = numpy_oneway_transfer_error(pts1, pts2, H, True, eps)

ivy_transpiled_outputs/numpy_outputs/kornia/geometry/homography.py:71: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pts1 = array([[[0.58664334, 0.5763237 ],
        [0.35373425, 0.4506089 ],
        [0.9954733 , 0.31429255],
        [0.5843975 , 0.2559877 ]]], dtype=float32)
pts2 = array([[[0.81938726, 0.34269172],
        [0.47870165, 0.2267946 ],
        [0.530423  , 0.43791676],
        [0.8651018 , 0.04129702]]], dtype=float32)
H = array([[[0.59073275, 0.9588163 , 0.05490428],
        [0.7045313 , 0.6174492 , 0.18143576],
        [0.33885396, 0.30324167, 0.50372875]]], dtype=float32), squared = True, eps = 1e-08

    def numpy_oneway_transfer_error(pts1, pts2, H, squared=True, eps=1e-08):
        from ..core.check import numpy_KORNIA_CHECK_SHAPE
        from ...ivy.functional.frontends.torch.tensor import numpy_size_frnt_
        from .conversions import numpy_convert_points_from_homogeneous
        from .linalg import numpy_transform_points
        from ...ivy.functional.frontends.torch.tensor import numpy_sum_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_pow_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_sqrt_frnt_
    
        numpy_KORNIA_CHECK_SHAPE(H, ["B", "3", "3"])
        if numpy_size_frnt_(pts1, -1) == 3:
            pts1 = numpy_convert_points_from_homogeneous(pts1)
        if numpy_size_frnt_(pts2, -1) == 3:
            pts2 = numpy_convert_points_from_homogeneous(pts2)
        pts1_in_2: typing.Any = numpy_transform_points(H, pts1)
        error_squared: typing.Any = numpy_sum_frnt_(
>           numpy_pow_frnt_(pts1_in_2 - pts2, 2), dim=-1
        )

ivy_transpiled_outputs/numpy_outputs/kornia/geometry/homography.py:46: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (array([[[ 0.26811236,  0.7408784 ],
        [ 0.43669498,  0.7056532 ],
        [ 0.47807413,  0.712114  ],
        [-0.03678709,  0.9225732 ]]], dtype=float32), 2), kwargs = {}
numpy_is_array_bknd = <function numpy_is_array_bknd at 0x7fbf2692c1f0>
array_like = array([[[ 0.26811236,  0.7408784 ],
        [ 0.43669498,  0.7056532 ],
        [ 0.47807413,  0.712114  ],
        [-0.03678709,  0.9225732 ]]], dtype=float32)

    @functools.wraps(fn)
    def wrapper(*args, **kwargs):
        from ..functional.ivy.general import numpy_is_array_bknd
    
        array_like = args[0]
        if hasattr(array_like, "__class__") and array_like.__class__.__name__ in [
            "list",
            "tuple",
        ]:
            array_like = array_like[0]
        if numpy_is_array_bknd(array_like):
>           return fn(*args, **kwargs)

ivy_transpiled_outputs/numpy_outputs/ivy/utils/decorator_utils.py:200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = array([[[ 0.26811236,  0.7408784 ],
        [ 0.43669498,  0.7056532 ],
        [ 0.47807413,  0.712114  ],
        [-0.03678709,  0.9225732 ]]], dtype=float32), exponent = 2

    @numpy_handle_methods
    def numpy_pow_frnt_(tensor, exponent):
        from .pointwise_ops import numpy_pow_frnt
    
>       return numpy_pow_frnt(tensor, exponent)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/tensor.py:272: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (array([[[ 0.26811236,  0.7408784 ],
        [ 0.43669498,  0.7056532 ],
        [ 0.47807413,  0.712114  ],
        [-0.03678709,  0.9225732 ]]], dtype=float32), 2), kwargs = {}
numpy_is_array_bknd = <function numpy_is_array_bknd at 0x7fbf2692c1f0>
array_like = array([[[ 0.26811236,  0.7408784 ],
        [ 0.43669498,  0.7056532 ],
        [ 0.47807413,  0.712114  ],
        [-0.03678709,  0.9225732 ]]], dtype=float32)

    @functools.wraps(fn)
    def wrapper(*args, **kwargs):
        from ..functional.ivy.general import numpy_is_array_bknd
    
        array_like = args[0]
        if hasattr(array_like, "__class__") and array_like.__class__.__name__ in [
            "list",
            "tuple",
        ]:
            array_like = array_like[0]
        if numpy_is_array_bknd(array_like):
>           return fn(*args, **kwargs)

ivy_transpiled_outputs/numpy_outputs/ivy/utils/decorator_utils.py:200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = array([[[ 0.26811236,  0.7408784 ],
        [ 0.43669498,  0.7056532 ],
        [ 0.47807413,  0.712114  ],
        [-0.03678709,  0.9225732 ]]], dtype=float32), exponent = array(2)

    @numpy_handle_methods
    def numpy_pow_frnt(input, exponent, *, out=None):
        from ...ivy.general import numpy_is_array_bknd
        from .creation_ops import numpy_as_tensor_frnt
        from ...backends.numpy.creation import numpy_asarray
        from .__init__ import numpy_promote_types_of_torch_inputs_frnt
        from ...ivy.data_type import numpy_is_int_dtype_bknd
        from ...backends.numpy.elementwise import numpy_pow
        from ...backends.numpy.utility import numpy_any
        from ...backends.numpy.searching import numpy_where
        from ...backends.numpy.elementwise import numpy_bitwise_and
        from ....data_classes.array.data_type import numpy_astype_bknd_
    
        if not numpy_is_array_bknd(input):
            input = numpy_as_tensor_frnt(input)
        if not numpy_is_array_bknd(exponent):
            if (
                any(dtype in str(input.dtype) for dtype in ["int8", "int16"])
                and isinstance(exponent, (int,))
                or "float16" in str(input.dtype)
                and isinstance(exponent, (float,))
            ):
                exponent = numpy_asarray(exponent, dtype=input.dtype)
            else:
                exponent = numpy_as_tensor_frnt(exponent)
>       input, exponent = numpy_promote_types_of_torch_inputs_frnt(input, exponent)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/pointwise_ops.py:97: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x1 = array([[[ 0.26811236,  0.7408784 ],
        [ 0.43669498,  0.7056532 ],
        [ 0.47807413,  0.712114  ],
        [-0.03678709,  0.9225732 ]]], dtype=float32), x2 = array(2)

    def numpy_promote_types_of_torch_inputs_frnt(x1, x2, /):
        from ...ivy.general import numpy_isscalar_bknd
        from ...ivy.data_type import numpy_is_int_dtype_bknd
        from ...backends.numpy.creation import numpy_asarray
        from ...ivy.data_type import numpy_default_dtype_bknd
        from .tensor import numpy_shape_frnt_
        from ...ivy.device import numpy_default_device_bknd
        from ....data_classes.array.data_type import numpy_astype_bknd_
    
        """Promote the dtype of the given native array inputs to a common dtype
        based on type promotion rules.
    
        While passing float or integer values or any other non-array input
        to this function, it should be noted that the return will be an
        array-like object. Therefore, outputs from this function should be
        used as inputs only for those functions that expect an array-like or
        tensor-like objects, otherwise it might give unexpected results.
        """
        if (
            numpy_isscalar_bknd(x1) or isinstance(x1, (list, tuple))
        ) and numpy_is_int_dtype_bknd(x1):
            x1 = numpy_asarray(x1, dtype="int64")
        elif numpy_isscalar_bknd(x1) or isinstance(x1, (list, tuple)):
            x1 = numpy_asarray(x1)
        if (
            numpy_isscalar_bknd(x2) or isinstance(x2, (list, tuple))
        ) and numpy_is_int_dtype_bknd(x2):
            x2 = numpy_asarray(x2, dtype="int64")
        elif numpy_isscalar_bknd(x2) or isinstance(x2, (list, tuple)):
            x2 = numpy_asarray(x2)
        type1 = numpy_default_dtype_bknd(item=x1).strip("u123456789")
        type2 = numpy_default_dtype_bknd(item=x2).strip("u123456789")
        if numpy_shape_frnt_(x1) != () and numpy_shape_frnt_(x2) == () and type1 == type2:
            x2 = numpy_asarray(
                x2,
                dtype=x1.dtype,
                device=numpy_default_device_bknd(item=x1, as_native=False),
            )
        elif numpy_shape_frnt_(x1) == () and numpy_shape_frnt_(x2) != () and type1 == type2:
            x1 = numpy_asarray(
                x1,
                dtype=x2.dtype,
                device=numpy_default_device_bknd(item=x2, as_native=False),
            )
        elif x1.dtype != x2.dtype:
>           promoted = numpy_promote_types_torch_frnt(x1.dtype, x2.dtype)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/__init__.py:87: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

type1 = dtype('float32'), type2 = dtype('int64')

    def numpy_promote_types_torch_frnt(type1, type2, /):
        from ...backends.numpy.general import numpy_get_item
        from ...backends.numpy.data_type import numpy_as_ivy_dtype
    
        try:
            ret = numpy_get_item(
>               torch_promotion_table,
                (numpy_as_ivy_dtype(type1), numpy_as_ivy_dtype(type2)),
            )
E           NameError: name 'torch_promotion_table' is not defined

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/__init__.py:34: NameError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.homography.symmetric_transfer_error
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/geometry/test_homography.py::test_find_homography_dlt[numpy-s2s-False] - AttributeError: module 'numpy' has no attribute 'bool'.
FAILED kornia/geometry/test_homography.py::test_find_homography_dlt_iterated[numpy-s2s-False] - AttributeError: module 'numpy' has no attribute 'bool'.
FAILED kornia/geometry/test_homography.py::test_find_homography_lines_dlt[numpy-s2s-False] - AttributeError: module 'numpy' has no attribute 'bool'.
FAILED kornia/geometry/test_homography.py::test_find_homography_lines_dlt_iterated[numpy-s2s-False] - AttributeError: module 'numpy' has no attribute 'bool'.
FAILED kornia/geometry/test_homography.py::test_oneway_transfer_error[numpy-s2s-False] - NameError: name 'torch_promotion_table' is not defined
FAILED kornia/geometry/test_homography.py::test_symmetric_transfer_error[numpy-s2s-False] - NameError: name 'torch_promotion_table' is not defined
=============================================================================== 6 failed, 2 passed in 586.97s (0:09:46) ================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 2 items

kornia/geometry/test_vector.py ..                                                                                                                                                                [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
==================================================================================== 2 passed in 131.90s (0:02:11) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 13 items

kornia/test_metrics.py ...F.....ssss                                                                                                                                                             [100%]

=============================================================================================== FAILURES ===============================================================================================
_____________________________________________________________________________ test_mean_average_precision[numpy-s2s-False] _____________________________________________________________________________

target_framework = 'numpy', mode = 's2s', backend_compile = False

    def test_mean_average_precision(target_framework, mode, backend_compile):
        trace_args = (
            [torch.tensor([[100, 50, 150, 100.]])],
            [torch.tensor([1.])],
            [torch.tensor([0.7])],
            [torch.tensor([[100, 50, 150, 100.]])],
            [torch.tensor([1.])],
            2,
        )
        trace_kwargs = {}
        test_args = (
            [torch.tensor([[50, 25, 75, 50], [100, 50, 150, 100.]])],
            [torch.tensor([1, 2.])],
            [torch.tensor([0.6, 0.8])],
            [torch.tensor([[50, 25, 75, 50], [100, 50, 150, 100.]])],
            [torch.tensor([1, 2.])],
            3,
        )
        kornia.metrics.mean_average_precision(*trace_args)
        kornia.metrics.mean_average_precision(*test_args)
        test_kwargs = {}
    
        # NOTE: this test fails due to the use of dynamic control flow; skipping
>       _test_function(
            kornia.metrics.mean_average_precision,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
            skip=True,
        )

kornia/test_metrics.py:118: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function mean_average_precision at 0x7f925b4f0a60>
trace_args = ([array([[100.,  50., 150., 100.]], dtype=float32)], [array([1.], dtype=float32)], [array([0.7], dtype=float32)], [array([[100.,  50., 150., 100.]], dtype=float32)], [array([1.], dtype=float32)], 2)
trace_kwargs = {}
test_args = ([array([[ 50.,  25.,  75.,  50.],
       [100.,  50., 150., 100.]], dtype=float32)], [array([1., 2.], dtype=float32)]...rray([[ 50.,  25.,  75.,  50.],
       [100.,  50., 150., 100.]], dtype=float32)], [array([1., 2.], dtype=float32)], 3)
test_kwargs = {}, target = 'numpy', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = True, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function mean_average_precision at 0x7f925b4f0a60>, fn_name = 'kornia.metrics.mean_average_precision'
trace_args = ([array([[100.,  50., 150., 100.]], dtype=float32)], [array([1.], dtype=float32)], [array([0.7], dtype=float32)], [array([[100.,  50., 150., 100.]], dtype=float32)], [array([1.], dtype=float32)], 2)
trace_kwargs = {}
test_args = ([array([[ 50.,  25.,  75.,  50.],
       [100.,  50., 150., 100.]], dtype=float32)], [array([1., 2.], dtype=float32)]...rray([[ 50.,  25.,  75.,  50.],
       [100.,  50., 150., 100.]], dtype=float32)], [array([1., 2.], dtype=float32)], 3)
test_kwargs = {}, target = 'numpy', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
>       orig_out = fn(*trace_args, **trace_kwargs)

helpers.py:335: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred_boxes = [array([[100.,  50., 150., 100.]], dtype=float32)], pred_labels = [array([1.], dtype=float32)], pred_scores = [array([0.7], dtype=float32)]
gt_boxes = [array([[100.,  50., 150., 100.]], dtype=float32)], gt_labels = [array([1.], dtype=float32)], n_classes = 2, threshold = 0.5

    def mean_average_precision(
        pred_boxes: List[Tensor],
        pred_labels: List[Tensor],
        pred_scores: List[Tensor],
        gt_boxes: List[Tensor],
        gt_labels: List[Tensor],
        n_classes: int,
        threshold: float = 0.5,
    ) -> Tuple[Tensor, Dict[int, float]]:
        """Calculate the Mean Average Precision (mAP) of detected objects.
    
        Code altered from https://github.com/sgrvinod/a-PyTorch-Tutorial-to-Object-Detection/blob/master/utils.py#L271.
        Background class (0 index) is excluded.
    
        Args:
            pred_boxes: a tensor list of predicted bounding boxes.
            pred_labels: a tensor list of predicted labels.
            pred_scores: a tensor list of predicted labels' scores.
            gt_boxes: a tensor list of ground truth bounding boxes.
            gt_labels: a tensor list of ground truth labels.
            n_classes: the number of classes.
            threshold: count as a positive if the overlap is greater than the threshold.
    
        Returns:
            mean average precision (mAP), list of average precisions for each class.
    
        Examples:
            >>> boxes, labels, scores = torch.tensor([[100, 50, 150, 100.]]), torch.tensor([1]), torch.tensor([.7])
            >>> gt_boxes, gt_labels = torch.tensor([[100, 50, 150, 100.]]), torch.tensor([1])
            >>> mean_average_precision([boxes], [labels], [scores], [gt_boxes], [gt_labels], 2)
            (tensor(1.), {1: 1.0})
        """
        # these are all lists of tensors of the same length, i.e. number of images
        if not len(pred_boxes) == len(pred_labels) == len(pred_scores) == len(gt_boxes) == len(gt_labels):
            raise AssertionError
    
        # Store all (true) objects in a single continuous tensor while keeping track of the image it is from
        gt_images = []
        for i, labels in enumerate(gt_labels):
>           gt_images.extend([i] * labels.size(0))
E           TypeError: 'int' object is not callable

/opt/miniconda/envs/multienv/lib/python3.10/site-packages/kornia/metrics/mean_average_precision.py:49: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.metrics.mean_average_precision.mean_average_precision
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/test_metrics.py::test_mean_average_precision[numpy-s2s-False] - TypeError: 'int' object is not callable
========================================================================== 1 failed, 8 passed, 4 skipped in 465.10s (0:07:45) ==========================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 5 items

kornia/test_x.py sssss                                                                                                                                                                           [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
==================================================================================== 5 skipped in 290.41s (0:04:50) ====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 56 items

kornia/geometry/test_transform.py ........................F..................F.......F..FF                                                                                                       [100%]

=============================================================================================== FAILURES ===============================================================================================
______________________________________________________________________________ test_upscale_double[tensorflow-s2s-False] _______________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_upscale_double(target_framework, mode, backend_compile):
        trace_args = (
            torch.rand(1, 3, 4, 4),
        )
        trace_kwargs = {}
        test_args = (
            torch.rand(5, 3, 8, 8),
        )
        test_kwargs = {}
>       _test_function(
            kornia.geometry.transform.upscale_double,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/geometry/test_transform.py:612: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function upscale_double at 0x7fa8a8332440>
trace_args = (tensor([[[[0.7982, 0.8144, 0.2668, 0.7472],
          [0.3586, 0.7798, 0.7046, 0.2697],
          [0.3384, 0.6931, 0...., 0.4674, 0.0570, 0.6737],
          [0.2739, 0.6048, 0.8739, 0.6656],
          [0.8739, 0.6883, 0.1002, 0.2570]]]]),)
trace_kwargs = {}
test_args = (tensor([[[[5.3363e-01, 3.1148e-01, 8.6450e-01, 1.2808e-01, 1.5536e-01,
           1.7066e-01, 5.3709e-01, 6.0621e-01]...      [9.8042e-01, 8.2682e-01, 5.1629e-01, 5.6195e-01, 7.0945e-01,
           3.1865e-01, 1.7095e-01, 7.9774e-01]]]]),)
test_kwargs = {}, target = 'tensorflow', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function upscale_double at 0x7fa8a8332440>, fn_name = 'kornia.geometry.transform.upscale_double'
trace_args = (tensor([[[[0.7982, 0.8144, 0.2668, 0.7472],
          [0.3586, 0.7798, 0.7046, 0.2697],
          [0.3384, 0.6931, 0...., 0.4674, 0.0570, 0.6737],
          [0.2739, 0.6048, 0.8739, 0.6656],
          [0.8739, 0.6883, 0.1002, 0.2570]]]]),)
trace_kwargs = {}
test_args = (tensor([[[[5.3363e-01, 3.1148e-01, 8.6450e-01, 1.2808e-01, 1.5536e-01,
           1.7066e-01, 5.3709e-01, 6.0621e-01]...      [9.8042e-01, 8.2682e-01, 5.1629e-01, 5.6195e-01, 7.0945e-01,
           3.1865e-01, 1.7095e-01, 7.9774e-01]]]]),)
test_kwargs = {}, target = 'tensorflow', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
>           graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:326: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = <tf.Tensor: shape=(1, 3, 4, 4), dtype=float32, numpy=
array([[[[0.79824615, 0.8143661 , 0.2668497 , 0.74722236],
     ....6048322 , 0.8739372 , 0.6656222 ],
         [0.87385744, 0.6883455 , 0.10017693, 0.2569933 ]]]],
      dtype=float32)>

    def tensorflow_upscale_double(x):
        from ...core._backend import zeros
        from ...core.check import tensorflow_KORNIA_CHECK_IS_TENSOR
        from ...core.check import tensorflow_KORNIA_CHECK_SHAPE
        from ....ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ....ivy.functional.backends.tensorflow.general import tensorflow_set_item
    
        tensorflow_KORNIA_CHECK_IS_TENSOR(x)
        tensorflow_KORNIA_CHECK_SHAPE(x, ["*", "H", "W"])
        double_shape = tensorflow_shape_frnt_(x)[:-2] + (
            tensorflow_shape_frnt_(x)[-2] * 2,
            tensorflow_shape_frnt_(x)[-1] * 2,
        )
        upscaled = zeros(double_shape, device=x.device, dtype=x.dtype)
        upscaled = tensorflow_set_item(
            upscaled, (..., slice(None, None, 2), slice(None, None, 2)), x
        )
>       upscaled[..., ::2, 1::2] = tensorflow_set_item(
            upscaled[..., ::2, 1::2],
            (..., slice(None, -1, None)),
            (upscaled[..., ::2, ::2][..., :-1] + upscaled[..., ::2, 2::2]) / 2,
        )
E       TypeError: 'tensorflow.python.framework.ops.EagerTensor' object does not support item assignment

ivy_transpiled_outputs/tensorflow_outputs/kornia/geometry/transform/pyramid.py:49: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.transform.pyramid.upscale_double
___________________________________________________________________________________ test_Shear[tensorflow-s2s-False] ___________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_Shear(target_framework, mode, backend_compile):
        print("kornia.geometry.transform.Shear")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledShear = ivy.transpile(kornia.geometry.transform.Shear, source="torch", target=target_framework)
    
        x = torch.rand(2, 3, 4, 4)
        shear = torch.tensor([[0.5, 0.0], [0.0, 0.5]])
        torch_out = kornia.geometry.transform.Shear(shear)(x)
    
        transpiled_x = _nest_torch_tensor_to_new_framework(x, target_framework)
        transpiled_shear = _nest_torch_tensor_to_new_framework(shear, target_framework)
>       transpiled_out = TranspiledShear(transpiled_shear)(transpiled_x)

kornia/geometry/test_transform.py:1156: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Shear()
args = (<tf.Tensor: shape=(2, 3, 4, 4), dtype=float32, numpy=
array([[[[0.7285764 , 0.6067234 , 0.7569605 , 0.29444706],
    ...534677 , 0.79732716, 0.51747763],
         [0.24238247, 0.5850113 , 0.56760025, 0.09626871]]]],
      dtype=float32)>,)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x7fa8552efa60, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...ode_context=['        return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_Shear(), <tf.Tensor: shape=(2, 3, 4, 4), dtype=float32, numpy=
array([[[[0.7285764 , 0.6067234 , 0.7569605...9534677 , 0.79732716, 0.51747763],
         [0.24238247, 0.5850113 , 0.56760025, 0.09626871]]]],
      dtype=float32)>)
kwargs = {}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Shear(), v = None, buffers = None
args = (<tf.Tensor: shape=(2, 3, 4, 4), dtype=float32, numpy=
array([[[[0.7285764 , 0.6067234 , 0.7569605 , 0.29444706],
    ...534677 , 0.79732716, 0.51747763],
         [0.24238247, 0.5850113 , 0.56760025, 0.09626871]]]],
      dtype=float32)>,)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:2013: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_Shear(), <tf.Tensor: shape=(2, 3, 4, 4), dtype=float32, numpy=
array([[[[0.7285764 , 0.6067234 , 0.7569605...9534677 , 0.79732716, 0.51747763],
         [0.24238247, 0.5850113 , 0.56760025, 0.09626871]]]],
      dtype=float32)>)
kwargs = {'buffers': None, 'v': None}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Shear(), v = None, buffers = None
args = (<tf.Tensor: shape=(2, 3, 4, 4), dtype=float32, numpy=
array([[[[0.7285764 , 0.6067234 , 0.7569605 , 0.29444706],
    ...534677 , 0.79732716, 0.51747763],
         [0.24238247, 0.5850113 , 0.56760025, 0.09626871]]]],
      dtype=float32)>,)
kwargs = {}
first_arr = <tf.Tensor: shape=(2, 3, 4, 4), dtype=float32, numpy=
array([[[[0.7285764 , 0.6067234 , 0.7569605 , 0.29444706],
     ....9534677 , 0.79732716, 0.51747763],
         [0.24238247, 0.5850113 , 0.56760025, 0.09626871]]]],
      dtype=float32)>
replace_v = False, replace_buffers = False, call_signature = <Signature (input)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Model, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Model, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Model, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1783: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_Shear(),)
kwargs = {'input': <tf.Tensor: shape=(2, 3, 4, 4), dtype=float32, numpy=
array([[[[0.7285764 , 0.6067234 , 0.7569605 , 0.294447...9534677 , 0.79732716, 0.51747763],
         [0.24238247, 0.5850113 , 0.56760025, 0.09626871]]]],
      dtype=float32)>}

    @wraps(fn)
    def error_handler(*args, **kwargs):
        if not is_traceback_filtering_enabled():
            return fn(*args, **kwargs)
    
        filtered_tb = None
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            filtered_tb = _process_traceback_frames(e.__traceback__)
            # To get the full stack trace, call:
            # `keras.config.disable_traceback_filtering()`
>           raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/keras/src/utils/traceback_utils.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Shear()
input = <tf.Tensor: shape=(2, 3, 4, 4), dtype=float32, numpy=
array([[[[0.7285764 , 0.6067234 , 0.7569605 , 0.29444706],
     ....9534677 , 0.79732716, 0.51747763],
         [0.24238247, 0.5850113 , 0.56760025, 0.09626871]]]],
      dtype=float32)>

    def call(self, input):
>       return shear(
            input, self.shear, self.mode, self.padding_mode, self.align_corners
        )
E       NameError: Exception encountered when calling tensorflow_Shear.call().
E       
E       [1mname 'shear' is not defined[0m
E       
E       Arguments received by tensorflow_Shear.call():
E          input=tf.Tensor(shape=(2, 3, 4, 4), dtype=float32)

ivy_transpiled_outputs/tensorflow_outputs/kornia/geometry/transform/affwarp.py:55: NameError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.transform.Shear
__________________________________________________________________________________ test_Rescale[tensorflow-s2s-False] __________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_Rescale(target_framework, mode, backend_compile):
        print("kornia.geometry.transform.Rescale")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledRescale = ivy.transpile(kornia.geometry.transform.Rescale, source="torch", target=target_framework)
    
        x = torch.rand(1, 3, 4, 4)
        torch_out = kornia.geometry.transform.Rescale((2.0, 3.0))(x)
    
        transpiled_x = _nest_torch_tensor_to_new_framework(x, target_framework)
        transpiled_out = TranspiledRescale((2.0, 3.0))(transpiled_x)
    
>       _to_numpy_and_allclose(torch_out, transpiled_out)

kornia/geometry/test_transform.py:1294: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

torch_x = tensor([[[[0.9152, 0.7690, 0.6227, 0.4764, 0.3493, 0.2605, 0.1718, 0.0830,
           0.1896, 0.3937, 0.5979, 0.8021],...        [0.4074, 0.3211, 0.2348, 0.1485, 0.0973, 0.1162, 0.1351, 0.1540,
           0.1868, 0.2267, 0.2665, 0.3063]]]])
transpiled_x = <tf.Tensor: shape=(1, 3, 8, 12), dtype=float32, numpy=
array([[[[0.91524404, 0.91524404, 0.73644686, 0.55764973, 0.378...      0.11410676, 0.13720492, 0.16030306, 0.20896396, 0.2576248 ,
          0.30628568, 0.30628568]]]], dtype=float32)>
tolerance = 0.001

    def _to_numpy_and_allclose(torch_x, transpiled_x, tolerance=1e-3):
        orig_data = _nest_array_to_numpy(torch_x)
        transpiled_data = _nest_array_to_numpy(transpiled_x)
>       _check_allclose(orig_data, transpiled_data, tolerance=tolerance)

helpers.py:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[[0.91524404, 0.76895547, 0.6226669 , 0.47637832, 0.34927213,
          0.2605307 , 0.17178926, 0.08304784, 0....       0.11620659, 0.13510509, 0.15400356, 0.18684536, 0.22665879,
          0.26647225, 0.30628568]]]], dtype=float32)
y = array([[[[0.91524404, 0.91524404, 0.73644686, 0.55764973, 0.3788526 ,
          0.27039087, 0.1619291 , 0.05346739, 0....       0.11410676, 0.13720492, 0.16030306, 0.20896396, 0.2576248 ,
          0.30628568, 0.30628568]]]], dtype=float32)
tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
>           assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
E           AssertionError: numpy array values are not all close

helpers.py:26: AssertionError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.transform.Rescale
________________________________________________________________________________ test_Homography[tensorflow-s2s-False] _________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_Homography(target_framework, mode, backend_compile):
        print("kornia.geometry.transform.Homography")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledHomography = ivy.transpile(
            kornia.geometry.transform.image_registrator.Homography, source="torch", target=target_framework
        )
    
        torch_out = kornia.geometry.transform.image_registrator.Homography()()
>       transpiled_out = TranspiledHomography()()

kornia/geometry/test_transform.py:1354: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Homography(<tf.Variable 'Variable:0' shape=(3, 3) dtype=float32, numpy=
array([[1., 0., 0.],
       [0., 1., 0.],
       [0., 0., 1.]], dtype=float32)>), args = (), kwargs = {}
stack = [FrameInfo(frame=<frame at 0x7fa854e59f40, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...ode_context=['        return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_Homography(<tf.Variable 'Variable:0' shape=(3, 3) dtype=float32, numpy=
array([[1., 0., 0.],
       [0., 1., 0.],
       [0., 0., 1.]], dtype=float32)>),), kwargs = {}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Homography(<tf.Variable 'Variable:0' shape=(3, 3) dtype=float32, numpy=
array([[1., 0., 0.],
       [0., 1., 0.],
       [0., 0., 1.]], dtype=float32)>), v = None, buffers = None
args = (), kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_Homography(<tf.Variable 'Variable:0' shape=(3, 3) dtype=float32, numpy=
array([[1., 0., 0.],
       [0., 1., 0.],
       [0., 0., 1.]], dtype=float32)>),)
kwargs = {'buffers': None, 'v': None}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Homography(<tf.Variable 'Variable:0' shape=(3, 3) dtype=float32, numpy=
array([[1., 0., 0.],
       [0., 1., 0.],
       [0., 0., 1.]], dtype=float32)>), v = None, buffers = None
args = (), kwargs = {}, first_arr = None, replace_v = False, replace_buffers = False, call_signature = <Signature ()>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Layer, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Layer, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Layer, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_Homography(<tf.Variable 'Variable:0' shape=(3, 3) dtype=float32, numpy=
array([[1., 0., 0.],
       [0., 1., 0.],
       [0., 0., 1.]], dtype=float32)>),), kwargs = {}

    @wraps(fn)
    def error_handler(*args, **kwargs):
        if not is_traceback_filtering_enabled():
            return fn(*args, **kwargs)
    
        filtered_tb = None
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            filtered_tb = _process_traceback_frames(e.__traceback__)
            # To get the full stack trace, call:
            # `keras.config.disable_traceback_filtering()`
>           raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/keras/src/utils/traceback_utils.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <keras.src.layers.layer.CallSpec object at 0x7fa83895c460>, signature = <Signature ()>, args = (), kwargs = {}

    def __init__(self, signature, args, kwargs):
        # `training` and `mask` are special kwargs that are always available in
        # a layer, if user specifies them in their call without adding to spec,
        # we remove them to be able to bind variables. User is not using
        # `training` anyway so we can ignore.
        # TODO: If necessary use workaround for `mask`
        if "training" in kwargs and "training" not in signature.parameters:
            kwargs.pop("training")
            bound_args = signature.bind(*args, **kwargs)
        else:
            bound_args = signature.bind(*args, **kwargs)
        self.user_arguments_dict = {
            k: v for k, v in bound_args.arguments.items()
        }
        bound_args.apply_defaults()
        arg_dict = {}
        arg_names = []
        tensor_arg_dict = {}
        tensor_args = []
        tensor_arg_names = []
        nested_tensor_arg_names = []
        for name, value in bound_args.arguments.items():
            arg_dict[name] = value
            arg_names.append(name)
            if is_backend_tensor_or_symbolic(value):
                tensor_args.append(value)
                tensor_arg_names.append(name)
                tensor_arg_dict[name] = value
            elif tree.is_nested(value) and len(value) > 0:
                flat_values = tree.flatten(value)
                if all(
                    is_backend_tensor_or_symbolic(x, allow_none=True)
                    for x in flat_values
                ):
                    tensor_args.append(value)
                    tensor_arg_names.append(name)
                    tensor_arg_dict[name] = value
                    nested_tensor_arg_names.append(name)
                elif any(is_backend_tensor_or_symbolic(x) for x in flat_values):
                    raise ValueError(
                        "In a nested call() argument, "
                        "you cannot mix tensors and non-tensors. "
                        "Received invalid mixed argument: "
                        f"{name}={value}"
                    )
        self.arguments_dict = arg_dict
        self.argument_names = arg_names
        self.tensor_arguments_dict = tensor_arg_dict
        self.tensor_arguments_names = tensor_arg_names
        self.nested_tensor_argument_names = nested_tensor_arg_names
>       self.first_arg = arg_dict[arg_names[0]]
E       IndexError: list index out of range

/opt/fw/tensorflow/keras/src/layers/layer.py:1608: IndexError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.transform.Homography
________________________________________________________________________________ test_Similarity[tensorflow-s2s-False] _________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_Similarity(target_framework, mode, backend_compile):
        print("kornia.geometry.transform.Similarity")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledSimilarity = ivy.transpile(
            kornia.geometry.transform.image_registrator.Similarity, source="torch", target=target_framework
        )
    
        torch_out = kornia.geometry.transform.image_registrator.Similarity()()
>       transpiled_out = TranspiledSimilarity()()

kornia/geometry/test_transform.py:1392: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Similarity(angle = <tf.Variable 'Variable:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>,  ...[0.]]], dtype=float32)>, 
 scale=<tf.Variable 'Variable:0' shape=(1,) dtype=float32, numpy=array([1.], dtype=float32)>)
args = (), kwargs = {}
stack = [FrameInfo(frame=<frame at 0x7fa8552d2240, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...ode_context=['        return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_Similarity(angle = <tf.Variable 'Variable:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>, ....]]], dtype=float32)>, 
 scale=<tf.Variable 'Variable:0' shape=(1,) dtype=float32, numpy=array([1.], dtype=float32)>),)
kwargs = {}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Similarity(angle = <tf.Variable 'Variable:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>,  ...[0.]]], dtype=float32)>, 
 scale=<tf.Variable 'Variable:0' shape=(1,) dtype=float32, numpy=array([1.], dtype=float32)>)
v = None, buffers = None, args = (), kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_Similarity(angle = <tf.Variable 'Variable:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>, ....]]], dtype=float32)>, 
 scale=<tf.Variable 'Variable:0' shape=(1,) dtype=float32, numpy=array([1.], dtype=float32)>),)
kwargs = {'buffers': None, 'v': None}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Similarity(angle = <tf.Variable 'Variable:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>,  ...[0.]]], dtype=float32)>, 
 scale=<tf.Variable 'Variable:0' shape=(1,) dtype=float32, numpy=array([1.], dtype=float32)>)
v = None, buffers = None, args = (), kwargs = {}, first_arr = None, replace_v = False, replace_buffers = False, call_signature = <Signature ()>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Layer, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Layer, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Layer, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_Similarity(angle = <tf.Variable 'Variable:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>, ....]]], dtype=float32)>, 
 scale=<tf.Variable 'Variable:0' shape=(1,) dtype=float32, numpy=array([1.], dtype=float32)>),)
kwargs = {}

    @wraps(fn)
    def error_handler(*args, **kwargs):
        if not is_traceback_filtering_enabled():
            return fn(*args, **kwargs)
    
        filtered_tb = None
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            filtered_tb = _process_traceback_frames(e.__traceback__)
            # To get the full stack trace, call:
            # `keras.config.disable_traceback_filtering()`
>           raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/keras/src/utils/traceback_utils.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <keras.src.layers.layer.CallSpec object at 0x7fa81cbeeda0>, signature = <Signature ()>, args = (), kwargs = {}

    def __init__(self, signature, args, kwargs):
        # `training` and `mask` are special kwargs that are always available in
        # a layer, if user specifies them in their call without adding to spec,
        # we remove them to be able to bind variables. User is not using
        # `training` anyway so we can ignore.
        # TODO: If necessary use workaround for `mask`
        if "training" in kwargs and "training" not in signature.parameters:
            kwargs.pop("training")
            bound_args = signature.bind(*args, **kwargs)
        else:
            bound_args = signature.bind(*args, **kwargs)
        self.user_arguments_dict = {
            k: v for k, v in bound_args.arguments.items()
        }
        bound_args.apply_defaults()
        arg_dict = {}
        arg_names = []
        tensor_arg_dict = {}
        tensor_args = []
        tensor_arg_names = []
        nested_tensor_arg_names = []
        for name, value in bound_args.arguments.items():
            arg_dict[name] = value
            arg_names.append(name)
            if is_backend_tensor_or_symbolic(value):
                tensor_args.append(value)
                tensor_arg_names.append(name)
                tensor_arg_dict[name] = value
            elif tree.is_nested(value) and len(value) > 0:
                flat_values = tree.flatten(value)
                if all(
                    is_backend_tensor_or_symbolic(x, allow_none=True)
                    for x in flat_values
                ):
                    tensor_args.append(value)
                    tensor_arg_names.append(name)
                    tensor_arg_dict[name] = value
                    nested_tensor_arg_names.append(name)
                elif any(is_backend_tensor_or_symbolic(x) for x in flat_values):
                    raise ValueError(
                        "In a nested call() argument, "
                        "you cannot mix tensors and non-tensors. "
                        "Received invalid mixed argument: "
                        f"{name}={value}"
                    )
        self.arguments_dict = arg_dict
        self.argument_names = arg_names
        self.tensor_arguments_dict = tensor_arg_dict
        self.tensor_arguments_names = tensor_arg_names
        self.nested_tensor_argument_names = nested_tensor_arg_names
>       self.first_arg = arg_dict[arg_names[0]]
E       IndexError: list index out of range

/opt/fw/tensorflow/keras/src/layers/layer.py:1608: IndexError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.transform.Similarity
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/geometry/test_transform.py::test_upscale_double[tensorflow-s2s-False] - TypeError: 'tensorflow.python.framework.ops.EagerTensor' object does not support item assignment
FAILED kornia/geometry/test_transform.py::test_Shear[tensorflow-s2s-False] - NameError: Exception encountered when calling tensorflow_Shear.call().
FAILED kornia/geometry/test_transform.py::test_Rescale[tensorflow-s2s-False] - AssertionError: numpy array values are not all close
FAILED kornia/geometry/test_transform.py::test_Homography[tensorflow-s2s-False] - IndexError: list index out of range
FAILED kornia/geometry/test_transform.py::test_Similarity[tensorflow-s2s-False] - IndexError: list index out of range
============================================================================== 5 failed, 51 passed in 5676.00s (1:34:36) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 8 items

kornia/geometry/test_linalg.py ........                                                                                                                                                          [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
==================================================================================== 8 passed in 287.03s (0:04:47) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 17 items

kornia/augmentation/test_augmentation2.py sssssssssssssssss                                                                                                                                      [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
========================================================================================= 17 skipped in 5.21s ==========================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 13 items

kornia/test_feature3.py .........F...                                                                                                                                                            [100%]

=============================================================================================== FAILURES ===============================================================================================
________________________________________________________________________________ test_ScaleSpaceDetector[jax-s2s-False] ________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_ScaleSpaceDetector(target_framework, mode, backend_compile):
        print("kornia.feature.ScaleSpaceDetector")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledScaleSpaceDetector = ivy.transpile(kornia.feature.ScaleSpaceDetector, source="torch", target=target_framework)
    
        x = torch.rand(1, 1, 32, 32) * 10.
        transpiled_x = _nest_torch_tensor_to_new_framework(x, target_framework)
    
        model = kornia.feature.ScaleSpaceDetector()
        torch_out = model(x)
    
        transpiled_model = TranspiledScaleSpaceDetector()
        if target_framework == "tensorflow":
            # build the layers
            transpiled_model(transpiled_x)
    
        ivy.sync_models(model, transpiled_model)
    
        transpiled_out = transpiled_model(transpiled_x)
    
>       _to_numpy_and_allclose(torch_out, transpiled_out)

kornia/test_feature3.py:206: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

torch_x = (tensor([[[[10.7773,  0.0000, 17.9977],
          [ 0.0000, 10.7773, 10.9736]],

         [[10.7922,  0.0000, 21.0146]...00, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
         0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]))
transpiled_x = (Array([[[[10.777309  ,  0.        , 17.99775   ],
         [ 0.        , 10.777309  , 10.973592  ]],

        [[10.79...   , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ]],      dtype=float32))
tolerance = 0.001

    def _to_numpy_and_allclose(torch_x, transpiled_x, tolerance=1e-3):
        orig_data = _nest_array_to_numpy(torch_x)
        transpiled_data = _nest_array_to_numpy(transpiled_x)
>       _check_allclose(orig_data, transpiled_data, tolerance=tolerance)

helpers.py:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = (array([[[[10.777309 ,  0.       , 17.99775  ],
         [ 0.       , 10.777309 , 10.973592 ]],

        [[10.792217 ,...        ,  0.        ,
         0.        ,  0.        ,  0.        ,  0.        ,  0.        ]],
      dtype=float32))
y = (array([[[[10.777309  ,  0.        , 17.99775   ],
         [ 0.        , 10.777309  , 10.973592  ]],

        [[10.79...  , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ]],
      dtype=float32))
tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
            assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
            return
    
        if isinstance(x, (list, set, tuple)):
>           all([
                _check_allclose(element_x, element_y, tolerance=tolerance) for element_x, element_y in zip(x, y)
            ])

helpers.py:30: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

.0 = <zip object at 0x7f70fbdbab80>

    all([
>       _check_allclose(element_x, element_y, tolerance=tolerance) for element_x, element_y in zip(x, y)
    ])

helpers.py:31: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[[10.777309 ,  0.       , 17.99775  ],
         [ 0.       , 10.777309 , 10.973592 ]],

        [[10.792217 , ...414]],

        [[21.551926 ,  0.       , 29.00205  ],
         [ 0.       , 21.551926 ,  5.995332 ]]]], dtype=float32)
y = array([[[[10.777309  ,  0.        , 17.99775   ],
         [ 0.        , 10.777309  , 10.973592  ]],

        [[10.792...

        [[15.249535  ,  0.        ,  8.011129  ],
         [ 0.        , 15.249535  , 20.99744   ]]]], dtype=float32)
tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
>           assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
E           AssertionError: numpy array values are not all close

helpers.py:26: AssertionError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.ScaleSpaceDetector
All parameters and buffers are now synced!
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/test_feature3.py::test_ScaleSpaceDetector[jax-s2s-False] - AssertionError: numpy array values are not all close
============================================================================== 1 failed, 12 passed in 1879.55s (0:31:19) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 2 items

kornia/test_io.py ..                                                                                                                                                                             [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
==================================================================================== 2 passed in 131.84s (0:02:11) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 6 items

kornia/geometry/test_depth.py ......                                                                                                                                                             [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
==================================================================================== 6 passed in 371.89s (0:06:11) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 18 items

kornia/augmentation/test_augmentation1.py .......F..........                                                                                                                                     [100%]

=============================================================================================== FAILURES ===============================================================================================
___________________________________________________________________________________ test_RandomClahe[jax-s2s-False] ____________________________________________________________________________________

arrays = []

    def jax_stack(
        arrays: Union[Tuple[jax.Array], List[jax.Array]],
        /,
        *,
        axis: int = 0,
        out: Optional[jax.Array] = None,
    ):
        try:
>           return jax.numpy.stack(arrays, axis=axis)

ivy_transpiled_outputs/jax_outputs/ivy/functional/backends/jax/manipulation.py:147: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

arrays = [], axis = 3, out = None, dtype = None

    def stack(arrays: np.ndarray | Array | Sequence[ArrayLike],
              axis: int = 0, out: None = None, dtype: DTypeLike | None = None) -> Array:
      """Join arrays along a new axis.
    
      JAX implementation of :func:`numpy.stack`.
    
      Args:
        arrays: a sequence of arrays to stack; each must have the same shape. If a
          single array is given it will be treated equivalently to
          `arrays = unstack(arrays)`, but the implementation will avoid explicit
          unstacking.
        axis: specify the axis along which to stack.
        out: unused by JAX
        dtype: optional dtype of the resulting array. If not specified, the dtype
          will be determined via type promotion rules described in :ref:`type-promotion`.
    
      Returns:
        the stacked result.
    
      See also:
        - :func:`jax.numpy.unstack`: inverse of ``stack``.
        - :func:`jax.numpy.concatenate`: concatenation along existing axes.
        - :func:`jax.numpy.vstack`: stack vertically, i.e. along axis 0.
        - :func:`jax.numpy.hstack`: stack horizontally, i.e. along axis 1.
        - :func:`jax.numpy.dstack`: stack depth-wise, i.e. along axis 2.
        - :func:`jax.numpy.column_stack`: stack columns.
    
      Examples:
        >>> x = jnp.array([1, 2, 3])
        >>> y = jnp.array([4, 5, 6])
        >>> jnp.stack([x, y])
        Array([[1, 2, 3],
               [4, 5, 6]], dtype=int32)
        >>> jnp.stack([x, y], axis=1)
        Array([[1, 4],
               [2, 5],
               [3, 6]], dtype=int32)
    
        :func:`~jax.numpy.unstack` performs the inverse operation:
    
        >>> arr = jnp.stack([x, y], axis=1)
        >>> x, y = jnp.unstack(arr, axis=1)
        >>> x
        Array([1, 2, 3], dtype=int32)
        >>> y
        Array([4, 5, 6], dtype=int32)
      """
      if not len(arrays):
>       raise ValueError("Need at least one array to stack.")
E       ValueError: Need at least one array to stack.

/opt/fw/jax/jax/_src/numpy/lax_numpy.py:4094: ValueError

The above exception was the direct cause of the following exception:

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_RandomClahe(target_framework, mode, backend_compile):
        print("kornia.augmentation.RandomClahe")
    
        init_args = ()
        init_kwargs = {}
        call_args = (torch.rand(2, 3, 10, 20),)
        call_kwargs = {}
    
>       _test_augmentation_class(
            kornia.augmentation.RandomClahe,
            target_framework,
            init_args,
            init_kwargs,
            call_args,
            call_kwargs,
            deterministic_output=False,
            backend_compile=backend_compile,
        )

kornia/augmentation/test_augmentation1.py:215: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

augmentation_cls = <class 'kornia.augmentation._2d.intensity.clahe.RandomClahe'>, target = 'jax', init_args = (), init_kwargs = {}
call_args = (tensor([[[[7.6232e-01, 1.3256e-01, 2.4694e-01,  ..., 8.6218e-01,
           8.6114e-02, 2.4388e-01],
          [6.881... 6.0310e-01],
          [6.3303e-01, 3.7383e-01, 8.7019e-01,  ..., 2.2795e-01,
           5.3670e-01, 3.8298e-01]]]]),)
call_kwargs = {}, deterministic_output = False, backend_compile = False, tolerance = 0.001

    def _test_augmentation_class(
        augmentation_cls,
        target,
        init_args=(),
        init_kwargs={},
        call_args=(),
        call_kwargs={},
        deterministic_output=True,
        backend_compile=False,
        tolerance=1e-3,
    ):
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_cls = ivy.transpile(augmentation_cls, source="torch", target=target)
    
        torch_aug = augmentation_cls(*init_args, **init_kwargs)
        transpiled_init_args = _nest_torch_tensor_to_new_framework(init_args, target)
        transpiled_init_kwargs = _nest_torch_tensor_to_new_framework(init_kwargs, target)
        transpiled_aug = transpiled_cls(*transpiled_init_args, **transpiled_init_kwargs)
    
        # assert dir(torch_aug) == dir(transpiled_aug), f"attributes/methods of transpiled object do not align with the original - orig: {dir(torch_aug)} != transpiled: {dir(transpiled_aug)}"
    
        torch_out = torch_aug(*call_args, **call_kwargs)
        transpiled_call_args = _nest_torch_tensor_to_new_framework(call_args, target)
        transpiled_call_kwargs = _nest_torch_tensor_to_new_framework(call_kwargs, target)
>       transpiled_out = transpiled_aug(*transpiled_call_args, **transpiled_call_kwargs)

kornia/augmentation/test_augmentation1.py:43: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_RandomClahe(clip_limit_factor=(40.0, 40.0), p=0.5, p_batch=1.0, same_on_batch=False, grid_size=(8, 8), slow_and_differentiable=False)
input = Array([[[[7.6231962e-01, 1.3256413e-01, 2.4693507e-01, ...,
          8.6217761e-01, 8.6113632e-02, 2.4387866e-01],
  ...03041e-01, 3.7383330e-01, 8.7019223e-01, ...,
          2.2794598e-01, 5.3670222e-01, 3.8298446e-01]]]], dtype=float32)
params = {'batch_prob': Array([0., 1.], dtype=float32), 'clip_limit_factor': Array([40.], dtype=float32), 'forward_input_shape': Array([ 2,  3, 10, 20], dtype=int64)}, kwargs = {}
jax_shape_frnt_ = <function jax_shape_frnt_ at 0x7f85a156dbd0>, jax_set_item = <function jax_set_item at 0x7f85a1a91120>, tensor = <function jax_tensor_frnt at 0x7f85a1292c20>
in_tensor = Array([[[[7.6231962e-01, 1.3256413e-01, 2.4693507e-01, ...,
          8.6217761e-01, 8.6113632e-02, 2.4387866e-01],
  ...03041e-01, 3.7383330e-01, 8.7019223e-01, ...,
          2.2794598e-01, 5.3670222e-01, 3.8298446e-01]]]], dtype=float32)
input_shape = ivy.frontends.torch.Size([2, 3, 10, 20]), batch_shape = ivy.frontends.torch.Size([2, 3, 10, 20]), flags = {'grid_size': (8, 8), 'slow_and_differentiable': False}

    def __call__(self, input, params=None, **kwargs):
        from ...ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ...ivy.functional.backends.jax.general import jax_set_item
        from ..core._backend import tensor
    
        in_tensor = self.__unpack_input__(input)
        input_shape = jax_shape_frnt_(in_tensor)
        in_tensor = self.transform_tensor(in_tensor)
        batch_shape = jax_shape_frnt_(in_tensor)
        if params is None:
            params = self.forward_parameters(batch_shape)
        if "batch_prob" not in params:
            params = jax_set_item(params, "batch_prob", tensor([True] * batch_shape[0]))
        params, flags = self._process_kwargs_to_params_and_flags(
            params, self.flags, **kwargs
        )
>       output = self.apply_func(in_tensor, params, flags)

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/base.py:219: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_RandomClahe(clip_limit_factor=(40.0, 40.0), p=0.5, p_batch=1.0, same_on_batch=False, grid_size=(8, 8), slow_and_differentiable=False)
in_tensor = Array([[[[7.6231962e-01, 1.3256413e-01, 2.4693507e-01, ...,
          8.6217761e-01, 8.6113632e-02, 2.4387866e-01],
  ...03041e-01, 3.7383330e-01, 8.7019223e-01, ...,
          2.2794598e-01, 5.3670222e-01, 3.8298446e-01]]]], dtype=float32)
params = {'batch_prob': Array([0., 1.], dtype=float32), 'clip_limit_factor': Array([40.], dtype=float32), 'forward_input_shape': Array([ 2,  3, 10, 20], dtype=int64)}
flags = {'grid_size': (8, 8), 'slow_and_differentiable': False}

    def apply_func(self, in_tensor, params, flags=None):
        if flags is None:
            flags = self.flags
        trans_matrix = self.generate_transformation_matrix(in_tensor, params, flags)
>       output = self.transform_inputs(in_tensor, params, flags, trans_matrix)

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/_2d/base.py:123: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_RandomClahe(clip_limit_factor=(40.0, 40.0), p=0.5, p_batch=1.0, same_on_batch=False, grid_size=(8, 8), slow_and_differentiable=False)
input = Array([[[[7.6231962e-01, 1.3256413e-01, 2.4693507e-01, ...,
          8.6217761e-01, 8.6113632e-02, 2.4387866e-01],
  ...03041e-01, 3.7383330e-01, 8.7019223e-01, ...,
          2.2794598e-01, 5.3670222e-01, 3.8298446e-01]]]], dtype=float32)
params = {'batch_prob': Array([0., 1.], dtype=float32), 'clip_limit_factor': Array([40.], dtype=float32), 'forward_input_shape': Array([ 2,  3, 10, 20], dtype=int64)}
flags = {'grid_size': (8, 8), 'slow_and_differentiable': False}
transform = Array([[[1., 0., 0.],
        [0., 1., 0.],
        [0., 0., 1.]],

       [[1., 0., 0.],
        [0., 1., 0.],
        [0., 0., 1.]]], dtype=float32), kwargs = {}
jax_shape_frnt_ = <function jax_shape_frnt_ at 0x7f85a156dbd0>, jax_all_frnt_ = <function jax_all_frnt_ at 0x7f85a156e9e0>, jax_any_frnt_ = <function jax_any_frnt_ at 0x7f85a1287400>
jax_get_item = <function jax_get_item at 0x7f85a1a90f70>, jax_is_autocast_enabled = <function jax_is_autocast_enabled at 0x7f85a1a3b6d0>, jax_type_frnt_ = <function jax_type_frnt_ at 0x7f85a12871c0>
jax_index_put_frnt_ = <function jax_index_put_frnt_ at 0x7f85a1284160>

    def transform_inputs(self, input, params, flags, transform=None, **kwargs):
        from ...ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_all_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_any_frnt_
        from ...ivy.functional.backends.jax.general import jax_get_item
        from ..utils.helpers import jax_is_autocast_enabled
        from ...ivy.functional.frontends.torch.tensor import jax_type_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_index_put_frnt_
        from .utils.helpers import jax__transform_output_shape
    
        params, flags = self._process_kwargs_to_params_and_flags(
            self._params if params is None else params, flags, **kwargs
        )
        batch_prob = params["batch_prob"]
        to_apply = batch_prob > 0.5
        ori_shape = jax_shape_frnt_(input)
        in_tensor = self.transform_tensor(input)
        self.validate_tensor(in_tensor)
        if jax_all_frnt_(to_apply):
            output = self.apply_transform(in_tensor, params, flags, transform=transform)
        elif not jax_any_frnt_(to_apply):
            output = self.apply_non_transform(
                in_tensor, params, flags, transform=transform
            )
        else:
            output = self.apply_non_transform(
                in_tensor, params, flags, transform=transform
            )
>           applied = self.apply_transform(
                jax_get_item(in_tensor, to_apply),
                params,
                flags,
                transform=transform
                if transform is None
                else jax_get_item(transform, to_apply),
            )

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/base.py:342: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_RandomClahe(clip_limit_factor=(40.0, 40.0), p=0.5, p_batch=1.0, same_on_batch=False, grid_size=(8, 8), slow_and_differentiable=False)
input = Array([[[[0.67410076, 0.71703684, 0.76711017, 0.82093984, 0.8626389 ,
          0.8296585 , 0.91898054, 0.8856318 , 0...., 0.5806628 , 0.5914575 ,
          0.5280768 , 0.4419577 , 0.22794598, 0.5367022 , 0.38298446]]]],      dtype=float32)
params = {'batch_prob': Array([0., 1.], dtype=float32), 'clip_limit_factor': Array([40.], dtype=float32), 'forward_input_shape': Array([ 2,  3, 10, 20], dtype=int64)}
flags = {'grid_size': (8, 8), 'slow_and_differentiable': False}, transform = Array([[[1., 0., 0.],
        [0., 1., 0.],
        [0., 0., 1.]]], dtype=float32)

    def apply_transform(self, input, params, flags, transform=None):
        from ....enhance.equalization import jax_equalize_clahe
    
        clip_limit = float(params["clip_limit_factor"][0])
>       return jax_equalize_clahe(
            input, clip_limit, flags["grid_size"], flags["slow_and_differentiable"]
        )

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/_2d/intensity/clahe.py:56: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = Array([[[[0.67410076, 0.71703684, 0.76711017, 0.82093984, 0.8626389 ,
          0.8296585 , 0.91898054, 0.8856318 , 0...., 0.5806628 , 0.5914575 ,
          0.5280768 , 0.4419577 , 0.22794598, 0.5367022 , 0.38298446]]]],      dtype=float32)
args = (40.0, (8, 8), False), kwargs = {}, jax_numel_frnt_ = <function jax_numel_frnt_ at 0x7f8596342320>, jax_shape_frnt_ = <function jax_shape_frnt_ at 0x7f85a156dbd0>
jax_view_frnt_ = <function jax_view_frnt_ at 0x7f85a1566170>, input_shape = ivy.frontends.torch.Size([1, 3, 10, 20])

    @wraps(f)
    def _wrapper(input, *args, **kwargs):
        from ...ivy.functional.frontends.torch.tensor import jax_numel_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_view_frnt_
    
        if not isinstance(input, (jax.Array, nnx.Param)):
            raise TypeError(f"Input input type is not a Tensor. Got {type(input)}")
        if jax_numel_frnt_(input) == 0:
            raise ValueError("Invalid input tensor, it is empty.")
        input_shape = jax_shape_frnt_(input)
        input = jax__to_bchw(input)
>       output = f(input, *args, **kwargs)

ivy_transpiled_outputs/jax_outputs/kornia/utils/image.py:71: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = Array([[[[0.67410076, 0.71703684, 0.76711017, 0.82093984, 0.8626389 ,
          0.8296585 , 0.91898054, 0.8856318 , 0...., 0.5806628 , 0.5914575 ,
          0.5280768 , 0.4419577 , 0.22794598, 0.5367022 , 0.38298446]]]],      dtype=float32)
clip_limit = 40.0, grid_size = (8, 8), slow_and_differentiable = False

    @jax_perform_keep_shape_image
    def jax_equalize_clahe(
        input, clip_limit=40.0, grid_size=(8, 8), slow_and_differentiable=False
    ):
        from ...ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_reshape_as_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_permute_frnt_
        from ...ivy.functional.backends.jax.general import jax_get_item
        from ...ivy.functional.frontends.torch.tensor import jax_dim_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_squeeze_frnt_
    
        if not isinstance(clip_limit, (float,)):
            raise TypeError(f"Input clip_limit type is not float. Got {type(clip_limit)}")
        if not isinstance(grid_size, (tuple,)):
            raise TypeError(f"Input grid_size type is not Tuple. Got {type(grid_size)}")
        if len(grid_size) != 2:
            raise TypeError(
                f"Input grid_size is not a Tuple with 2 elements. Got {len(grid_size)}"
            )
        if isinstance(grid_size[0], (float,)) or isinstance(grid_size[1], (float,)):
            raise TypeError("Input grid_size type is not valid, must be a Tuple[int, int].")
        if grid_size[0] <= 0 or grid_size[1] <= 0:
            raise ValueError(f"Input grid_size elements must be positive. Got {grid_size}")
        imgs: typing.Any = input
>       hist_tiles, img_padded = jax__compute_tiles(imgs, grid_size, True)

ivy_transpiled_outputs/jax_outputs/kornia/enhance/equalization.py:485: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

imgs = Array([[[[0.67410076, 0.71703684, 0.76711017, 0.82093984, 0.8626389 ,
          0.8296585 , 0.91898054, 0.8856318 , 0...., 0.5806628 , 0.5914575 ,
          0.5280768 , 0.4419577 , 0.22794598, 0.5367022 , 0.38298446]]]],      dtype=float32)
grid_size = (8, 8), even_tile_size = True

    def jax__compute_tiles(imgs, grid_size, even_tile_size=False):
        from ...ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ...ivy.functional.frontends.torch.nn.functional.vision_functions import (
            jax_pad_frnt,
        )
        from ...ivy.functional.frontends.torch.tensor import jax_contiguous_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_squeeze_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_unfold_frnt_
    
        batch: typing.Any = imgs
        h, w = jax_shape_frnt_(batch)[-2:][0], jax_shape_frnt_(batch)[-2:][1]
        kernel_vert: typing.Any = math.ceil(h / grid_size[0])
        kernel_horz: typing.Any = math.ceil(w / grid_size[1])
        if even_tile_size:
            kernel_vert = kernel_vert + (1 if kernel_vert % 2 else 0)
            kernel_horz = kernel_horz + (1 if kernel_horz % 2 else 0)
        pad_vert = kernel_vert * grid_size[0] - h
        pad_horz = kernel_horz * grid_size[1] - w
        if pad_vert > jax_shape_frnt_(batch)[-2] or pad_horz > jax_shape_frnt_(batch)[-1]:
            raise ValueError(
                "Cannot compute tiles on the image according to the given grid size"
            )
        if pad_vert > 0 or pad_horz > 0:
            batch = jax_pad_frnt(batch, [0, pad_horz, 0, pad_vert], mode="reflect")
        c: typing.Any = jax_shape_frnt_(batch)[-3]
        tiles: typing.Any = jax_contiguous_frnt_(
            jax_squeeze_frnt_(
>               jax_unfold_frnt_(
                    jax_unfold_frnt_(
                        jax_unfold_frnt_(batch, 1, c, c), 2, kernel_vert, kernel_vert
                    ),
                    3,
                    kernel_horz,
                    kernel_horz,
                ),
                1,
            )
        )

ivy_transpiled_outputs/jax_outputs/kornia/enhance/equalization.py:60: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (Array([[[[[[0.67410076, 0.71703684, 0.76711017, ..., 0.05223185,
            0.4098795 , 0.8856318 ],
           [0.6...0.41669524, 0.98221046, 0.14402437, ..., 0.56874293,
            0.50027275, 0.56189716]]]]]], dtype=float32), 3, 4, 4)
kwargs = {}, jax_is_array_bknd = <function jax_is_array_bknd at 0x7f85a122a680>
array_like = Array([[[[[[0.67410076, 0.71703684, 0.76711017, ..., 0.05223185,
            0.4098795 , 0.8856318 ],
           [0.62...         [0.41669524, 0.98221046, 0.14402437, ..., 0.56874293,
            0.50027275, 0.56189716]]]]]], dtype=float32)

    @functools.wraps(fn)
    def wrapper(*args, **kwargs):
        from ..functional.ivy.general import jax_is_array_bknd
    
        array_like = args[0]
        if hasattr(array_like, "__class__") and array_like.__class__.__name__ in [
            "list",
            "tuple",
        ]:
            array_like = array_like[0]
        if jax_is_array_bknd(array_like):
>           return fn(*args, **kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/utils/decorator_utils.py:200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = Array([[[[[[0.67410076, 0.71703684, 0.76711017, ..., 0.05223185,
            0.4098795 , 0.8856318 ],
           [0.62...         [0.41669524, 0.98221046, 0.14402437, ..., 0.56874293,
            0.50027275, 0.56189716]]]]]], dtype=float32)
dimension = 3, size = 4, step = 4

    @jax_handle_methods
    def jax_unfold_frnt_(tensor, dimension, size, step):
        from ...backends.jax.general import jax_get_item
        from ...backends.jax.general import jax_set_item
        from .indexing_slicing_joining_mutating_ops import jax_stack_frnt
    
        slices = []
        self_shape = tuple(jax_shape_frnt_(tensor))
        for i in range(0, jax_get_item(self_shape, dimension) - size + 1, step):
            slicing = [slice(None)] * len(jax_shape_frnt_(tensor))
            slicing = jax_set_item(slicing, dimension, slice(i, i + size))
            slices.append(jax_get_item(tensor, tuple(slicing)))
>       stacked = jax_stack_frnt(slices, dim=dimension)

ivy_transpiled_outputs/jax_outputs/ivy/functional/frontends/torch/tensor.py:648: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensors = [], dim = 3

    def jax_stack_frnt(tensors, dim=0, *, out=None):
        from ...backends.jax.manipulation import jax_stack
    
>       return jax_stack(tensors, axis=dim, out=out)

ivy_transpiled_outputs/jax_outputs/ivy/functional/frontends/torch/indexing_slicing_joining_mutating_ops.py:136: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

arrays = []

    def jax_stack(
        arrays: Union[Tuple[jax.Array], List[jax.Array]],
        /,
        *,
        axis: int = 0,
        out: Optional[jax.Array] = None,
    ):
        try:
            return jax.numpy.stack(arrays, axis=axis)
        except ValueError as error:
>           raise Exception(error) from error
E           Exception: Need at least one array to stack.

ivy_transpiled_outputs/jax_outputs/ivy/functional/backends/jax/manipulation.py:149: Exception
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.RandomClahe
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/augmentation/test_augmentation1.py::test_RandomClahe[jax-s2s-False] - Exception: Need at least one array to stack.
============================================================================== 1 failed, 17 passed in 3290.81s (0:54:50) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 17 items

kornia/test_feature2.py ...........ssssss                                                                                                                                                        [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
============================================================================== 11 passed, 6 skipped in 623.23s (0:10:23) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 10 items

kornia/test_feature5.py .......FF.                                                                                                                                                               [100%]

=============================================================================================== FAILURES ===============================================================================================
______________________________________________________________________________________ test_DeDoDe[jax-s2s-False] ______________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_DeDoDe(target_framework, mode, backend_compile):
        print("kornia.feature.DeDoDe")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledDeDoDe = ivy.transpile(kornia.feature.DeDoDe, source="torch", target=target_framework)
    
        x = torch.rand(1, 3, 256, 256)
        transpiled_x = _nest_torch_tensor_to_new_framework(x, target_framework)
    
        model = kornia.feature.DeDoDe(amp_dtype=torch.float32)
        torch_out = model(x)
    
        ivy.set_backend(target_framework)
>       transpiled_model = TranspiledDeDoDe(amp_dtype=ivy.as_native_dtype("float32"))

kornia/test_feature5.py:182: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.dedode.dedode.jax_DeDoDe'>, args = (), kwargs = {'amp_dtype': dtype('float32')}

    def __call__(cls, *args: Any, **kwargs: Any) -> Any:
>     return _graph_node_meta_call(cls, *args, **kwargs)

/opt/fw/jax/flax/nnx/nnx/object.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.dedode.dedode.jax_DeDoDe'>, args = (), kwargs = {'amp_dtype': dtype('float32')}, node = jax_DeDoDe()

    def _graph_node_meta_call(cls: tp.Type[G], *args, **kwargs) -> G:
      node = cls.__new__(cls, *args, **kwargs)
      vars(node)['_object__state'] = ObjectState()
>     cls._object_meta_construct(node, *args, **kwargs)

/opt/fw/jax/flax/nnx/nnx/object.py:88: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.dedode.dedode.jax_DeDoDe'>, self = jax_DeDoDe(), args = (), kwargs = {'amp_dtype': dtype('float32')}

    def _object_meta_construct(cls, self, *args, **kwargs):
>     self.__init__(*args, **kwargs)

/opt/fw/jax/flax/nnx/nnx/object.py:82: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_DeDoDe(), detector_model = 'L', descriptor_model = 'G', amp_dtype = dtype('float32')

    def __init__(self, detector_model="L", descriptor_model="G", amp_dtype=jnp.float16):
        from .dedode_models import jax_get_detector
        from .dedode_models import jax_get_descriptor
        from ...enhance.normalize import jax_Normalize
        from ....ivy.functional.frontends.torch.creation_ops import jax_tensor_frnt
    
        self.super___init__(
            detector_model=detector_model,
            descriptor_model=descriptor_model,
            amp_dtype=amp_dtype,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
>       self.detector: typing.Any = jax_get_detector(detector_model, amp_dtype)

ivy_transpiled_outputs/jax_outputs/kornia/feature/dedode/dedode.py:65: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

kind = 'L', amp_dtype = dtype('float32')

    def jax_get_detector(kind="L", amp_dtype=jnp.float16):
        if kind == "L":
>           return jax_dedode_detector_L(amp_dtype)

ivy_transpiled_outputs/jax_outputs/kornia/feature/dedode/dedode_models.py:214: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

amp_dtype = dtype('float32')

    def jax_dedode_detector_L(amp_dtype=jnp.float16):
        from ....torch.nn.modules.container import jax_ModuleDict
        from .decoder import jax_ConvRefiner
        from .encoder import jax_VGG19
        from .decoder import jax_Decoder
        from .detector import jax_DeDoDeDetector
    
        NUM_PROTOTYPES = 1
        residual = True
        hidden_blocks = 8
        amp = True
        conv_refiner = jax_ModuleDict(
            {
>               "8": jax_ConvRefiner(
                    512,
                    512,
                    256 + NUM_PROTOTYPES,
                    hidden_blocks=hidden_blocks,
                    residual=residual,
                    amp=amp,
                    amp_dtype=amp_dtype,
                ),
                "4": jax_ConvRefiner(
                    256 + 256,
                    256,
                    128 + NUM_PROTOTYPES,
                    hidden_blocks=hidden_blocks,
                    residual=residual,
                    amp=amp,
                    amp_dtype=amp_dtype,
                ),
                "2": jax_ConvRefiner(
                    128 + 128,
                    128,
                    64 + NUM_PROTOTYPES,
                    hidden_blocks=hidden_blocks,
                    residual=residual,
                    amp=amp,
                    amp_dtype=amp_dtype,
                ),
                "1": jax_ConvRefiner(
                    64 + 64,
                    64,
                    1 + NUM_PROTOTYPES,
                    hidden_blocks=hidden_blocks,
                    residual=residual,
                    amp=amp,
                    amp_dtype=amp_dtype,
                ),
            }
        )

ivy_transpiled_outputs/jax_outputs/kornia/feature/dedode/dedode_models.py:43: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.dedode.decoder.jax_ConvRefiner'>, args = (512, 512, 257)
kwargs = {'amp': True, 'amp_dtype': dtype('float32'), 'hidden_blocks': 8, 'residual': True}

    def __call__(cls, *args: Any, **kwargs: Any) -> Any:
>     return _graph_node_meta_call(cls, *args, **kwargs)

/opt/fw/jax/flax/nnx/nnx/object.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.dedode.decoder.jax_ConvRefiner'>, args = (512, 512, 257)
kwargs = {'amp': True, 'amp_dtype': dtype('float32'), 'hidden_blocks': 8, 'residual': True}, node = jax_ConvRefiner()

    def _graph_node_meta_call(cls: tp.Type[G], *args, **kwargs) -> G:
      node = cls.__new__(cls, *args, **kwargs)
      vars(node)['_object__state'] = ObjectState()
>     cls._object_meta_construct(node, *args, **kwargs)

/opt/fw/jax/flax/nnx/nnx/object.py:88: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.dedode.decoder.jax_ConvRefiner'>, self = jax_ConvRefiner(), args = (512, 512, 257)
kwargs = {'amp': True, 'amp_dtype': dtype('float32'), 'hidden_blocks': 8, 'residual': True}

    def _object_meta_construct(cls, self, *args, **kwargs):
>     self.__init__(*args, **kwargs)

/opt/fw/jax/flax/nnx/nnx/object.py:82: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_ConvRefiner(), args = (512, 512, 257), kwargs = {'amp': True, 'amp_dtype': dtype('float32'), 'hidden_blocks': 8, 'residual': True}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/utils/decorator_utils.py:245: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_ConvRefiner(), in_dim = 512, hidden_dim = 512, out_dim = 257, dw = True, kernel_size = 5, hidden_blocks = 8, amp = True, residual = True, amp_dtype = dtype('float32')

    @jax_store_config_info
    def __init__(
        self,
        in_dim=6,
        hidden_dim=16,
        out_dim=2,
        dw=True,
        kernel_size=5,
        hidden_blocks=5,
        amp=True,
        residual=False,
        amp_dtype=jnp.float16,
    ):
        from ....torch.nn.modules.container import jax_Sequential
        from ....jax__stateful_layers import FlaxConv
    
        self.super___init__(
            in_dim=in_dim,
            hidden_dim=hidden_dim,
            out_dim=out_dim,
            dw=dw,
            kernel_size=kernel_size,
            hidden_blocks=hidden_blocks,
            amp=amp,
            residual=residual,
            amp_dtype=amp_dtype,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
>       self.block1 = self.create_block(in_dim, hidden_dim, dw=False, kernel_size=1)

ivy_transpiled_outputs/jax_outputs/kornia/feature/dedode/decoder.py:211: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_ConvRefiner(), in_dim = 512, out_dim = 512, dw = False, kernel_size = 1, bias = True, norm_type = <class 'ivy_transpiled_outputs.jax_outputs.jax__stateful_layers.FlaxBatchNorm'>

    def create_block(
        self,
        in_dim,
        out_dim,
        dw=True,
        kernel_size=5,
        bias=True,
        norm_type=FlaxBatchNorm,
    ):
        from ....torch.nn.modules.container import jax_Sequential
        from ....torch.nn.modules.activation import jax_ReLU
        from ....jax__stateful_layers import FlaxConv
        from ....jax__stateful_layers import FlaxBatchNorm
    
        num_groups = 1 if not dw else in_dim
        if dw:
            if out_dim % in_dim != 0:
                raise Exception("outdim must be divisible by indim for depthwise")
        conv1 = FlaxConv(
            in_features=in_dim,
            out_features=out_dim,
            kernel_size=kernel_size,
            strides=1,
            padding=kernel_size // 2,
            padding_mode="zeros",
            use_bias=bias,
            feature_group_count=num_groups,
            input_dilation=1,
            kernel_dilation=1,
        )
        norm = (
>           norm_type(out_dim)
            if norm_type is FlaxBatchNorm
            else norm_type(num_channels=out_dim)
        )

ivy_transpiled_outputs/jax_outputs/kornia/feature/dedode/decoder.py:268: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.jax__stateful_layers.FlaxBatchNorm'>, args = (512,), kwargs = {}

    def __call__(cls, *args: Any, **kwargs: Any) -> Any:
>     return _graph_node_meta_call(cls, *args, **kwargs)

/opt/fw/jax/flax/nnx/nnx/object.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.jax__stateful_layers.FlaxBatchNorm'>, args = (512,), kwargs = {}
node = <[AttributeError("'FlaxBatchNorm' object has no attribute 'num_features'") raised in repr()] FlaxBatchNorm object at 0x7f1861332e00>

    def _graph_node_meta_call(cls: tp.Type[G], *args, **kwargs) -> G:
      node = cls.__new__(cls, *args, **kwargs)
      vars(node)['_object__state'] = ObjectState()
>     cls._object_meta_construct(node, *args, **kwargs)

/opt/fw/jax/flax/nnx/nnx/object.py:88: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.jax__stateful_layers.FlaxBatchNorm'>
self = <[AttributeError("'FlaxBatchNorm' object has no attribute 'num_features'") raised in repr()] FlaxBatchNorm object at 0x7f1861332e00>, args = (512,), kwargs = {}

    def _object_meta_construct(cls, self, *args, **kwargs):
>     self.__init__(*args, **kwargs)

/opt/fw/jax/flax/nnx/nnx/object.py:82: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'FlaxBatchNorm' object has no attribute 'num_features'") raised in repr()] FlaxBatchNorm object at 0x7f1861332e00>, args = (512,), kwargs = {}

    def __init__(self, *args, **kwargs):
        self._previous_frame_info = None
        self._built = False
    
        # Map PyTorch-style parameters to Flax parameters
        self.num_batches_tracked = jnp.array(0)
        self.track_running_stats = kwargs.pop("track_running_stats", True)
    
>       num_features = kwargs.pop("num_features")
E       KeyError: 'num_features'

ivy_transpiled_outputs/jax_outputs/jax__stateful_layers.py:428: KeyError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.DeDoDe
----------------------------------------------------------------------------------------- Captured stderr call -----------------------------------------------------------------------------------------
Downloading: "https://dl.fbaipublicfiles.com/dinov2/dinov2_vitl14/dinov2_vitl14_pretrain.pth" to /root/.cache/torch/hub/checkpoints/dinov2_vitl14_pretrain.pth

  0%|          | 0.00/1.13G [00:00<?, ?B/s]
  0%|          | 1.75M/1.13G [00:00<01:06, 18.3MB/s]
  2%|         | 18.4M/1.13G [00:00<00:11, 109MB/s] 
  3%|         | 35.5M/1.13G [00:00<00:08, 140MB/s]
  5%|         | 53.0M/1.13G [00:00<00:07, 157MB/s]
  6%|         | 70.9M/1.13G [00:00<00:06, 168MB/s]
  8%|         | 88.5M/1.13G [00:00<00:06, 173MB/s]
  9%|         | 106M/1.13G [00:00<00:06, 176MB/s] 
 11%|         | 123M/1.13G [00:00<00:06, 177MB/s]
 12%|        | 141M/1.13G [00:00<00:05, 179MB/s]
 14%|        | 158M/1.13G [00:01<00:05, 180MB/s]
 15%|        | 176M/1.13G [00:01<00:05, 180MB/s]
 17%|        | 193M/1.13G [00:01<00:05, 182MB/s]
 18%|        | 211M/1.13G [00:01<00:05, 182MB/s]
 20%|        | 228M/1.13G [00:01<00:05, 182MB/s]
 21%|        | 246M/1.13G [00:01<00:05, 183MB/s]
 23%|       | 263M/1.13G [00:01<00:05, 183MB/s]
 24%|       | 281M/1.13G [00:01<00:05, 182MB/s]
 26%|       | 298M/1.13G [00:01<00:04, 182MB/s]
 27%|       | 316M/1.13G [00:01<00:04, 182MB/s]
 29%|       | 333M/1.13G [00:02<00:04, 183MB/s]
 30%|       | 351M/1.13G [00:02<00:04, 183MB/s]
 32%|      | 368M/1.13G [00:02<00:04, 183MB/s]
 33%|      | 386M/1.13G [00:02<00:04, 182MB/s]
 35%|      | 403M/1.13G [00:02<00:04, 183MB/s]
 36%|      | 421M/1.13G [00:02<00:04, 183MB/s]
 38%|      | 438M/1.13G [00:02<00:04, 183MB/s]
 39%|      | 456M/1.13G [00:02<00:04, 181MB/s]
 41%|      | 474M/1.13G [00:02<00:03, 182MB/s]
 42%|     | 491M/1.13G [00:02<00:03, 182MB/s]
 44%|     | 508M/1.13G [00:03<00:03, 182MB/s]
 45%|     | 526M/1.13G [00:03<00:03, 183MB/s]
 47%|     | 544M/1.13G [00:03<00:03, 183MB/s]
 48%|     | 561M/1.13G [00:03<00:03, 182MB/s]
 50%|     | 579M/1.13G [00:03<00:03, 182MB/s]
 51%|    | 596M/1.13G [00:03<00:03, 182MB/s]
 53%|    | 614M/1.13G [00:03<00:03, 182MB/s]
 54%|    | 631M/1.13G [00:03<00:03, 182MB/s]
 56%|    | 649M/1.13G [00:03<00:02, 183MB/s]
 57%|    | 667M/1.13G [00:03<00:02, 184MB/s]
 59%|    | 684M/1.13G [00:04<00:02, 183MB/s]
 60%|    | 702M/1.13G [00:04<00:02, 184MB/s]
 62%|   | 720M/1.13G [00:04<00:02, 184MB/s]
 64%|   | 737M/1.13G [00:04<00:02, 185MB/s]
 65%|   | 755M/1.13G [00:04<00:02, 184MB/s]
 67%|   | 773M/1.13G [00:04<00:02, 184MB/s]
 68%|   | 790M/1.13G [00:04<00:02, 183MB/s]
 70%|   | 808M/1.13G [00:04<00:02, 183MB/s]
 71%|   | 825M/1.13G [00:04<00:01, 183MB/s]
 73%|  | 843M/1.13G [00:04<00:01, 182MB/s]
 74%|  | 860M/1.13G [00:05<00:01, 182MB/s]
 76%|  | 878M/1.13G [00:05<00:01, 182MB/s]
 77%|  | 895M/1.13G [00:05<00:01, 182MB/s]
 79%|  | 913M/1.13G [00:05<00:01, 183MB/s]
 80%|  | 930M/1.13G [00:05<00:01, 182MB/s]
 82%| | 948M/1.13G [00:05<00:01, 183MB/s]
 83%| | 966M/1.13G [00:05<00:01, 183MB/s]
 85%| | 983M/1.13G [00:05<00:01, 183MB/s]
 86%| | 0.98G/1.13G [00:05<00:00, 183MB/s]
 88%| | 0.99G/1.13G [00:05<00:00, 182MB/s]
 89%| | 1.01G/1.13G [00:06<00:00, 182MB/s]
 91%| | 1.03G/1.13G [00:06<00:00, 183MB/s]
 92%|| 1.05G/1.13G [00:06<00:00, 183MB/s]
 94%|| 1.06G/1.13G [00:06<00:00, 183MB/s]
 95%|| 1.08G/1.13G [00:06<00:00, 183MB/s]
 97%|| 1.10G/1.13G [00:06<00:00, 183MB/s]
 98%|| 1.11G/1.13G [00:06<00:00, 183MB/s]
100%|| 1.13G/1.13G [00:06<00:00, 184MB/s]
100%|| 1.13G/1.13G [00:06<00:00, 180MB/s]
_______________________________________________________________________________________ test_DISK[jax-s2s-False] _______________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_DISK(target_framework, mode, backend_compile):
        print("kornia.feature.DISK")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledDISK = ivy.transpile(kornia.feature.DISK, source="torch", target=target_framework)
    
        x = torch.rand(1, 3, 256, 256)
        transpiled_x = _nest_torch_tensor_to_new_framework(x, target_framework)
    
        model = kornia.feature.DISK()
        torch_out = model(x)
    
        transpiled_model = TranspiledDISK()
        if target_framework == "tensorflow":
            # build the layers
            transpiled_model(transpiled_x)
    
        ivy.sync_models(model, transpiled_model)
    
        transpiled_out = transpiled_model(transpiled_x)
    
>       _to_numpy_and_shape_allclose(torch_out.keypoints, transpiled_out.keypoints)
E       AttributeError: 'list' object has no attribute 'keypoints'

kornia/test_feature5.py:217: AttributeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.DISK
All parameters and buffers are now synced!
----------------------------------------------------------------------------------------- Captured stderr call -----------------------------------------------------------------------------------------
/ivy/ivy-integration-tests/ivy_transpiled_outputs/jax_outputs/torch/nn/modules/instancenorm.py:129: UserWarning: input's size at dim=1 does not match num_features. You can silence this warning by not passing in num_features, which is not used because affine=False
  warnings.warn(
/ivy/ivy-integration-tests/ivy_transpiled_outputs/jax_outputs/torch/nn/modules/instancenorm.py:129: UserWarning: input's size at dim=1 does not match num_features. You can silence this warning by not passing in num_features, which is not used because affine=False
  warnings.warn(
/ivy/ivy-integration-tests/ivy_transpiled_outputs/jax_outputs/torch/nn/modules/instancenorm.py:129: UserWarning: input's size at dim=1 does not match num_features. You can silence this warning by not passing in num_features, which is not used because affine=False
  warnings.warn(
/ivy/ivy-integration-tests/ivy_transpiled_outputs/jax_outputs/torch/nn/modules/instancenorm.py:129: UserWarning: input's size at dim=1 does not match num_features. You can silence this warning by not passing in num_features, which is not used because affine=False
  warnings.warn(
/ivy/ivy-integration-tests/ivy_transpiled_outputs/jax_outputs/torch/nn/modules/instancenorm.py:129: UserWarning: input's size at dim=1 does not match num_features. You can silence this warning by not passing in num_features, which is not used because affine=False
  warnings.warn(
/ivy/ivy-integration-tests/ivy_transpiled_outputs/jax_outputs/torch/nn/modules/instancenorm.py:129: UserWarning: input's size at dim=1 does not match num_features. You can silence this warning by not passing in num_features, which is not used because affine=False
  warnings.warn(
/ivy/ivy-integration-tests/ivy_transpiled_outputs/jax_outputs/torch/nn/modules/instancenorm.py:129: UserWarning: input's size at dim=1 does not match num_features. You can silence this warning by not passing in num_features, which is not used because affine=False
  warnings.warn(
/ivy/ivy-integration-tests/ivy_transpiled_outputs/jax_outputs/torch/nn/modules/instancenorm.py:129: UserWarning: input's size at dim=1 does not match num_features. You can silence this warning by not passing in num_features, which is not used because affine=False
  warnings.warn(
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/test_feature5.py::test_DeDoDe[jax-s2s-False] - KeyError: 'num_features'
FAILED kornia/test_feature5.py::test_DISK[jax-s2s-False] - AttributeError: 'list' object has no attribute 'keypoints'
=============================================================================== 2 failed, 8 passed in 1845.06s (0:30:45) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 4 items

kornia/geometry/test_liegroup.py ssss                                                                                                                                                            [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
========================================================================================== 4 skipped in 5.22s ==========================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 44 items

kornia/test_filters.py ...........................sssssssssssssssss                                                                                                                              [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
============================================================================= 27 passed, 17 skipped in 1759.68s (0:29:19) ==============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 13 items

kornia/test_metrics.py ...F.........                                                                                                                                                             [100%]

=============================================================================================== FAILURES ===============================================================================================
______________________________________________________________________________ test_mean_average_precision[jax-s2s-False] ______________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_mean_average_precision(target_framework, mode, backend_compile):
        trace_args = (
            [torch.tensor([[100, 50, 150, 100.]])],
            [torch.tensor([1.])],
            [torch.tensor([0.7])],
            [torch.tensor([[100, 50, 150, 100.]])],
            [torch.tensor([1.])],
            2,
        )
        trace_kwargs = {}
        test_args = (
            [torch.tensor([[50, 25, 75, 50], [100, 50, 150, 100.]])],
            [torch.tensor([1, 2.])],
            [torch.tensor([0.6, 0.8])],
            [torch.tensor([[50, 25, 75, 50], [100, 50, 150, 100.]])],
            [torch.tensor([1, 2.])],
            3,
        )
        kornia.metrics.mean_average_precision(*trace_args)
        kornia.metrics.mean_average_precision(*test_args)
        test_kwargs = {}
    
        # NOTE: this test fails due to the use of dynamic control flow; skipping
>       _test_function(
            kornia.metrics.mean_average_precision,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
            skip=True,
        )

kornia/test_metrics.py:118: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function mean_average_precision at 0x7ffadf4d8a60>
trace_args = ([Array([[100.,  50., 150., 100.]], dtype=float32)], [Array([1.], dtype=float32)], [Array([0.7], dtype=float32)], [Array([[100.,  50., 150., 100.]], dtype=float32)], [Array([1.], dtype=float32)], 2)
trace_kwargs = {}
test_args = ([Array([[ 50.,  25.,  75.,  50.],
       [100.,  50., 150., 100.]], dtype=float32)], [Array([1., 2.], dtype=float32)]...rray([[ 50.,  25.,  75.,  50.],
       [100.,  50., 150., 100.]], dtype=float32)], [Array([1., 2.], dtype=float32)], 3)
test_kwargs = {}, target = 'jax', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = True, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function mean_average_precision at 0x7ffadf4d8a60>, fn_name = 'kornia.metrics.mean_average_precision'
trace_args = ([Array([[100.,  50., 150., 100.]], dtype=float32)], [Array([1.], dtype=float32)], [Array([0.7], dtype=float32)], [Array([[100.,  50., 150., 100.]], dtype=float32)], [Array([1.], dtype=float32)], 2)
trace_kwargs = {}
test_args = ([Array([[ 50.,  25.,  75.,  50.],
       [100.,  50., 150., 100.]], dtype=float32)], [Array([1., 2.], dtype=float32)]...rray([[ 50.,  25.,  75.,  50.],
       [100.,  50., 150., 100.]], dtype=float32)], [Array([1., 2.], dtype=float32)], 3)
test_kwargs = {}, target = 'jax', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
>       orig_out = fn(*trace_args, **trace_kwargs)

helpers.py:335: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred_boxes = [Array([[100.,  50., 150., 100.]], dtype=float32)], pred_labels = [Array([1.], dtype=float32)], pred_scores = [Array([0.7], dtype=float32)]
gt_boxes = [Array([[100.,  50., 150., 100.]], dtype=float32)], gt_labels = [Array([1.], dtype=float32)], n_classes = 2, threshold = 0.5

    def mean_average_precision(
        pred_boxes: List[Tensor],
        pred_labels: List[Tensor],
        pred_scores: List[Tensor],
        gt_boxes: List[Tensor],
        gt_labels: List[Tensor],
        n_classes: int,
        threshold: float = 0.5,
    ) -> Tuple[Tensor, Dict[int, float]]:
        """Calculate the Mean Average Precision (mAP) of detected objects.
    
        Code altered from https://github.com/sgrvinod/a-PyTorch-Tutorial-to-Object-Detection/blob/master/utils.py#L271.
        Background class (0 index) is excluded.
    
        Args:
            pred_boxes: a tensor list of predicted bounding boxes.
            pred_labels: a tensor list of predicted labels.
            pred_scores: a tensor list of predicted labels' scores.
            gt_boxes: a tensor list of ground truth bounding boxes.
            gt_labels: a tensor list of ground truth labels.
            n_classes: the number of classes.
            threshold: count as a positive if the overlap is greater than the threshold.
    
        Returns:
            mean average precision (mAP), list of average precisions for each class.
    
        Examples:
            >>> boxes, labels, scores = torch.tensor([[100, 50, 150, 100.]]), torch.tensor([1]), torch.tensor([.7])
            >>> gt_boxes, gt_labels = torch.tensor([[100, 50, 150, 100.]]), torch.tensor([1])
            >>> mean_average_precision([boxes], [labels], [scores], [gt_boxes], [gt_labels], 2)
            (tensor(1.), {1: 1.0})
        """
        # these are all lists of tensors of the same length, i.e. number of images
        if not len(pred_boxes) == len(pred_labels) == len(pred_scores) == len(gt_boxes) == len(gt_labels):
            raise AssertionError
    
        # Store all (true) objects in a single continuous tensor while keeping track of the image it is from
        gt_images = []
        for i, labels in enumerate(gt_labels):
>           gt_images.extend([i] * labels.size(0))
E           TypeError: 'int' object is not callable

/opt/miniconda/envs/multienv/lib/python3.10/site-packages/kornia/metrics/mean_average_precision.py:49: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.metrics.mean_average_precision.mean_average_precision
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/test_metrics.py::test_mean_average_precision[jax-s2s-False] - TypeError: 'int' object is not callable
=============================================================================== 1 failed, 12 passed in 748.87s (0:12:28) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 19 items

kornia/geometry/test_camera.py .................ss                                                                                                                                               [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
============================================================================== 17 passed, 2 skipped in 836.79s (0:13:56) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 8 items

kornia/geometry/test_bbox.py ..F.....                                                                                                                                                            [100%]

=============================================================================================== FAILURES ===============================================================================================
___________________________________________________________________________________ test_bbox_to_mask[jax-s2s-False] ___________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_bbox_to_mask(target_framework, mode, backend_compile):
        trace_args = (
            torch.tensor([[[1., 1.], [3., 1.], [3., 2.], [1., 2.]]]),
            5,
            5,
        )
        trace_kwargs = {}
        test_args = (
            torch.tensor([[[2., 2.], [4., 2.], [4., 3.], [2., 3.]]]),
            6,
            6,
        )
        test_kwargs = {}
>       _test_function(
            kornia.geometry.bbox.bbox_to_mask,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/geometry/test_bbox.py:82: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function bbox_to_mask at 0x7f6549115f30>, trace_args = (tensor([[[1., 1.],
         [3., 1.],
         [3., 2.],
         [1., 2.]]]), 5, 5), trace_kwargs = {}
test_args = (tensor([[[2., 2.],
         [4., 2.],
         [4., 3.],
         [2., 3.]]]), 6, 6), test_kwargs = {}, target = 'jax', backend_compile = False, tolerance = 0.001, mode = 's2s'
skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function bbox_to_mask at 0x7f6549115f30>, fn_name = 'kornia.geometry.bbox.bbox_to_mask', trace_args = (tensor([[[1., 1.],
         [3., 1.],
         [3., 2.],
         [1., 2.]]]), 5, 5)
trace_kwargs = {}, test_args = (tensor([[[2., 2.],
         [4., 2.],
         [4., 3.],
         [2., 3.]]]), 6, 6), test_kwargs = {}, target = 'jax', backend_compile = False, tolerance = 0.001
deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
        graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
    
        if deterministic:
>           _to_numpy_and_allclose(orig_out, graph_out, tolerance=tolerance)

helpers.py:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

torch_x = tensor([[[0., 0., 0., 0., 0.],
         [0., 1., 1., 1., 0.],
         [0., 1., 1., 1., 0.],
         [0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.]]])
transpiled_x = Array([[[0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0.]]], dtype=float32), tolerance = 0.001

    def _to_numpy_and_allclose(torch_x, transpiled_x, tolerance=1e-3):
        orig_data = _nest_array_to_numpy(torch_x)
        transpiled_data = _nest_array_to_numpy(transpiled_x)
>       _check_allclose(orig_data, transpiled_data, tolerance=tolerance)

helpers.py:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[0., 0., 0., 0., 0.],
        [0., 1., 1., 1., 0.],
        [0., 1., 1., 1., 0.],
        [0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0.]]], dtype=float32)
y = array([[[0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0.]]], dtype=float32), tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
>           assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
E           AssertionError: numpy array values are not all close

helpers.py:26: AssertionError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.bbox.bbox_to_mask
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/geometry/test_bbox.py::test_bbox_to_mask[jax-s2s-False] - AssertionError: numpy array values are not all close
=============================================================================== 1 failed, 7 passed in 493.64s (0:08:13) ================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 8 items

kornia/test_image.py ........                                                                                                                                                                    [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
==================================================================================== 8 passed in 374.79s (0:06:14) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 1 item

kornia/test_tracking.py F                                                                                                                                                                        [100%]

=============================================================================================== FAILURES ===============================================================================================
_____________________________________________________________________________ test_HomographyTracker[tensorflow-s2s-False] _____________________________________________________________________________

inp = <tf.Variable 'Variable:0' shape=(5, 1, 1) dtype=float32, numpy=
array([[[0.63316965]],

       [[0.304214  ]],

       [[0.75925994]],

       [[0.01494718]],

       [[0.13923502]]], dtype=float32)>
query = slice(None, None, None), val = <tf.Tensor: shape=(1, 5), dtype=float32, numpy=
array([[0.1190625 , 0.2311236 , 0.29962778, 0.2311236 , 0.1190625 ]],
      dtype=float32)>, kwargs = {}

    @functools.wraps(fn)
    def wrapper(inp, query, val, **kwargs):
        try:
>           inp.__setitem__(query, val)
E           AttributeError: 'ResourceVariable' object has no attribute '__setitem__'. Did you mean: '__getitem__'?

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:233: AttributeError

During handling of the above exception, another exception occurred:

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_HomographyTracker(target_framework, mode, backend_compile):
        print("kornia.tracking.HomographyTracker")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledHomographyTracker = ivy.transpile(kornia.tracking.HomographyTracker, source="torch", target=target_framework)
    
        tracker = kornia.tracking.HomographyTracker()
>       transpiled_tracker = TranspiledHomographyTracker()

kornia/test_tracking.py:33: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_HomographyTracker(), initial_matcher = None, fast_matcher = None, ransac = None, minimum_inliers_num = 30

    def __init__(
        self,
        initial_matcher=None,
        fast_matcher=None,
        ransac=None,
        minimum_inliers_num=30,
    ):
        from ..feature.integrated import tensorflow_LocalFeatureMatcher
        from ..feature.integrated import tensorflow_GFTTAffNetHardNet
        from ..feature.matching import tensorflow_DescriptorMatcher
        from ..feature.loftr.loftr import tensorflow_LoFTR
        from ..geometry.ransac import tensorflow_RANSAC
    
        self.super___init__(
            initial_matcher=initial_matcher,
            fast_matcher=fast_matcher,
            ransac=ransac,
            minimum_inliers_num=minimum_inliers_num,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        self.initial_matcher = initial_matcher or tensorflow_LocalFeatureMatcher(
>           tensorflow_GFTTAffNetHardNet(3000),
            tensorflow_DescriptorMatcher("smnn", 0.95),
        )

ivy_transpiled_outputs/tensorflow_outputs/kornia/tracking/planar_tracker.py:60: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_GFTTAffNetHardNet object at 0x7fd141fc66b0>, args = (3000,), kwargs = {}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_GFTTAffNetHardNet object at 0x7fd141fc66b0>, num_features = 3000, upright = False, device = 'cpu'
config = {'nms_size': 15, 'pyramid_levels': 4, 's_mult': 22.0, 'scale_factor_levels': 1.4142135623730951, ...}

    @tensorflow_store_config_info
    def __init__(
        self,
        num_features=8000,
        upright=False,
        device=tensorflow_device_frnt("cpu"),
        config=tensorflow_get_default_detector_config(),
    ):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_to_frnt_
        from .scale_space_detector import tensorflow_MultiResolutionDetector
        from .responses import tensorflow_CornerGFTT
        from .orientation import tensorflow_PassLAF
        from .orientation import tensorflow_LAFOrienter
        from .affine_shape import tensorflow_LAFAffNetShapeEstimator
    
        detector = tensorflow_to_frnt_(
            tensorflow_MultiResolutionDetector(
                tensorflow_CornerGFTT(),
                num_features,
                config,
                ori_module=tensorflow_PassLAF()
                if upright
>               else tensorflow_LAFOrienter(19),
                aff_module=tensorflow_LAFAffNetShapeEstimator(True).eval(),
            ),
            device,
        )

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/integrated.py:352: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'tensorflow_LAFOrienter' object has no attribute 'angle_detector'") raised in repr()] tensorflow_LAFOrienter object at 0x7fd141fc7f40>, args = (19,), kwargs = {}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'tensorflow_LAFOrienter' object has no attribute 'angle_detector'") raised in repr()] tensorflow_LAFOrienter object at 0x7fd141fc7f40>, patch_size = 19, num_angular_bins = 36
angle_detector = None

    @tensorflow_store_config_info
    def __init__(self, patch_size=32, num_angular_bins=36, angle_detector=None):
        self.super___init__(
            patch_size=patch_size,
            num_angular_bins=num_angular_bins,
            angle_detector=angle_detector,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        self.patch_size = patch_size
        self.num_ang_bins = num_angular_bins
        self.angle_detector: typing.Any
        if angle_detector is None:
>           self.angle_detector = tensorflow_PatchDominantGradientOrientation(
                self.patch_size, self.num_ang_bins
            )

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/orientation.py:387: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_PatchDominantGradientOrientation(patch_size=19, num_ang_bins=36, eps=1e-08), args = (19, 36), kwargs = {}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_PatchDominantGradientOrientation(patch_size=19, num_ang_bins=36, eps=1e-08), patch_size = 19, num_angular_bins = 36, eps = 1e-08

    @tensorflow_store_config_info
    def __init__(self, patch_size=32, num_angular_bins=36, eps=1e-08):
        from ..filters.sobel import tensorflow_SpatialGradient
        from ...torch.nn.modules.conv import tensorflow_Conv1d
        from ...ivy.functional.backends.tensorflow.general import tensorflow_set_item
        from ..filters.kernels import tensorflow_get_gaussian_discrete_kernel1d
        from ..filters.kernels import tensorflow_get_gaussian_kernel2d
    
        self.super___init__(
            patch_size=patch_size,
            num_angular_bins=num_angular_bins,
            eps=eps,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        self.patch_size = patch_size
        self.num_ang_bins = num_angular_bins
        self.gradient = tensorflow_SpatialGradient("sobel", 1)
        self.eps = eps
        self.angular_smooth = tensorflow_Conv1d(
            1, 1, kernel_size=5, padding=2, bias=False, padding_mode="circular"
        )
>       self.angular_smooth.weight = tensorflow_set_item(
            self.angular_smooth.weight,
            slice(None, None, None),
            tensorflow_get_gaussian_discrete_kernel1d(5, 1.6),
        )

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/orientation.py:178: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

inp = <tf.Variable 'Variable:0' shape=(5, 1, 1) dtype=float32, numpy=
array([[[0.63316965]],

       [[0.304214  ]],

       [[0.75925994]],

       [[0.01494718]],

       [[0.13923502]]], dtype=float32)>
query = slice(None, None, None), val = <tf.Tensor: shape=(1, 5), dtype=float32, numpy=
array([[0.1190625 , 0.2311236 , 0.29962778, 0.2311236 , 0.1190625 ]],
      dtype=float32)>, kwargs = {}

    @functools.wraps(fn)
    def wrapper(inp, query, val, **kwargs):
        try:
            inp.__setitem__(query, val)
            res = inp
        except IndexError:
            raise
        except Exception:
>           res = fn(inp, query, val, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:238: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (<tf.Variable 'Variable:0' shape=(5, 1, 1) dtype=float32, numpy=
array([[[0.63316965]],

       [[0.304214  ]],

     ... 5), dtype=float32, numpy=
array([[0.1190625 , 0.2311236 , 0.29962778, 0.2311236 , 0.1190625 ]],
      dtype=float32)>)
kwargs = {}, handle_mixed_in_backend = True

    @functools.wraps(fn)
    def _handle_partial_mixed_function(*args, **kwargs):
        handle_mixed_in_backend = False
        if not hasattr(fn, "partial_mixed_handler"):
            handle_mixed_in_backend = True
        else:
            compos = getattr(fn, "compos")
            condition = getattr(fn, "partial_mixed_handler")
        if handle_mixed_in_backend or condition(*args, **kwargs):
>           return fn(*args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/func_wrapper.py:173: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[0.63316965]],

       [[0.304214  ]],

       [[0.75925994]],

       [[0.01494718]],

       [[0.13923502]]], dtype=float32), query = slice(None, None, None)
val = array([[0.1190625 , 0.2311236 , 0.29962778, 0.2311236 , 0.1190625 ]],
      dtype=float32)

    @tensorflow_handle_set_item
    @tensorflow_handle_partial_mixed_function
    def tensorflow_set_item(
        x: Union[tensorflow.Tensor, tensorflow.Variable],
        query: Union[tensorflow.Tensor, tensorflow.Variable, Tuple],
        val: Union[tensorflow.Tensor, tensorflow.Variable],
        /,
        *,
        copy: Optional[bool] = False,
    ):
        if tensorflow.is_tensor(x):
            x = x.numpy()
        if tensorflow.is_tensor(val):
            val = val.numpy()
        if isinstance(query, (tensorflow.Tensor, tensorflow.Variable)):
            query = query.numpy()
        elif isinstance(query, tuple):
            query = tuple(
                q.numpy() if isinstance(q, (tensorflow.Tensor, tensorflow.Variable)) else q
                for q in query
            )
>       x[query] = val
E       ValueError: could not broadcast input array from shape (1,5) into shape (5,1,1)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/backends/tensorflow/general.py:109: ValueError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.tracking.HomographyTracker
----------------------------------------------------------------------------------------- Captured stderr call -----------------------------------------------------------------------------------------
Downloading: "https://github.com/ducha-aiki/affnet/raw/master/pretrained/AffNet.pth" to /root/.cache/torch/hub/checkpoints/AffNet.pth

  0%|          | 0.00/332k [00:00<?, ?B/s]
100%|| 332k/332k [00:00<00:00, 12.3MB/s]
Downloading: "https://github.com/DagnyT/hardnet/raw/master/pretrained/train_liberty_with_aug/checkpoint_liberty_with_aug.pth" to /root/.cache/torch/hub/checkpoints/checkpoint_liberty_with_aug.pth

  0%|          | 0.00/5.10M [00:00<?, ?B/s]
100%|| 5.10M/5.10M [00:00<00:00, 85.4MB/s]
Downloading: "http://cmp.felk.cvut.cz/~mishkdmy/models/loftr_outdoor.ckpt" to /root/.cache/torch/hub/checkpoints/loftr_outdoor.ckpt

  0%|          | 0.00/44.2M [00:00<?, ?B/s]
  0%|          | 128k/44.2M [00:00<02:42, 285kB/s]
  1%|          | 256k/44.2M [00:00<01:38, 468kB/s]
  1%|          | 512k/44.2M [00:00<00:53, 858kB/s]
  2%|         | 896k/44.2M [00:00<00:32, 1.39MB/s]
  4%|         | 1.75M/44.2M [00:01<00:15, 2.80MB/s]
  8%|         | 3.50M/44.2M [00:01<00:07, 5.59MB/s]
 15%|        | 6.50M/44.2M [00:01<00:03, 10.1MB/s]
 21%|        | 9.38M/44.2M [00:01<00:02, 13.0MB/s]
 28%|       | 12.4M/44.2M [00:01<00:02, 15.2MB/s]
 35%|      | 15.4M/44.2M [00:01<00:01, 16.8MB/s]
 42%|     | 18.4M/44.2M [00:01<00:01, 17.9MB/s]
 48%|     | 21.2M/44.2M [00:02<00:01, 18.4MB/s]
 55%|    | 24.1M/44.2M [00:02<00:01, 18.8MB/s]
 61%|   | 27.1M/44.2M [00:02<00:00, 19.2MB/s]
 68%|   | 30.0M/44.2M [00:02<00:00, 19.4MB/s]
 74%|  | 32.9M/44.2M [00:02<00:00, 19.5MB/s]
 81%|  | 35.8M/44.2M [00:02<00:00, 19.4MB/s]
 87%| | 38.6M/44.2M [00:03<00:00, 19.5MB/s]
 94%|| 41.6M/44.2M [00:03<00:00, 19.8MB/s]
100%|| 44.2M/44.2M [00:03<00:00, 14.3MB/s]
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/test_tracking.py::test_HomographyTracker[tensorflow-s2s-False] - ValueError: could not broadcast input array from shape (1,5) into shape (5,1,1)
==================================================================================== 1 failed in 489.54s (0:08:09) =====================================================================================

