========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 38 items

kornia/geometry/test_conversions.py ......................................                                                                                                                       [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
=================================================================================== 38 passed in 1878.40s (0:31:18) ====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 2 items

kornia/geometry/test_boxes.py FF                                                                                                                                                                 [100%]

=============================================================================================== FAILURES ===============================================================================================
___________________________________________________________________________________ test_Boxes[tensorflow-s2s-False] ___________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_Boxes(target_framework, mode, backend_compile):
        print("kornia.geometry.boxes.Boxes")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target_framework)
    
        torch_args = (
            torch.as_tensor([[0, 3, 1, 4], [5, 1, 8, 4]]),
        )
        transpiled_args = _nest_torch_tensor_to_new_framework(torch_args, target_framework)
    
        # test .from_tensor
        torch_boxes = kornia.geometry.boxes.Boxes.from_tensor(*torch_args, mode="xyxy")
>       transpiled_boxes = transpiled_kornia.geometry.boxes.Boxes.from_tensor(*transpiled_args, mode="xyxy")
E       TypeError: 'classmethod' object is not callable

kornia/geometry/test_boxes.py:43: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.boxes.Boxes
__________________________________________________________________________________ test_Boxes3D[tensorflow-s2s-False] __________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_Boxes3D(target_framework, mode, backend_compile):
        print("kornia.geometry.boxes.Boxes3D")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target_framework)
    
        torch_args = (
            torch.as_tensor([[0, 3, 6, 1, 4, 8], [5, 1, 3, 8, 4, 9]]),
        )
        transpiled_args = _nest_torch_tensor_to_new_framework(torch_args, target_framework)
    
        # test .from_tensor
        torch_boxes3d = kornia.geometry.boxes.Boxes3D.from_tensor(*torch_args, mode="xyzxyz")
>       transpiled_boxes3d = transpiled_kornia.geometry.boxes.Boxes3D.from_tensor(*transpiled_args, mode="xyzxyz")
E       TypeError: 'classmethod' object is not callable

kornia/geometry/test_boxes.py:107: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.boxes.Boxes3D
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/geometry/test_boxes.py::test_Boxes[tensorflow-s2s-False] - TypeError: 'classmethod' object is not callable
FAILED kornia/geometry/test_boxes.py::test_Boxes3D[tensorflow-s2s-False] - TypeError: 'classmethod' object is not callable
========================================================================================== 2 failed in 5.99s ===========================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 1 item

kornia/geometry/test_quaternion.py F                                                                                                                                                             [100%]

=============================================================================================== FAILURES ===============================================================================================
____________________________________________________________________________________ test_Quaternion[jax-s2s-False] ____________________________________________________________________________________

args = (Param(
  value=Array([2., 0., 1., 1.], dtype=float32)
),), kwargs = {}, jax_is_array_bknd = <function jax_is_array_bknd at 0x7f26702bdea0>
array_like = Param(
  value=Array([2., 0., 1., 1.], dtype=float32)
), pattern = '_bknd_|_bknd|_frnt_|_frnt', fn_name = 'data', new_fn = Param(
  value=Array([2., 0., 1., 1.], dtype=float32)
)

    @functools.wraps(fn)
    def wrapper(*args, **kwargs):
        from ..functional.ivy.general import jax_is_array_bknd
    
        array_like = args[0]
        if hasattr(array_like, "__class__") and array_like.__class__.__name__ in [
            "list",
            "tuple",
        ]:
            array_like = array_like[0]
        if jax_is_array_bknd(array_like):
            return fn(*args, **kwargs)
        else:
            pattern = "_bknd_|_bknd|_frnt_|_frnt"
            fn_name = extract_function_name(re.sub(pattern, "", fn.__name__))
            try:
                new_fn = getattr(array_like, fn_name)
                if not callable(new_fn):
                    return new_fn
>               return new_fn(*args[1:], **kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/utils/decorator_utils.py:208: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = Param(
  value=Array([2., 0., 1., 1.], dtype=float32)
), args = (), kwargs = {}

    def __call__(self, *args, **kwargs) -> tp.Any:
>     return self.value(*args, **kwargs)  # type: ignore
E     TypeError: 'jaxlib.xla_extension.ArrayImpl' object is not callable

/opt/fw/jax/flax/nnx/variablelib.py:435: TypeError

During handling of the above exception, another exception occurred:
Traceback (most recent call last):
  File "/ivy/ivy-integration-tests/ivy_transpiled_outputs/jax_outputs/ivy/utils/decorator_utils.py", line 208, in wrapper
    return new_fn(*args[1:], **kwargs)
  File "/opt/fw/jax/flax/nnx/variablelib.py", line 435, in __call__
    return self.value(*args, **kwargs)  # type: ignore
TypeError: 'jaxlib.xla_extension.ArrayImpl' object is not callable

During handling of the above exception, another exception occurred:

TypeError: float() argument must be a string or a real number, not 'jax_Quaternion'

The above exception was the direct cause of the following exception:

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_Quaternion(target_framework, mode, backend_compile):
        print("kornia.geometry.quaternion.Quaternion")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledQuaternion = ivy.transpile(Quaternion, source="torch", target=target_framework)
    
        # test Quaternion.identity
    
        torch_q = Quaternion.identity(batch_size=4)
        transpiled_q = TranspiledQuaternion.identity(batch_size=4)
    
        orig_np = _nest_array_to_numpy(torch_q.data)
        transpiled_np = _nest_array_to_numpy(transpiled_q.data)
        _check_allclose(orig_np, transpiled_np)
    
    
        # test Quaternion.__add__
    
        torch_q1 = Quaternion.identity()
        torch_q2 = Quaternion(torch.tensor([2., 0., 1., 1.]))
        torch_q3 = torch_q1 + torch_q2
        transpiled_q1 = TranspiledQuaternion.identity()
        transpiled_q2 = TranspiledQuaternion(_array_to_new_backend(torch.tensor([2., 0., 1., 1.]), target_framework))
>       transpiled_q3 = transpiled_q1 + transpiled_q2

kornia/geometry/test_quaternion.py:42: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = Param(
  value=Array([1., 0., 0., 0.], dtype=float32)
), right = Param(
  value=Array([2., 0., 1., 1.], dtype=float32)
)

    def __add__(self, right):
        from ..core.check import jax_KORNIA_CHECK_TYPE
        from ...ivy.functional.frontends.torch.tensor import jax_data_frnt_
    
        jax_KORNIA_CHECK_TYPE(right, jax_Quaternion)
>       return jax_Quaternion(self.data + jax_data_frnt_(right))

ivy_transpiled_outputs/jax_outputs/kornia/geometry/quaternion.py:59: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (Param(
  value=Array([2., 0., 1., 1.], dtype=float32)
),), kwargs = {}, jax_is_array_bknd = <function jax_is_array_bknd at 0x7f26702bdea0>
array_like = Param(
  value=Array([2., 0., 1., 1.], dtype=float32)
), pattern = '_bknd_|_bknd|_frnt_|_frnt', fn_name = 'data', new_fn = Param(
  value=Array([2., 0., 1., 1.], dtype=float32)
)

    @functools.wraps(fn)
    def wrapper(*args, **kwargs):
        from ..functional.ivy.general import jax_is_array_bknd
    
        array_like = args[0]
        if hasattr(array_like, "__class__") and array_like.__class__.__name__ in [
            "list",
            "tuple",
        ]:
            array_like = array_like[0]
        if jax_is_array_bknd(array_like):
            return fn(*args, **kwargs)
        else:
            pattern = "_bknd_|_bknd|_frnt_|_frnt"
            fn_name = extract_function_name(re.sub(pattern, "", fn.__name__))
            try:
                new_fn = getattr(array_like, fn_name)
                if not callable(new_fn):
                    return new_fn
                return new_fn(*args[1:], **kwargs)
            except Exception:
>               return fn(*args, **kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/utils/decorator_utils.py:210: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = Param(
  value=Array([2., 0., 1., 1.], dtype=float32)
)

    @jax_handle_methods
    def jax_data_frnt_(tensor):
        from .creation_ops import jax_tensor_frnt
        from ...backends.jax.gradients import jax_stop_gradient
    
>       return jax_tensor_frnt(jax_stop_gradient(tensor, preserve_type=False))

ivy_transpiled_outputs/jax_outputs/ivy/functional/frontends/torch/tensor.py:134: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = [Param(
  value=Array([2., 0., 1., 1.], dtype=float32)
)], kwargs = {'preserve_type': False}, jax_is_array_bknd = <function jax_is_array_bknd at 0x7f26702bdea0>
jax_set_item = <function jax_set_item at 0x7f26702b1240>, jax_asarray = <function jax_asarray at 0x7f26702be7a0>, jax_get_item = <function jax_get_item at 0x7f26702b1090>, num_args = 1
type_hints = mappingproxy(OrderedDict([('x', <Parameter "x: jax.Array">), ('preserve_type', <Parameter "preserve_type: bool = True">), ('out', <Parameter "out: Optional[jax.Array] = None">)]))
parameters = ['x', 'preserve_type', 'out'], annotations = [<class 'jax.Array'>, <class 'bool'>, typing.Optional[jax.Array]], device = CpuDevice(id=0), i = 0

    @functools.wraps(fn)
    def _handle_array_like_without_promotion(*args, **kwargs):
        from .functional.ivy.general import jax_is_array_bknd
        from .functional.backends.jax.general import jax_set_item
        from .functional.backends.jax.creation import jax_asarray
        from .functional.backends.jax.general import jax_get_item
    
        args = list(args)
        num_args = len(args)
        try:
            type_hints = inspect.signature(fn).parameters
        except (TypeError, ValueError):
            return fn(*args, **kwargs)
        parameters = list(type_hints.keys())
        annotations = [param.annotation for param in type_hints.values()]
        device = jax__get_preferred_device(args, kwargs)
        for i, (annotation, parameter, arg) in enumerate(
            zip(annotations, parameters, args)
        ):
            annotation_str = str(annotation)
            if (
                ("rray" in annotation_str or "Tensor" in annotation_str)
                and parameter != "out"
                and all(
                    sq not in annotation_str
                    for sq in ["Sequence", "List", "Tuple", "float", "int", "bool"]
                )
            ):
                if i < num_args:
                    if arg is None or jax__check_in_nested_sequence(
                        arg, value=Ellipsis, _type=slice
                    ):
                        continue
                    if not jax_is_array_bknd(arg):
>                       args = jax_set_item(args, i, jax_asarray(arg, device=device))

ivy_transpiled_outputs/jax_outputs/ivy/func_wrapper.py:123: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = [Param(
  value=Array([2., 0., 1., 1.], dtype=float32)
)], kwargs = {'device': CpuDevice(id=0)}, jax_is_array_bknd = <function jax_is_array_bknd at 0x7f26702bdea0>
jax_set_item = <function jax_set_item at 0x7f26702b1240>, jax_asarray = <function jax_asarray at 0x7f26702be7a0>, jax_get_item = <function jax_get_item at 0x7f26702b1090>, num_args = 1
type_hints = mappingproxy(OrderedDict([('obj', <Parameter "obj: Union[jax.Array, bool, int, float, tuple, ivy_transpiled_outputs.ja...', <Parameter "device: jaxlib.xla_extension.Device = None">), ('out', <Parameter "out: Optional[jax.Array] = None">)]))
parameters = ['obj', 'copy', 'dtype', 'device', 'out']
annotations = [typing.Union[jax.Array, bool, int, float, tuple, ivy_transpiled_outputs.jax_outputs.ivy.functional.ivy.creation.jax_N...typing.Optional[bool], typing.Optional[numpy.dtype], <class 'jaxlib.xla_extension.Device'>, typing.Optional[jax.Array]]
device = None, i = 0

    @functools.wraps(fn)
    def _handle_array_like_without_promotion(*args, **kwargs):
        from .functional.ivy.general import jax_is_array_bknd
        from .functional.backends.jax.general import jax_set_item
        from .functional.backends.jax.creation import jax_asarray
        from .functional.backends.jax.general import jax_get_item
    
        args = list(args)
        num_args = len(args)
        try:
            type_hints = inspect.signature(fn).parameters
        except (TypeError, ValueError):
            return fn(*args, **kwargs)
        parameters = list(type_hints.keys())
        annotations = [param.annotation for param in type_hints.values()]
        device = jax__get_preferred_device(args, kwargs)
        for i, (annotation, parameter, arg) in enumerate(
            zip(annotations, parameters, args)
        ):
            annotation_str = str(annotation)
            if (
                ("rray" in annotation_str or "Tensor" in annotation_str)
                and parameter != "out"
                and all(
                    sq not in annotation_str
                    for sq in ["Sequence", "List", "Tuple", "float", "int", "bool"]
                )
            ):
                if i < num_args:
                    if arg is None or jax__check_in_nested_sequence(
                        arg, value=Ellipsis, _type=slice
                    ):
                        continue
                    if not jax_is_array_bknd(arg):
                        args = jax_set_item(args, i, jax_asarray(arg, device=device))
                elif parameters in kwargs:
                    kwarg = jax_get_item(kwargs, parameter)
                    if not jax_is_array_bknd(kwarg):
                        kwargs = jax_set_item(
                            kwargs, parameter, jax_asarray(kwarg, device=device)
                        )
>       return fn(*args, **kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/func_wrapper.py:130: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype = None, args = (Param(
  value=Array([2., 0., 1., 1.], dtype=float32)
),), kwargs = {'device': CpuDevice(id=0)}, jax_default_dtype_bknd = <function jax_default_dtype_bknd at 0x7f26702bd3f0>
jax_to_ivy_bknd_ = <function jax_to_ivy_bknd_ at 0x7f2670249750>, new_arg = Param(
  value=Array([2., 0., 1., 1.], dtype=float32)
)
new_args = (Param(
  value=Array([2., 0., 1., 1.], dtype=float32)
),)

    @functools.wraps(fn)
    def _asarray_to_native_arrays_and_back_wrapper(*args, dtype=None, **kwargs):
        from .data_type import jax_default_dtype_bknd
        from ...data_classes.array.conversions import jax_to_ivy_bknd_
    
        new_arg = args[0]
        new_args = (new_arg,) + args[1:]
        if dtype is not None:
            dtype = jax_default_dtype_bknd(dtype=dtype, as_native=True)
>       return jax_to_ivy_bknd_(fn(*new_args, dtype=dtype, **kwargs))

ivy_transpiled_outputs/jax_outputs/ivy/functional/ivy/creation.py:53: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype = <class 'jax.numpy.float32'>, args = (Param(
  value=Array([2., 0., 1., 1.], dtype=float32)
),), kwargs = {'device': CpuDevice(id=0)}
jax_default_float_dtype_bknd = <function jax_default_float_dtype_bknd at 0x7f26702bd2d0>, jax_as_native_dtype = <function jax_as_native_dtype at 0x7f26702bf6d0>
jax_exists_bknd = <function jax_exists_bknd at 0x7f26702bdfc0>, jax_nested_map_bknd = <function jax_nested_map_bknd at 0x7f26702be3b0>
jax_promote_types_bknd = <function jax_promote_types_bknd at 0x7f26702bd900>, arr = Param(
  value=Array([2., 0., 1., 1.], dtype=float32)
), dtype_list = [<class 'jax.numpy.float32'>]

    @functools.wraps(fn)
    def _asarray_infer_dtype_wrapper(*args, dtype=None, **kwargs):
        from .data_type import jax_default_float_dtype_bknd
        from ..backends.jax.data_type import jax_as_native_dtype
        from .general import jax_exists_bknd
        from .nest import jax_nested_map_bknd
        from .data_type import jax_promote_types_bknd
    
        def _infer_dtype(obj):
            from .data_type import jax_default_dtype_bknd
    
            if isinstance(obj, tuple):
                obj = list(obj)
            if hasattr(obj, "dtype"):
                return obj.dtype.name if isinstance(obj, np.ndarray) else obj.dtype
            else:
                return jax_default_dtype_bknd(item=obj)
    
        if not jax_exists_bknd(dtype):
            arr = args[0]
            dtype_list = [
                jax_nested_map_bknd(lambda x: _infer_dtype(x), arr, shallow=False)
            ]
            dtype_list = jax__flatten_nest_bknd(dtype_list)
            dtype_list = list(set(dtype_list))
            if len(dtype_list) != 0:
                dtype = dtype_list[0]
                for dt in dtype_list[1:]:
                    dtype = jax_promote_types_bknd(dtype, dt)
            else:
                dtype = jax_default_float_dtype_bknd()
            dtype = jax_as_native_dtype(dtype)
>       return fn(*args, dtype=dtype, **kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/functional/ivy/creation.py:92: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

obj = Param(
  value=Array([2., 0., 1., 1.], dtype=float32)
)

    @jax_handle_array_like_without_promotion
    @jax__asarray_to_native_arrays_and_back_bknd
    @jax__asarray_infer_dtype_bknd
    def jax_asarray(
        obj: Union[
            jax.Array,
            bool,
            int,
            float,
            tuple,
            jax_NestedSequence_bknd,
            SupportsBufferProtocol,
            np.ndarray,
        ],
        /,
        *,
        copy: Optional[bool] = None,
        dtype: Optional[jax.numpy.dtype] = None,
        device: jaxlib.xla_extension.Device = None,
        out: Optional[jax.Array] = None,
    ):
        from ...ivy.device import jax_dev_bknd
    
>       ret = jax.numpy.asarray(obj, dtype=dtype)

ivy_transpiled_outputs/jax_outputs/ivy/functional/backends/jax/creation.py:64: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = Param(
  value=Array([2., 0., 1., 1.], dtype=float32)
), dtype = dtype('float32'), order = None

    def asarray(a: Any, dtype: DTypeLike | None = None, order: str | None = None,
                *, copy: bool | None = None,
                device: xc.Device | Sharding | None = None) -> Array:
      """Convert an object to a JAX array.
    
      JAX implementation of :func:`numpy.asarray`.
    
      Args:
        a: an object that is convertible to an array. This includes JAX
          arrays, NumPy arrays, Python scalars, Python collections like lists
          and tuples, objects with an ``__array__`` method, and objects
          supporting the Python buffer protocol.
        dtype: optionally specify the dtype of the output array. If not
          specified it will be inferred from the input.
        order: not implemented in JAX
        copy: optional boolean specifying the copy mode. If True, then always
          return a copy. If False, then error if a copy is necessary. Default is
          None, which will only copy when necessary.
        device: optional :class:`~jax.Device` or :class:`~jax.sharding.Sharding`
          to which the created array will be committed.
    
      Returns:
        A JAX array constructed from the input.
    
      See also:
        - :func:`jax.numpy.array`: like `asarray`, but defaults to `copy=True`.
        - :func:`jax.numpy.from_dlpack`: construct a JAX array from an object
          that implements the dlpack interface.
        - :func:`jax.numpy.frombuffer`: construct a JAX array from an object
          that implements the buffer interface.
    
      Examples:
        Constructing JAX arrays from Python scalars:
    
        >>> jnp.asarray(True)
        Array(True, dtype=bool)
        >>> jnp.asarray(42)
        Array(42, dtype=int32, weak_type=True)
        >>> jnp.asarray(3.5)
        Array(3.5, dtype=float32, weak_type=True)
        >>> jnp.asarray(1 + 1j)
        Array(1.+1.j, dtype=complex64, weak_type=True)
    
        Constructing JAX arrays from Python collections:
    
        >>> jnp.asarray([1, 2, 3])  # list of ints -> 1D array
        Array([1, 2, 3], dtype=int32)
        >>> jnp.asarray([(1, 2, 3), (4, 5, 6)])  # list of tuples of ints -> 2D array
        Array([[1, 2, 3],
               [4, 5, 6]], dtype=int32)
        >>> jnp.asarray(range(5))
        Array([0, 1, 2, 3, 4], dtype=int32)
    
        Constructing JAX arrays from NumPy arrays:
    
        >>> jnp.asarray(np.linspace(0, 2, 5))
        Array([0. , 0.5, 1. , 1.5, 2. ], dtype=float32)
    
        Constructing a JAX array via the Python buffer interface, using Python's
        built-in :mod:`array` module.
    
        >>> from array import array
        >>> pybuffer = array('i', [2, 3, 5, 7])
        >>> jnp.asarray(pybuffer)
        Array([2, 3, 5, 7], dtype=int32)
      """
      # For copy=False, the array API specifies that we raise a ValueError if the input supports
      # the buffer protocol but a copy is required. Since array() supports the buffer protocol
      # via numpy, this is only the case when the default device is not 'cpu'
      if (copy is False and not isinstance(a, Array)
          and jax.default_backend() != 'cpu'
          and _supports_buffer_protocol(a)):
        raise ValueError(f"jnp.asarray: cannot convert object of type {type(a)} to JAX Array "
                         f"on backend={jax.default_backend()!r} with copy=False. "
                          "Consider using copy=None or copy=True instead.")
      dtypes.check_user_dtype_supported(dtype, "asarray")
      if dtype is not None:
        dtype = dtypes.canonicalize_dtype(dtype, allow_extended_dtype=True)  # type: ignore[assignment]
>     return array(a, dtype=dtype, copy=bool(copy), order=order, device=device)

/opt/fw/jax/jax/_src/numpy/lax_numpy.py:5191: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

object = Param(
  value=Array([2., 0., 1., 1.], dtype=float32)
), dtype = dtype('float32'), copy = False, order = None, ndmin = 0

    def array(object: Any, dtype: DTypeLike | None = None, copy: bool = True,
              order: str | None = "K", ndmin: int = 0,
              *, device: xc.Device | Sharding | None = None) -> Array:
      """Convert an object to a JAX array.
    
      JAX implementation of :func:`numpy.array`.
    
      Args:
        object: an object that is convertible to an array. This includes JAX
          arrays, NumPy arrays, Python scalars, Python collections like lists
          and tuples, objects with an ``__array__`` method, and objects
          supporting the Python buffer protocol.
        dtype: optionally specify the dtype of the output array. If not
          specified it will be inferred from the input.
        copy: specify whether to force a copy of the input. Default: True.
        order: not implemented in JAX
        ndmin: integer specifying the minimum number of dimensions in the
          output array.
        device: optional :class:`~jax.Device` or :class:`~jax.sharding.Sharding`
          to which the created array will be committed.
    
      Returns:
        A JAX array constructed from the input.
    
      See also:
        - :func:`jax.numpy.asarray`: like `array`, but by default only copies
          when necessary.
        - :func:`jax.numpy.from_dlpack`: construct a JAX array from an object
          that implements the dlpack interface.
        - :func:`jax.numpy.frombuffer`: construct a JAX array from an object
          that implements the buffer interface.
    
      Examples:
        Constructing JAX arrays from Python scalars:
    
        >>> jnp.array(True)
        Array(True, dtype=bool)
        >>> jnp.array(42)
        Array(42, dtype=int32, weak_type=True)
        >>> jnp.array(3.5)
        Array(3.5, dtype=float32, weak_type=True)
        >>> jnp.array(1 + 1j)
        Array(1.+1.j, dtype=complex64, weak_type=True)
    
        Constructing JAX arrays from Python collections:
    
        >>> jnp.array([1, 2, 3])  # list of ints -> 1D array
        Array([1, 2, 3], dtype=int32)
        >>> jnp.array([(1, 2, 3), (4, 5, 6)])  # list of tuples of ints -> 2D array
        Array([[1, 2, 3],
               [4, 5, 6]], dtype=int32)
        >>> jnp.array(range(5))
        Array([0, 1, 2, 3, 4], dtype=int32)
    
        Constructing JAX arrays from NumPy arrays:
    
        >>> jnp.array(np.linspace(0, 2, 5))
        Array([0. , 0.5, 1. , 1.5, 2. ], dtype=float32)
    
        Constructing a JAX array via the Python buffer interface, using Python's
        built-in :mod:`array` module.
    
        >>> from array import array
        >>> pybuffer = array('i', [2, 3, 5, 7])
        >>> jnp.array(pybuffer)
        Array([2, 3, 5, 7], dtype=int32)
      """
      if order is not None and order != "K":
        raise NotImplementedError("Only implemented for order='K'")
    
      # check if the given dtype is compatible with JAX
      dtypes.check_user_dtype_supported(dtype, "array")
    
      # Here we make a judgment call: we only return a weakly-typed array when the
      # input object itself is weakly typed. That ensures asarray(x) is a no-op
      # whenever x is weak, but avoids introducing weak types with something like
      # array([1, 2, 3])
      weak_type = dtype is None and dtypes.is_weakly_typed(object)
      sharding = canonicalize_device_to_sharding(device)
    
      # Use device_put to avoid a copy for ndarray inputs.
      if (not copy and isinstance(object, np.ndarray) and
          (dtype is None or dtype == object.dtype) and (ndmin <= object.ndim) and
          device is None):
        # Keep the output uncommitted.
        return jax.device_put(object)
    
      # For Python scalar literals, call coerce_to_array to catch any overflow
      # errors. We don't use dtypes.is_python_scalar because we don't want this
      # triggering for traced values. We do this here because it matters whether or
      # not dtype is None. We don't assign the result because we want the raw object
      # to be used for type inference below.
      if isinstance(object, (bool, int, float, complex)):
        _ = dtypes.coerce_to_array(object, dtype)
      elif not isinstance(object, Array):
        # Check if object supports any of the data exchange protocols
        # (except dlpack, see data-apis/array-api#301). If it does,
        # consume the object as jax array and continue (but not return) so
        # that other array() arguments get processed against the input
        # object.
        #
        # Notice that data exchange protocols define dtype in the
        # corresponding data structures and it may not be available as
        # object.dtype. So, we'll resolve the protocols here before
        # evaluating object.dtype.
        if hasattr(object, '__jax_array__'):
          object = object.__jax_array__()
        elif hasattr(object, '__cuda_array_interface__'):
          cai = object.__cuda_array_interface__
          backend = xla_bridge.get_backend("cuda")
          if cuda_plugin_extension is None:
            device_id = None
          else:
            device_id = cuda_plugin_extension.get_device_ordinal(cai["data"][0])
          object = xc._xla.cuda_array_interface_to_buffer(
              cai=cai, gpu_backend=backend, device_id=device_id)
    
      object = tree_map(lambda leaf: leaf.__jax_array__()
                        if hasattr(leaf, "__jax_array__") else leaf, object)
      leaves = tree_leaves(object, is_leaf=lambda x: x is None)
      if any(leaf is None for leaf in leaves):
        # Added Nov 16 2023
        if deprecations.is_accelerated("jax-numpy-array-none"):
          raise TypeError("None is not a valid value for jnp.array")
        warnings.warn(
          "None encountered in jnp.array(); this is currently treated as NaN. "
          "In the future this will result in an error.",
          FutureWarning, stacklevel=2)
        leaves = tree_leaves(object)
      if dtype is None:
        # Use lattice_result_type rather than result_type to avoid canonicalization.
        # Otherwise, weakly-typed inputs would have their dtypes canonicalized.
        try:
          dtype = dtypes._lattice_result_type(*leaves)[0] if leaves else dtypes.float_
        except TypeError:
          # This happens if, e.g. one of the entries is a memoryview object.
          # This is rare, so we only handle it if the normal path fails.
          leaves = [_convert_to_array_if_dtype_fails(leaf) for leaf in leaves]
          dtype = dtypes._lattice_result_type(*leaves)[0]
    
      if not weak_type:
        dtype = dtypes.canonicalize_dtype(dtype, allow_extended_dtype=True)  # type: ignore[assignment]
    
      out: ArrayLike
    
      if all(not isinstance(leaf, Array) for leaf in leaves):
        # TODO(jakevdp): falling back to numpy here fails to overflow for lists
        # containing large integers; see discussion in
        # https://github.com/jax-ml/jax/pull/6047. More correct would be to call
        # coerce_to_array on each leaf, but this may have performance implications.
>       out = np.asarray(object, dtype=dtype)
E       ValueError: setting an array element with a sequence.

/opt/fw/jax/jax/_src/numpy/lax_numpy.py:5010: ValueError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.quaternion.Quaternion
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/geometry/test_quaternion.py::test_Quaternion[jax-s2s-False] - ValueError: setting an array element with a sequence.
===================================================================================== 1 failed in 95.30s (0:01:35) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 5 items

kornia/geometry/test_calibration.py ....F                                                                                                                                                        [100%]

=============================================================================================== FAILURES ===============================================================================================
__________________________________________________________________________________ test_solve_pnp_dlt[jax-s2s-False] ___________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_solve_pnp_dlt(target_framework, mode, backend_compile):
        trace_args = (
            torch.tensor([[
                [5.0, -5.0, 0.0], [0.0, 0.0, 1.5],
                [2.5, 3.0, 6.0], [9.0, -2.0, 3.0],
                [-4.0, 5.0, 2.0], [-5.0, 5.0, 1.0]
            ]], dtype=torch.float64),
            torch.tensor([[
                [1409.1504, -800.936], [407.0207, -182.1229],
                [392.7021, 177.9428], [1016.838, -2.9416],
                [-63.1116, 142.9204], [-219.3874, 99.666]
            ]], dtype=torch.float64),
            torch.tensor([[
                [500.0, 0.0, 250.0],
                [0.0, 500.0, 250.0],
                [0.0, 0.0, 1.0]
            ]], dtype=torch.float64),
        )
        trace_kwargs = {'svd_eps': 1e-3}
        test_args = (
            torch.tensor([[
                [10.0, -10.0, 0.0], [0.0, 0.0, 3.0],
                [5.0, 6.0, 12.0], [18.0, -4.0, 6.0],
                [-8.0, 10.0, 4.0], [-10.0, 10.0, 2.0]
            ]], dtype=torch.float64),
            torch.tensor([[
                [2818.3008, -1601.872], [814.0414, -364.2458],
                [785.4042, 355.8856], [2033.676, -5.8832],
                [-126.2232, 285.8408], [-438.7748, 199.332]
            ]], dtype=torch.float64),
            torch.tensor([[
                [1000.0, 0.0, 500.0],
                [0.0, 1000.0, 500.0],
                [0.0, 0.0, 1.0]
            ]], dtype=torch.float64),
        )
        test_kwargs = {'svd_eps': 1e-3}
>       _test_function(
            kornia.geometry.calibration.solve_pnp_dlt,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/geometry/test_calibration.py:148: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function solve_pnp_dlt at 0x7fbbd4b6caf0>
trace_args = (tensor([[[ 5.0000, -5.0000,  0.0000],
         [ 0.0000,  0.0000,  1.5000],
         [ 2.5000,  3.0000,  6.0000],
   ...loat64), tensor([[[500.,   0., 250.],
         [  0., 500., 250.],
         [  0.,   0.,   1.]]], dtype=torch.float64))
trace_kwargs = {'svd_eps': 0.001}
test_args = (tensor([[[ 10., -10.,   0.],
         [  0.,   0.,   3.],
         [  5.,   6.,  12.],
         [ 18.,  -4.,   6.],
 ...tensor([[[1000.,    0.,  500.],
         [   0., 1000.,  500.],
         [   0.,    0.,    1.]]], dtype=torch.float64))
test_kwargs = {'svd_eps': 0.001}, target = 'jax', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function solve_pnp_dlt at 0x7fbbd4b6caf0>, fn_name = 'kornia.geometry.calibration.solve_pnp_dlt'
trace_args = (tensor([[[ 5.0000, -5.0000,  0.0000],
         [ 0.0000,  0.0000,  1.5000],
         [ 2.5000,  3.0000,  6.0000],
   ...loat64), tensor([[[500.,   0., 250.],
         [  0., 500., 250.],
         [  0.,   0.,   1.]]], dtype=torch.float64))
trace_kwargs = {'svd_eps': 0.001}
test_args = (tensor([[[ 10., -10.,   0.],
         [  0.,   0.,   3.],
         [  5.,   6.,  12.],
         [ 18.,  -4.,   6.],
 ...tensor([[[1000.,    0.,  500.],
         [   0., 1000.,  500.],
         [   0.,    0.,    1.]]], dtype=torch.float64))
test_kwargs = {'svd_eps': 0.001}, target = 'jax', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:232: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

world_points = Array([[[ 5. , -5. ,  0. ],
        [ 0. ,  0. ,  1.5],
        [ 2.5,  3. ,  6. ],
        [ 9. , -2. ,  3. ],
        [-4. ,  5. ,  2. ],
        [-5. ,  5. ,  1. ]]], dtype=float64)
img_points = Array([[[1409.1504, -800.936 ],
        [ 407.0207, -182.1229],
        [ 392.7021,  177.9428],
        [1016.838 ,   -2.9416],
        [ -63.1116,  142.9204],
        [-219.3874,   99.666 ]]], dtype=float64)
intrinsics = Array([[[500.,   0., 250.],
        [  0., 500., 250.],
        [  0.,   0.,   1.]]], dtype=float64), weights = None, svd_eps = 0.001

    def jax_solve_pnp_dlt(
        world_points, img_points, intrinsics, weights=None, svd_eps=0.0001
    ):
        from ....ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ...utils.helpers import jax__torch_linalg_svdvals
        from ....ivy.functional.frontends.torch.reduction_ops import jax_any_frnt
        from ....ivy.functional.frontends.torch.blas_and_lapack_ops import jax_inverse_frnt
        from ..conversions import jax_convert_points_to_homogeneous
        from ..linalg import jax_transform_points
        from ....ivy.functional.backends.jax.general import jax_set_item
        from ....ivy.functional.frontends.torch.blas_and_lapack_ops import (
            jax_svd_frnt_base_count_1_frnt,
        )
        from ....ivy.functional.frontends.torch.tensor import jax_reshape_frnt_
        from ...utils.misc import jax_eye_like
        from ....ivy.functional.frontends.torch.blas_and_lapack_ops import jax_bmm_frnt
        from ....ivy.functional.frontends.torch.blas_and_lapack_ops import jax_det_frnt
        from ....ivy.functional.frontends.torch.reduction_ops import jax_norm_frnt
        from ....ivy.functional.frontends.torch.linalg import jax_qr_frnt
        from ....ivy.functional.frontends.torch.pointwise_ops import jax_sign_frnt
        from ....ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            jax_cat_frnt,
        )
        from ...core._backend import zeros
        from ...core._backend import ones_like
        from ...core._backend import where
    
        if not isinstance(world_points, (jax.Array, nnx.Param)):
            raise AssertionError(
                f"world_points is not an instance of torch.Tensor. Type of world_points is {type(world_points)}"
            )
        if not isinstance(img_points, (jax.Array, nnx.Param)):
            raise AssertionError(
                f"img_points is not an instance of torch.Tensor. Type of img_points is {type(img_points)}"
            )
        if not isinstance(intrinsics, (jax.Array, nnx.Param)):
            raise AssertionError(
                f"intrinsics is not an instance of torch.Tensor. Type of intrinsics is {type(intrinsics)}"
            )
        if weights is not None and not isinstance(weights, (jax.Array, nnx.Param)):
            raise AssertionError(
                f"If weights is not None, then weights should be an instance of torch.Tensor. Type of weights is {type(weights)}"
            )
        if not isinstance(svd_eps, (float,)):
            raise AssertionError(f"Type of svd_eps is not float. Got {type(svd_eps)}")
        accepted_dtypes = jnp.float32, jnp.float64
        if world_points.dtype not in accepted_dtypes:
            raise AssertionError(
                f"world_points must have one of the following dtypes {accepted_dtypes}. Currently it has {world_points.dtype}."
            )
        if img_points.dtype not in accepted_dtypes:
            raise AssertionError(
                f"img_points must have one of the following dtypes {accepted_dtypes}. Currently it has {img_points.dtype}."
            )
        if intrinsics.dtype not in accepted_dtypes:
            raise AssertionError(
                f"intrinsics must have one of the following dtypes {accepted_dtypes}. Currently it has {intrinsics.dtype}."
            )
        if len(jax_shape_frnt_(world_points)) != 3 or jax_shape_frnt_(world_points)[2] != 3:
            raise AssertionError(
                f"world_points must be of shape (B, N, 3). Got shape {jax_shape_frnt_(world_points)}."
            )
        if len(jax_shape_frnt_(img_points)) != 3 or jax_shape_frnt_(img_points)[2] != 2:
            raise AssertionError(
                f"img_points must be of shape (B, N, 2). Got shape {jax_shape_frnt_(img_points)}."
            )
        if len(jax_shape_frnt_(intrinsics)) != 3 or jax_shape_frnt_(intrinsics)[1:] != (
            3,
            3,
        ):
            raise AssertionError(
                f"intrinsics must be of shape (B, 3, 3). Got shape {jax_shape_frnt_(intrinsics)}."
            )
        if jax_shape_frnt_(world_points)[1] != jax_shape_frnt_(img_points)[1]:
            raise AssertionError(
                "world_points and img_points must have equal number of points."
            )
        if (
            jax_shape_frnt_(world_points)[0] != jax_shape_frnt_(img_points)[0]
            or jax_shape_frnt_(world_points)[0] != jax_shape_frnt_(intrinsics)[0]
        ):
            raise AssertionError(
                "world_points, img_points and intrinsics must have the same batch size."
            )
        if jax_shape_frnt_(world_points)[1] < 6:
            raise AssertionError(
                f"At least 6 points are required to use this function. Got {jax_shape_frnt_(world_points)[1]} points."
            )
        B, N = jax_shape_frnt_(world_points)[:2][0], jax_shape_frnt_(world_points)[:2][1]
        world_points_norm, world_transform_norm = jax__mean_isotropic_scale_normalize(
            world_points
        )
        s = jax__torch_linalg_svdvals(world_points_norm)
        if jax_any_frnt(s[:, -1] < svd_eps):
            raise AssertionError(
                f"The last singular value of one/more of the elements of the batch is smaller than {svd_eps}. This function cannot be used if all world_points (of any element of the batch) lie on a line or if all world_points (of any element of the batch) lie on a plane."
            )
        intrinsics_inv = jax_inverse_frnt(intrinsics)
        world_points_norm_h = jax_convert_points_to_homogeneous(world_points_norm)
        img_points_inv = jax_transform_points(intrinsics_inv, img_points)
        img_points_norm, img_transform_norm = jax__mean_isotropic_scale_normalize(
            img_points_inv
        )
        inv_img_transform_norm = jax_inverse_frnt(img_transform_norm)
        system = zeros((B, 2 * N, 12), dtype=world_points.dtype, device=world_points.device)
        system = jax_set_item(
            system,
            (slice(None, None, None), slice(0, None, 2), slice(0, 4, None)),
            world_points_norm_h,
        )
        system = jax_set_item(
            system,
            (slice(None, None, None), slice(1, None, 2), slice(4, 8, None)),
            world_points_norm_h,
        )
        system = jax_set_item(
            system,
            (slice(None, None, None), slice(0, None, 2), slice(8, 12, None)),
            world_points_norm_h * -1 * img_points_norm[..., 0:1],
        )
        system = jax_set_item(
            system,
            (slice(None, None, None), slice(1, None, 2), slice(8, 12, None)),
            world_points_norm_h * -1 * img_points_norm[..., 1:2],
        )
        _, _, v = jax_svd_frnt_base_count_1_frnt(system)
        solution = v[..., -1]
        solution = jax_reshape_frnt_(solution, B, 3, 4)
        solution_4x4 = jax_eye_like(4, solution)
        solution_4x4 = jax_set_item(
            solution_4x4,
            (slice(None, None, None), slice(None, 3, None), slice(None, None, None)),
            solution,
        )
        intermediate = jax_bmm_frnt(solution_4x4, world_transform_norm)
        solution = jax_bmm_frnt(inv_img_transform_norm, intermediate[:, :3, :])
        det = jax_det_frnt(solution[:, :3, :3])
        ones = ones_like(det)
        sign_fix = where(det < 0, ones * -1, ones)
        solution = solution * sign_fix[:, None, None]
>       norm_col = jax_norm_frnt(input=solution[:, :3, 0], p=2, dim=1)

ivy_transpiled_outputs/jax_outputs/kornia/geometry/calibration/pnp.py:217: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (), kwargs = {'dim': 1, 'input': Array([[0.0754885 , 0.02388222, 0.0574928 ]], dtype=float64), 'p': 2}, jax_is_array_bknd = <function jax_is_array_bknd at 0x7fbb5404e200>

    @functools.wraps(fn)
    def wrapper(*args, **kwargs):
        from ..functional.ivy.general import jax_is_array_bknd
    
>       array_like = args[0]
E       IndexError: tuple index out of range

ivy_transpiled_outputs/jax_outputs/ivy/utils/decorator_utils.py:193: IndexError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.calibration.pnp.solve_pnp_dlt
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/geometry/test_calibration.py::test_solve_pnp_dlt[jax-s2s-False] - IndexError: tuple index out of range
=============================================================================== 1 failed, 4 passed in 328.67s (0:05:28) ================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 1 item

kornia/geometry/test_quaternion.py s                                                                                                                                                             [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
========================================================================================== 1 skipped in 5.46s ==========================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 5 items

kornia/test_x.py sssss                                                                                                                                                                           [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
========================================================================================== 5 skipped in 5.06s ==========================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 19 items

kornia/test_feature1.py ...................                                                                                                                                                      [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
=================================================================================== 19 passed in 1543.55s (0:25:43) ====================================================================================


========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 8 items

kornia/geometry/test_bbox.py ........                                                                                                                                                            [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
==================================================================================== 8 passed in 456.85s (0:07:36) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 13 items

kornia/test_feature3.py ........FF...                                                                                                                                                            [100%]

=============================================================================================== FAILURES ===============================================================================================
__________________________________________________________________________ test_MultiResolutionDetector[tensorflow-s2s-False] __________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_MultiResolutionDetector(target_framework, mode, backend_compile):
        print("kornia.feature.MultiResolutionDetector")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target_framework)
    
        keynet_model = kornia.feature.KeyNet()
        transpiled_keynet_model = transpiled_kornia.feature.KeyNet()
    
        x = torch.rand(1, 1, 32, 32) * 10.
        transpiled_x = _nest_torch_tensor_to_new_framework(x, target_framework)
    
        model = kornia.feature.MultiResolutionDetector(keynet_model)
        torch_out = model(x)
    
>       transpiled_model = transpiled_kornia.feature.MultiResolutionDetector(transpiled_keynet_model)

kornia/test_feature3.py:170: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:230: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:153: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:161: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

name = 'ivy_transpiled_outputs.tensorflow_outputs.kornia.feature.keynet', package = None

    def import_module(name, package=None):
        """Import a module.
    
        The 'package' argument is required when performing a relative import. It
        specifies the package to use as the anchor point from which to resolve the
        relative import to an absolute import.
    
        """
        level = 0
        if name.startswith('.'):
            if not package:
                msg = ("the 'package' argument is required to perform a relative "
                       "import for {!r}")
                raise TypeError(msg.format(name))
            for character in name:
                if character != '.':
                    break
                level += 1
>       return _bootstrap._gcd_import(name[level:], package, level)

/opt/miniconda/envs/multienv/lib/python3.10/importlib/__init__.py:126: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

name = 'ivy_transpiled_outputs.tensorflow_outputs.kornia.feature.keynet', package = None, level = 0

>   ???

<frozen importlib._bootstrap>:1050: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

name = 'ivy_transpiled_outputs.tensorflow_outputs.kornia.feature.keynet', import_ = <function _gcd_import at 0x7f211fb3b400>

>   ???

<frozen importlib._bootstrap>:1027: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

name = 'ivy_transpiled_outputs.tensorflow_outputs.kornia.feature.keynet', import_ = <function _gcd_import at 0x7f211fb3b400>

>   ???
E   ModuleNotFoundError: No module named 'ivy_transpiled_outputs.tensorflow_outputs.kornia.feature.keynet'

<frozen importlib._bootstrap>:1004: ModuleNotFoundError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.MultiResolutionDetector
____________________________________________________________________________ test_ScaleSpaceDetector[tensorflow-s2s-False] _____________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_ScaleSpaceDetector(target_framework, mode, backend_compile):
        print("kornia.feature.ScaleSpaceDetector")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target_framework)
    
        x = torch.rand(1, 1, 32, 32) * 10.
        transpiled_x = _nest_torch_tensor_to_new_framework(x, target_framework)
    
        model = kornia.feature.ScaleSpaceDetector()
        torch_out = model(x)
    
        transpiled_model = transpiled_kornia.feature.ScaleSpaceDetector()
        if target_framework == "tensorflow":
            # build the layers
>           transpiled_model(transpiled_x)

kornia/test_feature3.py:199: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_ScaleSpaceDetector(num_features=500, mr_size=6.0, scale_pyr=tensorflow_ScalePyramid(n_levels=3, init_sigma=...ates=False, eps=1e-08, strict_maxima_bonus=0.0, output_value=True), ori=tensorflow_PassLAF(), aff=tensorflow_PassLAF())
args = (<tf.Tensor: shape=(1, 1, 32, 32), dtype=float32, numpy=
array([[[[4.5639496 , 8.925398  , 0.79018414, ..., 4.818797  ...
         [5.112794  , 3.3548265 , 7.2967796 , ..., 4.636099  ,
          0.31971812, 0.6023824 ]]]], dtype=float32)>,)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x7f20883bb4d0, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...ode_context=['        return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_ScaleSpaceDetector(num_features=500, mr_size=6.0, scale_pyr=tensorflow_ScalePyramid(n_levels=3, init_sigma...,
         [5.112794  , 3.3548265 , 7.2967796 , ..., 4.636099  ,
          0.31971812, 0.6023824 ]]]], dtype=float32)>)
kwargs = {}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_ScaleSpaceDetector(num_features=500, mr_size=6.0, scale_pyr=tensorflow_ScalePyramid(n_levels=3, init_sigma=...ates=False, eps=1e-08, strict_maxima_bonus=0.0, output_value=True), ori=tensorflow_PassLAF(), aff=tensorflow_PassLAF())
v = None, buffers = None
args = (<tf.Tensor: shape=(1, 1, 32, 32), dtype=float32, numpy=
array([[[[4.5639496 , 8.925398  , 0.79018414, ..., 4.818797  ...
         [5.112794  , 3.3548265 , 7.2967796 , ..., 4.636099  ,
          0.31971812, 0.6023824 ]]]], dtype=float32)>,)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:2017: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_ScaleSpaceDetector(num_features=500, mr_size=6.0, scale_pyr=tensorflow_ScalePyramid(n_levels=3, init_sigma...,
         [5.112794  , 3.3548265 , 7.2967796 , ..., 4.636099  ,
          0.31971812, 0.6023824 ]]]], dtype=float32)>)
kwargs = {'buffers': None, 'v': None}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_ScaleSpaceDetector(num_features=500, mr_size=6.0, scale_pyr=tensorflow_ScalePyramid(n_levels=3, init_sigma=...ates=False, eps=1e-08, strict_maxima_bonus=0.0, output_value=True), ori=tensorflow_PassLAF(), aff=tensorflow_PassLAF())
v = None, buffers = None
args = (<tf.Tensor: shape=(1, 1, 32, 32), dtype=float32, numpy=
array([[[[4.5639496 , 8.925398  , 0.79018414, ..., 4.818797  ...
         [5.112794  , 3.3548265 , 7.2967796 , ..., 4.636099  ,
          0.31971812, 0.6023824 ]]]], dtype=float32)>,)
kwargs = {}
first_arr = <tf.Tensor: shape=(1, 1, 32, 32), dtype=float32, numpy=
array([[[[4.5639496 , 8.925398  , 0.79018414, ..., 4.818797  ,...],
         [5.112794  , 3.3548265 , 7.2967796 , ..., 4.636099  ,
          0.31971812, 0.6023824 ]]]], dtype=float32)>
replace_v = False, replace_buffers = False, call_signature = <Signature (img, mask=None)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Model, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Model, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Model, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1787: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_ScaleSpaceDetector(num_features=500, mr_size=6.0, scale_pyr=tensorflow_ScalePyramid(n_levels=3, init_sigma...es=False, eps=1e-08, strict_maxima_bonus=0.0, output_value=True), ori=tensorflow_PassLAF(), aff=tensorflow_PassLAF()),)
kwargs = {'img': <tf.Tensor: shape=(1, 1, 32, 32), dtype=float32, numpy=
array([[[[4.5639496 , 8.925398  , 0.79018414, ..., 4.8...,
         [5.112794  , 3.3548265 , 7.2967796 , ..., 4.636099  ,
          0.31971812, 0.6023824 ]]]], dtype=float32)>}

    @wraps(fn)
    def error_handler(*args, **kwargs):
        if not is_traceback_filtering_enabled():
            return fn(*args, **kwargs)
    
        filtered_tb = None
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            filtered_tb = _process_traceback_frames(e.__traceback__)
            # To get the full stack trace, call:
            # `keras.config.disable_traceback_filtering()`
>           raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/keras/src/utils/traceback_utils.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_ScaleSpaceDetector(num_features=500, mr_size=6.0, scale_pyr=tensorflow_ScalePyramid(n_levels=3, init_sigma=...ates=False, eps=1e-08, strict_maxima_bonus=0.0, output_value=True), ori=tensorflow_PassLAF(), aff=tensorflow_PassLAF())
img = <tf.Tensor: shape=(1, 1, 32, 32), dtype=float32, numpy=
array([[[[4.5639496 , 8.925398  , 0.79018414, ..., 4.818797  ,...],
         [5.112794  , 3.3548265 , 7.2967796 , ..., 4.636099  ,
          0.31971812, 0.6023824 ]]]], dtype=float32)>
mask = None

    def call(self, img, mask=None):
>       responses, lafs = self.detect(img, self.num_features, mask)

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/scale_space_detector.py:275: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_ScaleSpaceDetector(num_features=500, mr_size=6.0, scale_pyr=tensorflow_ScalePyramid(n_levels=3, init_sigma=...ates=False, eps=1e-08, strict_maxima_bonus=0.0, output_value=True), ori=tensorflow_PassLAF(), aff=tensorflow_PassLAF())
img = <tf.Tensor: shape=(1, 1, 32, 32), dtype=float32, numpy=
array([[[[4.5639496 , 8.925398  , 0.79018414, ..., 4.818797  ,...],
         [5.112794  , 3.3548265 , 7.2967796 , ..., 4.636099  ,
          0.31971812, 0.6023824 ]]]], dtype=float32)>
num_feats = 500, mask = None

    def detect(self, img, num_feats, mask=None):
        from ...ivy.functional.backends.tensorflow.general import tensorflow_get_item
        from ...ivy.functional.frontends.torch.tensor import tensorflow_size_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_view_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_reshape_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_permute_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_to_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_unsqueeze_frnt_
        from ...ivy.functional.frontends.torch.comparison_ops import (
            tensorflow_topk_frnt,
        )
        from ...ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            tensorflow_gather_frnt,
        )
        from ...ivy.functional.frontends.torch.tensor import tensorflow_repeat_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_item_frnt_
        from .laf import tensorflow_laf_is_inside_image
        from ..core._backend import eye
        from ..core._backend import concatenate
    
        dev: typing.Any = img.device
        dtype: typing.Any = img.dtype
        sigmas: typing.Any
        sp, sigmas, _ = self.scale_pyr(img)
        all_responses: typing.Any = []
        all_lafs: typing.Any = []
        px_size = 0.5 if self.scale_pyr.double_image else 1.0
        for oct_idx, octave in enumerate(sp):
            sigmas_oct = tensorflow_get_item(sigmas, oct_idx)
            B, CH, L, H, W = tensorflow_size_frnt_(octave)
            if self.scale_space_response:
                oct_resp = self.resp(octave, tensorflow_view_frnt_(sigmas_oct, -1))
            else:
                oct_resp = tensorflow_view_frnt_(
                    self.resp(
                        tensorflow_reshape_frnt_(
                            tensorflow_permute_frnt_(octave, 0, 2, 1, 3, 4),
                            B * L,
                            CH,
                            H,
                            W,
                        ),
                        tensorflow_view_frnt_(sigmas_oct, -1),
                    ),
                    B,
                    L,
                    CH,
                    H,
                    W,
                )
                oct_resp = tensorflow_permute_frnt_(oct_resp, 0, 2, 1, 3, 4)
                if (
                    isinstance(
                        self.scale_pyr.extra_levels,
                        (tensorflow.Tensor, tensorflow.keras.Variable),
                    )
                    and self.scale_pyr.extra_levels % 2 != 0
                ):
                    oct_resp = oct_resp[:, :, :-1]
            if mask is not None:
                oct_mask: typing.Any = tensorflow__create_octave_mask(
                    mask, tensorflow_shape_frnt_(oct_resp)
                )
                oct_resp = oct_mask * oct_resp
            coord_max: typing.Any
            response_max: typing.Any
            coord_max, response_max = self.nms(oct_resp)
            if self.minima_are_also_good:
                coord_min, response_min = self.nms(-oct_resp)
                take_min_mask = tensorflow_to_frnt_(
                    response_min > response_max, response_max.dtype
                )
                response_max = (
                    response_min * take_min_mask + (1 - take_min_mask) * response_max
                )
                coord_max = (
                    coord_min * tensorflow_unsqueeze_frnt_(take_min_mask, 2)
                    + (1 - tensorflow_unsqueeze_frnt_(take_min_mask, 2)) * coord_max
                )
            responses_flatten = tensorflow_view_frnt_(
                response_max, tensorflow_size_frnt_(response_max, 0), -1
            )
            max_coords_flatten = tensorflow_permute_frnt_(
                tensorflow_view_frnt_(
                    coord_max, tensorflow_size_frnt_(response_max, 0), 3, -1
                ),
                0,
                2,
                1,
            )
            if tensorflow_size_frnt_(responses_flatten, 1) > num_feats:
                resp_flat_best, idxs = tensorflow_topk_frnt(
                    responses_flatten, k=num_feats, dim=1
                )
                max_coords_best = tensorflow_gather_frnt(
                    max_coords_flatten,
                    1,
                    tensorflow_repeat_frnt_(
                        tensorflow_unsqueeze_frnt_(idxs, -1), 1, 1, 3
                    ),
                )
            else:
                resp_flat_best = responses_flatten
                max_coords_best = max_coords_flatten
            B, N = tensorflow_size_frnt_(resp_flat_best)
            if isinstance(
                self.scale_pyr.n_levels, (tensorflow.Tensor, tensorflow.keras.Variable)
            ):
                num_levels = int(tensorflow_item_frnt_(self.scale_pyr.n_levels))
            elif isinstance(self.scale_pyr.n_levels, (int,)):
                num_levels = self.scale_pyr.n_levels
            else:
                raise TypeError(
                    f"Expected the scale pyramid module to have `n_levels` as a Tensor or int.Gotcha {type(self.scale_pyr.n_levels)}"
                )
            max_coords_best = tensorflow__scale_index_to_scale(
                max_coords_best, sigmas_oct, num_levels
            )
            rotmat = tensorflow_view_frnt_(eye(2, dtype=dtype, device=dev), 1, 1, 2, 2)
            current_lafs = concatenate(
                [
                    self.mr_size
                    * tensorflow_view_frnt_(max_coords_best[:, :, 0], B, N, 1, 1)
                    * rotmat,
                    tensorflow_view_frnt_(max_coords_best[:, :, 1:3], B, N, 2, 1),
                ],
                3,
            )
>           good_mask = tensorflow_laf_is_inside_image(current_lafs, octave[:, 0])

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/scale_space_detector.py:252: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

laf = <tf.Tensor: shape=(1, 500, 2, 3), dtype=float32, numpy=
array([[[[15.258034,  0.      , 30.479235],
         [ 0.     ...3.003049]],

        [[27.156036,  0.      , 28.030958],
         [ 0.      , 27.156036,  0.992753]]]], dtype=float32)>
images = <tf.Tensor: shape=(1, 6, 32, 32), dtype=float32, numpy=
array([[[[4.5131707, 4.5850353, 4.858138 , ..., 3.5537746, 3.7...916315],
         [4.8738403, 4.876059 , 4.8826523, ..., 5.0206637, 4.993886 ,
          4.9845734]]]], dtype=float32)>
border = 0

    def tensorflow_laf_is_inside_image(laf, images, border=0):
        from ..core.check import tensorflow_KORNIA_CHECK_LAF
        from ...ivy.functional.frontends.torch.tensor import tensorflow_size_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_min_frnt_
    
        tensorflow_KORNIA_CHECK_LAF(laf)
        _, _, h, w = tensorflow_size_frnt_(images)
        pts = tensorflow_laf_to_boundary_points(laf, 12)
        good_lafs_mask = (
>           (pts[..., 0] >= border)
            * (pts[..., 0] <= w - border)
            * (pts[..., 1] >= border)
            * (pts[..., 1] <= h - border)
        )

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/laf.py:105: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <tf.Tensor: shape=(1, 500, 12), dtype=bool, numpy=
array([[[ True,  True,  True, ...,  True,  True,  True],
        [ ...],
        [ True,  True,  True, ...,  True,  True,  True],
        [ True,  True,  True, ...,  True,  True,  True]]])>
rhs = <tf.Tensor: shape=(1, 500, 12), dtype=bool, numpy=
array([[[ True,  True, False, ...,  True,  True,  True],
        [ ...],
        [ True,  True,  True, ...,  True,  True,  True],
        [ True,  True, False, ...,  True,  True,  True]]])>

    def impl(self, rhs):
        try:
            return original_method(self, rhs)
        except Exception:
>           return patched_method(self, rhs)

ivy_transpiled_outputs/tensorflow_outputs/__init__.py:65: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = <tf.Tensor: shape=(1, 500, 12), dtype=bool, numpy=
array([[[ True,  True,  True, ...,  True,  True,  True],
        [ ...],
        [ True,  True,  True, ...,  True,  True,  True],
        [ True,  True,  True, ...,  True,  True,  True]]])>
other = <tf.Tensor: shape=(1, 500, 12), dtype=bool, numpy=
array([[[ True,  True, False, ...,  True,  True,  True],
        [ ...],
        [ True,  True,  True, ...,  True,  True,  True],
        [ True,  True, False, ...,  True,  True,  True]]])>

    def tensorflow___mul___frnt_(tensor, other):
        from .pointwise_ops import tensorflow_mul_frnt
    
>       return tensorflow_mul_frnt(tensor, other)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/tensor.py:93: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = <tf.Tensor: shape=(1, 500, 12), dtype=bool, numpy=
array([[[ True,  True,  True, ...,  True,  True,  True],
        [ ...],
        [ True,  True,  True, ...,  True,  True,  True],
        [ True,  True,  True, ...,  True,  True,  True]]])>
other = <tf.Tensor: shape=(1, 500, 12), dtype=bool, numpy=
array([[[ True,  True, False, ...,  True,  True,  True],
        [ ...],
        [ True,  True,  True, ...,  True,  True,  True],
        [ True,  True, False, ...,  True,  True,  True]]])>

    def tensorflow_mul_frnt(input, other, *, out=None):
        from .__init__ import tensorflow_promote_types_of_torch_inputs_frnt
        from ...backends.tensorflow.elementwise import tensorflow_multiply
    
        input, other = tensorflow_promote_types_of_torch_inputs_frnt(input, other)
>       return tensorflow_multiply(input, other, out=out)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/pointwise_ops.py:100: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x1 = <tf.Tensor: shape=(1, 500, 12), dtype=bool, numpy=
array([[[ True,  True,  True, ...,  True,  True,  True],
        [ ...],
        [ True,  True,  True, ...,  True,  True,  True],
        [ True,  True,  True, ...,  True,  True,  True]]])>
x2 = <tf.Tensor: shape=(1, 500, 12), dtype=bool, numpy=
array([[[ True,  True, False, ...,  True,  True,  True],
        [ ...],
        [ True,  True,  True, ...,  True,  True,  True],
        [ True,  True, False, ...,  True,  True,  True]]])>

    def tensorflow_multiply(
        x1: Union[float, tensorflow.Tensor, tensorflow.Variable],
        x2: Union[float, tensorflow.Tensor, tensorflow.Variable],
        /,
        *,
        out: Optional[Union[tensorflow.Tensor, tensorflow.Variable]] = None,
    ):
        from ...ivy.data_type import tensorflow_promote_types_of_inputs_bknd
    
        x1, x2 = tensorflow_promote_types_of_inputs_bknd(x1, x2)
>       return tensorflow.math.multiply(x1, x2)
E       tensorflow.python.framework.errors_impl.InvalidArgumentError: Exception encountered when calling tensorflow_ScaleSpaceDetector.call().
E       
E       [1mValue for attr 'T' of bool is not in the list of allowed values: bfloat16, half, float, double, uint8, int8, uint16, int16, int32, uint32, uint64, int64, complex64, complex128
E       	; NodeDef: {{node Mul}}; Op<name=Mul; signature=x:T, y:T -> z:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE, DT_UINT8, DT_INT8, DT_UINT16, DT_INT16, DT_INT32, DT_UINT32, DT_UINT64, DT_INT64, DT_COMPLEX64, DT_COMPLEX128]; is_commutative=true> [Op:Mul] name: [0m
E       
E       Arguments received by tensorflow_ScaleSpaceDetector.call():
E         • img=tf.Tensor(shape=(1, 1, 32, 32), dtype=float32)
E         • mask=None

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/backends/tensorflow/elementwise.py:239: InvalidArgumentError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.ScaleSpaceDetector
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/test_feature3.py::test_MultiResolutionDetector[tensorflow-s2s-False] - ModuleNotFoundError: No module named 'ivy_transpiled_outputs.tensorflow_outputs.kornia.feature.keynet'
FAILED kornia/test_feature3.py::test_ScaleSpaceDetector[tensorflow-s2s-False] - tensorflow.python.framework.errors_impl.InvalidArgumentError: Exception encountered when calling tensorflow_ScaleSpac...
============================================================================== 2 failed, 11 passed in 1960.12s (0:32:40) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 13 items

kornia/test_utils.py .............                                                                                                                                                               [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
==================================================================================== 13 passed in 800.31s (0:13:20) ====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 6 items

kornia/test_nerf.py .F...F                                                                                                                                                                       [100%]

=============================================================================================== FAILURES ===============================================================================================
________________________________________________________________________________ test_NerfModelRenderer[jax-s2s-False] _________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_NerfModelRenderer(target_framework, mode, backend_compile):
        print("kornia.nerf.nerf_model.NerfModelRenderer")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledPinholeCamera = ivy.transpile(kornia.geometry.camera.pinhole.PinholeCamera, source="torch", target=target_framework)
        TranspiledNerfModel = ivy.transpile(nerf_model.NerfModel, source="torch", target=target_framework)
        TranspiledNerfModelRenderer = ivy.transpile(nerf_model.NerfModelRenderer, source="torch", target=target_framework)
    
        torch_nerf_model = nerf_model.NerfModel(num_ray_points=32)
        transpiled_nerf_model = TranspiledNerfModel(num_ray_points=32)
    
        torch_camera_args = (
            torch.rand(1, 4, 4),
            torch.rand(1, 4, 4),
            torch.tensor([256]),
            torch.tensor([256]),
        )
>       transpiled_camera_args = _nest_torch_tensor_to_new_framework(torch_camera_args)
E       TypeError: _nest_torch_tensor_to_new_framework() missing 1 required positional argument: 'target'

kornia/test_nerf.py:63: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.nerf.nerf_model.NerfModelRenderer
_________________________________________________________________________________ test_RandomRaySampler[jax-s2s-False] _________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_RandomRaySampler(target_framework, mode, backend_compile):
        print("kornia.nerf.samplers.RandomRaySampler")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledPinholeCamera = ivy.transpile(kornia.geometry.camera.pinhole.PinholeCamera, source="torch", target=target_framework)
        TranspiledRandomRaySampler = ivy.transpile(samplers.RandomRaySampler, source="torch", target=target_framework)
    
        torch_camera_args = (
            torch.rand(1, 4, 4),
            torch.rand(1, 4, 4),
            torch.tensor([256]),
            torch.tensor([256]),
        )
        transpiled_camera_args = _nest_torch_tensor_to_new_framework(torch_camera_args, target_framework)
    
        torch_camera = kornia.geometry.camera.pinhole.PinholeCamera(*torch_camera_args)
        transpiled_camera = TranspiledPinholeCamera(*transpiled_camera_args)
    
        heights, widths = torch.tensor([256]), torch.tensor([256])
        transpiled_heights = _array_to_new_backend(heights, target_framework)
        transpiled_widths = _array_to_new_backend(widths, target_framework)
    
        torch_sampler = samplers.RandomRaySampler(min_depth=0.1, max_depth=10.0, ndc=True, device="cpu", dtype=torch.float32)
        transpiled_sampler = TranspiledRandomRaySampler(min_depth=0.1, max_depth=10.0, ndc=True, device="cpu", dtype=torch.float32)
    
        torch_sampler.calc_ray_params(torch_camera, torch.tensor([1]))
>       transpiled_sampler.calc_ray_params(transpiled_camera, _array_to_new_backend(torch.tensor([1]), target_framework))

kornia/test_nerf.py:250: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <ivy_transpiled_outputs.jax_outputs.kornia.nerf.samplers.jax_RandomRaySampler object at 0x7f4d3439c760>
cameras = <ivy_transpiled_outputs.jax_outputs.kornia.geometry.camera.pinhole.jax_PinholeCamera object at 0x7f4d34cd0760>, num_img_rays = Array([1], dtype=int64)

    def calc_ray_params(self, cameras, num_img_rays):
        from ...ivy.functional.frontends.torch.tensor import jax_shape_frnt_
    
        num_cams = cameras.batch_size
        if num_cams != jax_shape_frnt_(num_img_rays)[0]:
            raise ValueError(
                f"Number of cameras {num_cams} does not match size of tensor to define number of rays to march from each camera {jax_shape_frnt_(num_img_rays)[0]}"
            )
>       points_2d_camera = self.sample_points_2d(
            cameras.height, cameras.width, num_img_rays
        )

ivy_transpiled_outputs/jax_outputs/kornia/nerf/samplers.py:359: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <ivy_transpiled_outputs.jax_outputs.kornia.nerf.samplers.jax_RandomRaySampler object at 0x7f4d3439c760>, heights = Array([256], dtype=int64), widths = Array([256], dtype=int64)
num_img_rays = Array([1], dtype=int32)

    def sample_points_2d(self, heights, widths, num_img_rays):
        from ...ivy.functional.frontends.torch.tensor import jax_int_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_tolist_frnt_
        from ...ivy.functional.frontends.torch.pointwise_ops import jax_trunc_frnt
        from ...ivy.functional.frontends.torch.random_sampling import jax_rand_frnt
    
        num_img_rays = jax_int_frnt_(num_img_rays)
        points2d_as_flat_tensors: typing.Any = {}
        for camera_id, (height, width, n) in enumerate(
            zip(
                jax_tolist_frnt_(heights),
                jax_tolist_frnt_(widths),
                jax_tolist_frnt_(num_img_rays),
            )
        ):
            y_rand = jax_trunc_frnt(
>               jax_rand_frnt(n, device=self._device, dtype=self._dtype) * height
            )

ivy_transpiled_outputs/jax_outputs/kornia/nerf/samplers.py:341: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

generator = None, out = None, dtype = torch.float32, layout = None, device = 'cpu', requires_grad = False, pin_memory = False, size = (1,), kwargs = {}
jax_random_uniform = <function jax_random_uniform at 0x7f4d146b3370>, seed = None

    def jax_rand_frnt(
        *size,
        generator=None,
        out=None,
        dtype=None,
        layout=None,
        device=None,
        requires_grad=False,
        pin_memory=False,
        **kwargs,
    ):
        from ...backends.jax.random import jax_random_uniform
    
        if not size and "size" not in kwargs:
            raise ValueError("Missing 1 required positional/keyword argument: size")
        size = size if size else kwargs["size"]
        if (
            isinstance(size, (list, tuple))
            and len(size) == 1
            and isinstance(size[0], (list, tuple, tuple))
        ):
            size = size[0]
        seed = generator.initial_seed() if generator is not None else None
>       return jax_random_uniform(
            shape=size, seed=seed, out=out, dtype=dtype, device=device
        )

ivy_transpiled_outputs/jax_outputs/ivy/functional/frontends/torch/random_sampling.py:51: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype = torch.float32, args = (), kwargs = {'device': 'cpu', 'out': None, 'seed': None, 'shape': (1,)}, jax_exists_bknd = <function jax_exists_bknd at 0x7f4d345f35b0>
jax_default_dtype_bknd = <function jax_default_dtype_bknd at 0x7f4d345f29e0>, arr = None

    @functools.wraps(fn)
    def _infer_dtype(*args, dtype=None, **kwargs):
        from .functional.ivy.general import jax_exists_bknd
        from .functional.ivy.data_type import jax_default_dtype_bknd
    
        arr = None if jax_exists_bknd(dtype) else jax__get_first_array(*args, **kwargs)
        dtype = jax_default_dtype_bknd(dtype=dtype, item=arr, as_native=True)
>       return fn(*args, dtype=dtype, **kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/func_wrapper.py:144: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    @jax_infer_dtype
    def jax_random_uniform(
        *,
        low: Union[float, jax.Array] = 0.0,
        high: Union[float, jax.Array, None] = 1.0,
        shape: Optional[Union[tuple, Sequence[int]]] = None,
        device: jaxlib.xla_extension.Device = None,
        dtype: jax.numpy.dtype,
        seed: Optional[int] = None,
        out: Optional[jax.Array] = None,
    ):
        from ...ivy.random import jax__check_bounds_and_get_shape_bknd
    
        if high is None:
            high = float(
                jax.numpy.finfo(dtype).max
                if dtype is not None
                else jax.numpy.finfo(jax.numpy.float32).max
            )
        shape = jax__check_bounds_and_get_shape_bknd(low, high, shape)
        if seed:
            rng_input = jax.random.PRNGKey(seed)
        else:
            RNG_, rng_input = jax.random.split(jax__getRNG())
            jax__setRNG(RNG_)
>       return jax.numpy.astype(
            jax.random.uniform(
                rng_input, shape, minval=low, maxval=high, dtype=jax.numpy.float32
            ),
            dtype,
        )

ivy_transpiled_outputs/jax_outputs/ivy/functional/backends/jax/random.py:80: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = Array([0.10536897], dtype=float32), dtype = torch.float32

    def astype(x: ArrayLike, dtype: DTypeLike | None,
               /, *, copy: bool = False,
               device: xc.Device | Sharding | None = None) -> Array:
      """Convert an array to a specified dtype.
    
      JAX imlementation of :func:`numpy.astype`.
    
      This is implemented via :func:`jax.lax.convert_element_type`, which may
      have slightly different behavior than :func:`numpy.astype` in some cases.
      In particular, the details of float-to-int and int-to-float casts are
      implementation dependent.
    
      Args:
        x: input array to convert
        dtype: output dtype
        copy: if True, then always return a copy. If False (default) then only
          return a copy if necessary.
        device: optionally specify the device to which the output will be committed.
    
      Returns:
        An array with the same shape as ``x``, containing values of the specified
        dtype.
    
      See Also:
        - :func:`jax.lax.convert_element_type`: lower-level function for XLA-style
          dtype conversions.
    
      Examples:
        >>> x = jnp.array([0, 1, 2, 3])
        >>> x
        Array([0, 1, 2, 3], dtype=int32)
        >>> x.astype('float32')
        Array([0.0, 1.0, 2.0, 3.0], dtype=float32)
    
        >>> y = jnp.array([0.0, 0.5, 1.0])
        >>> y.astype(int)  # truncates fractional values
        Array([0, 0, 1], dtype=int32)
      """
      util.check_arraylike("astype", x)
      x_arr = asarray(x)
    
      if dtype is None:
        dtype = dtypes.canonicalize_dtype(float_)
>     dtypes.check_user_dtype_supported(dtype, "astype")

/opt/fw/jax/jax/_src/numpy/lax_numpy.py:5091: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype = torch.float32, fun_name = 'astype'

    def check_user_dtype_supported(dtype, fun_name=None):
      if isinstance(dtype, Array):
        # Deprecation warning added 2024 June 13.
        warnings.warn("Passing an array as a dtype argument is deprecated; "
                      "instead of dtype=arr use dtype=arr.dtype.",
                      category=DeprecationWarning, stacklevel=3)
        return  # no further check needed, as array dtypes have already been validated.
>     if issubdtype(dtype, extended):

/opt/fw/jax/jax/_src/dtypes.py:776: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = torch.float32, b = <class 'jax.dtypes.extended'>

    def issubdtype(a: DTypeLike | ExtendedDType | None,
                   b: DTypeLike | ExtendedDType | None) -> bool:
      """Returns True if first argument is a typecode lower/equal in type hierarchy.
    
      This is like :func:`numpy.issubdtype`, but can handle dtype extensions such as
      :obj:`jax.dtypes.bfloat16` and `jax.dtypes.prng_key`.
      """
      # Main departures from np.issubdtype are:
      # - "extended" dtypes (like prng key types) are not normal numpy dtypes, so we
      #   need to handle them specifically. However, their scalar types do conform to
      #   the numpy scalar type hierarchy.
      # - custom dtypes (like bfloat16, int4, etc.) are normal numpy dtypes, but they
      #   don't conform to the standard numpy type hierarchy (e.g. the bfloat16 scalar
      #   type is not a subclass of np.floating) so we must also handle these specially.
    
      # We cannot use the cached version directly for all inputs, because some may be
      # unhashable (e.g. custom objects with a dtype attribute). The following check is
      # fast and covers the majority of calls to this function within JAX library code.
      return _issubdtype_cached(
>       a if isinstance(a, (type, np.dtype, ExtendedDType)) else np.dtype(a),  # type: ignore[arg-type]
        b if isinstance(b, (type, np.dtype, ExtendedDType)) else np.dtype(b),  # type: ignore[arg-type]
      )
E     TypeError: Cannot interpret 'torch.float32' as a data type

/opt/fw/jax/jax/_src/dtypes.py:363: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.nerf.samplers.RandomRaySampler
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/test_nerf.py::test_NerfModelRenderer[jax-s2s-False] - TypeError: _nest_torch_tensor_to_new_framework() missing 1 required positional argument: 'target'
FAILED kornia/test_nerf.py::test_RandomRaySampler[jax-s2s-False] - TypeError: Cannot interpret 'torch.float32' as a data type
=============================================================================== 2 failed, 4 passed in 342.12s (0:05:42) ================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 1 item

kornia/geometry/test_ransac.py .                                                                                                                                                                 [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
==================================================================================== 1 passed in 170.37s (0:02:50) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 15 items

kornia/geometry/test_subpix.py ..F.........F..                                                                                                                                                   [100%]

=============================================================================================== FAILURES ===============================================================================================
____________________________________________________________________________ test_conv_quad_interp3d[tensorflow-s2s-False] _____________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_conv_quad_interp3d(target_framework, mode, backend_compile):
        trace_args = (
            torch.rand(2, 2, 2, 5, 5),
        )
        trace_kwargs = {
            'strict_maxima_bonus': 10.0,
            'eps': 1e-7,
        }
        test_args = (
            torch.rand(1, 2, 2, 5, 5),
        )
        test_kwargs = {
            'strict_maxima_bonus': 5.0,
            'eps': 1e-7,
        }
>       _test_function(
            kornia.geometry.subpix.conv_quad_interp3d,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/geometry/test_subpix.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function conv_quad_interp3d at 0x7ff091c12f80>
trace_args = (tensor([[[[[0.4481, 0.6192, 0.2406, 0.4556, 0.9809],
           [0.5092, 0.2685, 0.1230, 0.4175, 0.8439],
           ....8337],
           [0.4615, 0.3467, 0.8987, 0.9352, 0.8300],
           [0.0850, 0.8795, 0.4396, 0.0394, 0.0548]]]]]),)
trace_kwargs = {'eps': 1e-07, 'strict_maxima_bonus': 10.0}
test_args = (tensor([[[[[0.5381, 0.1624, 0.9369, 0.2141, 0.0487],
           [0.7413, 0.9244, 0.3344, 0.7239, 0.7525],
           ....5272],
           [0.5452, 0.6864, 0.8676, 0.6870, 0.5570],
           [0.8734, 0.4138, 0.1834, 0.7796, 0.0583]]]]]),)
test_kwargs = {'eps': 1e-07, 'strict_maxima_bonus': 5.0}, target = 'tensorflow', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function conv_quad_interp3d at 0x7ff091c12f80>, fn_name = 'kornia.geometry.subpix.conv_quad_interp3d'
trace_args = (tensor([[[[[0.4481, 0.6192, 0.2406, 0.4556, 0.9809],
           [0.5092, 0.2685, 0.1230, 0.4175, 0.8439],
           ....8337],
           [0.4615, 0.3467, 0.8987, 0.9352, 0.8300],
           [0.0850, 0.8795, 0.4396, 0.0394, 0.0548]]]]]),)
trace_kwargs = {'eps': 1e-07, 'strict_maxima_bonus': 10.0}
test_args = (tensor([[[[[0.5381, 0.1624, 0.9369, 0.2141, 0.0487],
           [0.7413, 0.9244, 0.3344, 0.7239, 0.7525],
           ....5272],
           [0.5452, 0.6864, 0.8676, 0.6870, 0.5570],
           [0.8734, 0.4138, 0.1834, 0.7796, 0.0583]]]]]),)
test_kwargs = {'eps': 1e-07, 'strict_maxima_bonus': 5.0}, target = 'tensorflow', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
>           graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:326: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:232: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = <tf.Tensor: shape=(2, 2, 2, 5, 5), dtype=float32, numpy=
array([[[[[0.44807416, 0.61918974, 0.24058217, 0.45555925, 0....3521506, 0.8300033 ],
          [0.08498555, 0.8794869 , 0.43960953, 0.03936917, 0.05480725]]]]],
      dtype=float32)>
strict_maxima_bonus = 10.0, eps = 1e-07

    def tensorflow_conv_quad_interp3d(input, strict_maxima_bonus=10.0, eps=1e-07):
        from ...core._backend import stack
        from ...core._backend import rand
        from ...core._backend import zeros_like
        from ...core._backend import where
        from ....ivy.functional.frontends.torch.tensor_functions import (
            tensorflow_is_tensor_frnt_,
        )
        from ....ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ....ivy.functional.frontends.torch.tensor import tensorflow_permute_frnt_
        from ...utils.grid import tensorflow_create_meshgrid3d
        from ....ivy.functional.frontends.torch.tensor import tensorflow_to_frnt_
        from ...filters.sobel import tensorflow_spatial_gradient3d
        from ....ivy.functional.frontends.torch.tensor import tensorflow_reshape_frnt_
        from ....ivy.functional.frontends.torch.tensor import tensorflow_view_frnt_
        from ...utils._compat import tensorflow_torch_version_ge
        from ....ivy.functional.frontends.torch.tensor import tensorflow_abs_frnt_
        from ....ivy.functional.frontends.torch.tensor import tensorflow_size_frnt_
        from .nms import tensorflow_nms3d
        from ...utils.helpers import tensorflow_safe_solve_with_mask
        from ....ivy.functional.backends.tensorflow.general import tensorflow_get_item
        from ....ivy.functional.frontends.torch.tensor import (
            tensorflow_masked_scatter_frnt_,
        )
        from ....ivy.functional.backends.tensorflow.general import tensorflow_set_item
        from ....ivy.functional.frontends.torch.tensor import tensorflow_max_frnt_
        from ....ivy.functional.frontends.torch.tensor import tensorflow_masked_fill__frnt_
        from ....ivy.functional.frontends.torch.tensor import tensorflow_expand_as_frnt_
        from ....ivy.functional.frontends.torch.blas_and_lapack_ops import (
            tensorflow_bmm_frnt,
        )
        from ....ivy.functional.frontends.torch.tensor import tensorflow_flip_frnt_
        from ....ivy.functional.frontends.torch.tensor import tensorflow_unsqueeze_frnt_
        from ....ivy.functional.frontends.torch.tensor import tensorflow_repeat_frnt_
    
        if not tensorflow_is_tensor_frnt_(input):
            raise TypeError(f"Input type is not a Tensor. Got {type(input)}")
        if not len(tensorflow_shape_frnt_(input)) == 5:
            raise ValueError(
                f"Invalid input shape, we expect BxCxDxHxW. Got: {tensorflow_shape_frnt_(input)}"
            )
        B, CH, D, H, W = tensorflow_shape_frnt_(input)
        grid_global: typing.Any = tensorflow_permute_frnt_(
            tensorflow_create_meshgrid3d(D, H, W, False, device=input.device), 0, 4, 1, 2, 3
        )
        grid_global = tensorflow_to_frnt_(grid_global, input.dtype)
        b: typing.Any = tensorflow_spatial_gradient3d(input, order=1, mode="diff")
        b = tensorflow_reshape_frnt_(
            tensorflow_permute_frnt_(b, 0, 1, 3, 4, 5, 2), -1, 3, 1
        )
        A: typing.Any = tensorflow_spatial_gradient3d(input, order=2, mode="diff")
        A = tensorflow_reshape_frnt_(tensorflow_permute_frnt_(A, 0, 1, 3, 4, 5, 2), -1, 6)
        dxx = A[..., 0]
        dyy = A[..., 1]
        dss = A[..., 2]
        dxy = 0.25 * A[..., 3]
        dys = 0.25 * A[..., 4]
        dxs = 0.25 * A[..., 5]
        Hes = tensorflow_view_frnt_(
            stack([dxx, dxy, dxs, dxy, dyy, dys, dxs, dys, dss], -1), -1, 3, 3
        )
        if not tensorflow_torch_version_ge(1, 10):
            Hes = (
                Hes
                + tensorflow_abs_frnt_(
                    rand(tensorflow_size_frnt_(Hes[0]), device=Hes.device)
                )[None]
                * eps
            )
        nms_mask: typing.Any = tensorflow_nms3d(input, (3, 3, 3), True)
        x_solved: typing.Any = zeros_like(b)
        x_solved_masked, _, solved_correctly = tensorflow_safe_solve_with_mask(
            tensorflow_get_item(b, tensorflow_view_frnt_(nms_mask, -1)),
            tensorflow_get_item(Hes, tensorflow_view_frnt_(nms_mask, -1)),
        )
        new_nms_mask = tensorflow_masked_scatter_frnt_(nms_mask, nms_mask, solved_correctly)
        x_solved = tensorflow_set_item(
            x_solved,
>           where(new_nms_mask.view(-1, 1, 1))[0],
            tensorflow_get_item(x_solved_masked, solved_correctly),
        )

ivy_transpiled_outputs/tensorflow_outputs/kornia/geometry/subpix/spatial_soft_argmax.py:111: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <tf.Tensor: shape=(2, 2, 2, 5, 5), dtype=bool, numpy=
array([[[[[False, False, False, False, False],
          [False,...alse, False, False],
          [False, False, False, False, False],
          [False, False, False, False, False]]]]])>
name = 'view'

    def __getattr__(self, name):
      if name in {"T", "astype", "ravel", "transpose", "reshape", "clip", "size",
                  "tolist", "data"}:
        # TODO(wangpeng): Export the enable_numpy_behavior knob
        raise AttributeError(
            f"{type(self).__name__} object has no attribute '{name}'. " + """
          If you are looking for numpy-related methods, please run the following:
          tf.experimental.numpy.experimental_enable_numpy_behavior()
        """)
>     self.__getattribute__(name)
E     AttributeError: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'view'

/opt/fw/tensorflow/tensorflow/python/framework/tensor.py:260: AttributeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.subpix.spatial_soft_argmax.conv_quad_interp3d
_____________________________________________________________________________ test_ConvQuadInterp3d[tensorflow-s2s-False] ______________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_ConvQuadInterp3d(target_framework, mode, backend_compile):
        print("kornia.geometry.subpix.ConvQuadInterp3d")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target_framework)
    
        conv_quad_interp3d = kornia.geometry.subpix.ConvQuadInterp3d()
        transpiled_conv_quad_interp3d = transpiled_kornia.geometry.subpix.ConvQuadInterp3d()
    
        heatmap = torch.randn(1, 1, 3, 5, 5, requires_grad=True)
        transpiled_heatmap = _nest_torch_tensor_to_new_framework(heatmap, target_framework)
    
        torch_output = conv_quad_interp3d(heatmap)
>       transpiled_output = transpiled_conv_quad_interp3d(transpiled_heatmap)

kornia/geometry/test_subpix.py:363: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_ConvQuadInterp3d(strict_maxima_bonus=10.0)
args = (<tf.Tensor: shape=(1, 1, 3, 5, 5), dtype=float32, numpy=
array([[[[[ 1.0067405 , -0.8619741 , -1.06081   ,  0.4242578...05982  ],
          [ 0.15310992, -0.7514802 , -0.5931298 ,  0.1012269 ,
            1.9728568 ]]]]], dtype=float32)>,)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x55a3e87759b0, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...ode_context=['        return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_ConvQuadInterp3d(strict_maxima_bonus=10.0), <tf.Tensor: shape=(1, 1, 3, 5, 5), dtype=float32, numpy=
array...105982  ],
          [ 0.15310992, -0.7514802 , -0.5931298 ,  0.1012269 ,
            1.9728568 ]]]]], dtype=float32)>)
kwargs = {}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_ConvQuadInterp3d(strict_maxima_bonus=10.0), v = None, buffers = None
args = (<tf.Tensor: shape=(1, 1, 3, 5, 5), dtype=float32, numpy=
array([[[[[ 1.0067405 , -0.8619741 , -1.06081   ,  0.4242578...05982  ],
          [ 0.15310992, -0.7514802 , -0.5931298 ,  0.1012269 ,
            1.9728568 ]]]]], dtype=float32)>,)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:2017: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_ConvQuadInterp3d(strict_maxima_bonus=10.0), <tf.Tensor: shape=(1, 1, 3, 5, 5), dtype=float32, numpy=
array...105982  ],
          [ 0.15310992, -0.7514802 , -0.5931298 ,  0.1012269 ,
            1.9728568 ]]]]], dtype=float32)>)
kwargs = {'buffers': None, 'v': None}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_ConvQuadInterp3d(strict_maxima_bonus=10.0), v = None, buffers = None
args = (<tf.Tensor: shape=(1, 1, 3, 5, 5), dtype=float32, numpy=
array([[[[[ 1.0067405 , -0.8619741 , -1.06081   ,  0.4242578...05982  ],
          [ 0.15310992, -0.7514802 , -0.5931298 ,  0.1012269 ,
            1.9728568 ]]]]], dtype=float32)>,)
kwargs = {}
first_arr = <tf.Tensor: shape=(1, 1, 3, 5, 5), dtype=float32, numpy=
array([[[[[ 1.0067405 , -0.8619741 , -1.06081   ,  0.42425787....105982  ],
          [ 0.15310992, -0.7514802 , -0.5931298 ,  0.1012269 ,
            1.9728568 ]]]]], dtype=float32)>
replace_v = False, replace_buffers = False, call_signature = <Signature (x)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Model, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Model, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Model, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1787: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_ConvQuadInterp3d(strict_maxima_bonus=10.0),)
kwargs = {'x': <tf.Tensor: shape=(1, 1, 3, 5, 5), dtype=float32, numpy=
array([[[[[ 1.0067405 , -0.8619741 , -1.06081   ,  0.42...105982  ],
          [ 0.15310992, -0.7514802 , -0.5931298 ,  0.1012269 ,
            1.9728568 ]]]]], dtype=float32)>}

    @wraps(fn)
    def error_handler(*args, **kwargs):
        if not is_traceback_filtering_enabled():
            return fn(*args, **kwargs)
    
        filtered_tb = None
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            filtered_tb = _process_traceback_frames(e.__traceback__)
            # To get the full stack trace, call:
            # `keras.config.disable_traceback_filtering()`
>           raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/keras/src/utils/traceback_utils.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_ConvQuadInterp3d(strict_maxima_bonus=10.0)
x = <tf.Tensor: shape=(1, 1, 3, 5, 5), dtype=float32, numpy=
array([[[[[ 1.0067405 , -0.8619741 , -1.06081   ,  0.42425787....105982  ],
          [ 0.15310992, -0.7514802 , -0.5931298 ,  0.1012269 ,
            1.9728568 ]]]]], dtype=float32)>

    def call(self, x):
>       return tensorflow_conv_quad_interp3d(x, self.strict_maxima_bonus, self.eps)

ivy_transpiled_outputs/tensorflow_outputs/kornia/geometry/subpix/spatial_soft_argmax.py:165: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = <tf.Tensor: shape=(1, 1, 3, 5, 5), dtype=float32, numpy=
array([[[[[ 1.0067405 , -0.8619741 , -1.06081   ,  0.42425787....105982  ],
          [ 0.15310992, -0.7514802 , -0.5931298 ,  0.1012269 ,
            1.9728568 ]]]]], dtype=float32)>
strict_maxima_bonus = 10.0, eps = 1e-07

    def tensorflow_conv_quad_interp3d(input, strict_maxima_bonus=10.0, eps=1e-07):
        from ...core._backend import stack
        from ...core._backend import rand
        from ...core._backend import zeros_like
        from ...core._backend import where
        from ....ivy.functional.frontends.torch.tensor_functions import (
            tensorflow_is_tensor_frnt_,
        )
        from ....ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ....ivy.functional.frontends.torch.tensor import tensorflow_permute_frnt_
        from ...utils.grid import tensorflow_create_meshgrid3d
        from ....ivy.functional.frontends.torch.tensor import tensorflow_to_frnt_
        from ...filters.sobel import tensorflow_spatial_gradient3d
        from ....ivy.functional.frontends.torch.tensor import tensorflow_reshape_frnt_
        from ....ivy.functional.frontends.torch.tensor import tensorflow_view_frnt_
        from ...utils._compat import tensorflow_torch_version_ge
        from ....ivy.functional.frontends.torch.tensor import tensorflow_abs_frnt_
        from ....ivy.functional.frontends.torch.tensor import tensorflow_size_frnt_
        from .nms import tensorflow_nms3d
        from ...utils.helpers import tensorflow_safe_solve_with_mask
        from ....ivy.functional.backends.tensorflow.general import tensorflow_get_item
        from ....ivy.functional.frontends.torch.tensor import (
            tensorflow_masked_scatter_frnt_,
        )
        from ....ivy.functional.backends.tensorflow.general import tensorflow_set_item
        from ....ivy.functional.frontends.torch.tensor import tensorflow_max_frnt_
        from ....ivy.functional.frontends.torch.tensor import tensorflow_masked_fill__frnt_
        from ....ivy.functional.frontends.torch.tensor import tensorflow_expand_as_frnt_
        from ....ivy.functional.frontends.torch.blas_and_lapack_ops import (
            tensorflow_bmm_frnt,
        )
        from ....ivy.functional.frontends.torch.tensor import tensorflow_flip_frnt_
        from ....ivy.functional.frontends.torch.tensor import tensorflow_unsqueeze_frnt_
        from ....ivy.functional.frontends.torch.tensor import tensorflow_repeat_frnt_
    
        if not tensorflow_is_tensor_frnt_(input):
            raise TypeError(f"Input type is not a Tensor. Got {type(input)}")
        if not len(tensorflow_shape_frnt_(input)) == 5:
            raise ValueError(
                f"Invalid input shape, we expect BxCxDxHxW. Got: {tensorflow_shape_frnt_(input)}"
            )
        B, CH, D, H, W = tensorflow_shape_frnt_(input)
        grid_global: typing.Any = tensorflow_permute_frnt_(
            tensorflow_create_meshgrid3d(D, H, W, False, device=input.device), 0, 4, 1, 2, 3
        )
        grid_global = tensorflow_to_frnt_(grid_global, input.dtype)
        b: typing.Any = tensorflow_spatial_gradient3d(input, order=1, mode="diff")
        b = tensorflow_reshape_frnt_(
            tensorflow_permute_frnt_(b, 0, 1, 3, 4, 5, 2), -1, 3, 1
        )
        A: typing.Any = tensorflow_spatial_gradient3d(input, order=2, mode="diff")
        A = tensorflow_reshape_frnt_(tensorflow_permute_frnt_(A, 0, 1, 3, 4, 5, 2), -1, 6)
        dxx = A[..., 0]
        dyy = A[..., 1]
        dss = A[..., 2]
        dxy = 0.25 * A[..., 3]
        dys = 0.25 * A[..., 4]
        dxs = 0.25 * A[..., 5]
        Hes = tensorflow_view_frnt_(
            stack([dxx, dxy, dxs, dxy, dyy, dys, dxs, dys, dss], -1), -1, 3, 3
        )
        if not tensorflow_torch_version_ge(1, 10):
            Hes = (
                Hes
                + tensorflow_abs_frnt_(
                    rand(tensorflow_size_frnt_(Hes[0]), device=Hes.device)
                )[None]
                * eps
            )
        nms_mask: typing.Any = tensorflow_nms3d(input, (3, 3, 3), True)
        x_solved: typing.Any = zeros_like(b)
        x_solved_masked, _, solved_correctly = tensorflow_safe_solve_with_mask(
            tensorflow_get_item(b, tensorflow_view_frnt_(nms_mask, -1)),
            tensorflow_get_item(Hes, tensorflow_view_frnt_(nms_mask, -1)),
        )
        new_nms_mask = tensorflow_masked_scatter_frnt_(nms_mask, nms_mask, solved_correctly)
        x_solved = tensorflow_set_item(
            x_solved,
>           where(new_nms_mask.view(-1, 1, 1))[0],
            tensorflow_get_item(x_solved_masked, solved_correctly),
        )
E       AttributeError: Exception encountered when calling tensorflow_ConvQuadInterp3d.call().
E       
E       [1m'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'view'[0m
E       
E       Arguments received by tensorflow_ConvQuadInterp3d.call():
E         • x=tf.Tensor(shape=(1, 1, 3, 5, 5), dtype=float32)

ivy_transpiled_outputs/tensorflow_outputs/kornia/geometry/subpix/spatial_soft_argmax.py:114: AttributeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.subpix.ConvQuadInterp3d
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/geometry/test_subpix.py::test_conv_quad_interp3d[tensorflow-s2s-False] - AttributeError: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'view'
FAILED kornia/geometry/test_subpix.py::test_ConvQuadInterp3d[tensorflow-s2s-False] - AttributeError: Exception encountered when calling tensorflow_ConvQuadInterp3d.call().
============================================================================== 2 failed, 13 passed in 1299.99s (0:21:39) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 8 items

kornia/geometry/test_homography.py .F......                                                                                                                                                      [100%]

=============================================================================================== FAILURES ===============================================================================================
___________________________________________________________________________ test_find_homography_dlt_iterated[jax-s2s-False] ___________________________________________________________________________
jax.errors.SimplifiedTraceback: For simplicity, JAX has removed its internal frames from the traceback of the following exception. Set JAX_TRACEBACK_FILTERING=off to include these.

The above exception was the direct cause of the following exception:

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_find_homography_dlt_iterated(target_framework, mode, backend_compile):
        trace_args = (
            torch.rand(1, 4, 2),
            torch.rand(1, 4, 2),
            torch.rand(1, 4),
        )
        trace_kwargs = {'soft_inl_th': 3.0, 'n_iter': 5}
        test_args = (
            torch.rand(5, 4, 2),
            torch.rand(5, 4, 2),
            torch.rand(5, 4),
        )
        test_kwargs = {'soft_inl_th': 4.0, 'n_iter': 5}
>       _test_function(
            kornia.geometry.homography.find_homography_dlt_iterated,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=5e-2,
            mode=mode,
            # NOTE: numerical instability in svd()/lu() leads to logits not being allclose
            deterministic=False,
        )

kornia/geometry/test_homography.py:48: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function find_homography_dlt_iterated at 0x7f5337e53250>
trace_args = (tensor([[[0.6807, 0.9210],
         [0.7711, 0.2529],
         [0.1987, 0.0555],
         [0.1457, 0.5953]]]), tensor... [0.0385, 0.8681],
         [0.4750, 0.9479],
         [0.4100, 0.6742]]]), tensor([[0.7410, 0.7865, 0.0505, 0.7193]]))
trace_kwargs = {'n_iter': 5, 'soft_inl_th': 3.0}
test_args = (tensor([[[0.8768, 0.2969],
         [0.0542, 0.6541],
         [0.4940, 0.7014],
         [0.4230, 0.4364]],

       ...[0.6559, 0.9308, 0.1884, 0.1530],
        [0.3523, 0.5635, 0.1016, 0.8191],
        [0.7708, 0.7305, 0.8172, 0.2233]]))
test_kwargs = {'n_iter': 5, 'soft_inl_th': 4.0}, target = 'jax', backend_compile = False, tolerance = 0.05, mode = 's2s', skip = False, deterministic = False, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function find_homography_dlt_iterated at 0x7f5337e53250>, fn_name = 'kornia.geometry.homography.find_homography_dlt_iterated'
trace_args = (tensor([[[0.6807, 0.9210],
         [0.7711, 0.2529],
         [0.1987, 0.0555],
         [0.1457, 0.5953]]]), tensor... [0.0385, 0.8681],
         [0.4750, 0.9479],
         [0.4100, 0.6742]]]), tensor([[0.7410, 0.7865, 0.0505, 0.7193]]))
trace_kwargs = {'n_iter': 5, 'soft_inl_th': 3.0}
test_args = (tensor([[[0.8768, 0.2969],
         [0.0542, 0.6541],
         [0.4940, 0.7014],
         [0.4230, 0.4364]],

       ...[0.6559, 0.9308, 0.1884, 0.1530],
        [0.3523, 0.5635, 0.1016, 0.8191],
        [0.7708, 0.7305, 0.8172, 0.2233]]))
test_kwargs = {'n_iter': 5, 'soft_inl_th': 4.0}, target = 'jax', backend_compile = False, tolerance = 0.05, deterministic = False, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:232: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

points1 = Array([[[0.6807131 , 0.92096317],
        [0.77113444, 0.25290692],
        [0.19871992, 0.05547088],
        [0.14568478, 0.59530497]]], dtype=float32)
points2 = Array([[[0.80393684, 0.85743666],
        [0.03851509, 0.8680956 ],
        [0.47502136, 0.9479244 ],
        [0.41001815, 0.67418057]]], dtype=float32)
weights = Array([[0.74100053, 0.78653383, 0.0504629 , 0.7193481 ]], dtype=float32), soft_inl_th = 3.0, n_iter = 5

    def jax_find_homography_dlt_iterated(
        points1, points2, weights, soft_inl_th=3.0, n_iter=5
    ):
        from ...ivy.functional.frontends.torch.pointwise_ops import jax_exp_frnt
    
>       H: typing.Any = jax_find_homography_dlt(points1, points2, weights)

ivy_transpiled_outputs/jax_outputs/kornia/geometry/homography.py:181: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

points1 = Array([[[0.6807131 , 0.92096317],
        [0.77113444, 0.25290692],
        [0.19871992, 0.05547088],
        [0.14568478, 0.59530497]]], dtype=float32)
points2 = Array([[[0.80393684, 0.85743666],
        [0.03851509, 0.8680956 ],
        [0.47502136, 0.9479244 ],
        [0.41001815, 0.67418057]]], dtype=float32)
weights = Array([[0.74100053, 0.78653383, 0.0504629 , 0.7193481 ]], dtype=float32), solver = 'lu'

    def jax_find_homography_dlt(points1, points2, weights=None, solver="lu"):
        from ...ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ..core.check import jax_KORNIA_CHECK_SHAPE
        from ..utils.helpers import jax__extract_device_dtype
        from .epipolar.fundamental import jax_normalize_points
        from ...ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            jax_chunk_frnt,
        )
        from ...ivy.functional.frontends.torch.creation_ops import (
            jax_ones_like_v_0p4p0_and_above_frnt,
        )
        from ...ivy.functional.frontends.torch.creation_ops import jax_zeros_like_frnt
        from ...ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            jax_cat_frnt,
        )
        from ...ivy.functional.frontends.torch.tensor import jax_reshape_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_transpose_frnt_
        from ...ivy.functional.frontends.torch.miscellaneous_ops import jax_diag_embed_frnt
        from ...ivy.functional.frontends.torch.tensor import jax_repeat_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_unsqueeze_frnt_
        from ..utils.helpers import jax__torch_svd_cast
        from ...ivy.functional.frontends.torch.creation_ops import jax_empty_frnt
        from ...ivy.functional.frontends.torch.tensor import jax_size_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_view_frnt_
        from ...ivy.functional.frontends.torch.creation_ops import jax_ones_frnt
        from ..utils.helpers import jax_safe_solve_with_mask
        from ..utils.helpers import jax_safe_inverse_with_mask
    
        if jax_shape_frnt_(points1) != jax_shape_frnt_(points2):
            raise AssertionError(jax_shape_frnt_(points1))
        if jax_shape_frnt_(points1)[1] < 4:
            raise AssertionError(jax_shape_frnt_(points1))
        jax_KORNIA_CHECK_SHAPE(points1, ["B", "N", "2"])
        jax_KORNIA_CHECK_SHAPE(points2, ["B", "N", "2"])
        device, dtype = jax__extract_device_dtype([points1, points2])
        eps: typing.Any = 1e-08
        points1_norm, transform1 = jax_normalize_points(points1)
        points2_norm, transform2 = jax_normalize_points(points2)
        x1, y1 = jax_chunk_frnt(points1_norm, dim=-1, chunks=2)
        x2, y2 = jax_chunk_frnt(points2_norm, dim=-1, chunks=2)
        ones, zeros = jax_ones_like_v_0p4p0_and_above_frnt(x1), jax_zeros_like_frnt(x1)
        ax = jax_cat_frnt(
            [zeros, zeros, zeros, -x1, -y1, -ones, y2 * x1, y2 * y1, y2], dim=-1
        )
        ay = jax_cat_frnt(
            [x1, y1, ones, zeros, zeros, zeros, -x2 * x1, -x2 * y1, -x2], dim=-1
        )
        A = jax_reshape_frnt_(
            jax_cat_frnt((ax, ay), dim=-1),
            jax_shape_frnt_(ax)[0],
            -1,
            jax_shape_frnt_(ax)[-1],
        )
        if weights is None:
            A = jax_transpose_frnt_(A, -2, -1) @ A
        else:
            if not (
                len(jax_shape_frnt_(weights)) == 2
                and jax_shape_frnt_(weights) == jax_shape_frnt_(points1)[:2]
            ):
                raise AssertionError(jax_shape_frnt_(weights))
            w_diag = jax_diag_embed_frnt(
                jax_reshape_frnt_(
                    jax_repeat_frnt_(jax_unsqueeze_frnt_(weights, dim=-1), 1, 1, 2),
                    jax_shape_frnt_(weights)[0],
                    -1,
                )
            )
            A = jax_transpose_frnt_(A, -2, -1) @ w_diag @ A
        if solver == "svd":
            try:
                _, _, V = jax__torch_svd_cast(A)
            except RuntimeError:
                warnings.warn("SVD did not converge", RuntimeWarning)
                return jax_empty_frnt(
                    (jax_size_frnt_(points1_norm, 0), 3, 3), device=device, dtype=dtype
                )
            H = jax_view_frnt_(V[..., -1], -1, 3, 3)
        elif solver == "lu":
            B = jax_ones_frnt(
                jax_shape_frnt_(A)[0], jax_shape_frnt_(A)[1], device=device, dtype=dtype
            )
>           sol, _, _ = jax_safe_solve_with_mask(B, A)

ivy_transpiled_outputs/jax_outputs/kornia/geometry/homography.py:167: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

B = Array([[1., 1., 1., 1., 1., 1., 1., 1., 1.]], dtype=float32)
A = Array([[[ 2.0959635 ,  0.0328821 ,  0.6434728 ,  0.        ,
          0.        ,  0.        ,  1.1012303 , -3.00743 ...4297, -0.812836  ,
          0.2936204 ,  0.38618198,  5.499768  ,  2.4361262 ,
          7.117564  ]]], dtype=float32)

    def jax_safe_solve_with_mask(B, A):
        from ._compat import jax_torch_version_ge
        from ...ivy.functional.frontends.torch.creation_ops import jax_ones_frnt
        from ...ivy.functional.frontends.torch.linalg import jax_lu_factor_ex_frnt
        from ...ivy.functional.frontends.torch.tensor import jax_to_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_unsqueeze_frnt_
        from ...ivy.functional.frontends.torch.linalg import jax_lu_solve_frnt
        from ...ivy.functional.frontends.torch.miscellaneous_ops import (
            jax_lu_solve_frnt_base_count_1_frnt,
        )
        from ...ivy.functional.frontends.torch.linalg import lu
    
        if not jax_torch_version_ge(1, 10):
            sol = jax__torch_solve_cast(A, B)
            warnings.warn(
                "PyTorch version < 1.10, solve validness mask maybe not correct",
                RuntimeWarning,
            )
            return sol, sol, jax_ones_frnt(len(A), dtype=jnp.bool, device=A.device)
        if not isinstance(B, (jax.Array, nnx.Param)):
            raise AssertionError(f"B must be Tensor. Got: {type(B)}.")
        dtype: typing.Any = B.dtype
        if dtype not in (jnp.float32, jnp.float64):
            dtype = jnp.float32
        if TYPE_CHECKING:
            A_LU: typing.Any
            pivots: typing.Any
            info: typing.Any
        elif jax_torch_version_ge(1, 13):
>           A_LU, pivots, info = jax_lu_factor_ex_frnt(jax_to_frnt_(A, dtype))

ivy_transpiled_outputs/jax_outputs/kornia/utils/helpers.py:120: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

A = Array([[[ 2.0959635 ,  0.0328821 ,  0.6434728 ,  0.        ,
          0.        ,  0.        ,  1.1012303 , -3.00743 ...4297, -0.812836  ,
          0.2936204 ,  0.38618198,  5.499768  ,  2.4361262 ,
          7.117564  ]]], dtype=float32)

    def jax_lu_factor_ex_frnt(A, *, pivot=True, check_errors=False, out=None):
        from ...backends.jax.experimental.linear_algebra import jax_lu_factor
        from ...backends.jax.creation import jax_zeros
        from .tensor import jax_shape_frnt_
        from ...backends.jax.creation import jax_full_like
        from ...backends.jax.creation import jax_ones
    
        try:
>           LU, pivots = jax_lu_factor(A, pivot=pivot, out=out)

ivy_transpiled_outputs/jax_outputs/ivy/functional/frontends/torch/linalg.py:68: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = [Array([[[ 2.0959635 ,  0.0328821 ,  0.6434728 ,  0.        ,
          0.        ,  0.        ,  1.1012303 , -3.00743...297, -0.812836  ,
          0.2936204 ,  0.38618198,  5.499768  ,  2.4361262 ,
          7.117564  ]]], dtype=float32)]
kwargs = {'out': None, 'pivot': True}, jax_is_array_bknd = <function jax_is_array_bknd at 0x7f52acfee5f0>, jax_set_item = <function jax_set_item at 0x7f52acf31bd0>
jax_asarray = <function jax_asarray at 0x7f52acfef010>, jax_get_item = <function jax_get_item at 0x7f52acf31a20>, num_args = 1
type_hints = mappingproxy(OrderedDict([('x', <Parameter "x: jax.Array">), ('pivot', <Parameter "pivot: Optional[bool] = True">), ('out', <Parameter "out: Optional[jax.Array] = None">)]))
parameters = ['x', 'pivot', 'out'], annotations = [<class 'jax.Array'>, typing.Optional[bool], typing.Optional[jax.Array]], device = CpuDevice(id=0), i = 0

    @functools.wraps(fn)
    def _handle_array_like_without_promotion(*args, **kwargs):
        from .functional.ivy.general import jax_is_array_bknd
        from .functional.backends.jax.general import jax_set_item
        from .functional.backends.jax.creation import jax_asarray
        from .functional.backends.jax.general import jax_get_item
    
        args = list(args)
        num_args = len(args)
        try:
            type_hints = inspect.signature(fn).parameters
        except (TypeError, ValueError):
            return fn(*args, **kwargs)
        parameters = list(type_hints.keys())
        annotations = [param.annotation for param in type_hints.values()]
        device = jax__get_preferred_device(args, kwargs)
        for i, (annotation, parameter, arg) in enumerate(
            zip(annotations, parameters, args)
        ):
            annotation_str = str(annotation)
            if (
                ("rray" in annotation_str or "Tensor" in annotation_str)
                and parameter != "out"
                and all(
                    sq not in annotation_str
                    for sq in ["Sequence", "List", "Tuple", "float", "int", "bool"]
                )
            ):
                if i < num_args:
                    if arg is None or jax__check_in_nested_sequence(
                        arg, value=Ellipsis, _type=slice
                    ):
                        continue
                    if not jax_is_array_bknd(arg):
                        args = jax_set_item(args, i, jax_asarray(arg, device=device))
                elif parameters in kwargs:
                    kwarg = jax_get_item(kwargs, parameter)
                    if not jax_is_array_bknd(kwarg):
                        kwargs = jax_set_item(
                            kwargs, parameter, jax_asarray(kwarg, device=device)
                        )
>       return fn(*args, **kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/func_wrapper.py:130: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = Array([[[ 2.0959635 ,  0.0328821 ,  0.6434728 ,  0.        ,
          0.        ,  0.        ,  1.1012303 , -3.00743 ...4297, -0.812836  ,
          0.2936204 ,  0.38618198,  5.499768  ,  2.4361262 ,
          7.117564  ]]], dtype=float32)

    @jax_handle_array_like_without_promotion
    def jax_lu_factor(
        x: jax.Array, /, *, pivot: Optional[bool] = True, out: Optional[jax.Array] = None
    ):
>       ret = jax.scipy.linalg.lu(x)

ivy_transpiled_outputs/jax_outputs/ivy/functional/backends/jax/experimental/linear_algebra.py:48: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = Traced<ShapedArray(float32[1,9,9])>with<DynamicJaxprTrace(level=1/0)>, permute_l = False

    @partial(jit, static_argnames=('permute_l', 'overwrite_a', 'check_finite'))
    def lu(a: ArrayLike, permute_l: bool = False, overwrite_a: bool = False,
           check_finite: bool = True) -> tuple[Array, Array] | tuple[Array, Array, Array]:
      """Compute the LU decomposition
    
      JAX implementation of :func:`scipy.linalg.lu`.
    
      The LU decomposition of a matrix `A` is:
    
      .. math::
    
         A = P L U
    
      where `P` is a permutation matrix, `L` is lower-triangular and `U` is upper-triangular.
    
      Args:
        a: array of shape ``(..., M, N)`` to decompose.
        permute_l: if True, then permute ``L`` and return ``(P @ L, U)`` (default: False)
        overwrite_a: not used by JAX
        check_finite: not used by JAX
    
      Returns:
        A tuple of arrays ``(P @ L, U)`` if ``permute_l`` is True, else ``(P, L, U)``:
    
        - ``P`` is a permutation matrix of shape ``(..., M, M)``
        - ``L`` is a lower-triangular matrix of shape ``(... M, K)``
        - ``U`` is an upper-triangular matrix of shape ``(..., K, N)``
    
        with ``K = min(M, N)``
    
      See also:
        - :func:`jax.numpy.linalg.lu`: NumPy-style API for LU decomposition.
        - :func:`jax.lax.linalg.lu`: XLA-style API for LU decomposition.
        - :func:`jax.scipy.linalg.lu_solve`: LU-based linear solver.
    
      Examples:
        An LU decomposition of a 3x3 matrix:
    
        >>> a = jnp.array([[1., 2., 3.],
        ...                [5., 4., 2.],
        ...                [3., 2., 1.]])
        >>> P, L, U = jax.scipy.linalg.lu(a)
    
        ``P`` is a permutation matrix: i.e. each row and column has a single ``1``:
    
        >>> P
        Array([[0., 1., 0.],
               [1., 0., 0.],
               [0., 0., 1.]], dtype=float32)
    
        ``L`` and ``U`` are lower-triangular and upper-triangular matrices:
    
        >>> with jnp.printoptions(precision=3):
        ...   print(L)
        ...   print(U)
        [[ 1.     0.     0.   ]
         [ 0.2    1.     0.   ]
         [ 0.6   -0.333  1.   ]]
        [[5.    4.    2.   ]
         [0.    1.2   2.6  ]
         [0.    0.    0.667]]
    
        The original matrix can be reconstructed by multiplying the three together:
    
        >>> a_reconstructed = P @ L @ U
        >>> jnp.allclose(a, a_reconstructed)
        Array(True, dtype=bool)
      """
      del overwrite_a, check_finite  # unused
>     return _lu(a, permute_l)

/opt/fw/jax/jax/_src/scipy/linalg.py:821: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = Traced<ShapedArray(float32[1,9,9])>with<DynamicJaxprTrace(level=2/0)>, permute_l = False

    @partial(jit, static_argnums=(1,))
    def _lu(a: ArrayLike, permute_l: bool) -> tuple[Array, Array] | tuple[Array, Array, Array]:
      a, = promote_dtypes_inexact(jnp.asarray(a))
      lu, _, permutation = lax_linalg.lu(a)
      dtype = lax.dtype(a)
>     m, n = jnp.shape(a)
E     ValueError: too many values to unpack (expected 2)

/opt/fw/jax/jax/_src/scipy/linalg.py:729: ValueError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.homography.find_homography_dlt_iterated
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/geometry/test_homography.py::test_find_homography_dlt_iterated[jax-s2s-False] - ValueError: too many values to unpack (expected 2)
=============================================================================== 1 failed, 7 passed in 583.93s (0:09:43) ================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 8 items

kornia/test_image.py ssssssss                                                                                                                                                                    [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
========================================================================================== 8 skipped in 5.58s ==========================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 15 items

kornia/test_contrib.py ....FF......F..                                                                                                                                                           [100%]

=============================================================================================== FAILURES ===============================================================================================
__________________________________________________________________________________ test_diamond_square[jax-s2s-False] __________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_diamond_square(target_framework, mode, backend_compile):
        trace_args = ((1, 1, 8, 8),)
        trace_kwargs = {
            "roughness": 0.5,
            "random_scale": 1.0,
            "normalize_range": (0.0, 1.0),
            "random_fn": torch.ones,
        }
        test_args = ((5, 1, 8, 8),)
        test_kwargs = {
            "roughness": 0.7,
            "random_scale": 0.9,
            "normalize_range": (-1.0, 1.0),
            "random_fn": torch.ones,
        }
>       _test_function(
            kornia.contrib.diamond_square,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/test_contrib.py:141: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function diamond_square at 0x7f94ee3ed2d0>, trace_args = ((1, 1, 8, 8),)
trace_kwargs = {'normalize_range': (0.0, 1.0), 'random_fn': <built-in method ones of type object at 0x7f95067728c0>, 'random_scale': 1.0, 'roughness': 0.5}, test_args = ((5, 1, 8, 8),)
test_kwargs = {'normalize_range': (-1.0, 1.0), 'random_fn': <built-in method ones of type object at 0x7f95067728c0>, 'random_scale': 0.9, 'roughness': 0.7}, target = 'jax', backend_compile = False
tolerance = 0.001, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function diamond_square at 0x7f94ee3ed2d0>, fn_name = 'kornia.contrib.diamond_square', trace_args = ((1, 1, 8, 8),)
trace_kwargs = {'normalize_range': (0.0, 1.0), 'random_fn': <built-in method ones of type object at 0x7f95067728c0>, 'random_scale': 1.0, 'roughness': 0.5}, test_args = ((5, 1, 8, 8),)
test_kwargs = {'normalize_range': (-1.0, 1.0), 'random_fn': <built-in method ones of type object at 0x7f95067728c0>, 'random_scale': 0.9, 'roughness': 0.7}, target = 'jax', backend_compile = False
tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:232: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

output_size = (1, 1, 8, 8), roughness = Array([[[[0.5]]]], dtype=float64), random_scale = Array([[[[1.]]]], dtype=float64), random_fn = <built-in method ones of type object at 0x7f95067728c0>
normalize_range = (0.0, 1.0), device = None, dtype = None

    def jax_diamond_square(
        output_size,
        roughness=0.5,
        random_scale=1.0,
        random_fn=jax_rand_frnt,
        normalize_range=None,
        device=None,
        dtype=None,
    ):
        from ..core.check import jax_KORNIA_CHECK
        from ...ivy.functional.frontends.torch.tensor import jax_to_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_expand_frnt_
        from ..core.check import jax_KORNIA_CHECK_IS_TENSOR
        from ...ivy.functional.frontends.torch.tensor import jax_view_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_reshape_frnt_
        from ...ivy.functional.backends.jax.general import jax_get_item
        from ..enhance.normalize import jax_normalize_min_max
        from ...ivy.functional.frontends.torch.tensor import jax_contiguous_frnt_
    
        jax_KORNIA_CHECK(len(output_size) == 4, "output_size must be (B,C,H,W)")
        if not isinstance(random_scale, (jax.Array, nnx.Param)):
            random_scale = jax_to_frnt_(jnp.asarray([[[[random_scale]]]]), device, dtype)
            random_scale = jax_expand_frnt_(
                random_scale, [output_size[0] * output_size[1], 1, 1, 1]
            )
        else:
            jax_KORNIA_CHECK_IS_TENSOR(random_scale)
            random_scale = jax_view_frnt_(random_scale, -1, 1, 1, 1)
            random_scale = jax_expand_frnt_(
                random_scale, [output_size[0], output_size[1], 1, 1]
            )
            random_scale = jax_reshape_frnt_(random_scale, [-1, 1, 1, 1])
        if not isinstance(roughness, (jax.Array, nnx.Param)):
            roughness = jax_to_frnt_(jnp.asarray([[[[roughness]]]]), device, dtype)
            roughness = jax_expand_frnt_(
                roughness, [output_size[0] * output_size[1], 1, 1, 1]
            )
        else:
            roughness = jax_view_frnt_(roughness, -1, 1, 1, 1)
            roughness = jax_expand_frnt_(roughness, [output_size[0], output_size[1], 1, 1])
            roughness = jax_reshape_frnt_(roughness, [-1, 1, 1, 1])
        width, height = output_size[-2:][0], output_size[-2:][1]
        num_samples: typing.Any = 1
        for x in output_size[:-2]:
            num_samples = num_samples * x
        p2_width: typing.Any = 2 ** math.ceil(math.log2(width - 1)) + 1
        p2_height: typing.Any = 2 ** math.ceil(math.log2(height - 1)) + 1
        recursion_depth: typing.Any = int(
            min(math.log2(p2_width - 1) - 1, math.log2(p2_height - 1) - 1)
        )
        seed_width: typing.Any = (p2_width - 1) // 2**recursion_depth + 1
        seed_height: typing.Any = (p2_height - 1) // 2**recursion_depth + 1
>       img: typing.Any = random_scale * jax__diamond_square_seed(
            num_samples, seed_width, seed_height, random_fn, device, dtype
        )
E       TypeError: unsupported operand type(s) for *: 'jaxlib.xla_extension.ArrayImpl' and 'Tensor'

ivy_transpiled_outputs/jax_outputs/kornia/contrib/diamond_square.py:225: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.contrib.diamond_square.diamond_square
___________________________________________________________________________________ test_EdgeDetector[jax-s2s-False] ___________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_EdgeDetector(target_framework, mode, backend_compile):
        print("kornia.contrib.EdgeDetector")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, target=target_framework)
    
        torch_detector = kornia.contrib.EdgeDetector()
        transpiled_detector = transpiled_kornia.contrib.EdgeDetector()
    
        torch_args = (
            torch.rand(1, 3, 320, 320),
        )
        torch_out = torch_detector(*torch_args)
    
        transpiled_args = _nest_torch_tensor_to_new_framework(torch_args, target_framework)
>       transpiled_out = transpiled_detector(*transpiled_args)

kornia/test_contrib.py:171: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_EdgeDetector(
  (model): jax_DexiNed(
    (block_1): jax_DoubleConvBlock(
      (conv1): FlaxConv(in_features=3, o..., 1), padding=0, padding_mode=zeros)
      (bn): FlaxBatchNorm2D(1, eps=1e-05, momentum=0.99, affine=True, 
    )
  )
)
image = Array([[[[0.94756657, 0.1289041 , 0.5799332 , ..., 0.20425165,
          0.78013897, 0.12650478],
         [0.87928015... ],
         [0.49240792, 0.29875642, 0.95659524, ..., 0.35310584,
          0.45872307, 0.07385468]]]], dtype=float32)

    def __call__(self, image):
        from ..core.check import jax_KORNIA_CHECK_SHAPE
    
        jax_KORNIA_CHECK_SHAPE(image, ["B", "3", "H", "W"])
        img = self.preprocess(image)
>       out = self.model(img)

ivy_transpiled_outputs/jax_outputs/kornia/contrib/edge_detection.py:57: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_DexiNed(
  (block_1): jax_DoubleConvBlock(
    (conv1): FlaxConv(in_features=3, out_features=32, kernel_size=(3, 3...rides=(1, 1), padding=0, padding_mode=zeros)
    (bn): FlaxBatchNorm2D(1, eps=1e-05, momentum=0.99, affine=True, 
  )
)
x = Array([[[[0.94756657, 0.1289041 , 0.5799332 , ..., 0.20425165,
          0.78013897, 0.12650478],
         [0.87928015... ],
         [0.49240792, 0.29875642, 0.95659524, ..., 0.35310584,
          0.45872307, 0.07385468]]]], dtype=float32)

    def __call__(self, x):
        from ...ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ..core._backend import concatenate
    
        block_1 = self.block_1(x)
>       block_1_side = self.side_1(block_1)

ivy_transpiled_outputs/jax_outputs/kornia/filters/dexined.py:611: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_SingleConvBlock(
  (conv): FlaxConv(in_features=64, out_features=128, kernel_size=(1, 1), strides=(2, 2), padding=0, padding_mode=zeros)
  (bn): FlaxBatchNorm2D(128, eps=1e-05, momentum=0.99, affine=True, 
)
x = Array([[[[-0.09816843, -0.00303964, -0.03830347, ...,  0.12888813,
          -0.09862142,  0.10843743],
         [-0.0...       [ 0.09831925,  0.00826181,  0.11727384, ...,  0.10926876,
           0.05452048,  0.04923777]]]], dtype=float32)

    def __call__(self, x):
        x = self.conv(x)
        if self.use_bn:
>           x = self.bn(x)

ivy_transpiled_outputs/jax_outputs/kornia/filters/dexined.py:372: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = FlaxBatchNorm2D(128, eps=1e-05, momentum=0.99, affine=True, 
args = (Array([[[[-0.09816843, -0.00303964, -0.03830347, ...,  0.12888813,
          -0.09862142,  0.10843743],
         [-0....     [ 0.09831925,  0.00826181,  0.11727384, ...,  0.10926876,
           0.05452048,  0.04923777]]]], dtype=float32),)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x55ea40a0c6c0, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/jax_outputs/jax__st...y', lineno=159, function='pytest_pyfunc_call', code_context=['    result = testfunction(**testargs)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/jax_outputs/jax__stateful.py:102: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = FlaxBatchNorm2D(128, eps=1e-05, momentum=0.99, affine=True, 
args = (Array([[[[-0.09816843, -0.00303964, -0.03830347, ...,  0.12888813,
          -0.09862142,  0.10843743],
         [-0....     [ 0.09831925,  0.00826181,  0.11727384, ...,  0.10926876,
           0.05452048,  0.04923777]]]], dtype=float32),)
kwargs = {}, jax_get_item = <function jax_get_item at 0x7f943d1f7490>, jax_set_item = <function jax_set_item at 0x7f943d1f7640>, DATA_FORMAT = 'channels_last'
fn_args_and_kwargs = {'inputs': Array([[[[-0.09816843,  0.0550961 , -0.11583222, ...,  0.24398296,
          -0.37168542, -0.06128588],
   ...      [ 0.19638786, -0.08750517, -0.31797698, ..., -0.07513911,
          -0.338302  ,  0.04923777]]]], dtype=float32)}
conv_block_start = <function jax_handle_transpose_in_input_and_output.<locals>.transpose_wrapper.<locals>.<lambda> at 0x7f9460147b50>, next_call_in_seq = None, conv_block_continued = None
arg_name = 'inputs'
input = Array([[[[-0.09816843, -0.00303964, -0.03830347, ...,  0.12888813,
          -0.09862142,  0.10843743],
         [-0.0...       [ 0.09831925,  0.00826181,  0.11727384, ...,  0.10926876,
           0.05452048,  0.04923777]]]], dtype=float32)
transpose = <jax_TransposeType.CONV2D: 'conv2d'>

    @functools.wraps(fn)
    def transpose_wrapper(self, *args, **kwargs):
        from ..functional.backends.jax.general import jax_get_item
        from ..functional.backends.jax.general import jax_set_item
    
        DATA_FORMAT = os.environ.get("DATA_FORMAT", "channels_first")
        kwargs_call = {
            key: val
            for key, val in kwargs.items()
            if key not in dict(original_signature.parameters)
        }
        fn_args_and_kwargs = {
            key: val for key, val in kwargs.items() if key not in kwargs_call
        }
        fn_args_and_kwargs.update(dict(zip(fn.__code__.co_varnames[1:], args)))
        conv_block_start = lambda f: any(
            substr in f.__qualname__
            for substr in CONV_FUNCS
            + NORM_FUNCS
            + POOL_FUNCS
            + KERAS_CONV_FUNCS
            + KERAS_NORM_FUNCS
            + KERAS_POOL_FUNCS
            + FLAX_CONV_FUNCS
            + FLAX_NORM_FUNCS
            + FLAX_POOL_FUNCS
        )
        next_call_in_seq = jax_get_next_func(self)
        name_of_next_call = (
            next_call_in_seq.__class__.__name__
            if hasattr(next_call_in_seq, "__class__")
            else ""
        )
        conv_block_continued = next_call_in_seq and any(
            substr in name_of_next_call for substr in CONV_BLOCK_FNS
        )
        arg_name = "input" if "input" in fn_args_and_kwargs else "inputs"
        if DATA_FORMAT == "channels_first" and conv_block_start(self.__class__):
            input = jax_get_item(fn_args_and_kwargs, arg_name)
            if len(input.shape) > 4:
                transpose = jax_TransposeType.CONV3D
            elif len(input.shape) > 3:
                transpose = jax_TransposeType.CONV2D
            elif len(input.shape) > 2:
                transpose = jax_TransposeType.CONV1D
            else:
                transpose = jax_TransposeType.NO_TRANSPOSE
            fn_args_and_kwargs = jax_set_item(
                fn_args_and_kwargs,
                arg_name,
                jax_apply_transpose(input, transpose=transpose, pt_to_tf=True),
            )
            DATA_FORMAT = "channels_last"
            os.environ = jax_set_item(os.environ, "DATA_FORMAT", DATA_FORMAT)
>       res = fn(self, **fn_args_and_kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/utils/decorator_utils.py:412: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = FlaxBatchNorm2D(128, eps=1e-05, momentum=0.99, affine=True, 
inputs = Array([[[[-0.09816843,  0.0550961 , -0.11583222, ...,  0.24398296,
          -0.37168542, -0.06128588],
         [-0.0...       [ 0.19638786, -0.08750517, -0.31797698, ..., -0.07513911,
          -0.338302  ,  0.04923777]]]], dtype=float32)
use_running_average = None

    @store_frame_info
    @jax_handle_transpose_in_input_and_output
    def __call__(self, inputs, use_running_average=None, *, mask=None):
        self._built = True
>       logits = super().__call__(
            inputs, use_running_average=use_running_average, mask=mask
        )

ivy_transpiled_outputs/jax_outputs/jax__stateful_layers.py:479: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = FlaxBatchNorm2D(128, eps=1e-05, momentum=0.99, affine=True, 
x = Array([[[[-0.09816843,  0.0550961 , -0.11583222, ...,  0.24398296,
          -0.37168542, -0.06128588],
         [-0.0...       [ 0.19638786, -0.08750517, -0.31797698, ..., -0.07513911,
          -0.338302  ,  0.04923777]]]], dtype=float32)
use_running_average = True

    def __call__(
      self,
      x,
      use_running_average: tp.Optional[bool] = None,
      *,
      mask: tp.Optional[jax.Array] = None,
    ):
      """Normalizes the input using batch statistics.
    
      Args:
        x: the input to be normalized.
        use_running_average: if true, the stored batch statistics will be
          used instead of computing the batch statistics on the input. The
          ``use_running_average`` flag passed into the call method will take
          precedence over the ``use_running_average`` flag passed into the
          constructor.
    
      Returns:
        Normalized inputs (the same shape as inputs).
      """
    
      use_running_average = first_from(
        use_running_average,
        self.use_running_average,
        error_msg="""No `use_running_average` argument was provided to BatchNorm
          as either a __call__ argument, class attribute, or nnx.flag.""",
      )
      feature_axes = _canonicalize_axes(x.ndim, self.axis)
      reduction_axes = tuple(i for i in range(x.ndim) if i not in feature_axes)
    
      if use_running_average:
        mean, var = self.mean.value, self.var.value
      else:
        mean, var = _compute_stats(
          x,
          reduction_axes,
          dtype=self.dtype,
          axis_name=self.axis_name,
          axis_index_groups=self.axis_index_groups,
          use_fast_variance=self.use_fast_variance,
          mask=mask,
        )
    
        self.mean.value = (
          self.momentum * self.mean.value + (1 - self.momentum) * mean
        )
        self.var.value = (
          self.momentum * self.var.value + (1 - self.momentum) * var
        )
    
>     return _normalize(
        x,
        mean,
        var,
        self.scale.value,
        self.bias.value,
        reduction_axes,
        feature_axes,
        self.dtype,
        self.epsilon,
      )

/opt/fw/jax/flax/nnx/nn/normalization.py:367: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = Array([[[[-0.09816843,  0.0550961 , -0.11583222, ...,  0.24398296,
          -0.37168542, -0.06128588],
         [-0.0...       [ 0.19638786, -0.08750517, -0.31797698, ..., -0.07513911,
          -0.338302  ,  0.04923777]]]], dtype=float32)
mean = Param(
  value=Array([-0.2449035 ,  0.32071695, -0.8167501 , -0.30144545, -0.18064821,
          0.00530162,  0.227697..., -0.6198849 , -0.3519681 ,  0.04875631, -0.61422706,
          0.27642408, -0.27212012, -0.04358729], dtype=float32)
)
var = Param(
  value=Array([0.2625539 , 0.27113461, 0.21946596, 0.15521275, 0.25643   ,
         0.21336786, 0.39907008, 0.2...8342604, 0.5336697 , 0.19832538, 0.22804523, 0.6139669 ,
         0.32740036, 0.37694854, 0.2545803 ], dtype=float32)
)
scale = Array([0.9180028 , 0.85888755, 0.83077097, 0.8763835 , 0.96300054,
       0.8625907 , 0.8677793 , 0.9038065 , 0.968281... 0.9293163 , 0.97165966, 0.9689161 , 0.9450734 , 0.8873313 ,
       0.88254374, 0.99936277, 0.848198  ], dtype=float32)
bias = Array([-0.07675791, -0.03457952, -0.06084337,  0.0461219 , -0.04142413,
        0.07173445, -0.01962172,  0.00044565, ...8167, -0.02156175, -0.02820837,  0.02331718, -0.01897949,
        0.0239033 ,  0.00923689, -0.05559541], dtype=float32)
reduction_axes = (0, 1, 2), feature_axes = (3,), dtype = None, epsilon = 1e-05

    def _normalize(
      x: Array,
      mean: Array,
      var: Array,
      scale: tp.Optional[Array],
      bias: tp.Optional[Array],
      reduction_axes: Axes,
      feature_axes: Axes,
      dtype: tp.Optional[Dtype],
      epsilon: float,
    ):
      """ "Normalizes the input of a normalization layer and optionally applies a learned scale and bias.
    
      Arguments:
        x: The input.
        mean: Mean to use for normalization.
        var: Variance to use for normalization.
        reduction_axes: The axes in ``x`` to reduce.
        feature_axes: Axes containing features. A separate bias and scale is learned
          for each specified feature.
        dtype: The dtype of the result (default: infer from input and params).
        epsilon: Normalization epsilon.
    
      Returns:
        The normalized input.
      """
      reduction_axes = _canonicalize_axes(x.ndim, reduction_axes)
      feature_axes = _canonicalize_axes(x.ndim, feature_axes)
      stats_shape = list(x.shape)
      for axis in reduction_axes:
        stats_shape[axis] = 1
>     mean = mean.reshape(stats_shape)

/opt/fw/jax/flax/nnx/nn/normalization.py:163: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = Param(
  value=Array([-0.2449035 ,  0.32071695, -0.8167501 , -0.30144545, -0.18064821,
          0.00530162,  0.227697..., -0.6198849 , -0.3519681 ,  0.04875631, -0.61422706,
          0.27642408, -0.27212012, -0.04358729], dtype=float32)
)
name = 'reshape'

    def custom_getattr(self, name):
        if name in ("shape", "device", "dtype", "ndim", "size", "itemsize", "T"):
            value = getattr(self, "value")
            if value is not None:
                # Attempt to retrieve the attribute from the wrapped object (`value`)
                return getattr(value, name)
>       return object.__getattribute__(self, name)
E       AttributeError: 'Param' object has no attribute 'reshape'. Did you mean: 'shape'?

ivy_transpiled_outputs/jax_outputs/__init__.py:91: AttributeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.contrib.EdgeDetector
----------------------------------------------------------------------------------------- Captured stderr call -----------------------------------------------------------------------------------------
Downloading: "http://cmp.felk.cvut.cz/~mishkdmy/models/DexiNed_BIPED_10.pth" to /root/.cache/torch/hub/checkpoints/DexiNed_BIPED_10.pth

  0%|          | 0.00/135M [00:00<?, ?B/s]
  0%|          | 128k/135M [00:00<05:44, 409kB/s]
  0%|          | 256k/135M [00:00<03:29, 672kB/s]
  0%|          | 512k/135M [00:00<01:54, 1.23MB/s]
  1%|          | 896k/135M [00:00<01:10, 1.99MB/s]
  1%|▏         | 1.75M/135M [00:00<00:34, 4.02MB/s]
  3%|▎         | 3.50M/135M [00:00<00:17, 8.02MB/s]
  5%|▍         | 6.50M/135M [00:00<00:09, 14.5MB/s]
  7%|▋         | 9.38M/135M [00:01<00:07, 18.6MB/s]
  9%|▉         | 12.1M/135M [00:01<00:06, 21.1MB/s]
 11%|█         | 15.0M/135M [00:01<00:05, 23.2MB/s]
 13%|█▎        | 18.0M/135M [00:01<00:04, 25.0MB/s]
 15%|█▌        | 20.8M/135M [00:01<00:04, 25.5MB/s]
 18%|█▊        | 23.8M/135M [00:01<00:04, 26.6MB/s]
 20%|█▉        | 26.6M/135M [00:01<00:04, 27.2MB/s]
 22%|██▏       | 29.6M/135M [00:01<00:03, 27.8MB/s]
 24%|██▍       | 32.5M/135M [00:01<00:03, 27.7MB/s]
 26%|██▋       | 35.4M/135M [00:02<00:03, 27.9MB/s]
 29%|██▊       | 38.4M/135M [00:02<00:03, 28.3MB/s]
 31%|███       | 41.2M/135M [00:02<00:03, 28.3MB/s]
 33%|███▎      | 44.0M/135M [00:02<00:03, 27.8MB/s]
 35%|███▍      | 46.9M/135M [00:02<00:03, 27.9MB/s]
 37%|███▋      | 49.9M/135M [00:02<00:03, 28.3MB/s]
 39%|███▉      | 52.9M/135M [00:02<00:02, 28.6MB/s]
 41%|████▏     | 55.6M/135M [00:02<00:02, 28.1MB/s]
 43%|████▎     | 58.5M/135M [00:02<00:02, 28.0MB/s]
 46%|████▌     | 61.4M/135M [00:03<00:02, 28.2MB/s]
 48%|████▊     | 64.4M/135M [00:03<00:02, 28.5MB/s]
 50%|████▉     | 67.2M/135M [00:03<00:02, 28.5MB/s]
 52%|█████▏    | 70.1M/135M [00:03<00:02, 28.4MB/s]
 54%|█████▍    | 73.1M/135M [00:03<00:02, 28.4MB/s]
 56%|█████▋    | 76.0M/135M [00:03<00:02, 28.3MB/s]
 59%|█████▊    | 79.0M/135M [00:03<00:02, 28.6MB/s]
 61%|██████    | 82.0M/135M [00:03<00:01, 28.8MB/s]
 63%|██████▎   | 84.9M/135M [00:03<00:01, 28.7MB/s]
 65%|██████▌   | 87.9M/135M [00:03<00:01, 28.8MB/s]
 67%|██████▋   | 90.8M/135M [00:04<00:01, 28.5MB/s]
 70%|██████▉   | 93.6M/135M [00:04<00:01, 28.6MB/s]
 72%|███████▏  | 96.6M/135M [00:04<00:01, 28.8MB/s]
 74%|███████▍  | 99.6M/135M [00:04<00:01, 28.7MB/s]
 76%|███████▋  | 103M/135M [00:04<00:01, 28.9MB/s] 
 78%|███████▊  | 106M/135M [00:04<00:01, 28.3MB/s]
 80%|████████  | 108M/135M [00:04<00:00, 27.7MB/s]
 83%|████████▎ | 111M/135M [00:04<00:00, 27.7MB/s]
 85%|████████▍ | 114M/135M [00:04<00:00, 28.2MB/s]
 87%|████████▋ | 117M/135M [00:05<00:00, 28.5MB/s]
 89%|████████▉ | 120M/135M [00:05<00:00, 28.8MB/s]
 92%|█████████▏| 123M/135M [00:05<00:00, 28.9MB/s]
 94%|█████████▎| 126M/135M [00:05<00:00, 28.6MB/s]
 96%|█████████▌| 129M/135M [00:05<00:00, 28.1MB/s]
 98%|█████████▊| 132M/135M [00:05<00:00, 28.5MB/s]
100%|██████████| 135M/135M [00:05<00:00, 25.1MB/s]
__________________________________________________________________________________ test_ImageStitcher[jax-s2s-False] ___________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_ImageStitcher(target_framework, mode, backend_compile):
        print("kornia.contrib.ImageStitcher")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, target=target_framework)
    
        torch_matcher = kornia.feature.LoFTR(pretrained='outdoor')
>       transpiled_matcher = transpiled_kornia.feature.LoFTR(pretrained='outdoor')

kornia/test_contrib.py:313: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:232: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.loftr.loftr.jax_LoFTR'>, args = (), kwargs = {'pretrained': 'outdoor'}

    def __call__(cls, *args: Any, **kwargs: Any) -> Any:
>     return _graph_node_meta_call(cls, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.loftr.loftr.jax_LoFTR'>, args = (), kwargs = {'pretrained': 'outdoor'}, node = jax_LoFTR()

    def _graph_node_meta_call(cls: tp.Type[G], *args, **kwargs) -> G:
      node = cls.__new__(cls, *args, **kwargs)
      vars(node)['_object__state'] = ObjectState()
>     cls._object_meta_construct(node, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:88: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.loftr.loftr.jax_LoFTR'>, self = jax_LoFTR(), args = (), kwargs = {'pretrained': 'outdoor'}

    def _object_meta_construct(cls, self, *args, **kwargs):
>     self.__init__(*args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:82: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_LoFTR(), pretrained = 'outdoor'
config = {'backbone_type': 'ResNetFPN', 'coarse': {'attention': 'linear', 'd_ffn': 256, 'd_model': 256, 'layer_names': ['self',...: 'linear', 'd_ffn': 128, 'd_model': 128, 'layer_names': ['self', 'cross'], ...}, 'fine_concat_coarse_feat': True, ...}

    def __init__(self, pretrained="outdoor", config=default_cfg):
        from ....ivy.functional.backends.jax.general import jax_set_item
        from .backbone.__init__ import jax_build_backbone
        from .utils.position_encoding import jax_PositionEncodingSine
        from .loftr_module.transformer import jax_LocalFeatureTransformer
        from .utils.coarse_matching import jax_CoarseMatching
        from .loftr_module.fine_preprocess import jax_FinePreprocess
        from .utils.fine_matching import jax_FineMatching
        from ....ivy.functional.frontends.torch.hub.hub import (
            jax_load_state_dict_from_url_frnt,
        )
        from ....ivy.functional.backends.jax.general import jax_get_item
        from ...utils.helpers import jax_map_location_to_cpu
    
        self.super___init__(
            pretrained=pretrained,
            config=config,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        self.config = config
        if pretrained == "indoor_new":
            self.config["coarse"] = jax_set_item(
                self.config["coarse"], "temp_bug_fix", True
            )
>       self.backbone = jax_build_backbone(config)

ivy_transpiled_outputs/jax_outputs/kornia/feature/loftr/loftr.py:108: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

config = {'backbone_type': 'ResNetFPN', 'coarse': {'attention': 'linear', 'd_ffn': 256, 'd_model': 256, 'layer_names': ['self',...: 'linear', 'd_ffn': 128, 'd_model': 128, 'layer_names': ['self', 'cross'], ...}, 'fine_concat_coarse_feat': True, ...}

    def jax_build_backbone(config):
        if config["backbone_type"] == "ResNetFPN":
            if config["resolution"] == (8, 2):
>               return kornia.feature.loftr.resnet_fpn.ResNetFPN_8_2(config["resnetfpn"])
E               NameError: name 'kornia' is not defined

ivy_transpiled_outputs/jax_outputs/kornia/feature/loftr/backbone/__init__.py:42: NameError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.contrib.ImageStitcher
----------------------------------------------------------------------------------------- Captured stderr call -----------------------------------------------------------------------------------------
Downloading: "http://cmp.felk.cvut.cz/~mishkdmy/models/loftr_outdoor.ckpt" to /root/.cache/torch/hub/checkpoints/loftr_outdoor.ckpt

  0%|          | 0.00/44.2M [00:00<?, ?B/s]
  0%|          | 128k/44.2M [00:00<01:53, 407kB/s]
  1%|          | 256k/44.2M [00:00<01:08, 670kB/s]
  1%|          | 512k/44.2M [00:00<00:37, 1.23MB/s]
  2%|▏         | 896k/44.2M [00:00<00:22, 1.99MB/s]
  4%|▍         | 1.75M/44.2M [00:00<00:11, 4.00MB/s]
  8%|▊         | 3.50M/44.2M [00:00<00:05, 8.00MB/s]
 15%|█▍        | 6.50M/44.2M [00:00<00:02, 14.4MB/s]
 21%|██        | 9.38M/44.2M [00:01<00:01, 18.5MB/s]
 28%|██▊       | 12.2M/44.2M [00:01<00:01, 21.4MB/s]
 34%|███▍      | 15.1M/44.2M [00:01<00:01, 23.4MB/s]
 41%|████      | 18.1M/44.2M [00:01<00:01, 25.2MB/s]
 48%|████▊     | 21.1M/44.2M [00:01<00:00, 26.4MB/s]
 54%|█████▍    | 24.0M/44.2M [00:01<00:00, 26.9MB/s]
 61%|██████    | 27.0M/44.2M [00:01<00:00, 27.7MB/s]
 68%|██████▊   | 30.0M/44.2M [00:01<00:00, 28.1MB/s]
 75%|███████▍  | 33.0M/44.2M [00:01<00:00, 28.3MB/s]
 81%|████████▏ | 36.0M/44.2M [00:02<00:00, 28.5MB/s]
 88%|████████▊ | 38.8M/44.2M [00:02<00:00, 28.2MB/s]
 94%|█████████▍| 41.5M/44.2M [00:02<00:00, 27.9MB/s]
100%|██████████| 44.2M/44.2M [00:02<00:00, 20.4MB/s]
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/test_contrib.py::test_diamond_square[jax-s2s-False] - TypeError: unsupported operand type(s) for *: 'jaxlib.xla_extension.ArrayImpl' and 'Tensor'
FAILED kornia/test_contrib.py::test_EdgeDetector[jax-s2s-False] - AttributeError: 'Param' object has no attribute 'reshape'. Did you mean: 'shape'?
FAILED kornia/test_contrib.py::test_ImageStitcher[jax-s2s-False] - NameError: name 'kornia' is not defined
============================================================================== 3 failed, 12 passed in 1401.08s (0:23:21) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 17 items

kornia/augmentation/test_augmentation4.py FF.....F...F..FFF                                                                                                                                      [100%]

=============================================================================================== FAILURES ===============================================================================================
_______________________________________________________________________________ test_RandomMosaic[tensorflow-s2s-False] ________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_RandomMosaic(target_framework, mode, backend_compile):
        print("kornia.augmentation.RandomMosaic")
    
        init_args = ((300, 300),)
        init_kwargs = {"data_keys": ["input", "bbox_xyxy"]}
        call_args = (
            torch.randn(8, 3, 224, 224),
            torch.tensor([[
                [70, 5, 150, 100],
                [60, 180, 175, 220],
            ]]).repeat(8, 1, 1),
        )
        call_kwargs = {}
    
>       _test_augmentation_class(
            kornia.augmentation.RandomMosaic,
            target_framework,
            init_args,
            init_kwargs,
            call_args,
            call_kwargs,
            deterministic_output=False,
            backend_compile=backend_compile,
        )

kornia/augmentation/test_augmentation4.py:80: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

augmentation_cls = <class 'kornia.augmentation._2d.mix.mosaic.RandomMosaic'>, target = 'tensorflow', init_args = ((300, 300),), init_kwargs = {'data_keys': ['input', 'bbox_xyxy']}
call_args = (tensor([[[[-2.3226e-01,  1.8513e-01,  1.3636e+00,  ...,  2.8831e-01,
            2.3690e-01, -5.5250e-01],
          ...[ 70,   5, 150, 100],
         [ 60, 180, 175, 220]],

        [[ 70,   5, 150, 100],
         [ 60, 180, 175, 220]]]))
call_kwargs = {}, deterministic_output = False, backend_compile = False, tolerance = 0.001

    def _test_augmentation_class(
        augmentation_cls,
        target,
        init_args=(),
        init_kwargs={},
        call_args=(),
        call_kwargs={},
        deterministic_output=True,
        backend_compile=False,
        tolerance=1e-3,
    ):
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, target=target)
        transpiled_cls = eval("transpiled_" + f"{augmentation_cls.__module__}.{augmentation_cls.__name__}")
    
        torch_aug = augmentation_cls(*init_args, **init_kwargs)
        transpiled_init_args = _nest_torch_tensor_to_new_framework(init_args, target)
        transpiled_init_kwargs = _nest_torch_tensor_to_new_framework(init_kwargs, target)
        transpiled_aug = transpiled_cls(*transpiled_init_args, **transpiled_init_kwargs)
    
        # assert dir(torch_aug) == dir(transpiled_aug), f"attributes/methods of transpiled object do not align with the original - orig: {dir(torch_aug)} != transpiled: {dir(transpiled_aug)}"
    
        torch_out = torch_aug(*call_args, **call_kwargs)
        transpiled_call_args = _nest_torch_tensor_to_new_framework(call_args, target)
        transpiled_call_kwargs = _nest_torch_tensor_to_new_framework(call_kwargs, target)
>       transpiled_out = transpiled_aug(*transpiled_call_args, **transpiled_call_kwargs)

kornia/augmentation/test_augmentation4.py:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomMosaic(output_size=(300, 300), mosaic_grid=(2, 2), start_ratio_range=(0.3, 0.7), p=0.7, p_batch=1.0, ..._size=(300, 300), min_bbox_size=0.0, padding_mode=constant, resample=bilinear, align_corners=True, cropping_mode=slice)
args = (<tf.Tensor: shape=(8, 3, 224, 224), dtype=float32, numpy=
array([[[[-2.32255653e-01,  1.85131416e-01,  1.36359847e+00... [[ 70,   5, 150, 100],
        [ 60, 180, 175, 220]],

       [[ 70,   5, 150, 100],
        [ 60, 180, 175, 220]]])>)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x7f8051365e40, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...kexec', code_context=['        return self._inner_hookexec(hook_name, methods, kwargs, firstresult)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomMosaic(output_size=(300, 300), mosaic_grid=(2, 2), start_ratio_range=(0.3, 0.7), p=0.7, p_batch=1.0,... [[ 70,   5, 150, 100],
        [ 60, 180, 175, 220]],

       [[ 70,   5, 150, 100],
        [ 60, 180, 175, 220]]])>)
kwargs = {}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomMosaic(output_size=(300, 300), mosaic_grid=(2, 2), start_ratio_range=(0.3, 0.7), p=0.7, p_batch=1.0, ..._size=(300, 300), min_bbox_size=0.0, padding_mode=constant, resample=bilinear, align_corners=True, cropping_mode=slice)
v = None, buffers = None
args = (<tf.Tensor: shape=(8, 3, 224, 224), dtype=float32, numpy=
array([[[[-2.32255653e-01,  1.85131416e-01,  1.36359847e+00... [[ 70,   5, 150, 100],
        [ 60, 180, 175, 220]],

       [[ 70,   5, 150, 100],
        [ 60, 180, 175, 220]]])>)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomMosaic(output_size=(300, 300), mosaic_grid=(2, 2), start_ratio_range=(0.3, 0.7), p=0.7, p_batch=1.0,... [[ 70,   5, 150, 100],
        [ 60, 180, 175, 220]],

       [[ 70,   5, 150, 100],
        [ 60, 180, 175, 220]]])>)
kwargs = {'buffers': None, 'v': None}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomMosaic(output_size=(300, 300), mosaic_grid=(2, 2), start_ratio_range=(0.3, 0.7), p=0.7, p_batch=1.0, ..._size=(300, 300), min_bbox_size=0.0, padding_mode=constant, resample=bilinear, align_corners=True, cropping_mode=slice)
v = None, buffers = None
args = (<tf.Tensor: shape=(8, 3, 224, 224), dtype=float32, numpy=
array([[[[-2.32255653e-01,  1.85131416e-01,  1.36359847e+00... [[ 70,   5, 150, 100],
        [ 60, 180, 175, 220]],

       [[ 70,   5, 150, 100],
        [ 60, 180, 175, 220]]])>)
kwargs = {}
first_arr = <tf.Tensor: shape=(8, 3, 224, 224), dtype=float32, numpy=
array([[[[-2.32255653e-01,  1.85131416e-01,  1.36359847e+00,...82706e+00, -9.27120030e-01, ...,
           8.87718573e-02, -9.32777703e-01,  7.86986709e-01]]]],
      dtype=float32)>
replace_v = False, replace_buffers = False, call_signature = <Signature (*input, params=None, data_keys=None)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Layer, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Layer, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Layer, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomMosaic(output_size=(300, 300), mosaic_grid=(2, 2), start_ratio_range=(0.3, 0.7), p=0.7, p_batch=1.0,...ize=(300, 300), min_bbox_size=0.0, padding_mode=constant, resample=bilinear, align_corners=True, cropping_mode=slice),)
kwargs = {'input': <tf.Tensor: shape=(8, 3, 224, 224), dtype=float32, numpy=
array([[[[-2.32255653e-01,  1.85131416e-01,  1.363... [[ 70,   5, 150, 100],
        [ 60, 180, 175, 220]],

       [[ 70,   5, 150, 100],
        [ 60, 180, 175, 220]]])>}

    @wraps(fn)
    def error_handler(*args, **kwargs):
        if not is_traceback_filtering_enabled():
            return fn(*args, **kwargs)
    
        filtered_tb = None
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            filtered_tb = _process_traceback_frames(e.__traceback__)
            # To get the full stack trace, call:
            # `keras.config.disable_traceback_filtering()`
>           raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/keras/src/utils/traceback_utils.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <Signature (*input, params=None, data_keys=None)>, args = ()
kwargs = {'input': <tf.Tensor: shape=(8, 3, 224, 224), dtype=float32, numpy=
array([[[[-2.32255653e-01,  1.85131416e-01,  1.363...2706e+00, -9.27120030e-01, ...,
           8.87718573e-02, -9.32777703e-01,  7.86986709e-01]]]],
      dtype=float32)>}

    def bind(self, /, *args, **kwargs):
        """Get a BoundArguments object, that maps the passed `args`
        and `kwargs` to the function's signature.  Raises `TypeError`
        if the passed arguments can not be bound.
        """
>       return self._bind(args, kwargs)

/opt/miniconda/envs/multienv/lib/python3.10/inspect.py:3177: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <Signature (*input, params=None, data_keys=None)>, args = ()
kwargs = {'input': <tf.Tensor: shape=(8, 3, 224, 224), dtype=float32, numpy=
array([[[[-2.32255653e-01,  1.85131416e-01,  1.363...2706e+00, -9.27120030e-01, ...,
           8.87718573e-02, -9.32777703e-01,  7.86986709e-01]]]],
      dtype=float32)>}

    def _bind(self, args, kwargs, *, partial=False):
        """Private method. Don't use directly."""
    
        arguments = {}
    
        parameters = iter(self.parameters.values())
        parameters_ex = ()
        arg_vals = iter(args)
    
        while True:
            # Let's iterate through the positional arguments and corresponding
            # parameters
            try:
                arg_val = next(arg_vals)
            except StopIteration:
                # No more positional arguments
                try:
                    param = next(parameters)
                except StopIteration:
                    # No more parameters. That's it. Just need to check that
                    # we have no `kwargs` after this while loop
                    break
                else:
                    if param.kind == _VAR_POSITIONAL:
                        # That's OK, just empty *args.  Let's start parsing
                        # kwargs
                        break
                    elif param.name in kwargs:
                        if param.kind == _POSITIONAL_ONLY:
                            msg = '{arg!r} parameter is positional only, ' \
                                  'but was passed as a keyword'
                            msg = msg.format(arg=param.name)
                            raise TypeError(msg) from None
                        parameters_ex = (param,)
                        break
                    elif (param.kind == _VAR_KEYWORD or
                                                param.default is not _empty):
                        # That's fine too - we have a default value for this
                        # parameter.  So, lets start parsing `kwargs`, starting
                        # with the current parameter
                        parameters_ex = (param,)
                        break
                    else:
                        # No default, not VAR_KEYWORD, not VAR_POSITIONAL,
                        # not in `kwargs`
                        if partial:
                            parameters_ex = (param,)
                            break
                        else:
                            msg = 'missing a required argument: {arg!r}'
                            msg = msg.format(arg=param.name)
                            raise TypeError(msg) from None
            else:
                # We have a positional argument to process
                try:
                    param = next(parameters)
                except StopIteration:
                    raise TypeError('too many positional arguments') from None
                else:
                    if param.kind in (_VAR_KEYWORD, _KEYWORD_ONLY):
                        # Looks like we have no parameter for this positional
                        # argument
                        raise TypeError(
                            'too many positional arguments') from None
    
                    if param.kind == _VAR_POSITIONAL:
                        # We have an '*args'-like argument, let's fill it with
                        # all positional arguments we have left and move on to
                        # the next phase
                        values = [arg_val]
                        values.extend(arg_vals)
                        arguments[param.name] = tuple(values)
                        break
    
                    if param.name in kwargs and param.kind != _POSITIONAL_ONLY:
                        raise TypeError(
                            'multiple values for argument {arg!r}'.format(
                                arg=param.name)) from None
    
                    arguments[param.name] = arg_val
    
        # Now, we iterate through the remaining parameters to process
        # keyword arguments
        kwargs_param = None
        for param in itertools.chain(parameters_ex, parameters):
            if param.kind == _VAR_KEYWORD:
                # Memorize that we have a '**kwargs'-like parameter
                kwargs_param = param
                continue
    
            if param.kind == _VAR_POSITIONAL:
                # Named arguments don't refer to '*args'-like parameters.
                # We only arrive here if the positional arguments ended
                # before reaching the last parameter before *args.
                continue
    
            param_name = param.name
            try:
                arg_val = kwargs.pop(param_name)
            except KeyError:
                # We have no value for this parameter.  It's fine though,
                # if it has a default value, or it is an '*args'-like
                # parameter, left alone by the processing of positional
                # arguments.
                if (not partial and param.kind != _VAR_POSITIONAL and
                                                    param.default is _empty):
                    raise TypeError('missing a required argument: {arg!r}'. \
                                    format(arg=param_name)) from None
    
            else:
                if param.kind == _POSITIONAL_ONLY:
                    # This should never happen in case of a properly built
                    # Signature object (but let's have this check here
                    # to ensure correct behaviour just in case)
                    raise TypeError('{arg!r} parameter is positional only, '
                                    'but was passed as a keyword'. \
                                    format(arg=param.name))
    
                arguments[param_name] = arg_val
    
        if kwargs:
            if kwargs_param is not None:
                # Process our '**kwargs'-like parameter
                arguments[kwargs_param.name] = kwargs
            else:
>               raise TypeError(
                    'got an unexpected keyword argument {arg!r}'.format(
                        arg=next(iter(kwargs))))
E               TypeError: got an unexpected keyword argument 'input'

/opt/miniconda/envs/multienv/lib/python3.10/inspect.py:3166: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.RandomMosaic
___________________________________________________________________________ test_RandomTransplantation[tensorflow-s2s-False] ___________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_RandomTransplantation(target_framework, mode, backend_compile):
        print("kornia.augmentation.RandomTransplantation")
    
        init_args = ()
        init_kwargs = {"p": 1.}
        call_args = (torch.randn(2, 3, 5, 5), torch.randint(0, 3, (2, 5, 5)))
        call_kwargs = {}
    
>       _test_augmentation_class(
            kornia.augmentation.RandomTransplantation,
            target_framework,
            init_args,
            init_kwargs,
            call_args,
            call_kwargs,
            deterministic_output=False,
            backend_compile=backend_compile,
        )

kornia/augmentation/test_augmentation4.py:100: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

augmentation_cls = <class 'kornia.augmentation._2d.mix.transplantation.RandomTransplantation'>, target = 'tensorflow', init_args = (), init_kwargs = {'p': 1.0}
call_args = (tensor([[[[ 0.6602, -1.1159,  2.3276,  0.3691, -0.0110],
          [-0.5566,  1.4604,  0.2641, -1.4181, -1.0806],
   ...0, 0, 0, 2],
         [0, 0, 0, 0, 2],
         [0, 2, 1, 1, 1],
         [0, 0, 1, 1, 1],
         [0, 0, 1, 2, 1]]]))
call_kwargs = {}, deterministic_output = False, backend_compile = False, tolerance = 0.001

    def _test_augmentation_class(
        augmentation_cls,
        target,
        init_args=(),
        init_kwargs={},
        call_args=(),
        call_kwargs={},
        deterministic_output=True,
        backend_compile=False,
        tolerance=1e-3,
    ):
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, target=target)
        transpiled_cls = eval("transpiled_" + f"{augmentation_cls.__module__}.{augmentation_cls.__name__}")
    
        torch_aug = augmentation_cls(*init_args, **init_kwargs)
        transpiled_init_args = _nest_torch_tensor_to_new_framework(init_args, target)
        transpiled_init_kwargs = _nest_torch_tensor_to_new_framework(init_kwargs, target)
        transpiled_aug = transpiled_cls(*transpiled_init_args, **transpiled_init_kwargs)
    
        # assert dir(torch_aug) == dir(transpiled_aug), f"attributes/methods of transpiled object do not align with the original - orig: {dir(torch_aug)} != transpiled: {dir(transpiled_aug)}"
    
        torch_out = torch_aug(*call_args, **call_kwargs)
        transpiled_call_args = _nest_torch_tensor_to_new_framework(call_args, target)
        transpiled_call_kwargs = _nest_torch_tensor_to_new_framework(call_kwargs, target)
>       transpiled_out = transpiled_aug(*transpiled_call_args, **transpiled_call_kwargs)

kornia/augmentation/test_augmentation4.py:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomTransplantation(p=1.0, p_batch=1.0, same_on_batch=False)
args = (<tf.Tensor: shape=(2, 3, 5, 5), dtype=float32, numpy=
array([[[[ 0.66019213, -1.1158669 ,  2.3276002 ,  0.36913103,
 ...0, 0, 0, 0, 2],
        [0, 0, 0, 0, 2],
        [0, 2, 1, 1, 1],
        [0, 0, 1, 1, 1],
        [0, 0, 1, 2, 1]]])>)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x7f8051da4e40, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...kexec', code_context=['        return self._inner_hookexec(hook_name, methods, kwargs, firstresult)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomTransplantation(p=1.0, p_batch=1.0, same_on_batch=False), <tf.Tensor: shape=(2, 3, 5, 5), dtype=floa...0, 0, 0, 0, 2],
        [0, 0, 0, 0, 2],
        [0, 2, 1, 1, 1],
        [0, 0, 1, 1, 1],
        [0, 0, 1, 2, 1]]])>)
kwargs = {}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomTransplantation(p=1.0, p_batch=1.0, same_on_batch=False), v = None, buffers = None
args = (<tf.Tensor: shape=(2, 3, 5, 5), dtype=float32, numpy=
array([[[[ 0.66019213, -1.1158669 ,  2.3276002 ,  0.36913103,
 ...0, 0, 0, 0, 2],
        [0, 0, 0, 0, 2],
        [0, 2, 1, 1, 1],
        [0, 0, 1, 1, 1],
        [0, 0, 1, 2, 1]]])>)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomTransplantation(p=1.0, p_batch=1.0, same_on_batch=False), <tf.Tensor: shape=(2, 3, 5, 5), dtype=floa...0, 0, 0, 0, 2],
        [0, 0, 0, 0, 2],
        [0, 2, 1, 1, 1],
        [0, 0, 1, 1, 1],
        [0, 0, 1, 2, 1]]])>)
kwargs = {'buffers': None, 'v': None}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomTransplantation(p=1.0, p_batch=1.0, same_on_batch=False), v = None, buffers = None
args = (<tf.Tensor: shape=(2, 3, 5, 5), dtype=float32, numpy=
array([[[[ 0.66019213, -1.1158669 ,  2.3276002 ,  0.36913103,
 ...0, 0, 0, 0, 2],
        [0, 0, 0, 0, 2],
        [0, 2, 1, 1, 1],
        [0, 0, 1, 1, 1],
        [0, 0, 1, 2, 1]]])>)
kwargs = {}
first_arr = <tf.Tensor: shape=(2, 3, 5, 5), dtype=float32, numpy=
array([[[[ 0.66019213, -1.1158669 ,  2.3276002 ,  0.36913103,
  ... -0.21678534],
         [-0.547842  , -1.1008651 , -1.8437806 ,  1.177749  ,
          -0.55137795]]]], dtype=float32)>
replace_v = False, replace_buffers = False, call_signature = <Signature (*input, params=None, data_keys=None, **kwargs)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Layer, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Layer, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Layer, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomTransplantation(p=1.0, p_batch=1.0, same_on_batch=False),)
kwargs = {'input': <tf.Tensor: shape=(2, 3, 5, 5), dtype=float32, numpy=
array([[[[ 0.66019213, -1.1158669 ,  2.3276002 ,  0.36...0, 0, 0, 0, 2],
        [0, 0, 0, 0, 2],
        [0, 2, 1, 1, 1],
        [0, 0, 1, 1, 1],
        [0, 0, 1, 2, 1]]])>}

    @wraps(fn)
    def error_handler(*args, **kwargs):
        if not is_traceback_filtering_enabled():
            return fn(*args, **kwargs)
    
        filtered_tb = None
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            filtered_tb = _process_traceback_frames(e.__traceback__)
            # To get the full stack trace, call:
            # `keras.config.disable_traceback_filtering()`
>           raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/keras/src/utils/traceback_utils.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomTransplantation(p=1.0, p_batch=1.0, same_on_batch=False)
params = <tf.Tensor: shape=(2, 5, 5), dtype=int64, numpy=
array([[[0, 2, 0, 1, 0],
        [1, 0, 1, 2, 2],
        [2, 0, 0, 1...[0, 0, 0, 0, 2],
        [0, 0, 0, 0, 2],
        [0, 2, 1, 1, 1],
        [0, 0, 1, 1, 1],
        [0, 0, 1, 2, 1]]])>
data_keys = None, input = ()
kwargs = {'input': <tf.Tensor: shape=(2, 3, 5, 5), dtype=float32, numpy=
array([[[[ 0.66019213, -1.1158669 ,  2.3276002 ,  0.36...-0.21678534],
         [-0.547842  , -1.1008651 , -1.8437806 ,  1.177749  ,
          -0.55137795]]]], dtype=float32)>}
tensorflow_get_item = <function tensorflow_get_item at 0x7f804b778040>, tensorflow_shape_frnt_ = <function tensorflow_shape_frnt_ at 0x7f805112a4d0>
tensorflow_clone_frnt_ = <function tensorflow_clone_frnt_ at 0x7f8050d2ff40>, tensorflow__validate_input_dtype = <function tensorflow__validate_input_dtype at 0x7f804b7df010>
tensorflow_index_put_frnt_ = <function tensorflow_index_put_frnt_ at 0x7f80513e2f80>, keys = [<tensorflow_DataKey.IMAGE: 0>, <tensorflow_DataKey.MASK: 1>]

    def call(self, *input, params=None, data_keys=None, **kwargs):
        from ....constants import tensorflow_DataKey
        from .....ivy.functional.backends.tensorflow.general import tensorflow_get_item
        from .....ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from .....ivy.functional.frontends.torch.tensor import tensorflow_clone_frnt_
        from ...utils.helpers import tensorflow__validate_input_dtype
        from .....ivy.functional.frontends.torch.tensor import (
            tensorflow_index_put_frnt_,
        )
    
        keys: typing.Any
        if data_keys is None:
            keys = self.data_keys
        else:
            keys = [tensorflow_DataKey.get(inp) for inp in data_keys]
        if params is None:
            mask: typing.Any = tensorflow_get_item(
                input, keys.index(tensorflow_DataKey.MASK)
            )
            self._params = self.forward_parameters(tensorflow_shape_frnt_(mask))
        else:
            self._params = params
>       if any(
            k not in self._params
            for k in ["acceptor_indices", "donor_indices", "selection"]
        ):

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/_2d/mix/transplantation.py:246: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

.0 = <tuple_iterator object at 0x7f804b78add0>

    if any(
>       k not in self._params
        for k in ["acceptor_indices", "donor_indices", "selection"]
    ):

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/_2d/mix/transplantation.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <tf.Tensor: shape=(5, 5), dtype=int64, numpy=
array([[0, 2, 0, 1, 0],
       [1, 0, 1, 2, 2],
       [2, 0, 0, 1, 0],
       [0, 0, 0, 2, 0],
       [0, 2, 2, 1, 0]])>, rhs = 'acceptor_indices'

    def impl(self, rhs):
        try:
            res = original_method(self, rhs)
            if isinstance(rhs, (list, tuple)):
                return False if orig_method_name == "__eq__" else True
            return res
        except Exception:
>           return patched_method(self, rhs)

ivy_transpiled_outputs/tensorflow_outputs/__init__.py:58: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = <tf.Tensor: shape=(5, 5), dtype=int64, numpy=
array([[0, 2, 0, 1, 0],
       [1, 0, 1, 2, 2],
       [2, 0, 0, 1, 0],
       [0, 0, 0, 2, 0],
       [0, 2, 2, 1, 0]])>
other = 'acceptor_indices'

    def tensorflow___eq___frnt_(tensor, other):
        from .comparison_ops import tensorflow_eq_frnt
    
        if isinstance(other, (list, tuple)):
            return False
>       return tensorflow_eq_frnt(tensor, other)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/tensor.py:125: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = <tf.Tensor: shape=(5, 5), dtype=int64, numpy=
array([[0, 2, 0, 1, 0],
       [1, 0, 1, 2, 2],
       [2, 0, 0, 1, 0],
       [0, 0, 0, 2, 0],
       [0, 2, 2, 1, 0]])>
other = 'acceptor_indices'

    def tensorflow_eq_frnt(input, other, *, out=None):
        from .__init__ import tensorflow_promote_types_of_torch_inputs_frnt
        from ...backends.tensorflow.elementwise import tensorflow_equal
    
>       input, other = tensorflow_promote_types_of_torch_inputs_frnt(input, other)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/comparison_ops.py:110: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x1 = <tf.Tensor: shape=(5, 5), dtype=int64, numpy=
array([[0, 2, 0, 1, 0],
       [1, 0, 1, 2, 2],
       [2, 0, 0, 1, 0],
       [0, 0, 0, 2, 0],
       [0, 2, 2, 1, 0]])>, x2 = 'acceptor_indices'

    def tensorflow_promote_types_of_torch_inputs_frnt(x1, x2, /):
        from ...ivy.general import tensorflow_isscalar_bknd
        from ...ivy.data_type import tensorflow_is_int_dtype_bknd
        from ...backends.tensorflow.creation import tensorflow_asarray
        from ...ivy.data_type import tensorflow_default_dtype_bknd
        from .tensor import tensorflow_shape_frnt_
        from ...ivy.device import tensorflow_default_device_bknd
        from ....data_classes.array.data_type import tensorflow_astype_bknd_
    
        """Promote the dtype of the given native array inputs to a common dtype
        based on type promotion rules.
    
        While passing float or integer values or any other non-array input
        to this function, it should be noted that the return will be an
        array-like object. Therefore, outputs from this function should be
        used as inputs only for those functions that expect an array-like or
        tensor-like objects, otherwise it might give unexpected results.
        """
        if (
            tensorflow_isscalar_bknd(x1) or isinstance(x1, (list, tuple))
        ) and tensorflow_is_int_dtype_bknd(x1):
            x1 = tensorflow_asarray(x1, dtype="int64")
        elif tensorflow_isscalar_bknd(x1) or isinstance(x1, (list, tuple)):
            x1 = tensorflow_asarray(x1)
        if (
            tensorflow_isscalar_bknd(x2) or isinstance(x2, (list, tuple))
>       ) and tensorflow_is_int_dtype_bknd(x2):

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/__init__.py:222: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = 'acceptor_indices'

    def tensorflow_is_int_dtype_bknd(
        dtype_in: Union[str, str, tensorflow.Tensor, tf.Tensor, Number], /
    ):
        from .general import tensorflow_is_array_bknd
        from ..backends.tensorflow.data_type import tensorflow_dtype
        from .nest import tensorflow_nested_argwhere_bknd
        from ..backends.tensorflow.data_type import tensorflow_as_ivy_dtype
    
        if tensorflow_is_array_bknd(dtype_in):
            dtype_in = tensorflow_dtype(dtype_in)
        elif isinstance(dtype_in, tuple):
            dtype_in = tensorflow_default_int_dtype_bknd()
        elif isinstance(dtype_in, np.ndarray):
            return "int" in dtype_in.dtype.name
        elif isinstance(dtype_in, Number):
            return isinstance(dtype_in, (int, np.integer)) and not isinstance(
                dtype_in, bool
            )
        elif isinstance(dtype_in, (list, tuple, dict)):
    
            def nested_fun(x):
                from .general import tensorflow_is_array_bknd
                from ..backends.tensorflow.data_type import tensorflow_dtype
    
                return (
                    isinstance(x, (int, np.integer))
                    or tensorflow_is_array_bknd(x)
                    and "int" in tensorflow_dtype(x)
                ) and x is not bool
    
            return bool(tensorflow_nested_argwhere_bknd(dtype_in, nested_fun))
>       return "int" in tensorflow_as_ivy_dtype(dtype_in)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:485: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = 'acceptor_indices'

    def tensorflow_as_ivy_dtype(
        dtype_in: Union[tensorflow.DType, str, int, float, complex, bool, np.dtype], /
    ):
        from ...ivy.data_type import tensorflow_default_int_dtype_bknd
        from ...ivy.data_type import tensorflow_default_float_dtype_bknd
        from ...ivy.data_type import tensorflow_default_complex_dtype_bknd
    
        if dtype_in is int:
            return tensorflow_default_int_dtype_bknd()
        if dtype_in is float:
            return tensorflow_default_float_dtype_bknd()
        if dtype_in is complex:
            return tensorflow_default_complex_dtype_bknd()
        if dtype_in is bool:
            return str("bool")
        if isinstance(dtype_in, np.dtype):
            dtype_in = dtype_in.name
        if isinstance(dtype_in, str):
            if dtype_in in native_dtype_dict:
                dtype_str = dtype_in
            else:
>               raise Exception(
                    f"Cannot convert to ivy dtype. {dtype_in} is not supported by TensorFlow backend."
                )
E               Exception: Exception encountered when calling tensorflow_RandomTransplantation.call().
E               
E               [1mCannot convert to ivy dtype. acceptor_indices is not supported by TensorFlow backend.[0m
E               
E               Arguments received by tensorflow_RandomTransplantation.call():
E                 • input=<class 'inspect._empty'>
E                 • params=tf.Tensor(shape=(2, 5, 5), dtype=int64)
E                 • data_keys=None
E                 • kwargs={'input': 'tf.Tensor(shape=(2, 3, 5, 5), dtype=float32)'}

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/backends/tensorflow/data_type.py:204: Exception
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.RandomTransplantation
_____________________________________________________________________________ test_RandomRotation3D[tensorflow-s2s-False] ______________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_RandomRotation3D(target_framework, mode, backend_compile):
        print("kornia.augmentation.RandomRotation3D")
    
        init_args = ((15., 20., 20.),)
        init_kwargs = {"p": 1.}
        call_args = (torch.rand(1, 1, 3, 3, 3),)
        call_kwargs = {}
    
>       _test_augmentation_class(
            kornia.augmentation.RandomRotation3D,
            target_framework,
            init_args,
            init_kwargs,
            call_args,
            call_kwargs,
            deterministic_output=False,
            backend_compile=backend_compile,
        )

kornia/augmentation/test_augmentation4.py:220: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

augmentation_cls = <class 'kornia.augmentation._3d.geometric.rotation.RandomRotation3D'>, target = 'tensorflow', init_args = ((15.0, 20.0, 20.0),), init_kwargs = {'p': 1.0}
call_args = (tensor([[[[[0.8809, 0.2397, 0.0348],
           [0.1598, 0.1398, 0.8034],
           [0.8445, 0.9224, 0.7384]],

    ...,

          [[0.7429, 0.1079, 0.8076],
           [0.3080, 0.4505, 0.2538],
           [0.7305, 0.5889, 0.2915]]]]]),)
call_kwargs = {}, deterministic_output = False, backend_compile = False, tolerance = 0.001

    def _test_augmentation_class(
        augmentation_cls,
        target,
        init_args=(),
        init_kwargs={},
        call_args=(),
        call_kwargs={},
        deterministic_output=True,
        backend_compile=False,
        tolerance=1e-3,
    ):
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, target=target)
        transpiled_cls = eval("transpiled_" + f"{augmentation_cls.__module__}.{augmentation_cls.__name__}")
    
        torch_aug = augmentation_cls(*init_args, **init_kwargs)
        transpiled_init_args = _nest_torch_tensor_to_new_framework(init_args, target)
        transpiled_init_kwargs = _nest_torch_tensor_to_new_framework(init_kwargs, target)
        transpiled_aug = transpiled_cls(*transpiled_init_args, **transpiled_init_kwargs)
    
        # assert dir(torch_aug) == dir(transpiled_aug), f"attributes/methods of transpiled object do not align with the original - orig: {dir(torch_aug)} != transpiled: {dir(transpiled_aug)}"
    
        torch_out = torch_aug(*call_args, **call_kwargs)
        transpiled_call_args = _nest_torch_tensor_to_new_framework(call_args, target)
        transpiled_call_kwargs = _nest_torch_tensor_to_new_framework(call_kwargs, target)
>       transpiled_out = transpiled_aug(*transpiled_call_args, **transpiled_call_kwargs)

kornia/augmentation/test_augmentation4.py:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomRotation3D(degrees=(15.0, 20.0, 20.0), p=1.0, p_batch=1.0, same_on_batch=False, resample=bilinear, align_corners=False)
args = (<tf.Tensor: shape=(1, 1, 3, 3, 3), dtype=float32, numpy=
array([[[[[0.88086283, 0.23973411, 0.03482264],
          [0...,
          [0.30797094, 0.45054793, 0.2537784 ],
          [0.73045194, 0.5889455 , 0.2914725 ]]]]], dtype=float32)>,)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x7f804b03c440, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...kexec', code_context=['        return self._inner_hookexec(hook_name, methods, kwargs, firstresult)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomRotation3D(degrees=(15.0, 20.0, 20.0), p=1.0, p_batch=1.0, same_on_batch=False, resample=bilinear, a...],
          [0.30797094, 0.45054793, 0.2537784 ],
          [0.73045194, 0.5889455 , 0.2914725 ]]]]], dtype=float32)>)
kwargs = {}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomRotation3D(degrees=(15.0, 20.0, 20.0), p=1.0, p_batch=1.0, same_on_batch=False, resample=bilinear, align_corners=False), v = None, buffers = None
args = (<tf.Tensor: shape=(1, 1, 3, 3, 3), dtype=float32, numpy=
array([[[[[0.88086283, 0.23973411, 0.03482264],
          [0...,
          [0.30797094, 0.45054793, 0.2537784 ],
          [0.73045194, 0.5889455 , 0.2914725 ]]]]], dtype=float32)>,)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomRotation3D(degrees=(15.0, 20.0, 20.0), p=1.0, p_batch=1.0, same_on_batch=False, resample=bilinear, a...],
          [0.30797094, 0.45054793, 0.2537784 ],
          [0.73045194, 0.5889455 , 0.2914725 ]]]]], dtype=float32)>)
kwargs = {'buffers': None, 'v': None}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomRotation3D(degrees=(15.0, 20.0, 20.0), p=1.0, p_batch=1.0, same_on_batch=False, resample=bilinear, align_corners=False), v = None, buffers = None
args = (<tf.Tensor: shape=(1, 1, 3, 3, 3), dtype=float32, numpy=
array([[[[[0.88086283, 0.23973411, 0.03482264],
          [0...,
          [0.30797094, 0.45054793, 0.2537784 ],
          [0.73045194, 0.5889455 , 0.2914725 ]]]]], dtype=float32)>,)
kwargs = {}
first_arr = <tf.Tensor: shape=(1, 1, 3, 3, 3), dtype=float32, numpy=
array([[[[[0.88086283, 0.23973411, 0.03482264],
          [0.... ],
          [0.30797094, 0.45054793, 0.2537784 ],
          [0.73045194, 0.5889455 , 0.2914725 ]]]]], dtype=float32)>
replace_v = False, replace_buffers = False, call_signature = <Signature (input, params=None, **kwargs)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Layer, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Layer, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Layer, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomRotation3D(degrees=(15.0, 20.0, 20.0), p=1.0, p_batch=1.0, same_on_batch=False, resample=bilinear, align_corners=False),)
kwargs = {'input': <tf.Tensor: shape=(1, 1, 3, 3, 3), dtype=float32, numpy=
array([[[[[0.88086283, 0.23973411, 0.03482264],
   ...],
          [0.30797094, 0.45054793, 0.2537784 ],
          [0.73045194, 0.5889455 , 0.2914725 ]]]]], dtype=float32)>}

    @wraps(fn)
    def error_handler(*args, **kwargs):
        if not is_traceback_filtering_enabled():
            return fn(*args, **kwargs)
    
        filtered_tb = None
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            filtered_tb = _process_traceback_frames(e.__traceback__)
            # To get the full stack trace, call:
            # `keras.config.disable_traceback_filtering()`
>           raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/keras/src/utils/traceback_utils.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomRotation3D(degrees=(15.0, 20.0, 20.0), p=1.0, p_batch=1.0, same_on_batch=False, resample=bilinear, align_corners=False)
input = <tf.Tensor: shape=(1, 1, 3, 3, 3), dtype=float32, numpy=
array([[[[[0.88086283, 0.23973411, 0.03482264],
          [0.... ],
          [0.30797094, 0.45054793, 0.2537784 ],
          [0.73045194, 0.5889455 , 0.2914725 ]]]]], dtype=float32)>
params = {'batch_prob': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>, 'forward_input_shape': <tf.Te...070038], dtype=float32)>, 'roll': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.2736034], dtype=float32)>, ...}
kwargs = {}, tensorflow_shape_frnt_ = <function tensorflow_shape_frnt_ at 0x7f8056fb2b00>, tensorflow_set_item = <function tensorflow_set_item at 0x7f804adc4310>
tensor = <function tensorflow_tensor_frnt at 0x7f804b73a4d0>
in_tensor = <tf.Tensor: shape=(1, 1, 3, 3, 3), dtype=float32, numpy=
array([[[[[0.88086283, 0.23973411, 0.03482264],
          [0.... ],
          [0.30797094, 0.45054793, 0.2537784 ],
          [0.73045194, 0.5889455 , 0.2914725 ]]]]], dtype=float32)>
input_shape = ivy.frontends.torch.Size([1, 1, 3, 3, 3]), batch_shape = ivy.frontends.torch.Size([1, 1, 3, 3, 3]), flags = {'align_corners': False, 'resample': <tensorflow_Resample.BILINEAR: 1>}

    def call(self, input, params=None, **kwargs):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ...ivy.functional.backends.tensorflow.general import tensorflow_set_item
        from ..core._backend import tensor
    
        in_tensor = self.__unpack_input__(input)
        input_shape = tensorflow_shape_frnt_(in_tensor)
        in_tensor = self.transform_tensor(in_tensor)
        batch_shape = tensorflow_shape_frnt_(in_tensor)
        if params is None:
            params = self.forward_parameters(batch_shape)
        if "batch_prob" not in params:
            params = tensorflow_set_item(
                params, "batch_prob", tensor([True] * batch_shape[0])
            )
        params, flags = self._process_kwargs_to_params_and_flags(
            params, self.flags, **kwargs
        )
>       output = self.apply_func(in_tensor, params, flags)

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/base.py:236: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomRotation3D(degrees=(15.0, 20.0, 20.0), p=1.0, p_batch=1.0, same_on_batch=False, resample=bilinear, align_corners=False)
in_tensor = <tf.Tensor: shape=(1, 1, 3, 3, 3), dtype=float32, numpy=
array([[[[[0.88086283, 0.23973411, 0.03482264],
          [0.... ],
          [0.30797094, 0.45054793, 0.2537784 ],
          [0.73045194, 0.5889455 , 0.2914725 ]]]]], dtype=float32)>
params = {'batch_prob': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>, 'forward_input_shape': <tf.Te...070038], dtype=float32)>, 'roll': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.2736034], dtype=float32)>, ...}
flags = {'align_corners': False, 'resample': <tensorflow_Resample.BILINEAR: 1>}

    def apply_func(self, in_tensor, params, flags=None):
        if flags is None:
            flags = self.flags
>       trans_matrix = self.generate_transformation_matrix(in_tensor, params, flags)

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/_3d/base.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomRotation3D(degrees=(15.0, 20.0, 20.0), p=1.0, p_batch=1.0, same_on_batch=False, resample=bilinear, align_corners=False)
input = <tf.Tensor: shape=(1, 1, 3, 3, 3), dtype=float32, numpy=
array([[[[[0.88086283, 0.23973411, 0.03482264],
          [0.... ],
          [0.30797094, 0.45054793, 0.2537784 ],
          [0.73045194, 0.5889455 , 0.2914725 ]]]]], dtype=float32)>
params = {'batch_prob': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>, 'forward_input_shape': <tf.Te...070038], dtype=float32)>, 'roll': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.2736034], dtype=float32)>, ...}
flags = {'align_corners': False, 'resample': <tensorflow_Resample.BILINEAR: 1>}

    def generate_transformation_matrix(self, input, params, flags):
        from ....ivy.functional.frontends.torch.tensor import tensorflow_any_frnt_
        from ....ivy.functional.frontends.torch.tensor import tensorflow_all_frnt_
        from ....ivy.functional.frontends.torch.tensor import tensorflow_index_put_frnt_
        from ....ivy.functional.backends.tensorflow.general import tensorflow_get_item
    
        batch_prob = params["batch_prob"]
        to_apply = batch_prob > 0.5
        in_tensor = self.transform_tensor(input)
        if not tensorflow_any_frnt_(to_apply):
            trans_matrix = self.identity_matrix(in_tensor)
        elif tensorflow_all_frnt_(to_apply):
>           trans_matrix = self.compute_transformation(
                in_tensor, params=params, flags=flags
            )

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/_3d/base.py:90: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomRotation3D(degrees=(15.0, 20.0, 20.0), p=1.0, p_batch=1.0, same_on_batch=False, resample=bilinear, align_corners=False)
input = <tf.Tensor: shape=(1, 1, 3, 3, 3), dtype=float32, numpy=
array([[[[[0.88086283, 0.23973411, 0.03482264],
          [0.... ],
          [0.30797094, 0.45054793, 0.2537784 ],
          [0.73045194, 0.5889455 , 0.2914725 ]]]]], dtype=float32)>
params = {'batch_prob': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>, 'forward_input_shape': <tf.Te...070038], dtype=float32)>, 'roll': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.2736034], dtype=float32)>, ...}
flags = {'align_corners': False, 'resample': <tensorflow_Resample.BILINEAR: 1>}

    def compute_transformation(self, input, params, flags):
        from .....ivy.functional.frontends.torch.tensor import tensorflow_to_frnt_
        from ....geometry.transform.affwarp import tensorflow__compute_tensor_center3d
        from ....geometry.transform.affwarp import tensorflow__compute_rotation_matrix3d
        from .....ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ....utils.misc import tensorflow_eye_like
        from .....ivy.functional.backends.tensorflow.general import tensorflow_set_item
    
        yaw: typing.Any = tensorflow_to_frnt_(params["yaw"], input)
        pitch: typing.Any = tensorflow_to_frnt_(params["pitch"], input)
        roll: typing.Any = tensorflow_to_frnt_(params["roll"], input)
        center: typing.Any = tensorflow__compute_tensor_center3d(input)
        rotation_mat: typing.Any = tensorflow__compute_rotation_matrix3d(
>           yaw, pitch, roll, center.expand(tensorflow_shape_frnt_(yaw)[0], -1)
        )
E       AttributeError: Exception encountered when calling tensorflow_RandomRotation3D.call().
E       
E       [1m'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'expand'[0m
E       
E       Arguments received by tensorflow_RandomRotation3D.call():
E         • input=tf.Tensor(shape=(1, 1, 3, 3, 3), dtype=float32)
E         • params=None
E         • kwargs=<class 'inspect._empty'>

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/_3d/geometric/rotation.py:68: AttributeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.RandomRotation3D
__________________________________________________________________________ test_RandomTransplantation3D[tensorflow-s2s-False] __________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_RandomTransplantation3D(target_framework, mode, backend_compile):
        print("kornia.augmentation.RandomTransplantation3D")
    
        init_args = ()
        init_kwargs = {"p": 1.}
        call_args = (torch.randn(2, 3, 5, 5), torch.randint(0, 3, (2, 5, 5)))
        call_kwargs = {}
    
>       _test_augmentation_class(
            kornia.augmentation.RandomTransplantation3D,
            target_framework,
            init_args,
            init_kwargs,
            call_args,
            call_kwargs,
            deterministic_output=False,
            backend_compile=backend_compile,
        )

kornia/augmentation/test_augmentation4.py:300: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

augmentation_cls = <class 'kornia.augmentation._3d.mix.transplantation.RandomTransplantation3D'>, target = 'tensorflow', init_args = (), init_kwargs = {'p': 1.0}
call_args = (tensor([[[[-1.9237e-01,  8.1444e-01, -7.5099e-01,  1.2311e+00,  1.3862e+00],
          [-1.3203e+00, -5.6711e-01,  6....0, 1, 0, 2],
         [2, 2, 0, 0, 1],
         [2, 2, 1, 2, 0],
         [1, 1, 2, 2, 1],
         [0, 0, 0, 0, 0]]]))
call_kwargs = {}, deterministic_output = False, backend_compile = False, tolerance = 0.001

    def _test_augmentation_class(
        augmentation_cls,
        target,
        init_args=(),
        init_kwargs={},
        call_args=(),
        call_kwargs={},
        deterministic_output=True,
        backend_compile=False,
        tolerance=1e-3,
    ):
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, target=target)
        transpiled_cls = eval("transpiled_" + f"{augmentation_cls.__module__}.{augmentation_cls.__name__}")
    
        torch_aug = augmentation_cls(*init_args, **init_kwargs)
        transpiled_init_args = _nest_torch_tensor_to_new_framework(init_args, target)
        transpiled_init_kwargs = _nest_torch_tensor_to_new_framework(init_kwargs, target)
        transpiled_aug = transpiled_cls(*transpiled_init_args, **transpiled_init_kwargs)
    
        # assert dir(torch_aug) == dir(transpiled_aug), f"attributes/methods of transpiled object do not align with the original - orig: {dir(torch_aug)} != transpiled: {dir(transpiled_aug)}"
    
        torch_out = torch_aug(*call_args, **call_kwargs)
        transpiled_call_args = _nest_torch_tensor_to_new_framework(call_args, target)
        transpiled_call_kwargs = _nest_torch_tensor_to_new_framework(call_kwargs, target)
>       transpiled_out = transpiled_aug(*transpiled_call_args, **transpiled_call_kwargs)

kornia/augmentation/test_augmentation4.py:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomTransplantation3D(p=1.0, p_batch=1.0, same_on_batch=False)
args = (<tf.Tensor: shape=(2, 3, 5, 5), dtype=float32, numpy=
array([[[[-1.92366168e-01,  8.14442217e-01, -7.50994682e-01,
  ...1, 0, 1, 0, 2],
        [2, 2, 0, 0, 1],
        [2, 2, 1, 2, 0],
        [1, 1, 2, 2, 1],
        [0, 0, 0, 0, 0]]])>)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x7f8051ece040, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...kexec', code_context=['        return self._inner_hookexec(hook_name, methods, kwargs, firstresult)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomTransplantation3D(p=1.0, p_batch=1.0, same_on_batch=False), <tf.Tensor: shape=(2, 3, 5, 5), dtype=fl...1, 0, 1, 0, 2],
        [2, 2, 0, 0, 1],
        [2, 2, 1, 2, 0],
        [1, 1, 2, 2, 1],
        [0, 0, 0, 0, 0]]])>)
kwargs = {}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomTransplantation3D(p=1.0, p_batch=1.0, same_on_batch=False), v = None, buffers = None
args = (<tf.Tensor: shape=(2, 3, 5, 5), dtype=float32, numpy=
array([[[[-1.92366168e-01,  8.14442217e-01, -7.50994682e-01,
  ...1, 0, 1, 0, 2],
        [2, 2, 0, 0, 1],
        [2, 2, 1, 2, 0],
        [1, 1, 2, 2, 1],
        [0, 0, 0, 0, 0]]])>)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomTransplantation3D(p=1.0, p_batch=1.0, same_on_batch=False), <tf.Tensor: shape=(2, 3, 5, 5), dtype=fl...1, 0, 1, 0, 2],
        [2, 2, 0, 0, 1],
        [2, 2, 1, 2, 0],
        [1, 1, 2, 2, 1],
        [0, 0, 0, 0, 0]]])>)
kwargs = {'buffers': None, 'v': None}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomTransplantation3D(p=1.0, p_batch=1.0, same_on_batch=False), v = None, buffers = None
args = (<tf.Tensor: shape=(2, 3, 5, 5), dtype=float32, numpy=
array([[[[-1.92366168e-01,  8.14442217e-01, -7.50994682e-01,
  ...1, 0, 1, 0, 2],
        [2, 2, 0, 0, 1],
        [2, 2, 1, 2, 0],
        [1, 1, 2, 2, 1],
        [0, 0, 0, 0, 0]]])>)
kwargs = {}
first_arr = <tf.Tensor: shape=(2, 3, 5, 5), dtype=float32, numpy=
array([[[[-1.92366168e-01,  8.14442217e-01, -7.50994682e-01,
   ...    [-2.71075815e-01,  8.65778446e-01, -9.05304432e-01,
          -1.44943333e+00, -2.16450214e-01]]]], dtype=float32)>
replace_v = False, replace_buffers = False, call_signature = <Signature (*input, params=None, data_keys=None, **kwargs)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Layer, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Layer, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Layer, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomTransplantation3D(p=1.0, p_batch=1.0, same_on_batch=False),)
kwargs = {'input': <tf.Tensor: shape=(2, 3, 5, 5), dtype=float32, numpy=
array([[[[-1.92366168e-01,  8.14442217e-01, -7.5099468...1, 0, 1, 0, 2],
        [2, 2, 0, 0, 1],
        [2, 2, 1, 2, 0],
        [1, 1, 2, 2, 1],
        [0, 0, 0, 0, 0]]])>}

    @wraps(fn)
    def error_handler(*args, **kwargs):
        if not is_traceback_filtering_enabled():
            return fn(*args, **kwargs)
    
        filtered_tb = None
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            filtered_tb = _process_traceback_frames(e.__traceback__)
            # To get the full stack trace, call:
            # `keras.config.disable_traceback_filtering()`
>           raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/keras/src/utils/traceback_utils.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomTransplantation3D(p=1.0, p_batch=1.0, same_on_batch=False)
params = <tf.Tensor: shape=(2, 5, 5), dtype=int64, numpy=
array([[[2, 0, 0, 0, 0],
        [2, 0, 2, 0, 1],
        [2, 1, 1, 1...[1, 0, 1, 0, 2],
        [2, 2, 0, 0, 1],
        [2, 2, 1, 2, 0],
        [1, 1, 2, 2, 1],
        [0, 0, 0, 0, 0]]])>
data_keys = None, input = ()
kwargs = {'input': <tf.Tensor: shape=(2, 3, 5, 5), dtype=float32, numpy=
array([[[[-1.92366168e-01,  8.14442217e-01, -7.5099468...   [-2.71075815e-01,  8.65778446e-01, -9.05304432e-01,
          -1.44943333e+00, -2.16450214e-01]]]], dtype=float32)>}
tensorflow_get_item = <function tensorflow_get_item at 0x7f804a532050>, tensorflow_shape_frnt_ = <function tensorflow_shape_frnt_ at 0x7f8040d801f0>
tensorflow_clone_frnt_ = <function tensorflow_clone_frnt_ at 0x7f8040b2ef80>, tensorflow__validate_input_dtype = <function tensorflow__validate_input_dtype at 0x7f804abdeb90>
tensorflow_index_put_frnt_ = <function tensorflow_index_put_frnt_ at 0x7f8040b2f490>, keys = [<tensorflow_DataKey.IMAGE: 0>, <tensorflow_DataKey.MASK: 1>]

    def call(self, *input, params=None, data_keys=None, **kwargs):
        from ....constants import tensorflow_DataKey
        from .....ivy.functional.backends.tensorflow.general import tensorflow_get_item
        from .....ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from .....ivy.functional.frontends.torch.tensor import tensorflow_clone_frnt_
        from ...utils.helpers import tensorflow__validate_input_dtype
        from .....ivy.functional.frontends.torch.tensor import (
            tensorflow_index_put_frnt_,
        )
    
        keys: typing.Any
        if data_keys is None:
            keys = self.data_keys
        else:
            keys = [tensorflow_DataKey.get(inp) for inp in data_keys]
        if params is None:
            mask: typing.Any = tensorflow_get_item(
                input, keys.index(tensorflow_DataKey.MASK)
            )
            self._params = self.forward_parameters(tensorflow_shape_frnt_(mask))
        else:
            self._params = params
>       if any(
            k not in self._params
            for k in ["acceptor_indices", "donor_indices", "selection"]
        ):

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/_2d/mix/transplantation.py:248: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

.0 = <tuple_iterator object at 0x7f804b325b70>

    if any(
>       k not in self._params
        for k in ["acceptor_indices", "donor_indices", "selection"]
    ):

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/_2d/mix/transplantation.py:249: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <tf.Tensor: shape=(5, 5), dtype=int64, numpy=
array([[2, 0, 0, 0, 0],
       [2, 0, 2, 0, 1],
       [2, 1, 1, 1, 1],
       [1, 0, 0, 2, 1],
       [1, 0, 2, 2, 2]])>, rhs = 'acceptor_indices'

    def impl(self, rhs):
        try:
            res = original_method(self, rhs)
            if isinstance(rhs, (list, tuple)):
                return False if orig_method_name == "__eq__" else True
            return res
        except Exception:
>           return patched_method(self, rhs)

ivy_transpiled_outputs/tensorflow_outputs/__init__.py:58: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = <tf.Tensor: shape=(5, 5), dtype=int64, numpy=
array([[2, 0, 0, 0, 0],
       [2, 0, 2, 0, 1],
       [2, 1, 1, 1, 1],
       [1, 0, 0, 2, 1],
       [1, 0, 2, 2, 2]])>
other = 'acceptor_indices'

    def tensorflow___eq___frnt_(tensor, other):
        from .comparison_ops import tensorflow_eq_frnt
    
        if isinstance(other, (list, tuple)):
            return False
>       return tensorflow_eq_frnt(tensor, other)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/tensor.py:125: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = <tf.Tensor: shape=(5, 5), dtype=int64, numpy=
array([[2, 0, 0, 0, 0],
       [2, 0, 2, 0, 1],
       [2, 1, 1, 1, 1],
       [1, 0, 0, 2, 1],
       [1, 0, 2, 2, 2]])>
other = 'acceptor_indices'

    def tensorflow_eq_frnt(input, other, *, out=None):
        from .__init__ import tensorflow_promote_types_of_torch_inputs_frnt
        from ...backends.tensorflow.elementwise import tensorflow_equal
    
>       input, other = tensorflow_promote_types_of_torch_inputs_frnt(input, other)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/comparison_ops.py:110: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x1 = <tf.Tensor: shape=(5, 5), dtype=int64, numpy=
array([[2, 0, 0, 0, 0],
       [2, 0, 2, 0, 1],
       [2, 1, 1, 1, 1],
       [1, 0, 0, 2, 1],
       [1, 0, 2, 2, 2]])>, x2 = 'acceptor_indices'

    def tensorflow_promote_types_of_torch_inputs_frnt(x1, x2, /):
        from ...ivy.general import tensorflow_isscalar_bknd
        from ...ivy.data_type import tensorflow_is_int_dtype_bknd
        from ...backends.tensorflow.creation import tensorflow_asarray
        from ...ivy.data_type import tensorflow_default_dtype_bknd
        from .tensor import tensorflow_shape_frnt_
        from ...ivy.device import tensorflow_default_device_bknd
        from ....data_classes.array.data_type import tensorflow_astype_bknd_
    
        """Promote the dtype of the given native array inputs to a common dtype
        based on type promotion rules.
    
        While passing float or integer values or any other non-array input
        to this function, it should be noted that the return will be an
        array-like object. Therefore, outputs from this function should be
        used as inputs only for those functions that expect an array-like or
        tensor-like objects, otherwise it might give unexpected results.
        """
        if (
            tensorflow_isscalar_bknd(x1) or isinstance(x1, (list, tuple))
        ) and tensorflow_is_int_dtype_bknd(x1):
            x1 = tensorflow_asarray(x1, dtype="int64")
        elif tensorflow_isscalar_bknd(x1) or isinstance(x1, (list, tuple)):
            x1 = tensorflow_asarray(x1)
        if (
            tensorflow_isscalar_bknd(x2) or isinstance(x2, (list, tuple))
>       ) and tensorflow_is_int_dtype_bknd(x2):

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/__init__.py:222: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = 'acceptor_indices'

    def tensorflow_is_int_dtype_bknd(
        dtype_in: Union[str, str, tensorflow.Tensor, tf.Tensor, Number], /
    ):
        from .general import tensorflow_is_array_bknd
        from ..backends.tensorflow.data_type import tensorflow_dtype
        from .nest import tensorflow_nested_argwhere_bknd
        from ..backends.tensorflow.data_type import tensorflow_as_ivy_dtype
    
        if tensorflow_is_array_bknd(dtype_in):
            dtype_in = tensorflow_dtype(dtype_in)
        elif isinstance(dtype_in, tuple):
            dtype_in = tensorflow_default_int_dtype_bknd()
        elif isinstance(dtype_in, np.ndarray):
            return "int" in dtype_in.dtype.name
        elif isinstance(dtype_in, Number):
            return isinstance(dtype_in, (int, np.integer)) and not isinstance(
                dtype_in, bool
            )
        elif isinstance(dtype_in, (list, tuple, dict)):
    
            def nested_fun(x):
                from .general import tensorflow_is_array_bknd
                from ..backends.tensorflow.data_type import tensorflow_dtype
    
                return (
                    isinstance(x, (int, np.integer))
                    or tensorflow_is_array_bknd(x)
                    and "int" in tensorflow_dtype(x)
                ) and x is not bool
    
            return bool(tensorflow_nested_argwhere_bknd(dtype_in, nested_fun))
>       return "int" in tensorflow_as_ivy_dtype(dtype_in)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:485: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = 'acceptor_indices'

    def tensorflow_as_ivy_dtype(
        dtype_in: Union[tensorflow.DType, str, int, float, complex, bool, np.dtype], /
    ):
        from ...ivy.data_type import tensorflow_default_int_dtype_bknd
        from ...ivy.data_type import tensorflow_default_float_dtype_bknd
        from ...ivy.data_type import tensorflow_default_complex_dtype_bknd
    
        if dtype_in is int:
            return tensorflow_default_int_dtype_bknd()
        if dtype_in is float:
            return tensorflow_default_float_dtype_bknd()
        if dtype_in is complex:
            return tensorflow_default_complex_dtype_bknd()
        if dtype_in is bool:
            return str("bool")
        if isinstance(dtype_in, np.dtype):
            dtype_in = dtype_in.name
        if isinstance(dtype_in, str):
            if dtype_in in native_dtype_dict:
                dtype_str = dtype_in
            else:
>               raise Exception(
                    f"Cannot convert to ivy dtype. {dtype_in} is not supported by TensorFlow backend."
                )
E               Exception: Exception encountered when calling tensorflow_RandomTransplantation3D.call().
E               
E               [1mCannot convert to ivy dtype. acceptor_indices is not supported by TensorFlow backend.[0m
E               
E               Arguments received by tensorflow_RandomTransplantation3D.call():
E                 • input=<class 'inspect._empty'>
E                 • params=tf.Tensor(shape=(2, 5, 5), dtype=int64)
E                 • data_keys=None
E                 • kwargs={'input': 'tf.Tensor(shape=(2, 3, 5, 5), dtype=float32)'}

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/backends/tensorflow/data_type.py:204: Exception
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.RandomTransplantation3D
______________________________________________________________________________ test_LongestMaxSize[tensorflow-s2s-False] _______________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_LongestMaxSize(target_framework, mode, backend_compile):
        print("kornia.augmentation.LongestMaxSize")
    
        init_args = (100,)
        init_kwargs = {}
        call_args = (torch.rand(10, 3, 200, 200),)
        call_kwargs = {}
    
>       _test_augmentation_class(
            kornia.augmentation.LongestMaxSize,
            target_framework,
            init_args,
            init_kwargs,
            call_args,
            call_kwargs,
            deterministic_output=True,
            backend_compile=backend_compile,
        )

kornia/augmentation/test_augmentation4.py:360: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

augmentation_cls = <class 'kornia.augmentation._2d.geometric.resize.LongestMaxSize'>, target = 'tensorflow', init_args = (100,), init_kwargs = {}
call_args = (tensor([[[[5.1382e-01, 3.4626e-01, 1.9688e-01,  ..., 1.3044e-01,
           5.6897e-01, 8.6205e-01],
          [9.971... 5.2045e-01],
          [6.1714e-01, 2.9124e-01, 4.8936e-01,  ..., 8.4250e-01,
           5.3828e-01, 6.3940e-01]]]]),)
call_kwargs = {}, deterministic_output = True, backend_compile = False, tolerance = 0.001

    def _test_augmentation_class(
        augmentation_cls,
        target,
        init_args=(),
        init_kwargs={},
        call_args=(),
        call_kwargs={},
        deterministic_output=True,
        backend_compile=False,
        tolerance=1e-3,
    ):
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, target=target)
        transpiled_cls = eval("transpiled_" + f"{augmentation_cls.__module__}.{augmentation_cls.__name__}")
    
        torch_aug = augmentation_cls(*init_args, **init_kwargs)
        transpiled_init_args = _nest_torch_tensor_to_new_framework(init_args, target)
        transpiled_init_kwargs = _nest_torch_tensor_to_new_framework(init_kwargs, target)
        transpiled_aug = transpiled_cls(*transpiled_init_args, **transpiled_init_kwargs)
    
        # assert dir(torch_aug) == dir(transpiled_aug), f"attributes/methods of transpiled object do not align with the original - orig: {dir(torch_aug)} != transpiled: {dir(transpiled_aug)}"
    
        torch_out = torch_aug(*call_args, **call_kwargs)
        transpiled_call_args = _nest_torch_tensor_to_new_framework(call_args, target)
        transpiled_call_kwargs = _nest_torch_tensor_to_new_framework(call_kwargs, target)
        transpiled_out = transpiled_aug(*transpiled_call_args, **transpiled_call_kwargs)
    
        orig_np = _nest_array_to_numpy(torch_out)
        transpiled_np = _nest_array_to_numpy(transpiled_out)
    
        _check_shape_allclose(orig_np, transpiled_np)
    
        if deterministic_output:
            orig_np = _nest_array_to_numpy(torch_out)
            transpiled_np = _nest_array_to_numpy(transpiled_out)
>           _check_allclose(orig_np, transpiled_np, tolerance=tolerance)

kornia/augmentation/test_augmentation4.py:54: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[[0.51382315, 0.20470755, 0.36430964, ..., 0.17526159,
          0.12957826, 0.86205006],
         [0.77844507...4],
         [0.61713904, 0.48797664, 0.824981  , ..., 0.5038745 ,
          0.84104025, 0.63939935]]]], dtype=float32)
y = array([[[[0.6573019 , 0.546684  , 0.4234469 , ..., 0.53843963,
          0.18652108, 0.38763762],
         [0.4138704 ... ],
         [0.53104925, 0.6104187 , 0.5544082 , ..., 0.49569064,
          0.6440407 , 0.5750816 ]]]], dtype=float32)
tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
>           assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
E           AssertionError: numpy array values are not all close

helpers.py:26: AssertionError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.LongestMaxSize
__________________________________________________________________________________ test_Resize[tensorflow-s2s-False] ___________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_Resize(target_framework, mode, backend_compile):
        print("kornia.augmentation.Resize")
    
        init_args = ((100, 100),)
        init_kwargs = {}
        call_args = (torch.rand(10, 3, 50, 50),)
        call_kwargs = {}
    
>       _test_augmentation_class(
            kornia.augmentation.Resize,
            target_framework,
            init_args,
            init_kwargs,
            call_args,
            call_kwargs,
            deterministic_output=True,
            backend_compile=backend_compile,
        )

kornia/augmentation/test_augmentation4.py:380: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

augmentation_cls = <class 'kornia.augmentation._2d.geometric.resize.Resize'>, target = 'tensorflow', init_args = ((100, 100),), init_kwargs = {}
call_args = (tensor([[[[6.8631e-01, 3.1516e-01, 9.1620e-01,  ..., 9.6177e-01,
           4.9026e-02, 5.1791e-01],
          [6.664... 1.5941e-01],
          [3.4263e-01, 7.9081e-02, 2.1155e-01,  ..., 3.1216e-01,
           5.8205e-01, 4.2439e-01]]]]),)
call_kwargs = {}, deterministic_output = True, backend_compile = False, tolerance = 0.001

    def _test_augmentation_class(
        augmentation_cls,
        target,
        init_args=(),
        init_kwargs={},
        call_args=(),
        call_kwargs={},
        deterministic_output=True,
        backend_compile=False,
        tolerance=1e-3,
    ):
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, target=target)
        transpiled_cls = eval("transpiled_" + f"{augmentation_cls.__module__}.{augmentation_cls.__name__}")
    
        torch_aug = augmentation_cls(*init_args, **init_kwargs)
        transpiled_init_args = _nest_torch_tensor_to_new_framework(init_args, target)
        transpiled_init_kwargs = _nest_torch_tensor_to_new_framework(init_kwargs, target)
        transpiled_aug = transpiled_cls(*transpiled_init_args, **transpiled_init_kwargs)
    
        # assert dir(torch_aug) == dir(transpiled_aug), f"attributes/methods of transpiled object do not align with the original - orig: {dir(torch_aug)} != transpiled: {dir(transpiled_aug)}"
    
        torch_out = torch_aug(*call_args, **call_kwargs)
        transpiled_call_args = _nest_torch_tensor_to_new_framework(call_args, target)
        transpiled_call_kwargs = _nest_torch_tensor_to_new_framework(call_kwargs, target)
        transpiled_out = transpiled_aug(*transpiled_call_args, **transpiled_call_kwargs)
    
        orig_np = _nest_array_to_numpy(torch_out)
        transpiled_np = _nest_array_to_numpy(transpiled_out)
    
        _check_shape_allclose(orig_np, transpiled_np)
    
        if deterministic_output:
            orig_np = _nest_array_to_numpy(torch_out)
            transpiled_np = _nest_array_to_numpy(transpiled_out)
>           _check_allclose(orig_np, transpiled_np, tolerance=tolerance)

kornia/augmentation/test_augmentation4.py:54: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[[0.68631464, 0.5026123 , 0.31890994, ..., 0.0537619 ,
          0.28583395, 0.51790595],
         [0.676492  ...2],
         [0.3426339 , 0.21218863, 0.08174333, ..., 0.5804595 ,
          0.50242275, 0.42438602]]]], dtype=float32)
y = array([[[[0.68631464, 0.59352624, 0.40794936, ..., 0.16624568,
          0.40068585, 0.51790595],
         [0.68135315...5],
         [0.3426339 , 0.27674574, 0.14496936, ..., 0.54263556,
          0.46380255, 0.42438602]]]], dtype=float32)
tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
>           assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
E           AssertionError: numpy array values are not all close

helpers.py:26: AssertionError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.Resize
______________________________________________________________________________ test_SmallestMaxSize[tensorflow-s2s-False] ______________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_SmallestMaxSize(target_framework, mode, backend_compile):
        print("kornia.augmentation.SmallestMaxSize")
    
        init_args = (100,)
        init_kwargs = {}
        call_args = (torch.rand(10, 3, 50, 50),)
        call_kwargs = {}
    
>       _test_augmentation_class(
            kornia.augmentation.SmallestMaxSize,
            target_framework,
            init_args,
            init_kwargs,
            call_args,
            call_kwargs,
            deterministic_output=True,
            backend_compile=backend_compile,
        )

kornia/augmentation/test_augmentation4.py:400: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

augmentation_cls = <class 'kornia.augmentation._2d.geometric.resize.SmallestMaxSize'>, target = 'tensorflow', init_args = (100,), init_kwargs = {}
call_args = (tensor([[[[2.5151e-01, 8.3542e-01, 5.0773e-01,  ..., 8.2317e-02,
           9.3334e-01, 7.9542e-01],
          [8.647... 6.6047e-01],
          [9.3088e-01, 6.7327e-01, 2.7375e-01,  ..., 3.2509e-01,
           8.3580e-01, 9.6173e-01]]]]),)
call_kwargs = {}, deterministic_output = True, backend_compile = False, tolerance = 0.001

    def _test_augmentation_class(
        augmentation_cls,
        target,
        init_args=(),
        init_kwargs={},
        call_args=(),
        call_kwargs={},
        deterministic_output=True,
        backend_compile=False,
        tolerance=1e-3,
    ):
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, target=target)
        transpiled_cls = eval("transpiled_" + f"{augmentation_cls.__module__}.{augmentation_cls.__name__}")
    
        torch_aug = augmentation_cls(*init_args, **init_kwargs)
        transpiled_init_args = _nest_torch_tensor_to_new_framework(init_args, target)
        transpiled_init_kwargs = _nest_torch_tensor_to_new_framework(init_kwargs, target)
        transpiled_aug = transpiled_cls(*transpiled_init_args, **transpiled_init_kwargs)
    
        # assert dir(torch_aug) == dir(transpiled_aug), f"attributes/methods of transpiled object do not align with the original - orig: {dir(torch_aug)} != transpiled: {dir(transpiled_aug)}"
    
        torch_out = torch_aug(*call_args, **call_kwargs)
        transpiled_call_args = _nest_torch_tensor_to_new_framework(call_args, target)
        transpiled_call_kwargs = _nest_torch_tensor_to_new_framework(call_kwargs, target)
        transpiled_out = transpiled_aug(*transpiled_call_args, **transpiled_call_kwargs)
    
        orig_np = _nest_array_to_numpy(torch_out)
        transpiled_np = _nest_array_to_numpy(transpiled_out)
    
        _check_shape_allclose(orig_np, transpiled_np)
    
        if deterministic_output:
            orig_np = _nest_array_to_numpy(torch_out)
            transpiled_np = _nest_array_to_numpy(transpiled_out)
>           _check_allclose(orig_np, transpiled_np, tolerance=tolerance)

kornia/augmentation/test_augmentation4.py:54: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[[0.2515105 , 0.5405182 , 0.829526  , ..., 0.9319442 ,
          0.8636817 , 0.7954192 ],
         [0.55504274...4],
         [0.9308782 , 0.8033738 , 0.67586935, ..., 0.8370696 ,
          0.89940053, 0.96173143]]]], dtype=float32)
y = array([[[[0.2515105 , 0.3974889 , 0.68944573, ..., 0.89885783,
          0.8298987 , 0.7954192 ],
         [0.40482527... ],
         [0.9308782 , 0.86647546, 0.73767   , ..., 0.86728096,
          0.93024796, 0.96173143]]]], dtype=float32)
tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
>           assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
E           AssertionError: numpy array values are not all close

helpers.py:26: AssertionError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.SmallestMaxSize
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/augmentation/test_augmentation4.py::test_RandomMosaic[tensorflow-s2s-False] - TypeError: got an unexpected keyword argument 'input'
FAILED kornia/augmentation/test_augmentation4.py::test_RandomTransplantation[tensorflow-s2s-False] - Exception: Exception encountered when calling tensorflow_RandomTransplantation.call().
FAILED kornia/augmentation/test_augmentation4.py::test_RandomRotation3D[tensorflow-s2s-False] - AttributeError: Exception encountered when calling tensorflow_RandomRotation3D.call().
FAILED kornia/augmentation/test_augmentation4.py::test_RandomTransplantation3D[tensorflow-s2s-False] - Exception: Exception encountered when calling tensorflow_RandomTransplantation3D.call().
FAILED kornia/augmentation/test_augmentation4.py::test_LongestMaxSize[tensorflow-s2s-False] - AssertionError: numpy array values are not all close
FAILED kornia/augmentation/test_augmentation4.py::test_Resize[tensorflow-s2s-False] - AssertionError: numpy array values are not all close
FAILED kornia/augmentation/test_augmentation4.py::test_SmallestMaxSize[tensorflow-s2s-False] - AssertionError: numpy array values are not all close
============================================================================== 7 failed, 10 passed in 3636.52s (1:00:36) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 6 items

kornia/geometry/test_depth.py ......                                                                                                                                                             [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
==================================================================================== 6 passed in 409.33s (0:06:49) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 14 items

kornia/test_feature4.py .F.....FFFF...                                                                                                                                                           [100%]

=============================================================================================== FAILURES ===============================================================================================
______________________________________________________________________________ test_SIFTFeatureScaleSpace[jax-s2s-False] _______________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_SIFTFeatureScaleSpace(target_framework, mode, backend_compile):
        print("kornia.feature.SIFTFeatureScaleSpace")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target_framework)
    
        x = torch.rand(1, 1, 256, 256)
        transpiled_x = _nest_torch_tensor_to_new_framework(x, target_framework)
    
        model = kornia.feature.SIFTFeatureScaleSpace(num_features=10)
        torch_out = model(x)
    
        transpiled_model = transpiled_kornia.feature.SIFTFeatureScaleSpace(num_features=10)
        if target_framework == "tensorflow":
            # build the layers
            transpiled_model(transpiled_x)
    
        ivy.sync_models(model, transpiled_model)
    
>       transpiled_out = transpiled_model(transpiled_x)

kornia/test_feature4.py:64: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_SIFTFeatureScaleSpace(
  (detector): jax_ScaleSpaceDetector(num_features=10, mr_size=6.0, scale_pyr=jax_ScalePyram...ng_bins=8, num_spatial_bins=4, patch_size=41, rootsift=True, clipval=0.2), patch_size=41, grayscale_descriptor='True)
)
img = Array([[[[0.18823522, 0.06536162, 0.31722802, ..., 0.03407216,
          0.31541324, 0.9056276 ],
         [0.992722  ...2],
         [0.10165864, 0.6331967 , 0.5952796 , ..., 0.8450174 ,
          0.31223136, 0.09676909]]]], dtype=float32)
mask = None

    def __call__(self, img, mask=None):
        from .laf import jax_scale_laf
    
>       lafs, responses = self.detector(img, mask)

ivy_transpiled_outputs/jax_outputs/kornia/feature/integrated.py:202: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_ScaleSpaceDetector(num_features=10, mr_size=6.0, scale_pyr=jax_ScalePyramid(n_levels=3, init_sigma=1.6, min_size=3...19, angle_detector=jax_PatchDominantGradientOrientation(patch_size=19, num_ang_bins=36, eps=1e-08)), aff=jax_PassLAF())
img = Array([[[[0.18823522, 0.06536162, 0.31722802, ..., 0.03407216,
          0.31541324, 0.9056276 ],
         [0.992722  ...2],
         [0.10165864, 0.6331967 , 0.5952796 , ..., 0.8450174 ,
          0.31223136, 0.09676909]]]], dtype=float32)
mask = None

    def __call__(self, img, mask=None):
>       responses, lafs = self.detect(img, self.num_features, mask)

ivy_transpiled_outputs/jax_outputs/kornia/feature/scale_space_detector.py:256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_ScaleSpaceDetector(num_features=10, mr_size=6.0, scale_pyr=jax_ScalePyramid(n_levels=3, init_sigma=1.6, min_size=3...19, angle_detector=jax_PatchDominantGradientOrientation(patch_size=19, num_ang_bins=36, eps=1e-08)), aff=jax_PassLAF())
img = Array([[[[0.18823522, 0.06536162, 0.31722802, ..., 0.03407216,
          0.31541324, 0.9056276 ],
         [0.992722  ...2],
         [0.10165864, 0.6331967 , 0.5952796 , ..., 0.8450174 ,
          0.31223136, 0.09676909]]]], dtype=float32)
num_feats = 10, mask = None

    def detect(self, img, num_feats, mask=None):
        from ...ivy.functional.backends.jax.general import jax_get_item
        from ...ivy.functional.frontends.torch.tensor import jax_size_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_view_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_reshape_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_permute_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_to_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_unsqueeze_frnt_
        from ...ivy.functional.frontends.torch.comparison_ops import jax_topk_frnt
        from ...ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            jax_gather_frnt,
        )
        from ...ivy.functional.frontends.torch.tensor import jax_repeat_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_item_frnt_
        from .laf import jax_laf_is_inside_image
        from ..core._backend import eye
        from ..core._backend import concatenate
    
        dev: typing.Any = img.device
        dtype: typing.Any = img.dtype
        sigmas: typing.Any
>       sp, sigmas, _ = self.scale_pyr(img)

ivy_transpiled_outputs/jax_outputs/kornia/feature/scale_space_detector.py:145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_ScalePyramid(n_levels=3, init_sigma=1.6, min_size=32, extra_levels=3, border=15, sigma_step=1.2599210498948732, double_image=True)
x = Array([[[[0.18823522, 0.06536162, 0.31722802, ..., 0.03407216,
          0.31541324, 0.9056276 ],
         [0.992722  ...2],
         [0.10165864, 0.6331967 , 0.5952796 , ..., 0.8450174 ,
          0.31223136, 0.09676909]]]], dtype=float32)

    def __call__(self, x):
        from ...filters.gaussian import jax_gaussian_blur2d
        from ....ivy.functional.frontends.torch.tensor import jax_size_frnt_
        from ....ivy.functional.frontends.torch.tensor import jax_to_frnt_
        from ....ivy.functional.backends.jax.general import jax_set_item
        from ....ivy.functional.backends.jax.general import jax_get_item
        from ....ivy.functional.frontends.torch.creation_ops import jax_ones_frnt
        from ...core._backend import ones
        from ...core._backend import stack
    
        bs, _, _, _ = jax_size_frnt_(x)
>       cur_level, cur_sigma, pixel_distance = self.get_first_level(x)

ivy_transpiled_outputs/jax_outputs/kornia/geometry/transform/pyramid.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_ScalePyramid(n_levels=3, init_sigma=1.6, min_size=32, extra_levels=3, border=15, sigma_step=1.2599210498948732, double_image=True)
input = Array([[[[0.18823522, 0.06536162, 0.31722802, ..., 0.03407216,
          0.31541324, 0.9056276 ],
         [0.992722  ...2],
         [0.10165864, 0.6331967 , 0.5952796 , ..., 0.8450174 ,
          0.31223136, 0.09676909]]]], dtype=float32)

    def get_first_level(self, input):
        from ...filters.gaussian import jax_gaussian_blur2d
    
        pixel_distance = 1.0
        cur_sigma = 0.5
        if self.double_image:
>           x = jax_upscale_double(input)

ivy_transpiled_outputs/jax_outputs/kornia/geometry/transform/pyramid.py:89: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = Array([[[[0.18823522, 0.06536162, 0.31722802, ..., 0.03407216,
          0.31541324, 0.9056276 ],
         [0.992722  ...2],
         [0.10165864, 0.6331967 , 0.5952796 , ..., 0.8450174 ,
          0.31223136, 0.09676909]]]], dtype=float32)

    def jax_upscale_double(x):
        from ...core._backend import zeros
        from ...core.check import jax_KORNIA_CHECK_IS_TENSOR
        from ...core.check import jax_KORNIA_CHECK_SHAPE
        from ....ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ....ivy.functional.backends.jax.general import jax_set_item
    
        jax_KORNIA_CHECK_IS_TENSOR(x)
        jax_KORNIA_CHECK_SHAPE(x, ["*", "H", "W"])
        double_shape = jax_shape_frnt_(x)[:-2] + (
            jax_shape_frnt_(x)[-2] * 2,
            jax_shape_frnt_(x)[-1] * 2,
        )
        upscaled = zeros(double_shape, device=x.device, dtype=x.dtype)
        upscaled = jax_set_item(
            upscaled, (..., slice(None, None, 2), slice(None, None, 2)), x
        )
>       upscaled[..., ::2, 1::2] = jax_set_item(
            upscaled[..., ::2, 1::2],
            (..., slice(None, -1, None)),
            (upscaled[..., ::2, ::2][..., :-1] + upscaled[..., ::2, 2::2]) / 2,
        )

ivy_transpiled_outputs/jax_outputs/kornia/geometry/transform/pyramid.py:307: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = Array([[[[0.18823522, 0.        , 0.06536162, ..., 0.        ,
          0.9056276 , 0.        ],
         [0.        ... ],
         [0.        , 0.        , 0.        , ..., 0.        ,
          0.        , 0.        ]]]], dtype=float32)
i = (Ellipsis, slice(None, None, 2), slice(1, None, 2))
x = Array([[[[0.12679842, 0.19129482, 0.20254561, ..., 0.1747427 ,
          0.6105204 , 0.        ],
         [0.9079568 ... ],
         [0.36742768, 0.61423814, 0.30462143, ..., 0.57862437,
          0.20450023, 0.        ]]]], dtype=float32)

    def _unimplemented_setitem(self, i, x):
      msg = ("'{}' object does not support item assignment. JAX arrays are "
             "immutable. Instead of ``x[idx] = y``, use ``x = x.at[idx].set(y)`` "
             "or another .at[] method: "
             "https://jax.readthedocs.io/en/latest/_autosummary/jax.numpy.ndarray.at.html")
>     raise TypeError(msg.format(type(self)))
E     TypeError: '<class 'jaxlib.xla_extension.ArrayImpl'>' object does not support item assignment. JAX arrays are immutable. Instead of ``x[idx] = y``, use ``x = x.at[idx].set(y)`` or another .at[] method: https://jax.readthedocs.io/en/latest/_autosummary/jax.numpy.ndarray.at.html

/opt/fw/jax/jax/_src/numpy/array_methods.py:587: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.SIFTFeatureScaleSpace
All parameters and buffers are now synced!
_______________________________________________________________________________ test_LocalFeatureMatcher[jax-s2s-False] ________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_LocalFeatureMatcher(target_framework, mode, backend_compile):
        print("kornia.feature.LocalFeatureMatcher")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target_framework)
    
        data = {
            "image0": torch.rand(1, 1, 320, 200),
            "image1": torch.rand(1, 1, 128, 128),
        }
        transpiled_data = _nest_torch_tensor_to_new_framework(data, target_framework)
    
        torch_local_feature = kornia.feature.GFTTAffNetHardNet(10)
        torch_matcher = kornia.feature.DescriptorMatcher('snn', 0.8)
        model = kornia.feature.LocalFeatureMatcher(torch_local_feature, torch_matcher)
>       torch_out = model(data)

kornia/test_feature4.py:223: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalFeatureMatcher(
  (local_feature): GFTTAffNetHardNet(
    (detector): MultiResolutionDetector(
      (model): Cor...ck_running_stats=True)
      )
    ), patch_size=32, grayscale_descriptor='True)
  )
  (matcher): DescriptorMatcher()
)
args = ({'image0': Array([[[[0.7101024 , 0.9887812 , 0.45386726, ..., 0.6462765 ,
          0.57156783, 0.93334836],
        ...
         [0.03441882, 0.68699133, 0.18852389, ..., 0.28615493,
          0.39205557, 0.26914704]]]], dtype=float32)},)
kwargs = {}

    def _wrapped_call_impl(self, *args, **kwargs):
        if self._compiled_call_impl is not None:
            return self._compiled_call_impl(*args, **kwargs)  # type: ignore[misc]
        else:
>           return self._call_impl(*args, **kwargs)

/opt/fw/torch/torch/nn/modules/module.py:1736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalFeatureMatcher(
  (local_feature): GFTTAffNetHardNet(
    (detector): MultiResolutionDetector(
      (model): Cor...ck_running_stats=True)
      )
    ), patch_size=32, grayscale_descriptor='True)
  )
  (matcher): DescriptorMatcher()
)
args = ({'image0': Array([[[[0.7101024 , 0.9887812 , 0.45386726, ..., 0.6462765 ,
          0.57156783, 0.93334836],
        ...
         [0.03441882, 0.68699133, 0.18852389, ..., 0.28615493,
          0.39205557, 0.26914704]]]], dtype=float32)},)
kwargs = {}

    def _call_impl(self, *args, **kwargs):
        forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)
        # If we don't have any hooks, we want to skip the rest of the logic in
        # this function, and just call forward.
        if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks
                or _global_backward_pre_hooks or _global_backward_hooks
                or _global_forward_hooks or _global_forward_pre_hooks):
>           return forward_call(*args, **kwargs)

/opt/fw/torch/torch/nn/modules/module.py:1747: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalFeatureMatcher(
  (local_feature): GFTTAffNetHardNet(
    (detector): MultiResolutionDetector(
      (model): Cor...ck_running_stats=True)
      )
    ), patch_size=32, grayscale_descriptor='True)
  )
  (matcher): DescriptorMatcher()
)
data = {'image0': Array([[[[0.7101024 , 0.9887812 , 0.45386726, ..., 0.6462765 ,
          0.57156783, 0.93334836],
         ...],
         [0.03441882, 0.68699133, 0.18852389, ..., 0.28615493,
          0.39205557, 0.26914704]]]], dtype=float32)}

    def forward(self, data: Dict[str, Tensor]) -> Dict[str, Tensor]:
        """
        Args:
            data: dictionary containing the input data in the following format:
    
        Keyword Args:
            image0: left image with shape :math:`(N, 1, H1, W1)`.
            image1: right image with shape :math:`(N, 1, H2, W2)`.
            mask0 (optional): left image mask. '0' indicates a padded position :math:`(N, H1, W1)`.
            mask1 (optional): right image mask. '0' indicates a padded position :math:`(N, H2, W2)`.
    
        Returns:
            - ``keypoints0``, matching keypoints from image0 :math:`(NC, 2)`.
            - ``keypoints1``, matching keypoints from image1 :math:`(NC, 2)`.
            - ``confidence``, confidence score [0, 1] :math:`(NC)`.
            - ``lafs0``, matching LAFs from image0 :math:`(1, NC, 2, 3)`.
            - ``lafs1``, matching LAFs from image1 :math:`(1, NC, 2, 3)`.
            - ``batch_indexes``, batch indexes for the keypoints and lafs :math:`(NC)`.
        """
        num_image_pairs: int = data["image0"].shape[0]
    
        if ("lafs0" not in data.keys()) or ("descriptors0" not in data.keys()):
            # One can supply pre-extracted local features
>           feats_dict0: Dict[str, Tensor] = self.extract_features(data["image0"])

/opt/miniconda/envs/multienv/lib/python3.10/site-packages/kornia/feature/integrated.py:349: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalFeatureMatcher(
  (local_feature): GFTTAffNetHardNet(
    (detector): MultiResolutionDetector(
      (model): Cor...ck_running_stats=True)
      )
    ), patch_size=32, grayscale_descriptor='True)
  )
  (matcher): DescriptorMatcher()
)
image = Array([[[[0.7101024 , 0.9887812 , 0.45386726, ..., 0.6462765 ,
          0.57156783, 0.93334836],
         [0.98669535...8],
         [0.06612557, 0.70405126, 0.17925847, ..., 0.38889462,
          0.0536378 , 0.9304554 ]]]], dtype=float32)
mask = None

    def extract_features(self, image: Tensor, mask: Optional[Tensor] = None) -> Dict[str, Tensor]:
        """Function for feature extraction from simple image."""
>       lafs0, resps0, descs0 = self.local_feature(image, mask)

/opt/miniconda/envs/multienv/lib/python3.10/site-packages/kornia/feature/integrated.py:313: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = GFTTAffNetHardNet(
  (detector): MultiResolutionDetector(
    (model): CornerGFTT(grads_mode=sobel)
    (nms): NonMaxi...ps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    )
  ), patch_size=32, grayscale_descriptor='True)
)
args = (Array([[[[0.7101024 , 0.9887812 , 0.45386726, ..., 0.6462765 ,
          0.57156783, 0.93334836],
         [0.9866953...      [0.06612557, 0.70405126, 0.17925847, ..., 0.38889462,
          0.0536378 , 0.9304554 ]]]], dtype=float32), None)
kwargs = {}

    def _wrapped_call_impl(self, *args, **kwargs):
        if self._compiled_call_impl is not None:
            return self._compiled_call_impl(*args, **kwargs)  # type: ignore[misc]
        else:
>           return self._call_impl(*args, **kwargs)

/opt/fw/torch/torch/nn/modules/module.py:1736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = GFTTAffNetHardNet(
  (detector): MultiResolutionDetector(
    (model): CornerGFTT(grads_mode=sobel)
    (nms): NonMaxi...ps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    )
  ), patch_size=32, grayscale_descriptor='True)
)
args = (Array([[[[0.7101024 , 0.9887812 , 0.45386726, ..., 0.6462765 ,
          0.57156783, 0.93334836],
         [0.9866953...      [0.06612557, 0.70405126, 0.17925847, ..., 0.38889462,
          0.0536378 , 0.9304554 ]]]], dtype=float32), None)
kwargs = {}

    def _call_impl(self, *args, **kwargs):
        forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)
        # If we don't have any hooks, we want to skip the rest of the logic in
        # this function, and just call forward.
        if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks
                or _global_backward_pre_hooks or _global_backward_hooks
                or _global_forward_hooks or _global_forward_pre_hooks):
>           return forward_call(*args, **kwargs)

/opt/fw/torch/torch/nn/modules/module.py:1747: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = GFTTAffNetHardNet(
  (detector): MultiResolutionDetector(
    (model): CornerGFTT(grads_mode=sobel)
    (nms): NonMaxi...ps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    )
  ), patch_size=32, grayscale_descriptor='True)
)
img = Array([[[[0.7101024 , 0.9887812 , 0.45386726, ..., 0.6462765 ,
          0.57156783, 0.93334836],
         [0.98669535...8],
         [0.06612557, 0.70405126, 0.17925847, ..., 0.38889462,
          0.0536378 , 0.9304554 ]]]], dtype=float32)
mask = None

    def forward(self, img: Tensor, mask: Optional[Tensor] = None) -> Tuple[Tensor, Tensor, Tensor]:
        """
        Args:
            img: image to extract features with shape :math:`(B,C,H,W)`.
            mask: a mask with weights where to apply the response function.
                The shape must be the same as the input image.
    
        Returns:
            - Detected local affine frames with shape :math:`(B,N,2,3)`.
            - Response function values for corresponding lafs with shape :math:`(B,N,1)`.
            - Local descriptors of shape :math:`(B,N,D)` where :math:`D` is descriptor size.
        """
>       lafs, responses = self.detector(img, mask)

/opt/miniconda/envs/multienv/lib/python3.10/site-packages/kornia/feature/integrated.py:139: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = MultiResolutionDetector(
  (model): CornerGFTT(grads_mode=sobel)
  (nms): NonMaximaSuppression2d()
  (ori): LAFOriente...d(64, 3, kernel_size=(8, 8), stride=(1, 1))
      (20): Tanh()
      (21): AdaptiveAvgPool2d(output_size=1)
    )
  )
)
args = (Array([[[[0.7101024 , 0.9887812 , 0.45386726, ..., 0.6462765 ,
          0.57156783, 0.93334836],
         [0.9866953...      [0.06612557, 0.70405126, 0.17925847, ..., 0.38889462,
          0.0536378 , 0.9304554 ]]]], dtype=float32), None)
kwargs = {}

    def _wrapped_call_impl(self, *args, **kwargs):
        if self._compiled_call_impl is not None:
            return self._compiled_call_impl(*args, **kwargs)  # type: ignore[misc]
        else:
>           return self._call_impl(*args, **kwargs)

/opt/fw/torch/torch/nn/modules/module.py:1736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = MultiResolutionDetector(
  (model): CornerGFTT(grads_mode=sobel)
  (nms): NonMaximaSuppression2d()
  (ori): LAFOriente...d(64, 3, kernel_size=(8, 8), stride=(1, 1))
      (20): Tanh()
      (21): AdaptiveAvgPool2d(output_size=1)
    )
  )
)
args = (Array([[[[0.7101024 , 0.9887812 , 0.45386726, ..., 0.6462765 ,
          0.57156783, 0.93334836],
         [0.9866953...      [0.06612557, 0.70405126, 0.17925847, ..., 0.38889462,
          0.0536378 , 0.9304554 ]]]], dtype=float32), None)
kwargs = {}

    def _call_impl(self, *args, **kwargs):
        forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)
        # If we don't have any hooks, we want to skip the rest of the logic in
        # this function, and just call forward.
        if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks
                or _global_backward_pre_hooks or _global_backward_hooks
                or _global_forward_hooks or _global_forward_pre_hooks):
>           return forward_call(*args, **kwargs)

/opt/fw/torch/torch/nn/modules/module.py:1747: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = MultiResolutionDetector(
  (model): CornerGFTT(grads_mode=sobel)
  (nms): NonMaximaSuppression2d()
  (ori): LAFOriente...d(64, 3, kernel_size=(8, 8), stride=(1, 1))
      (20): Tanh()
      (21): AdaptiveAvgPool2d(output_size=1)
    )
  )
)
img = Array([[[[0.7101024 , 0.9887812 , 0.45386726, ..., 0.6462765 ,
          0.57156783, 0.93334836],
         [0.98669535...8],
         [0.06612557, 0.70405126, 0.17925847, ..., 0.38889462,
          0.0536378 , 0.9304554 ]]]], dtype=float32)
mask = None

    def forward(self, img: Tensor, mask: Optional[Tensor] = None) -> Tuple[Tensor, Tensor]:
        """Three stage local feature detection. First the location and scale of interest points are determined by
        detect function. Then affine shape and orientation.
    
        Args:
            img: image to extract features with shape [1xCxHxW]. KeyNetDetector does not support batch processing,
        because the number of detections is different on each image.
            mask: a mask with weights where to apply the response function. The shape must be the same as
              the input image.
    
        Returns:
            lafs: shape [1xNx2x3]. Detected local affine frames.
            responses: shape [1xNx1]. Response function values for corresponding lafs
        """
        KORNIA_CHECK_SHAPE(img, ["1", "C", "H", "W"])
>       responses, lafs = self.detect(img, mask)

/opt/miniconda/envs/multienv/lib/python3.10/site-packages/kornia/feature/scale_space_detector.py:392: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = MultiResolutionDetector(
  (model): CornerGFTT(grads_mode=sobel)
  (nms): NonMaximaSuppression2d()
  (ori): LAFOriente...d(64, 3, kernel_size=(8, 8), stride=(1, 1))
      (20): Tanh()
      (21): AdaptiveAvgPool2d(output_size=1)
    )
  )
)
img = Array([[[[0.7101024 , 0.9887812 , 0.45386726, ..., 0.6462765 ,
          0.57156783, 0.93334836],
         [0.98669535...8],
         [0.06612557, 0.70405126, 0.17925847, ..., 0.38889462,
          0.0536378 , 0.9304554 ]]]], dtype=float32)
mask = None

    def detect(self, img: Tensor, mask: Optional[Tensor] = None) -> Tuple[Tensor, Tensor]:
        # Compute points per level
        num_features_per_level: List[float] = []
        tmp = 0.0
        factor_points = self.scale_factor_levels**2
        levels = self.num_pyramid_levels + self.num_upscale_levels + 1
        for idx_level in range(levels):
            tmp += factor_points ** (-1 * (idx_level - self.num_upscale_levels))
            nf = self.num_features * factor_points ** (-1 * (idx_level - self.num_upscale_levels))
            num_features_per_level.append(nf)
        num_features_per_level = [int(x / tmp) for x in num_features_per_level]
    
        _, _, h, w = img.shape
        img_up = img
        cur_img = img
        all_responses: List[Tensor] = []
        all_lafs: List[Tensor] = []
        # Extract features from the upper levels
        for idx_level in range(self.num_upscale_levels):
            nf = num_features_per_level[len(num_features_per_level) - self.num_pyramid_levels - 1 - (idx_level + 1)]
            num_points_level = int(nf)
    
            # Resize input image
            up_factor = self.scale_factor_levels ** (1 + idx_level)
            nh, nw = int(h * up_factor), int(w * up_factor)
            up_factor_kpts = (float(w) / float(nw), float(h) / float(nh))
>           img_up = resize(img_up, (nh, nw), interpolation="bilinear", align_corners=False)

/opt/miniconda/envs/multienv/lib/python3.10/site-packages/kornia/feature/scale_space_detector.py:345: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = Array([[[[0.7101024 , 0.9887812 , 0.45386726, ..., 0.6462765 ,
          0.57156783, 0.93334836],
         [0.98669535...8],
         [0.06612557, 0.70405126, 0.17925847, ..., 0.38889462,
          0.0536378 , 0.9304554 ]]]], dtype=float32)
args = ((452, 282),), kwargs = {'align_corners': False, 'interpolation': 'bilinear'}

    @wraps(f)
    def _wrapper(input: Tensor, *args: Any, **kwargs: Any) -> Tensor:
        if not isinstance(input, Tensor):
>           raise TypeError(f"Input input type is not a Tensor. Got {type(input)}")
E           TypeError: Input input type is not a Tensor. Got <class 'jaxlib.xla_extension.ArrayImpl'>

/opt/miniconda/envs/multienv/lib/python3.10/site-packages/kornia/utils/image.py:224: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.LocalFeatureMatcher
_________________________________________________________________________________ test_LightGlueMatcher[jax-s2s-False] _________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_LightGlueMatcher(target_framework, mode, backend_compile):
        print("kornia.feature.LightGlueMatcher")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target_framework)
    
        torch_args = (
            torch.rand(2, 128),
            torch.rand(5, 128),
            torch.rand(1, 2, 2, 3),
            torch.rand(1, 5, 2, 3),
        )
        transpiled_args = _nest_torch_tensor_to_new_framework(torch_args, target_framework)
    
        model = kornia.feature.LightGlueMatcher('disk')
        torch_out = model(*torch_args)
    
>       transpiled_model = transpiled_kornia.feature.LightGlueMatcher('disk')

kornia/test_feature4.py:258: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:232: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.integrated.jax_LightGlueMatcher'>, args = ('disk',), kwargs = {}

    def __call__(cls, *args: Any, **kwargs: Any) -> Any:
>     return _graph_node_meta_call(cls, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.integrated.jax_LightGlueMatcher'>, args = ('disk',), kwargs = {}, node = jax_LightGlueMatcher()

    def _graph_node_meta_call(cls: tp.Type[G], *args, **kwargs) -> G:
      node = cls.__new__(cls, *args, **kwargs)
      vars(node)['_object__state'] = ObjectState()
>     cls._object_meta_construct(node, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:88: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.integrated.jax_LightGlueMatcher'>, self = jax_LightGlueMatcher(), args = ('disk',), kwargs = {}

    def _object_meta_construct(cls, self, *args, **kwargs):
>     self.__init__(*args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:82: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_LightGlueMatcher(), feature_name = 'disk', params = {}

    def __init__(self, feature_name="disk", params={}):
        from .lightglue import jax_LightGlue
    
        feature_name_: typing.Any = feature_name.lower()
        super().__init__(feature_name_)
        self.feature_name = feature_name_
        self.params = params
>       self.matcher = jax_LightGlue(self.feature_name, **params)

ivy_transpiled_outputs/jax_outputs/kornia/feature/integrated.py:51: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.lightglue.jax_LightGlue'>, args = ('disk',), kwargs = {}

    def __call__(cls, *args: Any, **kwargs: Any) -> Any:
>     return _graph_node_meta_call(cls, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.lightglue.jax_LightGlue'>, args = ('disk',), kwargs = {}
node = jax_LightGlue(
  (input_proj): FlaxLinear(in_features=128, out_features=256, use_bias=True)
  (posenc): jax_LearnableFourierPositionalEncoding(
    (Wr): FlaxLinear(in_features=2, out_features=32, use_bias=False)
  )
)

    def _graph_node_meta_call(cls: tp.Type[G], *args, **kwargs) -> G:
      node = cls.__new__(cls, *args, **kwargs)
      vars(node)['_object__state'] = ObjectState()
>     cls._object_meta_construct(node, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:88: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.lightglue.jax_LightGlue'>
self = jax_LightGlue(
  (input_proj): FlaxLinear(in_features=128, out_features=256, use_bias=True)
  (posenc): jax_LearnableFourierPositionalEncoding(
    (Wr): FlaxLinear(in_features=2, out_features=32, use_bias=False)
  )
)
args = ('disk',), kwargs = {}

    def _object_meta_construct(cls, self, *args, **kwargs):
>     self.__init__(*args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:82: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_LightGlue(
  (input_proj): FlaxLinear(in_features=128, out_features=256, use_bias=True)
  (posenc): jax_LearnableFourierPositionalEncoding(
    (Wr): FlaxLinear(in_features=2, out_features=32, use_bias=False)
  )
)
args = ('disk',), kwargs = {}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/utils/decorator_utils.py:245: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_LightGlue(
  (input_proj): FlaxLinear(in_features=128, out_features=256, use_bias=True)
  (posenc): jax_LearnableFourierPositionalEncoding(
    (Wr): FlaxLinear(in_features=2, out_features=32, use_bias=False)
  )
)
features = 'disk', conf_ = {}, jax_KORNIA_CHECK = <function jax_KORNIA_CHECK at 0x7fa4e0d2d090>, jax_get_item = <function jax_get_item at 0x7fa4e0d57910>
jax_Identity = <class 'ivy_transpiled_outputs.jax_outputs.torch.nn.modules.linear.jax_Identity'>, jax_load_state_dict_from_url_frnt = <function jax_load_state_dict_from_url_frnt at 0x7fa4e0dac670>
jax_load_frnt = <function jax_load_frnt at 0x7fa4e0dac8b0>, ModuleList = <class 'ivy_transpiled_outputs.jax_outputs.torch.nn.modules.container.jax_ModuleList'>
FlaxLinear = <class 'ivy_transpiled_outputs.jax_outputs.jax__stateful_layers.FlaxLinear'>

    @jax_store_config_info
    def __init__(self, features="superpoint", **conf_):
        from ..core.check import jax_KORNIA_CHECK
        from ...ivy.functional.backends.jax.general import jax_get_item
        from ...torch.nn.modules.linear import jax_Identity
        from ...ivy.functional.frontends.torch.hub.hub import (
            jax_load_state_dict_from_url_frnt,
        )
        from ...ivy.functional.frontends.torch.serialization.serialization import (
            jax_load_frnt,
        )
        from ..core._backend import ModuleList
        from ...jax__stateful_layers import FlaxLinear
    
        self.super___init__(
            features=features,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        self.conf = conf = SimpleNamespace(**{**self.default_conf, **conf_})
        if features is not None:
            jax_KORNIA_CHECK(
                features in list(self.features.keys()), "Features keys are wrong"
            )
            for k, v in jax_get_item(self.features, features).items():
                setattr(conf, k, v)
        jax_KORNIA_CHECK(not (self.conf.add_scale_ori and self.conf.add_laf))
        if conf.input_dim != conf.descriptor_dim:
            self.input_proj = FlaxLinear(
                in_features=conf.input_dim,
                out_features=conf.descriptor_dim,
                use_bias=True,
            )
        else:
            self.input_proj = jax_Identity()
        head_dim = conf.descriptor_dim // conf.num_heads
        self.posenc = jax_LearnableFourierPositionalEncoding(
            2 + 2 * conf.add_scale_ori + 4 * conf.add_laf, head_dim, head_dim
        )
        h, n, d = conf.num_heads, conf.n_layers, conf.descriptor_dim
        ag__result_list_0 = []
        for _ in range(n):
>           res = jax_TransformerLayer(d, h, conf.flash)

ivy_transpiled_outputs/jax_outputs/kornia/feature/lightglue.py:1389: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.lightglue.jax_TransformerLayer'>, args = (256, 4, True), kwargs = {}

    def __call__(cls, *args: Any, **kwargs: Any) -> Any:
>     return _graph_node_meta_call(cls, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.lightglue.jax_TransformerLayer'>, args = (256, 4, True), kwargs = {}, node = jax_TransformerLayer()

    def _graph_node_meta_call(cls: tp.Type[G], *args, **kwargs) -> G:
      node = cls.__new__(cls, *args, **kwargs)
      vars(node)['_object__state'] = ObjectState()
>     cls._object_meta_construct(node, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:88: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.lightglue.jax_TransformerLayer'>, self = jax_TransformerLayer(), args = (256, 4, True), kwargs = {}

    def _object_meta_construct(cls, self, *args, **kwargs):
>     self.__init__(*args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:82: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_TransformerLayer(), args = (256, 4, True), kwargs = {}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/utils/decorator_utils.py:245: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_TransformerLayer(), args = (256, 4, True), kwargs = {}

    @jax_store_config_info
    def __init__(self, *args, **kwargs):
        self.super___init__(
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
>       self.self_attn = jax_SelfBlock(*args, **kwargs)

ivy_transpiled_outputs/jax_outputs/kornia/feature/lightglue.py:944: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.lightglue.jax_SelfBlock'>, args = (256, 4, True), kwargs = {}

    def __call__(cls, *args: Any, **kwargs: Any) -> Any:
>     return _graph_node_meta_call(cls, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.lightglue.jax_SelfBlock'>, args = (256, 4, True), kwargs = {}
node = jax_SelfBlock(
  (Wqkv): FlaxLinear(in_features=256, out_features=768, use_bias=True)
)

    def _graph_node_meta_call(cls: tp.Type[G], *args, **kwargs) -> G:
      node = cls.__new__(cls, *args, **kwargs)
      vars(node)['_object__state'] = ObjectState()
>     cls._object_meta_construct(node, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:88: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.lightglue.jax_SelfBlock'>, self = jax_SelfBlock(
  (Wqkv): FlaxLinear(in_features=256, out_features=768, use_bias=True)
)
args = (256, 4, True), kwargs = {}

    def _object_meta_construct(cls, self, *args, **kwargs):
>     self.__init__(*args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:82: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_SelfBlock(
  (Wqkv): FlaxLinear(in_features=256, out_features=768, use_bias=True)
), args = (256, 4, True), kwargs = {}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/utils/decorator_utils.py:245: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_SelfBlock(
  (Wqkv): FlaxLinear(in_features=256, out_features=768, use_bias=True)
), embed_dim = 256, num_heads = 4, flash = True, bias = True

    @jax_store_config_info
    def __init__(self, embed_dim, num_heads, flash=False, bias=True):
        from ..core.check import jax_KORNIA_CHECK
        from ...torch.nn.modules.container import jax_Sequential
        from ...torch.nn.modules.normalization import jax_LayerNorm
        from ...torch.nn.modules.activation import jax_GELU
        from ...jax__stateful_layers import FlaxLinear
    
        self.super___init__(
            embed_dim,
            num_heads,
            flash=flash,
            bias=bias,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        self.embed_dim = embed_dim
        self.num_heads = num_heads
        jax_KORNIA_CHECK(
            self.embed_dim % num_heads == 0,
            "Embed dimension should be dividable by num_heads",
        )
        self.head_dim = self.embed_dim // num_heads
        self.Wqkv = FlaxLinear(
            in_features=embed_dim, out_features=3 * embed_dim, use_bias=bias
        )
>       self.inner_attn = jax_Attention(flash)

ivy_transpiled_outputs/jax_outputs/kornia/feature/lightglue.py:588: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.lightglue.jax_Attention'>, args = (True,), kwargs = {}

    def __call__(cls, *args: Any, **kwargs: Any) -> Any:
>     return _graph_node_meta_call(cls, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.lightglue.jax_Attention'>, args = (True,), kwargs = {}, node = jax_Attention()

    def _graph_node_meta_call(cls: tp.Type[G], *args, **kwargs) -> G:
      node = cls.__new__(cls, *args, **kwargs)
      vars(node)['_object__state'] = ObjectState()
>     cls._object_meta_construct(node, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:88: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.lightglue.jax_Attention'>, self = jax_Attention(), args = (True,), kwargs = {}

    def _object_meta_construct(cls, self, *args, **kwargs):
>     self.__init__(*args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:82: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_Attention(), args = (True,), kwargs = {}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/utils/decorator_utils.py:245: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_Attention(), allow_flash = True

    @jax_store_config_info
    def __init__(self, allow_flash):
        self.super___init__(
            allow_flash,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        if allow_flash and not FLASH_AVAILABLE:
            warnings.warn(
                "FlashAttention is not available. For optimal speed, consider installing torch >= 2.0 or flash-attn.",
                stacklevel=2,
            )
        self.enable_flash = allow_flash and FLASH_AVAILABLE
>       self.has_sdp = hasattr(torch.nn.functional, "scaled_dot_product_attention")
E       NameError: name 'torch' is not defined

ivy_transpiled_outputs/jax_outputs/kornia/feature/lightglue.py:398: NameError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.LightGlueMatcher
Loaded LightGlue model
----------------------------------------------------------------------------------------- Captured stderr call -----------------------------------------------------------------------------------------
Downloading: "https://github.com/cvg/LightGlue/releases/download/v0.1_arxiv/disk_lightglue.pth" to /root/.cache/torch/hub/checkpoints/disk_lightglue_v0-1_arxiv-pth

  0%|          | 0.00/45.4M [00:00<?, ?B/s]
 66%|██████▌   | 29.9M/45.4M [00:00<00:00, 313MB/s]
100%|██████████| 45.4M/45.4M [00:00<00:00, 332MB/s]
____________________________________________________________________________________ test_LightGlue[jax-s2s-False] _____________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_LightGlue(target_framework, mode, backend_compile):
        print("kornia.feature.LightGlue")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target_framework)
    
        data = {
            "image0": {
                "keypoints": torch.rand(1, 100, 2),
                "descriptors": torch.rand(1, 100, 256),
                "image_size": torch.tensor([[640, 480]]),
            },
            "image1": {
                "keypoints": torch.rand(1, 120, 2),
                "descriptors": torch.rand(1, 120, 256),
                "image_size": torch.tensor([[640, 480]]),
            }
        }
        transpiled_data = _nest_torch_tensor_to_new_framework(data, target_framework)
    
        model = kornia.feature.LightGlue(features='superpoint')
>       torch_out = model(data)

kornia/test_feature4.py:293: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LightGlue(
  (input_proj): Identity()
  (posenc): LearnableFourierPositionalEncoding(
    (Wr): Linear(in_features=2, ... Sequential(
        (0): Linear(in_features=256, out_features=1, bias=True)
        (1): Sigmoid()
      )
    )
  )
)
args = ({'image0': {'descriptors': Array([[[0.714322  , 0.94986194, 0.64271957, ..., 0.60650766,
         0.4872803 , 0.17902...     [0.6694481 , 0.41656148],
        [0.05598414, 0.6844437 ],
        [0.48127216, 0.39866573]]], dtype=float32)}},)
kwargs = {}

    def _wrapped_call_impl(self, *args, **kwargs):
        if self._compiled_call_impl is not None:
            return self._compiled_call_impl(*args, **kwargs)  # type: ignore[misc]
        else:
>           return self._call_impl(*args, **kwargs)

/opt/fw/torch/torch/nn/modules/module.py:1736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LightGlue(
  (input_proj): Identity()
  (posenc): LearnableFourierPositionalEncoding(
    (Wr): Linear(in_features=2, ... Sequential(
        (0): Linear(in_features=256, out_features=1, bias=True)
        (1): Sigmoid()
      )
    )
  )
)
args = ({'image0': {'descriptors': Array([[[0.714322  , 0.94986194, 0.64271957, ..., 0.60650766,
         0.4872803 , 0.17902...     [0.6694481 , 0.41656148],
        [0.05598414, 0.6844437 ],
        [0.48127216, 0.39866573]]], dtype=float32)}},)
kwargs = {}

    def _call_impl(self, *args, **kwargs):
        forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)
        # If we don't have any hooks, we want to skip the rest of the logic in
        # this function, and just call forward.
        if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks
                or _global_backward_pre_hooks or _global_backward_hooks
                or _global_forward_hooks or _global_forward_pre_hooks):
>           return forward_call(*args, **kwargs)

/opt/fw/torch/torch/nn/modules/module.py:1747: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LightGlue(
  (input_proj): Identity()
  (posenc): LearnableFourierPositionalEncoding(
    (Wr): Linear(in_features=2, ... Sequential(
        (0): Linear(in_features=256, out_features=1, bias=True)
        (1): Sigmoid()
      )
    )
  )
)
data = {'image0': {'descriptors': Array([[[0.714322  , 0.94986194, 0.64271957, ..., 0.60650766,
         0.4872803 , 0.179029...       [0.6694481 , 0.41656148],
        [0.05598414, 0.6844437 ],
        [0.48127216, 0.39866573]]], dtype=float32)}}

    def forward(self, data: dict) -> dict:  # type: ignore
        """Match keypoints and descriptors between two images.
    
        Input (dict):
            image0: dict
                keypoints: [B x M x 2]
                descriptors: [B x M x D]
                image: [B x C x H x W] or image_size: [B x 2]
            image1: dict
                keypoints: [B x N x 2]
                descriptors: [B x N x D]
                image: [B x C x H x W] or image_size: [B x 2]
        Output (dict):
            log_assignment: [B x M+1 x N+1]
            matches0: [B x M]
            matching_scores0: [B x M]
            matches1: [B x N]
            matching_scores1: [B x N]
            matches: List[[Si x 2]], scores: List[[Si]]
        """
        with torch.autocast(enabled=self.conf.mp, device_type="cuda"):
>           return self._forward(data)

/opt/miniconda/envs/multienv/lib/python3.10/site-packages/kornia/feature/lightglue.py:497: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LightGlue(
  (input_proj): Identity()
  (posenc): LearnableFourierPositionalEncoding(
    (Wr): Linear(in_features=2, ... Sequential(
        (0): Linear(in_features=256, out_features=1, bias=True)
        (1): Sigmoid()
      )
    )
  )
)
data = {'image0': {'descriptors': Array([[[0.714322  , 0.94986194, 0.64271957, ..., 0.60650766,
         0.4872803 , 0.179029...       [0.6694481 , 0.41656148],
        [0.05598414, 0.6844437 ],
        [0.48127216, 0.39866573]]], dtype=float32)}}

    def _forward(self, data: dict) -> dict:  # type: ignore
        for key in self.required_data_keys:
            KORNIA_CHECK(key in data, f"Missing key {key} in data")
        data0, data1 = data["image0"], data["image1"]
        kpts0, kpts1 = data0["keypoints"], data1["keypoints"]
        b, m, _ = kpts0.shape
        b, n, _ = kpts1.shape
        device = kpts0.device
        size0, size1 = data0.get("image_size"), data1.get("image_size")
        size0 = size0 if size0 is not None else data0["image"].shape[-2:][::-1]
        size1 = size1 if size1 is not None else data1["image"].shape[-2:][::-1]
    
>       kpts0 = normalize_keypoints(kpts0, size0).clone()

/opt/miniconda/envs/multienv/lib/python3.10/site-packages/kornia/feature/lightglue.py:511: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (Array([[[0.92331445, 0.8850206 ],
        [0.48808086, 0.38892353],
        [0.68034923, 0.6688786 ],
        [0.0836...        [0.8821224 , 0.8414316 ],
        [0.01538849, 0.85459065]]], dtype=float32), Array([[640, 480]], dtype=int64))
kwargs = {}, autocast_context = False

    @functools.wraps(fwd)
    def decorate_fwd(*args, **kwargs):
        args[0]._dtype = torch.get_autocast_dtype(device_type)
        if cast_inputs is None:
            args[0]._fwd_used_autocast = torch.is_autocast_enabled(device_type)
            return fwd(*args, **kwargs)
        else:
            autocast_context = torch.is_autocast_enabled(device_type)
            args[0]._fwd_used_autocast = False
            if autocast_context:
                with autocast(device_type=device_type, enabled=False):
                    return fwd(
                        *_cast(args, device_type, cast_inputs),
                        **_cast(kwargs, device_type, cast_inputs),
                    )
            else:
>               return fwd(*args, **kwargs)

/opt/fw/torch/torch/amp/autocast_mode.py:476: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

kpts = Array([[[0.92331445, 0.8850206 ],
        [0.48808086, 0.38892353],
        [0.68034923, 0.6688786 ],
        [0.08363...
        [0.87604815, 0.9812926 ],
        [0.8821224 , 0.8414316 ],
        [0.01538849, 0.85459065]]], dtype=float32)
size = Array([[640, 480]], dtype=int64)

    @torch.cuda.amp.custom_fwd(cast_inputs=torch.float32)
    def normalize_keypoints(kpts: Tensor, size: Tensor) -> Tensor:
        if isinstance(size, torch.Size):
            size = Tensor(size)[None]
>       shift = size.float().to(kpts) / 2
E       AttributeError: 'jaxlib.xla_extension.ArrayImpl' object has no attribute 'float'. Did you mean: 'flat'?

/opt/miniconda/envs/multienv/lib/python3.10/site-packages/kornia/feature/lightglue.py:48: AttributeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.LightGlue
Loaded LightGlue model
----------------------------------------------------------------------------------------- Captured stderr call -----------------------------------------------------------------------------------------
Downloading: "https://github.com/cvg/LightGlue/releases/download/v0.1_arxiv/superpoint_lightglue.pth" to /root/.cache/torch/hub/checkpoints/superpoint_lightglue_v0-1_arxiv-pth

  0%|          | 0.00/45.3M [00:00<?, ?B/s]
 69%|██████▉   | 31.4M/45.3M [00:00<00:00, 328MB/s]
100%|██████████| 45.3M/45.3M [00:00<00:00, 342MB/s]
______________________________________________________________________________________ test_LoFTR[jax-s2s-False] _______________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_LoFTR(target_framework, mode, backend_compile):
        print("kornia.feature.LoFTR")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target_framework)
    
        data = {"image0": torch.rand(1, 1, 320, 200), "image1": torch.rand(1, 1, 128, 128)}
        transpiled_data = _nest_torch_tensor_to_new_framework(data, target_framework)
    
        model = kornia.feature.LoFTR(None)
>       torch_out = model(data)

kornia/test_feature4.py:320: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LoFTR(
  (backbone): ResNetFPN_8_2(
    (conv1): Conv2d(1, 128, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bia...   (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (fine_matching): FineMatching()
)
args = ({'image0': Array([[[[9.6524006e-01, 7.7067804e-01, 2.0074236e-01, ...,
          8.4428549e-01, 8.3258086e-01, 9.2652...
         [0.71909773, 0.5018965 , 0.36076152, ..., 0.66071683,
          0.37080932, 0.22152352]]]], dtype=float32)},)
kwargs = {}

    def _wrapped_call_impl(self, *args, **kwargs):
        if self._compiled_call_impl is not None:
            return self._compiled_call_impl(*args, **kwargs)  # type: ignore[misc]
        else:
>           return self._call_impl(*args, **kwargs)

/opt/fw/torch/torch/nn/modules/module.py:1736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LoFTR(
  (backbone): ResNetFPN_8_2(
    (conv1): Conv2d(1, 128, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bia...   (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (fine_matching): FineMatching()
)
args = ({'image0': Array([[[[9.6524006e-01, 7.7067804e-01, 2.0074236e-01, ...,
          8.4428549e-01, 8.3258086e-01, 9.2652...
         [0.71909773, 0.5018965 , 0.36076152, ..., 0.66071683,
          0.37080932, 0.22152352]]]], dtype=float32)},)
kwargs = {}

    def _call_impl(self, *args, **kwargs):
        forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)
        # If we don't have any hooks, we want to skip the rest of the logic in
        # this function, and just call forward.
        if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks
                or _global_backward_pre_hooks or _global_backward_hooks
                or _global_forward_hooks or _global_forward_pre_hooks):
>           return forward_call(*args, **kwargs)

/opt/fw/torch/torch/nn/modules/module.py:1747: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LoFTR(
  (backbone): ResNetFPN_8_2(
    (conv1): Conv2d(1, 128, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bia...   (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (fine_matching): FineMatching()
)
data = {'image0': Array([[[[9.6524006e-01, 7.7067804e-01, 2.0074236e-01, ...,
          8.4428549e-01, 8.3258086e-01, 9.26521...],
         [0.71909773, 0.5018965 , 0.36076152, ..., 0.66071683,
          0.37080932, 0.22152352]]]], dtype=float32)}

    def forward(self, data: dict[str, Tensor]) -> dict[str, Tensor]:
        """
        Args:
            data: dictionary containing the input data in the following format:
    
        Keyword Args:
            image0: left image with shape :math:`(N, 1, H1, W1)`.
            image1: right image with shape :math:`(N, 1, H2, W2)`.
            mask0 (optional): left image mask. '0' indicates a padded position :math:`(N, H1, W1)`.
            mask1 (optional): right image mask. '0' indicates a padded position :math:`(N, H2, W2)`.
    
        Returns:
            - ``keypoints0``, matching keypoints from image0 :math:`(NC, 2)`.
            - ``keypoints1``, matching keypoints from image1 :math:`(NC, 2)`.
            - ``confidence``, confidence score [0, 1] :math:`(NC)`.
            - ``batch_indexes``, batch indexes for the keypoints and lafs :math:`(NC)`.
        """
        # 1. Local Feature CNN
        _data: dict[str, Tensor | int | torch.Size] = {
>           "bs": data["image0"].size(0),
            "hw0_i": data["image0"].shape[2:],
            "hw1_i": data["image1"].shape[2:],
        }
E       TypeError: 'int' object is not callable

/opt/miniconda/envs/multienv/lib/python3.10/site-packages/kornia/feature/loftr/loftr.py:123: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.LoFTR
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/test_feature4.py::test_SIFTFeatureScaleSpace[jax-s2s-False] - TypeError: '<class 'jaxlib.xla_extension.ArrayImpl'>' object does not support item assignment. JAX arrays are immutable. ...
FAILED kornia/test_feature4.py::test_LocalFeatureMatcher[jax-s2s-False] - TypeError: Input input type is not a Tensor. Got <class 'jaxlib.xla_extension.ArrayImpl'>
FAILED kornia/test_feature4.py::test_LightGlueMatcher[jax-s2s-False] - NameError: name 'torch' is not defined
FAILED kornia/test_feature4.py::test_LightGlue[jax-s2s-False] - AttributeError: 'jaxlib.xla_extension.ArrayImpl' object has no attribute 'float'. Did you mean: 'flat'?
FAILED kornia/test_feature4.py::test_LoFTR[jax-s2s-False] - TypeError: 'int' object is not callable
=============================================================================== 5 failed, 9 passed in 2586.51s (0:43:06) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 14 items

kornia/test_feature4.py FFFF...FFFF...                                                                                                                                                           [100%]

=============================================================================================== FAILURES ===============================================================================================
________________________________________________________________________________ test_SIFTFeature[tensorflow-s2s-False] ________________________________________________________________________________

inp = <KerasVariable shape=(5, 1, 1), dtype=float32, path=variable>, query = slice(None, None, None)
val = <tf.Tensor: shape=(1, 5), dtype=float32, numpy=
array([[0.1190625 , 0.2311236 , 0.29962778, 0.2311236 , 0.1190625 ]],
      dtype=float32)>, kwargs = {}

    @functools.wraps(fn)
    def wrapper(inp, query, val, **kwargs):
        try:
>           inp.__setitem__(query, val)
E           AttributeError: 'Variable' object has no attribute '__setitem__'. Did you mean: '__getitem__'?

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:233: AttributeError

During handling of the above exception, another exception occurred:

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_SIFTFeature(target_framework, mode, backend_compile):
        print("kornia.feature.SIFTFeature")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target_framework)
    
        x = torch.rand(1, 1, 256, 256)
        transpiled_x = _nest_torch_tensor_to_new_framework(x, target_framework)
    
        model = kornia.feature.SIFTFeature(num_features=10)
        torch_out = model(x)
    
>       transpiled_model = transpiled_kornia.feature.SIFTFeature(num_features=10)

kornia/test_feature4.py:31: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:232: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_SIFTFeature object at 0x7f02d93d5390>, num_features = 10, upright = False, rootsift = True
device = 'cpu', config = {'nms_size': 15, 'pyramid_levels': 4, 's_mult': 22.0, 'scale_factor_levels': 1.4142135623730951, ...}

    def __init__(
        self,
        num_features=8000,
        upright=False,
        rootsift=True,
        device=tensorflow_device_frnt("cpu"),
        config=tensorflow_get_default_detector_config(),
    ):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_to_frnt_
        from .scale_space_detector import tensorflow_MultiResolutionDetector
        from .responses import tensorflow_BlobDoGSingle
        from .orientation import tensorflow_PassLAF
        from .orientation import tensorflow_LAFOrienter
        from .siftdesc import tensorflow_SIFTDescriptor
    
        patch_size: typing.Any = 41
        detector = tensorflow_to_frnt_(
            tensorflow_MultiResolutionDetector(
                tensorflow_BlobDoGSingle(1.0, 1.6),
                num_features,
                config,
                ori_module=tensorflow_PassLAF()
                if upright
>               else tensorflow_LAFOrienter(19),
                aff_module=tensorflow_PassLAF(),
            ),
            device,
        )

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/integrated.py:353: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'tensorflow_LAFOrienter' object has no attribute 'angle_detector'") raised in repr()] tensorflow_LAFOrienter object at 0x7f02d93d4a30>, args = (19,), kwargs = {}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'tensorflow_LAFOrienter' object has no attribute 'angle_detector'") raised in repr()] tensorflow_LAFOrienter object at 0x7f02d93d4a30>, patch_size = 19, num_angular_bins = 36
angle_detector = None

    @tensorflow_store_config_info
    def __init__(self, patch_size=32, num_angular_bins=36, angle_detector=None):
        self.super___init__(
            patch_size=patch_size,
            num_angular_bins=num_angular_bins,
            angle_detector=angle_detector,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        self.patch_size = patch_size
        self.num_ang_bins = num_angular_bins
        self.angle_detector: typing.Any
        if angle_detector is None:
>           self.angle_detector = tensorflow_PatchDominantGradientOrientation(
                self.patch_size, self.num_ang_bins
            )

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/orientation.py:387: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_PatchDominantGradientOrientation(patch_size=19, num_ang_bins=36, eps=1e-08), args = (19, 36), kwargs = {}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_PatchDominantGradientOrientation(patch_size=19, num_ang_bins=36, eps=1e-08), patch_size = 19, num_angular_bins = 36, eps = 1e-08

    @tensorflow_store_config_info
    def __init__(self, patch_size=32, num_angular_bins=36, eps=1e-08):
        from ..filters.sobel import tensorflow_SpatialGradient
        from ...torch.nn.modules.conv import tensorflow_Conv1d
        from ...ivy.functional.backends.tensorflow.general import tensorflow_set_item
        from ..filters.kernels import tensorflow_get_gaussian_discrete_kernel1d
        from ..filters.kernels import tensorflow_get_gaussian_kernel2d
    
        self.super___init__(
            patch_size=patch_size,
            num_angular_bins=num_angular_bins,
            eps=eps,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        self.patch_size = patch_size
        self.num_ang_bins = num_angular_bins
        self.gradient = tensorflow_SpatialGradient("sobel", 1)
        self.eps = eps
        self.angular_smooth = tensorflow_Conv1d(
            1, 1, kernel_size=5, padding=2, bias=False, padding_mode="circular"
        )
>       self.angular_smooth.weight = tensorflow_set_item(
            self.angular_smooth.weight,
            slice(None, None, None),
            tensorflow_get_gaussian_discrete_kernel1d(5, 1.6),
        )

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/orientation.py:178: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

inp = <KerasVariable shape=(5, 1, 1), dtype=float32, path=variable>, query = slice(None, None, None)
val = <tf.Tensor: shape=(1, 5), dtype=float32, numpy=
array([[0.1190625 , 0.2311236 , 0.29962778, 0.2311236 , 0.1190625 ]],
      dtype=float32)>, kwargs = {}

    @functools.wraps(fn)
    def wrapper(inp, query, val, **kwargs):
        try:
            inp.__setitem__(query, val)
            res = inp
        except IndexError:
            raise
        except Exception:
>           res = fn(inp, query, val, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:238: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (<KerasVariable shape=(5, 1, 1), dtype=float32, path=variable>, slice(None, None, None), <tf.Tensor: shape=(1, 5), dtype=float32, numpy=
array([[0.1190625 , 0.2311236 , 0.29962778, 0.2311236 , 0.1190625 ]],
      dtype=float32)>)
kwargs = {}, handle_mixed_in_backend = True

    @functools.wraps(fn)
    def _handle_partial_mixed_function(*args, **kwargs):
        handle_mixed_in_backend = False
        if not hasattr(fn, "partial_mixed_handler"):
            handle_mixed_in_backend = True
        else:
            compos = getattr(fn, "compos")
            condition = getattr(fn, "partial_mixed_handler")
        if handle_mixed_in_backend or condition(*args, **kwargs):
>           return fn(*args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/func_wrapper.py:173: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[0.]],

       [[0.]],

       [[0.]],

       [[0.]],

       [[0.]]], dtype=float32), query = slice(None, None, None)
val = array([[0.1190625 , 0.2311236 , 0.29962778, 0.2311236 , 0.1190625 ]],
      dtype=float32)

    @tensorflow_handle_set_item
    @tensorflow_handle_partial_mixed_function
    def tensorflow_set_item(
        x: Union[tensorflow.Tensor, tensorflow.Variable],
        query: Union[tensorflow.Tensor, tensorflow.Variable, Tuple],
        val: Union[tensorflow.Tensor, tensorflow.Variable],
        /,
        *,
        copy: Optional[bool] = False,
    ):
        if tensorflow.is_tensor(x):
            x = x.numpy()
        if tensorflow.is_tensor(val):
            val = val.numpy()
        if isinstance(query, (tensorflow.Tensor, tensorflow.Variable)):
            query = query.numpy()
        elif isinstance(query, tuple):
            query = tuple(
                q.numpy() if isinstance(q, (tensorflow.Tensor, tensorflow.Variable)) else q
                for q in query
            )
>       x[query] = val
E       ValueError: could not broadcast input array from shape (1,5) into shape (5,1,1)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/backends/tensorflow/general.py:109: ValueError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.SIFTFeature
___________________________________________________________________________ test_SIFTFeatureScaleSpace[tensorflow-s2s-False] ___________________________________________________________________________

inp = <KerasVariable shape=(5, 1, 1), dtype=float32, path=variable_1>, query = slice(None, None, None)
val = <tf.Tensor: shape=(1, 5), dtype=float32, numpy=
array([[0.1190625 , 0.2311236 , 0.29962778, 0.2311236 , 0.1190625 ]],
      dtype=float32)>, kwargs = {}

    @functools.wraps(fn)
    def wrapper(inp, query, val, **kwargs):
        try:
>           inp.__setitem__(query, val)
E           AttributeError: 'Variable' object has no attribute '__setitem__'. Did you mean: '__getitem__'?

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:233: AttributeError

During handling of the above exception, another exception occurred:

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_SIFTFeatureScaleSpace(target_framework, mode, backend_compile):
        print("kornia.feature.SIFTFeatureScaleSpace")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target_framework)
    
        x = torch.rand(1, 1, 256, 256)
        transpiled_x = _nest_torch_tensor_to_new_framework(x, target_framework)
    
        model = kornia.feature.SIFTFeatureScaleSpace(num_features=10)
        torch_out = model(x)
    
>       transpiled_model = transpiled_kornia.feature.SIFTFeatureScaleSpace(num_features=10)

kornia/test_feature4.py:57: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:232: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_SIFTFeatureScaleSpace object at 0x7f02cfa00c70>, num_features = 10, upright = False, rootsift = True
device = 'cpu'

    def __init__(
        self,
        num_features=8000,
        upright=False,
        rootsift=True,
        device=tensorflow_device_frnt("cpu"),
    ):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_to_frnt_
        from .scale_space_detector import tensorflow_ScaleSpaceDetector
        from .responses import tensorflow_BlobDoG
        from ..geometry.subpix.spatial_soft_argmax import tensorflow_ConvQuadInterp3d
        from ..geometry.transform.pyramid import tensorflow_ScalePyramid
        from .orientation import tensorflow_PassLAF
        from .orientation import tensorflow_LAFOrienter
        from .siftdesc import tensorflow_SIFTDescriptor
    
        patch_size: typing.Any = 41
        detector = tensorflow_to_frnt_(
            tensorflow_ScaleSpaceDetector(
                num_features,
                resp_module=tensorflow_BlobDoG(),
                nms_module=tensorflow_ConvQuadInterp3d(10),
                scale_pyr_module=tensorflow_ScalePyramid(3, 1.6, 32, double_image=True),
                ori_module=tensorflow_PassLAF()
                if upright
>               else tensorflow_LAFOrienter(19),
                scale_space_response=True,
                minima_are_also_good=True,
                mr_size=6.0,
            ),
            device,
        )

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/integrated.py:354: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'tensorflow_LAFOrienter' object has no attribute 'angle_detector'") raised in repr()] tensorflow_LAFOrienter object at 0x7f02cfa02770>, args = (19,), kwargs = {}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'tensorflow_LAFOrienter' object has no attribute 'angle_detector'") raised in repr()] tensorflow_LAFOrienter object at 0x7f02cfa02770>, patch_size = 19, num_angular_bins = 36
angle_detector = None

    @tensorflow_store_config_info
    def __init__(self, patch_size=32, num_angular_bins=36, angle_detector=None):
        self.super___init__(
            patch_size=patch_size,
            num_angular_bins=num_angular_bins,
            angle_detector=angle_detector,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        self.patch_size = patch_size
        self.num_ang_bins = num_angular_bins
        self.angle_detector: typing.Any
        if angle_detector is None:
>           self.angle_detector = tensorflow_PatchDominantGradientOrientation(
                self.patch_size, self.num_ang_bins
            )

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/orientation.py:387: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_PatchDominantGradientOrientation(patch_size=19, num_ang_bins=36, eps=1e-08), args = (19, 36), kwargs = {}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_PatchDominantGradientOrientation(patch_size=19, num_ang_bins=36, eps=1e-08), patch_size = 19, num_angular_bins = 36, eps = 1e-08

    @tensorflow_store_config_info
    def __init__(self, patch_size=32, num_angular_bins=36, eps=1e-08):
        from ..filters.sobel import tensorflow_SpatialGradient
        from ...torch.nn.modules.conv import tensorflow_Conv1d
        from ...ivy.functional.backends.tensorflow.general import tensorflow_set_item
        from ..filters.kernels import tensorflow_get_gaussian_discrete_kernel1d
        from ..filters.kernels import tensorflow_get_gaussian_kernel2d
    
        self.super___init__(
            patch_size=patch_size,
            num_angular_bins=num_angular_bins,
            eps=eps,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        self.patch_size = patch_size
        self.num_ang_bins = num_angular_bins
        self.gradient = tensorflow_SpatialGradient("sobel", 1)
        self.eps = eps
        self.angular_smooth = tensorflow_Conv1d(
            1, 1, kernel_size=5, padding=2, bias=False, padding_mode="circular"
        )
>       self.angular_smooth.weight = tensorflow_set_item(
            self.angular_smooth.weight,
            slice(None, None, None),
            tensorflow_get_gaussian_discrete_kernel1d(5, 1.6),
        )

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/orientation.py:178: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

inp = <KerasVariable shape=(5, 1, 1), dtype=float32, path=variable_1>, query = slice(None, None, None)
val = <tf.Tensor: shape=(1, 5), dtype=float32, numpy=
array([[0.1190625 , 0.2311236 , 0.29962778, 0.2311236 , 0.1190625 ]],
      dtype=float32)>, kwargs = {}

    @functools.wraps(fn)
    def wrapper(inp, query, val, **kwargs):
        try:
            inp.__setitem__(query, val)
            res = inp
        except IndexError:
            raise
        except Exception:
>           res = fn(inp, query, val, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:238: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (<KerasVariable shape=(5, 1, 1), dtype=float32, path=variable_1>, slice(None, None, None), <tf.Tensor: shape=(1, 5), dtype=float32, numpy=
array([[0.1190625 , 0.2311236 , 0.29962778, 0.2311236 , 0.1190625 ]],
      dtype=float32)>)
kwargs = {}, handle_mixed_in_backend = True

    @functools.wraps(fn)
    def _handle_partial_mixed_function(*args, **kwargs):
        handle_mixed_in_backend = False
        if not hasattr(fn, "partial_mixed_handler"):
            handle_mixed_in_backend = True
        else:
            compos = getattr(fn, "compos")
            condition = getattr(fn, "partial_mixed_handler")
        if handle_mixed_in_backend or condition(*args, **kwargs):
>           return fn(*args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/func_wrapper.py:173: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[0.]],

       [[0.]],

       [[0.]],

       [[0.]],

       [[0.]]], dtype=float32), query = slice(None, None, None)
val = array([[0.1190625 , 0.2311236 , 0.29962778, 0.2311236 , 0.1190625 ]],
      dtype=float32)

    @tensorflow_handle_set_item
    @tensorflow_handle_partial_mixed_function
    def tensorflow_set_item(
        x: Union[tensorflow.Tensor, tensorflow.Variable],
        query: Union[tensorflow.Tensor, tensorflow.Variable, Tuple],
        val: Union[tensorflow.Tensor, tensorflow.Variable],
        /,
        *,
        copy: Optional[bool] = False,
    ):
        if tensorflow.is_tensor(x):
            x = x.numpy()
        if tensorflow.is_tensor(val):
            val = val.numpy()
        if isinstance(query, (tensorflow.Tensor, tensorflow.Variable)):
            query = query.numpy()
        elif isinstance(query, tuple):
            query = tuple(
                q.numpy() if isinstance(q, (tensorflow.Tensor, tensorflow.Variable)) else q
                for q in query
            )
>       x[query] = val
E       ValueError: could not broadcast input array from shape (1,5) into shape (5,1,1)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/backends/tensorflow/general.py:109: ValueError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.SIFTFeatureScaleSpace
_____________________________________________________________________________ test_GFTTAffNetHardNet[tensorflow-s2s-False] _____________________________________________________________________________

inp = <KerasVariable shape=(5, 1, 1), dtype=float32, path=variable_2>, query = slice(None, None, None)
val = <tf.Tensor: shape=(1, 5), dtype=float32, numpy=
array([[0.1190625 , 0.2311236 , 0.29962778, 0.2311236 , 0.1190625 ]],
      dtype=float32)>, kwargs = {}

    @functools.wraps(fn)
    def wrapper(inp, query, val, **kwargs):
        try:
>           inp.__setitem__(query, val)
E           AttributeError: 'Variable' object has no attribute '__setitem__'. Did you mean: '__getitem__'?

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:233: AttributeError

During handling of the above exception, another exception occurred:

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_GFTTAffNetHardNet(target_framework, mode, backend_compile):
        print("kornia.feature.GFTTAffNetHardNet")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target_framework)
    
        x = torch.rand(1, 1, 256, 256)
        transpiled_x = _nest_torch_tensor_to_new_framework(x, target_framework)
    
        model = kornia.feature.GFTTAffNetHardNet(num_features=10)
        torch_out = model(x)
    
>       transpiled_model = transpiled_kornia.feature.GFTTAffNetHardNet(num_features=10)

kornia/test_feature4.py:83: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:232: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_GFTTAffNetHardNet object at 0x7f02d9cbcac0>, num_features = 10, upright = False, device = 'cpu'
config = {'nms_size': 15, 'pyramid_levels': 4, 's_mult': 22.0, 'scale_factor_levels': 1.4142135623730951, ...}

    def __init__(
        self,
        num_features=8000,
        upright=False,
        device=tensorflow_device_frnt("cpu"),
        config=tensorflow_get_default_detector_config(),
    ):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_to_frnt_
        from .scale_space_detector import tensorflow_MultiResolutionDetector
        from .responses import tensorflow_CornerGFTT
        from .orientation import tensorflow_PassLAF
        from .orientation import tensorflow_LAFOrienter
        from .affine_shape import tensorflow_LAFAffNetShapeEstimator
    
        detector = tensorflow_to_frnt_(
            tensorflow_MultiResolutionDetector(
                tensorflow_CornerGFTT(),
                num_features,
                config,
                ori_module=tensorflow_PassLAF()
                if upright
>               else tensorflow_LAFOrienter(19),
                aff_module=tensorflow_LAFAffNetShapeEstimator(True).eval(),
            ),
            device,
        )

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/integrated.py:351: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'tensorflow_LAFOrienter' object has no attribute 'angle_detector'") raised in repr()] tensorflow_LAFOrienter object at 0x7f02d9cbf430>, args = (19,), kwargs = {}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'tensorflow_LAFOrienter' object has no attribute 'angle_detector'") raised in repr()] tensorflow_LAFOrienter object at 0x7f02d9cbf430>, patch_size = 19, num_angular_bins = 36
angle_detector = None

    @tensorflow_store_config_info
    def __init__(self, patch_size=32, num_angular_bins=36, angle_detector=None):
        self.super___init__(
            patch_size=patch_size,
            num_angular_bins=num_angular_bins,
            angle_detector=angle_detector,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        self.patch_size = patch_size
        self.num_ang_bins = num_angular_bins
        self.angle_detector: typing.Any
        if angle_detector is None:
>           self.angle_detector = tensorflow_PatchDominantGradientOrientation(
                self.patch_size, self.num_ang_bins
            )

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/orientation.py:387: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_PatchDominantGradientOrientation(patch_size=19, num_ang_bins=36, eps=1e-08), args = (19, 36), kwargs = {}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_PatchDominantGradientOrientation(patch_size=19, num_ang_bins=36, eps=1e-08), patch_size = 19, num_angular_bins = 36, eps = 1e-08

    @tensorflow_store_config_info
    def __init__(self, patch_size=32, num_angular_bins=36, eps=1e-08):
        from ..filters.sobel import tensorflow_SpatialGradient
        from ...torch.nn.modules.conv import tensorflow_Conv1d
        from ...ivy.functional.backends.tensorflow.general import tensorflow_set_item
        from ..filters.kernels import tensorflow_get_gaussian_discrete_kernel1d
        from ..filters.kernels import tensorflow_get_gaussian_kernel2d
    
        self.super___init__(
            patch_size=patch_size,
            num_angular_bins=num_angular_bins,
            eps=eps,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        self.patch_size = patch_size
        self.num_ang_bins = num_angular_bins
        self.gradient = tensorflow_SpatialGradient("sobel", 1)
        self.eps = eps
        self.angular_smooth = tensorflow_Conv1d(
            1, 1, kernel_size=5, padding=2, bias=False, padding_mode="circular"
        )
>       self.angular_smooth.weight = tensorflow_set_item(
            self.angular_smooth.weight,
            slice(None, None, None),
            tensorflow_get_gaussian_discrete_kernel1d(5, 1.6),
        )

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/orientation.py:178: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

inp = <KerasVariable shape=(5, 1, 1), dtype=float32, path=variable_2>, query = slice(None, None, None)
val = <tf.Tensor: shape=(1, 5), dtype=float32, numpy=
array([[0.1190625 , 0.2311236 , 0.29962778, 0.2311236 , 0.1190625 ]],
      dtype=float32)>, kwargs = {}

    @functools.wraps(fn)
    def wrapper(inp, query, val, **kwargs):
        try:
            inp.__setitem__(query, val)
            res = inp
        except IndexError:
            raise
        except Exception:
>           res = fn(inp, query, val, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:238: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (<KerasVariable shape=(5, 1, 1), dtype=float32, path=variable_2>, slice(None, None, None), <tf.Tensor: shape=(1, 5), dtype=float32, numpy=
array([[0.1190625 , 0.2311236 , 0.29962778, 0.2311236 , 0.1190625 ]],
      dtype=float32)>)
kwargs = {}, handle_mixed_in_backend = True

    @functools.wraps(fn)
    def _handle_partial_mixed_function(*args, **kwargs):
        handle_mixed_in_backend = False
        if not hasattr(fn, "partial_mixed_handler"):
            handle_mixed_in_backend = True
        else:
            compos = getattr(fn, "compos")
            condition = getattr(fn, "partial_mixed_handler")
        if handle_mixed_in_backend or condition(*args, **kwargs):
>           return fn(*args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/func_wrapper.py:173: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[0.]],

       [[0.]],

       [[0.]],

       [[0.]],

       [[0.]]], dtype=float32), query = slice(None, None, None)
val = array([[0.1190625 , 0.2311236 , 0.29962778, 0.2311236 , 0.1190625 ]],
      dtype=float32)

    @tensorflow_handle_set_item
    @tensorflow_handle_partial_mixed_function
    def tensorflow_set_item(
        x: Union[tensorflow.Tensor, tensorflow.Variable],
        query: Union[tensorflow.Tensor, tensorflow.Variable, Tuple],
        val: Union[tensorflow.Tensor, tensorflow.Variable],
        /,
        *,
        copy: Optional[bool] = False,
    ):
        if tensorflow.is_tensor(x):
            x = x.numpy()
        if tensorflow.is_tensor(val):
            val = val.numpy()
        if isinstance(query, (tensorflow.Tensor, tensorflow.Variable)):
            query = query.numpy()
        elif isinstance(query, tuple):
            query = tuple(
                q.numpy() if isinstance(q, (tensorflow.Tensor, tensorflow.Variable)) else q
                for q in query
            )
>       x[query] = val
E       ValueError: could not broadcast input array from shape (1,5) into shape (5,1,1)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/backends/tensorflow/general.py:109: ValueError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.GFTTAffNetHardNet
----------------------------------------------------------------------------------------- Captured stderr call -----------------------------------------------------------------------------------------
Downloading: "https://github.com/ducha-aiki/affnet/raw/master/pretrained/AffNet.pth" to /root/.cache/torch/hub/checkpoints/AffNet.pth

  0%|          | 0.00/332k [00:00<?, ?B/s]
100%|██████████| 332k/332k [00:00<00:00, 80.5MB/s]
Downloading: "https://github.com/DagnyT/hardnet/raw/master/pretrained/train_liberty_with_aug/checkpoint_liberty_with_aug.pth" to /root/.cache/torch/hub/checkpoints/checkpoint_liberty_with_aug.pth

  0%|          | 0.00/5.10M [00:00<?, ?B/s]
100%|██████████| 5.10M/5.10M [00:00<00:00, 260MB/s]
____________________________________________________________________________ test_KeyNetAffNetHardNet[tensorflow-s2s-False] ____________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_KeyNetAffNetHardNet(target_framework, mode, backend_compile):
        print("kornia.feature.KeyNetAffNetHardNet")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target_framework)
    
        x = torch.rand(1, 1, 256, 256)
        transpiled_x = _nest_torch_tensor_to_new_framework(x, target_framework)
    
        model = kornia.feature.KeyNetAffNetHardNet(num_features=10)
        torch_out = model(x)
    
        transpiled_model = transpiled_kornia.feature.KeyNetAffNetHardNet(num_features=10)
        if target_framework == "tensorflow":
            # build the layers
            transpiled_model(transpiled_x)
    
        ivy.sync_models(model, transpiled_model)
    
        transpiled_out = transpiled_model(transpiled_x)
    
>       _to_numpy_and_allclose(torch_out, transpiled_out)

kornia/test_feature4.py:118: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

torch_x = (tensor([[[[ -5.0818,  15.1595,  79.2044],
          [-14.9895,  -2.9161,  16.9724]],

         [[ 15.1094,  -2.3789, ...47, -0.0613],
         [ 0.0892,  0.1085, -0.0070,  ...,  0.1280, -0.0506,  0.0509]]],
       grad_fn=<ViewBackward0>))
transpiled_x = (<tf.Tensor: shape=(1, 10, 2, 3), dtype=float32, numpy=
array([[[[ -5.0818343,  15.159506 ,  79.20442  ],
         [-1...       [ 0.08917049,  0.10852774, -0.0069594 , ...,  0.12789749,
         -0.05058575,  0.05099777]]], dtype=float32)>)
tolerance = 0.001

    def _to_numpy_and_allclose(torch_x, transpiled_x, tolerance=1e-3):
        orig_data = _nest_array_to_numpy(torch_x)
        transpiled_data = _nest_array_to_numpy(transpiled_x)
>       _check_allclose(orig_data, transpiled_data, tolerance=tolerance)

helpers.py:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = (array([[[[ -5.0817957,  15.159498 ,  79.20442  ],
         [-14.989458 ,  -2.9161098,  16.972376 ]],

        [[ 15.1...        [ 0.08915276,  0.10850985, -0.00698939, ...,  0.12797466,
         -0.05055413,  0.05093056]]], dtype=float32))
y = (array([[[[ -5.0818343,  15.159506 ,  79.20442  ],
         [-14.9894285,  -2.9161432,  16.972376 ]],

        [[ 15.1...        [ 0.08917049,  0.10852774, -0.0069594 , ...,  0.12789749,
         -0.05058575,  0.05099777]]], dtype=float32))
tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
            assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
            return
    
        if isinstance(x, (list, set, tuple)):
>           all([
                _check_allclose(element_x, element_y, tolerance=tolerance) for element_x, element_y in zip(x, y)
            ])

helpers.py:30: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

.0 = <zip object at 0x7f02d8c1e400>

    all([
>       _check_allclose(element_x, element_y, tolerance=tolerance) for element_x, element_y in zip(x, y)
    ])

helpers.py:31: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[[ -5.0817957,  15.159498 ,  79.20442  ],
         [-14.989458 ,  -2.9161098,  16.972376 ]],

        [[ 15.10...

        [[-16.664885 , -12.420581 ,  45.       ],
         [ 12.82451  , -19.48482  , 160.       ]]]], dtype=float32)
y = array([[[[ -5.0818343,  15.159506 ,  79.20442  ],
         [-14.9894285,  -2.9161432,  16.972376 ]],

        [[ 15.10...

        [[-16.665071 , -12.420332 ,  45.       ],
         [ 12.824217 , -19.485004 , 160.       ]]]], dtype=float32)
tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
>           assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
E           AssertionError: numpy array values are not all close

helpers.py:26: AssertionError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.KeyNetAffNetHardNet
All parameters and buffers are now synced!
----------------------------------------------------------------------------------------- Captured stderr call -----------------------------------------------------------------------------------------
Downloading: "https://github.com/ducha-aiki/affnet/raw/master/pretrained/OriNet.pth" to /root/.cache/torch/hub/checkpoints/OriNet.pth

  0%|          | 0.00/316k [00:00<?, ?B/s]
100%|██████████| 316k/316k [00:00<00:00, 76.0MB/s]
Downloading: "https://github.com/axelBarroso/Key.Net-Pytorch/raw/main/model/weights/keynet_pytorch.pth" to /root/.cache/torch/hub/checkpoints/keynet_pytorch.pth

  0%|          | 0.00/78.0k [00:00<?, ?B/s]
100%|██████████| 78.0k/78.0k [00:00<00:00, 29.4MB/s]
____________________________________________________________________________ test_LocalFeatureMatcher[tensorflow-s2s-False] ____________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_LocalFeatureMatcher(target_framework, mode, backend_compile):
        print("kornia.feature.LocalFeatureMatcher")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target_framework)
    
        data = {
            "image0": torch.rand(1, 1, 320, 200),
            "image1": torch.rand(1, 1, 128, 128),
        }
        transpiled_data = _nest_torch_tensor_to_new_framework(data, target_framework)
    
        torch_local_feature = kornia.feature.GFTTAffNetHardNet(10)
        torch_matcher = kornia.feature.DescriptorMatcher('snn', 0.8)
        model = kornia.feature.LocalFeatureMatcher(torch_local_feature, torch_matcher)
>       torch_out = model(data)

kornia/test_feature4.py:223: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalFeatureMatcher(
  (local_feature): GFTTAffNetHardNet(
    (detector): MultiResolutionDetector(
      (model): Cor...ck_running_stats=True)
      )
    ), patch_size=32, grayscale_descriptor='True)
  )
  (matcher): DescriptorMatcher()
)
args = ({'image0': <tf.Tensor: shape=(1, 1, 320, 200), dtype=float32, numpy=
array([[[[0.6048078 , 0.11149019, 0.04408693, .....         [0.09654427, 0.33094525, 0.7803678 , ..., 0.11766434,
          0.6944086 , 0.6931563 ]]]], dtype=float32)>},)
kwargs = {}

    def _wrapped_call_impl(self, *args, **kwargs):
        if self._compiled_call_impl is not None:
            return self._compiled_call_impl(*args, **kwargs)  # type: ignore[misc]
        else:
>           return self._call_impl(*args, **kwargs)

/opt/fw/torch/torch/nn/modules/module.py:1736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalFeatureMatcher(
  (local_feature): GFTTAffNetHardNet(
    (detector): MultiResolutionDetector(
      (model): Cor...ck_running_stats=True)
      )
    ), patch_size=32, grayscale_descriptor='True)
  )
  (matcher): DescriptorMatcher()
)
args = ({'image0': <tf.Tensor: shape=(1, 1, 320, 200), dtype=float32, numpy=
array([[[[0.6048078 , 0.11149019, 0.04408693, .....         [0.09654427, 0.33094525, 0.7803678 , ..., 0.11766434,
          0.6944086 , 0.6931563 ]]]], dtype=float32)>},)
kwargs = {}

    def _call_impl(self, *args, **kwargs):
        forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)
        # If we don't have any hooks, we want to skip the rest of the logic in
        # this function, and just call forward.
        if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks
                or _global_backward_pre_hooks or _global_backward_hooks
                or _global_forward_hooks or _global_forward_pre_hooks):
>           return forward_call(*args, **kwargs)

/opt/fw/torch/torch/nn/modules/module.py:1747: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalFeatureMatcher(
  (local_feature): GFTTAffNetHardNet(
    (detector): MultiResolutionDetector(
      (model): Cor...ck_running_stats=True)
      )
    ), patch_size=32, grayscale_descriptor='True)
  )
  (matcher): DescriptorMatcher()
)
data = {'image0': <tf.Tensor: shape=(1, 1, 320, 200), dtype=float32, numpy=
array([[[[0.6048078 , 0.11149019, 0.04408693, ......,
         [0.09654427, 0.33094525, 0.7803678 , ..., 0.11766434,
          0.6944086 , 0.6931563 ]]]], dtype=float32)>}

    def forward(self, data: Dict[str, Tensor]) -> Dict[str, Tensor]:
        """
        Args:
            data: dictionary containing the input data in the following format:
    
        Keyword Args:
            image0: left image with shape :math:`(N, 1, H1, W1)`.
            image1: right image with shape :math:`(N, 1, H2, W2)`.
            mask0 (optional): left image mask. '0' indicates a padded position :math:`(N, H1, W1)`.
            mask1 (optional): right image mask. '0' indicates a padded position :math:`(N, H2, W2)`.
    
        Returns:
            - ``keypoints0``, matching keypoints from image0 :math:`(NC, 2)`.
            - ``keypoints1``, matching keypoints from image1 :math:`(NC, 2)`.
            - ``confidence``, confidence score [0, 1] :math:`(NC)`.
            - ``lafs0``, matching LAFs from image0 :math:`(1, NC, 2, 3)`.
            - ``lafs1``, matching LAFs from image1 :math:`(1, NC, 2, 3)`.
            - ``batch_indexes``, batch indexes for the keypoints and lafs :math:`(NC)`.
        """
        num_image_pairs: int = data["image0"].shape[0]
    
        if ("lafs0" not in data.keys()) or ("descriptors0" not in data.keys()):
            # One can supply pre-extracted local features
>           feats_dict0: Dict[str, Tensor] = self.extract_features(data["image0"])

/opt/miniconda/envs/multienv/lib/python3.10/site-packages/kornia/feature/integrated.py:349: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalFeatureMatcher(
  (local_feature): GFTTAffNetHardNet(
    (detector): MultiResolutionDetector(
      (model): Cor...ck_running_stats=True)
      )
    ), patch_size=32, grayscale_descriptor='True)
  )
  (matcher): DescriptorMatcher()
)
image = <tf.Tensor: shape=(1, 1, 320, 200), dtype=float32, numpy=
array([[[[0.6048078 , 0.11149019, 0.04408693, ..., 0.8570821...],
         [0.02635199, 0.0848912 , 0.9472018 , ..., 0.26334184,
          0.93338   , 0.53244853]]]], dtype=float32)>
mask = None

    def extract_features(self, image: Tensor, mask: Optional[Tensor] = None) -> Dict[str, Tensor]:
        """Function for feature extraction from simple image."""
>       lafs0, resps0, descs0 = self.local_feature(image, mask)

/opt/miniconda/envs/multienv/lib/python3.10/site-packages/kornia/feature/integrated.py:313: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = GFTTAffNetHardNet(
  (detector): MultiResolutionDetector(
    (model): CornerGFTT(grads_mode=sobel)
    (nms): NonMaxi...ps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    )
  ), patch_size=32, grayscale_descriptor='True)
)
args = (<tf.Tensor: shape=(1, 1, 320, 200), dtype=float32, numpy=
array([[[[0.6048078 , 0.11149019, 0.04408693, ..., 0.857082...     [0.02635199, 0.0848912 , 0.9472018 , ..., 0.26334184,
          0.93338   , 0.53244853]]]], dtype=float32)>, None)
kwargs = {}

    def _wrapped_call_impl(self, *args, **kwargs):
        if self._compiled_call_impl is not None:
            return self._compiled_call_impl(*args, **kwargs)  # type: ignore[misc]
        else:
>           return self._call_impl(*args, **kwargs)

/opt/fw/torch/torch/nn/modules/module.py:1736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = GFTTAffNetHardNet(
  (detector): MultiResolutionDetector(
    (model): CornerGFTT(grads_mode=sobel)
    (nms): NonMaxi...ps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    )
  ), patch_size=32, grayscale_descriptor='True)
)
args = (<tf.Tensor: shape=(1, 1, 320, 200), dtype=float32, numpy=
array([[[[0.6048078 , 0.11149019, 0.04408693, ..., 0.857082...     [0.02635199, 0.0848912 , 0.9472018 , ..., 0.26334184,
          0.93338   , 0.53244853]]]], dtype=float32)>, None)
kwargs = {}

    def _call_impl(self, *args, **kwargs):
        forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)
        # If we don't have any hooks, we want to skip the rest of the logic in
        # this function, and just call forward.
        if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks
                or _global_backward_pre_hooks or _global_backward_hooks
                or _global_forward_hooks or _global_forward_pre_hooks):
>           return forward_call(*args, **kwargs)

/opt/fw/torch/torch/nn/modules/module.py:1747: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = GFTTAffNetHardNet(
  (detector): MultiResolutionDetector(
    (model): CornerGFTT(grads_mode=sobel)
    (nms): NonMaxi...ps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    )
  ), patch_size=32, grayscale_descriptor='True)
)
img = <tf.Tensor: shape=(1, 1, 320, 200), dtype=float32, numpy=
array([[[[0.6048078 , 0.11149019, 0.04408693, ..., 0.8570821...],
         [0.02635199, 0.0848912 , 0.9472018 , ..., 0.26334184,
          0.93338   , 0.53244853]]]], dtype=float32)>
mask = None

    def forward(self, img: Tensor, mask: Optional[Tensor] = None) -> Tuple[Tensor, Tensor, Tensor]:
        """
        Args:
            img: image to extract features with shape :math:`(B,C,H,W)`.
            mask: a mask with weights where to apply the response function.
                The shape must be the same as the input image.
    
        Returns:
            - Detected local affine frames with shape :math:`(B,N,2,3)`.
            - Response function values for corresponding lafs with shape :math:`(B,N,1)`.
            - Local descriptors of shape :math:`(B,N,D)` where :math:`D` is descriptor size.
        """
>       lafs, responses = self.detector(img, mask)

/opt/miniconda/envs/multienv/lib/python3.10/site-packages/kornia/feature/integrated.py:139: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = MultiResolutionDetector(
  (model): CornerGFTT(grads_mode=sobel)
  (nms): NonMaximaSuppression2d()
  (ori): LAFOriente...d(64, 3, kernel_size=(8, 8), stride=(1, 1))
      (20): Tanh()
      (21): AdaptiveAvgPool2d(output_size=1)
    )
  )
)
args = (<tf.Tensor: shape=(1, 1, 320, 200), dtype=float32, numpy=
array([[[[0.6048078 , 0.11149019, 0.04408693, ..., 0.857082...     [0.02635199, 0.0848912 , 0.9472018 , ..., 0.26334184,
          0.93338   , 0.53244853]]]], dtype=float32)>, None)
kwargs = {}

    def _wrapped_call_impl(self, *args, **kwargs):
        if self._compiled_call_impl is not None:
            return self._compiled_call_impl(*args, **kwargs)  # type: ignore[misc]
        else:
>           return self._call_impl(*args, **kwargs)

/opt/fw/torch/torch/nn/modules/module.py:1736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = MultiResolutionDetector(
  (model): CornerGFTT(grads_mode=sobel)
  (nms): NonMaximaSuppression2d()
  (ori): LAFOriente...d(64, 3, kernel_size=(8, 8), stride=(1, 1))
      (20): Tanh()
      (21): AdaptiveAvgPool2d(output_size=1)
    )
  )
)
args = (<tf.Tensor: shape=(1, 1, 320, 200), dtype=float32, numpy=
array([[[[0.6048078 , 0.11149019, 0.04408693, ..., 0.857082...     [0.02635199, 0.0848912 , 0.9472018 , ..., 0.26334184,
          0.93338   , 0.53244853]]]], dtype=float32)>, None)
kwargs = {}

    def _call_impl(self, *args, **kwargs):
        forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)
        # If we don't have any hooks, we want to skip the rest of the logic in
        # this function, and just call forward.
        if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks
                or _global_backward_pre_hooks or _global_backward_hooks
                or _global_forward_hooks or _global_forward_pre_hooks):
>           return forward_call(*args, **kwargs)

/opt/fw/torch/torch/nn/modules/module.py:1747: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = MultiResolutionDetector(
  (model): CornerGFTT(grads_mode=sobel)
  (nms): NonMaximaSuppression2d()
  (ori): LAFOriente...d(64, 3, kernel_size=(8, 8), stride=(1, 1))
      (20): Tanh()
      (21): AdaptiveAvgPool2d(output_size=1)
    )
  )
)
img = <tf.Tensor: shape=(1, 1, 320, 200), dtype=float32, numpy=
array([[[[0.6048078 , 0.11149019, 0.04408693, ..., 0.8570821...],
         [0.02635199, 0.0848912 , 0.9472018 , ..., 0.26334184,
          0.93338   , 0.53244853]]]], dtype=float32)>
mask = None

    def forward(self, img: Tensor, mask: Optional[Tensor] = None) -> Tuple[Tensor, Tensor]:
        """Three stage local feature detection. First the location and scale of interest points are determined by
        detect function. Then affine shape and orientation.
    
        Args:
            img: image to extract features with shape [1xCxHxW]. KeyNetDetector does not support batch processing,
        because the number of detections is different on each image.
            mask: a mask with weights where to apply the response function. The shape must be the same as
              the input image.
    
        Returns:
            lafs: shape [1xNx2x3]. Detected local affine frames.
            responses: shape [1xNx1]. Response function values for corresponding lafs
        """
        KORNIA_CHECK_SHAPE(img, ["1", "C", "H", "W"])
>       responses, lafs = self.detect(img, mask)

/opt/miniconda/envs/multienv/lib/python3.10/site-packages/kornia/feature/scale_space_detector.py:392: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = MultiResolutionDetector(
  (model): CornerGFTT(grads_mode=sobel)
  (nms): NonMaximaSuppression2d()
  (ori): LAFOriente...d(64, 3, kernel_size=(8, 8), stride=(1, 1))
      (20): Tanh()
      (21): AdaptiveAvgPool2d(output_size=1)
    )
  )
)
img = <tf.Tensor: shape=(1, 1, 320, 200), dtype=float32, numpy=
array([[[[0.6048078 , 0.11149019, 0.04408693, ..., 0.8570821...],
         [0.02635199, 0.0848912 , 0.9472018 , ..., 0.26334184,
          0.93338   , 0.53244853]]]], dtype=float32)>
mask = None

    def detect(self, img: Tensor, mask: Optional[Tensor] = None) -> Tuple[Tensor, Tensor]:
        # Compute points per level
        num_features_per_level: List[float] = []
        tmp = 0.0
        factor_points = self.scale_factor_levels**2
        levels = self.num_pyramid_levels + self.num_upscale_levels + 1
        for idx_level in range(levels):
            tmp += factor_points ** (-1 * (idx_level - self.num_upscale_levels))
            nf = self.num_features * factor_points ** (-1 * (idx_level - self.num_upscale_levels))
            num_features_per_level.append(nf)
        num_features_per_level = [int(x / tmp) for x in num_features_per_level]
    
        _, _, h, w = img.shape
        img_up = img
        cur_img = img
        all_responses: List[Tensor] = []
        all_lafs: List[Tensor] = []
        # Extract features from the upper levels
        for idx_level in range(self.num_upscale_levels):
            nf = num_features_per_level[len(num_features_per_level) - self.num_pyramid_levels - 1 - (idx_level + 1)]
            num_points_level = int(nf)
    
            # Resize input image
            up_factor = self.scale_factor_levels ** (1 + idx_level)
            nh, nw = int(h * up_factor), int(w * up_factor)
            up_factor_kpts = (float(w) / float(nw), float(h) / float(nh))
>           img_up = resize(img_up, (nh, nw), interpolation="bilinear", align_corners=False)

/opt/miniconda/envs/multienv/lib/python3.10/site-packages/kornia/feature/scale_space_detector.py:345: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = <tf.Tensor: shape=(1, 1, 320, 200), dtype=float32, numpy=
array([[[[0.6048078 , 0.11149019, 0.04408693, ..., 0.8570821...],
         [0.02635199, 0.0848912 , 0.9472018 , ..., 0.26334184,
          0.93338   , 0.53244853]]]], dtype=float32)>
args = ((452, 282),), kwargs = {'align_corners': False, 'interpolation': 'bilinear'}

    @wraps(f)
    def _wrapper(input: Tensor, *args: Any, **kwargs: Any) -> Tensor:
        if not isinstance(input, Tensor):
>           raise TypeError(f"Input input type is not a Tensor. Got {type(input)}")
E           TypeError: Input input type is not a Tensor. Got <class 'tensorflow.python.framework.ops.EagerTensor'>

/opt/miniconda/envs/multienv/lib/python3.10/site-packages/kornia/utils/image.py:224: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.LocalFeatureMatcher
_____________________________________________________________________________ test_LightGlueMatcher[tensorflow-s2s-False] ______________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_LightGlueMatcher(target_framework, mode, backend_compile):
        print("kornia.feature.LightGlueMatcher")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target_framework)
    
        torch_args = (
            torch.rand(2, 128),
            torch.rand(5, 128),
            torch.rand(1, 2, 2, 3),
            torch.rand(1, 5, 2, 3),
        )
        transpiled_args = _nest_torch_tensor_to_new_framework(torch_args, target_framework)
    
        model = kornia.feature.LightGlueMatcher('disk')
        torch_out = model(*torch_args)
    
>       transpiled_model = transpiled_kornia.feature.LightGlueMatcher('disk')

kornia/test_feature4.py:258: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:232: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_LightGlueMatcher(), feature_name = 'disk', params = {}

    def __init__(self, feature_name="disk", params={}):
        from .lightglue import tensorflow_LightGlue
    
        feature_name_: typing.Any = feature_name.lower()
        super().__init__(feature_name_)
        self.feature_name = feature_name_
        self.params = params
>       self.matcher = tensorflow_LightGlue(self.feature_name, **params)

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/integrated.py:54: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_LightGlue(
  (input_proj): KerasDense()
  (posenc): tensorflow_LearnableFourierPositionalEncoding(
    (Wr): KerasDense()
  )
), args = ('disk',), kwargs = {}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_LightGlue(
  (input_proj): KerasDense()
  (posenc): tensorflow_LearnableFourierPositionalEncoding(
    (Wr): KerasDense()
  )
), features = 'disk', conf_ = {}
tensorflow_KORNIA_CHECK = <function tensorflow_KORNIA_CHECK at 0x7f02d8c79510>, tensorflow_get_item = <function tensorflow_get_item at 0x7f02d8c531c0>
tensorflow_Identity = <class 'ivy_transpiled_outputs.tensorflow_outputs.torch.nn.modules.linear.tensorflow_Identity'>
tensorflow_load_state_dict_from_url_frnt = <function tensorflow_load_state_dict_from_url_frnt at 0x7f02d8c30160>, tensorflow_load_frnt = <function tensorflow_load_frnt at 0x7f02d8c30a60>
ModuleList = <class 'ivy_transpiled_outputs.tensorflow_outputs.torch.nn.modules.container.tensorflow_ModuleList'>
KerasDense = <class 'ivy_transpiled_outputs.tensorflow_outputs.tensorflow__stateful_layers.KerasDense'>

    @tensorflow_store_config_info
    def __init__(self, features="superpoint", **conf_):
        from ..core.check import tensorflow_KORNIA_CHECK
        from ...ivy.functional.backends.tensorflow.general import tensorflow_get_item
        from ...torch.nn.modules.linear import tensorflow_Identity
        from ...ivy.functional.frontends.torch.hub.hub import (
            tensorflow_load_state_dict_from_url_frnt,
        )
        from ...ivy.functional.frontends.torch.serialization.serialization import (
            tensorflow_load_frnt,
        )
        from ..core._backend import ModuleList
        from ...tensorflow__stateful_layers import KerasDense
    
        self.super___init__(
            features=features,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        self.conf = conf = SimpleNamespace(**{**self.default_conf, **conf_})
        if features is not None:
            tensorflow_KORNIA_CHECK(
                features in list(self.features.keys()), "Features keys are wrong"
            )
            for k, v in tensorflow_get_item(self.features, features).items():
                setattr(conf, k, v)
        tensorflow_KORNIA_CHECK(not (self.conf.add_scale_ori and self.conf.add_laf))
        if conf.input_dim != conf.descriptor_dim:
            self.input_proj = KerasDense(
                in_features=conf.input_dim, units=conf.descriptor_dim, use_bias=True
            )
        else:
            self.input_proj = tensorflow_Identity()
        head_dim = conf.descriptor_dim // conf.num_heads
        self.posenc = tensorflow_LearnableFourierPositionalEncoding(
            2 + 2 * conf.add_scale_ori + 4 * conf.add_laf, head_dim, head_dim
        )
        h, n, d = conf.num_heads, conf.n_layers, conf.descriptor_dim
        ag__result_list_0 = []
        for _ in range(n):
>           res = tensorflow_TransformerLayer(d, h, conf.flash)

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/lightglue.py:1433: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_TransformerLayer(), args = (256, 4, True), kwargs = {}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_TransformerLayer(), args = (256, 4, True), kwargs = {}

    @tensorflow_store_config_info
    def __init__(self, *args, **kwargs):
        self.super___init__(
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
>       self.self_attn = tensorflow_SelfBlock(*args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/lightglue.py:976: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_SelfBlock(
  (Wqkv): KerasDense()
), args = (256, 4, True), kwargs = {}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_SelfBlock(
  (Wqkv): KerasDense()
), embed_dim = 256, num_heads = 4, flash = True, bias = True

    @tensorflow_store_config_info
    def __init__(self, embed_dim, num_heads, flash=False, bias=True):
        from ..core.check import tensorflow_KORNIA_CHECK
        from ...torch.nn.modules.container import tensorflow_Sequential
        from ...torch.nn.modules.normalization import tensorflow_LayerNorm
        from ...torch.nn.modules.activation import tensorflow_GELU
        from ...tensorflow__stateful_layers import KerasDense
    
        self.super___init__(
            embed_dim,
            num_heads,
            flash=flash,
            bias=bias,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        self.embed_dim = embed_dim
        self.num_heads = num_heads
        tensorflow_KORNIA_CHECK(
            self.embed_dim % num_heads == 0,
            "Embed dimension should be dividable by num_heads",
        )
        self.head_dim = self.embed_dim // num_heads
        self.Wqkv = KerasDense(
            in_features=embed_dim, units=3 * embed_dim, use_bias=bias
        )
>       self.inner_attn = tensorflow_Attention(flash)

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/lightglue.py:612: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Attention(), args = (True,), kwargs = {}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Attention(), allow_flash = True

    @tensorflow_store_config_info
    def __init__(self, allow_flash):
        self.super___init__(
            allow_flash,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        if allow_flash and not FLASH_AVAILABLE:
            warnings.warn(
                "FlashAttention is not available. For optimal speed, consider installing torch >= 2.0 or flash-attn.",
                stacklevel=2,
            )
        self.enable_flash = allow_flash and FLASH_AVAILABLE
>       self.has_sdp = hasattr(torch.nn.functional, "scaled_dot_product_attention")
E       NameError: name 'torch' is not defined

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/lightglue.py:411: NameError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.LightGlueMatcher
Loaded LightGlue model
----------------------------------------------------------------------------------------- Captured stderr call -----------------------------------------------------------------------------------------
Downloading: "https://github.com/cvg/LightGlue/releases/download/v0.1_arxiv/disk_lightglue.pth" to /root/.cache/torch/hub/checkpoints/disk_lightglue_v0-1_arxiv-pth

  0%|          | 0.00/45.4M [00:00<?, ?B/s]
 22%|██▏       | 10.1M/45.4M [00:00<00:00, 106MB/s]
 45%|████▌     | 20.5M/45.4M [00:00<00:00, 107MB/s]
 75%|███████▌  | 34.1M/45.4M [00:00<00:00, 53.0MB/s]
 91%|█████████ | 41.4M/45.4M [00:00<00:00, 54.5MB/s]
100%|██████████| 45.4M/45.4M [00:00<00:00, 60.9MB/s]
_________________________________________________________________________________ test_LightGlue[tensorflow-s2s-False] _________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_LightGlue(target_framework, mode, backend_compile):
        print("kornia.feature.LightGlue")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target_framework)
    
        data = {
            "image0": {
                "keypoints": torch.rand(1, 100, 2),
                "descriptors": torch.rand(1, 100, 256),
                "image_size": torch.tensor([[640, 480]]),
            },
            "image1": {
                "keypoints": torch.rand(1, 120, 2),
                "descriptors": torch.rand(1, 120, 256),
                "image_size": torch.tensor([[640, 480]]),
            }
        }
        transpiled_data = _nest_torch_tensor_to_new_framework(data, target_framework)
    
        model = kornia.feature.LightGlue(features='superpoint')
>       torch_out = model(data)

kornia/test_feature4.py:293: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LightGlue(
  (input_proj): Identity()
  (posenc): LearnableFourierPositionalEncoding(
    (Wr): Linear(in_features=2, ... Sequential(
        (0): Linear(in_features=256, out_features=1, bias=True)
        (1): Sigmoid()
      )
    )
  )
)
args = ({'image0': {'descriptors': <tf.Tensor: shape=(1, 100, 256), dtype=float32, numpy=
array([[[0.6325957 , 0.36721432, 0....    [0.7259848 , 0.8861473 ],
        [0.02958691, 0.5214976 ],
        [0.2633975 , 0.82921827]]], dtype=float32)>}},)
kwargs = {}

    def _wrapped_call_impl(self, *args, **kwargs):
        if self._compiled_call_impl is not None:
            return self._compiled_call_impl(*args, **kwargs)  # type: ignore[misc]
        else:
>           return self._call_impl(*args, **kwargs)

/opt/fw/torch/torch/nn/modules/module.py:1736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LightGlue(
  (input_proj): Identity()
  (posenc): LearnableFourierPositionalEncoding(
    (Wr): Linear(in_features=2, ... Sequential(
        (0): Linear(in_features=256, out_features=1, bias=True)
        (1): Sigmoid()
      )
    )
  )
)
args = ({'image0': {'descriptors': <tf.Tensor: shape=(1, 100, 256), dtype=float32, numpy=
array([[[0.6325957 , 0.36721432, 0....    [0.7259848 , 0.8861473 ],
        [0.02958691, 0.5214976 ],
        [0.2633975 , 0.82921827]]], dtype=float32)>}},)
kwargs = {}

    def _call_impl(self, *args, **kwargs):
        forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)
        # If we don't have any hooks, we want to skip the rest of the logic in
        # this function, and just call forward.
        if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks
                or _global_backward_pre_hooks or _global_backward_hooks
                or _global_forward_hooks or _global_forward_pre_hooks):
>           return forward_call(*args, **kwargs)

/opt/fw/torch/torch/nn/modules/module.py:1747: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LightGlue(
  (input_proj): Identity()
  (posenc): LearnableFourierPositionalEncoding(
    (Wr): Linear(in_features=2, ... Sequential(
        (0): Linear(in_features=256, out_features=1, bias=True)
        (1): Sigmoid()
      )
    )
  )
)
data = {'image0': {'descriptors': <tf.Tensor: shape=(1, 100, 256), dtype=float32, numpy=
array([[[0.6325957 , 0.36721432, 0.8...      [0.7259848 , 0.8861473 ],
        [0.02958691, 0.5214976 ],
        [0.2633975 , 0.82921827]]], dtype=float32)>}}

    def forward(self, data: dict) -> dict:  # type: ignore
        """Match keypoints and descriptors between two images.
    
        Input (dict):
            image0: dict
                keypoints: [B x M x 2]
                descriptors: [B x M x D]
                image: [B x C x H x W] or image_size: [B x 2]
            image1: dict
                keypoints: [B x N x 2]
                descriptors: [B x N x D]
                image: [B x C x H x W] or image_size: [B x 2]
        Output (dict):
            log_assignment: [B x M+1 x N+1]
            matches0: [B x M]
            matching_scores0: [B x M]
            matches1: [B x N]
            matching_scores1: [B x N]
            matches: List[[Si x 2]], scores: List[[Si]]
        """
        with torch.autocast(enabled=self.conf.mp, device_type="cuda"):
>           return self._forward(data)

/opt/miniconda/envs/multienv/lib/python3.10/site-packages/kornia/feature/lightglue.py:497: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LightGlue(
  (input_proj): Identity()
  (posenc): LearnableFourierPositionalEncoding(
    (Wr): Linear(in_features=2, ... Sequential(
        (0): Linear(in_features=256, out_features=1, bias=True)
        (1): Sigmoid()
      )
    )
  )
)
data = {'image0': {'descriptors': <tf.Tensor: shape=(1, 100, 256), dtype=float32, numpy=
array([[[0.6325957 , 0.36721432, 0.8...      [0.7259848 , 0.8861473 ],
        [0.02958691, 0.5214976 ],
        [0.2633975 , 0.82921827]]], dtype=float32)>}}

    def _forward(self, data: dict) -> dict:  # type: ignore
        for key in self.required_data_keys:
            KORNIA_CHECK(key in data, f"Missing key {key} in data")
        data0, data1 = data["image0"], data["image1"]
        kpts0, kpts1 = data0["keypoints"], data1["keypoints"]
        b, m, _ = kpts0.shape
        b, n, _ = kpts1.shape
        device = kpts0.device
        size0, size1 = data0.get("image_size"), data1.get("image_size")
        size0 = size0 if size0 is not None else data0["image"].shape[-2:][::-1]
        size1 = size1 if size1 is not None else data1["image"].shape[-2:][::-1]
    
>       kpts0 = normalize_keypoints(kpts0, size0).clone()

/opt/miniconda/envs/multienv/lib/python3.10/site-packages/kornia/feature/lightglue.py:511: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (<tf.Tensor: shape=(1, 100, 2), dtype=float32, numpy=
array([[[0.4479267 , 0.651264  ],
        [0.953495  , 0.9829005...        [0.20584226, 0.45503742]]], dtype=float32)>, <tf.Tensor: shape=(1, 2), dtype=int64, numpy=array([[640, 480]])>)
kwargs = {}, autocast_context = False

    @functools.wraps(fwd)
    def decorate_fwd(*args, **kwargs):
        args[0]._dtype = torch.get_autocast_dtype(device_type)
        if cast_inputs is None:
            args[0]._fwd_used_autocast = torch.is_autocast_enabled(device_type)
            return fwd(*args, **kwargs)
        else:
            autocast_context = torch.is_autocast_enabled(device_type)
            args[0]._fwd_used_autocast = False
            if autocast_context:
                with autocast(device_type=device_type, enabled=False):
                    return fwd(
                        *_cast(args, device_type, cast_inputs),
                        **_cast(kwargs, device_type, cast_inputs),
                    )
            else:
>               return fwd(*args, **kwargs)

/opt/fw/torch/torch/amp/autocast_mode.py:476: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

kpts = <tf.Tensor: shape=(1, 100, 2), dtype=float32, numpy=
array([[[0.4479267 , 0.651264  ],
        [0.953495  , 0.98290056...        [0.60969186, 0.05836785],
        [0.4932472 , 0.763172  ],
        [0.20584226, 0.45503742]]], dtype=float32)>
size = <tf.Tensor: shape=(1, 2), dtype=int64, numpy=array([[640, 480]])>

    @torch.cuda.amp.custom_fwd(cast_inputs=torch.float32)
    def normalize_keypoints(kpts: Tensor, size: Tensor) -> Tensor:
        if isinstance(size, torch.Size):
            size = Tensor(size)[None]
>       shift = size.float().to(kpts) / 2

/opt/miniconda/envs/multienv/lib/python3.10/site-packages/kornia/feature/lightglue.py:48: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <tf.Tensor: shape=(1, 2), dtype=int64, numpy=array([[640, 480]])>, name = 'float'

    def __getattr__(self, name):
      if name in {"T", "astype", "ravel", "transpose", "reshape", "clip", "size",
                  "tolist", "data"}:
        # TODO(wangpeng): Export the enable_numpy_behavior knob
        raise AttributeError(
            f"{type(self).__name__} object has no attribute '{name}'. " + """
          If you are looking for numpy-related methods, please run the following:
          tf.experimental.numpy.experimental_enable_numpy_behavior()
        """)
>     self.__getattribute__(name)
E     AttributeError: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'float'

/opt/fw/tensorflow/tensorflow/python/framework/tensor.py:260: AttributeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.LightGlue
Loaded LightGlue model
----------------------------------------------------------------------------------------- Captured stderr call -----------------------------------------------------------------------------------------
Downloading: "https://github.com/cvg/LightGlue/releases/download/v0.1_arxiv/superpoint_lightglue.pth" to /root/.cache/torch/hub/checkpoints/superpoint_lightglue_v0-1_arxiv-pth

  0%|          | 0.00/45.3M [00:00<?, ?B/s]
 22%|██▏       | 10.1M/45.3M [00:00<00:00, 101MB/s]
 44%|████▍     | 20.1M/45.3M [00:00<00:00, 56.5MB/s]
 70%|██████▉   | 31.6M/45.3M [00:00<00:00, 76.3MB/s]
 89%|████████▉ | 40.4M/45.3M [00:00<00:00, 75.6MB/s]
100%|██████████| 45.3M/45.3M [00:00<00:00, 80.5MB/s]
___________________________________________________________________________________ test_LoFTR[tensorflow-s2s-False] ___________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_LoFTR(target_framework, mode, backend_compile):
        print("kornia.feature.LoFTR")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target_framework)
    
        data = {"image0": torch.rand(1, 1, 320, 200), "image1": torch.rand(1, 1, 128, 128)}
        transpiled_data = _nest_torch_tensor_to_new_framework(data, target_framework)
    
        model = kornia.feature.LoFTR(None)
>       torch_out = model(data)

kornia/test_feature4.py:320: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LoFTR(
  (backbone): ResNetFPN_8_2(
    (conv1): Conv2d(1, 128, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bia...   (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (fine_matching): FineMatching()
)
args = ({'image0': <tf.Tensor: shape=(1, 1, 320, 200), dtype=float32, numpy=
array([[[[0.18093199, 0.42166007, 0.47623563, .....         [0.24737442, 0.5428471 , 0.3145007 , ..., 0.6794955 ,
          0.2251476 , 0.5455755 ]]]], dtype=float32)>},)
kwargs = {}

    def _wrapped_call_impl(self, *args, **kwargs):
        if self._compiled_call_impl is not None:
            return self._compiled_call_impl(*args, **kwargs)  # type: ignore[misc]
        else:
>           return self._call_impl(*args, **kwargs)

/opt/fw/torch/torch/nn/modules/module.py:1736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LoFTR(
  (backbone): ResNetFPN_8_2(
    (conv1): Conv2d(1, 128, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bia...   (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (fine_matching): FineMatching()
)
args = ({'image0': <tf.Tensor: shape=(1, 1, 320, 200), dtype=float32, numpy=
array([[[[0.18093199, 0.42166007, 0.47623563, .....         [0.24737442, 0.5428471 , 0.3145007 , ..., 0.6794955 ,
          0.2251476 , 0.5455755 ]]]], dtype=float32)>},)
kwargs = {}

    def _call_impl(self, *args, **kwargs):
        forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)
        # If we don't have any hooks, we want to skip the rest of the logic in
        # this function, and just call forward.
        if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks
                or _global_backward_pre_hooks or _global_backward_hooks
                or _global_forward_hooks or _global_forward_pre_hooks):
>           return forward_call(*args, **kwargs)

/opt/fw/torch/torch/nn/modules/module.py:1747: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LoFTR(
  (backbone): ResNetFPN_8_2(
    (conv1): Conv2d(1, 128, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bia...   (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (fine_matching): FineMatching()
)
data = {'image0': <tf.Tensor: shape=(1, 1, 320, 200), dtype=float32, numpy=
array([[[[0.18093199, 0.42166007, 0.47623563, ......,
         [0.24737442, 0.5428471 , 0.3145007 , ..., 0.6794955 ,
          0.2251476 , 0.5455755 ]]]], dtype=float32)>}

    def forward(self, data: dict[str, Tensor]) -> dict[str, Tensor]:
        """
        Args:
            data: dictionary containing the input data in the following format:
    
        Keyword Args:
            image0: left image with shape :math:`(N, 1, H1, W1)`.
            image1: right image with shape :math:`(N, 1, H2, W2)`.
            mask0 (optional): left image mask. '0' indicates a padded position :math:`(N, H1, W1)`.
            mask1 (optional): right image mask. '0' indicates a padded position :math:`(N, H2, W2)`.
    
        Returns:
            - ``keypoints0``, matching keypoints from image0 :math:`(NC, 2)`.
            - ``keypoints1``, matching keypoints from image1 :math:`(NC, 2)`.
            - ``confidence``, confidence score [0, 1] :math:`(NC)`.
            - ``batch_indexes``, batch indexes for the keypoints and lafs :math:`(NC)`.
        """
        # 1. Local Feature CNN
        _data: dict[str, Tensor | int | torch.Size] = {
>           "bs": data["image0"].size(0),
            "hw0_i": data["image0"].shape[2:],
            "hw1_i": data["image1"].shape[2:],
        }
E       TypeError: 'numpy.int64' object is not callable

/opt/miniconda/envs/multienv/lib/python3.10/site-packages/kornia/feature/loftr/loftr.py:123: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.LoFTR
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/test_feature4.py::test_SIFTFeature[tensorflow-s2s-False] - ValueError: could not broadcast input array from shape (1,5) into shape (5,1,1)
FAILED kornia/test_feature4.py::test_SIFTFeatureScaleSpace[tensorflow-s2s-False] - ValueError: could not broadcast input array from shape (1,5) into shape (5,1,1)
FAILED kornia/test_feature4.py::test_GFTTAffNetHardNet[tensorflow-s2s-False] - ValueError: could not broadcast input array from shape (1,5) into shape (5,1,1)
FAILED kornia/test_feature4.py::test_KeyNetAffNetHardNet[tensorflow-s2s-False] - AssertionError: numpy array values are not all close
FAILED kornia/test_feature4.py::test_LocalFeatureMatcher[tensorflow-s2s-False] - TypeError: Input input type is not a Tensor. Got <class 'tensorflow.python.framework.ops.EagerTensor'>
FAILED kornia/test_feature4.py::test_LightGlueMatcher[tensorflow-s2s-False] - NameError: name 'torch' is not defined
FAILED kornia/test_feature4.py::test_LightGlue[tensorflow-s2s-False] - AttributeError: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'float'
FAILED kornia/test_feature4.py::test_LoFTR[tensorflow-s2s-False] - TypeError: 'numpy.int64' object is not callable
=============================================================================== 8 failed, 6 passed in 2377.54s (0:39:37) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 17 items

kornia/augmentation/test_augmentation2.py ...F.......F.F...                                                                                                                                      [100%]

=============================================================================================== FAILURES ===============================================================================================
_________________________________________________________________________________ test_RandomMotionBlur[jax-s2s-False] _________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_RandomMotionBlur(target_framework, mode, backend_compile):
        print("kornia.augmentation.RandomMotionBlur")
    
        init_args = (3, 35., 0.5)
        init_kwargs = {"p": 1.}
        call_args = (torch.ones(1, 1, 5, 5),)
        call_kwargs = {}
    
>       _test_augmentation_class(
            kornia.augmentation.RandomMotionBlur,
            target_framework,
            init_args,
            init_kwargs,
            call_args,
            call_kwargs,
            deterministic_output=False,
            backend_compile=backend_compile,
        )

kornia/augmentation/test_augmentation2.py:134: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

augmentation_cls = <class 'kornia.augmentation._2d.intensity.motion_blur.RandomMotionBlur'>, target = 'jax', init_args = (3, 35.0, 0.5), init_kwargs = {'p': 1.0}
call_args = (tensor([[[[1., 1., 1., 1., 1.],
          [1., 1., 1., 1., 1.],
          [1., 1., 1., 1., 1.],
          [1., 1., 1., 1., 1.],
          [1., 1., 1., 1., 1.]]]]),), call_kwargs = {}
deterministic_output = False, backend_compile = False, tolerance = 0.001

    def _test_augmentation_class(
        augmentation_cls,
        target,
        init_args=(),
        init_kwargs={},
        call_args=(),
        call_kwargs={},
        deterministic_output=True,
        backend_compile=False,
        tolerance=1e-3,
    ):
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, target=target)
        transpiled_cls = eval("transpiled_" + f"{augmentation_cls.__module__}.{augmentation_cls.__name__}")
    
        torch_aug = augmentation_cls(*init_args, **init_kwargs)
        transpiled_init_args = _nest_torch_tensor_to_new_framework(init_args, target)
        transpiled_init_kwargs = _nest_torch_tensor_to_new_framework(init_kwargs, target)
        transpiled_aug = transpiled_cls(*transpiled_init_args, **transpiled_init_kwargs)
    
        # assert dir(torch_aug) == dir(transpiled_aug), f"attributes/methods of transpiled object do not align with the original - orig: {dir(torch_aug)} != transpiled: {dir(transpiled_aug)}"
    
        torch_out = torch_aug(*call_args, **call_kwargs)
        transpiled_call_args = _nest_torch_tensor_to_new_framework(call_args, target)
        transpiled_call_kwargs = _nest_torch_tensor_to_new_framework(call_kwargs, target)
>       transpiled_out = transpiled_aug(*transpiled_call_args, **transpiled_call_kwargs)

kornia/augmentation/test_augmentation2.py:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_RandomMotionBlur(kernel_size=3, angle=35.0, direction=0.5, p=1.0, p_batch=1.0, same_on_batch=False, border_type=constant, resample=nearest)
input = Array([[[[1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.]]]], dtype=float32), params = None
kwargs = {}, jax_shape_frnt_ = <function jax_shape_frnt_ at 0x7f3ab0f26b00>, jax_set_item = <function jax_set_item at 0x7f3ac059b520>, tensor = <function jax_tensor_frnt at 0x7f3ab0e5ce50>
in_tensor = Array([[[[1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.]]]], dtype=float32)
input_shape = ivy.frontends.torch.Size([1, 1, 5, 5]), batch_shape = ivy.frontends.torch.Size([1, 1, 5, 5])

    def __call__(self, input, params=None, **kwargs):
        from ...ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ...ivy.functional.backends.jax.general import jax_set_item
        from ..core._backend import tensor
    
        in_tensor = self.__unpack_input__(input)
        input_shape = jax_shape_frnt_(in_tensor)
        in_tensor = self.transform_tensor(in_tensor)
        batch_shape = jax_shape_frnt_(in_tensor)
        if params is None:
>           params = self.forward_parameters(batch_shape)

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/base.py:213: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_RandomMotionBlur(kernel_size=3, angle=35.0, direction=0.5, p=1.0, p_batch=1.0, same_on_batch=False, border_type=constant, resample=nearest)
batch_shape = ivy.frontends.torch.Size([1, 1, 5, 5])

    def forward_parameters(self, batch_shape):
        from ...ivy.functional.frontends.torch.tensor import jax_sum_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_item_frnt_
        from ...ivy.functional.backends.jax.general import jax_set_item
        from ..core._backend import tensor
    
        batch_prob = self.__batch_prob_generator__(
            batch_shape, self.p, self.p_batch, self.same_on_batch
        )
        to_apply = batch_prob > 0.5
>       _params = self.generate_parameters(
            tuple((int(jax_item_frnt_(jax_sum_frnt_(to_apply))), *batch_shape[1:]))
        )

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/base.py:190: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_RandomMotionBlur(kernel_size=3, angle=35.0, direction=0.5, p=1.0, p_batch=1.0, same_on_batch=False, border_type=constant, resample=nearest), batch_shape = (1, 1, 5, 5)

    def generate_parameters(self, batch_shape):
        from ....core._backend import tensor
        from .....ivy.functional.backends.jax.general import jax_set_item
        from .....ivy.functional.frontends.torch.random_sampling import jax_randint_frnt
    
        params = super().generate_parameters(batch_shape)
        params = jax_set_item(
            params,
            "idx",
            tensor([0])
            if batch_shape[0] == 0
>           else jax_randint_frnt(batch_shape[0], (1,)),
        )
E       TypeError: jax_randint_frnt() missing 1 required positional argument: 'size'

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/_2d/intensity/motion_blur.py:66: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.RandomMotionBlur
_____________________________________________________________________________ test_RandomSaltAndPepperNoise[jax-s2s-False] _____________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_RandomSaltAndPepperNoise(target_framework, mode, backend_compile):
        print("kornia.augmentation.RandomSaltAndPepperNoise")
    
        init_args = ()
        init_kwargs = {"amount": 0.5, "salt_vs_pepper": 0.5, "p": 1.}
        call_args = (torch.rand(1, 3, 3, 3),)
        call_kwargs = {}
    
>       _test_augmentation_class(
            kornia.augmentation.RandomSaltAndPepperNoise,
            target_framework,
            init_args,
            init_kwargs,
            call_args,
            call_kwargs,
            deterministic_output=False,
            backend_compile=backend_compile,
        )

kornia/augmentation/test_augmentation2.py:294: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

augmentation_cls = <class 'kornia.augmentation._2d.intensity.salt_pepper_noise.RandomSaltAndPepperNoise'>, target = 'jax', init_args = ()
init_kwargs = {'amount': 0.5, 'p': 1.0, 'salt_vs_pepper': 0.5}
call_args = (tensor([[[[0.9480, 0.5178, 0.5444],
          [0.1282, 0.0603, 0.1668],
          [0.8264, 0.7279, 0.2585]],

       ...28]],

         [[0.7196, 0.5987, 0.0119],
          [0.7013, 0.7862, 0.5323],
          [0.4867, 0.7126, 0.8812]]]]),)
call_kwargs = {}, deterministic_output = False, backend_compile = False, tolerance = 0.001

    def _test_augmentation_class(
        augmentation_cls,
        target,
        init_args=(),
        init_kwargs={},
        call_args=(),
        call_kwargs={},
        deterministic_output=True,
        backend_compile=False,
        tolerance=1e-3,
    ):
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, target=target)
        transpiled_cls = eval("transpiled_" + f"{augmentation_cls.__module__}.{augmentation_cls.__name__}")
    
        torch_aug = augmentation_cls(*init_args, **init_kwargs)
        transpiled_init_args = _nest_torch_tensor_to_new_framework(init_args, target)
        transpiled_init_kwargs = _nest_torch_tensor_to_new_framework(init_kwargs, target)
        transpiled_aug = transpiled_cls(*transpiled_init_args, **transpiled_init_kwargs)
    
        # assert dir(torch_aug) == dir(transpiled_aug), f"attributes/methods of transpiled object do not align with the original - orig: {dir(torch_aug)} != transpiled: {dir(transpiled_aug)}"
    
        torch_out = torch_aug(*call_args, **call_kwargs)
        transpiled_call_args = _nest_torch_tensor_to_new_framework(call_args, target)
        transpiled_call_kwargs = _nest_torch_tensor_to_new_framework(call_kwargs, target)
>       transpiled_out = transpiled_aug(*transpiled_call_args, **transpiled_call_kwargs)

kornia/augmentation/test_augmentation2.py:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_RandomSaltAndPepperNoise(amount=(0.5, 0.5), salt_and_pepper=(0.5, 0.5), p=1.0, p_batch=1.0, same_on_batch=False)
input = Array([[[[0.94795305, 0.51781803, 0.5444308 ],
         [0.1282376 , 0.06026602, 0.16681296],
         [0.82636297, 0....90525],
         [0.70134664, 0.7862381 , 0.53229994],
         [0.4866532 , 0.71256053, 0.8812425 ]]]], dtype=float32)
params = {'amount_factor': Array([0.5], dtype=float32), 'batch_prob': Array([1.], dtype=float32), 'forward_input_shape': Array(...,

        [[False, False,  True],
         [False, False, False],
         [False,  True, False]]]], dtype=bool), ...}
kwargs = {}, jax_shape_frnt_ = <function jax_shape_frnt_ at 0x7f3a9f56eb00>, jax_set_item = <function jax_set_item at 0x7f3ac0611480>, tensor = <function jax_tensor_frnt at 0x7f3a9f7071c0>
in_tensor = Array([[[[0.94795305, 0.51781803, 0.5444308 ],
         [0.1282376 , 0.06026602, 0.16681296],
         [0.82636297, 0....90525],
         [0.70134664, 0.7862381 , 0.53229994],
         [0.4866532 , 0.71256053, 0.8812425 ]]]], dtype=float32)
input_shape = ivy.frontends.torch.Size([1, 3, 3, 3]), batch_shape = ivy.frontends.torch.Size([1, 3, 3, 3]), flags = {}

    def __call__(self, input, params=None, **kwargs):
        from ...ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ...ivy.functional.backends.jax.general import jax_set_item
        from ..core._backend import tensor
    
        in_tensor = self.__unpack_input__(input)
        input_shape = jax_shape_frnt_(in_tensor)
        in_tensor = self.transform_tensor(in_tensor)
        batch_shape = jax_shape_frnt_(in_tensor)
        if params is None:
            params = self.forward_parameters(batch_shape)
        if "batch_prob" not in params:
            params = jax_set_item(params, "batch_prob", tensor([True] * batch_shape[0]))
        params, flags = self._process_kwargs_to_params_and_flags(
            params, self.flags, **kwargs
        )
>       output = self.apply_func(in_tensor, params, flags)

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/base.py:219: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_RandomSaltAndPepperNoise(amount=(0.5, 0.5), salt_and_pepper=(0.5, 0.5), p=1.0, p_batch=1.0, same_on_batch=False)
in_tensor = Array([[[[0.94795305, 0.51781803, 0.5444308 ],
         [0.1282376 , 0.06026602, 0.16681296],
         [0.82636297, 0....90525],
         [0.70134664, 0.7862381 , 0.53229994],
         [0.4866532 , 0.71256053, 0.8812425 ]]]], dtype=float32)
params = {'amount_factor': Array([0.5], dtype=float32), 'batch_prob': Array([1.], dtype=float32), 'forward_input_shape': Array(...,

        [[False, False,  True],
         [False, False, False],
         [False,  True, False]]]], dtype=bool), ...}
flags = {}

    def apply_func(self, in_tensor, params, flags=None):
        if flags is None:
            flags = self.flags
        trans_matrix = self.generate_transformation_matrix(in_tensor, params, flags)
>       output = self.transform_inputs(in_tensor, params, flags, trans_matrix)

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/_2d/base.py:123: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_RandomSaltAndPepperNoise(amount=(0.5, 0.5), salt_and_pepper=(0.5, 0.5), p=1.0, p_batch=1.0, same_on_batch=False)
input = Array([[[[0.94795305, 0.51781803, 0.5444308 ],
         [0.1282376 , 0.06026602, 0.16681296],
         [0.82636297, 0....90525],
         [0.70134664, 0.7862381 , 0.53229994],
         [0.4866532 , 0.71256053, 0.8812425 ]]]], dtype=float32)
params = {'amount_factor': Array([0.5], dtype=float32), 'batch_prob': Array([1.], dtype=float32), 'forward_input_shape': Array(...,

        [[False, False,  True],
         [False, False, False],
         [False,  True, False]]]], dtype=bool), ...}
flags = {}, transform = Array([[[1., 0., 0.],
        [0., 1., 0.],
        [0., 0., 1.]]], dtype=float32), kwargs = {}, jax_shape_frnt_ = <function jax_shape_frnt_ at 0x7f3a9f56eb00>
jax_all_frnt_ = <function jax_all_frnt_ at 0x7f3a9f56f370>, jax_any_frnt_ = <function jax_any_frnt_ at 0x7f3adbf40a60>, jax_get_item = <function jax_get_item at 0x7f3ac06112d0>
jax_is_autocast_enabled = <function jax_is_autocast_enabled at 0x7f3a9f7b28c0>, jax_type_frnt_ = <function jax_type_frnt_ at 0x7f3adbf43be0>
jax_index_put_frnt_ = <function jax_index_put_frnt_ at 0x7f3adbf43eb0>

    def transform_inputs(self, input, params, flags, transform=None, **kwargs):
        from ...ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_all_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_any_frnt_
        from ...ivy.functional.backends.jax.general import jax_get_item
        from ..utils.helpers import jax_is_autocast_enabled
        from ...ivy.functional.frontends.torch.tensor import jax_type_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_index_put_frnt_
        from .utils.helpers import jax__transform_output_shape
    
        params, flags = self._process_kwargs_to_params_and_flags(
            self._params if params is None else params, flags, **kwargs
        )
        batch_prob = params["batch_prob"]
        to_apply = batch_prob > 0.5
        ori_shape = jax_shape_frnt_(input)
        in_tensor = self.transform_tensor(input)
        self.validate_tensor(in_tensor)
        if jax_all_frnt_(to_apply):
>           output = self.apply_transform(in_tensor, params, flags, transform=transform)

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/base.py:333: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_RandomSaltAndPepperNoise(amount=(0.5, 0.5), salt_and_pepper=(0.5, 0.5), p=1.0, p_batch=1.0, same_on_batch=False)
input = Array([[[[0.94795305, 0.51781803, 0.5444308 ],
         [0.1282376 , 0.06026602, 0.16681296],
         [0.82636297, 0....90525],
         [0.70134664, 0.7862381 , 0.53229994],
         [0.4866532 , 0.71256053, 0.8812425 ]]]], dtype=float32)
params = {'amount_factor': Array([0.5], dtype=float32), 'batch_prob': Array([1.], dtype=float32), 'forward_input_shape': Array(...,

        [[False, False,  True],
         [False, False, False],
         [False,  True, False]]]], dtype=bool), ...}
flags = {}, transform = Array([[[1., 0., 0.],
        [0., 1., 0.],
        [0., 0., 1.]]], dtype=float32)

    def apply_transform(self, input, params, flags, transform=None):
        from ....core.check import jax_KORNIA_CHECK
        from .....ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from .....ivy.functional.frontends.torch.tensor import jax_clone_frnt_
        from .....ivy.functional.backends.jax.general import jax_set_item
    
        jax_KORNIA_CHECK(
            len(jax_shape_frnt_(input)) in (3, 4), "Wrong input dimension."
        )
        if len(jax_shape_frnt_(input)) == 3:
            input = input[None, :, :, :]
        jax_KORNIA_CHECK(
            jax_shape_frnt_(input)[1] in {3, 1},
            "Number of color channels should be 1 or 3.",
        )
        noisy_image = jax_clone_frnt_(input)
        noisy_image = jax_set_item(
>           noisy_image, params["mask_salt"].to(input.device), 1.0
        )
E       AttributeError: 'jaxlib.xla_extension.ArrayImpl' object has no attribute 'to'

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/_2d/intensity/salt_pepper_noise.py:92: AttributeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.RandomSaltAndPepperNoise
_________________________________________________________________________________ test_RandomSharpness[jax-s2s-False] __________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_RandomSharpness(target_framework, mode, backend_compile):
        print("kornia.augmentation.RandomSharpness")
    
        init_args = (1.,)
        init_kwargs = {"p": 1.}
        call_args = (torch.rand(1, 1, 5, 5),)
        call_kwargs = {}
    
>       _test_augmentation_class(
            kornia.augmentation.RandomSharpness,
            target_framework,
            init_args,
            init_kwargs,
            call_args,
            call_kwargs,
            deterministic_output=False,
            backend_compile=backend_compile,
        )

kornia/augmentation/test_augmentation2.py:334: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

augmentation_cls = <class 'kornia.augmentation._2d.intensity.sharpness.RandomSharpness'>, target = 'jax', init_args = (1.0,), init_kwargs = {'p': 1.0}
call_args = (tensor([[[[0.9227, 0.9022, 0.5534, 0.5797, 0.4925],
          [0.2217, 0.3330, 0.1196, 0.3117, 0.9132],
          [0...., 0.5626],
          [0.9795, 0.4075, 0.2005, 0.2264, 0.0858],
          [0.3757, 0.5372, 0.9795, 0.3182, 0.5175]]]]),)
call_kwargs = {}, deterministic_output = False, backend_compile = False, tolerance = 0.001

    def _test_augmentation_class(
        augmentation_cls,
        target,
        init_args=(),
        init_kwargs={},
        call_args=(),
        call_kwargs={},
        deterministic_output=True,
        backend_compile=False,
        tolerance=1e-3,
    ):
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, target=target)
        transpiled_cls = eval("transpiled_" + f"{augmentation_cls.__module__}.{augmentation_cls.__name__}")
    
        torch_aug = augmentation_cls(*init_args, **init_kwargs)
        transpiled_init_args = _nest_torch_tensor_to_new_framework(init_args, target)
        transpiled_init_kwargs = _nest_torch_tensor_to_new_framework(init_kwargs, target)
        transpiled_aug = transpiled_cls(*transpiled_init_args, **transpiled_init_kwargs)
    
        # assert dir(torch_aug) == dir(transpiled_aug), f"attributes/methods of transpiled object do not align with the original - orig: {dir(torch_aug)} != transpiled: {dir(transpiled_aug)}"
    
        torch_out = torch_aug(*call_args, **call_kwargs)
        transpiled_call_args = _nest_torch_tensor_to_new_framework(call_args, target)
        transpiled_call_kwargs = _nest_torch_tensor_to_new_framework(call_kwargs, target)
>       transpiled_out = transpiled_aug(*transpiled_call_args, **transpiled_call_kwargs)

kornia/augmentation/test_augmentation2.py:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_RandomSharpness(sharpness=1.0, p=1.0, p_batch=1.0, same_on_batch=False)
input = Array([[[[0.9226681 , 0.9022162 , 0.5534068 , 0.5797207 , 0.49250668],
         [0.22168207, 0.33295196, 0.11961615, 0... 0.22636741, 0.08577883],
         [0.3757388 , 0.5372005 , 0.979507  , 0.31819588, 0.51753646]]]],      dtype=float32)
params = {'batch_prob': Array([1.], dtype=float32), 'forward_input_shape': Array([1, 1, 5, 5], dtype=int64), 'sharpness': Array([0.10536897], dtype=float32)}, kwargs = {}
jax_shape_frnt_ = <function jax_shape_frnt_ at 0x7f3a9f252dd0>, jax_set_item = <function jax_set_item at 0x7f3ae782a710>, tensor = <function jax_tensor_frnt at 0x7f3a9ff617e0>
in_tensor = Array([[[[0.9226681 , 0.9022162 , 0.5534068 , 0.5797207 , 0.49250668],
         [0.22168207, 0.33295196, 0.11961615, 0... 0.22636741, 0.08577883],
         [0.3757388 , 0.5372005 , 0.979507  , 0.31819588, 0.51753646]]]],      dtype=float32)
input_shape = ivy.frontends.torch.Size([1, 1, 5, 5]), batch_shape = ivy.frontends.torch.Size([1, 1, 5, 5]), flags = {}

    def __call__(self, input, params=None, **kwargs):
        from ...ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ...ivy.functional.backends.jax.general import jax_set_item
        from ..core._backend import tensor
    
        in_tensor = self.__unpack_input__(input)
        input_shape = jax_shape_frnt_(in_tensor)
        in_tensor = self.transform_tensor(in_tensor)
        batch_shape = jax_shape_frnt_(in_tensor)
        if params is None:
            params = self.forward_parameters(batch_shape)
        if "batch_prob" not in params:
            params = jax_set_item(params, "batch_prob", tensor([True] * batch_shape[0]))
        params, flags = self._process_kwargs_to_params_and_flags(
            params, self.flags, **kwargs
        )
>       output = self.apply_func(in_tensor, params, flags)

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/base.py:219: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_RandomSharpness(sharpness=1.0, p=1.0, p_batch=1.0, same_on_batch=False)
in_tensor = Array([[[[0.9226681 , 0.9022162 , 0.5534068 , 0.5797207 , 0.49250668],
         [0.22168207, 0.33295196, 0.11961615, 0... 0.22636741, 0.08577883],
         [0.3757388 , 0.5372005 , 0.979507  , 0.31819588, 0.51753646]]]],      dtype=float32)
params = {'batch_prob': Array([1.], dtype=float32), 'forward_input_shape': Array([1, 1, 5, 5], dtype=int64), 'sharpness': Array([0.10536897], dtype=float32)}, flags = {}

    def apply_func(self, in_tensor, params, flags=None):
        if flags is None:
            flags = self.flags
        trans_matrix = self.generate_transformation_matrix(in_tensor, params, flags)
>       output = self.transform_inputs(in_tensor, params, flags, trans_matrix)

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/_2d/base.py:123: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_RandomSharpness(sharpness=1.0, p=1.0, p_batch=1.0, same_on_batch=False)
input = Array([[[[0.9226681 , 0.9022162 , 0.5534068 , 0.5797207 , 0.49250668],
         [0.22168207, 0.33295196, 0.11961615, 0... 0.22636741, 0.08577883],
         [0.3757388 , 0.5372005 , 0.979507  , 0.31819588, 0.51753646]]]],      dtype=float32)
params = {'batch_prob': Array([1.], dtype=float32), 'forward_input_shape': Array([1, 1, 5, 5], dtype=int64), 'sharpness': Array([0.10536897], dtype=float32)}, flags = {}
transform = Array([[[1., 0., 0.],
        [0., 1., 0.],
        [0., 0., 1.]]], dtype=float32), kwargs = {}, jax_shape_frnt_ = <function jax_shape_frnt_ at 0x7f3a9f252dd0>
jax_all_frnt_ = <function jax_all_frnt_ at 0x7f3a9f251750>, jax_any_frnt_ = <function jax_any_frnt_ at 0x7f3a9f26cb80>, jax_get_item = <function jax_get_item at 0x7f3ae782a560>
jax_is_autocast_enabled = <function jax_is_autocast_enabled at 0x7f3ae77777f0>, jax_type_frnt_ = <function jax_type_frnt_ at 0x7f3a9f26ecb0>
jax_index_put_frnt_ = <function jax_index_put_frnt_ at 0x7f3a9f26d240>

    def transform_inputs(self, input, params, flags, transform=None, **kwargs):
        from ...ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_all_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_any_frnt_
        from ...ivy.functional.backends.jax.general import jax_get_item
        from ..utils.helpers import jax_is_autocast_enabled
        from ...ivy.functional.frontends.torch.tensor import jax_type_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_index_put_frnt_
        from .utils.helpers import jax__transform_output_shape
    
        params, flags = self._process_kwargs_to_params_and_flags(
            self._params if params is None else params, flags, **kwargs
        )
        batch_prob = params["batch_prob"]
        to_apply = batch_prob > 0.5
        ori_shape = jax_shape_frnt_(input)
        in_tensor = self.transform_tensor(input)
        self.validate_tensor(in_tensor)
        if jax_all_frnt_(to_apply):
>           output = self.apply_transform(in_tensor, params, flags, transform=transform)

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/base.py:333: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_RandomSharpness(sharpness=1.0, p=1.0, p_batch=1.0, same_on_batch=False)
input = Array([[[[0.9226681 , 0.9022162 , 0.5534068 , 0.5797207 , 0.49250668],
         [0.22168207, 0.33295196, 0.11961615, 0... 0.22636741, 0.08577883],
         [0.3757388 , 0.5372005 , 0.979507  , 0.31819588, 0.51753646]]]],      dtype=float32)
params = {'batch_prob': Array([1.], dtype=float32), 'forward_input_shape': Array([1, 1, 5, 5], dtype=int64), 'sharpness': Array([0.10536897], dtype=float32)}, flags = {}
transform = Array([[[1., 0., 0.],
        [0., 1., 0.],
        [0., 0., 1.]]], dtype=float32)

    def apply_transform(self, input, params, flags, transform=None):
        factor = params["sharpness"]
>       return sharpness(input, factor)
E       NameError: name 'sharpness' is not defined

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/_2d/intensity/sharpness.py:41: NameError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.RandomSharpness
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/augmentation/test_augmentation2.py::test_RandomMotionBlur[jax-s2s-False] - TypeError: jax_randint_frnt() missing 1 required positional argument: 'size'
FAILED kornia/augmentation/test_augmentation2.py::test_RandomSaltAndPepperNoise[jax-s2s-False] - AttributeError: 'jaxlib.xla_extension.ArrayImpl' object has no attribute 'to'
FAILED kornia/augmentation/test_augmentation2.py::test_RandomSharpness[jax-s2s-False] - NameError: name 'sharpness' is not defined
============================================================================== 3 failed, 14 passed in 3432.09s (0:57:12) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 2 items

kornia/geometry/test_line.py Fs                                                                                                                                                                  [100%]

=============================================================================================== FAILURES ===============================================================================================
____________________________________________________________________________________ test_fit_line[numpy-s2s-False] ____________________________________________________________________________________

target_framework = 'numpy', mode = 's2s', backend_compile = False

    def test_fit_line(target_framework, mode, backend_compile):
        print("kornia.geometry.line.fit_line")
    
        if backend_compile:
            pytest.skip()
    
>       transpiled_fit_line = ivy.transpile(kornia.geometry.line.fit_line, source="torch", target=target_framework)

kornia/geometry/test_line.py:24: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

object = <function fit_line at 0x7f4e31b57250>, source = 'torch', target = 'numpy', reuse_existing = True, output_dir = 'ivy_transpiled_outputs/'

    def transpile(
        object,
        source: str = "torch",
        target: str = "tensorflow",
        reuse_existing: bool = True,
        output_dir: str = "ivy_transpiled_outputs/",
    ):
        """Converts a given object (class/function) from one framework to another.
    
        This function performs source-to-source translation of a given object from the source framework
        to the target framework.
    
        The object can be translated between two frameworks or between the Ivy IR as well
        e.g. (source="torch_frontend", target="ivy") or (source="torch_frontend", target="tensorflow") etc.
    
        Args:
            object: The object (class/function) to be translated.
            source (str, optional): The source framework. Defaults to 'torch'.
            target (str, optional): The target framework. Defaults to 'tensorflow'.
            reuse_existing (bool, optional): If True, the function will check if `object`
                                             already exists in the translated directory and reuse it.
                                             If False, it will re-translate `object`,
                                             even if it already exists in the directory, and overwrite
                                             the old implementation. Defaults to 'True'.
            output_dir (str, optional): The path to the directory where translated files will be saved.
                                        Defaults to 'ivy_transpiled_outputs/' in the current working directory.
    
        Returns:
            The translated object."""
    
        from ._compiler import transpile as _transpile
    
>       return _transpile(
            object=object,
            source=source,
            target=target,
            reuse_existing=reuse_existing,
            output_dir=output_dir,
        )

../ivy/ivy/compiler/compiler.py:208: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:322: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:310: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:300: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXL.pyx:24: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

MC.pyx:145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

MC.pyx:127: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f4dd8ed9c30>, node = <gast.gast.Module object at 0x7f4dd8c52440>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f4dd8ed9c30>, node = <gast.gast.Module object at 0x7f4dd8c52440>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
>                       value = self.visit(value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:486: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f4dd8ed9c30>, node = <gast.gast.FunctionDef object at 0x7f4dd8c51690>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:273: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f4dd8ed9c30>, node = <gast.gast.Return object at 0x7f4dd8c4ec20>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f4dd8ed9c30>, node = <gast.gast.Return object at 0x7f4dd8c4ec20>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
                        value = self.visit(value)
                        if value is None:
                            continue
                        elif not isinstance(value, AST):
                            new_values.extend(value)
                            continue
                    new_values.append(value)
                old_value[:] = new_values
            elif isinstance(old_value, AST):
>               new_node = self.visit(old_value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:495: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f4dd8ed9c30>, node = <gast.gast.Call object at 0x7f4dd8c4fd30>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f4dd8ed9c30>, node = <gast.gast.Call object at 0x7f4dd8c4fd30>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
                        value = self.visit(value)
                        if value is None:
                            continue
                        elif not isinstance(value, AST):
                            new_values.extend(value)
                            continue
                    new_values.append(value)
                old_value[:] = new_values
            elif isinstance(old_value, AST):
>               new_node = self.visit(old_value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:495: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f4dd8ed9c30>, node = <gast.gast.Name object at 0x7f4dd8c4fe50>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:324: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:141: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:111: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:91: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   I.InvalidObjectException: Cannot transpile the object '<class 'ivy_transpiled_outputs.ivy_outputs.kornia.geometry.line.ivy_ParametrizedLine'>' to `numpy` because it is an instance of a stateful class.

IL.pyx:247: InvalidObjectException
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.line.fit_line
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/geometry/test_line.py::test_fit_line[numpy-s2s-False] - I.InvalidObjectException: Cannot transpile the object '<class 'ivy_transpiled_outputs.ivy_outputs.kornia.geometry.line.ivy_Para...
=============================================================================== 1 failed, 1 skipped in 72.11s (0:01:12) ================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 5 items

kornia/geometry/test_solvers.py .....                                                                                                                                                            [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
==================================================================================== 5 passed in 269.29s (0:04:29) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 35 items

kornia/test_losses.py .................FF...F............                                                                                                                                        [100%]

=============================================================================================== FAILURES ===============================================================================================
_________________________________________________________________________________ test_HausdorffERLoss[jax-s2s-False] __________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_HausdorffERLoss(target_framework, mode, backend_compile):
        print("kornia.losses.HausdorffERLoss")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledHausdorffERLoss = ivy.transpile(kornia.losses.HausdorffERLoss, source="torch", target=target_framework)
    
        torch_loss_fn = kornia.losses.HausdorffERLoss()
        transpiled_loss_fn = TranspiledHausdorffERLoss()
    
        torch_args = (
            torch.randn(5, 3, 20, 20),
            (torch.rand(5, 1, 20, 20) * 2).long(),
        )
        transpiled_args = _nest_torch_tensor_to_new_framework(torch_args, target_framework)
    
        torch_res = torch_loss_fn(*torch_args)
>       transpiled_res = transpiled_loss_fn(*transpiled_args)

kornia/test_losses.py:446: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_HausdorffERLoss()
pred = Array([[[[-1.177454  ,  0.25442654,  0.09347799, ...,  0.3006743 ,
          -0.90449846,  0.862194  ],
         [-1.4...       [-0.41626173, -1.1917478 , -1.2986147 , ...,  0.5670363 ,
           0.35094872,  0.38648683]]]], dtype=float32)
target = Array([[[[0, 1, 0, ..., 1, 0, 0],
         [0, 1, 1, ..., 1, 1, 0],
         [0, 1, 0, ..., 1, 0, 0],
         ...,
  ...,
         [0, 0, 1, ..., 0, 1, 0],
         [1, 1, 1, ..., 1, 1, 1],
         [0, 1, 1, ..., 0, 0, 0]]]], dtype=int64)

    def __call__(self, pred, target):
        from ...ivy.functional.frontends.torch.tensor import jax_dim_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_max_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_size_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_min_frnt_
    
        if jax_dim_frnt_(pred) != 4:
            raise ValueError(f"Only 2D images supported. Got {jax_dim_frnt_(pred)}.")
        if not (
            jax_max_frnt_(target) < jax_size_frnt_(pred, 1)
            and jax_min_frnt_(target) >= 0
            and target.dtype == jnp.int64
        ):
            raise ValueError(
                f"Expect long type target value in range (0, {jax_size_frnt_(pred, 1)}). ({jax_min_frnt_(target)}, {jax_max_frnt_(target)})"
            )
>       return super().__call__(pred, target)

ivy_transpiled_outputs/jax_outputs/kornia/losses/hausdorff.py:279: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_HausdorffERLoss()
pred = Array([[[[-1.177454  ,  0.25442654,  0.09347799, ...,  0.3006743 ,
          -0.90449846,  0.862194  ],
         [-1.4...       [-0.41626173, -1.1917478 , -1.2986147 , ...,  0.5670363 ,
           0.35094872,  0.38648683]]]], dtype=float32)
target = Array([[[[0, 1, 0, ..., 1, 0, 0],
         [0, 1, 1, ..., 1, 1, 0],
         [0, 1, 0, ..., 1, 0, 0],
         ...,
  ...,
         [0, 0, 1, ..., 0, 1, 0],
         [1, 1, 1, ..., 1, 1, 1],
         [0, 1, 1, ..., 0, 0, 0]]]], dtype=int64)

    def __call__(self, pred, target):
        from ..core._backend import where
        from ..core._backend import stack
        from ..core._backend import tensor
        from ...ivy.functional.frontends.torch.tensor import jax_size_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_item_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_max_frnt_
        from ...ivy.functional.backends.jax.general import jax_get_item
        from ...ivy.functional.frontends.torch.tensor import jax_mean_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_sum_frnt_
    
        if not (
            jax_shape_frnt_(pred)[2:] == jax_shape_frnt_(target)[2:]
            and jax_size_frnt_(pred, 0) == jax_size_frnt_(target, 0)
            and jax_size_frnt_(target, 1) == 1
        ):
            raise ValueError(
                f"Prediction and target need to be of same size, and target should not be one-hot.Got {jax_shape_frnt_(pred)} and {jax_shape_frnt_(target)}."
            )
        if jax_size_frnt_(pred, 1) < jax_item_frnt_(jax_max_frnt_(target)):
            raise ValueError("Invalid target value.")
        out = stack(
>           [
                self.perform_erosion(
                    jax_get_item(
                        pred, (slice(None, None, None), slice(i, i + 1, None))
                    ),
                    where(
                        target == i,
                        tensor(1, device=target.device, dtype=target.dtype),
                        tensor(0, device=target.device, dtype=target.dtype),
                    ),
                )
                for i in range(jax_size_frnt_(pred, 1))
            ]
        )

ivy_transpiled_outputs/jax_outputs/kornia/losses/hausdorff.py:118: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

.0 = <range_iterator object at 0x7f25fe971dd0>

        [
>           self.perform_erosion(
                jax_get_item(
                    pred, (slice(None, None, None), slice(i, i + 1, None))
                ),
                where(
                    target == i,
                    tensor(1, device=target.device, dtype=target.dtype),
                    tensor(0, device=target.device, dtype=target.dtype),
                ),
            )
            for i in range(jax_size_frnt_(pred, 1))
        ]
    )

ivy_transpiled_outputs/jax_outputs/kornia/losses/hausdorff.py:119: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_HausdorffERLoss()
pred = Array([[[[-1.177454  ,  0.25442654,  0.09347799, ...,  0.3006743 ,
          -0.90449846,  0.862194  ],
         [-1.4...       [ 0.18134418, -0.02239206,  0.06570774, ..., -2.2268062 ,
           0.44697323, -0.8888894 ]]]], dtype=float32)
target = Array([[[[1, 0, 1, ..., 0, 1, 1],
         [1, 0, 0, ..., 0, 0, 1],
         [1, 0, 1, ..., 0, 1, 1],
         ...,
  ...,
         [1, 1, 0, ..., 1, 0, 1],
         [0, 0, 0, ..., 0, 0, 0],
         [1, 0, 0, ..., 1, 1, 1]]]], dtype=int64)

    def perform_erosion(self, pred, target):
        from ..core._backend import as_tensor
        from ..core._backend import zeros_like
        from ..core._backend import where
        from ...ivy.functional.frontends.torch.creation_ops import (
            jax_ones_like_v_0p4p0_and_above_frnt,
        )
        from ...ivy.functional.frontends.torch.tensor import jax_size_frnt_
        from ...ivy.functional.backends.jax.general import jax_set_item
        from ...ivy.functional.frontends.torch.tensor import jax_squeeze_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_any_frnt_
    
        bound = (pred - target) ** 2
        kernel = as_tensor(self.kernel, device=pred.device, dtype=pred.dtype)
        eroded = zeros_like(bound, device=pred.device, dtype=pred.dtype)
        mask = jax_ones_like_v_0p4p0_and_above_frnt(
            bound, device=pred.device, dtype=jnp.bool
        )
        padding = (jax_size_frnt_(kernel, -1) - 1) // 2
        for k in range(self.k):
>           dilation = self.conv(bound, weight=kernel, padding=padding, groups=1)
E           TypeError: jax_conv2d_frnt() got multiple values for argument 'weight'

ivy_transpiled_outputs/jax_outputs/kornia/losses/hausdorff.py:81: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.losses.HausdorffERLoss
________________________________________________________________________________ test_HausdorffERLoss3D[jax-s2s-False] _________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_HausdorffERLoss3D(target_framework, mode, backend_compile):
        print("kornia.losses.HausdorffERLoss3D")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledHausdorffERLoss3D = ivy.transpile(kornia.losses.HausdorffERLoss3D, source="torch", target=target_framework)
    
        torch_loss_fn = kornia.losses.HausdorffERLoss3D()
        transpiled_loss_fn = TranspiledHausdorffERLoss3D()
    
        torch_args = (
            torch.randn(5, 3, 20, 20, 20),
            (torch.rand(5, 1, 20, 20, 20) * 2).long(),
        )
        transpiled_args = _nest_torch_tensor_to_new_framework(torch_args, target_framework)
    
        torch_res = torch_loss_fn(*torch_args)
>       transpiled_res = transpiled_loss_fn(*transpiled_args)

kornia/test_losses.py:471: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_HausdorffERLoss3D()
pred = Array([[[[[ 3.26329708e-01, -2.11770058e+00,  2.22509432e+00, ...,
           -9.37261701e-01,  5.70644200e-01, -8.807...62031e+00,  2.06317306e+00, ...,
            6.61357343e-01, -4.02961791e-01, -1.13702834e+00]]]]],      dtype=float32)
target = Array([[[[[0, 1, 1, ..., 1, 0, 0],
          [1, 1, 1, ..., 0, 0, 1],
          [0, 0, 1, ..., 0, 1, 1],
          ......        [1, 0, 0, ..., 1, 0, 1],
          [0, 1, 1, ..., 1, 0, 0],
          [0, 1, 1, ..., 0, 0, 0]]]]], dtype=int64)

    def __call__(self, pred, target):
        from ...ivy.functional.frontends.torch.tensor import jax_dim_frnt_
    
        if jax_dim_frnt_(pred) != 5:
            raise ValueError(f"Only 3D images supported. Got {jax_dim_frnt_(pred)}.")
>       return super().__call__(pred, target)

ivy_transpiled_outputs/jax_outputs/kornia/losses/hausdorff.py:270: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_HausdorffERLoss3D()
pred = Array([[[[[ 3.26329708e-01, -2.11770058e+00,  2.22509432e+00, ...,
           -9.37261701e-01,  5.70644200e-01, -8.807...62031e+00,  2.06317306e+00, ...,
            6.61357343e-01, -4.02961791e-01, -1.13702834e+00]]]]],      dtype=float32)
target = Array([[[[[0, 1, 1, ..., 1, 0, 0],
          [1, 1, 1, ..., 0, 0, 1],
          [0, 0, 1, ..., 0, 1, 1],
          ......        [1, 0, 0, ..., 1, 0, 1],
          [0, 1, 1, ..., 1, 0, 0],
          [0, 1, 1, ..., 0, 0, 0]]]]], dtype=int64)

    def __call__(self, pred, target):
        from ..core._backend import where
        from ..core._backend import stack
        from ..core._backend import tensor
        from ...ivy.functional.frontends.torch.tensor import jax_size_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_item_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_max_frnt_
        from ...ivy.functional.backends.jax.general import jax_get_item
        from ...ivy.functional.frontends.torch.tensor import jax_mean_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_sum_frnt_
    
        if not (
            jax_shape_frnt_(pred)[2:] == jax_shape_frnt_(target)[2:]
            and jax_size_frnt_(pred, 0) == jax_size_frnt_(target, 0)
            and jax_size_frnt_(target, 1) == 1
        ):
            raise ValueError(
                f"Prediction and target need to be of same size, and target should not be one-hot.Got {jax_shape_frnt_(pred)} and {jax_shape_frnt_(target)}."
            )
        if jax_size_frnt_(pred, 1) < jax_item_frnt_(jax_max_frnt_(target)):
            raise ValueError("Invalid target value.")
        out = stack(
>           [
                self.perform_erosion(
                    jax_get_item(
                        pred, (slice(None, None, None), slice(i, i + 1, None))
                    ),
                    where(
                        target == i,
                        tensor(1, device=target.device, dtype=target.dtype),
                        tensor(0, device=target.device, dtype=target.dtype),
                    ),
                )
                for i in range(jax_size_frnt_(pred, 1))
            ]
        )

ivy_transpiled_outputs/jax_outputs/kornia/losses/hausdorff.py:118: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

.0 = <range_iterator object at 0x7f25fea34a50>

        [
>           self.perform_erosion(
                jax_get_item(
                    pred, (slice(None, None, None), slice(i, i + 1, None))
                ),
                where(
                    target == i,
                    tensor(1, device=target.device, dtype=target.dtype),
                    tensor(0, device=target.device, dtype=target.dtype),
                ),
            )
            for i in range(jax_size_frnt_(pred, 1))
        ]
    )

ivy_transpiled_outputs/jax_outputs/kornia/losses/hausdorff.py:119: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_HausdorffERLoss3D()
pred = Array([[[[[ 3.26329708e-01, -2.11770058e+00,  2.22509432e+00, ...,
           -9.37261701e-01,  5.70644200e-01, -8.807...16600e-01,  8.60004723e-01, ...,
           -5.82976341e-01, -4.69865918e-01,  1.43641245e+00]]]]],      dtype=float32)
target = Array([[[[[1, 0, 0, ..., 0, 1, 1],
          [0, 0, 0, ..., 1, 1, 0],
          [1, 1, 0, ..., 1, 0, 0],
          ......        [0, 1, 1, ..., 0, 1, 0],
          [1, 0, 0, ..., 0, 1, 1],
          [1, 0, 0, ..., 1, 1, 1]]]]], dtype=int64)

    def perform_erosion(self, pred, target):
        from ..core._backend import as_tensor
        from ..core._backend import zeros_like
        from ..core._backend import where
        from ...ivy.functional.frontends.torch.creation_ops import (
            jax_ones_like_v_0p4p0_and_above_frnt,
        )
        from ...ivy.functional.frontends.torch.tensor import jax_size_frnt_
        from ...ivy.functional.backends.jax.general import jax_set_item
        from ...ivy.functional.frontends.torch.tensor import jax_squeeze_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_any_frnt_
    
        bound = (pred - target) ** 2
        kernel = as_tensor(self.kernel, device=pred.device, dtype=pred.dtype)
        eroded = zeros_like(bound, device=pred.device, dtype=pred.dtype)
        mask = jax_ones_like_v_0p4p0_and_above_frnt(
            bound, device=pred.device, dtype=jnp.bool
        )
        padding = (jax_size_frnt_(kernel, -1) - 1) // 2
        for k in range(self.k):
>           dilation = self.conv(bound, weight=kernel, padding=padding, groups=1)
E           TypeError: jax_conv3d_frnt() got multiple values for argument 'weight'

ivy_transpiled_outputs/jax_outputs/kornia/losses/hausdorff.py:81: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.losses.HausdorffERLoss3D
__________________________________________________________________________________ test_TotalVariation[jax-s2s-False] __________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_TotalVariation(target_framework, mode, backend_compile):
        print("kornia.losses.TotalVariation")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledTotalVariation = ivy.transpile(kornia.losses.TotalVariation, source="torch", target=target_framework)
    
        torch_loss_fn = kornia.losses.TotalVariation()
        transpiled_loss_fn = TranspiledTotalVariation()
    
        torch_args = (
            torch.ones((2, 3, 4, 4)),
        )
        transpiled_args = _nest_torch_tensor_to_new_framework(torch_args, target_framework)
    
        torch_res = torch_loss_fn(*torch_args).data
>       transpiled_res = transpiled_loss_fn(*transpiled_args).data
E       AttributeError: 'jaxlib.xla_extension.ArrayImpl' object has no attribute 'data'

kornia/test_losses.py:570: AttributeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.losses.TotalVariation
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/test_losses.py::test_HausdorffERLoss[jax-s2s-False] - TypeError: jax_conv2d_frnt() got multiple values for argument 'weight'
FAILED kornia/test_losses.py::test_HausdorffERLoss3D[jax-s2s-False] - TypeError: jax_conv3d_frnt() got multiple values for argument 'weight'
FAILED kornia/test_losses.py::test_TotalVariation[jax-s2s-False] - AttributeError: 'jaxlib.xla_extension.ArrayImpl' object has no attribute 'data'
============================================================================== 3 failed, 32 passed in 2296.34s (0:38:16) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 6 items

kornia/test_nerf.py .FF..F                                                                                                                                                                       [100%]

=============================================================================================== FAILURES ===============================================================================================
_____________________________________________________________________________ test_NerfModelRenderer[tensorflow-s2s-False] _____________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_NerfModelRenderer(target_framework, mode, backend_compile):
        print("kornia.nerf.nerf_model.NerfModelRenderer")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledPinholeCamera = ivy.transpile(kornia.geometry.camera.pinhole.PinholeCamera, source="torch", target=target_framework)
        TranspiledNerfModel = ivy.transpile(nerf_model.NerfModel, source="torch", target=target_framework)
        TranspiledNerfModelRenderer = ivy.transpile(nerf_model.NerfModelRenderer, source="torch", target=target_framework)
    
        torch_nerf_model = nerf_model.NerfModel(num_ray_points=32)
        transpiled_nerf_model = TranspiledNerfModel(num_ray_points=32)
    
        torch_camera_args = (
            torch.rand(1, 4, 4),
            torch.rand(1, 4, 4),
            torch.tensor([256]),
            torch.tensor([256]),
        )
>       transpiled_camera_args = _nest_torch_tensor_to_new_framework(torch_camera_args)
E       TypeError: _nest_torch_tensor_to_new_framework() missing 1 required positional argument: 'target'

kornia/test_nerf.py:63: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.nerf.nerf_model.NerfModelRenderer
____________________________________________________________________________________ test_MLP[tensorflow-s2s-False] ____________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_MLP(target_framework, mode, backend_compile):
        print("kornia.nerf.nerf_model.MLP")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledMLP = ivy.transpile(nerf_model.MLP, source="torch", target=target_framework)
    
        torch_args = (
            torch.rand(5, 3),
        )
        transpiled_args = _nest_torch_tensor_to_new_framework(torch_args, target_framework)
    
        torch_mlp = nerf_model.MLP(num_dims=3)
        transpiled_mlp = TranspiledMLP(num_dims=3)
    
        torch_out = torch_mlp(*torch_args)
>       transpiled_out = transpiled_mlp(*transpiled_args)

kornia/test_nerf.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_MLP(
  (_mlp): tensorflow_ModuleList(
    (0-7): 8 x tensorflow_Sequential(
      (0): KerasDense()
      (1): tensorflow_ReLU()
    )
  )
)
args = (<tf.Tensor: shape=(5, 3), dtype=float32, numpy=
array([[0.6413965 , 0.07685238, 0.3421719 ],
       [0.47010028, 0.92...40216136],
       [0.10537714, 0.38868505, 0.04257709],
       [0.4460283 , 0.21748471, 0.11089653]], dtype=float32)>,)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x7f639c9e99a0, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...ode_context=['        return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)\n'], index=0), ...]

>   ???

/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_MLP(
  (_mlp): tensorflow_ModuleList(
    (0-7): 8 x tensorflow_Sequential(
      (0): KerasDense()
      ....40216136],
       [0.10537714, 0.38868505, 0.04257709],
       [0.4460283 , 0.21748471, 0.11089653]], dtype=float32)>)
kwargs = {}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_MLP(
  (_mlp): tensorflow_ModuleList(
    (0-7): 8 x tensorflow_Sequential(
      (0): KerasDense()
      (1): tensorflow_ReLU()
    )
  )
), v = None, buffers = None
args = (<tf.Tensor: shape=(5, 3), dtype=float32, numpy=
array([[0.6413965 , 0.07685238, 0.3421719 ],
       [0.47010028, 0.92...40216136],
       [0.10537714, 0.38868505, 0.04257709],
       [0.4460283 , 0.21748471, 0.11089653]], dtype=float32)>,)
kwargs = {}

>   ???

/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_MLP(
  (_mlp): tensorflow_ModuleList(
    (0-7): 8 x tensorflow_Sequential(
      (0): KerasDense()
      ....40216136],
       [0.10537714, 0.38868505, 0.04257709],
       [0.4460283 , 0.21748471, 0.11089653]], dtype=float32)>)
kwargs = {'buffers': None, 'v': None}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_MLP(
  (_mlp): tensorflow_ModuleList(
    (0-7): 8 x tensorflow_Sequential(
      (0): KerasDense()
      (1): tensorflow_ReLU()
    )
  )
), v = None, buffers = None
args = (<tf.Tensor: shape=(5, 3), dtype=float32, numpy=
array([[0.6413965 , 0.07685238, 0.3421719 ],
       [0.47010028, 0.92...40216136],
       [0.10537714, 0.38868505, 0.04257709],
       [0.4460283 , 0.21748471, 0.11089653]], dtype=float32)>,)
kwargs = {}
first_arr = <tf.Tensor: shape=(5, 3), dtype=float32, numpy=
array([[0.6413965 , 0.07685238, 0.3421719 ],
       [0.47010028, 0.923...0.40216136],
       [0.10537714, 0.38868505, 0.04257709],
       [0.4460283 , 0.21748471, 0.11089653]], dtype=float32)>
replace_v = False, replace_buffers = False, call_signature = <Signature (x)>

>   ???

/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_MLP(
  (_mlp): tensorflow_ModuleList(
    (0-7): 8 x tensorflow_Sequential(
      (0): KerasDense()
      (1): tensorflow_ReLU()
    )
  )
),)
kwargs = {'x': <tf.Tensor: shape=(5, 3), dtype=float32, numpy=
array([[0.6413965 , 0.07685238, 0.3421719 ],
       [0.47010028,....40216136],
       [0.10537714, 0.38868505, 0.04257709],
       [0.4460283 , 0.21748471, 0.11089653]], dtype=float32)>}

    @wraps(fn)
    def error_handler(*args, **kwargs):
        if not is_traceback_filtering_enabled():
            return fn(*args, **kwargs)
    
        filtered_tb = None
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            filtered_tb = _process_traceback_frames(e.__traceback__)
            # To get the full stack trace, call:
            # `keras.config.disable_traceback_filtering()`
>           raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/keras/src/utils/traceback_utils.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_MLP(
  (_mlp): tensorflow_ModuleList(
    (0-7): 8 x tensorflow_Sequential(
      (0): KerasDense()
      (1): tensorflow_ReLU()
    )
  )
)
x = <tf.Tensor: shape=(5, 3), dtype=float32, numpy=
array([[0.6413965 , 0.07685238, 0.3421719 ],
       [0.47010028, 0.923...0.40216136],
       [0.10537714, 0.38868505, 0.04257709],
       [0.4460283 , 0.21748471, 0.11089653]], dtype=float32)>

>   ???

/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/kornia/nerf/nerf_model.py:77: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Sequential(
  (0): KerasDense()
  (1): tensorflow_ReLU()
)
args = (<tf.Tensor: shape=(5, 3), dtype=float32, numpy=
array([[0.6413965 , 0.07685238, 0.3421719 ],
       [0.47010028, 0.92...40216136],
       [0.10537714, 0.38868505, 0.04257709],
       [0.4460283 , 0.21748471, 0.11089653]], dtype=float32)>,)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x55bbbe906cd0, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...function='__call__', code_context=['                    outputs = super().__call__(*args, **kwargs)\n'], index=0), ...]

>   ???

/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Sequential(
  (0): KerasDense()
  (1): tensorflow_ReLU()
), v = None, buffers = None
args = (<tf.Tensor: shape=(5, 3), dtype=float32, numpy=
array([[0.6413965 , 0.07685238, 0.3421719 ],
       [0.47010028, 0.92...40216136],
       [0.10537714, 0.38868505, 0.04257709],
       [0.4460283 , 0.21748471, 0.11089653]], dtype=float32)>,)
kwargs = {}

>   ???

/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Sequential(
  (0): KerasDense()
  (1): tensorflow_ReLU()
), v = None, buffers = None
args = (<tf.Tensor: shape=(5, 3), dtype=float32, numpy=
array([[0.6413965 , 0.07685238, 0.3421719 ],
       [0.47010028, 0.92...40216136],
       [0.10537714, 0.38868505, 0.04257709],
       [0.4460283 , 0.21748471, 0.11089653]], dtype=float32)>,)
kwargs = {}
first_arr = <tf.Tensor: shape=(5, 3), dtype=float32, numpy=
array([[0.6413965 , 0.07685238, 0.3421719 ],
       [0.47010028, 0.923...0.40216136],
       [0.10537714, 0.38868505, 0.04257709],
       [0.4460283 , 0.21748471, 0.11089653]], dtype=float32)>
replace_v = False, replace_buffers = False, call_signature = <Signature (input)>

>   ???

/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Sequential(
  (0): KerasDense()
  (1): tensorflow_ReLU()
)
input = <tf.Tensor: shape=(5, 128), dtype=float32, numpy=
array([[-3.54362130e-02, -2.16132291e-02, -5.11924997e-02,
         ...
        -1.24460302e-01, -2.83526834e-02, -7.73017853e-02,
        -7.13833272e-02,  1.32757407e-02]], dtype=float32)>

>   ???

/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/torch/nn/modules/container.py:199: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_ReLU()
args = (<tf.Tensor: shape=(5, 128), dtype=float32, numpy=
array([[-3.54362130e-02, -2.16132291e-02, -5.11924997e-02,
        ...       -1.24460302e-01, -2.83526834e-02, -7.73017853e-02,
        -7.13833272e-02,  1.32757407e-02]], dtype=float32)>,)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x7f639c5ed780, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...function='__call__', code_context=['                    outputs = super().__call__(*args, **kwargs)\n'], index=0), ...]

>   ???

/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_ReLU(), v = None, buffers = None
args = (<tf.Tensor: shape=(5, 128), dtype=float32, numpy=
array([[-3.54362130e-02, -2.16132291e-02, -5.11924997e-02,
        ...       -1.24460302e-01, -2.83526834e-02, -7.73017853e-02,
        -7.13833272e-02,  1.32757407e-02]], dtype=float32)>,)
kwargs = {}

>   ???

/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_ReLU(), v = None, buffers = None
args = (<tf.Tensor: shape=(5, 128), dtype=float32, numpy=
array([[-3.54362130e-02, -2.16132291e-02, -5.11924997e-02,
        ...       -1.24460302e-01, -2.83526834e-02, -7.73017853e-02,
        -7.13833272e-02,  1.32757407e-02]], dtype=float32)>,)
kwargs = {}
first_arr = <tf.Tensor: shape=(5, 128), dtype=float32, numpy=
array([[-3.54362130e-02, -2.16132291e-02, -5.11924997e-02,
         ...
        -1.24460302e-01, -2.83526834e-02, -7.73017853e-02,
        -7.13833272e-02,  1.32757407e-02]], dtype=float32)>
replace_v = False, replace_buffers = False, call_signature = <Signature (input)>

>   ???

/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_ReLU(), args = ()
kwargs = {'input': <tf.Tensor: shape=(5, 128), dtype=float32, numpy=
array([[-3.54362130e-02, -2.16132291e-02, -5.11924997e-02,...        -1.24460302e-01, -2.83526834e-02, -7.73017853e-02,
        -7.13833272e-02,  1.32757407e-02]], dtype=float32)>}
tensorflow_get_item = <function tensorflow_get_item at 0x7f6397fb1ea0>, tensorflow_set_item = <function tensorflow_set_item at 0x7f6397fb2050>, DATA_FORMAT = 'channels_first'
fn_args_and_kwargs = {'input': <tf.Tensor: shape=(5, 128), dtype=float32, numpy=
array([[-3.54362130e-02, -2.16132291e-02, -5.11924997e-02,...        -1.24460302e-01, -2.83526834e-02, -7.73017853e-02,
        -7.13833272e-02,  1.32757407e-02]], dtype=float32)>}
conv_block_start = <function tensorflow_handle_transpose_in_input_and_output.<locals>.transpose_wrapper.<locals>.<lambda> at 0x7f639ca24280>

>   ???

/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:387: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

obj = tensorflow_ReLU()

>   ???

/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:315: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

object = <frame at 0x55bbbe78f1b0, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/kornia/nerf/nerf_model.py', line 77, code call>

    def getsourcelines(object):
        """Return a list of source lines and starting line number for an object.
    
        The argument may be a module, class, method, function, traceback, frame,
        or code object.  The source code is returned as a list of the lines
        corresponding to the object and the line number indicates where in the
        original source file the first line of code was found.  An OSError is
        raised if the source code cannot be retrieved."""
        object = unwrap(object)
>       lines, lnum = findsource(object)

/opt/miniconda/envs/multienv/lib/python3.10/inspect.py:1129: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

object = <frame at 0x55bbbe78f1b0, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/kornia/nerf/nerf_model.py', line 77, code call>

    def findsource(object):
        """Return the entire source file and starting line number for an object.
    
        The argument may be a module, class, method, function, traceback, frame,
        or code object.  The source code is returned as a list of all the lines
        in the file and the line number indexes a line in that list.  An OSError
        is raised if the source code cannot be retrieved."""
    
        file = getsourcefile(object)
        if file:
            # Invalidate cache if needed.
            linecache.checkcache(file)
        else:
            file = getfile(object)
            # Allow filenames in form of "<something>" to pass through.
            # `doctest` monkeypatches `linecache` module to enable
            # inspection, so let `linecache.getlines` to be called.
            if not (file.startswith('<') and file.endswith('>')):
                raise OSError('source code not available')
    
        module = getmodule(object, file)
        if module:
            lines = linecache.getlines(file, module.__dict__)
        else:
            lines = linecache.getlines(file)
        if not lines:
>           raise OSError('could not get source code')
E           OSError: Exception encountered when calling tensorflow_ReLU.call().
E           
E           [1mcould not get source code[0m
E           
E           Arguments received by tensorflow_ReLU.call():
E             • input=tf.Tensor(shape=(5, 128), dtype=float32)

/opt/miniconda/envs/multienv/lib/python3.10/inspect.py:958: OSError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.nerf.nerf_model.MLP
_____________________________________________________________________________ test_RandomRaySampler[tensorflow-s2s-False] ______________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_RandomRaySampler(target_framework, mode, backend_compile):
        print("kornia.nerf.samplers.RandomRaySampler")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledPinholeCamera = ivy.transpile(kornia.geometry.camera.pinhole.PinholeCamera, source="torch", target=target_framework)
        TranspiledRandomRaySampler = ivy.transpile(samplers.RandomRaySampler, source="torch", target=target_framework)
    
        torch_camera_args = (
            torch.rand(1, 4, 4),
            torch.rand(1, 4, 4),
            torch.tensor([256]),
            torch.tensor([256]),
        )
        transpiled_camera_args = _nest_torch_tensor_to_new_framework(torch_camera_args, target_framework)
    
        torch_camera = kornia.geometry.camera.pinhole.PinholeCamera(*torch_camera_args)
        transpiled_camera = TranspiledPinholeCamera(*transpiled_camera_args)
    
        heights, widths = torch.tensor([256]), torch.tensor([256])
        transpiled_heights = _array_to_new_backend(heights, target_framework)
        transpiled_widths = _array_to_new_backend(widths, target_framework)
    
        torch_sampler = samplers.RandomRaySampler(min_depth=0.1, max_depth=10.0, ndc=True, device="cpu", dtype=torch.float32)
        transpiled_sampler = TranspiledRandomRaySampler(min_depth=0.1, max_depth=10.0, ndc=True, device="cpu", dtype=torch.float32)
    
        torch_sampler.calc_ray_params(torch_camera, torch.tensor([1]))
>       transpiled_sampler.calc_ray_params(transpiled_camera, _array_to_new_backend(torch.tensor([1]), target_framework))

kornia/test_nerf.py:250: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <ivy_transpiled_outputs.tensorflow_outputs.kornia.nerf.samplers.tensorflow_RandomRaySampler object at 0x7f6396e8f0a0>
cameras = <ivy_transpiled_outputs.tensorflow_outputs.kornia.geometry.camera.pinhole.tensorflow_PinholeCamera object at 0x7f6396e8d810>
num_img_rays = <tf.Tensor: shape=(1,), dtype=int64, numpy=array([1])>

    def calc_ray_params(self, cameras, num_img_rays):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
    
        num_cams = cameras.batch_size
        if num_cams != tensorflow_shape_frnt_(num_img_rays)[0]:
            raise ValueError(
                f"Number of cameras {num_cams} does not match size of tensor to define number of rays to march from each camera {tensorflow_shape_frnt_(num_img_rays)[0]}"
            )
>       points_2d_camera = self.sample_points_2d(
            cameras.height, cameras.width, num_img_rays
        )

ivy_transpiled_outputs/tensorflow_outputs/kornia/nerf/samplers.py:384: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <ivy_transpiled_outputs.tensorflow_outputs.kornia.nerf.samplers.tensorflow_RandomRaySampler object at 0x7f6396e8f0a0>, heights = <tf.Tensor: shape=(1,), dtype=int64, numpy=array([256])>
widths = <tf.Tensor: shape=(1,), dtype=int64, numpy=array([256])>, num_img_rays = <tf.Tensor: shape=(1,), dtype=int32, numpy=array([1], dtype=int32)>

    def sample_points_2d(self, heights, widths, num_img_rays):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_int_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_tolist_frnt_
        from ...ivy.functional.frontends.torch.pointwise_ops import (
            tensorflow_trunc_frnt,
        )
        from ...ivy.functional.frontends.torch.random_sampling import (
            tensorflow_rand_frnt,
        )
    
        num_img_rays = tensorflow_int_frnt_(num_img_rays)
        points2d_as_flat_tensors: typing.Any = {}
        for camera_id, (height, width, n) in enumerate(
            zip(
                tensorflow_tolist_frnt_(heights),
                tensorflow_tolist_frnt_(widths),
                tensorflow_tolist_frnt_(num_img_rays),
            )
        ):
            y_rand = tensorflow_trunc_frnt(
>               tensorflow_rand_frnt(n, device=self._device, dtype=self._dtype) * height
            )

ivy_transpiled_outputs/tensorflow_outputs/kornia/nerf/samplers.py:364: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

generator = None, out = None, dtype = torch.float32, layout = None, device = 'cpu', requires_grad = False, pin_memory = False, size = (1,), kwargs = {}
tensorflow_random_uniform = <function tensorflow_random_uniform at 0x7f639712e5f0>, seed = None

    def tensorflow_rand_frnt(
        *size,
        generator=None,
        out=None,
        dtype=None,
        layout=None,
        device=None,
        requires_grad=False,
        pin_memory=False,
        **kwargs,
    ):
        from ...backends.tensorflow.random import tensorflow_random_uniform
    
        if not size and "size" not in kwargs:
            raise ValueError("Missing 1 required positional/keyword argument: size")
        size = size if size else kwargs["size"]
        if (
            isinstance(size, (list, tuple))
            and len(size) == 1
            and isinstance(size[0], (list, tuple, tuple))
        ):
            size = size[0]
        seed = generator.initial_seed() if generator is not None else None
>       return tensorflow_random_uniform(
            shape=size, seed=seed, out=out, dtype=dtype, device=device
        )

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/random_sampling.py:55: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype = torch.float32, args = (), kwargs = {'device': 'cpu', 'out': None, 'seed': None, 'shape': (1,)}, tensorflow_exists_bknd = <function tensorflow_exists_bknd at 0x7f6396fe0b80>
tensorflow_default_dtype_bknd = <function tensorflow_default_dtype_bknd at 0x7f6396fe01f0>, arr = None

    @functools.wraps(fn)
    def _infer_dtype(*args, dtype=None, **kwargs):
        from .functional.ivy.general import tensorflow_exists_bknd
        from .functional.ivy.data_type import tensorflow_default_dtype_bknd
    
        arr = (
            None
            if tensorflow_exists_bknd(dtype)
            else tensorflow__get_first_array(*args, **kwargs)
        )
        dtype = tensorflow_default_dtype_bknd(dtype=dtype, item=arr, as_native=True)
>       return fn(*args, dtype=dtype, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/func_wrapper.py:157: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    @tensorflow_infer_dtype
    def tensorflow_random_uniform(
        *,
        low: Union[float, tensorflow.Tensor, tensorflow.Variable] = 0.0,
        high: Union[float, tensorflow.Tensor, tensorflow.Variable, None] = 1.0,
        shape: Optional[Union[tf.TensorShape, Sequence[int], tensorflow.Tensor]] = None,
        dtype: tf.DType,
        device: Optional[str] = None,
        seed: Optional[int] = None,
        out: Optional[Union[tensorflow.Tensor, tensorflow.Variable]] = None,
    ):
        from ...ivy.random import tensorflow__check_bounds_and_get_shape_bknd
    
        shape = tensorflow__check_bounds_and_get_shape_bknd(
            low,
            float(
                tensorflow.experimental.numpy.finfo(tensorflow.float32).max
                if dtype is None
                else tensorflow.experimental.numpy.finfo(dtype).max
            )
            if high is None
            else high,
            shape,
        )
>       low = tensorflow.cast(low, dtype)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/backends/tensorflow/random.py:61: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (0.0, torch.float32), kwargs = {}

    def error_handler(*args, **kwargs):
      try:
        if not is_traceback_filtering_enabled():
          return fn(*args, **kwargs)
      except NameError:
        # In some very rare cases,
        # `is_traceback_filtering_enabled` (from the outer scope) may not be
        # accessible from inside this function
        return fn(*args, **kwargs)
    
      filtered_tb = None
      try:
        return fn(*args, **kwargs)
      except Exception as e:
        filtered_tb = _process_traceback_frames(e.__traceback__)
>       raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/tensorflow/python/util/traceback_utils.py:153: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

type_value = torch.float32

    @tf_export("dtypes.as_dtype", "as_dtype")
    def as_dtype(type_value):
      """Converts the given `type_value` to a `tf.DType`.
    
      Inputs can be existing `tf.DType` objects, a [`DataType`
      enum](https://www.tensorflow.org/code/tensorflow/core/framework/types.proto),
      a string type name, or a
      [`numpy.dtype`](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html).
    
      Examples:
      >>> tf.as_dtype(2)  # Enum value for float64.
      tf.float64
    
      >>> tf.as_dtype('float')
      tf.float32
    
      >>> tf.as_dtype(np.int32)
      tf.int32
    
      Note: `DType` values are interned (i.e. a single instance of each dtype is
      stored in a map). When passed a new `DType` object, `as_dtype` always returns
      the interned value.
    
      Args:
        type_value: A value that can be converted to a `tf.DType` object.
    
      Returns:
        A `DType` corresponding to `type_value`.
    
      Raises:
        TypeError: If `type_value` cannot be converted to a `DType`.
      """
      if isinstance(type_value, DType):
        if type_value._handle_data is None:  # pylint:disable=protected-access
          return _INTERN_TABLE[type_value.as_datatype_enum]
        else:
          return type_value
    
      if isinstance(type_value, np.dtype):
        try:
          return _NP_TO_TF[type_value.type]
        except KeyError:
          pass
    
      try:
        return _ANY_TO_TF[type_value]
      except (KeyError, TypeError):
        # TypeError indicates that type_value is not hashable.
        pass
    
      if hasattr(type_value, "dtype"):
        try:
          return _NP_TO_TF[np.dtype(type_value.dtype).type]
        except (KeyError, TypeError):
          pass
    
      if isinstance(type_value, _dtypes.DType):
        return _INTERN_TABLE[type_value.as_datatype_enum]
    
>     raise TypeError(f"Cannot convert the argument `type_value`: {type_value!r} "
                      "to a TensorFlow DType.")
E     TypeError: Cannot convert the argument `type_value`: torch.float32 to a TensorFlow DType.

/opt/fw/tensorflow/tensorflow/python/framework/dtypes.py:852: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.nerf.samplers.RandomRaySampler
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/test_nerf.py::test_NerfModelRenderer[tensorflow-s2s-False] - TypeError: _nest_torch_tensor_to_new_framework() missing 1 required positional argument: 'target'
FAILED kornia/test_nerf.py::test_MLP[tensorflow-s2s-False] - OSError: Exception encountered when calling tensorflow_ReLU.call().
FAILED kornia/test_nerf.py::test_RandomRaySampler[tensorflow-s2s-False] - TypeError: Cannot convert the argument `type_value`: torch.float32 to a TensorFlow DType.
=============================================================================== 3 failed, 3 passed in 375.76s (0:06:15) ================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 17 items

kornia/test_feature2.py .......F.....F..F                                                                                                                                                        [100%]

=============================================================================================== FAILURES ===============================================================================================
____________________________________________________________________________ test_laf_is_inside_image[tensorflow-s2s-False] ____________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_laf_is_inside_image(target_framework, mode, backend_compile):
        trace_args = (
            torch.rand(1, 5, 2, 3),
            torch.rand(1, 1, 32, 32),
        )
        trace_kwargs = {'border': 0}
        test_args = (
            torch.rand(2, 10, 2, 3),
            torch.rand(2, 1, 64, 64),
        )
        test_kwargs = {'border': 1}
>       _test_function(
            kornia.feature.laf_is_inside_image,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/test_feature2.py:192: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function laf_is_inside_image at 0x7f204c758af0>
trace_args = (tensor([[[[0.0334, 0.8616, 0.6047],
          [0.8622, 0.6612, 0.9344]],

         [[0.3264, 0.8638, 0.6206],
       ...2, 0.2483, 0.6624,  ..., 0.1040, 0.9611, 0.4418],
          [0.3250, 0.6645, 0.8369,  ..., 0.0246, 0.2358, 0.1508]]]]))
trace_kwargs = {'border': 0}
test_args = (tensor([[[[0.3873, 0.3822, 0.6325],
          [0.3293, 0.8625, 0.8439]],

         [[0.1350, 0.6099, 0.6942],
       ...7, 0.0137, 0.2059,  ..., 0.1546, 0.0596, 0.9670],
          [0.4608, 0.7747, 0.7248,  ..., 0.7675, 0.9241, 0.6345]]]]))
test_kwargs = {'border': 1}, target = 'tensorflow', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function laf_is_inside_image at 0x7f204c758af0>, fn_name = 'kornia.feature.laf_is_inside_image'
trace_args = (tensor([[[[0.0334, 0.8616, 0.6047],
          [0.8622, 0.6612, 0.9344]],

         [[0.3264, 0.8638, 0.6206],
       ...2, 0.2483, 0.6624,  ..., 0.1040, 0.9611, 0.4418],
          [0.3250, 0.6645, 0.8369,  ..., 0.0246, 0.2358, 0.1508]]]]))
trace_kwargs = {'border': 0}
test_args = (tensor([[[[0.3873, 0.3822, 0.6325],
          [0.3293, 0.8625, 0.8439]],

         [[0.1350, 0.6099, 0.6942],
       ...7, 0.0137, 0.2059,  ..., 0.1546, 0.0596, 0.9670],
          [0.4608, 0.7747, 0.7248,  ..., 0.7675, 0.9241, 0.6345]]]]))
test_kwargs = {'border': 1}, target = 'tensorflow', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
>           graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:326: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:232: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

laf = <tf.Tensor: shape=(1, 5, 2, 3), dtype=float32, numpy=
array([[[[0.03343272, 0.86155057, 0.60467595],
         [0.86222...3 ]],

        [[0.97037464, 0.35187036, 0.38343972],
         [0.2499221 , 0.71165276, 0.6218956 ]]]], dtype=float32)>
images = <tf.Tensor: shape=(1, 1, 32, 32), dtype=float32, numpy=
array([[[[0.50519764, 0.35180855, 0.74044824, ..., 0.16199195,...],
         [0.32504708, 0.6645109 , 0.83692676, ..., 0.02461171,
          0.23577386, 0.15083772]]]], dtype=float32)>
border = 0

    def tensorflow_laf_is_inside_image(laf, images, border=0):
        from ..core.check import tensorflow_KORNIA_CHECK_LAF
        from ...ivy.functional.frontends.torch.tensor import tensorflow_size_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_min_frnt_
    
        tensorflow_KORNIA_CHECK_LAF(laf)
        _, _, h, w = tensorflow_size_frnt_(images)
        pts = tensorflow_laf_to_boundary_points(laf, 12)
        good_lafs_mask = (
>           (pts[..., 0] >= border)
            * (pts[..., 0] <= w - border)
            * (pts[..., 1] >= border)
            * (pts[..., 1] <= h - border)
        )

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/laf.py:105: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <tf.Tensor: shape=(1, 5, 12), dtype=bool, numpy=
array([[[ True,  True,  True,  True,  True, False, False, False,  Tru...True,  True],
        [ True,  True,  True,  True,  True,  True,  True, False, False,
         False,  True,  True]]])>
rhs = <tf.Tensor: shape=(1, 5, 12), dtype=bool, numpy=
array([[[ True,  True,  True,  True,  True,  True,  True,  True,  Tru...True,  True],
        [ True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True]]])>

    def impl(self, rhs):
        try:
            return original_method(self, rhs)
        except Exception:
>           return patched_method(self, rhs)

ivy_transpiled_outputs/tensorflow_outputs/__init__.py:65: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = <tf.Tensor: shape=(1, 5, 12), dtype=bool, numpy=
array([[[ True,  True,  True,  True,  True, False, False, False,  Tru...True,  True],
        [ True,  True,  True,  True,  True,  True,  True, False, False,
         False,  True,  True]]])>
other = <tf.Tensor: shape=(1, 5, 12), dtype=bool, numpy=
array([[[ True,  True,  True,  True,  True,  True,  True,  True,  Tru...True,  True],
        [ True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True]]])>

    def tensorflow___mul___frnt_(tensor, other):
        from .pointwise_ops import tensorflow_mul_frnt
    
>       return tensorflow_mul_frnt(tensor, other)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/tensor.py:113: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = <tf.Tensor: shape=(1, 5, 12), dtype=bool, numpy=
array([[[ True,  True,  True,  True,  True, False, False, False,  Tru...True,  True],
        [ True,  True,  True,  True,  True,  True,  True, False, False,
         False,  True,  True]]])>
other = <tf.Tensor: shape=(1, 5, 12), dtype=bool, numpy=
array([[[ True,  True,  True,  True,  True,  True,  True,  True,  Tru...True,  True],
        [ True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True]]])>

    def tensorflow_mul_frnt(input, other, *, out=None):
        from .__init__ import tensorflow_promote_types_of_torch_inputs_frnt
        from ...backends.tensorflow.elementwise import tensorflow_multiply
    
        input, other = tensorflow_promote_types_of_torch_inputs_frnt(input, other)
>       return tensorflow_multiply(input, other, out=out)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/pointwise_ops.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x1 = <tf.Tensor: shape=(1, 5, 12), dtype=bool, numpy=
array([[[ True,  True,  True,  True,  True, False, False, False,  Tru...True,  True],
        [ True,  True,  True,  True,  True,  True,  True, False, False,
         False,  True,  True]]])>
x2 = <tf.Tensor: shape=(1, 5, 12), dtype=bool, numpy=
array([[[ True,  True,  True,  True,  True,  True,  True,  True,  Tru...True,  True],
        [ True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True]]])>

    def tensorflow_multiply(
        x1: Union[float, tensorflow.Tensor, tensorflow.Variable],
        x2: Union[float, tensorflow.Tensor, tensorflow.Variable],
        /,
        *,
        out: Optional[Union[tensorflow.Tensor, tensorflow.Variable]] = None,
    ):
        from ...ivy.data_type import tensorflow_promote_types_of_inputs_bknd
    
        x1, x2 = tensorflow_promote_types_of_inputs_bknd(x1, x2)
>       return tensorflow.math.multiply(x1, x2)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/backends/tensorflow/elementwise.py:151: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (<tf.Tensor: shape=(1, 5, 12), dtype=bool, numpy=
array([[[ True,  True,  True,  True,  True, False, False, False,  Tr...rue,  True],
        [ True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True]]])>)
kwargs = {}

    def wrapper(*args, **kwargs):
      if not ops.is_auto_dtype_conversion_enabled():
>       return op(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/ops/weak_tensor_ops.py:142: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (<tf.Tensor: shape=(1, 5, 12), dtype=bool, numpy=
array([[[ True,  True,  True,  True,  True, False, False, False,  Tr...rue,  True],
        [ True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True]]])>)
kwargs = {}

    def error_handler(*args, **kwargs):
      try:
        if not is_traceback_filtering_enabled():
          return fn(*args, **kwargs)
      except NameError:
        # In some very rare cases,
        # `is_traceback_filtering_enabled` (from the outer scope) may not be
        # accessible from inside this function
        return fn(*args, **kwargs)
    
      filtered_tb = None
      try:
        return fn(*args, **kwargs)
      except Exception as e:
        filtered_tb = _process_traceback_frames(e.__traceback__)
>       raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/tensorflow/python/util/traceback_utils.py:153: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

e = _NotOkStatusException(), name = None

    def raise_from_not_ok_status(e, name) -> NoReturn:
      e.message += (" name: " + str(name if name is not None else ""))
>     raise core._status_to_exception(e) from None  # pylint: disable=protected-access
E     tensorflow.python.framework.errors_impl.InvalidArgumentError: Value for attr 'T' of bool is not in the list of allowed values: bfloat16, half, float, double, uint8, int8, uint16, int16, int32, uint32, uint64, int64, complex64, complex128
E     	; NodeDef: {{node Mul}}; Op<name=Mul; signature=x:T, y:T -> z:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE, DT_UINT8, DT_INT8, DT_UINT16, DT_INT16, DT_INT32, DT_UINT32, DT_UINT64, DT_INT64, DT_COMPLEX64, DT_COMPLEX128]; is_commutative=true> [Op:Mul] name:

/opt/fw/tensorflow/tensorflow/python/framework/ops.py:5983: InvalidArgumentError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.laf.laf_is_inside_image
_______________________________________________________________________________ test_MKDDescriptor[tensorflow-s2s-False] _______________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_MKDDescriptor(target_framework, mode, backend_compile):
        print("kornia.feature.MKDDescriptor")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target_framework)
    
        x = torch.rand(23, 1, 32, 32)
        transpiled_x = _nest_torch_tensor_to_new_framework(x, target_framework)
    
        model = kornia.feature.MKDDescriptor()
        torch_out = model(x)
    
>       transpiled_model = transpiled_kornia.feature.MKDDescriptor()

kornia/test_feature2.py:339: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:232: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'tensorflow_MKDDescriptor' object has no attribute 'output_dims'") raised in repr()] tensorflow_MKDDescriptor object at 0x7f1fcc678fd0>, patch_size = 32
kernel_type = 'concat', whitening = 'pcawt', training_set = 'liberty', output_dims = 128

    def __init__(
        self,
        patch_size=32,
        kernel_type="concat",
        whitening="pcawt",
        training_set="liberty",
        output_dims=128,
    ):
        from ..filters.gaussian import tensorflow_GaussianBlur2d
        from ...ivy.functional.backends.tensorflow.general import tensorflow_get_item
        from ...ivy.functional.backends.tensorflow.general import tensorflow_set_item
        from ...torch.nn.modules.container import tensorflow_Sequential
        from ...ivy.functional.frontends.torch.hub.hub import (
            tensorflow_load_state_dict_from_url_frnt,
        )
        from ..utils.helpers import tensorflow_map_location_to_cpu
    
        self.super___init__(
            patch_size=patch_size,
            kernel_type=kernel_type,
            whitening=whitening,
            training_set=training_set,
            output_dims=output_dims,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        self.patch_size: typing.Any = patch_size
        self.kernel_type: typing.Any = kernel_type
        self.whitening: typing.Any = whitening
        self.training_set: typing.Any = training_set
        self.sigma = 1.4 * (patch_size / 64)
        self.smoothing = tensorflow_GaussianBlur2d(
            (5, 5), (self.sigma, self.sigma), "replicate"
        )
        self.gradients = tensorflow_MKDGradients()
        polar_s: typing.Any = "polar"
        cart_s: typing.Any = "cart"
        self.parametrizations = (
            [polar_s, cart_s] if self.kernel_type == "concat" else [self.kernel_type]
        )
        self.odims: typing.Any = 0
        relative_orientations = {polar_s: True, cart_s: False}
        self.feats = {}
        for parametrization in self.parametrizations:
            gradient_embedding = tensorflow_EmbedGradients(
                patch_size=patch_size,
                relative=tensorflow_get_item(relative_orientations, parametrization),
            )
>           spatial_encoding = tensorflow_ExplicitSpacialEncoding(
                kernel_type=parametrization,
                fmap_size=patch_size,
                in_dims=gradient_embedding.kernel.d,
            )

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/mkd.py:989: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'tensorflow_ExplicitSpacialEncoding' object has no attribute 'out_dims'") raised in repr()] tensorflow_ExplicitSpacialEncoding object at 0x7f1fcc679ba0>, args = ()
kwargs = {'fmap_size': 32, 'in_dims': 7, 'kernel_type': 'polar'}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'tensorflow_ExplicitSpacialEncoding' object has no attribute 'out_dims'") raised in repr()] tensorflow_ExplicitSpacialEncoding object at 0x7f1fcc679ba0>, kernel_type = 'polar'
fmap_size = 32, in_dims = 7, do_gmask = True, do_l2 = True

    @tensorflow_store_config_info
    def __init__(
        self, kernel_type="polar", fmap_size=32, in_dims=7, do_gmask=True, do_l2=True
    ):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_unsqueeze_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
    
        self.super___init__(
            kernel_type=kernel_type,
            fmap_size=fmap_size,
            in_dims=in_dims,
            do_gmask=do_gmask,
            do_l2=do_l2,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        if kernel_type not in ["polar", "cart"]:
            raise NotImplementedError(
                f"{kernel_type} is not valid, use polar or cart)."
            )
        self.kernel_type = kernel_type
        self.fmap_size = fmap_size
        self.in_dims = in_dims
        self.do_gmask = do_gmask
        self.do_l2 = do_l2
        self.grid = tensorflow_get_grid_dict(fmap_size)
        self.gmask = None
>       emb = tensorflow_spatial_kernel_embedding(self.kernel_type, self.grid)

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/mkd.py:575: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

kernel_type = 'polar'
grids = {'x': <tf.Tensor: shape=(32, 32), dtype=float32, numpy=
array([[-1.        , -0.9354839 , -0.87096775, ...,  0.8709677...,
       [ 2.3561945 ,  2.3228736 ,  2.287338  , ...,  0.8542547 ,
         0.81871915,  0.7853981 ]], dtype=float32)>}

    def tensorflow_spatial_kernel_embedding(kernel_type, grids):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ...ivy.functional.backends.tensorflow.general import tensorflow_get_item
        from ...ivy.functional.frontends.torch.tensor import tensorflow_float_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_unsqueeze_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_squeeze_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_index_select_frnt_
        from ..constants import pi
    
        factors = {"phi": 1.0, "rho": pi / sqrt2, "x": pi / 2, "y": pi / 2}
        if kernel_type == "cart":
            coeffs_ = "xy"
            params_ = ["x", "y"]
        elif kernel_type == "polar":
            coeffs_ = "rhophi"
            params_ = ["phi", "rho"]
        keys = list(grids.keys())
        patch_size = tensorflow_shape_frnt_(tensorflow_get_item(grids, keys[0]))[-1]
        grids_normed = {k: (v * tensorflow_get_item(factors, k)) for k, v in grids.items()}
        grids_normed = {
            k: tensorflow_float_frnt_(
                tensorflow_unsqueeze_frnt_(tensorflow_unsqueeze_frnt_(v, 0), 0)
            )
            for k, v in grids_normed.items()
        }
        vm_a = tensorflow_VonMisesKernel(
            patch_size=patch_size, coeffs=tensorflow_get_item(COEFFS, coeffs_)
        )
        vm_b = tensorflow_VonMisesKernel(
            patch_size=patch_size, coeffs=tensorflow_get_item(COEFFS, coeffs_)
        )
        emb_a = tensorflow_squeeze_frnt_(
>           vm_a(tensorflow_get_item(grids_normed, params_[0]))
        )

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/mkd.py:534: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_VonMisesKernel(patch_size=32, n=2, d=5, coeffs=[0.14343168 0.268285   0.21979234])
args = (<tf.Tensor: shape=(1, 1, 32, 32), dtype=float32, numpy=
array([[[[-2.3561945 , -2.3228736 , -2.287338  , ..., -0.8542...    [ 2.3561945 ,  2.3228736 ,  2.287338  , ...,  0.8542547 ,
           0.81871915,  0.7853981 ]]]], dtype=float32)>,)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x5642b8916a30, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...est_MKDDescriptor', code_context=['    transpiled_model = transpiled_kornia.feature.MKDDescriptor()\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_VonMisesKernel(patch_size=32, n=2, d=5, coeffs=[0.14343168 0.268285   0.21979234]), <tf.Tensor: shape=(1, ...     [ 2.3561945 ,  2.3228736 ,  2.287338  , ...,  0.8542547 ,
           0.81871915,  0.7853981 ]]]], dtype=float32)>)
kwargs = {}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_VonMisesKernel(patch_size=32, n=2, d=5, coeffs=[0.14343168 0.268285   0.21979234]), v = None, buffers = None
args = (<tf.Tensor: shape=(1, 1, 32, 32), dtype=float32, numpy=
array([[[[-2.3561945 , -2.3228736 , -2.287338  , ..., -0.8542...    [ 2.3561945 ,  2.3228736 ,  2.287338  , ...,  0.8542547 ,
           0.81871915,  0.7853981 ]]]], dtype=float32)>,)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_VonMisesKernel(patch_size=32, n=2, d=5, coeffs=[0.14343168 0.268285   0.21979234]), <tf.Tensor: shape=(1, ...     [ 2.3561945 ,  2.3228736 ,  2.287338  , ...,  0.8542547 ,
           0.81871915,  0.7853981 ]]]], dtype=float32)>)
kwargs = {'buffers': None, 'v': None}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_VonMisesKernel(patch_size=32, n=2, d=5, coeffs=[0.14343168 0.268285   0.21979234]), v = None, buffers = None
args = (<tf.Tensor: shape=(1, 1, 32, 32), dtype=float32, numpy=
array([[[[-2.3561945 , -2.3228736 , -2.287338  , ..., -0.8542...    [ 2.3561945 ,  2.3228736 ,  2.287338  , ...,  0.8542547 ,
           0.81871915,  0.7853981 ]]]], dtype=float32)>,)
kwargs = {}
first_arr = <tf.Tensor: shape=(1, 1, 32, 32), dtype=float32, numpy=
array([[[[-2.3561945 , -2.3228736 , -2.287338  , ..., -0.85425...      [ 2.3561945 ,  2.3228736 ,  2.287338  , ...,  0.8542547 ,
           0.81871915,  0.7853981 ]]]], dtype=float32)>
replace_v = False, replace_buffers = False, call_signature = <Signature (x)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Layer, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Layer, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Layer, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_VonMisesKernel(patch_size=32, n=2, d=5, coeffs=[0.14343168 0.268285   0.21979234]),)
kwargs = {'x': <tf.Tensor: shape=(1, 1, 32, 32), dtype=float32, numpy=
array([[[[-2.3561945 , -2.3228736 , -2.287338  , ..., -0...     [ 2.3561945 ,  2.3228736 ,  2.287338  , ...,  0.8542547 ,
           0.81871915,  0.7853981 ]]]], dtype=float32)>}

    @wraps(fn)
    def error_handler(*args, **kwargs):
        if not is_traceback_filtering_enabled():
            return fn(*args, **kwargs)
    
        filtered_tb = None
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            filtered_tb = _process_traceback_frames(e.__traceback__)
            # To get the full stack trace, call:
            # `keras.config.disable_traceback_filtering()`
>           raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/keras/src/utils/traceback_utils.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_VonMisesKernel(patch_size=32, n=2, d=5, coeffs=[0.14343168 0.268285   0.21979234])
x = <tf.Tensor: shape=(1, 1, 32, 32), dtype=float32, numpy=
array([[[[-2.3561945 , -2.3228736 , -2.287338  , ..., -0.85425...      [ 2.3561945 ,  2.3228736 ,  2.287338  , ...,  0.8542547 ,
           0.81871915,  0.7853981 ]]]], dtype=float32)>

    def call(self, x):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_repeat_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_to_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_size_frnt_
        from ...ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            tensorflow_cat_frnt,
        )
        from ..core._backend import cos
        from ..core._backend import sin
    
        if not isinstance(x, (tensorflow.Tensor, tensorflow.keras.Variable)):
            raise TypeError(f"Input type is not a Tensor. Got {type(x)}")
        if not len(tensorflow_shape_frnt_(x)) == 4 or tensorflow_shape_frnt_(x)[1] != 1:
            raise ValueError(
                f"Invalid input shape, we expect Bx1xHxW. Got: {tensorflow_shape_frnt_(x)}"
            )
        if not isinstance(self.emb0, (tensorflow.Tensor, tensorflow.keras.Variable)):
            raise TypeError(f"Emb0 type is not a Tensor. Got {type(x)}")
        emb0 = tensorflow_repeat_frnt_(
            tensorflow_to_frnt_(self.emb0, x), tensorflow_size_frnt_(x, 0), 1, 1, 1
        )
        frange = tensorflow_to_frnt_(self.frange, x) * x
        emb1 = cos(frange)
        emb2 = sin(frange)
        embedding = tensorflow_cat_frnt([emb0, emb1, emb2], dim=1)
>       embedding = self.pt_weights * embedding

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/mkd.py:265: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_VonMisesKernel(patch_size=32, n=2, d=5, coeffs=[0.14343168 0.268285   0.21979234]), name = 'pt_weights'

    @tf.autograph.experimental.do_not_convert
    def __getattr__(self, name):
        if name == "v":
            if not super().__getattribute__("_v") and not getattr(  # noqa: E501
                self, "_built", False
            ):
                return self._build_and_return_v(
                    *self._args, dynamic_backend=self._dynamic_backend, **self._kwargs
                )
    
        _dict = super().__getattribute__("__dict__")
        if name in _dict:
            return _dict[name]
    
        elif "_v" in _dict and name in _dict["_v"]:
            return _dict["_v"][name]
    
>       return super().__getattribute__(name)
E       AttributeError: Exception encountered when calling tensorflow_VonMisesKernel.call().
E       
E       [1m'tensorflow_VonMisesKernel' object has no attribute 'pt_weights'[0m
E       
E       Arguments received by tensorflow_VonMisesKernel.call():
E         • x=tf.Tensor(shape=(1, 1, 32, 32), dtype=float32)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1343: AttributeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.MKDDescriptor
----------------------------------------------------------------------------------------- Captured stderr call -----------------------------------------------------------------------------------------
Downloading: "https://github.com/manyids2/mkd_pytorch/raw/master/mkd_pytorch/mkd-concat-64.pth" to /root/.cache/torch/hub/checkpoints/mkd-concat-64.pth

  0%|          | 0.00/1.31M [00:00<?, ?B/s]
100%|██████████| 1.31M/1.31M [00:00<00:00, 142MB/s]
___________________________________________________________________________________ test_HyNet[tensorflow-s2s-False] ___________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_HyNet(target_framework, mode, backend_compile):
        print("kornia.feature.HyNet")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target_framework)
    
        x = torch.rand(16, 1, 32, 32)
        torch_out = kornia.feature.HyNet()(x)
    
        transpiled_x = _nest_torch_tensor_to_new_framework(x, target_framework)
>       transpiled_out = transpiled_kornia.feature.HyNet()(transpiled_x)

kornia/test_feature2.py:397: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_HyNet(
  (layer1): tensorflow_Sequential(
    (0): tensorflow_FilterResponseNorm2d()
    (1): tensorflow_TL...orflow_Dropout()
    (1): KerasConv2D()
    (2): KerasBatchNorm2D()
  )
  (desc_norm): tensorflow_LocalResponseNorm()
)
args = (<tf.Tensor: shape=(16, 1, 32, 32), dtype=float32, numpy=
array([[[[0.38407713, 0.59118134, 0.29808187, ..., 0.7355026...
         [0.36767638, 0.17058605, 0.74112695, ..., 0.01888204,
          0.6323651 , 0.256545  ]]]], dtype=float32)>,)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x7f1fc2a59260, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...ode_context=['        return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_HyNet(
  (layer1): tensorflow_Sequential(
    (0): tensorflow_FilterResponseNorm2d()
    (1): tensorflow_T...,
         [0.36767638, 0.17058605, 0.74112695, ..., 0.01888204,
          0.6323651 , 0.256545  ]]]], dtype=float32)>)
kwargs = {}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_HyNet(
  (layer1): tensorflow_Sequential(
    (0): tensorflow_FilterResponseNorm2d()
    (1): tensorflow_TL...orflow_Dropout()
    (1): KerasConv2D()
    (2): KerasBatchNorm2D()
  )
  (desc_norm): tensorflow_LocalResponseNorm()
)
v = None, buffers = None
args = (<tf.Tensor: shape=(16, 1, 32, 32), dtype=float32, numpy=
array([[[[0.38407713, 0.59118134, 0.29808187, ..., 0.7355026...
         [0.36767638, 0.17058605, 0.74112695, ..., 0.01888204,
          0.6323651 , 0.256545  ]]]], dtype=float32)>,)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:2017: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_HyNet(
  (layer1): tensorflow_Sequential(
    (0): tensorflow_FilterResponseNorm2d()
    (1): tensorflow_T...,
         [0.36767638, 0.17058605, 0.74112695, ..., 0.01888204,
          0.6323651 , 0.256545  ]]]], dtype=float32)>)
kwargs = {'buffers': None, 'v': None}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_HyNet(
  (layer1): tensorflow_Sequential(
    (0): tensorflow_FilterResponseNorm2d()
    (1): tensorflow_TL...orflow_Dropout()
    (1): KerasConv2D()
    (2): KerasBatchNorm2D()
  )
  (desc_norm): tensorflow_LocalResponseNorm()
)
v = None, buffers = None
args = (<tf.Tensor: shape=(16, 1, 32, 32), dtype=float32, numpy=
array([[[[0.38407713, 0.59118134, 0.29808187, ..., 0.7355026...
         [0.36767638, 0.17058605, 0.74112695, ..., 0.01888204,
          0.6323651 , 0.256545  ]]]], dtype=float32)>,)
kwargs = {}, replace_v = False, replace_buffers = False, call_signature = <Signature (x)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Model, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Model, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Model, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1787: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_HyNet(
  (layer1): tensorflow_Sequential(
    (0): tensorflow_FilterResponseNorm2d()
    (1): tensorflow_T...flow_Dropout()
    (1): KerasConv2D()
    (2): KerasBatchNorm2D()
  )
  (desc_norm): tensorflow_LocalResponseNorm()
),)
kwargs = {'x': <tf.Tensor: shape=(16, 1, 32, 32), dtype=float32, numpy=
array([[[[0.38407713, 0.59118134, 0.29808187, ..., 0.73...,
         [0.36767638, 0.17058605, 0.74112695, ..., 0.01888204,
          0.6323651 , 0.256545  ]]]], dtype=float32)>}

    @wraps(fn)
    def error_handler(*args, **kwargs):
        if not is_traceback_filtering_enabled():
            return fn(*args, **kwargs)
    
        filtered_tb = None
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            filtered_tb = _process_traceback_frames(e.__traceback__)
            # To get the full stack trace, call:
            # `keras.config.disable_traceback_filtering()`
>           raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/keras/src/utils/traceback_utils.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_HyNet(
  (layer1): tensorflow_Sequential(
    (0): tensorflow_FilterResponseNorm2d()
    (1): tensorflow_TL...orflow_Dropout()
    (1): KerasConv2D()
    (2): KerasBatchNorm2D()
  )
  (desc_norm): tensorflow_LocalResponseNorm()
)
x = <tf.Tensor: shape=(16, 1, 32, 32), dtype=float32, numpy=
array([[[[0.38407713, 0.59118134, 0.29808187, ..., 0.73550266...],
         [0.36767638, 0.17058605, 0.74112695, ..., 0.01888204,
          0.6323651 , 0.256545  ]]]], dtype=float32)>

    def call(self, x):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_view_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_size_frnt_
    
>       x = self.layer1(x)

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/hynet.py:543: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Sequential(
  (0): tensorflow_FilterResponseNorm2d()
  (1): tensorflow_TLU()
  (2): KerasConv2D()
  (3): tensorflow_FilterResponseNorm2d()
  (4): tensorflow_TLU()
)
args = (<tf.Tensor: shape=(16, 1, 32, 32), dtype=float32, numpy=
array([[[[0.38407713, 0.59118134, 0.29808187, ..., 0.7355026...
         [0.36767638, 0.17058605, 0.74112695, ..., 0.01888204,
          0.6323651 , 0.256545  ]]]], dtype=float32)>,)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x5642b92ddb80, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...function='__call__', code_context=['                    outputs = super().__call__(*args, **kwargs)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Sequential(
  (0): tensorflow_FilterResponseNorm2d()
  (1): tensorflow_TLU()
  (2): KerasConv2D()
  (3): tensorflow_FilterResponseNorm2d()
  (4): tensorflow_TLU()
), v = None
buffers = None
args = (<tf.Tensor: shape=(16, 1, 32, 32), dtype=float32, numpy=
array([[[[0.38407713, 0.59118134, 0.29808187, ..., 0.7355026...
         [0.36767638, 0.17058605, 0.74112695, ..., 0.01888204,
          0.6323651 , 0.256545  ]]]], dtype=float32)>,)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Sequential(
  (0): tensorflow_FilterResponseNorm2d()
  (1): tensorflow_TLU()
  (2): KerasConv2D()
  (3): tensorflow_FilterResponseNorm2d()
  (4): tensorflow_TLU()
), v = None
buffers = None
args = (<tf.Tensor: shape=(16, 1, 32, 32), dtype=float32, numpy=
array([[[[0.38407713, 0.59118134, 0.29808187, ..., 0.7355026...
         [0.36767638, 0.17058605, 0.74112695, ..., 0.01888204,
          0.6323651 , 0.256545  ]]]], dtype=float32)>,)
kwargs = {}, replace_v = False, replace_buffers = False, call_signature = <Signature (input)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Layer, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Layer, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Layer, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Sequential(
  (0): tensorflow_FilterResponseNorm2d()
  (1): tensorflow_TLU()
  (2): KerasConv2D()
  (3): tensorflow_FilterResponseNorm2d()
  (4): tensorflow_TLU()
)
input = <tf.Tensor: shape=(16, 1, 32, 32), dtype=float32, numpy=
array([[[[0.6738605 , 1.0372233 , 0.5229825 , ..., 1.290434  ...],
         [0.6349224 , 0.2945767 , 1.2798159 , ..., 0.03260646,
          1.0920004 , 0.44301504]]]], dtype=float32)>

    def call(self, input):
        for i, module in enumerate(self):
>           input = module(input)

ivy_transpiled_outputs/tensorflow_outputs/torch/nn/modules/container.py:184: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_TLU()
args = (<tf.Tensor: shape=(16, 1, 32, 32), dtype=float32, numpy=
array([[[[0.6738605 , 1.0372233 , 0.5229825 , ..., 1.290434 ...
         [0.6349224 , 0.2945767 , 1.2798159 , ..., 0.03260646,
          1.0920004 , 0.44301504]]]], dtype=float32)>,)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x5642b97520c0, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...function='__call__', code_context=['                    outputs = super().__call__(*args, **kwargs)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_TLU(), v = None, buffers = None
args = (<tf.Tensor: shape=(16, 1, 32, 32), dtype=float32, numpy=
array([[[[0.6738605 , 1.0372233 , 0.5229825 , ..., 1.290434 ...
         [0.6349224 , 0.2945767 , 1.2798159 , ..., 0.03260646,
          1.0920004 , 0.44301504]]]], dtype=float32)>,)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_TLU(), v = None, buffers = None
args = (<tf.Tensor: shape=(16, 1, 32, 32), dtype=float32, numpy=
array([[[[0.6738605 , 1.0372233 , 0.5229825 , ..., 1.290434 ...
         [0.6349224 , 0.2945767 , 1.2798159 , ..., 0.03260646,
          1.0920004 , 0.44301504]]]], dtype=float32)>,)
kwargs = {}, replace_v = False, replace_buffers = False, call_signature = <Signature (x)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Layer, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Layer, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Layer, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_TLU()
x = <tf.Tensor: shape=(16, 1, 32, 32), dtype=float32, numpy=
array([[[[0.6738605 , 1.0372233 , 0.5229825 , ..., 1.290434  ...],
         [0.6349224 , 0.2945767 , 1.2798159 , ..., 0.03260646,
          1.0920004 , 0.44301504]]]], dtype=float32)>

    def call(self, x):
        from ...ivy.functional.frontends.torch.reduction_ops import tensorflow_max_frnt
    
>       return tensorflow_max_frnt(x, self.tau)

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/hynet.py:257: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dim = <KerasVariable shape=(1, 1, 1, 1), dtype=float32, path=variable_13>, keepdim = False, out = None
input = <tf.Tensor: shape=(16, 1, 32, 32), dtype=float32, numpy=
array([[[[0.6738605 , 1.0372233 , 0.5229825 , ..., 1.290434  ...],
         [0.6349224 , 0.2945767 , 1.2798159 , ..., 0.03260646,
          1.0920004 , 0.44301504]]]], dtype=float32)>

    def tensorflow_max_frnt(*input, dim=None, keepdim=False, out=None):
        from ...ivy.general import tensorflow_is_array_bknd
        from .comparison_ops import tensorflow_maximum_frnt
        from ...backends.tensorflow.statistical import tensorflow_max
        from ...backends.tensorflow.searching import tensorflow_argmax
    
        if len(input) == 1:
            input = input[0]
        elif len(input) == 2:
            input_0 = input[0]
            input_1 = input[1]
            if tensorflow_is_array_bknd(input_1):
                return tensorflow_maximum_frnt(*input)
            else:
                input = input_0
                dim = input_1
        else:
            input = input[0]
            dim = input[1]
            keepdim = input[2]
        if dim is None:
            return tensorflow_max(input, axis=dim, keepdims=keepdim, out=out)
        elif out is not None:
            tensorflow_max(input, axis=dim, keepdims=keepdim, out=out[0])
            tensorflow_argmax(input, axis=dim, keepdims=keepdim, out=out[1])
            return out
        else:
            max_tuple = namedtuple("max", ["values", "indices"])
            return max_tuple(
>               tensorflow_max(input, axis=dim, keepdims=keepdim),
                tensorflow_argmax(input, axis=dim, keepdims=keepdim),
            )

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/reduction_ops.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = [<tf.Tensor: shape=(16, 1, 32, 32), dtype=float32, numpy=
array([[[[0.6738605 , 1.0372233 , 0.5229825 , ..., 1.290434 ...,
         [0.6349224 , 0.2945767 , 1.2798159 , ..., 0.03260646,
          1.0920004 , 0.44301504]]]], dtype=float32)>]
kwargs = {'axis': <KerasVariable shape=(1, 1, 1, 1), dtype=float32, path=variable_13>, 'keepdims': False}, tensorflow_is_array_bknd = <function tensorflow_is_array_bknd at 0x7f1fc2c50ee0>
tensorflow_set_item = <function tensorflow_set_item at 0x7f1fc2c2a290>, tensorflow_asarray = <function tensorflow_asarray at 0x7f1fc2c532e0>
tensorflow_get_item = <function tensorflow_get_item at 0x7f1fc2c2a0e0>, num_args = 1
type_hints = mappingproxy(OrderedDict([('x', <Parameter "x: Union[tensorflow.python.framework.tensor.Tensor, tensorflow.python.ops...."out: Union[tensorflow.python.framework.tensor.Tensor, tensorflow.python.ops.variables.Variable, NoneType] = None">)]))
parameters = ['x', 'axis', 'keepdims', 'out']
annotations = [typing.Union[tensorflow.python.framework.tensor.Tensor, tensorflow.python.ops.variables.Variable], typing.Union[int, ...s 'bool'>, typing.Union[tensorflow.python.framework.tensor.Tensor, tensorflow.python.ops.variables.Variable, NoneType]]
device = '/job:localhost/replica:0/task:0/device:CPU:0', i = 0

    @functools.wraps(fn)
    def _handle_array_like_without_promotion(*args, **kwargs):
        from .functional.ivy.general import tensorflow_is_array_bknd
        from .functional.backends.tensorflow.general import tensorflow_set_item
        from .functional.backends.tensorflow.creation import tensorflow_asarray
        from .functional.backends.tensorflow.general import tensorflow_get_item
    
        args = list(args)
        num_args = len(args)
        try:
            type_hints = inspect.signature(fn).parameters
        except (TypeError, ValueError):
            return fn(*args, **kwargs)
        parameters = list(type_hints.keys())
        annotations = [param.annotation for param in type_hints.values()]
        device = tensorflow__get_preferred_device(args, kwargs)
        for i, (annotation, parameter, arg) in enumerate(
            zip(annotations, parameters, args)
        ):
            annotation_str = str(annotation)
            if (
                ("rray" in annotation_str or "Tensor" in annotation_str)
                and parameter != "out"
                and all(
                    sq not in annotation_str
                    for sq in ["Sequence", "List", "Tuple", "float", "int", "bool"]
                )
            ):
                if i < num_args:
                    if arg is None or tensorflow__check_in_nested_sequence(
                        arg, value=Ellipsis, _type=slice
                    ):
                        continue
                    if not tensorflow_is_array_bknd(arg):
                        args = tensorflow_set_item(
                            args, i, tensorflow_asarray(arg, device=device)
                        )
                elif parameters in kwargs:
                    kwarg = tensorflow_get_item(kwargs, parameter)
                    if not tensorflow_is_array_bknd(kwarg):
                        kwargs = tensorflow_set_item(
                            kwargs, parameter, tensorflow_asarray(kwarg, device=device)
                        )
>       return fn(*args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/func_wrapper.py:139: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = <tf.Tensor: shape=(16, 1, 32, 32), dtype=float32, numpy=
array([[[[0.6738605 , 1.0372233 , 0.5229825 , ..., 1.290434  ...],
         [0.6349224 , 0.2945767 , 1.2798159 , ..., 0.03260646,
          1.0920004 , 0.44301504]]]], dtype=float32)>

    @tensorflow_handle_array_like_without_promotion
    def tensorflow_max(
        x: Union[tensorflow.Tensor, tensorflow.Variable],
        /,
        *,
        axis: Optional[Union[int, Sequence[int]]] = None,
        keepdims: bool = False,
        out: Optional[Union[tensorflow.Tensor, tensorflow.Variable]] = None,
    ):
        if "complex" in str(x.dtype):
            real = tensorflow.math.real(x)
            img = tensorflow.math.imag(x)
            const = tensorflow.constant(1.0j, dtype=x.dtype)
            real_max = tensorflow.reduce_max(real, axis=axis, keepdims=keepdims)
            imag = tensorflow.where(
                real == real_max, img, tensorflow.experimental.numpy.finfo(img.dtype).min
            )
            img_max = tensorflow.reduce_max(imag, axis=axis, keepdims=keepdims)
            img_max = tensorflow.cast(img_max, x.dtype)
            return tensorflow.add(
                tensorflow.cast(real_max, x.dtype), tensorflow.multiply(img_max, const)
            )
        axis = tuple(axis) if isinstance(axis, list) else axis
>       return tensorflow.math.reduce_max(x, axis=axis, keepdims=keepdims)
E       tensorflow.python.framework.errors_impl.InvalidArgumentError: Exception encountered when calling tensorflow_TLU.call().
E       
E       [1mValue for attr 'Tidx' of float is not in the list of allowed values: int32, int64
E       	; NodeDef: {{node Max}}; Op<name=Max; signature=input:T, reduction_indices:Tidx -> output:T; attr=keep_dims:bool,default=false; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, DT_INT8, DT_INT64, DT_BFLOAT16, DT_UINT16, DT_HALF, DT_UINT32, DT_UINT64, DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=Tidx:type,default=DT_INT32,allowed=[DT_INT32, DT_INT64]> [Op:Max][0m
E       
E       Arguments received by tensorflow_TLU.call():
E         • x=tf.Tensor(shape=(16, 1, 32, 32), dtype=float32)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/backends/tensorflow/statistical.py:95: InvalidArgumentError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.HyNet
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/test_feature2.py::test_laf_is_inside_image[tensorflow-s2s-False] - tensorflow.python.framework.errors_impl.InvalidArgumentError: Value for attr 'T' of bool is not in the list of allow...
FAILED kornia/test_feature2.py::test_MKDDescriptor[tensorflow-s2s-False] - AttributeError: Exception encountered when calling tensorflow_VonMisesKernel.call().
FAILED kornia/test_feature2.py::test_HyNet[tensorflow-s2s-False] - tensorflow.python.framework.errors_impl.InvalidArgumentError: Exception encountered when calling tensorflow_TLU.call().
============================================================================== 3 failed, 14 passed in 1375.39s (0:22:55) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 6 items

kornia/augmentation/test_container.py ...F.F                                                                                                                                                     [100%]

=============================================================================================== FAILURES ===============================================================================================
_________________________________________________________________________________ test_ImageSequential[jax-s2s-False] __________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_ImageSequential(target_framework, mode, backend_compile):
        print("kornia.augmentation.container.ImageSequential")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledImageSequential = ivy.transpile(
            kornia.augmentation.container.ImageSequential,
            source="torch",
            target=target_framework,
        )
        TranspiledColorJiggle = ivy.transpile(
            kornia.augmentation.ColorJiggle,
            source="torch",
            target=target_framework,
        )
        TranspiledRandomAffine = ivy.transpile(
            kornia.augmentation.RandomAffine,
            source="torch",
            target=target_framework,
        )
        TranspiledBgrToRgb = ivy.transpile(
            kornia.color.BgrToRgb,
            source="torch",
            target=target_framework,
        )
        TranspiledMedianBlur = ivy.transpile(
            kornia.filters.MedianBlur,
            source="torch",
            target=target_framework,
        )
        TranspiledInvert = ivy.transpile(
            kornia.enhance.Invert,
            source="torch",
            target=target_framework,
        )
        TranspiledRandomMixUpV2 = ivy.transpile(
            kornia.augmentation.RandomMixUpV2,
            source="torch",
            target=target_framework,
        )
    
        torch_aug_list = kornia.augmentation.container.ImageSequential(
            kornia.color.BgrToRgb(),
            kornia.augmentation.ColorJiggle(0.1, 0.1, 0.1, 0.1, p=1.0),
            kornia.filters.MedianBlur((3, 3)),
            kornia.augmentation.RandomAffine(360, p=1.0),
            kornia.enhance.Invert(),
            kornia.augmentation.RandomMixUpV2(p=1.0),
            same_on_batch=True,
            random_apply=10,
        )
        transpiled_aug_list = TranspiledImageSequential(
            TranspiledBgrToRgb(),
>           TranspiledColorJiggle(0.1, 0.1, 0.1, 0.1, p=1.0),
            TranspiledMedianBlur((3, 3)),
            TranspiledRandomAffine(360, p=1.0),
            TranspiledInvert(),
            TranspiledRandomMixUpV2(p=1.0),
            same_on_batch=True,
            random_apply=10,
        )

kornia/augmentation/test_container.py:261: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.augmentation._2d.intensity.color_jiggle.jax_ColorJiggle'>, args = (0.1, 0.1, 0.1, 0.1), kwargs = {'p': 1.0}

    def __call__(cls, *args: Any, **kwargs: Any) -> Any:
>     return _graph_node_meta_call(cls, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.augmentation._2d.intensity.color_jiggle.jax_ColorJiggle'>, args = (0.1, 0.1, 0.1, 0.1), kwargs = {'p': 1.0}
node = <[AttributeError("'jax_ColorJiggle' object has no attribute 'p'") raised in repr()] jax_ColorJiggle object at 0x7f1dbf178280>

    def _graph_node_meta_call(cls: tp.Type[G], *args, **kwargs) -> G:
      node = cls.__new__(cls, *args, **kwargs)
      vars(node)['_object__state'] = ObjectState()
>     cls._object_meta_construct(node, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:88: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.augmentation._2d.intensity.color_jiggle.jax_ColorJiggle'>
self = <[AttributeError("'jax_ColorJiggle' object has no attribute 'p'") raised in repr()] jax_ColorJiggle object at 0x7f1dbf178280>, args = (0.1, 0.1, 0.1, 0.1), kwargs = {'p': 1.0}

    def _object_meta_construct(cls, self, *args, **kwargs):
>     self.__init__(*args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:82: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'jax_ColorJiggle' object has no attribute 'p'") raised in repr()] jax_ColorJiggle object at 0x7f1dbf178280>, args = (0.1, 0.1, 0.1, 0.1), kwargs = {'p': 1.0}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/utils/decorator_utils.py:245: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'jax_ColorJiggle' object has no attribute 'p'") raised in repr()] jax_ColorJiggle object at 0x7f1dbf178280>, brightness = 0.1, contrast = 0.1, saturation = 0.1, hue = 0.1
same_on_batch = False, p = 1.0, keepdim = False

>   ???
E   ModuleNotFoundError: No module named 'ivy_transpiled_outputs.jax_outputs.kornia.augmentation.random_generator._2d.color_jiggle'

/ivy/ivy-integration-tests/ivy_transpiled_outputs/jax_outputs/kornia/augmentation/_2d/intensity/color_jiggle.py:43: ModuleNotFoundError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.container.ImageSequential
_________________________________________________________________________________ test_VideoSequential[jax-s2s-False] __________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_VideoSequential(target_framework, mode, backend_compile):
        print("kornia.augmentation.container.VideoSequential")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledVideoSequential = ivy.transpile(
            kornia.augmentation.container.VideoSequential,
            source="torch",
            target=target_framework,
        )
        TranspiledColorJiggle = ivy.transpile(
            kornia.augmentation.ColorJiggle,
            source="torch",
            target=target_framework,
        )
        TranspiledRandomAffine = ivy.transpile(
            kornia.augmentation.RandomAffine,
            source="torch",
            target=target_framework,
        )
        TranspiledBgrToRgb = ivy.transpile(
            kornia.color.BgrToRgb,
            source="torch",
            target=target_framework,
        )
    
        torch_aug_list = kornia.augmentation.container.VideoSequential(
            kornia.augmentation.ColorJiggle(0.1, 0.1, 0.1, 0.1, p=1.0),
            kornia.color.BgrToRgb(),
            kornia.augmentation.RandomAffine(360, p=1.0),
            random_apply=10,
            data_format="BCTHW",
            same_on_frame=True
        )
        transpiled_aug_list =  TranspiledVideoSequential(
>           TranspiledColorJiggle(0.1, 0.1, 0.1, 0.1, p=1.0),
            TranspiledBgrToRgb(),
            TranspiledRandomAffine(360, p=1.0),
            random_apply=10,
            data_format="BCTHW",
            same_on_frame=True
        )

kornia/augmentation/test_container.py:406: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.augmentation._2d.intensity.color_jiggle.jax_ColorJiggle'>, args = (0.1, 0.1, 0.1, 0.1), kwargs = {'p': 1.0}

    def __call__(cls, *args: Any, **kwargs: Any) -> Any:
>     return _graph_node_meta_call(cls, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.augmentation._2d.intensity.color_jiggle.jax_ColorJiggle'>, args = (0.1, 0.1, 0.1, 0.1), kwargs = {'p': 1.0}
node = <[ModuleNotFoundError("No module named 'ivy_transpiled_outputs.jax_outputs.kornia.augmentation'") raised in repr()] jax_ColorJiggle object at 0x7f1dcad412a0>

    def _graph_node_meta_call(cls: tp.Type[G], *args, **kwargs) -> G:
      node = cls.__new__(cls, *args, **kwargs)
      vars(node)['_object__state'] = ObjectState()
>     cls._object_meta_construct(node, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:88: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.augmentation._2d.intensity.color_jiggle.jax_ColorJiggle'>
self = <[ModuleNotFoundError("No module named 'ivy_transpiled_outputs.jax_outputs.kornia.augmentation'") raised in repr()] jax_ColorJiggle object at 0x7f1dcad412a0>, args = (0.1, 0.1, 0.1, 0.1)
kwargs = {'p': 1.0}

    def _object_meta_construct(cls, self, *args, **kwargs):
>     self.__init__(*args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:82: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[ModuleNotFoundError("No module named 'ivy_transpiled_outputs.jax_outputs.kornia.augmentation'") raised in repr()] jax_ColorJiggle object at 0x7f1dcad412a0>, args = (0.1, 0.1, 0.1, 0.1)
kwargs = {'p': 1.0}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/utils/decorator_utils.py:245: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[ModuleNotFoundError("No module named 'ivy_transpiled_outputs.jax_outputs.kornia.augmentation'") raised in repr()] jax_ColorJiggle object at 0x7f1dcad412a0>, brightness = 0.1, contrast = 0.1
saturation = 0.1, hue = 0.1, same_on_batch = False, p = 1.0, keepdim = False

>   ???
E   ModuleNotFoundError: No module named 'ivy_transpiled_outputs.jax_outputs.kornia.augmentation'

/ivy/ivy-integration-tests/ivy_transpiled_outputs/jax_outputs/kornia/augmentation/_2d/intensity/color_jiggle.py:43: ModuleNotFoundError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.container.VideoSequential
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/augmentation/test_container.py::test_ImageSequential[jax-s2s-False] - ModuleNotFoundError: No module named 'ivy_transpiled_outputs.jax_outputs.kornia.augmentation.random_generator._2d...
FAILED kornia/augmentation/test_container.py::test_VideoSequential[jax-s2s-False] - ModuleNotFoundError: No module named 'ivy_transpiled_outputs.jax_outputs.kornia.augmentation'
=============================================================================== 2 failed, 4 passed in 2208.74s (0:36:48) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 17 items

kornia/test_feature2.py ...............F.                                                                                                                                                        [100%]

=============================================================================================== FAILURES ===============================================================================================
_____________________________________________________________________________________ test_HardNet8[jax-s2s-False] _____________________________________________________________________________________
jax.errors.SimplifiedTraceback: For simplicity, JAX has removed its internal frames from the traceback of the following exception. Set JAX_TRACEBACK_FILTERING=off to include these.

The above exception was the direct cause of the following exception:

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_HardNet8(target_framework, mode, backend_compile):
        print("kornia.feature.HardNet8")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target_framework)
    
        x = torch.rand(16, 1, 32, 32)
        torch_out = kornia.feature.HardNet8()(x)
    
        transpiled_x = _nest_torch_tensor_to_new_framework(x, target_framework)
>       transpiled_out = transpiled_kornia.feature.HardNet8()(transpiled_x)

kornia/test_feature2.py:380: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_HardNet8(
  (features): jax_Sequential(
    (0): FlaxConv(in_features=1, out_features=32, kernel_size=(3, 3), stri...es=(1, 1), padding=0, padding_mode=zeros)
    (23): FlaxBatchNorm2D(512, eps=1e-05, momentum=0.99, affine=False, 
  )
)
input = Array([[[[9.83362198e-01, 4.88668263e-01, 2.24062264e-01, ...,
          5.66788197e-01, 9.51377749e-02, 4.23873127e-0... 6.36619508e-01, 3.85196328e-01, ...,
          2.63512611e-01, 2.85540283e-01, 3.72771502e-01]]]],      dtype=float32)

    def __call__(self, input):
        from ..core.check import jax_KORNIA_CHECK_SHAPE
        from ...ivy.functional.frontends.torch.jit._jit_internal import (
            jax_annotate_frnt,
        )
        from ...ivy.functional.frontends.torch.nn.functional.non_linear_activation_functions import (
            jax_normalize_frnt,
        )
        from ...ivy.functional.frontends.torch.tensor import jax_view_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_size_frnt_
        from ...ivy.functional.frontends.torch.blas_and_lapack_ops import jax_mm_frnt
    
        jax_KORNIA_CHECK_SHAPE(input, ["B", "1", "32", "32"])
        x_norm: typing.Any = self._normalize_input(input)
>       x_features: typing.Any = self.features(x_norm)

ivy_transpiled_outputs/jax_outputs/kornia/feature/hardnet.py:295: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_Sequential(
  (0): FlaxConv(in_features=1, out_features=32, kernel_size=(3, 3), strides=(1, 1), padding=1, padding... strides=(1, 1), padding=0, padding_mode=zeros)
  (23): FlaxBatchNorm2D(512, eps=1e-05, momentum=0.99, affine=False, 
)
input = Array([[[[ 1.7113085 , -0.00951955, -0.9299703 , ...,  0.2622262 ,
          -1.3784434 , -0.23491403],
         [-0.2...       [-0.6838486 ,  0.4097336 , -0.4479629 , ..., -0.8630706 ,
          -0.78792614, -0.49034852]]]], dtype=float32)

    def __call__(self, input):
        for i, module in enumerate(self):
>           input = module(input)

ivy_transpiled_outputs/jax_outputs/torch/nn/modules/container.py:181: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = FlaxConv(in_features=1, out_features=32, kernel_size=(3, 3), strides=(1, 1), padding=1, padding_mode=zeros)
args = (Array([[[[ 1.7113085 , -0.00951955, -0.9299703 , ...,  0.2622262 ,
          -1.3784434 , -0.23491403],
         [-0....     [-0.6838486 ,  0.4097336 , -0.4479629 , ..., -0.8630706 ,
          -0.78792614, -0.49034852]]]], dtype=float32),)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x55900faec1b0, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/jax_outputs/jax__st...neno=103, function='_multicall', code_context=['                    res = hook_impl.function(*args)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/jax_outputs/jax__stateful.py:102: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = FlaxConv(in_features=1, out_features=32, kernel_size=(3, 3), strides=(1, 1), padding=1, padding_mode=zeros)
args = (Array([[[[ 1.7113085 , -0.00951955, -0.9299703 , ...,  0.2622262 ,
          -1.3784434 , -0.23491403],
         [-0....     [-0.6838486 ,  0.4097336 , -0.4479629 , ..., -0.8630706 ,
          -0.78792614, -0.49034852]]]], dtype=float32),)
kwargs = {}, jax_get_item = <function jax_get_item at 0x7f7a146016c0>, jax_set_item = <function jax_set_item at 0x7f7a14601870>, DATA_FORMAT = 'channels_last'
fn_args_and_kwargs = {'inputs': Array([[[[ 1.7113085 ],
         [-0.00951955],
         [-0.9299703 ],
         ...,
         [ 0.2622262 ...[-0.4479629 ],
         ...,
         [-0.8630706 ],
         [-0.78792614],
         [-0.49034852]]]], dtype=float32)}
conv_block_start = <function jax_handle_transpose_in_input_and_output.<locals>.transpose_wrapper.<locals>.<lambda> at 0x7f7a179b89d0>
next_call_in_seq = FlaxBatchNorm2D(32, eps=1e-05, momentum=0.99, affine=False, , conv_block_continued = True, arg_name = 'inputs'
input = Array([[[[ 1.7113085 , -0.00951955, -0.9299703 , ...,  0.2622262 ,
          -1.3784434 , -0.23491403],
         [-0.2...       [-0.6838486 ,  0.4097336 , -0.4479629 , ..., -0.8630706 ,
          -0.78792614, -0.49034852]]]], dtype=float32)
transpose = <jax_TransposeType.CONV2D: 'conv2d'>

    @functools.wraps(fn)
    def transpose_wrapper(self, *args, **kwargs):
        from ..functional.backends.jax.general import jax_get_item
        from ..functional.backends.jax.general import jax_set_item
    
        DATA_FORMAT = os.environ.get("DATA_FORMAT", "channels_first")
        kwargs_call = {
            key: val
            for key, val in kwargs.items()
            if key not in dict(original_signature.parameters)
        }
        fn_args_and_kwargs = {
            key: val for key, val in kwargs.items() if key not in kwargs_call
        }
        fn_args_and_kwargs.update(dict(zip(fn.__code__.co_varnames[1:], args)))
        conv_block_start = lambda f: any(
            substr in f.__qualname__
            for substr in CONV_FUNCS
            + NORM_FUNCS
            + POOL_FUNCS
            + KERAS_CONV_FUNCS
            + KERAS_NORM_FUNCS
            + KERAS_POOL_FUNCS
            + FLAX_CONV_FUNCS
            + FLAX_NORM_FUNCS
            + FLAX_POOL_FUNCS
        )
        next_call_in_seq = jax_get_next_func(self)
        name_of_next_call = (
            next_call_in_seq.__class__.__name__
            if hasattr(next_call_in_seq, "__class__")
            else ""
        )
        conv_block_continued = next_call_in_seq and any(
            substr in name_of_next_call for substr in CONV_BLOCK_FNS
        )
        arg_name = "input" if "input" in fn_args_and_kwargs else "inputs"
        if DATA_FORMAT == "channels_first" and conv_block_start(self.__class__):
            input = jax_get_item(fn_args_and_kwargs, arg_name)
            if len(input.shape) > 4:
                transpose = jax_TransposeType.CONV3D
            elif len(input.shape) > 3:
                transpose = jax_TransposeType.CONV2D
            elif len(input.shape) > 2:
                transpose = jax_TransposeType.CONV1D
            else:
                transpose = jax_TransposeType.NO_TRANSPOSE
            fn_args_and_kwargs = jax_set_item(
                fn_args_and_kwargs,
                arg_name,
                jax_apply_transpose(input, transpose=transpose, pt_to_tf=True),
            )
            DATA_FORMAT = "channels_last"
            os.environ = jax_set_item(os.environ, "DATA_FORMAT", DATA_FORMAT)
>       res = fn(self, **fn_args_and_kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/utils/decorator_utils.py:412: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = FlaxConv(in_features=1, out_features=32, kernel_size=(3, 3), strides=(1, 1), padding=1, padding_mode=zeros)
inputs = Array([[[[ 1.7113085 ],
         [-0.00951955],
         [-0.9299703 ],
         ...,
         [ 0.2622262 ],
        ... [-0.4479629 ],
         ...,
         [-0.8630706 ],
         [-0.78792614],
         [-0.49034852]]]], dtype=float32)

    @store_frame_info
    @jax_handle_transpose_in_input_and_output
    def __call__(self, inputs):
        self._built = True
        if self.padding_mode != "zeros":
            padding_mode = (
                "constant" if self.padding_mode == "zeros" else self.padding_mode
            )
            # handle Pytorch-style padding
            inputs = torch_pad(
                inputs, self._reversed_padding_repeated_twice, mode=padding_mode
            )
            old_pad = self.padding
            self.padding = 0
            logits = super().__call__(inputs)
            self.padding = old_pad
            self._built = False
            return logits
>       logits = super().__call__(inputs)

ivy_transpiled_outputs/jax_outputs/jax__stateful_layers.py:299: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = FlaxConv(in_features=1, out_features=32, kernel_size=(3, 3), strides=(1, 1), padding=1, padding_mode=zeros)
inputs = Array([[[[ 1.7113085 ],
         [-0.00951955],
         [-0.9299703 ],
         ...,
         [ 0.2622262 ],
        ... [-0.4479629 ],
         ...,
         [-0.8630706 ],
         [-0.78792614],
         [-0.49034852]]]], dtype=float32)

    def __call__(self, inputs: Array) -> Array:
      """Applies a (potentially unshared) convolution to the inputs.
    
      Args:
        inputs: input data with dimensions ``(*batch_dims, spatial_dims..., features)``.
          This is the channels-last convention, i.e. NHWC for a 2d convolution and
          NDHWC for a 3D convolution. Note: this is different from the input convention
          used by ``lax.conv_general_dilated``, which puts the spatial dimensions last.
          Note: If the input has more than 1 batch dimension, all batch dimensions
          are flattened into a single dimension for the convolution and restored
          before returning.  In some cases directly vmap'ing the layer may yield
          better performance than this default flattening approach.  If the input
          lacks a batch dimension it will be added for the convolution and removed
          n return, an allowance made to enable writing single-example code.
    
      Returns:
        The convolved data.
      """
    
      assert isinstance(self.kernel_size, tuple)
      kernel_size = self.kernel_size
    
      def maybe_broadcast(
        x: tp.Optional[tp.Union[int, tp.Sequence[int]]],
      ) -> tuple[int, ...]:
        if x is None:
          # backward compatibility with using None as sentinel for
          # broadcast 1
          x = 1
        if isinstance(x, int):
          return (x,) * len(kernel_size)
        return tuple(x)
    
      # Combine all input batch dimensions into a single leading batch axis.
      num_batch_dimensions = inputs.ndim - (len(kernel_size) + 1)
      if num_batch_dimensions != 1:
        input_batch_shape = inputs.shape[:num_batch_dimensions]
        total_batch_size = int(np.prod(input_batch_shape))
        flat_input_shape = (total_batch_size,) + inputs.shape[
          num_batch_dimensions:
        ]
        inputs = jnp.reshape(inputs, flat_input_shape)
    
      # self.strides or (1,) * (inputs.ndim - 2)
      strides = maybe_broadcast(self.strides)
      input_dilation = maybe_broadcast(self.input_dilation)
      kernel_dilation = maybe_broadcast(self.kernel_dilation)
    
      padding_lax = canonicalize_padding(self.padding, len(kernel_size))
      if padding_lax == 'CIRCULAR':
        kernel_size_dilated = [
          (k - 1) * d + 1 for k, d in zip(kernel_size, kernel_dilation)
        ]
        zero_pad: tp.List[tuple[int, int]] = [(0, 0)]
        pads = (
          zero_pad
          + [((k - 1) // 2, k // 2) for k in kernel_size_dilated]
          + [(0, 0)]
        )
        inputs = jnp.pad(inputs, pads, mode='wrap')
        padding_lax = 'VALID'
      elif padding_lax == 'CAUSAL':
        if len(kernel_size) != 1:
          raise ValueError(
            'Causal padding is only implemented for 1D convolutions.'
          )
        left_pad = kernel_dilation[0] * (kernel_size[0] - 1)
        pads = [(0, 0), (left_pad, 0), (0, 0)]
        inputs = jnp.pad(inputs, pads)
        padding_lax = 'VALID'
    
      dimension_numbers = _conv_dimension_numbers(inputs.shape)
    
      # One shared convolutional kernel for all pixels in the output.
      assert self.in_features % self.feature_group_count == 0
    
      if self.mask is not None and self.mask.shape != self.kernel_shape:
        raise ValueError(
          'Mask needs to have the same shape as weights. '
          f'Shapes are: {self.mask.shape}, {self.kernel_shape}'
        )
    
      kernel = self.kernel.value
    
      if self.mask is not None:
        kernel *= self.mask
    
      bias = self.bias.value
    
      inputs, kernel, bias = dtypes.promote_dtype(
        (inputs, kernel, bias), dtype=self.dtype
      )
    
>     y = self.conv_general_dilated(
        inputs,
        kernel,
        strides,
        padding_lax,
        lhs_dilation=input_dilation,
        rhs_dilation=kernel_dilation,
        dimension_numbers=dimension_numbers,
        feature_group_count=self.feature_group_count,
        precision=self.precision,
      )

/opt/fw/jax/flax/nnx/nn/linear.py:764: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

lhs = Array([[[[ 1.7113085 ],
         [-0.00951955],
         [-0.9299703 ],
         ...,
         [ 0.2622262 ],
        ... [-0.4479629 ],
         ...,
         [-0.8630706 ],
         [-0.78792614],
         [-0.49034852]]]], dtype=float32)
rhs = Array([[ 0.17321092,  0.14065616, -0.1845205 ,  0.04476047,  0.02703602,
         0.05671129,  0.05412335, -0.08114062...0.07064222,  0.01723543,  0.00141026,
        -0.12867665, -0.09788989, -0.0136649 , -0.03683599]],      dtype=float32)
window_strides = (1, 1), padding = ((1, 1), (1, 1)), lhs_dilation = (1, 1), rhs_dilation = (1, 1)
dimension_numbers = ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)), feature_group_count = 1, batch_group_count = 1, precision = None
preferred_element_type = None

    def conv_general_dilated(
      lhs: Array, rhs: Array, window_strides: Sequence[int],
      padding: str | Sequence[tuple[int, int]],
      lhs_dilation: Sequence[int] | None = None,
      rhs_dilation: Sequence[int] | None = None,
      dimension_numbers: ConvGeneralDilatedDimensionNumbers  = None,
      feature_group_count: int = 1, batch_group_count: int = 1,
      precision: lax.PrecisionLike = None,
      preferred_element_type: DTypeLike | None = None) -> Array:
      """General n-dimensional convolution operator, with optional dilation.
    
      Wraps XLA's `Conv
      <https://www.tensorflow.org/xla/operation_semantics#conv_convolution>`_
      operator.
    
      Args:
        lhs: a rank `n+2` dimensional input array.
        rhs: a rank `n+2` dimensional array of kernel weights.
        window_strides: a sequence of `n` integers, representing the inter-window
          strides.
        padding: either the strings `'SAME'`, `'SAME_LOWER'`, or `'VALID'`, or a
          sequence of `n` `(low, high)` integer pairs that give the padding to apply
          before and after each spatial dimension. `'SAME'` and `'SAME_LOWER'` add
          padding to produce same output size as the input. The padding is split
          between the two sides equally or almost equally. In case the padding is an
          odd number, the extra padding is added at the end for `'SAME'` and at the
          beginning for `'SAME_LOWER'`.
        lhs_dilation: `None`, or a sequence of `n` integers, giving the dilation
          factor to apply in each spatial dimension of `lhs`. LHS dilation is also
          known as transposed convolution.
        rhs_dilation: `None`, or a sequence of `n` integers, giving the dilation
          factor to apply in each spatial dimension of `rhs`. RHS dilation is also
          known as atrous convolution.
        dimension_numbers: either `None`, a ``ConvDimensionNumbers`` object, or a
          3-tuple ``(lhs_spec, rhs_spec, out_spec)``, where each element is a string
          of length `n+2`.
        feature_group_count: integer, default 1. See XLA HLO docs.
        batch_group_count: integer, default 1. See XLA HLO docs.
        precision: Optional. Either ``None``, which means the default precision for
          the backend, a :class:`~jax.lax.Precision` enum value
          (``Precision.DEFAULT``, ``Precision.HIGH`` or ``Precision.HIGHEST``), a
          string (e.g. 'highest' or 'fastest', see the
          ``jax.default_matmul_precision`` context manager), or a tuple of two
          :class:`~jax.lax.Precision` enums or strings indicating precision of
          ``lhs`` and ``rhs``.
        preferred_element_type: Optional. Either ``None``, which means the default
          accumulation type for the input types, or a datatype, indicating to
          accumulate results to and return a result with that datatype.
    
      Returns:
        An array containing the convolution result.
    
      In the string case of ``dimension_numbers``, each character identifies by
      position:
    
      - the batch dimensions in ``lhs``, ``rhs``, and the output with the character
        'N',
      - the feature dimensions in `lhs` and the output with the character 'C',
      - the input and output feature dimensions in rhs with the characters 'I'
        and 'O' respectively, and
      - spatial dimension correspondences between lhs, rhs, and the output using
        any distinct characters. The examples below use 'W' and 'H'.
    
      For example, to indicate dimension numbers consistent with the ``conv``
      function with two spatial dimensions, one could use ``('NCHW', 'OIHW',
      'NCHW')``. As another example, to indicate dimension numbers consistent with
      the TensorFlow Conv2D operation, one could use ``('NHWC', 'HWIO', 'NHWC')``.
      When using the latter form of convolution dimension specification, window
      strides are associated with spatial dimension character labels according to
      the order in which the labels appear in the ``rhs_spec`` string, so that
      ``window_strides[0]`` is matched with the dimension corresponding to the first
      character appearing in rhs_spec that is not ``'I'`` or ``'O'``.
    
      If ``dimension_numbers`` is ``None``, the default is ``('NCHW', 'OIHW',
      'NCHW')`` (for a 2D convolution).
      """
      dnums = conv_dimension_numbers(lhs.shape, rhs.shape, dimension_numbers)
      if lhs_dilation is None:
        lhs_dilation = (1,) * (lhs.ndim - 2)
      elif isinstance(padding, str) and not len(lhs_dilation) == lhs_dilation.count(1):
        raise ValueError(
            "String padding is not implemented for transposed convolution "
            "using this op. Please either exactly specify the required padding or "
            "use conv_transpose.")
      if rhs_dilation is None:
        rhs_dilation = (1,) * (rhs.ndim - 2)
      if isinstance(padding, str):
        lhs_perm, rhs_perm, _ = dnums
        rhs_shape = np.take(rhs.shape, rhs_perm)[2:]
        effective_rhs_shape = [core.dilate_dim(k, r) for k, r in zip(rhs_shape, rhs_dilation)]
        padding = lax.padtype_to_pads(
            np.take(lhs.shape, lhs_perm)[2:], effective_rhs_shape,
            window_strides, padding)
      else:
        try:
          padding = tuple((operator.index(lo), operator.index(hi))
                          for lo, hi in padding)
        except (ValueError, TypeError) as e:
          raise ValueError(
            "padding argument to conv_general_dilated should be a string or a "
            f"sequence of (low, high) pairs, got {padding}") from e
    
      preferred_element_type = (
          None if preferred_element_type is None else
          dtypes.canonicalize_dtype(np.dtype(preferred_element_type)))
>     return conv_general_dilated_p.bind(
          lhs, rhs, window_strides=tuple(window_strides), padding=tuple(padding),
          lhs_dilation=tuple(lhs_dilation), rhs_dilation=tuple(rhs_dilation),
          dimension_numbers=dnums,
          feature_group_count=feature_group_count,
          batch_group_count=batch_group_count,
          precision=lax.canonicalize_precision(precision),
          preferred_element_type=preferred_element_type)

/opt/fw/jax/jax/_src/lax/convolution.py:161: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = conv_general_dilated
args = (Array([[[[ 1.7113085 ],
         [-0.00951955],
         [-0.9299703 ],
         ...,
         [ 0.2622262 ],
       ....07064222,  0.01723543,  0.00141026,
        -0.12867665, -0.09788989, -0.0136649 , -0.03683599]],      dtype=float32))
params = {'batch_group_count': 1, 'dimension_numbers': ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)), 'feature_group_count': 1, 'lhs_dilation': (1, 1), ...}

    def bind(self, *args, **params):
      assert (not config.enable_checks.value or
              all(isinstance(arg, Tracer) or valid_jaxtype(arg) for arg in args)), args
>     return self.bind_with_trace(find_top_trace(args), args, params)

/opt/fw/jax/jax/_src/core.py:438: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = conv_general_dilated, trace = EvalTrace(level=0/0)
args = (Array([[[[ 1.7113085 ],
         [-0.00951955],
         [-0.9299703 ],
         ...,
         [ 0.2622262 ],
       ....07064222,  0.01723543,  0.00141026,
        -0.12867665, -0.09788989, -0.0136649 , -0.03683599]],      dtype=float32))
params = {'batch_group_count': 1, 'dimension_numbers': ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)), 'feature_group_count': 1, 'lhs_dilation': (1, 1), ...}

    def bind_with_trace(self, trace, args, params):
      with pop_level(trace.level):
>       out = trace.process_primitive(self, map(trace.full_raise, args), params)

/opt/fw/jax/jax/_src/core.py:442: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = EvalTrace(level=0/0), primitive = conv_general_dilated
tracers = [Array([[[[ 1.7113085 ],
         [-0.00951955],
         [-0.9299703 ],
         ...,
         [ 0.2622262 ],
       ....07064222,  0.01723543,  0.00141026,
        -0.12867665, -0.09788989, -0.0136649 , -0.03683599]],      dtype=float32)]
params = {'batch_group_count': 1, 'dimension_numbers': ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)), 'feature_group_count': 1, 'lhs_dilation': (1, 1), ...}

    def process_primitive(self, primitive, tracers, params):
      if config.debug_key_reuse.value:
        # Import here to avoid circular imports
        from jax.experimental.key_reuse._core import call_impl_with_key_reuse_checks  # pytype: disable=import-error
        return call_impl_with_key_reuse_checks(primitive, primitive.impl, *tracers, **params)
      else:
>       return primitive.impl(*tracers, **params)

/opt/fw/jax/jax/_src/core.py:948: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

prim = conv_general_dilated
args = (Array([[[[ 1.7113085 ],
         [-0.00951955],
         [-0.9299703 ],
         ...,
         [ 0.2622262 ],
       ....07064222,  0.01723543,  0.00141026,
        -0.12867665, -0.09788989, -0.0136649 , -0.03683599]],      dtype=float32))
params = {'batch_group_count': 1, 'dimension_numbers': ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)), 'feature_group_count': 1, 'lhs_dilation': (1, 1), ...}
fun = <PjitFunction of <function conv_general_dilated at 0x7f7a4433e9e0>>, prev = None

    def apply_primitive(prim, *args, **params):
      """Impl rule that compiles and runs a single primitive 'prim' using XLA."""
      fun = xla_primitive_callable(prim, **params)
      # TODO(yashkatariya): Investigate adding is_primitive to jit and never
      # triggering the disable jit path instead of messing around with it here.
      prev = lib.jax_jit.swap_thread_local_state_disable_jit(False)
      try:
>       outs = fun(*args)
E       ValueError: conv_general_dilated lhs and rhs must have the same number of dimensions, but got (16, 32, 32, 1) and (32, 9).

/opt/fw/jax/jax/_src/dispatch.py:90: ValueError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.HardNet8
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/test_feature2.py::test_HardNet8[jax-s2s-False] - ValueError: conv_general_dilated lhs and rhs must have the same number of dimensions, but got (16, 32, 32, 1) and (32, 9).
============================================================================== 1 failed, 16 passed in 1356.25s (0:22:36) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 6 items

kornia/geometry/test_depth.py ......                                                                                                                                                             [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
==================================================================================== 6 passed in 357.81s (0:05:57) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 8 items

kornia/test_image.py .F.FF.FF                                                                                                                                                                    [100%]

=============================================================================================== FAILURES ===============================================================================================
___________________________________________________________________________________ test_PixelFormat[jax-s2s-False] ____________________________________________________________________________________

>   ???

IM.pyx:94: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

object = <enum 'ColorSpace'>

    def getsource(object):
        """Return the text of the source code for an object.
    
        The argument may be a module, class, method, function, traceback, frame,
        or code object.  The source code is returned as a single string.  An
        OSError is raised if the source code cannot be retrieved."""
>       lines, lnum = getsourcelines(object)

/opt/miniconda/envs/multienv/lib/python3.10/inspect.py:1147: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

object = <enum 'ColorSpace'>

    def getsourcelines(object):
        """Return a list of source lines and starting line number for an object.
    
        The argument may be a module, class, method, function, traceback, frame,
        or code object.  The source code is returned as a list of the lines
        corresponding to the object and the line number indicates where in the
        original source file the first line of code was found.  An OSError is
        raised if the source code cannot be retrieved."""
        object = unwrap(object)
>       lines, lnum = findsource(object)

/opt/miniconda/envs/multienv/lib/python3.10/inspect.py:1129: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

object = <enum 'ColorSpace'>

    def findsource(object):
        """Return the entire source file and starting line number for an object.
    
        The argument may be a module, class, method, function, traceback, frame,
        or code object.  The source code is returned as a list of all the lines
        in the file and the line number indexes a line in that list.  An OSError
        is raised if the source code cannot be retrieved."""
    
        file = getsourcefile(object)
        if file:
            # Invalidate cache if needed.
            linecache.checkcache(file)
        else:
            file = getfile(object)
            # Allow filenames in form of "<something>" to pass through.
            # `doctest` monkeypatches `linecache` module to enable
            # inspection, so let `linecache.getlines` to be called.
            if not (file.startswith('<') and file.endswith('>')):
>               raise OSError('source code not available')
E               OSError: source code not available

/opt/miniconda/envs/multienv/lib/python3.10/inspect.py:950: OSError

During handling of the above exception, another exception occurred:

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_PixelFormat(target_framework, mode, backend_compile):
        print("kornia.image.PixelFormat")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target_framework)
    
>       pixel_format = transpiled_kornia.image.PixelFormat(ColorSpace.rgb, 8)

kornia/test_image.py:39: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:225: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:322: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:310: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:297: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   I.InvalidObjectException: Unable to access the source code of the object 'ColorSpace' of type 'EnumMeta'. This may occur if the object is dynamically created, defined in a Jupyter notebook, or not saved to disk.
E   
E   Suggested actions:
E   - Ensure that the object is defined in a Python module or script that is saved to disk.
E   - If you're working in a Jupyter notebook, consider using the `%%writefile` magic command to save the code to a file.
E     For example:
E     ```
E     %%writefile my_module.py
E     class MyClass:
E         def __init__(self):
E             pass
E     ```
E   - After saving the object to a file, you can then import it and call `ivy.transpile`.
E   - If the object is dynamically created, consider saving its definition to disk before transpiling.
E   Original error: source code not available

IM.pyx:96: InvalidObjectException
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.image.PixelFormat
___________________________________________________________________________________ test_ImageLayout[jax-s2s-False] ____________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_ImageLayout(target_framework, mode, backend_compile):
        print("kornia.image.ImageLayout")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target_framework)
    
>       layout = transpiled_kornia.image.ImageLayout(transpiled_kornia.image.ImageSize(3, 4), 3, transpiled_kornia.image.ChannelsOrder.CHANNELS_LAST)

kornia/test_image.py:64: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:230: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:153: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:162: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_ImageSize(height=3, width=4), name = '__class__', value = <class 'ivy_transpiled_outputs.jax_outputs.kornia.image.base.jax_ImageSize'>

>   ???
E   dataclasses.FrozenInstanceError: cannot assign to field '__class__'

<string>:4: FrozenInstanceError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.image.ImageLayout
______________________________________________________________________________________ test_Image[jax-s2s-False] _______________________________________________________________________________________

>   ???

IM.pyx:94: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

object = <enum 'ColorSpace'>

    def getsource(object):
        """Return the text of the source code for an object.
    
        The argument may be a module, class, method, function, traceback, frame,
        or code object.  The source code is returned as a single string.  An
        OSError is raised if the source code cannot be retrieved."""
>       lines, lnum = getsourcelines(object)

/opt/miniconda/envs/multienv/lib/python3.10/inspect.py:1147: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

object = <enum 'ColorSpace'>

    def getsourcelines(object):
        """Return a list of source lines and starting line number for an object.
    
        The argument may be a module, class, method, function, traceback, frame,
        or code object.  The source code is returned as a list of the lines
        corresponding to the object and the line number indicates where in the
        original source file the first line of code was found.  An OSError is
        raised if the source code cannot be retrieved."""
        object = unwrap(object)
>       lines, lnum = findsource(object)

/opt/miniconda/envs/multienv/lib/python3.10/inspect.py:1129: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

object = <enum 'ColorSpace'>

    def findsource(object):
        """Return the entire source file and starting line number for an object.
    
        The argument may be a module, class, method, function, traceback, frame,
        or code object.  The source code is returned as a list of all the lines
        in the file and the line number indexes a line in that list.  An OSError
        is raised if the source code cannot be retrieved."""
    
        file = getsourcefile(object)
        if file:
            # Invalidate cache if needed.
            linecache.checkcache(file)
        else:
            file = getfile(object)
            # Allow filenames in form of "<something>" to pass through.
            # `doctest` monkeypatches `linecache` module to enable
            # inspection, so let `linecache.getlines` to be called.
            if not (file.startswith('<') and file.endswith('>')):
>               raise OSError('source code not available')
E               OSError: source code not available

/opt/miniconda/envs/multienv/lib/python3.10/inspect.py:950: OSError

During handling of the above exception, another exception occurred:

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_Image(target_framework, mode, backend_compile):
        print("kornia.image.Image")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target_framework)
    
        torch_data = torch.randint(0, 255, (3, 4, 5), dtype=torch.uint8)
        transpiled_data = _array_to_new_backend(torch_data, target_framework)
    
        # torch
        pixel_format = kornia.image.PixelFormat(
            color_space=ColorSpace.rgb,
            bit_depth=8,
        )
        layout = kornia.image.ImageLayout(
            image_size=kornia.image.ImageSize(4, 5),
            channels=3,
            channels_order=kornia.image.ChannelsOrder.CHANNELS_FIRST,
        )
        torch_img = kornia.image.Image(torch_data, pixel_format, layout)
    
        # transpiled
>       pixel_format = transpiled_kornia.image.PixelFormat(
            color_space=ColorSpace.rgb,
            bit_depth=8,
        )

kornia/test_image.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:229: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:322: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:310: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:297: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   I.InvalidObjectException: Unable to access the source code of the object 'ColorSpace' of type 'EnumMeta'. This may occur if the object is dynamically created, defined in a Jupyter notebook, or not saved to disk.
E   
E   Suggested actions:
E   - Ensure that the object is defined in a Python module or script that is saved to disk.
E   - If you're working in a Jupyter notebook, consider using the `%%writefile` magic command to save the code to a file.
E     For example:
E     ```
E     %%writefile my_module.py
E     class MyClass:
E         def __init__(self):
E             pass
E     ```
E   - After saving the object to a file, you can then import it and call `ivy.transpile`.
E   - If the object is dynamically created, consider saving its definition to disk before transpiling.
E   Original error: source code not available

IM.pyx:96: InvalidObjectException
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.image.Image
________________________________________________________________________________ test_Image_from_dlpack[jax-s2s-False] _________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_Image_from_dlpack(target_framework, mode, backend_compile):
        print("kornia.image.Image.from_dlpack")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target_framework)
    
        x = np.ones((4, 5, 3))
>       img = transpiled_kornia.image.Image.from_dlpack(x.__dlpack__())
E       TypeError: 'classmethod' object is not callable

kornia/test_image.py:139: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.image.Image.from_dlpack
__________________________________________________________________________________ test_Image_to_numpy[jax-s2s-False] __________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_Image_to_numpy(target_framework, mode, backend_compile):
        print("kornia.image.Image.to_numpy")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target_framework)
    
        data = np.ones((4, 5, 3), dtype=np.uint8)
>       img = transpiled_kornia.image.Image.from_numpy(data, color_space=ColorSpace.rgb)
E       TypeError: 'classmethod' object is not callable

kornia/test_image.py:152: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.image.Image.to_numpy
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/test_image.py::test_PixelFormat[jax-s2s-False] - I.InvalidObjectException: Unable to access the source code of the object 'ColorSpace' of type 'EnumMeta'. This may occur if the object...
FAILED kornia/test_image.py::test_ImageLayout[jax-s2s-False] - dataclasses.FrozenInstanceError: cannot assign to field '__class__'
FAILED kornia/test_image.py::test_Image[jax-s2s-False] - I.InvalidObjectException: Unable to access the source code of the object 'ColorSpace' of type 'EnumMeta'. This may occur if the object is dy...
FAILED kornia/test_image.py::test_Image_from_dlpack[jax-s2s-False] - TypeError: 'classmethod' object is not callable
FAILED kornia/test_image.py::test_Image_to_numpy[jax-s2s-False] - TypeError: 'classmethod' object is not callable
=============================================================================== 5 failed, 3 passed in 254.04s (0:04:14) ================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 2 items

kornia/geometry/test_boxes.py ss                                                                                                                                                                 [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
========================================================================================== 2 skipped in 5.71s ==========================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 8 items

kornia/geometry/test_bbox.py ..F.....                                                                                                                                                            [100%]

=============================================================================================== FAILURES ===============================================================================================
_______________________________________________________________________________ test_bbox_to_mask[tensorflow-s2s-False] ________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_bbox_to_mask(target_framework, mode, backend_compile):
        trace_args = (
            torch.tensor([[[1., 1.], [3., 1.], [3., 2.], [1., 2.]]]),
            5,
            5,
        )
        trace_kwargs = {}
        test_args = (
            torch.tensor([[[2., 2.], [4., 2.], [4., 3.], [2., 3.]]]),
            6,
            6,
        )
        test_kwargs = {}
>       _test_function(
            kornia.geometry.bbox.bbox_to_mask,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/geometry/test_bbox.py:82: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function bbox_to_mask at 0x7fe109aa00d0>, trace_args = (tensor([[[1., 1.],
         [3., 1.],
         [3., 2.],
         [1., 2.]]]), 5, 5), trace_kwargs = {}
test_args = (tensor([[[2., 2.],
         [4., 2.],
         [4., 3.],
         [2., 3.]]]), 6, 6), test_kwargs = {}, target = 'tensorflow', backend_compile = False, tolerance = 0.001, mode = 's2s'
skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function bbox_to_mask at 0x7fe109aa00d0>, fn_name = 'kornia.geometry.bbox.bbox_to_mask', trace_args = (tensor([[[1., 1.],
         [3., 1.],
         [3., 2.],
         [1., 2.]]]), 5, 5)
trace_kwargs = {}, test_args = (tensor([[[2., 2.],
         [4., 2.],
         [4., 3.],
         [2., 3.]]]), 6, 6), test_kwargs = {}, target = 'tensorflow', backend_compile = False
tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
        graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
    
        if deterministic:
>           _to_numpy_and_allclose(orig_out, graph_out, tolerance=tolerance)

helpers.py:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

torch_x = tensor([[[0., 0., 0., 0., 0.],
         [0., 1., 1., 1., 0.],
         [0., 1., 1., 1., 0.],
         [0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.]]])
transpiled_x = <tf.Tensor: shape=(1, 5, 5), dtype=float32, numpy=
array([[[0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0.]]], dtype=float32)>
tolerance = 0.001

    def _to_numpy_and_allclose(torch_x, transpiled_x, tolerance=1e-3):
        orig_data = _nest_array_to_numpy(torch_x)
        transpiled_data = _nest_array_to_numpy(transpiled_x)
>       _check_allclose(orig_data, transpiled_data, tolerance=tolerance)

helpers.py:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[0., 0., 0., 0., 0.],
        [0., 1., 1., 1., 0.],
        [0., 1., 1., 1., 0.],
        [0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0.]]], dtype=float32)
y = array([[[0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0.]]], dtype=float32), tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
>           assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
E           AssertionError: numpy array values are not all close

helpers.py:26: AssertionError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.bbox.bbox_to_mask
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/geometry/test_bbox.py::test_bbox_to_mask[tensorflow-s2s-False] - AssertionError: numpy array values are not all close
=============================================================================== 1 failed, 7 passed in 502.07s (0:08:22) ================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 13 items

kornia/test_feature3.py sssssssssssss                                                                                                                                                            [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
========================================================================================= 13 skipped in 5.41s ==========================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 4 items

kornia/test_sensors.py ....                                                                                                                                                                      [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
===================================================================================== 4 passed in 82.53s (0:01:22) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 2 items

kornia/geometry/test_vector.py ss                                                                                                                                                                [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
========================================================================================== 2 skipped in 5.10s ==========================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 4 items

kornia/geometry/test_liegroup.py FFFF                                                                                                                                                            [100%]

=============================================================================================== FAILURES ===============================================================================================
____________________________________________________________________________________ test_So3[tensorflow-s2s-False] ____________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_So3(target_framework, mode, backend_compile):
        print("kornia.geometry.liegroup.So3")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target_framework)
    
        # Initialize a Quaternion and create an So3 object
        quaternion_data = torch.tensor([1., 0., 0., 0.])
        torch_quaternion = kornia.geometry.quaternion.Quaternion(quaternion_data)
        torch_so3 = kornia.geometry.liegroup.So3(torch_quaternion)
    
        # Transpile the So3 class
        transpiled_quaternion = transpiled_kornia.geometry.quaternion.Quaternion(_nest_torch_tensor_to_new_framework(quaternion_data, target_framework))
        transpiled_so3 = transpiled_kornia.geometry.liegroup.So3(transpiled_quaternion)
    
        # Test .matrix()
        torch_matrix = torch_so3.matrix()
        transpiled_matrix = transpiled_so3.matrix()
        _to_numpy_and_allclose(torch_matrix, transpiled_matrix)
    
        # Test .inverse()
        torch_inverse = torch_so3.inverse()
        transpiled_inverse = transpiled_so3.inverse()
        _to_numpy_and_allclose(torch_inverse.q.data, transpiled_inverse.q.data)
    
        # Test .log()
        torch_log = torch_so3.log()
        transpiled_log = transpiled_so3.log()
        _to_numpy_and_allclose(torch_log, transpiled_log)
    
        # Test .__mul__()
        other_quaternion_data = torch.tensor([0., 1., 0., 0.])
        other_torch_quaternion = kornia.geometry.quaternion.Quaternion(other_quaternion_data)
        other_torch_so3 = kornia.geometry.liegroup.So3(other_torch_quaternion)
    
        transpiled_other_quaternion = _nest_torch_tensor_to_new_framework(other_quaternion_data, target_framework)
        transpiled_other_quaternion_obj = transpiled_kornia.geometry.quaternion.Quaternion(transpiled_other_quaternion)
        transpiled_other_so3 = transpiled_kornia.geometry.liegroup.So3(transpiled_other_quaternion_obj)
    
        torch_composed_so3 = torch_so3 * other_torch_so3
        transpiled_composed_so3 = transpiled_so3 * transpiled_other_so3
        _to_numpy_and_allclose(torch_composed_so3.q.data, transpiled_composed_so3.q.data)
    
        # Test .adjoint()
        torch_adjoint = torch_so3.adjoint()
        transpiled_adjoint = transpiled_so3.adjoint()
        _to_numpy_and_allclose(torch_adjoint, transpiled_adjoint)
    
        # Test .from_matrix()
        rotation_matrix = torch.eye(3)
        transpiled_rotation_matrix = _nest_torch_tensor_to_new_framework(rotation_matrix, target_framework)
    
        torch_from_matrix = kornia.geometry.liegroup.So3.from_matrix(rotation_matrix)
>       transpiled_from_matrix = transpiled_kornia.geometry.liegroup.So3.from_matrix(transpiled_rotation_matrix)
E       TypeError: 'classmethod' object is not callable

kornia/geometry/test_liegroup.py:70: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.liegroup.So3
____________________________________________________________________________________ test_Se3[tensorflow-s2s-False] ____________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_Se3(target_framework, mode, backend_compile):
        print("kornia.geometry.liegroup.Se3")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        quaternion_data = torch.tensor([1., 0., 0., 0.])
        translation_data = torch.tensor([1., 1., 1.])
        torch_quaternion = kornia.geometry.quaternion.Quaternion(quaternion_data)
        torch_se3 = kornia.geometry.liegroup.Se3(torch_quaternion, translation_data)
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target_framework)
    
        transpiled_translation = _nest_torch_tensor_to_new_framework(translation_data, target_framework)
        transpiled_quaternion = transpiled_kornia.geometry.quaternion.Quaternion(_nest_torch_tensor_to_new_framework(quaternion_data, target_framework))
        transpiled_se3 = transpiled_kornia.geometry.liegroup.Se3(transpiled_quaternion, transpiled_translation)
    
        # Test .matrix()
        torch_matrix = torch_se3.matrix()
        transpiled_matrix = transpiled_se3.matrix()
        _to_numpy_and_allclose(torch_matrix, transpiled_matrix)
    
        # Test .inverse()
        torch_inverse = torch_se3.inverse()
        transpiled_inverse = transpiled_se3.inverse()
        _to_numpy_and_allclose(torch_inverse.r.q.data, transpiled_inverse.r.q.data)
        _to_numpy_and_allclose(torch_inverse.t, transpiled_inverse.t)
    
        # Test .log()
        torch_log = torch_se3.log()
        transpiled_log = transpiled_se3.log()
        _to_numpy_and_allclose(torch_log, transpiled_log)
    
        # Test .__mul__()
        other_quaternion_data = torch.tensor([0., 1., 0., 0.])
        other_translation_data = torch.tensor([2., 2., 2.])
        other_torch_quaternion = kornia.geometry.quaternion.Quaternion(other_quaternion_data)
        other_torch_se3 = kornia.geometry.liegroup.Se3(other_torch_quaternion, other_translation_data)
    
        transpiled_other_quaternion = _nest_torch_tensor_to_new_framework(other_quaternion_data, target_framework)
        transpiled_other_translation = _nest_torch_tensor_to_new_framework(other_translation_data, target_framework)
        transpiled_other_quaternion_obj = transpiled_kornia.geometry.quaternion.Quaternion(transpiled_other_quaternion)
        transpiled_other_se3 = transpiled_kornia.geometry.liegroup.Se3(transpiled_other_quaternion_obj, transpiled_other_translation)
    
        torch_composed_se3 = torch_se3 * other_torch_se3
        transpiled_composed_se3 = transpiled_se3 * transpiled_other_se3
        _to_numpy_and_allclose(torch_composed_se3.r.q.data, transpiled_composed_se3.r.q.data)
        _to_numpy_and_allclose(torch_composed_se3.t, transpiled_composed_se3.t)
    
        # Test .adjoint()
        torch_adjoint = torch_se3.adjoint()
        transpiled_adjoint = transpiled_se3.adjoint()
        _to_numpy_and_allclose(torch_adjoint, transpiled_adjoint)
    
        # Test .from_matrix()
        rotation_translation_matrix = torch.eye(4)
        transpiled_rotation_translation_matrix = _nest_torch_tensor_to_new_framework(rotation_translation_matrix, target_framework)
    
        torch_from_matrix = kornia.geometry.liegroup.Se3.from_matrix(rotation_translation_matrix)
>       transpiled_from_matrix = transpiled_kornia.geometry.liegroup.Se3.from_matrix(transpiled_rotation_translation_matrix)
E       TypeError: 'classmethod' object is not callable

kornia/geometry/test_liegroup.py:141: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.liegroup.Se3
____________________________________________________________________________________ test_So2[tensorflow-s2s-False] ____________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_So2(target_framework, mode, backend_compile):
        print("kornia.geometry.liegroup.So2")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target_framework)
    
        real_part = torch.tensor([1.0], requires_grad=True)
        imaginary_part = torch.tensor([2.0], requires_grad=True)
        complex_number = torch.complex(real_part, imaginary_part)
        torch_so2 = kornia.geometry.liegroup.So2(complex_number)
    
        transpiled_complex_number = _nest_torch_tensor_to_new_framework(complex_number, target_framework)
>       transpiled_so2 = transpiled_kornia.geometry.liegroup.So2(transpiled_complex_number)

kornia/geometry/test_liegroup.py:169: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:232: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'tensorflow_So2' object has no attribute '_z'") raised in repr()] tensorflow_So2 object at 0x7ff924232710>
z = <tf.Tensor: shape=(1,), dtype=complex64, numpy=array([1.+2.j], dtype=complex64)>

    def __init__(self, z):
        from ...core.check import tensorflow_KORNIA_CHECK_IS_TENSOR
        from ._utils import tensorflow_check_so2_z_shape
    
        self.super___init__(
            z,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        tensorflow_KORNIA_CHECK_IS_TENSOR(z)
        tensorflow_check_so2_z_shape(z)
>       self._z = tensorflow.keras.Variable(z)

ivy_transpiled_outputs/tensorflow_outputs/kornia/geometry/liegroup/so2.py:49: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <KerasVariable shape=<unknown>, dtype=float32, path=variable_20>, initializer = <tf.Tensor: shape=(1,), dtype=complex64, numpy=array([1.+2.j], dtype=complex64)>, shape = None, dtype = 'float32'
trainable = True, autocast = True, aggregation = 'mean', name = 'variable_20'

    def __init__(
        self,
        initializer,
        shape=None,
        dtype=None,
        trainable=True,
        autocast=True,
        aggregation="mean",
        name=None,
    ):
        name = name or auto_name(self.__class__.__name__)
        if not isinstance(name, str) or "/" in name:
            raise ValueError(
                "Argument `name` must be a string and "
                "cannot contain character `/`. "
                f"Received: name={name}"
            )
        if aggregation not in ("mean", "sum", "only_first_replica"):
            raise ValueError(
                "Invalid valid for argument `aggregation`. Expected "
                "one of {'mean', 'sum', 'only_first_replica'}. "
                f"Received: aggregation={aggregation}"
            )
        self.name = name
        parent_path = current_path()
        if parent_path:
            self.path = current_path() + "/" + self.name
        else:
            self.path = self.name
        dtype = standardize_dtype(dtype)
        self._dtype = dtype
        self._shape = None
        self._initializer = None
        self._regularizer = None
        self._constraint = None
        self._trainable = trainable
        self._autocast = autocast
        self._aggregation = aggregation
        # `self._overwrite_with_gradient` is an internal property to determine
        # whether this variable should be overwritten by the computed gradient.
        # Ref: https://github.com/google/flax/blob/main/flax/linen/fp8_ops.py
        self._overwrite_with_gradient = False
        if isinstance(initializer, str):
            from keras.src import initializers
    
            initializer = initializers.get(initializer)
        if callable(initializer):
            if shape is None:
                raise ValueError(
                    "When creating a Variable from an initializer, "
                    "the `shape` argument should be specified. "
                    f"Received: initializer={initializer} "
                    f"and shape={shape}"
                )
    
        if in_stateless_scope():
            if callable(initializer):
                self._value = None
                self._initializer = initializer
                self._shape = self._validate_shape(shape)
                register_uninitialized_variable(self)
            else:
                raise ValueError(
                    "You are attempting to create a variable "
                    "while in a stateless scope. This is disallowed. "
                    "Make sure that all variables are created "
                    "before you start using your layer/model objects.\n\n"
                    "In some cases, you might be seeing this error "
                    "because you need to "
                    "implement a `def build(self, input_shape)` method "
                    "on your layer/model, which will "
                    "create its variables.\n\n"
                    "In some other cases, you might be seeing this error "
                    "because you are instantiating a `Variable` and "
                    "assigning it to a layer without going through "
                    "self.add_variable()/self.add_weight(). Always prefer "
                    "using these methods "
                    "(with a `shape` and `initializer` argument)."
                )
        else:
            if callable(initializer):
                self._shape = self._validate_shape(shape)
                self._initialize_with_initializer(initializer)
            else:
>               self._initialize(initializer)

/opt/fw/tensorflow/keras/src/backend/common/variables.py:165: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <KerasVariable shape=<unknown>, dtype=float32, path=variable_20>, value = <tf.Tensor: shape=(1,), dtype=complex64, numpy=array([1.+2.j], dtype=complex64)>

    def _initialize(self, value):
>       self._value = tf.Variable(
            value, dtype=self._dtype, trainable=self.trainable, name=self.name
        )

/opt/fw/tensorflow/keras/src/backend/tensorflow/core.py:35: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (<class 'tensorflow.python.ops.variables.Variable'>, <tf.Tensor: shape=(1,), dtype=complex64, numpy=array([1.+2.j], dtype=complex64)>)
kwargs = {'dtype': 'float32', 'name': 'variable_20', 'trainable': True}

    def error_handler(*args, **kwargs):
      try:
        if not is_traceback_filtering_enabled():
          return fn(*args, **kwargs)
      except NameError:
        # In some very rare cases,
        # `is_traceback_filtering_enabled` (from the outer scope) may not be
        # accessible from inside this function
        return fn(*args, **kwargs)
    
      filtered_tb = None
      try:
        return fn(*args, **kwargs)
      except Exception as e:
        filtered_tb = _process_traceback_frames(e.__traceback__)
>       raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/tensorflow/python/util/traceback_utils.py:153: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <tf.Tensor: shape=(1,), dtype=complex64, numpy=array([1.+2.j], dtype=complex64)>, dtype = tf.float32, name = 'initial_value'

    def __tf_tensor__(
        self, dtype: Optional[dtypes.DType] = None, name: Optional[str] = None
        ) -> "Tensor":
      if dtype is not None and not dtype.is_compatible_with(self.dtype):
>       raise ValueError(
            _add_error_prefix(
                f"Tensor conversion requested dtype {dtype.name} "
                f"for Tensor with dtype {self.dtype.name}: {self!r}",
                name=name))
E       ValueError: initial_value: Tensor conversion requested dtype float32 for Tensor with dtype complex64: <tf.Tensor: shape=(1,), dtype=complex64, numpy=array([1.+2.j], dtype=complex64)>

/opt/fw/tensorflow/tensorflow/python/framework/tensor.py:761: ValueError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.liegroup.So2
____________________________________________________________________________________ test_Se2[tensorflow-s2s-False] ____________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_Se2(target_framework, mode, backend_compile):
        print("kornia.geometry.liegroup.Se2")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target_framework)
    
        so2_rotation = kornia.geometry.liegroup.So2.identity(1)
        translation_vector = torch.ones((1, 2), requires_grad=True)
        torch_se2 = kornia.geometry.liegroup.Se2(so2_rotation, translation_vector)
    
>       transpiled_so2_rotation = transpiled_kornia.geometry.liegroup.Se2.identity(1)
E       TypeError: 'classmethod' object is not callable

kornia/geometry/test_liegroup.py:250: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.liegroup.Se2
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/geometry/test_liegroup.py::test_So3[tensorflow-s2s-False] - TypeError: 'classmethod' object is not callable
FAILED kornia/geometry/test_liegroup.py::test_Se3[tensorflow-s2s-False] - TypeError: 'classmethod' object is not callable
FAILED kornia/geometry/test_liegroup.py::test_So2[tensorflow-s2s-False] - ValueError: initial_value: Tensor conversion requested dtype float32 for Tensor with dtype complex64: <tf.Tensor: shape=(1,...
FAILED kornia/geometry/test_liegroup.py::test_Se2[tensorflow-s2s-False] - TypeError: 'classmethod' object is not callable
==================================================================================== 4 failed in 323.37s (0:05:23) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 19 items

kornia/geometry/test_camera.py ...................                                                                                                                                               [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
=================================================================================== 19 passed in 1069.94s (0:17:49) ====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 17 items

kornia/augmentation/test_augmentation2.py ...F.......F.F.F.                                                                                                                                      [100%]

=============================================================================================== FAILURES ===============================================================================================
_____________________________________________________________________________ test_RandomMotionBlur[tensorflow-s2s-False] ______________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_RandomMotionBlur(target_framework, mode, backend_compile):
        print("kornia.augmentation.RandomMotionBlur")
    
        init_args = (3, 35., 0.5)
        init_kwargs = {"p": 1.}
        call_args = (torch.ones(1, 1, 5, 5),)
        call_kwargs = {}
    
>       _test_augmentation_class(
            kornia.augmentation.RandomMotionBlur,
            target_framework,
            init_args,
            init_kwargs,
            call_args,
            call_kwargs,
            deterministic_output=False,
            backend_compile=backend_compile,
        )

kornia/augmentation/test_augmentation2.py:134: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

augmentation_cls = <class 'kornia.augmentation._2d.intensity.motion_blur.RandomMotionBlur'>, target = 'tensorflow', init_args = (3, 35.0, 0.5), init_kwargs = {'p': 1.0}
call_args = (tensor([[[[1., 1., 1., 1., 1.],
          [1., 1., 1., 1., 1.],
          [1., 1., 1., 1., 1.],
          [1., 1., 1., 1., 1.],
          [1., 1., 1., 1., 1.]]]]),), call_kwargs = {}
deterministic_output = False, backend_compile = False, tolerance = 0.001

    def _test_augmentation_class(
        augmentation_cls,
        target,
        init_args=(),
        init_kwargs={},
        call_args=(),
        call_kwargs={},
        deterministic_output=True,
        backend_compile=False,
        tolerance=1e-3,
    ):
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, target=target)
        transpiled_cls = eval("transpiled_" + f"{augmentation_cls.__module__}.{augmentation_cls.__name__}")
    
        torch_aug = augmentation_cls(*init_args, **init_kwargs)
        transpiled_init_args = _nest_torch_tensor_to_new_framework(init_args, target)
        transpiled_init_kwargs = _nest_torch_tensor_to_new_framework(init_kwargs, target)
        transpiled_aug = transpiled_cls(*transpiled_init_args, **transpiled_init_kwargs)
    
        # assert dir(torch_aug) == dir(transpiled_aug), f"attributes/methods of transpiled object do not align with the original - orig: {dir(torch_aug)} != transpiled: {dir(transpiled_aug)}"
    
        torch_out = torch_aug(*call_args, **call_kwargs)
        transpiled_call_args = _nest_torch_tensor_to_new_framework(call_args, target)
        transpiled_call_kwargs = _nest_torch_tensor_to_new_framework(call_kwargs, target)
>       transpiled_out = transpiled_aug(*transpiled_call_args, **transpiled_call_kwargs)

kornia/augmentation/test_augmentation2.py:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomMotionBlur(kernel_size=3, angle=35.0, direction=0.5, p=1.0, p_batch=1.0, same_on_batch=False, border_type=constant, resample=nearest)
args = (<tf.Tensor: shape=(1, 1, 5, 5), dtype=float32, numpy=
array([[[[1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.]]]], dtype=float32)>,)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x7f7d2fd50c40, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...kexec', code_context=['        return self._inner_hookexec(hook_name, methods, kwargs, firstresult)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomMotionBlur(kernel_size=3, angle=35.0, direction=0.5, p=1.0, p_batch=1.0, same_on_batch=False, border..., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.]]]], dtype=float32)>)
kwargs = {}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomMotionBlur(kernel_size=3, angle=35.0, direction=0.5, p=1.0, p_batch=1.0, same_on_batch=False, border_type=constant, resample=nearest), v = None, buffers = None
args = (<tf.Tensor: shape=(1, 1, 5, 5), dtype=float32, numpy=
array([[[[1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.]]]], dtype=float32)>,)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomMotionBlur(kernel_size=3, angle=35.0, direction=0.5, p=1.0, p_batch=1.0, same_on_batch=False, border..., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.]]]], dtype=float32)>)
kwargs = {'buffers': None, 'v': None}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomMotionBlur(kernel_size=3, angle=35.0, direction=0.5, p=1.0, p_batch=1.0, same_on_batch=False, border_type=constant, resample=nearest), v = None, buffers = None
args = (<tf.Tensor: shape=(1, 1, 5, 5), dtype=float32, numpy=
array([[[[1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.]]]], dtype=float32)>,)
kwargs = {}
first_arr = <tf.Tensor: shape=(1, 1, 5, 5), dtype=float32, numpy=
array([[[[1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.]]]], dtype=float32)>
replace_v = False, replace_buffers = False, call_signature = <Signature (input, params=None, **kwargs)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Layer, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Layer, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Layer, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomMotionBlur(kernel_size=3, angle=35.0, direction=0.5, p=1.0, p_batch=1.0, same_on_batch=False, border_type=constant, resample=nearest),)
kwargs = {'input': <tf.Tensor: shape=(1, 1, 5, 5), dtype=float32, numpy=
array([[[[1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.]]]], dtype=float32)>}

    @wraps(fn)
    def error_handler(*args, **kwargs):
        if not is_traceback_filtering_enabled():
            return fn(*args, **kwargs)
    
        filtered_tb = None
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            filtered_tb = _process_traceback_frames(e.__traceback__)
            # To get the full stack trace, call:
            # `keras.config.disable_traceback_filtering()`
>           raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/keras/src/utils/traceback_utils.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomMotionBlur(kernel_size=3, angle=35.0, direction=0.5, p=1.0, p_batch=1.0, same_on_batch=False, border_type=constant, resample=nearest)
input = <tf.Tensor: shape=(1, 1, 5, 5), dtype=float32, numpy=
array([[[[1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.]]]], dtype=float32)>
params = None, kwargs = {}, tensorflow_shape_frnt_ = <function tensorflow_shape_frnt_ at 0x7f7d24995870>, tensorflow_set_item = <function tensorflow_set_item at 0x7f7d24f8a680>
tensor = <function tensorflow_tensor_frnt at 0x7f7d3a46eb00>
in_tensor = <tf.Tensor: shape=(1, 1, 5, 5), dtype=float32, numpy=
array([[[[1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.]]]], dtype=float32)>
input_shape = ivy.frontends.torch.Size([1, 1, 5, 5]), batch_shape = ivy.frontends.torch.Size([1, 1, 5, 5])

    def call(self, input, params=None, **kwargs):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ...ivy.functional.backends.tensorflow.general import tensorflow_set_item
        from ..core._backend import tensor
    
        in_tensor = self.__unpack_input__(input)
        input_shape = tensorflow_shape_frnt_(in_tensor)
        in_tensor = self.transform_tensor(in_tensor)
        batch_shape = tensorflow_shape_frnt_(in_tensor)
        if params is None:
>           params = self.forward_parameters(batch_shape)

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/base.py:228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomMotionBlur(kernel_size=3, angle=35.0, direction=0.5, p=1.0, p_batch=1.0, same_on_batch=False, border_type=constant, resample=nearest)
batch_shape = ivy.frontends.torch.Size([1, 1, 5, 5])

    def forward_parameters(self, batch_shape):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_sum_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_item_frnt_
        from ...ivy.functional.backends.tensorflow.general import tensorflow_set_item
        from ..core._backend import tensor
    
        batch_prob = self.__batch_prob_generator__(
            batch_shape, self.p, self.p_batch, self.same_on_batch
        )
        to_apply = batch_prob > 0.5
>       _params = self.generate_parameters(
            tuple(
                (
                    int(tensorflow_item_frnt_(tensorflow_sum_frnt_(to_apply))),
                    *batch_shape[1:],
                )
            )
        )

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/base.py:200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomMotionBlur(kernel_size=3, angle=35.0, direction=0.5, p=1.0, p_batch=1.0, same_on_batch=False, border_type=constant, resample=nearest), batch_shape = (1, 1, 5, 5)

    def generate_parameters(self, batch_shape):
        from ....core._backend import tensor
        from .....ivy.functional.backends.tensorflow.general import tensorflow_set_item
        from .....ivy.functional.frontends.torch.random_sampling import (
            tensorflow_randint_frnt,
        )
    
        params = super().generate_parameters(batch_shape)
        params = tensorflow_set_item(
            params,
            "idx",
            tensor([0])
            if batch_shape[0] == 0
>           else tensorflow_randint_frnt(batch_shape[0], (1,)),
        )
E       TypeError: Exception encountered when calling tensorflow_RandomMotionBlur.call().
E       
E       [1mtensorflow_randint_frnt() missing 1 required positional argument: 'size'[0m
E       
E       Arguments received by tensorflow_RandomMotionBlur.call():
E         • input=tf.Tensor(shape=(1, 1, 5, 5), dtype=float32)
E         • params=None
E         • kwargs=<class 'inspect._empty'>

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/_2d/intensity/motion_blur.py:73: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.RandomMotionBlur
_________________________________________________________________________ test_RandomSaltAndPepperNoise[tensorflow-s2s-False] __________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_RandomSaltAndPepperNoise(target_framework, mode, backend_compile):
        print("kornia.augmentation.RandomSaltAndPepperNoise")
    
        init_args = ()
        init_kwargs = {"amount": 0.5, "salt_vs_pepper": 0.5, "p": 1.}
        call_args = (torch.rand(1, 3, 3, 3),)
        call_kwargs = {}
    
>       _test_augmentation_class(
            kornia.augmentation.RandomSaltAndPepperNoise,
            target_framework,
            init_args,
            init_kwargs,
            call_args,
            call_kwargs,
            deterministic_output=False,
            backend_compile=backend_compile,
        )

kornia/augmentation/test_augmentation2.py:294: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

augmentation_cls = <class 'kornia.augmentation._2d.intensity.salt_pepper_noise.RandomSaltAndPepperNoise'>, target = 'tensorflow', init_args = ()
init_kwargs = {'amount': 0.5, 'p': 1.0, 'salt_vs_pepper': 0.5}
call_args = (tensor([[[[0.3606, 0.3998, 0.4476],
          [0.2850, 0.7014, 0.3229],
          [0.7224, 0.6926, 0.9202]],

       ...37]],

         [[0.4555, 0.0914, 0.6407],
          [0.9712, 0.1913, 0.9859],
          [0.1344, 0.3031, 0.3516]]]]),)
call_kwargs = {}, deterministic_output = False, backend_compile = False, tolerance = 0.001

    def _test_augmentation_class(
        augmentation_cls,
        target,
        init_args=(),
        init_kwargs={},
        call_args=(),
        call_kwargs={},
        deterministic_output=True,
        backend_compile=False,
        tolerance=1e-3,
    ):
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, target=target)
        transpiled_cls = eval("transpiled_" + f"{augmentation_cls.__module__}.{augmentation_cls.__name__}")
    
        torch_aug = augmentation_cls(*init_args, **init_kwargs)
        transpiled_init_args = _nest_torch_tensor_to_new_framework(init_args, target)
        transpiled_init_kwargs = _nest_torch_tensor_to_new_framework(init_kwargs, target)
        transpiled_aug = transpiled_cls(*transpiled_init_args, **transpiled_init_kwargs)
    
        # assert dir(torch_aug) == dir(transpiled_aug), f"attributes/methods of transpiled object do not align with the original - orig: {dir(torch_aug)} != transpiled: {dir(transpiled_aug)}"
    
        torch_out = torch_aug(*call_args, **call_kwargs)
        transpiled_call_args = _nest_torch_tensor_to_new_framework(call_args, target)
        transpiled_call_kwargs = _nest_torch_tensor_to_new_framework(call_kwargs, target)
>       transpiled_out = transpiled_aug(*transpiled_call_args, **transpiled_call_kwargs)

kornia/augmentation/test_augmentation2.py:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomSaltAndPepperNoise(amount=(0.5, 0.5), salt_and_pepper=(0.5, 0.5), p=1.0, p_batch=1.0, same_on_batch=False)
args = (<tf.Tensor: shape=(1, 3, 3, 3), dtype=float32, numpy=
array([[[[0.3606429 , 0.39978802, 0.44758683],
         [0.2850...2 ],
         [0.9711976 , 0.1913349 , 0.98594505],
         [0.13441569, 0.30307662, 0.35164738]]]], dtype=float32)>,)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x7f7d2efab240, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...kexec', code_context=['        return self._inner_hookexec(hook_name, methods, kwargs, firstresult)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomSaltAndPepperNoise(amount=(0.5, 0.5), salt_and_pepper=(0.5, 0.5), p=1.0, p_batch=1.0, same_on_batch=...52 ],
         [0.9711976 , 0.1913349 , 0.98594505],
         [0.13441569, 0.30307662, 0.35164738]]]], dtype=float32)>)
kwargs = {}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomSaltAndPepperNoise(amount=(0.5, 0.5), salt_and_pepper=(0.5, 0.5), p=1.0, p_batch=1.0, same_on_batch=False), v = None, buffers = None
args = (<tf.Tensor: shape=(1, 3, 3, 3), dtype=float32, numpy=
array([[[[0.3606429 , 0.39978802, 0.44758683],
         [0.2850...2 ],
         [0.9711976 , 0.1913349 , 0.98594505],
         [0.13441569, 0.30307662, 0.35164738]]]], dtype=float32)>,)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomSaltAndPepperNoise(amount=(0.5, 0.5), salt_and_pepper=(0.5, 0.5), p=1.0, p_batch=1.0, same_on_batch=...52 ],
         [0.9711976 , 0.1913349 , 0.98594505],
         [0.13441569, 0.30307662, 0.35164738]]]], dtype=float32)>)
kwargs = {'buffers': None, 'v': None}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomSaltAndPepperNoise(amount=(0.5, 0.5), salt_and_pepper=(0.5, 0.5), p=1.0, p_batch=1.0, same_on_batch=False), v = None, buffers = None
args = (<tf.Tensor: shape=(1, 3, 3, 3), dtype=float32, numpy=
array([[[[0.3606429 , 0.39978802, 0.44758683],
         [0.2850...2 ],
         [0.9711976 , 0.1913349 , 0.98594505],
         [0.13441569, 0.30307662, 0.35164738]]]], dtype=float32)>,)
kwargs = {}
first_arr = <tf.Tensor: shape=(1, 3, 3, 3), dtype=float32, numpy=
array([[[[0.3606429 , 0.39978802, 0.44758683],
         [0.28504...752 ],
         [0.9711976 , 0.1913349 , 0.98594505],
         [0.13441569, 0.30307662, 0.35164738]]]], dtype=float32)>
replace_v = False, replace_buffers = False, call_signature = <Signature (input, params=None, **kwargs)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Layer, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Layer, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Layer, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomSaltAndPepperNoise(amount=(0.5, 0.5), salt_and_pepper=(0.5, 0.5), p=1.0, p_batch=1.0, same_on_batch=False),)
kwargs = {'input': <tf.Tensor: shape=(1, 3, 3, 3), dtype=float32, numpy=
array([[[[0.3606429 , 0.39978802, 0.44758683],
       ...52 ],
         [0.9711976 , 0.1913349 , 0.98594505],
         [0.13441569, 0.30307662, 0.35164738]]]], dtype=float32)>}

    @wraps(fn)
    def error_handler(*args, **kwargs):
        if not is_traceback_filtering_enabled():
            return fn(*args, **kwargs)
    
        filtered_tb = None
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            filtered_tb = _process_traceback_frames(e.__traceback__)
            # To get the full stack trace, call:
            # `keras.config.disable_traceback_filtering()`
>           raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/keras/src/utils/traceback_utils.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomSaltAndPepperNoise(amount=(0.5, 0.5), salt_and_pepper=(0.5, 0.5), p=1.0, p_batch=1.0, same_on_batch=False)
input = <tf.Tensor: shape=(1, 3, 3, 3), dtype=float32, numpy=
array([[[[0.3606429 , 0.39978802, 0.44758683],
         [0.28504...752 ],
         [0.9711976 , 0.1913349 , 0.98594505],
         [0.13441569, 0.30307662, 0.35164738]]]], dtype=float32)>
params = {'amount_factor': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.5], dtype=float32)>, 'batch_prob': <tf.Tensor:...ue, False]],

        [[False,  True, False],
         [ True, False, False],
         [False,  True, False]]]])>, ...}
kwargs = {}, tensorflow_shape_frnt_ = <function tensorflow_shape_frnt_ at 0x7f7d14fb9b40>, tensorflow_set_item = <function tensorflow_set_item at 0x7f7d24dc0940>
tensor = <function tensorflow_tensor_frnt at 0x7f7d14f20d30>
in_tensor = <tf.Tensor: shape=(1, 3, 3, 3), dtype=float32, numpy=
array([[[[0.3606429 , 0.39978802, 0.44758683],
         [0.28504...752 ],
         [0.9711976 , 0.1913349 , 0.98594505],
         [0.13441569, 0.30307662, 0.35164738]]]], dtype=float32)>
input_shape = ivy.frontends.torch.Size([1, 3, 3, 3]), batch_shape = ivy.frontends.torch.Size([1, 3, 3, 3]), flags = {}

    def call(self, input, params=None, **kwargs):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ...ivy.functional.backends.tensorflow.general import tensorflow_set_item
        from ..core._backend import tensor
    
        in_tensor = self.__unpack_input__(input)
        input_shape = tensorflow_shape_frnt_(in_tensor)
        in_tensor = self.transform_tensor(in_tensor)
        batch_shape = tensorflow_shape_frnt_(in_tensor)
        if params is None:
            params = self.forward_parameters(batch_shape)
        if "batch_prob" not in params:
            params = tensorflow_set_item(
                params, "batch_prob", tensor([True] * batch_shape[0])
            )
        params, flags = self._process_kwargs_to_params_and_flags(
            params, self.flags, **kwargs
        )
>       output = self.apply_func(in_tensor, params, flags)

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/base.py:236: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomSaltAndPepperNoise(amount=(0.5, 0.5), salt_and_pepper=(0.5, 0.5), p=1.0, p_batch=1.0, same_on_batch=False)
in_tensor = <tf.Tensor: shape=(1, 3, 3, 3), dtype=float32, numpy=
array([[[[0.3606429 , 0.39978802, 0.44758683],
         [0.28504...752 ],
         [0.9711976 , 0.1913349 , 0.98594505],
         [0.13441569, 0.30307662, 0.35164738]]]], dtype=float32)>
params = {'amount_factor': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.5], dtype=float32)>, 'batch_prob': <tf.Tensor:...ue, False]],

        [[False,  True, False],
         [ True, False, False],
         [False,  True, False]]]])>, ...}
flags = {}

    def apply_func(self, in_tensor, params, flags=None):
        if flags is None:
            flags = self.flags
        trans_matrix = self.generate_transformation_matrix(in_tensor, params, flags)
>       output = self.transform_inputs(in_tensor, params, flags, trans_matrix)

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/_2d/base.py:127: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomSaltAndPepperNoise(amount=(0.5, 0.5), salt_and_pepper=(0.5, 0.5), p=1.0, p_batch=1.0, same_on_batch=False)
input = <tf.Tensor: shape=(1, 3, 3, 3), dtype=float32, numpy=
array([[[[0.3606429 , 0.39978802, 0.44758683],
         [0.28504...752 ],
         [0.9711976 , 0.1913349 , 0.98594505],
         [0.13441569, 0.30307662, 0.35164738]]]], dtype=float32)>
params = {'amount_factor': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.5], dtype=float32)>, 'batch_prob': <tf.Tensor:...ue, False]],

        [[False,  True, False],
         [ True, False, False],
         [False,  True, False]]]])>, ...}
flags = {}, transform = <tf.Tensor: shape=(1, 3, 3), dtype=float32, numpy=
array([[[1., 0., 0.],
        [0., 1., 0.],
        [0., 0., 1.]]], dtype=float32)>, kwargs = {}
tensorflow_shape_frnt_ = <function tensorflow_shape_frnt_ at 0x7f7d14fb9b40>, tensorflow_all_frnt_ = <function tensorflow_all_frnt_ at 0x7f7d14fb8790>
tensorflow_any_frnt_ = <function tensorflow_any_frnt_ at 0x7f7d39fa95a0>, tensorflow_get_item = <function tensorflow_get_item at 0x7f7d24dc0790>
tensorflow_is_autocast_enabled = <function tensorflow_is_autocast_enabled at 0x7f7d24d06170>, tensorflow_type_frnt_ = <function tensorflow_type_frnt_ at 0x7f7d14fa7520>
tensorflow_index_put_frnt_ = <function tensorflow_index_put_frnt_ at 0x7f7d14fa7910>

    def transform_inputs(self, input, params, flags, transform=None, **kwargs):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_all_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_any_frnt_
        from ...ivy.functional.backends.tensorflow.general import tensorflow_get_item
        from ..utils.helpers import tensorflow_is_autocast_enabled
        from ...ivy.functional.frontends.torch.tensor import tensorflow_type_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_index_put_frnt_
        from .utils.helpers import tensorflow__transform_output_shape
    
        params, flags = self._process_kwargs_to_params_and_flags(
            self._params if params is None else params, flags, **kwargs
        )
        batch_prob = params["batch_prob"]
        to_apply = batch_prob > 0.5
        ori_shape = tensorflow_shape_frnt_(input)
        in_tensor = self.transform_tensor(input)
        self.validate_tensor(in_tensor)
        if tensorflow_all_frnt_(to_apply):
>           output = self.apply_transform(in_tensor, params, flags, transform=transform)

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/base.py:354: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomSaltAndPepperNoise(amount=(0.5, 0.5), salt_and_pepper=(0.5, 0.5), p=1.0, p_batch=1.0, same_on_batch=False)
input = <tf.Tensor: shape=(1, 3, 3, 3), dtype=float32, numpy=
array([[[[0.3606429 , 0.39978802, 0.44758683],
         [0.28504...752 ],
         [0.9711976 , 0.1913349 , 0.98594505],
         [0.13441569, 0.30307662, 0.35164738]]]], dtype=float32)>
params = {'amount_factor': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.5], dtype=float32)>, 'batch_prob': <tf.Tensor:...ue, False]],

        [[False,  True, False],
         [ True, False, False],
         [False,  True, False]]]])>, ...}
flags = {}, transform = <tf.Tensor: shape=(1, 3, 3), dtype=float32, numpy=
array([[[1., 0., 0.],
        [0., 1., 0.],
        [0., 0., 1.]]], dtype=float32)>

    def apply_transform(self, input, params, flags, transform=None):
        from ....core.check import tensorflow_KORNIA_CHECK
        from .....ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from .....ivy.functional.frontends.torch.tensor import tensorflow_clone_frnt_
        from .....ivy.functional.backends.tensorflow.general import tensorflow_set_item
    
        tensorflow_KORNIA_CHECK(
            len(tensorflow_shape_frnt_(input)) in (3, 4), "Wrong input dimension."
        )
        if len(tensorflow_shape_frnt_(input)) == 3:
            input = input[None, :, :, :]
        tensorflow_KORNIA_CHECK(
            tensorflow_shape_frnt_(input)[1] in {3, 1},
            "Number of color channels should be 1 or 3.",
        )
        noisy_image = tensorflow_clone_frnt_(input)
        noisy_image = tensorflow_set_item(
>           noisy_image, params["mask_salt"].to(input.device), 1.0
        )
E       AttributeError: Exception encountered when calling tensorflow_RandomSaltAndPepperNoise.call().
E       
E       [1m'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'to'[0m
E       
E       Arguments received by tensorflow_RandomSaltAndPepperNoise.call():
E         • input=tf.Tensor(shape=(1, 3, 3, 3), dtype=float32)
E         • params=None
E         • kwargs=<class 'inspect._empty'>

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/_2d/intensity/salt_pepper_noise.py:99: AttributeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.RandomSaltAndPepperNoise
______________________________________________________________________________ test_RandomSharpness[tensorflow-s2s-False] ______________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_RandomSharpness(target_framework, mode, backend_compile):
        print("kornia.augmentation.RandomSharpness")
    
        init_args = (1.,)
        init_kwargs = {"p": 1.}
        call_args = (torch.rand(1, 1, 5, 5),)
        call_kwargs = {}
    
>       _test_augmentation_class(
            kornia.augmentation.RandomSharpness,
            target_framework,
            init_args,
            init_kwargs,
            call_args,
            call_kwargs,
            deterministic_output=False,
            backend_compile=backend_compile,
        )

kornia/augmentation/test_augmentation2.py:334: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

augmentation_cls = <class 'kornia.augmentation._2d.intensity.sharpness.RandomSharpness'>, target = 'tensorflow', init_args = (1.0,), init_kwargs = {'p': 1.0}
call_args = (tensor([[[[0.5650, 0.3407, 0.0877, 0.0903, 0.3503],
          [0.0414, 0.0842, 0.5882, 0.9088, 0.7370],
          [0...., 0.7267],
          [0.4085, 0.8800, 0.9281, 0.9811, 0.3096],
          [0.3476, 0.1272, 0.5579, 0.5636, 0.9429]]]]),)
call_kwargs = {}, deterministic_output = False, backend_compile = False, tolerance = 0.001

    def _test_augmentation_class(
        augmentation_cls,
        target,
        init_args=(),
        init_kwargs={},
        call_args=(),
        call_kwargs={},
        deterministic_output=True,
        backend_compile=False,
        tolerance=1e-3,
    ):
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, target=target)
        transpiled_cls = eval("transpiled_" + f"{augmentation_cls.__module__}.{augmentation_cls.__name__}")
    
        torch_aug = augmentation_cls(*init_args, **init_kwargs)
        transpiled_init_args = _nest_torch_tensor_to_new_framework(init_args, target)
        transpiled_init_kwargs = _nest_torch_tensor_to_new_framework(init_kwargs, target)
        transpiled_aug = transpiled_cls(*transpiled_init_args, **transpiled_init_kwargs)
    
        # assert dir(torch_aug) == dir(transpiled_aug), f"attributes/methods of transpiled object do not align with the original - orig: {dir(torch_aug)} != transpiled: {dir(transpiled_aug)}"
    
        torch_out = torch_aug(*call_args, **call_kwargs)
        transpiled_call_args = _nest_torch_tensor_to_new_framework(call_args, target)
        transpiled_call_kwargs = _nest_torch_tensor_to_new_framework(call_kwargs, target)
>       transpiled_out = transpiled_aug(*transpiled_call_args, **transpiled_call_kwargs)

kornia/augmentation/test_augmentation2.py:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomSharpness(sharpness=1.0, p=1.0, p_batch=1.0, same_on_batch=False)
args = (<tf.Tensor: shape=(1, 1, 5, 5), dtype=float32, numpy=
array([[[[0.56502753, 0.34068644, 0.08765864, 0.09032553, 0.350...810502 , 0.30962855],
         [0.3476361 , 0.12720138, 0.55785877, 0.5635841 , 0.94286865]]]],
      dtype=float32)>,)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x7f7d34ce1040, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...kexec', code_context=['        return self._inner_hookexec(hook_name, methods, kwargs, firstresult)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomSharpness(sharpness=1.0, p=1.0, p_batch=1.0, same_on_batch=False), <tf.Tensor: shape=(1, 1, 5, 5), d...9810502 , 0.30962855],
         [0.3476361 , 0.12720138, 0.55785877, 0.5635841 , 0.94286865]]]],
      dtype=float32)>)
kwargs = {}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomSharpness(sharpness=1.0, p=1.0, p_batch=1.0, same_on_batch=False), v = None, buffers = None
args = (<tf.Tensor: shape=(1, 1, 5, 5), dtype=float32, numpy=
array([[[[0.56502753, 0.34068644, 0.08765864, 0.09032553, 0.350...810502 , 0.30962855],
         [0.3476361 , 0.12720138, 0.55785877, 0.5635841 , 0.94286865]]]],
      dtype=float32)>,)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomSharpness(sharpness=1.0, p=1.0, p_batch=1.0, same_on_batch=False), <tf.Tensor: shape=(1, 1, 5, 5), d...9810502 , 0.30962855],
         [0.3476361 , 0.12720138, 0.55785877, 0.5635841 , 0.94286865]]]],
      dtype=float32)>)
kwargs = {'buffers': None, 'v': None}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomSharpness(sharpness=1.0, p=1.0, p_batch=1.0, same_on_batch=False), v = None, buffers = None
args = (<tf.Tensor: shape=(1, 1, 5, 5), dtype=float32, numpy=
array([[[[0.56502753, 0.34068644, 0.08765864, 0.09032553, 0.350...810502 , 0.30962855],
         [0.3476361 , 0.12720138, 0.55785877, 0.5635841 , 0.94286865]]]],
      dtype=float32)>,)
kwargs = {}
first_arr = <tf.Tensor: shape=(1, 1, 5, 5), dtype=float32, numpy=
array([[[[0.56502753, 0.34068644, 0.08765864, 0.09032553, 0.3502....9810502 , 0.30962855],
         [0.3476361 , 0.12720138, 0.55785877, 0.5635841 , 0.94286865]]]],
      dtype=float32)>
replace_v = False, replace_buffers = False, call_signature = <Signature (input, params=None, **kwargs)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Layer, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Layer, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Layer, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomSharpness(sharpness=1.0, p=1.0, p_batch=1.0, same_on_batch=False),)
kwargs = {'input': <tf.Tensor: shape=(1, 1, 5, 5), dtype=float32, numpy=
array([[[[0.56502753, 0.34068644, 0.08765864, 0.090325...9810502 , 0.30962855],
         [0.3476361 , 0.12720138, 0.55785877, 0.5635841 , 0.94286865]]]],
      dtype=float32)>}

    @wraps(fn)
    def error_handler(*args, **kwargs):
        if not is_traceback_filtering_enabled():
            return fn(*args, **kwargs)
    
        filtered_tb = None
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            filtered_tb = _process_traceback_frames(e.__traceback__)
            # To get the full stack trace, call:
            # `keras.config.disable_traceback_filtering()`
>           raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/keras/src/utils/traceback_utils.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomSharpness(sharpness=1.0, p=1.0, p_batch=1.0, same_on_batch=False)
input = <tf.Tensor: shape=(1, 1, 5, 5), dtype=float32, numpy=
array([[[[0.56502753, 0.34068644, 0.08765864, 0.09032553, 0.3502....9810502 , 0.30962855],
         [0.3476361 , 0.12720138, 0.55785877, 0.5635841 , 0.94286865]]]],
      dtype=float32)>
params = {'batch_prob': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>, 'forward_input_shape': <tf.Te...mpy=array([1, 1, 5, 5])>, 'sharpness': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.6295351], dtype=float32)>}
kwargs = {}, tensorflow_shape_frnt_ = <function tensorflow_shape_frnt_ at 0x7f7d14c80e50>, tensorflow_set_item = <function tensorflow_set_item at 0x7f7d24197e20>
tensor = <function tensorflow_tensor_frnt at 0x7f7d14aa4ee0>
in_tensor = <tf.Tensor: shape=(1, 1, 5, 5), dtype=float32, numpy=
array([[[[0.56502753, 0.34068644, 0.08765864, 0.09032553, 0.3502....9810502 , 0.30962855],
         [0.3476361 , 0.12720138, 0.55785877, 0.5635841 , 0.94286865]]]],
      dtype=float32)>
input_shape = ivy.frontends.torch.Size([1, 1, 5, 5]), batch_shape = ivy.frontends.torch.Size([1, 1, 5, 5]), flags = {}

    def call(self, input, params=None, **kwargs):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ...ivy.functional.backends.tensorflow.general import tensorflow_set_item
        from ..core._backend import tensor
    
        in_tensor = self.__unpack_input__(input)
        input_shape = tensorflow_shape_frnt_(in_tensor)
        in_tensor = self.transform_tensor(in_tensor)
        batch_shape = tensorflow_shape_frnt_(in_tensor)
        if params is None:
            params = self.forward_parameters(batch_shape)
        if "batch_prob" not in params:
            params = tensorflow_set_item(
                params, "batch_prob", tensor([True] * batch_shape[0])
            )
        params, flags = self._process_kwargs_to_params_and_flags(
            params, self.flags, **kwargs
        )
>       output = self.apply_func(in_tensor, params, flags)

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/base.py:236: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomSharpness(sharpness=1.0, p=1.0, p_batch=1.0, same_on_batch=False)
in_tensor = <tf.Tensor: shape=(1, 1, 5, 5), dtype=float32, numpy=
array([[[[0.56502753, 0.34068644, 0.08765864, 0.09032553, 0.3502....9810502 , 0.30962855],
         [0.3476361 , 0.12720138, 0.55785877, 0.5635841 , 0.94286865]]]],
      dtype=float32)>
params = {'batch_prob': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>, 'forward_input_shape': <tf.Te...mpy=array([1, 1, 5, 5])>, 'sharpness': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.6295351], dtype=float32)>}
flags = {}

    def apply_func(self, in_tensor, params, flags=None):
        if flags is None:
            flags = self.flags
        trans_matrix = self.generate_transformation_matrix(in_tensor, params, flags)
>       output = self.transform_inputs(in_tensor, params, flags, trans_matrix)

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/_2d/base.py:127: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomSharpness(sharpness=1.0, p=1.0, p_batch=1.0, same_on_batch=False)
input = <tf.Tensor: shape=(1, 1, 5, 5), dtype=float32, numpy=
array([[[[0.56502753, 0.34068644, 0.08765864, 0.09032553, 0.3502....9810502 , 0.30962855],
         [0.3476361 , 0.12720138, 0.55785877, 0.5635841 , 0.94286865]]]],
      dtype=float32)>
params = {'batch_prob': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>, 'forward_input_shape': <tf.Te...mpy=array([1, 1, 5, 5])>, 'sharpness': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.6295351], dtype=float32)>}
flags = {}, transform = <tf.Tensor: shape=(1, 3, 3), dtype=float32, numpy=
array([[[1., 0., 0.],
        [0., 1., 0.],
        [0., 0., 1.]]], dtype=float32)>, kwargs = {}
tensorflow_shape_frnt_ = <function tensorflow_shape_frnt_ at 0x7f7d14c80e50>, tensorflow_all_frnt_ = <function tensorflow_all_frnt_ at 0x7f7d14c80670>
tensorflow_any_frnt_ = <function tensorflow_any_frnt_ at 0x7f7d14c825f0>, tensorflow_get_item = <function tensorflow_get_item at 0x7f7d24197c70>
tensorflow_is_autocast_enabled = <function tensorflow_is_autocast_enabled at 0x7f7d241913f0>, tensorflow_type_frnt_ = <function tensorflow_type_frnt_ at 0x7f7d3a0c7010>
tensorflow_index_put_frnt_ = <function tensorflow_index_put_frnt_ at 0x7f7d14d59e10>

    def transform_inputs(self, input, params, flags, transform=None, **kwargs):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_all_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_any_frnt_
        from ...ivy.functional.backends.tensorflow.general import tensorflow_get_item
        from ..utils.helpers import tensorflow_is_autocast_enabled
        from ...ivy.functional.frontends.torch.tensor import tensorflow_type_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_index_put_frnt_
        from .utils.helpers import tensorflow__transform_output_shape
    
        params, flags = self._process_kwargs_to_params_and_flags(
            self._params if params is None else params, flags, **kwargs
        )
        batch_prob = params["batch_prob"]
        to_apply = batch_prob > 0.5
        ori_shape = tensorflow_shape_frnt_(input)
        in_tensor = self.transform_tensor(input)
        self.validate_tensor(in_tensor)
        if tensorflow_all_frnt_(to_apply):
>           output = self.apply_transform(in_tensor, params, flags, transform=transform)

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/base.py:354: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomSharpness(sharpness=1.0, p=1.0, p_batch=1.0, same_on_batch=False)
input = <tf.Tensor: shape=(1, 1, 5, 5), dtype=float32, numpy=
array([[[[0.56502753, 0.34068644, 0.08765864, 0.09032553, 0.3502....9810502 , 0.30962855],
         [0.3476361 , 0.12720138, 0.55785877, 0.5635841 , 0.94286865]]]],
      dtype=float32)>
params = {'batch_prob': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>, 'forward_input_shape': <tf.Te...mpy=array([1, 1, 5, 5])>, 'sharpness': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.6295351], dtype=float32)>}
flags = {}, transform = <tf.Tensor: shape=(1, 3, 3), dtype=float32, numpy=
array([[[1., 0., 0.],
        [0., 1., 0.],
        [0., 0., 1.]]], dtype=float32)>

    def apply_transform(self, input, params, flags, transform=None):
        factor = params["sharpness"]
>       return sharpness(input, factor)
E       NameError: Exception encountered when calling tensorflow_RandomSharpness.call().
E       
E       [1mname 'sharpness' is not defined[0m
E       
E       Arguments received by tensorflow_RandomSharpness.call():
E         • input=tf.Tensor(shape=(1, 1, 5, 5), dtype=float32)
E         • params=None
E         • kwargs=<class 'inspect._empty'>

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/_2d/intensity/sharpness.py:46: NameError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.RandomSharpness
______________________________________________________________________________ test_RandomSolarize[tensorflow-s2s-False] _______________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_RandomSolarize(target_framework, mode, backend_compile):
        print("kornia.augmentation.RandomSolarize")
    
        init_args = (0.1, 0.1)
        init_kwargs = {"p": 1.}
        call_args = (torch.rand(1, 1, 5, 5),)
        call_kwargs = {}
    
>       _test_augmentation_class(
            kornia.augmentation.RandomSolarize,
            target_framework,
            init_args,
            init_kwargs,
            call_args,
            call_kwargs,
            deterministic_output=False,
            backend_compile=backend_compile,
        )

kornia/augmentation/test_augmentation2.py:374: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

augmentation_cls = <class 'kornia.augmentation._2d.intensity.solarize.RandomSolarize'>, target = 'tensorflow', init_args = (0.1, 0.1), init_kwargs = {'p': 1.0}
call_args = (tensor([[[[0.5867, 0.5994, 0.5272, 0.3294, 0.2930],
          [0.3883, 0.5416, 0.7702, 0.6107, 0.9371],
          [0...., 0.0278],
          [0.3855, 0.3101, 0.8191, 0.6598, 0.8092],
          [0.4958, 0.1090, 0.9172, 0.6653, 0.5336]]]]),)
call_kwargs = {}, deterministic_output = False, backend_compile = False, tolerance = 0.001

    def _test_augmentation_class(
        augmentation_cls,
        target,
        init_args=(),
        init_kwargs={},
        call_args=(),
        call_kwargs={},
        deterministic_output=True,
        backend_compile=False,
        tolerance=1e-3,
    ):
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, target=target)
        transpiled_cls = eval("transpiled_" + f"{augmentation_cls.__module__}.{augmentation_cls.__name__}")
    
        torch_aug = augmentation_cls(*init_args, **init_kwargs)
        transpiled_init_args = _nest_torch_tensor_to_new_framework(init_args, target)
        transpiled_init_kwargs = _nest_torch_tensor_to_new_framework(init_kwargs, target)
        transpiled_aug = transpiled_cls(*transpiled_init_args, **transpiled_init_kwargs)
    
        # assert dir(torch_aug) == dir(transpiled_aug), f"attributes/methods of transpiled object do not align with the original - orig: {dir(torch_aug)} != transpiled: {dir(transpiled_aug)}"
    
        torch_out = torch_aug(*call_args, **call_kwargs)
        transpiled_call_args = _nest_torch_tensor_to_new_framework(call_args, target)
        transpiled_call_kwargs = _nest_torch_tensor_to_new_framework(call_kwargs, target)
>       transpiled_out = transpiled_aug(*transpiled_call_args, **transpiled_call_kwargs)

kornia/augmentation/test_augmentation2.py:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomSolarize(thresholds=0.1, additions=0.1, p=1.0, p_batch=1.0, same_on_batch=False)
args = (<tf.Tensor: shape=(1, 1, 5, 5), dtype=float32, numpy=
array([[[[0.58669436, 0.59938526, 0.5272368 , 0.3293541 , 0.292...5983105, 0.80919105],
         [0.49576014, 0.10896289, 0.9171534 , 0.66534084, 0.53361744]]]],
      dtype=float32)>,)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x7f7d2e390040, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...kexec', code_context=['        return self._inner_hookexec(hook_name, methods, kwargs, firstresult)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomSolarize(thresholds=0.1, additions=0.1, p=1.0, p_batch=1.0, same_on_batch=False), <tf.Tensor: shape=...65983105, 0.80919105],
         [0.49576014, 0.10896289, 0.9171534 , 0.66534084, 0.53361744]]]],
      dtype=float32)>)
kwargs = {}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomSolarize(thresholds=0.1, additions=0.1, p=1.0, p_batch=1.0, same_on_batch=False), v = None, buffers = None
args = (<tf.Tensor: shape=(1, 1, 5, 5), dtype=float32, numpy=
array([[[[0.58669436, 0.59938526, 0.5272368 , 0.3293541 , 0.292...5983105, 0.80919105],
         [0.49576014, 0.10896289, 0.9171534 , 0.66534084, 0.53361744]]]],
      dtype=float32)>,)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomSolarize(thresholds=0.1, additions=0.1, p=1.0, p_batch=1.0, same_on_batch=False), <tf.Tensor: shape=...65983105, 0.80919105],
         [0.49576014, 0.10896289, 0.9171534 , 0.66534084, 0.53361744]]]],
      dtype=float32)>)
kwargs = {'buffers': None, 'v': None}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomSolarize(thresholds=0.1, additions=0.1, p=1.0, p_batch=1.0, same_on_batch=False), v = None, buffers = None
args = (<tf.Tensor: shape=(1, 1, 5, 5), dtype=float32, numpy=
array([[[[0.58669436, 0.59938526, 0.5272368 , 0.3293541 , 0.292...5983105, 0.80919105],
         [0.49576014, 0.10896289, 0.9171534 , 0.66534084, 0.53361744]]]],
      dtype=float32)>,)
kwargs = {}
first_arr = <tf.Tensor: shape=(1, 1, 5, 5), dtype=float32, numpy=
array([[[[0.58669436, 0.59938526, 0.5272368 , 0.3293541 , 0.2929....65983105, 0.80919105],
         [0.49576014, 0.10896289, 0.9171534 , 0.66534084, 0.53361744]]]],
      dtype=float32)>
replace_v = False, replace_buffers = False, call_signature = <Signature (input, params=None, **kwargs)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Layer, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Layer, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Layer, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomSolarize(thresholds=0.1, additions=0.1, p=1.0, p_batch=1.0, same_on_batch=False),)
kwargs = {'input': <tf.Tensor: shape=(1, 1, 5, 5), dtype=float32, numpy=
array([[[[0.58669436, 0.59938526, 0.5272368 , 0.329354...65983105, 0.80919105],
         [0.49576014, 0.10896289, 0.9171534 , 0.66534084, 0.53361744]]]],
      dtype=float32)>}

    @wraps(fn)
    def error_handler(*args, **kwargs):
        if not is_traceback_filtering_enabled():
            return fn(*args, **kwargs)
    
        filtered_tb = None
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            filtered_tb = _process_traceback_frames(e.__traceback__)
            # To get the full stack trace, call:
            # `keras.config.disable_traceback_filtering()`
>           raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/keras/src/utils/traceback_utils.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomSolarize(thresholds=0.1, additions=0.1, p=1.0, p_batch=1.0, same_on_batch=False)
input = <tf.Tensor: shape=(1, 1, 5, 5), dtype=float32, numpy=
array([[[[0.58669436, 0.59938526, 0.5272368 , 0.3293541 , 0.2929....65983105, 0.80919105],
         [0.49576014, 0.10896289, 0.9171534 , 0.66534084, 0.53361744]]]],
      dtype=float32)>
params = {'additions': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([-0.08288383], dtype=float32)>, 'batch_prob': <tf.Ten...py=array([1, 1, 5, 5])>, 'thresholds': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.5606487], dtype=float32)>}
kwargs = {}, tensorflow_shape_frnt_ = <function tensorflow_shape_frnt_ at 0x7f7d148e7ac0>, tensorflow_set_item = <function tensorflow_set_item at 0x7f7d24ed4550>
tensor = <function tensorflow_tensor_frnt at 0x7f7d24e29e10>
in_tensor = <tf.Tensor: shape=(1, 1, 5, 5), dtype=float32, numpy=
array([[[[0.58669436, 0.59938526, 0.5272368 , 0.3293541 , 0.2929....65983105, 0.80919105],
         [0.49576014, 0.10896289, 0.9171534 , 0.66534084, 0.53361744]]]],
      dtype=float32)>
input_shape = ivy.frontends.torch.Size([1, 1, 5, 5]), batch_shape = ivy.frontends.torch.Size([1, 1, 5, 5]), flags = {}

    def call(self, input, params=None, **kwargs):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ...ivy.functional.backends.tensorflow.general import tensorflow_set_item
        from ..core._backend import tensor
    
        in_tensor = self.__unpack_input__(input)
        input_shape = tensorflow_shape_frnt_(in_tensor)
        in_tensor = self.transform_tensor(in_tensor)
        batch_shape = tensorflow_shape_frnt_(in_tensor)
        if params is None:
            params = self.forward_parameters(batch_shape)
        if "batch_prob" not in params:
            params = tensorflow_set_item(
                params, "batch_prob", tensor([True] * batch_shape[0])
            )
        params, flags = self._process_kwargs_to_params_and_flags(
            params, self.flags, **kwargs
        )
>       output = self.apply_func(in_tensor, params, flags)

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/base.py:236: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomSolarize(thresholds=0.1, additions=0.1, p=1.0, p_batch=1.0, same_on_batch=False)
in_tensor = <tf.Tensor: shape=(1, 1, 5, 5), dtype=float32, numpy=
array([[[[0.58669436, 0.59938526, 0.5272368 , 0.3293541 , 0.2929....65983105, 0.80919105],
         [0.49576014, 0.10896289, 0.9171534 , 0.66534084, 0.53361744]]]],
      dtype=float32)>
params = {'additions': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([-0.08288383], dtype=float32)>, 'batch_prob': <tf.Ten...py=array([1, 1, 5, 5])>, 'thresholds': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.5606487], dtype=float32)>}
flags = {}

    def apply_func(self, in_tensor, params, flags=None):
        if flags is None:
            flags = self.flags
        trans_matrix = self.generate_transformation_matrix(in_tensor, params, flags)
>       output = self.transform_inputs(in_tensor, params, flags, trans_matrix)

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/_2d/base.py:127: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomSolarize(thresholds=0.1, additions=0.1, p=1.0, p_batch=1.0, same_on_batch=False)
input = <tf.Tensor: shape=(1, 1, 5, 5), dtype=float32, numpy=
array([[[[0.58669436, 0.59938526, 0.5272368 , 0.3293541 , 0.2929....65983105, 0.80919105],
         [0.49576014, 0.10896289, 0.9171534 , 0.66534084, 0.53361744]]]],
      dtype=float32)>
params = {'additions': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([-0.08288383], dtype=float32)>, 'batch_prob': <tf.Ten...py=array([1, 1, 5, 5])>, 'thresholds': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.5606487], dtype=float32)>}
flags = {}, transform = <tf.Tensor: shape=(1, 3, 3), dtype=float32, numpy=
array([[[1., 0., 0.],
        [0., 1., 0.],
        [0., 0., 1.]]], dtype=float32)>, kwargs = {}
tensorflow_shape_frnt_ = <function tensorflow_shape_frnt_ at 0x7f7d148e7ac0>, tensorflow_all_frnt_ = <function tensorflow_all_frnt_ at 0x7f7d148e64d0>
tensorflow_any_frnt_ = <function tensorflow_any_frnt_ at 0x7f7d148e48b0>, tensorflow_get_item = <function tensorflow_get_item at 0x7f7d24ed43a0>
tensorflow_is_autocast_enabled = <function tensorflow_is_autocast_enabled at 0x7f7d3a191e10>, tensorflow_type_frnt_ = <function tensorflow_type_frnt_ at 0x7f7d148e4700>
tensorflow_index_put_frnt_ = <function tensorflow_index_put_frnt_ at 0x7f7d148e4550>

    def transform_inputs(self, input, params, flags, transform=None, **kwargs):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_all_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_any_frnt_
        from ...ivy.functional.backends.tensorflow.general import tensorflow_get_item
        from ..utils.helpers import tensorflow_is_autocast_enabled
        from ...ivy.functional.frontends.torch.tensor import tensorflow_type_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_index_put_frnt_
        from .utils.helpers import tensorflow__transform_output_shape
    
        params, flags = self._process_kwargs_to_params_and_flags(
            self._params if params is None else params, flags, **kwargs
        )
        batch_prob = params["batch_prob"]
        to_apply = batch_prob > 0.5
        ori_shape = tensorflow_shape_frnt_(input)
        in_tensor = self.transform_tensor(input)
        self.validate_tensor(in_tensor)
        if tensorflow_all_frnt_(to_apply):
>           output = self.apply_transform(in_tensor, params, flags, transform=transform)

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/base.py:354: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomSolarize(thresholds=0.1, additions=0.1, p=1.0, p_batch=1.0, same_on_batch=False)
input = <tf.Tensor: shape=(1, 1, 5, 5), dtype=float32, numpy=
array([[[[0.58669436, 0.59938526, 0.5272368 , 0.3293541 , 0.2929....65983105, 0.80919105],
         [0.49576014, 0.10896289, 0.9171534 , 0.66534084, 0.53361744]]]],
      dtype=float32)>
params = {'additions': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([-0.08288383], dtype=float32)>, 'batch_prob': <tf.Ten...py=array([1, 1, 5, 5])>, 'thresholds': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.5606487], dtype=float32)>}
flags = {}, transform = <tf.Tensor: shape=(1, 3, 3), dtype=float32, numpy=
array([[[1., 0., 0.],
        [0., 1., 0.],
        [0., 0., 1.]]], dtype=float32)>

    def apply_transform(self, input, params, flags, transform=None):
        from ....enhance.adjust import tensorflow_solarize
    
        thresholds = params["thresholds"]
        additions: typing.Any
        if "additions" in params:
            additions = params["additions"]
        else:
            additions = None
>       return tensorflow_solarize(input, thresholds, additions)

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/_2d/intensity/solarize.py:57: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = <tf.Tensor: shape=(1, 1, 5, 5), dtype=float32, numpy=
array([[[[0.58669436, 0.59938526, 0.5272368 , 0.3293541 , 0.2929....65983105, 0.80919105],
         [0.49576014, 0.10896289, 0.9171534 , 0.66534084, 0.53361744]]]],
      dtype=float32)>
thresholds = <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.5606487], dtype=float32)>, additions = <tf.Tensor: shape=(1,), dtype=float32, numpy=array([-0.08288383], dtype=float32)>

    def tensorflow_solarize(input, thresholds=0.5, additions=None):
        from ...ivy.functional.frontends.torch.creation_ops import tensorflow_as_tensor_frnt
        from ...ivy.functional.frontends.torch.reduction_ops import tensorflow_all_frnt
        from ...ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_size_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_to_frnt_
        from ...ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            tensorflow_stack_frnt,
        )
        from ...ivy.functional.frontends.torch.tensor import tensorflow_expand_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_clamp_frnt_
    
        if not isinstance(input, (tensorflow.Tensor, tensorflow.keras.Variable)):
            raise TypeError(f"Input type is not a Tensor. Got {type(input)}")
        if not isinstance(
            thresholds, (float, tensorflow.Tensor, tensorflow.keras.Variable)
        ):
            raise TypeError(
                f"The factor should be either a float or Tensor. Got {type(thresholds)}"
            )
        if isinstance(thresholds, (float,)):
            thresholds = tensorflow_as_tensor_frnt(thresholds)
        if additions is not None:
            if not isinstance(
                additions, (float, tensorflow.Tensor, tensorflow.keras.Variable)
            ):
                raise TypeError(
                    f"The factor should be either a float or Tensor. Got {type(additions)}"
                )
            if isinstance(additions, (float,)):
                additions = tensorflow_as_tensor_frnt(additions)
>           if not tensorflow_all_frnt((additions < 0.5) * (additions > -0.5)):

ivy_transpiled_outputs/tensorflow_outputs/kornia/enhance/adjust.py:107: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <tf.Tensor: shape=(1,), dtype=bool, numpy=array([ True])>, rhs = <tf.Tensor: shape=(1,), dtype=bool, numpy=array([ True])>

    def impl(self, rhs):
        try:
            return original_method(self, rhs)
        except Exception:
>           return patched_method(self, rhs)

ivy_transpiled_outputs/tensorflow_outputs/__init__.py:65: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = <tf.Tensor: shape=(1,), dtype=bool, numpy=array([ True])>, other = <tf.Tensor: shape=(1,), dtype=bool, numpy=array([ True])>

    def tensorflow___mul___frnt_(tensor, other):
        from .pointwise_ops import tensorflow_mul_frnt
    
>       return tensorflow_mul_frnt(tensor, other)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/tensor.py:111: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = <tf.Tensor: shape=(1,), dtype=bool, numpy=array([ True])>, other = <tf.Tensor: shape=(1,), dtype=bool, numpy=array([ True])>

    def tensorflow_mul_frnt(input, other, *, out=None):
        from .__init__ import tensorflow_promote_types_of_torch_inputs_frnt
        from ...backends.tensorflow.elementwise import tensorflow_multiply
    
        input, other = tensorflow_promote_types_of_torch_inputs_frnt(input, other)
>       return tensorflow_multiply(input, other, out=out)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/pointwise_ops.py:111: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x1 = <tf.Tensor: shape=(1,), dtype=bool, numpy=array([ True])>, x2 = <tf.Tensor: shape=(1,), dtype=bool, numpy=array([ True])>

    def tensorflow_multiply(
        x1: Union[float, tensorflow.Tensor, tensorflow.Variable],
        x2: Union[float, tensorflow.Tensor, tensorflow.Variable],
        /,
        *,
        out: Optional[Union[tensorflow.Tensor, tensorflow.Variable]] = None,
    ):
        from ...ivy.data_type import tensorflow_promote_types_of_inputs_bknd
    
        x1, x2 = tensorflow_promote_types_of_inputs_bknd(x1, x2)
>       return tensorflow.math.multiply(x1, x2)
E       tensorflow.python.framework.errors_impl.InvalidArgumentError: Exception encountered when calling tensorflow_RandomSolarize.call().
E       
E       [1mValue for attr 'T' of bool is not in the list of allowed values: bfloat16, half, float, double, uint8, int8, uint16, int16, int32, uint32, uint64, int64, complex64, complex128
E       	; NodeDef: {{node Mul}}; Op<name=Mul; signature=x:T, y:T -> z:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE, DT_UINT8, DT_INT8, DT_UINT16, DT_INT16, DT_INT32, DT_UINT32, DT_UINT64, DT_INT64, DT_COMPLEX64, DT_COMPLEX128]; is_commutative=true> [Op:Mul] name: [0m
E       
E       Arguments received by tensorflow_RandomSolarize.call():
E         • input=tf.Tensor(shape=(1, 1, 5, 5), dtype=float32)
E         • params=None
E         • kwargs=<class 'inspect._empty'>

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/backends/tensorflow/elementwise.py:299: InvalidArgumentError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.RandomSolarize
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/augmentation/test_augmentation2.py::test_RandomMotionBlur[tensorflow-s2s-False] - TypeError: Exception encountered when calling tensorflow_RandomMotionBlur.call().
FAILED kornia/augmentation/test_augmentation2.py::test_RandomSaltAndPepperNoise[tensorflow-s2s-False] - AttributeError: Exception encountered when calling tensorflow_RandomSaltAndPepperNoise.call().
FAILED kornia/augmentation/test_augmentation2.py::test_RandomSharpness[tensorflow-s2s-False] - NameError: Exception encountered when calling tensorflow_RandomSharpness.call().
FAILED kornia/augmentation/test_augmentation2.py::test_RandomSolarize[tensorflow-s2s-False] - tensorflow.python.framework.errors_impl.InvalidArgumentError: Exception encountered when calling tensor...
============================================================================== 4 failed, 13 passed in 3643.29s (1:00:43) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 2 items

kornia/test_io.py ..                                                                                                                                                                             [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
==================================================================================== 2 passed in 123.18s (0:02:03) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 8 items

kornia/geometry/test_homography.py ........                                                                                                                                                      [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
==================================================================================== 8 passed in 684.57s (0:11:24) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 10 items

kornia/test_feature5.py FF...F.FF.                                                                                                                                                               [100%]

=============================================================================================== FAILURES ===============================================================================================
________________________________________________________________________________ test_LAFOrienter[tensorflow-s2s-False] ________________________________________________________________________________

inp = <KerasVariable shape=(5, 1, 1), dtype=float32, path=variable>, query = slice(None, None, None)
val = <tf.Tensor: shape=(1, 5), dtype=float32, numpy=
array([[0.1190625 , 0.2311236 , 0.29962778, 0.2311236 , 0.1190625 ]],
      dtype=float32)>, kwargs = {}

    @functools.wraps(fn)
    def wrapper(inp, query, val, **kwargs):
        try:
>           inp.__setitem__(query, val)
E           AttributeError: 'Variable' object has no attribute '__setitem__'. Did you mean: '__getitem__'?

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:233: AttributeError

During handling of the above exception, another exception occurred:

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_LAFOrienter(target_framework, mode, backend_compile):
        print("kornia.feature.LAFOrienter")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target_framework)
    
        laf = torch.rand(1, 2, 2, 3)
        img = torch.rand(1, 1, 32, 32)
        transpiled_laf = _nest_torch_tensor_to_new_framework(laf, target_framework)
        transpiled_img = _nest_torch_tensor_to_new_framework(img, target_framework)
    
        model = kornia.feature.LAFOrienter()
        torch_out = model(laf, img)
    
>       transpiled_model = transpiled_kornia.feature.LAFOrienter()

kornia/test_feature5.py:33: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:232: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'tensorflow_LAFOrienter' object has no attribute 'angle_detector'") raised in repr()] tensorflow_LAFOrienter object at 0x7f4ccaf552d0>, patch_size = 32, num_angular_bins = 36
angle_detector = None

    def __init__(self, patch_size=32, num_angular_bins=36, angle_detector=None):
        self.super___init__(
            patch_size=patch_size,
            num_angular_bins=num_angular_bins,
            angle_detector=angle_detector,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        self.patch_size = patch_size
        self.num_ang_bins = num_angular_bins
        self.angle_detector: typing.Any
        if angle_detector is None:
>           self.angle_detector = tensorflow_PatchDominantGradientOrientation(
                self.patch_size, self.num_ang_bins
            )

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/orientation.py:270: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_PatchDominantGradientOrientation(patch_size=32, num_ang_bins=36, eps=1e-08), args = (32, 36), kwargs = {}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_PatchDominantGradientOrientation(patch_size=32, num_ang_bins=36, eps=1e-08), patch_size = 32, num_angular_bins = 36, eps = 1e-08

    @tensorflow_store_config_info
    def __init__(self, patch_size=32, num_angular_bins=36, eps=1e-08):
        from ..filters.sobel import tensorflow_SpatialGradient
        from ...torch.nn.modules.conv import tensorflow_Conv1d
        from ...ivy.functional.backends.tensorflow.general import tensorflow_set_item
        from ..filters.kernels import tensorflow_get_gaussian_discrete_kernel1d
        from ..filters.kernels import tensorflow_get_gaussian_kernel2d
    
        self.super___init__(
            patch_size=patch_size,
            num_angular_bins=num_angular_bins,
            eps=eps,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        self.patch_size = patch_size
        self.num_ang_bins = num_angular_bins
        self.gradient = tensorflow_SpatialGradient("sobel", 1)
        self.eps = eps
        self.angular_smooth = tensorflow_Conv1d(
            1, 1, kernel_size=5, padding=2, bias=False, padding_mode="circular"
        )
>       self.angular_smooth.weight = tensorflow_set_item(
            self.angular_smooth.weight,
            slice(None, None, None),
            tensorflow_get_gaussian_discrete_kernel1d(5, 1.6),
        )

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/orientation.py:62: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

inp = <KerasVariable shape=(5, 1, 1), dtype=float32, path=variable>, query = slice(None, None, None)
val = <tf.Tensor: shape=(1, 5), dtype=float32, numpy=
array([[0.1190625 , 0.2311236 , 0.29962778, 0.2311236 , 0.1190625 ]],
      dtype=float32)>, kwargs = {}

    @functools.wraps(fn)
    def wrapper(inp, query, val, **kwargs):
        try:
            inp.__setitem__(query, val)
            res = inp
        except IndexError:
            raise
        except Exception:
>           res = fn(inp, query, val, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:238: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (<KerasVariable shape=(5, 1, 1), dtype=float32, path=variable>, slice(None, None, None), <tf.Tensor: shape=(1, 5), dtype=float32, numpy=
array([[0.1190625 , 0.2311236 , 0.29962778, 0.2311236 , 0.1190625 ]],
      dtype=float32)>)
kwargs = {}, handle_mixed_in_backend = True

    @functools.wraps(fn)
    def _handle_partial_mixed_function(*args, **kwargs):
        handle_mixed_in_backend = False
        if not hasattr(fn, "partial_mixed_handler"):
            handle_mixed_in_backend = True
        else:
            compos = getattr(fn, "compos")
            condition = getattr(fn, "partial_mixed_handler")
        if handle_mixed_in_backend or condition(*args, **kwargs):
>           return fn(*args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/func_wrapper.py:173: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[0.]],

       [[0.]],

       [[0.]],

       [[0.]],

       [[0.]]], dtype=float32), query = slice(None, None, None)
val = array([[0.1190625 , 0.2311236 , 0.29962778, 0.2311236 , 0.1190625 ]],
      dtype=float32)

    @tensorflow_handle_set_item
    @tensorflow_handle_partial_mixed_function
    def tensorflow_set_item(
        x: Union[tensorflow.Tensor, tensorflow.Variable],
        query: Union[tensorflow.Tensor, tensorflow.Variable, Tuple],
        val: Union[tensorflow.Tensor, tensorflow.Variable],
        /,
        *,
        copy: Optional[bool] = False,
    ):
        if tensorflow.is_tensor(x):
            x = x.numpy()
        if tensorflow.is_tensor(val):
            val = val.numpy()
        if isinstance(query, (tensorflow.Tensor, tensorflow.Variable)):
            query = query.numpy()
        elif isinstance(query, tuple):
            query = tuple(
                q.numpy() if isinstance(q, (tensorflow.Tensor, tensorflow.Variable)) else q
                for q in query
            )
>       x[query] = val
E       ValueError: could not broadcast input array from shape (1,5) into shape (5,1,1)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/backends/tensorflow/general.py:109: ValueError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.LAFOrienter
_____________________________________________________________________ test_PatchDominantGradientOrientation[tensorflow-s2s-False] ______________________________________________________________________

inp = <KerasVariable shape=(5, 1, 1), dtype=float32, path=variable_1>, query = slice(None, None, None)
val = <tf.Tensor: shape=(1, 5), dtype=float32, numpy=
array([[0.1190625 , 0.2311236 , 0.29962778, 0.2311236 , 0.1190625 ]],
      dtype=float32)>, kwargs = {}

>   ???
E   AttributeError: 'Variable' object has no attribute '__setitem__'. Did you mean: '__getitem__'?

/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:233: AttributeError

During handling of the above exception, another exception occurred:

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_PatchDominantGradientOrientation(target_framework, mode, backend_compile):
        print("kornia.feature.PatchDominantGradientOrientation")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target_framework)
    
        patch = torch.rand(10, 1, 32, 32)
        transpiled_patch = _nest_torch_tensor_to_new_framework(patch, target_framework)
    
        model = kornia.feature.PatchDominantGradientOrientation()
        torch_out = model(patch)
    
>       transpiled_model = transpiled_kornia.feature.PatchDominantGradientOrientation()

kornia/test_feature5.py:59: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:232: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_PatchDominantGradientOrientation(patch_size=32, num_ang_bins=36, eps=1e-08), args = (), kwargs = {}

>   ???

/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_PatchDominantGradientOrientation(patch_size=32, num_ang_bins=36, eps=1e-08), patch_size = 32, num_angular_bins = 36, eps = 1e-08

>   ???

/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/orientation.py:62: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

inp = <KerasVariable shape=(5, 1, 1), dtype=float32, path=variable_1>, query = slice(None, None, None)
val = <tf.Tensor: shape=(1, 5), dtype=float32, numpy=
array([[0.1190625 , 0.2311236 , 0.29962778, 0.2311236 , 0.1190625 ]],
      dtype=float32)>, kwargs = {}

>   ???

/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:238: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (<KerasVariable shape=(5, 1, 1), dtype=float32, path=variable_1>, slice(None, None, None), <tf.Tensor: shape=(1, 5), dtype=float32, numpy=
array([[0.1190625 , 0.2311236 , 0.29962778, 0.2311236 , 0.1190625 ]],
      dtype=float32)>)
kwargs = {}, handle_mixed_in_backend = True

>   ???

/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/ivy/func_wrapper.py:173: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[0.]],

       [[0.]],

       [[0.]],

       [[0.]],

       [[0.]]], dtype=float32), query = slice(None, None, None)
val = array([[0.1190625 , 0.2311236 , 0.29962778, 0.2311236 , 0.1190625 ]],
      dtype=float32)

>   ???
E   ValueError: could not broadcast input array from shape (1,5) into shape (5,1,1)

/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/backends/tensorflow/general.py:109: ValueError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.PatchDominantGradientOrientation
____________________________________________________________________________________ test_TLU[tensorflow-s2s-False] ____________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_TLU(target_framework, mode, backend_compile):
        print("kornia.feature.TLU")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target_framework)
    
        x = torch.rand(1, 3, 8, 8)
        torch_out = kornia.feature.TLU(3)(x)
    
        transpiled_x = _nest_torch_tensor_to_new_framework(x, target_framework)
>       transpiled_out = transpiled_kornia.feature.TLU(3)(transpiled_x)

kornia/test_feature5.py:145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_TLU()
args = (<tf.Tensor: shape=(1, 3, 8, 8), dtype=float32, numpy=
array([[[[0.04555446, 0.3436687 , 0.44165987, 0.20463705, 0.739...55, 0.0349943 , 0.41187322, 0.8857047 , 0.07077765,
          0.16387516, 0.7854996 , 0.11651444]]]], dtype=float32)>,)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x55d8ea2f22f0, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...ode_context=['        return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_TLU(), <tf.Tensor: shape=(1, 3, 8, 8), dtype=float32, numpy=
array([[[[0.04555446, 0.3436687 , 0.44165987,...355, 0.0349943 , 0.41187322, 0.8857047 , 0.07077765,
          0.16387516, 0.7854996 , 0.11651444]]]], dtype=float32)>)
kwargs = {}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_TLU(), v = None, buffers = None
args = (<tf.Tensor: shape=(1, 3, 8, 8), dtype=float32, numpy=
array([[[[0.04555446, 0.3436687 , 0.44165987, 0.20463705, 0.739...55, 0.0349943 , 0.41187322, 0.8857047 , 0.07077765,
          0.16387516, 0.7854996 , 0.11651444]]]], dtype=float32)>,)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:2017: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_TLU(), <tf.Tensor: shape=(1, 3, 8, 8), dtype=float32, numpy=
array([[[[0.04555446, 0.3436687 , 0.44165987,...355, 0.0349943 , 0.41187322, 0.8857047 , 0.07077765,
          0.16387516, 0.7854996 , 0.11651444]]]], dtype=float32)>)
kwargs = {'buffers': None, 'v': None}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_TLU(), v = None, buffers = None
args = (<tf.Tensor: shape=(1, 3, 8, 8), dtype=float32, numpy=
array([[[[0.04555446, 0.3436687 , 0.44165987, 0.20463705, 0.739...55, 0.0349943 , 0.41187322, 0.8857047 , 0.07077765,
          0.16387516, 0.7854996 , 0.11651444]]]], dtype=float32)>,)
kwargs = {}
first_arr = <tf.Tensor: shape=(1, 3, 8, 8), dtype=float32, numpy=
array([[[[0.04555446, 0.3436687 , 0.44165987, 0.20463705, 0.7395...6355, 0.0349943 , 0.41187322, 0.8857047 , 0.07077765,
          0.16387516, 0.7854996 , 0.11651444]]]], dtype=float32)>
replace_v = False, replace_buffers = False, call_signature = <Signature (x)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Model, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Model, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Model, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1787: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_TLU(),)
kwargs = {'x': <tf.Tensor: shape=(1, 3, 8, 8), dtype=float32, numpy=
array([[[[0.04555446, 0.3436687 , 0.44165987, 0.20463705, ...355, 0.0349943 , 0.41187322, 0.8857047 , 0.07077765,
          0.16387516, 0.7854996 , 0.11651444]]]], dtype=float32)>}

    @wraps(fn)
    def error_handler(*args, **kwargs):
        if not is_traceback_filtering_enabled():
            return fn(*args, **kwargs)
    
        filtered_tb = None
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            filtered_tb = _process_traceback_frames(e.__traceback__)
            # To get the full stack trace, call:
            # `keras.config.disable_traceback_filtering()`
>           raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/keras/src/utils/traceback_utils.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_TLU()
x = <tf.Tensor: shape=(1, 3, 8, 8), dtype=float32, numpy=
array([[[[0.04555446, 0.3436687 , 0.44165987, 0.20463705, 0.7395...6355, 0.0349943 , 0.41187322, 0.8857047 , 0.07077765,
          0.16387516, 0.7854996 , 0.11651444]]]], dtype=float32)>

    def call(self, x):
        from ...ivy.functional.frontends.torch.reduction_ops import tensorflow_max_frnt
    
>       return tensorflow_max_frnt(x, self.tau)

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/hynet.py:62: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dim = <KerasVariable shape=(1, 3, 1, 1), dtype=float32, path=variable_16>, keepdim = False, out = None
input = <tf.Tensor: shape=(1, 3, 8, 8), dtype=float32, numpy=
array([[[[0.04555446, 0.3436687 , 0.44165987, 0.20463705, 0.7395...6355, 0.0349943 , 0.41187322, 0.8857047 , 0.07077765,
          0.16387516, 0.7854996 , 0.11651444]]]], dtype=float32)>

    def tensorflow_max_frnt(*input, dim=None, keepdim=False, out=None):
        from ...ivy.general import tensorflow_is_array_bknd
        from .comparison_ops import tensorflow_maximum_frnt
        from ...backends.tensorflow.statistical import tensorflow_max
        from ...backends.tensorflow.searching import tensorflow_argmax
    
        if len(input) == 1:
            input = input[0]
        elif len(input) == 2:
            input_0 = input[0]
            input_1 = input[1]
            if tensorflow_is_array_bknd(input_1):
                return tensorflow_maximum_frnt(*input)
            else:
                input = input_0
                dim = input_1
        else:
            input = input[0]
            dim = input[1]
            keepdim = input[2]
        if dim is None:
            return tensorflow_max(input, axis=dim, keepdims=keepdim, out=out)
        elif out is not None:
            tensorflow_max(input, axis=dim, keepdims=keepdim, out=out[0])
            tensorflow_argmax(input, axis=dim, keepdims=keepdim, out=out[1])
            return out
        else:
            max_tuple = namedtuple("max", ["values", "indices"])
            return max_tuple(
>               tensorflow_max(input, axis=dim, keepdims=keepdim),
                tensorflow_argmax(input, axis=dim, keepdims=keepdim),
            )

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/reduction_ops.py:62: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = [<tf.Tensor: shape=(1, 3, 8, 8), dtype=float32, numpy=
array([[[[0.04555446, 0.3436687 , 0.44165987, 0.20463705, 0.739...355, 0.0349943 , 0.41187322, 0.8857047 , 0.07077765,
          0.16387516, 0.7854996 , 0.11651444]]]], dtype=float32)>]
kwargs = {'axis': <KerasVariable shape=(1, 3, 1, 1), dtype=float32, path=variable_16>, 'keepdims': False}, tensorflow_is_array_bknd = <function tensorflow_is_array_bknd at 0x7f4c968b04c0>
tensorflow_set_item = <function tensorflow_set_item at 0x7f4c968b2560>, tensorflow_asarray = <function tensorflow_asarray at 0x7f4c968b0dc0>
tensorflow_get_item = <function tensorflow_get_item at 0x7f4c968b23b0>, num_args = 1
type_hints = mappingproxy(OrderedDict([('x', <Parameter "x: Union[tensorflow.python.framework.tensor.Tensor, tensorflow.python.ops...."out: Union[tensorflow.python.framework.tensor.Tensor, tensorflow.python.ops.variables.Variable, NoneType] = None">)]))
parameters = ['x', 'axis', 'keepdims', 'out']
annotations = [typing.Union[tensorflow.python.framework.tensor.Tensor, tensorflow.python.ops.variables.Variable], typing.Union[int, ...s 'bool'>, typing.Union[tensorflow.python.framework.tensor.Tensor, tensorflow.python.ops.variables.Variable, NoneType]]
device = '/job:localhost/replica:0/task:0/device:CPU:0', i = 0

    @functools.wraps(fn)
    def _handle_array_like_without_promotion(*args, **kwargs):
        from .functional.ivy.general import tensorflow_is_array_bknd
        from .functional.backends.tensorflow.general import tensorflow_set_item
        from .functional.backends.tensorflow.creation import tensorflow_asarray
        from .functional.backends.tensorflow.general import tensorflow_get_item
    
        args = list(args)
        num_args = len(args)
        try:
            type_hints = inspect.signature(fn).parameters
        except (TypeError, ValueError):
            return fn(*args, **kwargs)
        parameters = list(type_hints.keys())
        annotations = [param.annotation for param in type_hints.values()]
        device = tensorflow__get_preferred_device(args, kwargs)
        for i, (annotation, parameter, arg) in enumerate(
            zip(annotations, parameters, args)
        ):
            annotation_str = str(annotation)
            if (
                ("rray" in annotation_str or "Tensor" in annotation_str)
                and parameter != "out"
                and all(
                    sq not in annotation_str
                    for sq in ["Sequence", "List", "Tuple", "float", "int", "bool"]
                )
            ):
                if i < num_args:
                    if arg is None or tensorflow__check_in_nested_sequence(
                        arg, value=Ellipsis, _type=slice
                    ):
                        continue
                    if not tensorflow_is_array_bknd(arg):
                        args = tensorflow_set_item(
                            args, i, tensorflow_asarray(arg, device=device)
                        )
                elif parameters in kwargs:
                    kwarg = tensorflow_get_item(kwargs, parameter)
                    if not tensorflow_is_array_bknd(kwarg):
                        kwargs = tensorflow_set_item(
                            kwargs, parameter, tensorflow_asarray(kwarg, device=device)
                        )
>       return fn(*args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/func_wrapper.py:139: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = <tf.Tensor: shape=(1, 3, 8, 8), dtype=float32, numpy=
array([[[[0.04555446, 0.3436687 , 0.44165987, 0.20463705, 0.7395...6355, 0.0349943 , 0.41187322, 0.8857047 , 0.07077765,
          0.16387516, 0.7854996 , 0.11651444]]]], dtype=float32)>

    @tensorflow_handle_array_like_without_promotion
    def tensorflow_max(
        x: Union[tensorflow.Tensor, tensorflow.Variable],
        /,
        *,
        axis: Optional[Union[int, Sequence[int]]] = None,
        keepdims: bool = False,
        out: Optional[Union[tensorflow.Tensor, tensorflow.Variable]] = None,
    ):
        if "complex" in str(x.dtype):
            real = tensorflow.math.real(x)
            img = tensorflow.math.imag(x)
            const = tensorflow.constant(1.0j, dtype=x.dtype)
            real_max = tensorflow.reduce_max(real, axis=axis, keepdims=keepdims)
            imag = tensorflow.where(
                real == real_max, img, tensorflow.experimental.numpy.finfo(img.dtype).min
            )
            img_max = tensorflow.reduce_max(imag, axis=axis, keepdims=keepdims)
            img_max = tensorflow.cast(img_max, x.dtype)
            return tensorflow.add(
                tensorflow.cast(real_max, x.dtype), tensorflow.multiply(img_max, const)
            )
        axis = tuple(axis) if isinstance(axis, list) else axis
>       return tensorflow.math.reduce_max(x, axis=axis, keepdims=keepdims)
E       tensorflow.python.framework.errors_impl.InvalidArgumentError: Exception encountered when calling tensorflow_TLU.call().
E       
E       [1mValue for attr 'Tidx' of float is not in the list of allowed values: int32, int64
E       	; NodeDef: {{node Max}}; Op<name=Max; signature=input:T, reduction_indices:Tidx -> output:T; attr=keep_dims:bool,default=false; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, DT_INT8, DT_INT64, DT_BFLOAT16, DT_UINT16, DT_HALF, DT_UINT32, DT_UINT64, DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=Tidx:type,default=DT_INT32,allowed=[DT_INT32, DT_INT64]> [Op:Max][0m
E       
E       Arguments received by tensorflow_TLU.call():
E         • x=tf.Tensor(shape=(1, 3, 8, 8), dtype=float32)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/backends/tensorflow/statistical.py:60: InvalidArgumentError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.TLU
__________________________________________________________________________________ test_DeDoDe[tensorflow-s2s-False] ___________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_DeDoDe(target_framework, mode, backend_compile):
        print("kornia.feature.DeDoDe")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target_framework)
    
        x = torch.rand(1, 3, 256, 256)
        transpiled_x = _nest_torch_tensor_to_new_framework(x, target_framework)
    
        model = kornia.feature.DeDoDe(amp_dtype=torch.float32)
        torch_out = model(x)
    
        ivy.set_backend(target_framework)
        transpiled_model = transpiled_kornia.feature.DeDoDe(amp_dtype=ivy.as_native_dtype("float32"))
        if target_framework == "tensorflow":
            # build the layers
>           transpiled_model(transpiled_x)

kornia/test_feature5.py:185: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_DeDoDe(
  (detector): tensorflow_DeDoDeDetector(
    (encoder): tensorflow_VGG19(
      (pt_layers): tensor...)
        )
      )
    )
  )
  (normalizer): tensorflow_Normalize(mean=[0.485 0.456 0.406], std=[0.229 0.224 0.225])
)
args = (<tf.Tensor: shape=(1, 3, 256, 256), dtype=float32, numpy=
array([[[[0.03572643, 0.76152027, 0.37315536, ..., 0.871383...
         [0.20240927, 0.6003894 , 0.96467024, ..., 0.58100945,
          0.3029765 , 0.7111616 ]]]], dtype=float32)>,)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x55d96705ff20, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...ode_context=['        return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_DeDoDe(
  (detector): tensorflow_DeDoDeDetector(
    (encoder): tensorflow_VGG19(
      (pt_layers): tenso...,
         [0.20240927, 0.6003894 , 0.96467024, ..., 0.58100945,
          0.3029765 , 0.7111616 ]]]], dtype=float32)>)
kwargs = {}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_DeDoDe(
  (detector): tensorflow_DeDoDeDetector(
    (encoder): tensorflow_VGG19(
      (pt_layers): tensor...)
        )
      )
    )
  )
  (normalizer): tensorflow_Normalize(mean=[0.485 0.456 0.406], std=[0.229 0.224 0.225])
)
v = None, buffers = None
args = (<tf.Tensor: shape=(1, 3, 256, 256), dtype=float32, numpy=
array([[[[0.03572643, 0.76152027, 0.37315536, ..., 0.871383...
         [0.20240927, 0.6003894 , 0.96467024, ..., 0.58100945,
          0.3029765 , 0.7111616 ]]]], dtype=float32)>,)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:2017: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_DeDoDe(
  (detector): tensorflow_DeDoDeDetector(
    (encoder): tensorflow_VGG19(
      (pt_layers): tenso...,
         [0.20240927, 0.6003894 , 0.96467024, ..., 0.58100945,
          0.3029765 , 0.7111616 ]]]], dtype=float32)>)
kwargs = {'buffers': None, 'v': None}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_DeDoDe(
  (detector): tensorflow_DeDoDeDetector(
    (encoder): tensorflow_VGG19(
      (pt_layers): tensor...)
        )
      )
    )
  )
  (normalizer): tensorflow_Normalize(mean=[0.485 0.456 0.406], std=[0.229 0.224 0.225])
)
v = None, buffers = None
args = (<tf.Tensor: shape=(1, 3, 256, 256), dtype=float32, numpy=
array([[[[0.03572643, 0.76152027, 0.37315536, ..., 0.871383...
         [0.20240927, 0.6003894 , 0.96467024, ..., 0.58100945,
          0.3029765 , 0.7111616 ]]]], dtype=float32)>,)
kwargs = {}
first_arr = <tf.Tensor: shape=(1, 3, 256, 256), dtype=float32, numpy=
array([[[[0.03572643, 0.76152027, 0.37315536, ..., 0.8713839...],
         [0.20240927, 0.6003894 , 0.96467024, ..., 0.58100945,
          0.3029765 , 0.7111616 ]]]], dtype=float32)>
replace_v = False, replace_buffers = False, call_signature = <Signature (images, n=10000, apply_imagenet_normalization=True, pad_if_not_divisible=True)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Model, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Model, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Model, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1787: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_DeDoDe(
  (detector): tensorflow_DeDoDeDetector(
    (encoder): tensorflow_VGG19(
      (pt_layers): tenso...        )
      )
    )
  )
  (normalizer): tensorflow_Normalize(mean=[0.485 0.456 0.406], std=[0.229 0.224 0.225])
),)
kwargs = {'images': <tf.Tensor: shape=(1, 3, 256, 256), dtype=float32, numpy=
array([[[[0.03572643, 0.76152027, 0.37315536, ......,
         [0.20240927, 0.6003894 , 0.96467024, ..., 0.58100945,
          0.3029765 , 0.7111616 ]]]], dtype=float32)>}

    @wraps(fn)
    def error_handler(*args, **kwargs):
        if not is_traceback_filtering_enabled():
            return fn(*args, **kwargs)
    
        filtered_tb = None
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            filtered_tb = _process_traceback_frames(e.__traceback__)
            # To get the full stack trace, call:
            # `keras.config.disable_traceback_filtering()`
>           raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/keras/src/utils/traceback_utils.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_DeDoDe(
  (detector): tensorflow_DeDoDeDetector(
    (encoder): tensorflow_VGG19(
      (pt_layers): tensor...)
        )
      )
    )
  )
  (normalizer): tensorflow_Normalize(mean=[0.485 0.456 0.406], std=[0.229 0.224 0.225])
)
images = <tf.Tensor: shape=(1, 3, 266, 266), dtype=float32, numpy=
array([[[[-1.9618933 ,  1.207512  , -0.48840463, ...,  0.   ...      [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ]]]], dtype=float32)>
n = 10000, apply_imagenet_normalization = True, pad_if_not_divisible = True

    def call(
        self,
        images,
        n=10000,
        apply_imagenet_normalization=True,
        pad_if_not_divisible=True,
    ):
        from ....ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ....ivy.functional.frontends.torch.nn.functional.vision_functions import (
            tensorflow_pad_frnt,
        )
        from ...geometry.conversions import tensorflow_denormalize_pixel_coordinates
    
        if apply_imagenet_normalization:
            images = self.normalizer(images)
        B, C, H, W = tensorflow_shape_frnt_(images)
        if pad_if_not_divisible:
            h, w = (
                tensorflow_shape_frnt_(images)[2:][0],
                tensorflow_shape_frnt_(images)[2:][1],
            )
            pd_h = 14 - h % 14 if h % 14 > 0 else 0
            pd_w = 14 - w % 14 if w % 14 > 0 else 0
            images = tensorflow_pad_frnt(images, (0, pd_w, 0, pd_h), value=0.0)
>       keypoints, scores = self.detect(
            images, n=n, apply_imagenet_normalization=False, crop_h=h, crop_w=w
        )

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/dedode/dedode.py:101: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_DeDoDe(
  (detector): tensorflow_DeDoDeDetector(
    (encoder): tensorflow_VGG19(
      (pt_layers): tensor...)
        )
      )
    )
  )
  (normalizer): tensorflow_Normalize(mean=[0.485 0.456 0.406], std=[0.229 0.224 0.225])
)
images = <tf.Tensor: shape=(1, 3, 266, 266), dtype=float32, numpy=
array([[[[-1.9618933 ,  1.207512  , -0.48840463, ...,  0.   ...      [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ]]]], dtype=float32)>
n = 10000, apply_imagenet_normalization = False, pad_if_not_divisible = True, crop_h = 256, crop_w = 256

    def detect(
        self,
        images,
        n=10000,
        apply_imagenet_normalization=True,
        pad_if_not_divisible=True,
        crop_h=None,
        crop_w=None,
    ):
        from ....ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ....ivy.functional.frontends.torch.nn.functional.vision_functions import (
            tensorflow_pad_frnt,
        )
        from ...core.check import tensorflow_KORNIA_CHECK_SHAPE
        from ....ivy.functional.backends.tensorflow.general import tensorflow_get_item
        from ....ivy.functional.frontends.torch.tensor import tensorflow_reshape_frnt_
        from ....ivy.functional.frontends.torch.tensor import tensorflow_softmax_frnt_
        from .utils import tensorflow_sample_keypoints
    
        tensorflow_KORNIA_CHECK_SHAPE(images, ["B", "3", "H", "W"])
        self.train(False)
        if pad_if_not_divisible:
            h, w = (
                tensorflow_shape_frnt_(images)[2:][0],
                tensorflow_shape_frnt_(images)[2:][1],
            )
            pd_h = 14 - h % 14 if h % 14 > 0 else 0
            pd_w = 14 - w % 14 if w % 14 > 0 else 0
            images = tensorflow_pad_frnt(images, (0, pd_w, 0, pd_h), value=0.0)
        if apply_imagenet_normalization:
            images = self.normalizer(images)
        B, C, H, W = tensorflow_shape_frnt_(images)
>       logits = self.detector.call(images)

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/dedode/dedode.py:145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_DeDoDeDetector(
  (encoder): tensorflow_VGG19(
    (pt_layers): tensorflow_ModuleList(
      (0): KerasConv...rflow_ReLU()
            (3): KerasConv2D()
          )
        )
        (out_conv): KerasConv2D()
      )
    )
  )
)
images = <tf.Tensor: shape=(1, 3, 266, 266), dtype=float32, numpy=
array([[[[-1.9618933 ,  1.207512  , -0.48840463, ...,  0.   ...      [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ]]]], dtype=float32)>

    def call(self, images):
        from ....ivy.functional.frontends.torch.tensor import tensorflow_float_frnt_
        from ....ivy.functional.backends.tensorflow.general import tensorflow_get_item
        from ....ivy.functional.frontends.torch.nn.functional.vision_functions import (
            tensorflow_interpolate_frnt,
        )
        from ....ivy.functional.frontends.torch.tensor import tensorflow_to_frnt_
    
        dtype = images.dtype
        features, sizes = self.encoder(images)
        context = None
        logits = None
        scales = ["8", "4", "2", "1"]
        for idx, (feature_map, scale) in enumerate(zip(reversed(features), scales)):
>           delta_logits, context = self.decoder(
                feature_map, context=context, scale=scale
            )

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/dedode/detector.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Decoder(
  (pt_layers): tensorflow_ModuleDict(
    (8): tensorflow_ConvRefiner(
      (block1): tensorflow_...      (2): tensorflow_ReLU()
          (3): KerasConv2D()
        )
      )
      (out_conv): KerasConv2D()
    )
  )
)
args = (<tf.Tensor: shape=(1, 512, 33, 33), dtype=float32, numpy=
array([[[[0.        , 0.00517493, 0.00449416, ..., 0.014183...
         [0.        , 0.        , 0.        , ..., 0.        ,
          0.        , 0.        ]]]], dtype=float32)>,)
kwargs = {'context': None, 'scale': '8'}
stack = [FrameInfo(frame=<frame at 0x55d8ec2bb3e0, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...ion.py', lineno=46, function='__call__', code_context=['            return call_fn(*args, **kwargs)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Decoder(
  (pt_layers): tensorflow_ModuleDict(
    (8): tensorflow_ConvRefiner(
      (block1): tensorflow_...      (2): tensorflow_ReLU()
          (3): KerasConv2D()
        )
      )
      (out_conv): KerasConv2D()
    )
  )
)
v = None, buffers = None
args = (<tf.Tensor: shape=(1, 512, 33, 33), dtype=float32, numpy=
array([[[[0.        , 0.00517493, 0.00449416, ..., 0.014183...
         [0.        , 0.        , 0.        , ..., 0.        ,
          0.        , 0.        ]]]], dtype=float32)>,)
kwargs = {'context': None, 'scale': '8'}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Decoder(
  (pt_layers): tensorflow_ModuleDict(
    (8): tensorflow_ConvRefiner(
      (block1): tensorflow_...      (2): tensorflow_ReLU()
          (3): KerasConv2D()
        )
      )
      (out_conv): KerasConv2D()
    )
  )
)
v = None, buffers = None
args = (<tf.Tensor: shape=(1, 512, 33, 33), dtype=float32, numpy=
array([[[[0.        , 0.00517493, 0.00449416, ..., 0.014183...
         [0.        , 0.        , 0.        , ..., 0.        ,
          0.        , 0.        ]]]], dtype=float32)>,)
kwargs = {'context': None, 'scale': '8'}, replace_v = False, replace_buffers = False, call_signature = <Signature (features, context=None, scale=None)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Layer, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Layer, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Layer, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Decoder(
  (pt_layers): tensorflow_ModuleDict(
    (8): tensorflow_ConvRefiner(
      (block1): tensorflow_...      (2): tensorflow_ReLU()
          (3): KerasConv2D()
        )
      )
      (out_conv): KerasConv2D()
    )
  )
)
features = <tf.Tensor: shape=(1, 512, 33, 33), dtype=float32, numpy=
array([[[[0.        , 0.00517493, 0.00449416, ..., 0.0141836...],
         [0.        , 0.        , 0.        , ..., 0.        ,
          0.        , 0.        ]]]], dtype=float32)>
context = None, scale = '8'

    def call(self, features, context=None, scale=None):
        from ....ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            tensorflow_cat_frnt,
        )
        from ....ivy.functional.backends.tensorflow.general import tensorflow_get_item
    
        if context is not None:
            features = tensorflow_cat_frnt((features, context), dim=1)
>       stuff = tensorflow_get_item(self.pt_layers, scale)(features)

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/dedode/decoder.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_ConvRefiner(
  (block1): tensorflow_Sequential(
    (0): KerasConv2D()
    (1): KerasBatchNorm2D()
    (2):...  (1): KerasBatchNorm2D()
      (2): tensorflow_ReLU()
      (3): KerasConv2D()
    )
  )
  (out_conv): KerasConv2D()
)
args = (<tf.Tensor: shape=(1, 512, 33, 33), dtype=float32, numpy=
array([[[[0.        , 0.00517493, 0.00449416, ..., 0.014183...
         [0.        , 0.        , 0.        , ..., 0.        ,
          0.        , 0.        ]]]], dtype=float32)>,)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x55d9aad9f330, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...function='__call__', code_context=['                    outputs = super().__call__(*args, **kwargs)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_ConvRefiner(
  (block1): tensorflow_Sequential(
    (0): KerasConv2D()
    (1): KerasBatchNorm2D()
    (2):...  (1): KerasBatchNorm2D()
      (2): tensorflow_ReLU()
      (3): KerasConv2D()
    )
  )
  (out_conv): KerasConv2D()
)
v = None, buffers = None
args = (<tf.Tensor: shape=(1, 512, 33, 33), dtype=float32, numpy=
array([[[[0.        , 0.00517493, 0.00449416, ..., 0.014183...
         [0.        , 0.        , 0.        , ..., 0.        ,
          0.        , 0.        ]]]], dtype=float32)>,)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_ConvRefiner(
  (block1): tensorflow_Sequential(
    (0): KerasConv2D()
    (1): KerasBatchNorm2D()
    (2):...  (1): KerasBatchNorm2D()
      (2): tensorflow_ReLU()
      (3): KerasConv2D()
    )
  )
  (out_conv): KerasConv2D()
)
v = None, buffers = None
args = (<tf.Tensor: shape=(1, 512, 33, 33), dtype=float32, numpy=
array([[[[0.        , 0.00517493, 0.00449416, ..., 0.014183...
         [0.        , 0.        , 0.        , ..., 0.        ,
          0.        , 0.        ]]]], dtype=float32)>,)
kwargs = {}, replace_v = False, replace_buffers = False, call_signature = <Signature (feats)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Layer, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Layer, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Layer, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_ConvRefiner(
  (block1): tensorflow_Sequential(
    (0): KerasConv2D()
    (1): KerasBatchNorm2D()
    (2):...  (1): KerasBatchNorm2D()
      (2): tensorflow_ReLU()
      (3): KerasConv2D()
    )
  )
  (out_conv): KerasConv2D()
)
feats = <tf.Tensor: shape=(1, 512, 33, 33), dtype=float32, numpy=
array([[[[0.        , 0.00517493, 0.00449416, ..., 0.0141836...],
         [0.        , 0.        , 0.        , ..., 0.        ,
          0.        , 0.        ]]]], dtype=float32)>

    def call(self, feats):
        from ....ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
    
        b, c, hs, ws = tensorflow_shape_frnt_(feats)
>       x0 = self.block1(feats)

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/dedode/decoder.py:298: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Sequential(
  (0): KerasConv2D()
  (1): KerasBatchNorm2D()
  (2): tensorflow_ReLU()
  (3): KerasConv2D()
)
args = (<tf.Tensor: shape=(1, 512, 33, 33), dtype=float32, numpy=
array([[[[0.        , 0.00517493, 0.00449416, ..., 0.014183...
         [0.        , 0.        , 0.        , ..., 0.        ,
          0.        , 0.        ]]]], dtype=float32)>,)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x7f4c968583e0, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...function='__call__', code_context=['                    outputs = super().__call__(*args, **kwargs)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Sequential(
  (0): KerasConv2D()
  (1): KerasBatchNorm2D()
  (2): tensorflow_ReLU()
  (3): KerasConv2D()
), v = None, buffers = None
args = (<tf.Tensor: shape=(1, 512, 33, 33), dtype=float32, numpy=
array([[[[0.        , 0.00517493, 0.00449416, ..., 0.014183...
         [0.        , 0.        , 0.        , ..., 0.        ,
          0.        , 0.        ]]]], dtype=float32)>,)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Sequential(
  (0): KerasConv2D()
  (1): KerasBatchNorm2D()
  (2): tensorflow_ReLU()
  (3): KerasConv2D()
), v = None, buffers = None
args = (<tf.Tensor: shape=(1, 512, 33, 33), dtype=float32, numpy=
array([[[[0.        , 0.00517493, 0.00449416, ..., 0.014183...
         [0.        , 0.        , 0.        , ..., 0.        ,
          0.        , 0.        ]]]], dtype=float32)>,)
kwargs = {}, replace_v = False, replace_buffers = False, call_signature = <Signature (input)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Layer, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Layer, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Layer, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Sequential(
  (0): KerasConv2D()
  (1): KerasBatchNorm2D()
  (2): tensorflow_ReLU()
  (3): KerasConv2D()
)
input = <tf.Tensor: shape=(1, 33, 33, 512), dtype=float32, numpy=
array([[[[-4.15515155e-03, -7.68294791e-04,  4.50568413e-03,...17734e-03, -7.88149016e-04, ...,
           1.17538148e-03,  8.22526868e-04,  4.08924371e-03]]]],
      dtype=float32)>

    def call(self, input):
        for i, module in enumerate(self):
>           input = module(input)

ivy_transpiled_outputs/tensorflow_outputs/torch/nn/modules/container.py:199: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = KerasBatchNorm2D()
args = (<tf.Tensor: shape=(1, 33, 33, 512), dtype=float32, numpy=
array([[[[-4.15515155e-03, -7.68294791e-04,  4.50568413e-03...734e-03, -7.88149016e-04, ...,
           1.17538148e-03,  8.22526868e-04,  4.08924371e-03]]]],
      dtype=float32)>,)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x55d8ec2a0500, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...function='__call__', code_context=['                    outputs = super().__call__(*args, **kwargs)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = KerasBatchNorm2D()
args = (<tf.Tensor: shape=(1, 33, 33, 512), dtype=float32, numpy=
array([[[[-4.15515155e-03, -7.68294791e-04,  4.50568413e-03...734e-03, -7.88149016e-04, ...,
           1.17538148e-03,  8.22526868e-04,  4.08924371e-03]]]],
      dtype=float32)>,)
kwargs = {}

    @store_frame_info
    def __call__(self, *args, **kwargs):
        if not self.built:
>           res = super().__call__(*args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful_layers.py:1010: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = KerasBatchNorm2D(), input_shape = (1, 33, 33, 512)

    def build(self, input_shape):
        _, ch, _, _ = input_shape
        if (
            not self.built
            and self.axis == -1
            and os.environ.get("DATA_FORMAT", "channels_first") == "channels_first"
        ):
            order = (0, 2, 3, 1)
            new_shape = tuple(input_shape[i] for i in order)
            input_shape = tf.TensorShape(new_shape)
    
>       super().build(input_shape)
E       IndexError: Exception encountered when calling tensorflow_Sequential.call().
E       
E       [1mtuple index out of range[0m
E       
E       Arguments received by tensorflow_Sequential.call():
E         • input=tf.Tensor(shape=(1, 512, 33, 33), dtype=float32)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful_layers.py:1030: IndexError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.DeDoDe
----------------------------------------------------------------------------------------- Captured stderr call -----------------------------------------------------------------------------------------
Downloading: "https://dl.fbaipublicfiles.com/dinov2/dinov2_vitl14/dinov2_vitl14_pretrain.pth" to /root/.cache/torch/hub/checkpoints/dinov2_vitl14_pretrain.pth

  0%|          | 0.00/1.13G [00:00<?, ?B/s]
  2%|▏         | 27.2M/1.13G [00:00<00:04, 285MB/s]
  5%|▍         | 57.5M/1.13G [00:00<00:03, 304MB/s]
  8%|▊         | 90.6M/1.13G [00:00<00:03, 322MB/s]
 10%|█         | 121M/1.13G [00:00<00:03, 312MB/s] 
 14%|█▎        | 158M/1.13G [00:00<00:03, 335MB/s]
 16%|█▋        | 190M/1.13G [00:00<00:03, 318MB/s]
 19%|█▉        | 220M/1.13G [00:00<00:03, 313MB/s]
 22%|██▏       | 251M/1.13G [00:00<00:03, 317MB/s]
 25%|██▍       | 290M/1.13G [00:00<00:02, 343MB/s]
 28%|██▊       | 327M/1.13G [00:01<00:02, 357MB/s]
 31%|███       | 361M/1.13G [00:01<00:02, 353MB/s]
 34%|███▍      | 395M/1.13G [00:01<00:02, 347MB/s]
 37%|███▋      | 428M/1.13G [00:01<00:02, 330MB/s]
 40%|███▉      | 460M/1.13G [00:01<00:02, 327MB/s]
 43%|████▎     | 494M/1.13G [00:01<00:02, 335MB/s]
 45%|████▌     | 526M/1.13G [00:01<00:02, 332MB/s]
 48%|████▊     | 561M/1.13G [00:01<00:01, 342MB/s]
 51%|█████▏    | 596M/1.13G [00:01<00:01, 350MB/s]
 54%|█████▍    | 630M/1.13G [00:01<00:01, 352MB/s]
 57%|█████▋    | 664M/1.13G [00:02<00:01, 347MB/s]
 60%|██████    | 698M/1.13G [00:02<00:01, 348MB/s]
 63%|██████▎   | 731M/1.13G [00:02<00:01, 342MB/s]
 66%|██████▌   | 764M/1.13G [00:02<00:01, 341MB/s]
 69%|██████▊   | 796M/1.13G [00:02<00:01, 340MB/s]
 71%|███████▏  | 829M/1.13G [00:02<00:01, 342MB/s]
 74%|███████▍  | 862M/1.13G [00:02<00:00, 343MB/s]
 77%|███████▋  | 896M/1.13G [00:02<00:00, 347MB/s]
 80%|████████  | 929M/1.13G [00:02<00:00, 342MB/s]
 83%|████████▎ | 962M/1.13G [00:02<00:00, 341MB/s]
 86%|████████▌ | 994M/1.13G [00:03<00:00, 332MB/s]
 89%|████████▊ | 1.01G/1.13G [00:03<00:00, 341MB/s]
 91%|█████████▏| 1.04G/1.13G [00:03<00:00, 343MB/s]
 94%|█████████▍| 1.07G/1.13G [00:03<00:00, 340MB/s]
 97%|█████████▋| 1.10G/1.13G [00:03<00:00, 341MB/s]
100%|█████████▉| 1.13G/1.13G [00:03<00:00, 342MB/s]
100%|██████████| 1.13G/1.13G [00:03<00:00, 337MB/s]
2024-10-18 15:01:38.912616: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 411041792 exceeds 10% of free system memory.
2024-10-18 15:01:39.251451: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 411041792 exceeds 10% of free system memory.
2024-10-18 15:01:39.861126: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 411041792 exceeds 10% of free system memory.
2024-10-18 15:01:39.958149: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 411041792 exceeds 10% of free system memory.
2024-10-18 15:01:40.121451: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 411041792 exceeds 10% of free system memory.
___________________________________________________________________________________ test_DISK[tensorflow-s2s-False] ____________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_DISK(target_framework, mode, backend_compile):
        print("kornia.feature.DISK")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target_framework)
    
        x = torch.rand(1, 3, 256, 256)
        transpiled_x = _nest_torch_tensor_to_new_framework(x, target_framework)
    
        model = kornia.feature.DISK()
        torch_out = model(x)
    
        transpiled_model = transpiled_kornia.feature.DISK()
        if target_framework == "tensorflow":
            # build the layers
>           transpiled_model(transpiled_x)

kornia/test_feature5.py:211: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_DISK(
  (unet): tensorflow_Unet(
    (path_down): tensorflow_ModuleList(
      (0): tensorflow_ThinUnetDown...): tensorflow_PReLU()
          (2): tensorflow_Sequential()
          (3): KerasConv2D()
        )
      )
    )
  )
)
args = (<tf.Tensor: shape=(1, 3, 256, 256), dtype=float32, numpy=
array([[[[0.5089304 , 0.4098404 , 0.527982  , ..., 0.368288...
         [0.1002059 , 0.78155535, 0.7770803 , ..., 0.35324663,
          0.4615149 , 0.4155228 ]]]], dtype=float32)>,)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x7f4c96d9b300, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...ode_context=['        return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_DISK(
  (unet): tensorflow_Unet(
    (path_down): tensorflow_ModuleList(
      (0): tensorflow_ThinUnetDow...,
         [0.1002059 , 0.78155535, 0.7770803 , ..., 0.35324663,
          0.4615149 , 0.4155228 ]]]], dtype=float32)>)
kwargs = {}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_DISK(
  (unet): tensorflow_Unet(
    (path_down): tensorflow_ModuleList(
      (0): tensorflow_ThinUnetDown...): tensorflow_PReLU()
          (2): tensorflow_Sequential()
          (3): KerasConv2D()
        )
      )
    )
  )
)
v = None, buffers = None
args = (<tf.Tensor: shape=(1, 3, 256, 256), dtype=float32, numpy=
array([[[[0.5089304 , 0.4098404 , 0.527982  , ..., 0.368288...
         [0.1002059 , 0.78155535, 0.7770803 , ..., 0.35324663,
          0.4615149 , 0.4155228 ]]]], dtype=float32)>,)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:2017: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_DISK(
  (unet): tensorflow_Unet(
    (path_down): tensorflow_ModuleList(
      (0): tensorflow_ThinUnetDow...,
         [0.1002059 , 0.78155535, 0.7770803 , ..., 0.35324663,
          0.4615149 , 0.4155228 ]]]], dtype=float32)>)
kwargs = {'buffers': None, 'v': None}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_DISK(
  (unet): tensorflow_Unet(
    (path_down): tensorflow_ModuleList(
      (0): tensorflow_ThinUnetDown...): tensorflow_PReLU()
          (2): tensorflow_Sequential()
          (3): KerasConv2D()
        )
      )
    )
  )
)
v = None, buffers = None
args = (<tf.Tensor: shape=(1, 3, 256, 256), dtype=float32, numpy=
array([[[[0.5089304 , 0.4098404 , 0.527982  , ..., 0.368288...
         [0.1002059 , 0.78155535, 0.7770803 , ..., 0.35324663,
          0.4615149 , 0.4155228 ]]]], dtype=float32)>,)
kwargs = {}
first_arr = <tf.Tensor: shape=(1, 3, 256, 256), dtype=float32, numpy=
array([[[[0.5089304 , 0.4098404 , 0.527982  , ..., 0.3682884...],
         [0.1002059 , 0.78155535, 0.7770803 , ..., 0.35324663,
          0.4615149 , 0.4155228 ]]]], dtype=float32)>
replace_v = False, replace_buffers = False, call_signature = <Signature (images, n=None, window_size=5, score_threshold=0.0, pad_if_not_divisible=False)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Model, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Model, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Model, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1787: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_DISK(
  (unet): tensorflow_Unet(
    (path_down): tensorflow_ModuleList(
      (0): tensorflow_ThinUnetDow... tensorflow_PReLU()
          (2): tensorflow_Sequential()
          (3): KerasConv2D()
        )
      )
    )
  )
),)
kwargs = {'images': <tf.Tensor: shape=(1, 3, 256, 256), dtype=float32, numpy=
array([[[[0.5089304 , 0.4098404 , 0.527982  , ......,
         [0.1002059 , 0.78155535, 0.7770803 , ..., 0.35324663,
          0.4615149 , 0.4155228 ]]]], dtype=float32)>}

    @wraps(fn)
    def error_handler(*args, **kwargs):
        if not is_traceback_filtering_enabled():
            return fn(*args, **kwargs)
    
        filtered_tb = None
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            filtered_tb = _process_traceback_frames(e.__traceback__)
            # To get the full stack trace, call:
            # `keras.config.disable_traceback_filtering()`
>           raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/keras/src/utils/traceback_utils.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_DISK(
  (unet): tensorflow_Unet(
    (path_down): tensorflow_ModuleList(
      (0): tensorflow_ThinUnetDown...): tensorflow_PReLU()
          (2): tensorflow_Sequential()
          (3): KerasConv2D()
        )
      )
    )
  )
)
images = <tf.Tensor: shape=(1, 3, 256, 256), dtype=float32, numpy=
array([[[[0.5089304 , 0.4098404 , 0.527982  , ..., 0.3682884...],
         [0.1002059 , 0.78155535, 0.7770803 , ..., 0.35324663,
          0.4615149 , 0.4155228 ]]]], dtype=float32)>
n = None, window_size = 5, score_threshold = 0.0, pad_if_not_divisible = False

    def call(
        self,
        images,
        n=None,
        window_size=5,
        score_threshold=0.0,
        pad_if_not_divisible=False,
    ):
        from ....ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ....ivy.functional.backends.tensorflow.general import tensorflow_get_item
        from ....ivy.functional.frontends.torch.nn.functional.vision_functions import (
            tensorflow_pad_frnt,
        )
        from .detector import tensorflow_heatmap_to_keypoints
    
        B = tensorflow_shape_frnt_(images)[0]
        if pad_if_not_divisible:
            h, w = (
                tensorflow_shape_frnt_(images)[2:][0],
                tensorflow_shape_frnt_(images)[2:][1],
            )
            pd_h = 16 - h % 16 if h % 16 > 0 else 0
            pd_w = 16 - w % 16 if w % 16 > 0 else 0
            images = tensorflow_pad_frnt(images, (0, pd_w, 0, pd_h), value=0.0)
>       heatmaps, descriptors = self.heatmap_and_dense_descriptors(images)

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/disk/disk.py:99: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_DISK(
  (unet): tensorflow_Unet(
    (path_down): tensorflow_ModuleList(
      (0): tensorflow_ThinUnetDown...): tensorflow_PReLU()
          (2): tensorflow_Sequential()
          (3): KerasConv2D()
        )
      )
    )
  )
)
images = <tf.Tensor: shape=(1, 3, 256, 256), dtype=float32, numpy=
array([[[[0.5089304 , 0.4098404 , 0.527982  , ..., 0.3682884...],
         [0.1002059 , 0.78155535, 0.7770803 , ..., 0.35324663,
          0.4615149 , 0.4155228 ]]]], dtype=float32)>

    def heatmap_and_dense_descriptors(self, images):
        from ....ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ....ivy.functional.backends.tensorflow.general import tensorflow_get_item
    
>       unet_output = self.unet(images)

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/disk/disk.py:62: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Unet(
  (path_down): tensorflow_ModuleList(
    (0): tensorflow_ThinUnetDownBlock(
      (0): tensorflow_Se...d()
        (1): tensorflow_PReLU()
        (2): tensorflow_Sequential()
        (3): KerasConv2D()
      )
    )
  )
)
args = (<tf.Tensor: shape=(1, 3, 256, 256), dtype=float32, numpy=
array([[[[0.5089304 , 0.4098404 , 0.527982  , ..., 0.368288...
         [0.1002059 , 0.78155535, 0.7770803 , ..., 0.35324663,
          0.4615149 , 0.4155228 ]]]], dtype=float32)>,)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x7f4cb41ed9a0, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...ls.py', lineno=117, function='error_handler', code_context=['            return fn(*args, **kwargs)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Unet(
  (path_down): tensorflow_ModuleList(
    (0): tensorflow_ThinUnetDownBlock(
      (0): tensorflow_Se...d()
        (1): tensorflow_PReLU()
        (2): tensorflow_Sequential()
        (3): KerasConv2D()
      )
    )
  )
)
v = None, buffers = None
args = (<tf.Tensor: shape=(1, 3, 256, 256), dtype=float32, numpy=
array([[[[0.5089304 , 0.4098404 , 0.527982  , ..., 0.368288...
         [0.1002059 , 0.78155535, 0.7770803 , ..., 0.35324663,
          0.4615149 , 0.4155228 ]]]], dtype=float32)>,)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Unet(
  (path_down): tensorflow_ModuleList(
    (0): tensorflow_ThinUnetDownBlock(
      (0): tensorflow_Se...d()
        (1): tensorflow_PReLU()
        (2): tensorflow_Sequential()
        (3): KerasConv2D()
      )
    )
  )
)
v = None, buffers = None
args = (<tf.Tensor: shape=(1, 3, 256, 256), dtype=float32, numpy=
array([[[[0.5089304 , 0.4098404 , 0.527982  , ..., 0.368288...
         [0.1002059 , 0.78155535, 0.7770803 , ..., 0.35324663,
          0.4615149 , 0.4155228 ]]]], dtype=float32)>,)
kwargs = {}, replace_v = False, replace_buffers = False, call_signature = <Signature (inp)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Layer, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Layer, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Layer, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Unet(
  (path_down): tensorflow_ModuleList(
    (0): tensorflow_ThinUnetDownBlock(
      (0): tensorflow_Se...d()
        (1): tensorflow_PReLU()
        (2): tensorflow_Sequential()
        (3): KerasConv2D()
      )
    )
  )
)
inp = <tf.Tensor: shape=(1, 3, 256, 256), dtype=float32, numpy=
array([[[[0.5089304 , 0.4098404 , 0.527982  , ..., 0.3682884...],
         [0.1002059 , 0.78155535, 0.7770803 , ..., 0.35324663,
          0.4615149 , 0.4155228 ]]]], dtype=float32)>

    def call(self, inp):
        from .....ivy.functional.frontends.torch.tensor import tensorflow_size_frnt_
    
        if tensorflow_size_frnt_(inp, 1) != self.in_features:
            fmt = "Expected {} feature channels in input, got {}"
            msg = fmt.format(self.in_features, tensorflow_size_frnt_(inp, 1))
            raise ValueError(msg)
        input_size_divisor = 2 ** len(self.up)
        if (
            tensorflow_size_frnt_(inp, 2) % input_size_divisor != 0
            or tensorflow_size_frnt_(inp, 3) % input_size_divisor != 0
        ):
            raise ValueError(
                f"Input image shape must be divisible by {input_size_divisor} (got {tensorflow_size_frnt_(inp)}). This is not inherent to DISK, but to the U-Net architecture used in pretrained models. Please pad if necessary."
            )
        features = [inp]
        for layer in self.path_down:
>           features.append(layer(features[-1]))

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/disk/_unets/unet.py:92: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_ThinUnetDownBlock(
  (0): tensorflow_TrivialDownsample()
  (1): tensorflow_Conv(
    (0): tensorflow_InstanceNorm2d()
    (1): tensorflow_PReLU()
    (2): tensorflow_Sequential()
    (3): KerasConv2D()
  )
)
args = (<tf.Tensor: shape=(1, 16, 256, 256), dtype=float32, numpy=
array([[[[-0.11386427, -0.12716305, -0.18081813, ..., -0.1...    [-0.022462  , -0.12947467,  0.13716345, ...,  0.19039659,
           0.1306257 ,  0.08804227]]]], dtype=float32)>,)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x7f4cb41ed430, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...function='__call__', code_context=['                    outputs = super().__call__(*args, **kwargs)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_ThinUnetDownBlock(
  (0): tensorflow_TrivialDownsample()
  (1): tensorflow_Conv(
    (0): tensorflow_InstanceNorm2d()
    (1): tensorflow_PReLU()
    (2): tensorflow_Sequential()
    (3): KerasConv2D()
  )
)
v = None, buffers = None
args = (<tf.Tensor: shape=(1, 16, 256, 256), dtype=float32, numpy=
array([[[[-0.11386427, -0.12716305, -0.18081813, ..., -0.1...    [-0.022462  , -0.12947467,  0.13716345, ...,  0.19039659,
           0.1306257 ,  0.08804227]]]], dtype=float32)>,)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_ThinUnetDownBlock(
  (0): tensorflow_TrivialDownsample()
  (1): tensorflow_Conv(
    (0): tensorflow_InstanceNorm2d()
    (1): tensorflow_PReLU()
    (2): tensorflow_Sequential()
    (3): KerasConv2D()
  )
)
v = None, buffers = None
args = (<tf.Tensor: shape=(1, 16, 256, 256), dtype=float32, numpy=
array([[[[-0.11386427, -0.12716305, -0.18081813, ..., -0.1...    [-0.022462  , -0.12947467,  0.13716345, ...,  0.19039659,
           0.1306257 ,  0.08804227]]]], dtype=float32)>,)
kwargs = {}, replace_v = False, replace_buffers = False, call_signature = <Signature (input)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Layer, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Layer, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Layer, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_ThinUnetDownBlock(
  (0): tensorflow_TrivialDownsample()
  (1): tensorflow_Conv(
    (0): tensorflow_InstanceNorm2d()
    (1): tensorflow_PReLU()
    (2): tensorflow_Sequential()
    (3): KerasConv2D()
  )
)
input = <tf.Tensor: shape=(1, 16, 128, 128), dtype=float32, numpy=
array([[[[-0.07635118, -0.11035389, -0.08761296, ..., -0.08...      [ 0.13922134,  0.22605136,  0.1365703 , ...,  0.16436075,
           0.29203305,  0.20429173]]]], dtype=float32)>

    def call(self, input):
        for i, module in enumerate(self):
>           input = module(input)

ivy_transpiled_outputs/tensorflow_outputs/torch/nn/modules/container.py:199: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Conv(
  (0): tensorflow_InstanceNorm2d()
  (1): tensorflow_PReLU()
  (2): tensorflow_Sequential()
  (3): KerasConv2D()
)
args = (<tf.Tensor: shape=(1, 16, 128, 128), dtype=float32, numpy=
array([[[[-0.07635118, -0.11035389, -0.08761296, ..., -0.0...    [ 0.13922134,  0.22605136,  0.1365703 , ...,  0.16436075,
           0.29203305,  0.20429173]]]], dtype=float32)>,)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x55d9a172a950, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...function='__call__', code_context=['                    outputs = super().__call__(*args, **kwargs)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Conv(
  (0): tensorflow_InstanceNorm2d()
  (1): tensorflow_PReLU()
  (2): tensorflow_Sequential()
  (3): KerasConv2D()
), v = None, buffers = None
args = (<tf.Tensor: shape=(1, 16, 128, 128), dtype=float32, numpy=
array([[[[-0.07635118, -0.11035389, -0.08761296, ..., -0.0...    [ 0.13922134,  0.22605136,  0.1365703 , ...,  0.16436075,
           0.29203305,  0.20429173]]]], dtype=float32)>,)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Conv(
  (0): tensorflow_InstanceNorm2d()
  (1): tensorflow_PReLU()
  (2): tensorflow_Sequential()
  (3): KerasConv2D()
), v = None, buffers = None
args = (<tf.Tensor: shape=(1, 16, 128, 128), dtype=float32, numpy=
array([[[[-0.07635118, -0.11035389, -0.08761296, ..., -0.0...    [ 0.13922134,  0.22605136,  0.1365703 , ...,  0.16436075,
           0.29203305,  0.20429173]]]], dtype=float32)>,)
kwargs = {}, replace_v = False, replace_buffers = False, call_signature = <Signature (input)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Layer, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Layer, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Layer, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Conv(
  (0): tensorflow_InstanceNorm2d()
  (1): tensorflow_PReLU()
  (2): tensorflow_Sequential()
  (3): KerasConv2D()
)
input = <tf.Tensor: shape=(1, 128, 128, 16), dtype=float32, numpy=
array([[[[-3.2733786e+00,  4.1153002e-01,  2.7678711e+00, ....2.4058106e+00, -2.2807369e+00, ...,
           1.6065272e+00,  1.8394227e+00, -1.2292967e+00]]]],
      dtype=float32)>

    def call(self, input):
        for i, module in enumerate(self):
>           input = module(input)

ivy_transpiled_outputs/tensorflow_outputs/torch/nn/modules/container.py:199: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_PReLU()
args = (<tf.Tensor: shape=(1, 128, 128, 16), dtype=float32, numpy=
array([[[[-3.2733786e+00,  4.1153002e-01,  2.7678711e+00, ...4058106e+00, -2.2807369e+00, ...,
           1.6065272e+00,  1.8394227e+00, -1.2292967e+00]]]],
      dtype=float32)>,)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x55d8ec538350, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...function='__call__', code_context=['                    outputs = super().__call__(*args, **kwargs)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_PReLU(), v = None, buffers = None
args = (<tf.Tensor: shape=(1, 128, 128, 16), dtype=float32, numpy=
array([[[[-3.2733786e+00,  4.1153002e-01,  2.7678711e+00, ...4058106e+00, -2.2807369e+00, ...,
           1.6065272e+00,  1.8394227e+00, -1.2292967e+00]]]],
      dtype=float32)>,)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_PReLU(), v = None, buffers = None
args = (<tf.Tensor: shape=(1, 128, 128, 16), dtype=float32, numpy=
array([[[[-3.2733786e+00,  4.1153002e-01,  2.7678711e+00, ...4058106e+00, -2.2807369e+00, ...,
           1.6065272e+00,  1.8394227e+00, -1.2292967e+00]]]],
      dtype=float32)>,)
kwargs = {}, replace_v = False, replace_buffers = False, call_signature = <Signature (input)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Layer, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Layer, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Layer, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_PReLU(), args = ()
kwargs = {'input': <tf.Tensor: shape=(1, 128, 128, 16), dtype=float32, numpy=
array([[[[-3.2733786e+00,  4.1153002e-01,  2.7678....4058106e+00, -2.2807369e+00, ...,
           1.6065272e+00,  1.8394227e+00, -1.2292967e+00]]]],
      dtype=float32)>}
tensorflow_get_item = <function tensorflow_get_item at 0x7f4c947b23b0>, tensorflow_set_item = <function tensorflow_set_item at 0x7f4c947b2560>, DATA_FORMAT = 'channels_last'
fn_args_and_kwargs = {'input': <tf.Tensor: shape=(1, 128, 128, 16), dtype=float32, numpy=
array([[[[-3.2733786e+00,  4.1153002e-01,  2.7678....4058106e+00, -2.2807369e+00, ...,
           1.6065272e+00,  1.8394227e+00, -1.2292967e+00]]]],
      dtype=float32)>}
conv_block_start = <function tensorflow_handle_transpose_in_input_and_output.<locals>.transpose_wrapper.<locals>.<lambda> at 0x7f4c95d8b1c0>, next_call_in_seq = tensorflow_Sequential()
conv_block_continued = tensorflow_Sequential(), arg_name = 'input'

    @functools.wraps(fn)
    def transpose_wrapper(self, *args, **kwargs):
        from ..functional.backends.tensorflow.general import tensorflow_get_item
        from ..functional.backends.tensorflow.general import tensorflow_set_item
    
        DATA_FORMAT = os.environ.get("DATA_FORMAT", "channels_first")
        kwargs_call = {
            key: val
            for key, val in kwargs.items()
            if key not in dict(original_signature.parameters)
        }
        fn_args_and_kwargs = {
            key: val for key, val in kwargs.items() if key not in kwargs_call
        }
        fn_args_and_kwargs.update(dict(zip(fn.__code__.co_varnames[1:], args)))
        conv_block_start = lambda f: any(
            substr in f.__qualname__
            for substr in CONV_FUNCS
            + NORM_FUNCS
            + POOL_FUNCS
            + KERAS_CONV_FUNCS
            + KERAS_NORM_FUNCS
            + KERAS_POOL_FUNCS
            + FLAX_CONV_FUNCS
            + FLAX_NORM_FUNCS
            + FLAX_POOL_FUNCS
        )
        next_call_in_seq = tensorflow_get_next_func(self)
        name_of_next_call = (
            next_call_in_seq.__class__.__name__
            if hasattr(next_call_in_seq, "__class__")
            else ""
        )
        conv_block_continued = next_call_in_seq and any(
            substr in name_of_next_call for substr in CONV_BLOCK_FNS
        )
        arg_name = "input" if "input" in fn_args_and_kwargs else "inputs"
        if DATA_FORMAT == "channels_first" and conv_block_start(self.__class__):
            input = tensorflow_get_item(fn_args_and_kwargs, arg_name)
            if len(input.shape) > 4:
                transpose = tensorflow_TransposeType.CONV3D
            elif len(input.shape) > 3:
                transpose = tensorflow_TransposeType.CONV2D
            elif len(input.shape) > 2:
                transpose = tensorflow_TransposeType.CONV1D
            else:
                transpose = tensorflow_TransposeType.NO_TRANSPOSE
            fn_args_and_kwargs = tensorflow_set_item(
                fn_args_and_kwargs,
                arg_name,
                tensorflow_apply_transpose(input, transpose=transpose, pt_to_tf=True),
            )
            DATA_FORMAT = "channels_last"
            os.environ = tensorflow_set_item(os.environ, "DATA_FORMAT", DATA_FORMAT)
>       res = fn(self, **fn_args_and_kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:414: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_PReLU()
input = <tf.Tensor: shape=(1, 128, 128, 16), dtype=float32, numpy=
array([[[[-3.2733786e+00,  4.1153002e-01,  2.7678711e+00, ....2.4058106e+00, -2.2807369e+00, ...,
           1.6065272e+00,  1.8394227e+00, -1.2292967e+00]]]],
      dtype=float32)>

    @tensorflow_handle_transpose_in_input_and_output
    def call(self, input):
        from ....ivy.functional.frontends.torch.nn.functional.non_linear_activation_functions import (
            tensorflow_prelu_frnt,
        )
    
>       return tensorflow_prelu_frnt(input, self.weight)

ivy_transpiled_outputs/tensorflow_outputs/torch/nn/modules/activation.py:78: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = <tf.Tensor: shape=(1, 128, 128, 16), dtype=float32, numpy=
array([[[[-3.2733786e+00,  4.1153002e-01,  2.7678711e+00, ....2.4058106e+00, -2.2807369e+00, ...,
           1.6065272e+00,  1.8394227e+00, -1.2292967e+00]]]],
      dtype=float32)>
weight = <KerasVariable shape=(16,), dtype=float32, path=variable_665>

    def tensorflow_prelu_frnt(input, weight):
        from ...tensor import tensorflow_ndim_frnt_
        from ...tensor import tensorflow_shape_frnt_
        from ......data_classes.array.manipulation import tensorflow_expand_dims_bknd_
        from .....backends.tensorflow.elementwise import tensorflow_add
        from .....backends.tensorflow.elementwise import tensorflow_maximum
        from .....backends.tensorflow.elementwise import tensorflow_multiply
        from .....backends.tensorflow.elementwise import tensorflow_minimum
    
        input_dim = tensorflow_ndim_frnt_(input)
        weight_dim = tensorflow_ndim_frnt_(weight)
        if weight_dim == 0:
            pass
        elif weight_dim == 1:
            if input_dim >= 2:
>               assert (
                    tensorflow_shape_frnt_(weight)[0] == tensorflow_shape_frnt_(input)[1]
                ), "Weight size must match input channels"
E               AssertionError: Exception encountered when calling tensorflow_PReLU.call().
E               
E               [1mWeight size must match input channels[0m
E               
E               Arguments received by tensorflow_PReLU.call():
E                 • input=tf.Tensor(shape=(1, 128, 128, 16), dtype=float32)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/nn/functional/non_linear_activation_functions.py:61: AssertionError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.DISK
----------------------------------------------------------------------------------------- Captured stderr call -----------------------------------------------------------------------------------------
/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/torch/nn/modules/instancenorm.py:134: UserWarning: input's size at dim=1 does not match num_features. You can silence this warning by not passing in num_features, which is not used because affine=False
  warnings.warn(
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/test_feature5.py::test_LAFOrienter[tensorflow-s2s-False] - ValueError: could not broadcast input array from shape (1,5) into shape (5,1,1)
FAILED kornia/test_feature5.py::test_PatchDominantGradientOrientation[tensorflow-s2s-False] - ValueError: could not broadcast input array from shape (1,5) into shape (5,1,1)
FAILED kornia/test_feature5.py::test_TLU[tensorflow-s2s-False] - tensorflow.python.framework.errors_impl.InvalidArgumentError: Exception encountered when calling tensorflow_TLU.call().
FAILED kornia/test_feature5.py::test_DeDoDe[tensorflow-s2s-False] - IndexError: Exception encountered when calling tensorflow_Sequential.call().
FAILED kornia/test_feature5.py::test_DISK[tensorflow-s2s-False] - AssertionError: Exception encountered when calling tensorflow_PReLU.call().
=============================================================================== 5 failed, 5 passed in 1432.87s (0:23:52) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 17 items

kornia/augmentation/test_augmentation4.py F......F.........                                                                                                                                      [100%]

=============================================================================================== FAILURES ===============================================================================================
___________________________________________________________________________________ test_RandomMosaic[jax-s2s-False] ___________________________________________________________________________________

inp = jax_DType.INT64 | jax_DType.FLOAT16 | jax_DType.FLOAT32 | jax_DType.FLOAT64, query = '2', kwargs = {}

    @functools.wraps(fn)
    def wrapper(inp, query, **kwargs):
        try:
>           res = inp.__getitem__(query)

ivy_transpiled_outputs/jax_outputs/ivy/utils/decorator_utils.py:219: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = jax_DType.INT64 | jax_DType.FLOAT16 | jax_DType.FLOAT32 | jax_DType.FLOAT64, name = '2'

    def __getitem__(cls, name):
>       return cls._member_map_[name]
E       KeyError: '2'

/opt/miniconda/envs/multienv/lib/python3.10/enum.py:432: KeyError

During handling of the above exception, another exception occurred:

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_RandomMosaic(target_framework, mode, backend_compile):
        print("kornia.augmentation.RandomMosaic")
    
        init_args = ((300, 300),)
        init_kwargs = {"data_keys": ["input", "bbox_xyxy"]}
        call_args = (
            torch.randn(8, 3, 224, 224),
            torch.tensor([[
                [70, 5, 150, 100],
                [60, 180, 175, 220],
            ]]).repeat(8, 1, 1),
        )
        call_kwargs = {}
    
>       _test_augmentation_class(
            kornia.augmentation.RandomMosaic,
            target_framework,
            init_args,
            init_kwargs,
            call_args,
            call_kwargs,
            deterministic_output=False,
            backend_compile=backend_compile,
        )

kornia/augmentation/test_augmentation4.py:80: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

augmentation_cls = <class 'kornia.augmentation._2d.mix.mosaic.RandomMosaic'>, target = 'jax', init_args = ((300, 300),), init_kwargs = {'data_keys': ['input', 'bbox_xyxy']}
call_args = (tensor([[[[ 1.0751e+00, -3.4547e-01, -1.6069e+00,  ..., -2.9005e-01,
           -2.9156e+00, -1.2842e+00],
          ...[ 70,   5, 150, 100],
         [ 60, 180, 175, 220]],

        [[ 70,   5, 150, 100],
         [ 60, 180, 175, 220]]]))
call_kwargs = {}, deterministic_output = False, backend_compile = False, tolerance = 0.001

    def _test_augmentation_class(
        augmentation_cls,
        target,
        init_args=(),
        init_kwargs={},
        call_args=(),
        call_kwargs={},
        deterministic_output=True,
        backend_compile=False,
        tolerance=1e-3,
    ):
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, target=target)
        transpiled_cls = eval("transpiled_" + f"{augmentation_cls.__module__}.{augmentation_cls.__name__}")
    
        torch_aug = augmentation_cls(*init_args, **init_kwargs)
        transpiled_init_args = _nest_torch_tensor_to_new_framework(init_args, target)
        transpiled_init_kwargs = _nest_torch_tensor_to_new_framework(init_kwargs, target)
        transpiled_aug = transpiled_cls(*transpiled_init_args, **transpiled_init_kwargs)
    
        # assert dir(torch_aug) == dir(transpiled_aug), f"attributes/methods of transpiled object do not align with the original - orig: {dir(torch_aug)} != transpiled: {dir(transpiled_aug)}"
    
        torch_out = torch_aug(*call_args, **call_kwargs)
        transpiled_call_args = _nest_torch_tensor_to_new_framework(call_args, target)
        transpiled_call_kwargs = _nest_torch_tensor_to_new_framework(call_kwargs, target)
>       transpiled_out = transpiled_aug(*transpiled_call_args, **transpiled_call_kwargs)

kornia/augmentation/test_augmentation4.py:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_RandomMosaic(output_size=(300, 300), mosaic_grid=(2, 2), start_ratio_range=(0.3, 0.7), p=0.7, p_batch=1.0, same_on..._size=(300, 300), min_bbox_size=0.0, padding_mode=constant, resample=bilinear, align_corners=True, cropping_mode=slice)
params = None, data_keys = None
input = (Array([[[[ 1.07510746e+00, -3.45471680e-01, -1.60685515e+00, ...,
          -2.90052503e-01, -2.91564941e+00, -1.2842... 150, 100],
        [ 60, 180, 175, 220]],

       [[ 70,   5, 150, 100],
        [ 60, 180, 175, 220]]], dtype=int64))
tensor = <function jax_tensor_frnt at 0x7fab0fadf2e0>

    def __call__(self, *input, params=None, data_keys=None):
        from ....core._backend import tensor
        from .....ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ....geometry.boxes import jax_Boxes
        from .....ivy.functional.backends.jax.general import jax_get_item
        from ....constants import jax_DType
        from ....core.check import jax_KORNIA_UNWRAP
    
        keys: typing.Any
        if data_keys is None:
            keys = self.data_keys
        else:
            keys = [jax_DataKey.get(inp) for inp in data_keys]
        if params is None:
            in_tensor_idx: typing.Any = keys.index(jax_DataKey.INPUT)
            in_tensor: typing.Any = jax_get_item(input, in_tensor_idx)
            in_tensor = self.transform_tensor(in_tensor)
            self._params = self.forward_parameters(jax_shape_frnt_(in_tensor))
>           self._params.update({"dtype": tensor(jax_DType.get(in_tensor.dtype).value)})

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/_2d/mix/base.py:193: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = jax_DType.INT64 | jax_DType.FLOAT16 | jax_DType.FLOAT32 | jax_DType.FLOAT64, value = dtype('float32')

    @classmethod
    def get(cls, value):
        from ..ivy.functional.backends.jax.general import jax_get_item
        from ..ivy.functional.frontends.torch.tensor import jax_item_frnt_
    
        if isinstance(value, (np.dtype,)):
>           return jax_get_item(cls, str(value).upper()[6:])

ivy_transpiled_outputs/jax_outputs/kornia/constants.py:87: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

inp = jax_DType.INT64 | jax_DType.FLOAT16 | jax_DType.FLOAT32 | jax_DType.FLOAT64, query = '2', kwargs = {}

    @functools.wraps(fn)
    def wrapper(inp, query, **kwargs):
        try:
            res = inp.__getitem__(query)
        except Exception:
>           res = fn(inp, query, **kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/utils/decorator_utils.py:221: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (jax_DType.INT64 | jax_DType.FLOAT16 | jax_DType.FLOAT32 | jax_DType.FLOAT64, '2'), kwargs = {}, handle_mixed_in_backend = True

    @functools.wraps(fn)
    def _handle_partial_mixed_function(*args, **kwargs):
        handle_mixed_in_backend = False
        if not hasattr(fn, "partial_mixed_handler"):
            handle_mixed_in_backend = True
        else:
            compos = getattr(fn, "compos")
            condition = getattr(fn, "partial_mixed_handler")
        if handle_mixed_in_backend or condition(*args, **kwargs):
>           return fn(*args, **kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/func_wrapper.py:160: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = jax_DType.INT64 | jax_DType.FLOAT16 | jax_DType.FLOAT32 | jax_DType.FLOAT64, query = '2'

    @jax_handle_get_item
    @jax_handle_partial_mixed_function
    def jax_get_item(
        x: jax.Array, /, query: Union[jax.Array, Tuple], *, copy: Optional[bool] = None
    ):
        from ...ivy.general import jax_is_array_bknd
        from ...ivy.data_type import jax_is_bool_dtype_bknd
    
        if copy:
            x = x.copy()
        if jax_is_array_bknd(query) and jax_is_bool_dtype_bknd(query):
            if not len(query.shape):
                if not query:
                    return jax.numpy.array([], dtype=x.dtype)
                else:
                    return jax.numpy.expand_dims(x, 0)
            query = jax__mask_to_index(query, x)
        elif isinstance(query, list):
            query = (query,)
>       return x.__getitem__(query)

ivy_transpiled_outputs/jax_outputs/ivy/functional/backends/jax/general.py:86: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = jax_DType.INT64 | jax_DType.FLOAT16 | jax_DType.FLOAT32 | jax_DType.FLOAT64, name = '2'

    def __getitem__(cls, name):
>       return cls._member_map_[name]
E       KeyError: '2'

/opt/miniconda/envs/multienv/lib/python3.10/enum.py:432: KeyError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.RandomMosaic
_________________________________________________________________________________ test_RandomRotation3D[jax-s2s-False] _________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_RandomRotation3D(target_framework, mode, backend_compile):
        print("kornia.augmentation.RandomRotation3D")
    
        init_args = ((15., 20., 20.),)
        init_kwargs = {"p": 1.}
        call_args = (torch.rand(1, 1, 3, 3, 3),)
        call_kwargs = {}
    
>       _test_augmentation_class(
            kornia.augmentation.RandomRotation3D,
            target_framework,
            init_args,
            init_kwargs,
            call_args,
            call_kwargs,
            deterministic_output=False,
            backend_compile=backend_compile,
        )

kornia/augmentation/test_augmentation4.py:220: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

augmentation_cls = <class 'kornia.augmentation._3d.geometric.rotation.RandomRotation3D'>, target = 'jax', init_args = ((15.0, 20.0, 20.0),), init_kwargs = {'p': 1.0}
call_args = (tensor([[[[[0.4124, 0.3532, 0.3209],
           [0.4316, 0.6918, 0.6251],
           [0.5657, 0.0820, 0.4878]],

    ...,

          [[0.3261, 0.3948, 0.9732],
           [0.0287, 0.1028, 0.3718],
           [0.9589, 0.9443, 0.6536]]]]]),)
call_kwargs = {}, deterministic_output = False, backend_compile = False, tolerance = 0.001

    def _test_augmentation_class(
        augmentation_cls,
        target,
        init_args=(),
        init_kwargs={},
        call_args=(),
        call_kwargs={},
        deterministic_output=True,
        backend_compile=False,
        tolerance=1e-3,
    ):
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, target=target)
        transpiled_cls = eval("transpiled_" + f"{augmentation_cls.__module__}.{augmentation_cls.__name__}")
    
        torch_aug = augmentation_cls(*init_args, **init_kwargs)
        transpiled_init_args = _nest_torch_tensor_to_new_framework(init_args, target)
        transpiled_init_kwargs = _nest_torch_tensor_to_new_framework(init_kwargs, target)
        transpiled_aug = transpiled_cls(*transpiled_init_args, **transpiled_init_kwargs)
    
        # assert dir(torch_aug) == dir(transpiled_aug), f"attributes/methods of transpiled object do not align with the original - orig: {dir(torch_aug)} != transpiled: {dir(transpiled_aug)}"
    
        torch_out = torch_aug(*call_args, **call_kwargs)
        transpiled_call_args = _nest_torch_tensor_to_new_framework(call_args, target)
        transpiled_call_kwargs = _nest_torch_tensor_to_new_framework(call_kwargs, target)
>       transpiled_out = transpiled_aug(*transpiled_call_args, **transpiled_call_kwargs)

kornia/augmentation/test_augmentation4.py:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_RandomRotation3D(degrees=(15.0, 20.0, 20.0), p=1.0, p_batch=1.0, same_on_batch=False, resample=bilinear, align_corners=False)
input = Array([[[[[0.41238588, 0.35317838, 0.32094038],
          [0.43163848, 0.6917618 , 0.6251203 ],
          [0.5656899 ,...9 ],
          [0.02867687, 0.10282338, 0.3718452 ],
          [0.9588662 , 0.9443095 , 0.653551  ]]]]], dtype=float32)
params = {'batch_prob': Array([1.], dtype=float32), 'forward_input_shape': Array([1, 1, 3, 3, 3], dtype=int64), 'pitch': Array([-8.851233], dtype=float32), 'roll': Array([7.4675026], dtype=float32), ...}
kwargs = {}, jax_shape_frnt_ = <function jax_shape_frnt_ at 0x7faae8c4c9d0>, jax_set_item = <function jax_set_item at 0x7faae80ab490>, tensor = <function jax_tensor_frnt at 0x7faad4b8c790>
in_tensor = Array([[[[[0.41238588, 0.35317838, 0.32094038],
          [0.43163848, 0.6917618 , 0.6251203 ],
          [0.5656899 ,...9 ],
          [0.02867687, 0.10282338, 0.3718452 ],
          [0.9588662 , 0.9443095 , 0.653551  ]]]]], dtype=float32)
input_shape = ivy.frontends.torch.Size([1, 1, 3, 3, 3]), batch_shape = ivy.frontends.torch.Size([1, 1, 3, 3, 3]), flags = {'align_corners': False, 'resample': <jax_Resample.BILINEAR: 1>}

    def __call__(self, input, params=None, **kwargs):
        from ...ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ...ivy.functional.backends.jax.general import jax_set_item
        from ..core._backend import tensor
    
        in_tensor = self.__unpack_input__(input)
        input_shape = jax_shape_frnt_(in_tensor)
        in_tensor = self.transform_tensor(in_tensor)
        batch_shape = jax_shape_frnt_(in_tensor)
        if params is None:
            params = self.forward_parameters(batch_shape)
        if "batch_prob" not in params:
            params = jax_set_item(params, "batch_prob", tensor([True] * batch_shape[0]))
        params, flags = self._process_kwargs_to_params_and_flags(
            params, self.flags, **kwargs
        )
>       output = self.apply_func(in_tensor, params, flags)

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/base.py:219: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_RandomRotation3D(degrees=(15.0, 20.0, 20.0), p=1.0, p_batch=1.0, same_on_batch=False, resample=bilinear, align_corners=False)
in_tensor = Array([[[[[0.41238588, 0.35317838, 0.32094038],
          [0.43163848, 0.6917618 , 0.6251203 ],
          [0.5656899 ,...9 ],
          [0.02867687, 0.10282338, 0.3718452 ],
          [0.9588662 , 0.9443095 , 0.653551  ]]]]], dtype=float32)
params = {'batch_prob': Array([1.], dtype=float32), 'forward_input_shape': Array([1, 1, 3, 3, 3], dtype=int64), 'pitch': Array([-8.851233], dtype=float32), 'roll': Array([7.4675026], dtype=float32), ...}
flags = {'align_corners': False, 'resample': <jax_Resample.BILINEAR: 1>}

    def apply_func(self, in_tensor, params, flags=None):
        if flags is None:
            flags = self.flags
>       trans_matrix = self.generate_transformation_matrix(in_tensor, params, flags)

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/_3d/base.py:118: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_RandomRotation3D(degrees=(15.0, 20.0, 20.0), p=1.0, p_batch=1.0, same_on_batch=False, resample=bilinear, align_corners=False)
input = Array([[[[[0.41238588, 0.35317838, 0.32094038],
          [0.43163848, 0.6917618 , 0.6251203 ],
          [0.5656899 ,...9 ],
          [0.02867687, 0.10282338, 0.3718452 ],
          [0.9588662 , 0.9443095 , 0.653551  ]]]]], dtype=float32)
params = {'batch_prob': Array([1.], dtype=float32), 'forward_input_shape': Array([1, 1, 3, 3, 3], dtype=int64), 'pitch': Array([-8.851233], dtype=float32), 'roll': Array([7.4675026], dtype=float32), ...}
flags = {'align_corners': False, 'resample': <jax_Resample.BILINEAR: 1>}

    def generate_transformation_matrix(self, input, params, flags):
        from ....ivy.functional.frontends.torch.tensor import jax_any_frnt_
        from ....ivy.functional.frontends.torch.tensor import jax_all_frnt_
        from ....ivy.functional.frontends.torch.tensor import jax_index_put_frnt_
        from ....ivy.functional.backends.jax.general import jax_get_item
    
        batch_prob = params["batch_prob"]
        to_apply = batch_prob > 0.5
        in_tensor = self.transform_tensor(input)
        if not jax_any_frnt_(to_apply):
            trans_matrix = self.identity_matrix(in_tensor)
        elif jax_all_frnt_(to_apply):
>           trans_matrix = self.compute_transformation(
                in_tensor, params=params, flags=flags
            )

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/_3d/base.py:86: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_RandomRotation3D(degrees=(15.0, 20.0, 20.0), p=1.0, p_batch=1.0, same_on_batch=False, resample=bilinear, align_corners=False)
input = Array([[[[[0.41238588, 0.35317838, 0.32094038],
          [0.43163848, 0.6917618 , 0.6251203 ],
          [0.5656899 ,...9 ],
          [0.02867687, 0.10282338, 0.3718452 ],
          [0.9588662 , 0.9443095 , 0.653551  ]]]]], dtype=float32)
params = {'batch_prob': Array([1.], dtype=float32), 'forward_input_shape': Array([1, 1, 3, 3, 3], dtype=int64), 'pitch': Array([-8.851233], dtype=float32), 'roll': Array([7.4675026], dtype=float32), ...}
flags = {'align_corners': False, 'resample': <jax_Resample.BILINEAR: 1>}

    def compute_transformation(self, input, params, flags):
        from .....ivy.functional.frontends.torch.tensor import jax_to_frnt_
        from ....geometry.transform.affwarp import jax__compute_tensor_center3d
        from ....geometry.transform.affwarp import jax__compute_rotation_matrix3d
        from .....ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ....utils.misc import jax_eye_like
        from .....ivy.functional.backends.jax.general import jax_set_item
    
        yaw: typing.Any = jax_to_frnt_(params["yaw"], input)
        pitch: typing.Any = jax_to_frnt_(params["pitch"], input)
        roll: typing.Any = jax_to_frnt_(params["roll"], input)
        center: typing.Any = jax__compute_tensor_center3d(input)
        rotation_mat: typing.Any = jax__compute_rotation_matrix3d(
>           yaw, pitch, roll, center.expand(jax_shape_frnt_(yaw)[0], -1)
        )
E       AttributeError: 'jaxlib.xla_extension.ArrayImpl' object has no attribute 'expand'

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/_3d/geometric/rotation.py:66: AttributeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.RandomRotation3D
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/augmentation/test_augmentation4.py::test_RandomMosaic[jax-s2s-False] - KeyError: '2'
FAILED kornia/augmentation/test_augmentation4.py::test_RandomRotation3D[jax-s2s-False] - AttributeError: 'jaxlib.xla_extension.ArrayImpl' object has no attribute 'expand'
============================================================================== 2 failed, 15 passed in 3224.98s (0:53:44) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 39 items

kornia/test_enhance.py ..............F.............F..........                                                                                                                                   [100%]

=============================================================================================== FAILURES ===============================================================================================
__________________________________________________________________________________ test_equalize_clahe[jax-s2s-False] __________________________________________________________________________________

arrays = []

    def jax_stack(
        arrays: Union[Tuple[jax.Array], List[jax.Array]],
        /,
        *,
        axis: int = 0,
        out: Optional[jax.Array] = None,
    ):
        try:
>           return jax.numpy.stack(arrays, axis=axis)

ivy_transpiled_outputs/jax_outputs/ivy/functional/backends/jax/manipulation.py:125: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

arrays = [], axis = 2, out = None, dtype = None

    def stack(arrays: np.ndarray | Array | Sequence[ArrayLike],
              axis: int = 0, out: None = None, dtype: DTypeLike | None = None) -> Array:
      """Join arrays along a new axis.
    
      JAX implementation of :func:`numpy.stack`.
    
      Args:
        arrays: a sequence of arrays to stack; each must have the same shape. If a
          single array is given it will be treated equivalently to
          `arrays = unstack(arrays)`, but the implementation will avoid explicit
          unstacking.
        axis: specify the axis along which to stack.
        out: unused by JAX
        dtype: optional dtype of the resulting array. If not specified, the dtype
          will be determined via type promotion rules described in :ref:`type-promotion`.
    
      Returns:
        the stacked result.
    
      See also:
        - :func:`jax.numpy.unstack`: inverse of ``stack``.
        - :func:`jax.numpy.concatenate`: concatenation along existing axes.
        - :func:`jax.numpy.vstack`: stack vertically, i.e. along axis 0.
        - :func:`jax.numpy.hstack`: stack horizontally, i.e. along axis 1.
        - :func:`jax.numpy.dstack`: stack depth-wise, i.e. along axis 2.
        - :func:`jax.numpy.column_stack`: stack columns.
    
      Examples:
        >>> x = jnp.array([1, 2, 3])
        >>> y = jnp.array([4, 5, 6])
        >>> jnp.stack([x, y])
        Array([[1, 2, 3],
               [4, 5, 6]], dtype=int32)
        >>> jnp.stack([x, y], axis=1)
        Array([[1, 4],
               [2, 5],
               [3, 6]], dtype=int32)
    
        :func:`~jax.numpy.unstack` performs the inverse operation:
    
        >>> arr = jnp.stack([x, y], axis=1)
        >>> x, y = jnp.unstack(arr, axis=1)
        >>> x
        Array([1, 2, 3], dtype=int32)
        >>> y
        Array([4, 5, 6], dtype=int32)
      """
      if not len(arrays):
>       raise ValueError("Need at least one array to stack.")
E       ValueError: Need at least one array to stack.

/opt/fw/jax/jax/_src/numpy/lax_numpy.py:4094: ValueError

The above exception was the direct cause of the following exception:

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_equalize_clahe(target_framework, mode, backend_compile):
        trace_args = (torch.rand(1, 10, 20),)
        trace_kwargs = {
            "clip_limit": 40.0,
            "grid_size": (8, 8),
            "slow_and_differentiable": False,
        }
        test_args = (torch.rand(2, 3, 10, 20),)
        test_kwargs = {
            "clip_limit": 20.0,
            "grid_size": (4, 4),
            "slow_and_differentiable": False,
        }
>       _test_function(
            kornia.enhance.equalize_clahe,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
            skip=True,
        )

kornia/test_enhance.py:363: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function equalize_clahe at 0x7fc271567a30>
trace_args = (tensor([[[2.4511e-01, 2.1387e-01, 8.9433e-01, 3.7338e-01, 4.9255e-01,
          3.8943e-01, 2.7861e-01, 9.3384e-01, 6...920e-01, 8.4569e-01, 3.2479e-04, 4.4545e-01,
          7.6445e-01, 7.7929e-01, 1.7129e-01, 3.6990e-01, 3.1993e-01]]]),)
trace_kwargs = {'clip_limit': 40.0, 'grid_size': (8, 8), 'slow_and_differentiable': False}
test_args = (tensor([[[[6.9864e-01, 2.6819e-01, 6.8005e-01,  ..., 7.7282e-01,
           8.1182e-01, 6.5862e-02],
          [4.816... 1.9580e-01],
          [5.2556e-02, 6.7997e-01, 5.9658e-01,  ..., 4.6035e-01,
           4.1474e-02, 9.2456e-01]]]]),)
test_kwargs = {'clip_limit': 20.0, 'grid_size': (4, 4), 'slow_and_differentiable': False}, target = 'jax', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = True, deterministic = True
class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function equalize_clahe at 0x7fc271567a30>, fn_name = 'kornia.enhance.equalize_clahe'
trace_args = (tensor([[[2.4511e-01, 2.1387e-01, 8.9433e-01, 3.7338e-01, 4.9255e-01,
          3.8943e-01, 2.7861e-01, 9.3384e-01, 6...920e-01, 8.4569e-01, 3.2479e-04, 4.4545e-01,
          7.6445e-01, 7.7929e-01, 1.7129e-01, 3.6990e-01, 3.1993e-01]]]),)
trace_kwargs = {'clip_limit': 40.0, 'grid_size': (8, 8), 'slow_and_differentiable': False}
test_args = (tensor([[[[6.9864e-01, 2.6819e-01, 6.8005e-01,  ..., 7.7282e-01,
           8.1182e-01, 6.5862e-02],
          [4.816... 1.9580e-01],
          [5.2556e-02, 6.7997e-01, 5.9658e-01,  ..., 4.6035e-01,
           4.1474e-02, 9.2456e-01]]]]),)
test_kwargs = {'clip_limit': 20.0, 'grid_size': (4, 4), 'slow_and_differentiable': False}, target = 'jax', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:232: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = Array([[[[2.45106161e-01, 2.13869989e-01, 8.94329369e-01,
          3.73376071e-01, 4.92548525e-01, 3.89425695e-01,
  ...
          7.64454067e-01, 7.79285848e-01, 1.71286285e-01,
          3.69898319e-01, 3.19933414e-01]]]], dtype=float32)
args = (), kwargs = {'clip_limit': 40.0, 'grid_size': (8, 8), 'slow_and_differentiable': False}, jax_numel_frnt_ = <function jax_numel_frnt_ at 0x7fc1e4f72440>
jax_shape_frnt_ = <function jax_shape_frnt_ at 0x7fc1e4f73130>, jax_view_frnt_ = <function jax_view_frnt_ at 0x7fc1e4f71e10>, input_shape = ivy.frontends.torch.Size([1, 10, 20])

    @wraps(f)
    def _wrapper(input, *args, **kwargs):
        from ...ivy.functional.frontends.torch.tensor import jax_numel_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_view_frnt_
    
        if not isinstance(input, (jax.Array, nnx.Param)):
            raise TypeError(f"Input input type is not a Tensor. Got {type(input)}")
        if jax_numel_frnt_(input) == 0:
            raise ValueError("Invalid input tensor, it is empty.")
        input_shape = jax_shape_frnt_(input)
        input = jax__to_bchw(input)
>       output = f(input, *args, **kwargs)

ivy_transpiled_outputs/jax_outputs/kornia/utils/image.py:71: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = Array([[[[2.45106161e-01, 2.13869989e-01, 8.94329369e-01,
          3.73376071e-01, 4.92548525e-01, 3.89425695e-01,
  ...
          7.64454067e-01, 7.79285848e-01, 1.71286285e-01,
          3.69898319e-01, 3.19933414e-01]]]], dtype=float32)
clip_limit = 40.0, grid_size = (8, 8), slow_and_differentiable = False

    @jax_perform_keep_shape_image
    def jax_equalize_clahe(
        input, clip_limit=40.0, grid_size=(8, 8), slow_and_differentiable=False
    ):
        from ...ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_reshape_as_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_permute_frnt_
        from ...ivy.functional.backends.jax.general import jax_get_item
        from ...ivy.functional.frontends.torch.tensor import jax_dim_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_squeeze_frnt_
    
        if not isinstance(clip_limit, (float,)):
            raise TypeError(f"Input clip_limit type is not float. Got {type(clip_limit)}")
        if not isinstance(grid_size, (tuple,)):
            raise TypeError(f"Input grid_size type is not Tuple. Got {type(grid_size)}")
        if len(grid_size) != 2:
            raise TypeError(
                f"Input grid_size is not a Tuple with 2 elements. Got {len(grid_size)}"
            )
        if isinstance(grid_size[0], (float,)) or isinstance(grid_size[1], (float,)):
            raise TypeError("Input grid_size type is not valid, must be a Tuple[int, int].")
        if grid_size[0] <= 0 or grid_size[1] <= 0:
            raise ValueError(f"Input grid_size elements must be positive. Got {grid_size}")
        imgs: typing.Any = input
>       hist_tiles, img_padded = jax__compute_tiles(imgs, grid_size, True)

ivy_transpiled_outputs/jax_outputs/kornia/enhance/equalization.py:487: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

imgs = Array([[[[2.45106161e-01, 2.13869989e-01, 8.94329369e-01,
          3.73376071e-01, 4.92548525e-01, 3.89425695e-01,
  ...
          7.64454067e-01, 7.79285848e-01, 1.71286285e-01,
          3.69898319e-01, 3.19933414e-01]]]], dtype=float32)
grid_size = (8, 8), even_tile_size = True

    def jax__compute_tiles(imgs, grid_size, even_tile_size=False):
        from ...ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ...ivy.functional.frontends.torch.nn.functional.vision_functions import (
            jax_pad_frnt,
        )
        from ...ivy.functional.frontends.torch.tensor import jax_contiguous_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_squeeze_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_unfold_frnt_
    
        batch: typing.Any = imgs
        h, w = jax_shape_frnt_(batch)[-2:][0], jax_shape_frnt_(batch)[-2:][1]
        kernel_vert: typing.Any = math.ceil(h / grid_size[0])
        kernel_horz: typing.Any = math.ceil(w / grid_size[1])
        if even_tile_size:
            kernel_vert = kernel_vert + (1 if kernel_vert % 2 else 0)
            kernel_horz = kernel_horz + (1 if kernel_horz % 2 else 0)
        pad_vert = kernel_vert * grid_size[0] - h
        pad_horz = kernel_horz * grid_size[1] - w
        if pad_vert > jax_shape_frnt_(batch)[-2] or pad_horz > jax_shape_frnt_(batch)[-1]:
            raise ValueError(
                "Cannot compute tiles on the image according to the given grid size"
            )
        if pad_vert > 0 or pad_horz > 0:
            batch = jax_pad_frnt(batch, [0, pad_horz, 0, pad_vert], mode="reflect")
        c: typing.Any = jax_shape_frnt_(batch)[-3]
        tiles: typing.Any = jax_contiguous_frnt_(
            jax_squeeze_frnt_(
                jax_unfold_frnt_(
>                   jax_unfold_frnt_(
                        jax_unfold_frnt_(batch, 1, c, c), 2, kernel_vert, kernel_vert
                    ),
                    3,
                    kernel_horz,
                    kernel_horz,
                ),
                1,
            )
        )

ivy_transpiled_outputs/jax_outputs/kornia/enhance/equalization.py:61: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (Array([[[[[2.45106161e-01, 7.41351724e-01, 5.93482137e-01,
           4.43523586e-01, 8.60047936e-02, 5.18464446e-02,...01,
           9.59806383e-01, 6.02555513e-01, 8.93429637e-01,
           2.83091307e-01]]]]], dtype=float32), 2, 2, 2)
kwargs = {}, jax_is_array_bknd = <function jax_is_array_bknd at 0x7fc1d2d29870>
array_like = Array([[[[[2.45106161e-01, 7.41351724e-01, 5.93482137e-01,
           4.43523586e-01, 8.60047936e-02, 5.18464446e-02,
...85123599e-01,
           9.59806383e-01, 6.02555513e-01, 8.93429637e-01,
           2.83091307e-01]]]]], dtype=float32)

    @functools.wraps(fn)
    def wrapper(*args, **kwargs):
        from ..functional.ivy.general import jax_is_array_bknd
    
        array_like = args[0]
        if hasattr(array_like, "__class__") and array_like.__class__.__name__ in [
            "list",
            "tuple",
        ]:
            array_like = array_like[0]
        if jax_is_array_bknd(array_like):
>           return fn(*args, **kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/utils/decorator_utils.py:200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = Array([[[[[2.45106161e-01, 7.41351724e-01, 5.93482137e-01,
           4.43523586e-01, 8.60047936e-02, 5.18464446e-02,
...85123599e-01,
           9.59806383e-01, 6.02555513e-01, 8.93429637e-01,
           2.83091307e-01]]]]], dtype=float32)
dimension = 2, size = 2, step = 2

    @jax_handle_methods
    def jax_unfold_frnt_(tensor, dimension, size, step):
        from ...backends.jax.general import jax_get_item
        from ...backends.jax.general import jax_set_item
        from .indexing_slicing_joining_mutating_ops import jax_stack_frnt
    
        slices = []
        self_shape = tuple(jax_shape_frnt_(tensor))
        for i in range(0, jax_get_item(self_shape, dimension) - size + 1, step):
            slicing = [slice(None)] * len(jax_shape_frnt_(tensor))
            slicing = jax_set_item(slicing, dimension, slice(i, i + size))
            slices.append(jax_get_item(tensor, tuple(slicing)))
>       stacked = jax_stack_frnt(slices, dim=dimension)

ivy_transpiled_outputs/jax_outputs/ivy/functional/frontends/torch/tensor.py:256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensors = [], dim = 2

    def jax_stack_frnt(tensors, dim=0, *, out=None):
        from ...backends.jax.manipulation import jax_stack
    
>       return jax_stack(tensors, axis=dim, out=out)

ivy_transpiled_outputs/jax_outputs/ivy/functional/frontends/torch/indexing_slicing_joining_mutating_ops.py:119: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

arrays = []

    def jax_stack(
        arrays: Union[Tuple[jax.Array], List[jax.Array]],
        /,
        *,
        axis: int = 0,
        out: Optional[jax.Array] = None,
    ):
        try:
            return jax.numpy.stack(arrays, axis=axis)
        except ValueError as error:
>           raise Exception(error) from error
E           Exception: Need at least one array to stack.

ivy_transpiled_outputs/jax_outputs/ivy/functional/backends/jax/manipulation.py:127: Exception
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.enhance.equalization.equalize_clahe
___________________________________________________________________________________ test_ZCAWhitening[jax-s2s-False] ___________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_ZCAWhitening(target_framework, mode, backend_compile):
        print("kornia.enhance.ZCAWhitening")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, target=target_framework)
    
        x = torch.tensor([[0,1],[1,0],[-1,0],[0,-1]], dtype = torch.float32)
        zca = kornia.enhance.ZCAWhitening().fit(x)
        torch_out = zca(x)
    
        transpiled_x = _nest_torch_tensor_to_new_framework(x, target_framework)
        transpiled_zca = transpiled_kornia.enhance.ZCAWhitening().fit(transpiled_x)
>       transpiled_out = transpiled_zca(x)

kornia/test_enhance.py:697: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_ZCAWhitening(), x = tensor([[ 0.,  1.],
        [ 1.,  0.],
        [-1.,  0.],
        [ 0., -1.]]), include_fit = False

    def __call__(self, x, include_fit=False):
        if include_fit:
            self.fit(x)
        if not self.fitted:
            raise RuntimeError(
                "Needs to be fitted first before running. Please call fit or set include_fit to True."
            )
>       x_whiten = jax_linear_transform(
            x, self.transform_matrix, self.mean_vector, self.dim
        )

ivy_transpiled_outputs/jax_outputs/kornia/enhance/zca.py:85: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

inp = tensor([[ 0.,  1.],
        [ 1.,  0.],
        [-1.,  0.],
        [ 0., -1.]]), transform_matrix = Array([[1.224744, 0.      ],
       [0.      , 1.224744]], dtype=float32)
mean_vector = Array([[0., 0.]], dtype=float32), dim = 0

    def jax_linear_transform(inp, transform_matrix, mean_vector, dim=0):
        from ...ivy.functional.frontends.torch.tensor import jax_size_frnt_
        from ...ivy.functional.frontends.torch.creation_ops import jax_arange_frnt
        from ...ivy.functional.frontends.torch.comparison_ops import jax_argsort_frnt
        from ...ivy.functional.frontends.torch.tensor import jax_tolist_frnt_
        from ...ivy.functional.backends.jax.general import jax_get_item
        from ...ivy.functional.frontends.torch.tensor import jax_item_frnt_
        from ...ivy.functional.frontends.torch.reduction_ops import jax_prod_frnt
        from ...ivy.functional.frontends.torch.tensor import jax_permute_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_reshape_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_mm_frnt_
        from ..core._backend import concatenate
        from ..core._backend import tensor
    
        inp_size = jax_size_frnt_(inp)
        if dim >= len(inp_size) or dim < -len(inp_size):
            raise IndexError(
                f"Dimension out of range (expected to be in range of [{-len(inp_size)},{len(inp_size) - 1}], but got {dim}"
            )
        if dim < 0:
            dim = len(inp_size) + dim
        feat_dims = concatenate(
            [jax_arange_frnt(0, dim), jax_arange_frnt(dim + 1, len(inp_size))]
        )
        perm = concatenate([tensor([dim]), feat_dims])
        perm_inv = jax_argsort_frnt(perm)
        new_order: typing.Any = jax_tolist_frnt_(perm)
        inv_order: typing.Any = jax_tolist_frnt_(perm_inv)
        feature_sizes = tensor(
            jax_get_item(inp_size, slice(0, dim, None))
            + jax_get_item(inp_size, slice(dim + 1, None, None))
        )
        num_features: typing.Any = int(jax_item_frnt_(jax_prod_frnt(feature_sizes)))
        inp_permute = jax_permute_frnt_(inp, new_order)
        inp_flat = jax_reshape_frnt_(inp_permute, (-1, num_features))
>       inp_center = inp_flat - mean_vector
E       TypeError: unsupported operand type(s) for -: 'Tensor' and 'jaxlib.xla_extension.ArrayImpl'

ivy_transpiled_outputs/jax_outputs/kornia/enhance/zca.py:318: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.enhance.ZCAWhitening
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/test_enhance.py::test_equalize_clahe[jax-s2s-False] - Exception: Need at least one array to stack.
FAILED kornia/test_enhance.py::test_ZCAWhitening[jax-s2s-False] - TypeError: unsupported operand type(s) for -: 'Tensor' and 'jaxlib.xla_extension.ArrayImpl'
============================================================================== 2 failed, 37 passed in 2586.40s (0:43:06) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 26 items

kornia/geometry/test_epipolar.py F......F.......FF.........                                                                                                                                      [100%]

=============================================================================================== FAILURES ===============================================================================================
_________________________________________________________________________________ test_find_essential[numpy-s2s-False] _________________________________________________________________________________

target_framework = 'numpy', mode = 's2s', backend_compile = False

    def test_find_essential(target_framework, mode, backend_compile):
        trace_args = (
            torch.rand(1, 8, 2),
            torch.rand(1, 8, 2),
        )
        trace_kwargs = {'weights': torch.rand(1, 8)}
        test_args = (
            torch.rand(5, 8, 2),
            torch.rand(5, 8, 2),
        )
        test_kwargs = {'weights': torch.rand(5, 8)}
>       _test_function(
            kornia.geometry.epipolar.find_essential,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
            # NOTE: numerical instability in svd()/lu() leads to logits not being allclose
            deterministic=False,
        )

kornia/geometry/test_epipolar.py:20: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function find_essential at 0x7fd1aa16a200>
trace_args = (tensor([[[0.8754, 0.8167],
         [0.4545, 0.8898],
         [0.4997, 0.0890],
         [0.6050, 0.6722],
         ...0.1878],
         [0.6811, 0.4099],
         [0.5021, 0.3441],
         [0.4254, 0.9705],
         [0.7826, 0.3688]]]))
trace_kwargs = {'weights': tensor([[0.1340, 0.3605, 0.5320, 0.3562, 0.9036, 0.6162, 0.6566, 0.6782]])}
test_args = (tensor([[[0.6669, 0.2218],
         [0.5656, 0.7298],
         [0.5292, 0.8540],
         [0.2419, 0.7546],
         ...0.8027],
         [0.6574, 0.6864],
         [0.2788, 0.2774],
         [0.1853, 0.1124],
         [0.9502, 0.2413]]]))
test_kwargs = {'weights': tensor([[0.0331, 0.8531, 0.7180, 0.1603, 0.7565, 0.3155, 0.5985, 0.3472],
        [0.3602, 0.5174, 0.8208,...4, 0.2928, 0.0305, 0.1879, 0.4232, 0.4608],
        [0.7013, 0.8235, 0.2414, 0.3274, 0.4882, 0.2819, 0.9000, 0.5737]])}
target = 'numpy', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = False, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function find_essential at 0x7fd1aa16a200>, fn_name = 'kornia.geometry.epipolar.find_essential'
trace_args = (tensor([[[0.8754, 0.8167],
         [0.4545, 0.8898],
         [0.4997, 0.0890],
         [0.6050, 0.6722],
         ...0.1878],
         [0.6811, 0.4099],
         [0.5021, 0.3441],
         [0.4254, 0.9705],
         [0.7826, 0.3688]]]))
trace_kwargs = {'weights': tensor([[0.1340, 0.3605, 0.5320, 0.3562, 0.9036, 0.6162, 0.6566, 0.6782]])}
test_args = (tensor([[[0.6669, 0.2218],
         [0.5656, 0.7298],
         [0.5292, 0.8540],
         [0.2419, 0.7546],
         ...0.8027],
         [0.6574, 0.6864],
         [0.2788, 0.2774],
         [0.1853, 0.1124],
         [0.9502, 0.2413]]]))
test_kwargs = {'weights': tensor([[0.0331, 0.8531, 0.7180, 0.1603, 0.7565, 0.3155, 0.5985, 0.3472],
        [0.3602, 0.5174, 0.8208,...4, 0.2928, 0.0305, 0.1879, 0.4232, 0.4608],
        [0.7013, 0.8235, 0.2414, 0.3274, 0.4882, 0.2819, 0.9000, 0.5737]])}
target = 'numpy', backend_compile = False, tolerance = 0.001, deterministic = False, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:232: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

points1 = array([[[0.875414  , 0.81671596],
        [0.4545306 , 0.8898385 ],
        [0.49971735, 0.08904284],
        [0.60496...
        [0.73680156, 0.0298034 ],
        [0.43563354, 0.74541926],
        [0.90027416, 0.559794  ]]], dtype=float32)
points2 = array([[[0.86808753, 0.6361271 ],
        [0.5727285 , 0.4200706 ],
        [0.5053643 , 0.17175078],
        [0.76574...
        [0.50209063, 0.34414607],
        [0.42536378, 0.9705412 ],
        [0.7826434 , 0.36879194]]], dtype=float32)
weights = array([[0.1339528 , 0.360534  , 0.5320015 , 0.35617292, 0.9035985 ,
        0.616184  , 0.6566357 , 0.6781609 ]], dtype=float32)

    def numpy_find_essential(points1, points2, weights=None):
        from ....ivy.functional.frontends.torch.tensor import numpy_to_frnt_
    
>       E = numpy_to_frnt_(numpy_run_5point(points1, points2, weights), points1.dtype)

ivy_transpiled_outputs/numpy_outputs/kornia/geometry/epipolar/essential.py:455: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

points1 = array([[[0.875414  , 0.81671596],
        [0.4545306 , 0.8898385 ],
        [0.49971735, 0.08904284],
        [0.60496...
        [0.73680156, 0.0298034 ],
        [0.43563354, 0.74541926],
        [0.90027416, 0.559794  ]]], dtype=float32)
points2 = array([[[0.86808753, 0.6361271 ],
        [0.5727285 , 0.4200706 ],
        [0.5053643 , 0.17175078],
        [0.76574...
        [0.50209063, 0.34414607],
        [0.42536378, 0.9705412 ],
        [0.7826434 , 0.36879194]]], dtype=float32)
weights = array([[0.1339528 , 0.360534  , 0.5320015 , 0.35617292, 0.9035985 ,
        0.616184  , 0.6566357 , 0.6781609 ]], dtype=float32)

    def numpy_run_5point(points1, points2, weights=None):
        from ...core.check import numpy_KORNIA_CHECK_SHAPE
        from ...core.check import numpy_KORNIA_CHECK_SAME_SHAPE
        from ...core.check import numpy_KORNIA_CHECK
        from ....ivy.functional.frontends.torch.tensor import numpy_shape_frnt_
        from ....ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            numpy_chunk_frnt,
        )
        from ....ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            numpy_cat_frnt,
        )
        from ....ivy.functional.frontends.torch.tensor import numpy_transpose_frnt_
        from ....ivy.functional.frontends.torch.miscellaneous_ops import (
            numpy_diag_embed_frnt,
        )
        from ...core._backend import ones_like
    
        numpy_KORNIA_CHECK_SHAPE(points1, ["B", "N", "2"])
        numpy_KORNIA_CHECK_SAME_SHAPE(points1, points2)
        numpy_KORNIA_CHECK(
            numpy_shape_frnt_(points1)[1] >= 5, "Number of points should be >=5"
        )
        if weights is not None:
            numpy_KORNIA_CHECK_SAME_SHAPE(points1[:, :, 0], weights)
        batch_size, _, _ = numpy_shape_frnt_(points1)
        x1, y1 = numpy_chunk_frnt(points1, dim=-1, chunks=2)
        x2, y2 = numpy_chunk_frnt(points2, dim=-1, chunks=2)
        ones = ones_like(x1)
        X = numpy_cat_frnt(
            [x1 * x2, x1 * y2, x1, y1 * x2, y1 * y2, y1, x2, y2, ones], dim=-1
        )
        if weights is None:
            X = numpy_transpose_frnt_(X, -2, -1) @ X
        else:
>           w_diag = numpy_diag_embed_frnt(weights)

ivy_transpiled_outputs/numpy_outputs/kornia/geometry/epipolar/essential.py:62: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = array([[[0.1339528 , 0.360534  , 0.5320015 , 0.35617292, 0.9035985 ,
         0.616184  , 0.6566357 , 0.6781609 ]]], dtype=float32), offset = 0, dim1 = 1, dim2 = 2

    def numpy_diag_embed_frnt(input, offset=0, dim1=-2, dim2=-1):
        from ...backends.numpy.data_type import numpy_dtype
        from .tensor import numpy_ndim_frnt_
        from .tensor import numpy_shape_frnt_
        from ...backends.numpy.general import numpy_set_item
        from ...backends.numpy.creation import numpy_zeros
        from ...backends.numpy.manipulation import numpy_concat
        from ....data_classes.array.experimental.manipulation import numpy_moveaxis_bknd_
        from ....data_classes.array.manipulation import numpy_expand_dims_bknd_
        from ...backends.numpy.creation import numpy_arange
        from .tensor import numpy_reshape_frnt_
        from .tensor import numpy_logical_and_frnt_
        from ...backends.numpy.searching import numpy_where
        from ....data_classes.array.data_type import numpy_astype_bknd_
    
        def _handle_dim(rank, idx):
            if idx >= 0 and idx < rank:
                return idx
            if idx < 0:
                idx = idx + rank
            if idx < 0 or idx >= rank:
                raise IndexError
            return idx
    
        input_type = numpy_dtype(input)
        rank = numpy_ndim_frnt_(input) + 1
        dim1 = _handle_dim(rank, dim1)
        dim2 = _handle_dim(rank, dim2)
        if dim1 > dim2:
            dim1, dim2 = dim2, dim1
            offset = -offset
        last_dim = list(numpy_shape_frnt_(input))[-1]
        if offset != 0:
            t_shape = list(numpy_shape_frnt_(input))
            t_shape = numpy_set_item(t_shape, -1, abs(offset))
            z = numpy_zeros(t_shape, dtype=input.dtype, device=None)
            pair = (z, input) if offset > 0 else (input, z)
            input = numpy_concat(pair, axis=-1)
            last_dim = last_dim + abs(offset)
        input = numpy_moveaxis_bknd_(numpy_expand_dims_bknd_(input, axis=dim1), -1, dim2)
        a_range = numpy_arange(last_dim, device=None, dtype=np.int64)
        b_range = numpy_arange(offset, last_dim + offset, device=None, dtype=np.int64)
        cond = a_range == numpy_expand_dims_bknd_(b_range, axis=-1)
        ag__result_list_0 = []
        for i in range(len(numpy_shape_frnt_(input))):
            res = last_dim if i in (dim1, dim2) else 1
            ag__result_list_0.append(res)
        cond_shape = ag__result_list_0
        cond = numpy_reshape_frnt_(cond, cond_shape)
>       if input.dtype == np.bool:

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/miscellaneous_ops.py:80: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

attr = 'bool'

    def __getattr__(attr):
        # Warn for expired attributes, and return a dummy function
        # that always raises an exception.
        import warnings
        import math
        try:
            msg = __expired_functions__[attr]
        except KeyError:
            pass
        else:
            warnings.warn(msg, DeprecationWarning, stacklevel=2)
    
            def _expired(*args, **kwds):
                raise RuntimeError(msg)
    
            return _expired
    
        # Emit warnings for deprecated attributes
        try:
            val, msg = __deprecated_attrs__[attr]
        except KeyError:
            pass
        else:
            warnings.warn(msg, DeprecationWarning, stacklevel=2)
            return val
    
        if attr in __future_scalars__:
            # And future warnings for those that will change, but also give
            # the AttributeError
            warnings.warn(
                f"In the future `np.{attr}` will be defined as the "
                "corresponding NumPy scalar.", FutureWarning, stacklevel=2)
    
        if attr in __former_attrs__:
>           raise AttributeError(__former_attrs__[attr])
E           AttributeError: module 'numpy' has no attribute 'bool'.
E           `np.bool` was a deprecated alias for the builtin `bool`. To avoid this error in existing code, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
E           The aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:
E               https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations. Did you mean: 'bool_'?

/opt/fw/mxnet/numpy/__init__.py:324: AttributeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.epipolar.essential.find_essential
----------------------------------------------------------------------------------------- Captured stderr call -----------------------------------------------------------------------------------------
/ivy/ivy-integration-tests/ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/miscellaneous_ops.py:80: FutureWarning: In the future `np.bool` will be defined as the corresponding NumPy scalar.
  if input.dtype == np.bool:
________________________________________________________________________________ test_find_fundamental[numpy-s2s-False] ________________________________________________________________________________

target_framework = 'numpy', mode = 's2s', backend_compile = False

    def test_find_fundamental(target_framework, mode, backend_compile):
        trace_args = (
            torch.rand(2, 8, 2),
            torch.rand(2, 8, 2),
        )
        trace_kwargs = {'weights': torch.rand(2, 8), 'method': '8POINT'}
        test_args = (
            torch.rand(5, 8, 2),
            torch.rand(5, 8, 2),
        )
        test_kwargs = {'weights': torch.rand(5, 8), 'method': '8POINT'}
>       _test_function(
            kornia.geometry.epipolar.find_fundamental,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=3e-2,
            mode=mode,
        )

kornia/geometry/test_epipolar.py:206: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function find_fundamental at 0x7fd1aa16a7a0>
trace_args = (tensor([[[0.0279, 0.7853],
         [0.1209, 0.8045],
         [0.9485, 0.8758],
         [0.8058, 0.0409],
         ...0.8097],
         [0.1253, 0.7797],
         [0.4820, 0.5050],
         [0.5708, 0.4632],
         [0.0695, 0.8093]]]))
trace_kwargs = {'method': '8POINT', 'weights': tensor([[0.5191, 0.1370, 0.3562, 0.0198, 0.5840, 0.2398, 0.7894, 0.5504],
        [0.6182, 0.7438, 0.6685, 0.4273, 0.5356, 0.1988, 0.4400, 0.4274]])}
test_args = (tensor([[[0.1790, 0.5679],
         [0.2154, 0.5885],
         [0.4196, 0.4349],
         [0.4070, 0.0678],
         ...0.1659],
         [0.6921, 0.2893],
         [0.7890, 0.7172],
         [0.2304, 0.9215],
         [0.6546, 0.1465]]]))
test_kwargs = {'method': '8POINT', 'weights': tensor([[0.5421, 0.7616, 0.0848, 0.2210, 0.6621, 0.3181, 0.0127, 0.5345],
        [0.3...7, 0.3132, 0.3455, 0.0956, 0.3059, 0.0140],
        [0.7313, 0.6936, 0.9728, 0.2166, 0.7938, 0.2990, 0.4263, 0.0968]])}
target = 'numpy', backend_compile = False, tolerance = 0.03, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function find_fundamental at 0x7fd1aa16a7a0>, fn_name = 'kornia.geometry.epipolar.find_fundamental'
trace_args = (tensor([[[0.0279, 0.7853],
         [0.1209, 0.8045],
         [0.9485, 0.8758],
         [0.8058, 0.0409],
         ...0.8097],
         [0.1253, 0.7797],
         [0.4820, 0.5050],
         [0.5708, 0.4632],
         [0.0695, 0.8093]]]))
trace_kwargs = {'method': '8POINT', 'weights': tensor([[0.5191, 0.1370, 0.3562, 0.0198, 0.5840, 0.2398, 0.7894, 0.5504],
        [0.6182, 0.7438, 0.6685, 0.4273, 0.5356, 0.1988, 0.4400, 0.4274]])}
test_args = (tensor([[[0.1790, 0.5679],
         [0.2154, 0.5885],
         [0.4196, 0.4349],
         [0.4070, 0.0678],
         ...0.1659],
         [0.6921, 0.2893],
         [0.7890, 0.7172],
         [0.2304, 0.9215],
         [0.6546, 0.1465]]]))
test_kwargs = {'method': '8POINT', 'weights': tensor([[0.5421, 0.7616, 0.0848, 0.2210, 0.6621, 0.3181, 0.0127, 0.5345],
        [0.3...7, 0.3132, 0.3455, 0.0956, 0.3059, 0.0140],
        [0.7313, 0.6936, 0.9728, 0.2166, 0.7938, 0.2990, 0.4263, 0.0968]])}
target = 'numpy', backend_compile = False, tolerance = 0.03, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:232: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

points1 = array([[[0.02792114, 0.7852511 ],
        [0.12089133, 0.8045279 ],
        [0.94845235, 0.8758401 ],
        [0.80584...
        [0.56485784, 0.7192693 ],
        [0.17804062, 0.04806429],
        [0.18538934, 0.02913803]]], dtype=float32)
points2 = array([[[0.42431033, 0.149517  ],
        [0.0927242 , 0.05847615],
        [0.5578472 , 0.84240633],
        [0.01250...
        [0.48197436, 0.5049649 ],
        [0.5707542 , 0.46319133],
        [0.06947225, 0.8093109 ]]], dtype=float32)
weights = array([[0.5190853 , 0.13702661, 0.35622245, 0.01980293, 0.58402133,
        0.23978943, 0.7894032 , 0.5503788 ],
     ....6181586 , 0.74380225, 0.6685245 , 0.42734146, 0.535613  ,
        0.19880104, 0.44003916, 0.42741746]], dtype=float32)
method = '8POINT'

    def numpy_find_fundamental(points1, points2, weights=None, method="8POINT"):
        if method.upper() == "7POINT":
            result = numpy_run_7point(points1, points2)
        elif method.upper() == "8POINT":
>           result = numpy_run_8point(points1, points2, weights)

ivy_transpiled_outputs/numpy_outputs/kornia/geometry/epipolar/fundamental.py:259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

points1 = array([[[0.02792114, 0.7852511 ],
        [0.12089133, 0.8045279 ],
        [0.94845235, 0.8758401 ],
        [0.80584...
        [0.56485784, 0.7192693 ],
        [0.17804062, 0.04806429],
        [0.18538934, 0.02913803]]], dtype=float32)
points2 = array([[[0.42431033, 0.149517  ],
        [0.0927242 , 0.05847615],
        [0.5578472 , 0.84240633],
        [0.01250...
        [0.48197436, 0.5049649 ],
        [0.5707542 , 0.46319133],
        [0.06947225, 0.8093109 ]]], dtype=float32)
weights = array([[0.5190853 , 0.13702661, 0.35622245, 0.01980293, 0.58402133,
        0.23978943, 0.7894032 , 0.5503788 ],
     ....6181586 , 0.74380225, 0.6685245 , 0.42734146, 0.535613  ,
        0.19880104, 0.44003916, 0.42741746]], dtype=float32)

    def numpy_run_8point(points1, points2, weights=None):
        from ....ivy.functional.frontends.torch.tensor import numpy_shape_frnt_
        from ....ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            numpy_chunk_frnt,
        )
        from ....ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            numpy_cat_frnt,
        )
        from ....ivy.functional.frontends.torch.tensor import numpy_transpose_frnt_
        from ....ivy.functional.frontends.torch.miscellaneous_ops import (
            numpy_diag_embed_frnt,
        )
        from ...utils.helpers import numpy__torch_svd_cast
        from ....ivy.functional.frontends.torch.tensor import numpy_view_frnt_
        from ....ivy.functional.frontends.torch.creation_ops import numpy_tensor_frnt
        from ...core._backend import ones_like
    
        if numpy_shape_frnt_(points1) != numpy_shape_frnt_(points2):
            raise AssertionError(numpy_shape_frnt_(points1), numpy_shape_frnt_(points2))
        if numpy_shape_frnt_(points1)[1] < 8:
            raise AssertionError(numpy_shape_frnt_(points1))
        if weights is not None:
            if not (
                len(numpy_shape_frnt_(weights)) == 2
                and numpy_shape_frnt_(weights)[1] == numpy_shape_frnt_(points1)[1]
            ):
                raise AssertionError(numpy_shape_frnt_(weights))
        points1_norm, transform1 = numpy_normalize_points(points1)
        points2_norm, transform2 = numpy_normalize_points(points2)
        x1, y1 = numpy_chunk_frnt(points1_norm, dim=-1, chunks=2)
        x2, y2 = numpy_chunk_frnt(points2_norm, dim=-1, chunks=2)
        ones = ones_like(x1)
        X = numpy_cat_frnt(
            [x2 * x1, x2 * y1, x2, y2 * x1, y2 * y1, y2, x1, y1, ones], dim=-1
        )
        if weights is None:
            X = numpy_transpose_frnt_(X, -2, -1) @ X
        else:
>           w_diag = numpy_diag_embed_frnt(weights)

ivy_transpiled_outputs/numpy_outputs/kornia/geometry/epipolar/fundamental.py:242: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = array([[[0.5190853 , 0.13702661, 0.35622245, 0.01980293, 0.58402133,
         0.23978943, 0.7894032 , 0.5503788 ]],

 ...181586 , 0.74380225, 0.6685245 , 0.42734146, 0.535613  ,
         0.19880104, 0.44003916, 0.42741746]]], dtype=float32)
offset = 0, dim1 = 1, dim2 = 2

    def numpy_diag_embed_frnt(input, offset=0, dim1=-2, dim2=-1):
        from ...backends.numpy.data_type import numpy_dtype
        from .tensor import numpy_ndim_frnt_
        from .tensor import numpy_shape_frnt_
        from ...backends.numpy.general import numpy_set_item
        from ...backends.numpy.creation import numpy_zeros
        from ...backends.numpy.manipulation import numpy_concat
        from ....data_classes.array.experimental.manipulation import numpy_moveaxis_bknd_
        from ....data_classes.array.manipulation import numpy_expand_dims_bknd_
        from ...backends.numpy.creation import numpy_arange
        from .tensor import numpy_reshape_frnt_
        from .tensor import numpy_logical_and_frnt_
        from ...backends.numpy.searching import numpy_where
        from ....data_classes.array.data_type import numpy_astype_bknd_
    
        def _handle_dim(rank, idx):
            if idx >= 0 and idx < rank:
                return idx
            if idx < 0:
                idx = idx + rank
            if idx < 0 or idx >= rank:
                raise IndexError
            return idx
    
        input_type = numpy_dtype(input)
        rank = numpy_ndim_frnt_(input) + 1
        dim1 = _handle_dim(rank, dim1)
        dim2 = _handle_dim(rank, dim2)
        if dim1 > dim2:
            dim1, dim2 = dim2, dim1
            offset = -offset
        last_dim = list(numpy_shape_frnt_(input))[-1]
        if offset != 0:
            t_shape = list(numpy_shape_frnt_(input))
            t_shape = numpy_set_item(t_shape, -1, abs(offset))
            z = numpy_zeros(t_shape, dtype=input.dtype, device=None)
            pair = (z, input) if offset > 0 else (input, z)
            input = numpy_concat(pair, axis=-1)
            last_dim = last_dim + abs(offset)
        input = numpy_moveaxis_bknd_(numpy_expand_dims_bknd_(input, axis=dim1), -1, dim2)
        a_range = numpy_arange(last_dim, device=None, dtype=np.int64)
        b_range = numpy_arange(offset, last_dim + offset, device=None, dtype=np.int64)
        cond = a_range == numpy_expand_dims_bknd_(b_range, axis=-1)
        ag__result_list_0 = []
        for i in range(len(numpy_shape_frnt_(input))):
            res = last_dim if i in (dim1, dim2) else 1
            ag__result_list_0.append(res)
        cond_shape = ag__result_list_0
        cond = numpy_reshape_frnt_(cond, cond_shape)
>       if input.dtype == np.bool:

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/miscellaneous_ops.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

attr = 'bool'

    def __getattr__(attr):
        # Warn for expired attributes, and return a dummy function
        # that always raises an exception.
        import warnings
        import math
        try:
            msg = __expired_functions__[attr]
        except KeyError:
            pass
        else:
            warnings.warn(msg, DeprecationWarning, stacklevel=2)
    
            def _expired(*args, **kwds):
                raise RuntimeError(msg)
    
            return _expired
    
        # Emit warnings for deprecated attributes
        try:
            val, msg = __deprecated_attrs__[attr]
        except KeyError:
            pass
        else:
            warnings.warn(msg, DeprecationWarning, stacklevel=2)
            return val
    
        if attr in __future_scalars__:
            # And future warnings for those that will change, but also give
            # the AttributeError
            warnings.warn(
                f"In the future `np.{attr}` will be defined as the "
                "corresponding NumPy scalar.", FutureWarning, stacklevel=2)
    
        if attr in __former_attrs__:
>           raise AttributeError(__former_attrs__[attr])
E           AttributeError: module 'numpy' has no attribute 'bool'.
E           `np.bool` was a deprecated alias for the builtin `bool`. To avoid this error in existing code, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
E           The aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:
E               https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations. Did you mean: 'bool_'?

/opt/fw/mxnet/numpy/__init__.py:324: AttributeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.epipolar.fundamental.find_fundamental
----------------------------------------------------------------------------------------- Captured stderr call -----------------------------------------------------------------------------------------
/ivy/ivy-integration-tests/ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/miscellaneous_ops.py:79: FutureWarning: In the future `np.bool` will be defined as the corresponding NumPy scalar.
  cond = numpy_reshape_frnt_(cond, cond_shape)
___________________________________________________________________________ test_sampson_epipolar_distance[numpy-s2s-False] ____________________________________________________________________________

target_framework = 'numpy', mode = 's2s', backend_compile = False

    def test_sampson_epipolar_distance(target_framework, mode, backend_compile):
        trace_args = (
            torch.rand(1, 4, 2),
            torch.rand(1, 4, 2),
            torch.rand(1, 3, 3),
        )
        trace_kwargs = {'squared': True, 'eps': 1e-8}
        test_args = (
            torch.rand(5, 4, 2),
            torch.rand(5, 4, 2),
            torch.rand(5, 3, 3),
        )
        test_kwargs = {'squared': True, 'eps': 1e-8}
>       _test_function(
            kornia.geometry.epipolar.sampson_epipolar_distance,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/geometry/test_epipolar.py:400: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function sampson_epipolar_distance at 0x7fd1aa1685e0>
trace_args = (tensor([[[0.0604, 0.2932],
         [0.4352, 0.2361],
         [0.4547, 0.8918],
         [0.6966, 0.7405]]]), tensor...0.6846]]]), tensor([[[0.0709, 0.5274, 0.4267],
         [0.4260, 0.4432, 0.7418],
         [0.7311, 0.1881, 0.0804]]]))
trace_kwargs = {'eps': 1e-08, 'squared': True}
test_args = (tensor([[[0.0905, 0.0664],
         [0.5218, 0.2472],
         [0.5252, 0.1587],
         [0.1846, 0.1023]],

       ... 0.8567]],

        [[0.5490, 0.1064, 0.7888],
         [0.1587, 0.1473, 0.1634],
         [0.6293, 0.1251, 0.2493]]]))
test_kwargs = {'eps': 1e-08, 'squared': True}, target = 'numpy', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function sampson_epipolar_distance at 0x7fd1aa1685e0>, fn_name = 'kornia.geometry.epipolar.sampson_epipolar_distance'
trace_args = (tensor([[[0.0604, 0.2932],
         [0.4352, 0.2361],
         [0.4547, 0.8918],
         [0.6966, 0.7405]]]), tensor...0.6846]]]), tensor([[[0.0709, 0.5274, 0.4267],
         [0.4260, 0.4432, 0.7418],
         [0.7311, 0.1881, 0.0804]]]))
trace_kwargs = {'eps': 1e-08, 'squared': True}
test_args = (tensor([[[0.0905, 0.0664],
         [0.5218, 0.2472],
         [0.5252, 0.1587],
         [0.1846, 0.1023]],

       ... 0.8567]],

        [[0.5490, 0.1064, 0.7888],
         [0.1587, 0.1473, 0.1634],
         [0.6293, 0.1251, 0.2493]]]))
test_kwargs = {'eps': 1e-08, 'squared': True}, target = 'numpy', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:232: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pts1 = array([[[0.06041503, 0.29317838, 1.        ],
        [0.43520725, 0.23613769, 1.        ],
        [0.45471305, 0.891829  , 1.        ],
        [0.69656366, 0.7404865 , 1.        ]]], dtype=float32)
pts2 = array([[[0.06580877, 0.5152904 , 1.        ],
        [0.04574591, 0.7133303 , 1.        ],
        [0.16342843, 0.4146654 , 1.        ],
        [0.6806723 , 0.684609  , 1.        ]]], dtype=float32)
Fm = array([[[0.07089102, 0.52735734, 0.4266944 ],
        [0.42601603, 0.4431848 , 0.74175316],
        [0.73111874, 0.1880768 , 0.08036745]]], dtype=float32), squared = True, eps = 1e-08

    def numpy_sampson_epipolar_distance(pts1, pts2, Fm, squared=True, eps=1e-08):
        from ....ivy.functional.frontends.torch.tensor import numpy_shape_frnt_
        from ..conversions import numpy_convert_points_to_homogeneous
        from ....ivy.functional.frontends.torch.tensor import numpy_transpose_frnt_
        from ....ivy.functional.frontends.torch.tensor import numpy_pow_frnt_
        from ....ivy.functional.frontends.torch.tensor import numpy_sum_frnt_
        from ....ivy.functional.frontends.torch.tensor import numpy_norm_frnt_
        from ....ivy.functional.frontends.torch.tensor import numpy_sqrt_frnt_
    
        if not isinstance(Fm, (numpy.ndarray, numpy.ndarray)):
            raise TypeError(f"Fm type is not a torch.Tensor. Got {type(Fm)}")
        if len(numpy_shape_frnt_(Fm)) < 3 or not numpy_shape_frnt_(Fm)[-2:] == (3, 3):
            raise ValueError(f"Fm must be a (*, 3, 3) tensor. Got {numpy_shape_frnt_(Fm)}")
        if numpy_shape_frnt_(pts1)[-1] == 2:
            pts1 = numpy_convert_points_to_homogeneous(pts1)
        if numpy_shape_frnt_(pts2)[-1] == 2:
            pts2 = numpy_convert_points_to_homogeneous(pts2)
        F_t: typing.Any = numpy_transpose_frnt_(Fm, dim0=-2, dim1=-1)
        line1_in_2: typing.Any = pts1 @ F_t
        line2_in_1: typing.Any = pts2 @ Fm
>       numerator: typing.Any = numpy_pow_frnt_(
            numpy_sum_frnt_(pts2 * line1_in_2, dim=-1), 2
        )

ivy_transpiled_outputs/numpy_outputs/kornia/geometry/epipolar/_metrics.py:51: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (array([[0.6806483, 1.2056173, 1.2842143, 2.254397 ]], dtype=float32), 2), kwargs = {}, numpy_is_array_bknd = <function numpy_is_array_bknd at 0x7fd150512d40>
array_like = array([[0.6806483, 1.2056173, 1.2842143, 2.254397 ]], dtype=float32)

    @functools.wraps(fn)
    def wrapper(*args, **kwargs):
        from ..functional.ivy.general import numpy_is_array_bknd
    
        array_like = args[0]
        if hasattr(array_like, "__class__") and array_like.__class__.__name__ in [
            "list",
            "tuple",
        ]:
            array_like = array_like[0]
        if numpy_is_array_bknd(array_like):
>           return fn(*args, **kwargs)

ivy_transpiled_outputs/numpy_outputs/ivy/utils/decorator_utils.py:200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = array([[0.6806483, 1.2056173, 1.2842143, 2.254397 ]], dtype=float32), exponent = 2

    @numpy_handle_methods
    def numpy_pow_frnt_(tensor, exponent):
        from .pointwise_ops import numpy_pow_frnt
    
>       return numpy_pow_frnt(tensor, exponent)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/tensor.py:140: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (array([[0.6806483, 1.2056173, 1.2842143, 2.254397 ]], dtype=float32), 2), kwargs = {}, numpy_is_array_bknd = <function numpy_is_array_bknd at 0x7fd150512d40>
array_like = array([[0.6806483, 1.2056173, 1.2842143, 2.254397 ]], dtype=float32)

    @functools.wraps(fn)
    def wrapper(*args, **kwargs):
        from ..functional.ivy.general import numpy_is_array_bknd
    
        array_like = args[0]
        if hasattr(array_like, "__class__") and array_like.__class__.__name__ in [
            "list",
            "tuple",
        ]:
            array_like = array_like[0]
        if numpy_is_array_bknd(array_like):
>           return fn(*args, **kwargs)

ivy_transpiled_outputs/numpy_outputs/ivy/utils/decorator_utils.py:200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = array([[0.6806483, 1.2056173, 1.2842143, 2.254397 ]], dtype=float32), exponent = array(2)

    @numpy_handle_methods
    def numpy_pow_frnt(input, exponent, *, out=None):
        from ...ivy.general import numpy_is_array_bknd
        from .creation_ops import numpy_as_tensor_frnt
        from ...backends.numpy.creation import numpy_asarray
        from .__init__ import numpy_promote_types_of_torch_inputs_frnt
        from ...ivy.data_type import numpy_is_int_dtype_bknd
        from ...backends.numpy.elementwise import numpy_pow
        from ...backends.numpy.utility import numpy_any
        from ...backends.numpy.searching import numpy_where
        from ...backends.numpy.elementwise import numpy_bitwise_and
        from ....data_classes.array.data_type import numpy_astype_bknd_
    
        if not numpy_is_array_bknd(input):
            input = numpy_as_tensor_frnt(input)
        if not numpy_is_array_bknd(exponent):
            if (
                any(dtype in str(input.dtype) for dtype in ["int8", "int16"])
                and isinstance(exponent, (int,))
                or "float16" in str(input.dtype)
                and isinstance(exponent, (float,))
            ):
                exponent = numpy_asarray(exponent, dtype=input.dtype)
            else:
                exponent = numpy_as_tensor_frnt(exponent)
>       input, exponent = numpy_promote_types_of_torch_inputs_frnt(input, exponent)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/pointwise_ops.py:91: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x1 = array([[0.6806483, 1.2056173, 1.2842143, 2.254397 ]], dtype=float32), x2 = array(2)

    def numpy_promote_types_of_torch_inputs_frnt(x1, x2, /):
        from ...ivy.general import numpy_isscalar_bknd
        from ...ivy.data_type import numpy_is_int_dtype_bknd
        from ...backends.numpy.creation import numpy_asarray
        from ...ivy.data_type import numpy_default_dtype_bknd
        from .tensor import numpy_shape_frnt_
        from ...ivy.device import numpy_default_device_bknd
        from ....data_classes.array.data_type import numpy_astype_bknd_
    
        """Promote the dtype of the given native array inputs to a common dtype
        based on type promotion rules.
    
        While passing float or integer values or any other non-array input
        to this function, it should be noted that the return will be an
        array-like object. Therefore, outputs from this function should be
        used as inputs only for those functions that expect an array-like or
        tensor-like objects, otherwise it might give unexpected results.
        """
        if (
            numpy_isscalar_bknd(x1) or isinstance(x1, (list, tuple))
        ) and numpy_is_int_dtype_bknd(x1):
            x1 = numpy_asarray(x1, dtype="int64")
        elif numpy_isscalar_bknd(x1) or isinstance(x1, (list, tuple)):
            x1 = numpy_asarray(x1)
        if (
            numpy_isscalar_bknd(x2) or isinstance(x2, (list, tuple))
        ) and numpy_is_int_dtype_bknd(x2):
            x2 = numpy_asarray(x2, dtype="int64")
        elif numpy_isscalar_bknd(x2) or isinstance(x2, (list, tuple)):
            x2 = numpy_asarray(x2)
        type1 = numpy_default_dtype_bknd(item=x1).strip("u123456789")
        type2 = numpy_default_dtype_bknd(item=x2).strip("u123456789")
        if numpy_shape_frnt_(x1) != () and numpy_shape_frnt_(x2) == () and type1 == type2:
            x2 = numpy_asarray(
                x2,
                dtype=x1.dtype,
                device=numpy_default_device_bknd(item=x1, as_native=False),
            )
        elif numpy_shape_frnt_(x1) == () and numpy_shape_frnt_(x2) != () and type1 == type2:
            x1 = numpy_asarray(
                x1,
                dtype=x2.dtype,
                device=numpy_default_device_bknd(item=x2, as_native=False),
            )
        elif x1.dtype != x2.dtype:
>           promoted = numpy_promote_types_torch_frnt(x1.dtype, x2.dtype)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/__init__.py:87: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

type1 = dtype('float32'), type2 = dtype('int64')

    def numpy_promote_types_torch_frnt(type1, type2, /):
        from ...backends.numpy.general import numpy_get_item
        from ...backends.numpy.data_type import numpy_as_ivy_dtype
    
        try:
            ret = numpy_get_item(
>               torch_promotion_table,
                (numpy_as_ivy_dtype(type1), numpy_as_ivy_dtype(type2)),
            )
E           NameError: name 'torch_promotion_table' is not defined

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/__init__.py:34: NameError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.epipolar._metrics.sampson_epipolar_distance
_________________________________________________________________________ test_symmetrical_epipolar_distance[numpy-s2s-False] __________________________________________________________________________

target_framework = 'numpy', mode = 's2s', backend_compile = False

    def test_symmetrical_epipolar_distance(target_framework, mode, backend_compile):
        trace_args = (
            torch.rand(1, 4, 2),
            torch.rand(1, 4, 2),
            torch.rand(1, 3, 3),
        )
        trace_kwargs = {'squared': True, 'eps': 1e-8}
        test_args = (
            torch.rand(5, 4, 2),
            torch.rand(5, 4, 2),
            torch.rand(5, 3, 3),
        )
        test_kwargs = {'squared': True, 'eps': 1e-8}
>       _test_function(
            kornia.geometry.epipolar.symmetrical_epipolar_distance,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/geometry/test_epipolar.py:426: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function symmetrical_epipolar_distance at 0x7fd1aa168700>
trace_args = (tensor([[[0.2195, 0.5294],
         [0.4392, 0.1139],
         [0.7831, 0.2320],
         [0.1437, 0.7232]]]), tensor...0.9432]]]), tensor([[[0.6678, 0.2428, 0.8128],
         [0.2872, 0.2480, 0.0840],
         [0.9909, 0.1683, 0.2541]]]))
trace_kwargs = {'eps': 1e-08, 'squared': True}
test_args = (tensor([[[0.8378, 0.1894],
         [0.6375, 0.1723],
         [0.3056, 0.8070],
         [0.1430, 0.6444]],

       ... 0.6599]],

        [[0.0779, 0.3233, 0.7277],
         [0.4857, 0.2222, 0.1872],
         [0.7895, 0.3190, 0.8633]]]))
test_kwargs = {'eps': 1e-08, 'squared': True}, target = 'numpy', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function symmetrical_epipolar_distance at 0x7fd1aa168700>, fn_name = 'kornia.geometry.epipolar.symmetrical_epipolar_distance'
trace_args = (tensor([[[0.2195, 0.5294],
         [0.4392, 0.1139],
         [0.7831, 0.2320],
         [0.1437, 0.7232]]]), tensor...0.9432]]]), tensor([[[0.6678, 0.2428, 0.8128],
         [0.2872, 0.2480, 0.0840],
         [0.9909, 0.1683, 0.2541]]]))
trace_kwargs = {'eps': 1e-08, 'squared': True}
test_args = (tensor([[[0.8378, 0.1894],
         [0.6375, 0.1723],
         [0.3056, 0.8070],
         [0.1430, 0.6444]],

       ... 0.6599]],

        [[0.0779, 0.3233, 0.7277],
         [0.4857, 0.2222, 0.1872],
         [0.7895, 0.3190, 0.8633]]]))
test_kwargs = {'eps': 1e-08, 'squared': True}, target = 'numpy', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:232: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pts1 = array([[[0.21945876, 0.52938974, 1.        ],
        [0.43919224, 0.11387891, 1.        ],
        [0.78306675, 0.23198533, 1.        ],
        [0.14365578, 0.7232411 , 1.        ]]], dtype=float32)
pts2 = array([[[0.9377678 , 0.6256202 , 1.        ],
        [0.07720941, 0.00754935, 1.        ],
        [0.685489  , 0.2283929 , 1.        ],
        [0.3747558 , 0.94323945, 1.        ]]], dtype=float32)
Fm = array([[[0.66780895, 0.24276489, 0.81284654],
        [0.28719658, 0.24795711, 0.0839712 ],
        [0.99085295, 0.1683386 , 0.2541474 ]]], dtype=float32), squared = True, eps = 1e-08

    def numpy_symmetrical_epipolar_distance(pts1, pts2, Fm, squared=True, eps=1e-08):
        from ....ivy.functional.frontends.torch.tensor import numpy_shape_frnt_
        from ..conversions import numpy_convert_points_to_homogeneous
        from ....ivy.functional.frontends.torch.tensor import numpy_transpose_frnt_
        from ....ivy.functional.frontends.torch.tensor import numpy_pow_frnt_
        from ....ivy.functional.frontends.torch.tensor import numpy_sum_frnt_
        from ....ivy.functional.frontends.torch.tensor import numpy_norm_frnt_
        from ....ivy.functional.frontends.torch.tensor import numpy_sqrt_frnt_
    
        if not isinstance(Fm, (numpy.ndarray, numpy.ndarray)):
            raise TypeError(f"Fm type is not a torch.Tensor. Got {type(Fm)}")
        if len(numpy_shape_frnt_(Fm)) < 3 or not numpy_shape_frnt_(Fm)[-2:] == (3, 3):
            raise ValueError(f"Fm must be a (*, 3, 3) tensor. Got {numpy_shape_frnt_(Fm)}")
        if numpy_shape_frnt_(pts1)[-1] == 2:
            pts1 = numpy_convert_points_to_homogeneous(pts1)
        if numpy_shape_frnt_(pts2)[-1] == 2:
            pts2 = numpy_convert_points_to_homogeneous(pts2)
        F_t: typing.Any = numpy_transpose_frnt_(Fm, dim0=-2, dim1=-1)
        line1_in_2: typing.Any = pts1 @ F_t
        line2_in_1: typing.Any = pts2 @ Fm
>       numerator: typing.Any = numpy_pow_frnt_(
            numpy_sum_frnt_(pts2 * line1_in_2, dim=-1), 2
        )

ivy_transpiled_outputs/numpy_outputs/kornia/geometry/epipolar/_metrics.py:51: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (array([[1.7550201, 0.797831 , 2.1070554, 1.2118826]], dtype=float32), 2), kwargs = {}, numpy_is_array_bknd = <function numpy_is_array_bknd at 0x7fd14a42feb0>
array_like = array([[1.7550201, 0.797831 , 2.1070554, 1.2118826]], dtype=float32)

    @functools.wraps(fn)
    def wrapper(*args, **kwargs):
        from ..functional.ivy.general import numpy_is_array_bknd
    
        array_like = args[0]
        if hasattr(array_like, "__class__") and array_like.__class__.__name__ in [
            "list",
            "tuple",
        ]:
            array_like = array_like[0]
        if numpy_is_array_bknd(array_like):
>           return fn(*args, **kwargs)

ivy_transpiled_outputs/numpy_outputs/ivy/utils/decorator_utils.py:200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = array([[1.7550201, 0.797831 , 2.1070554, 1.2118826]], dtype=float32), exponent = 2

    @numpy_handle_methods
    def numpy_pow_frnt_(tensor, exponent):
        from .pointwise_ops import numpy_pow_frnt
    
>       return numpy_pow_frnt(tensor, exponent)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/tensor.py:140: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (array([[1.7550201, 0.797831 , 2.1070554, 1.2118826]], dtype=float32), 2), kwargs = {}, numpy_is_array_bknd = <function numpy_is_array_bknd at 0x7fd14a42feb0>
array_like = array([[1.7550201, 0.797831 , 2.1070554, 1.2118826]], dtype=float32)

    @functools.wraps(fn)
    def wrapper(*args, **kwargs):
        from ..functional.ivy.general import numpy_is_array_bknd
    
        array_like = args[0]
        if hasattr(array_like, "__class__") and array_like.__class__.__name__ in [
            "list",
            "tuple",
        ]:
            array_like = array_like[0]
        if numpy_is_array_bknd(array_like):
>           return fn(*args, **kwargs)

ivy_transpiled_outputs/numpy_outputs/ivy/utils/decorator_utils.py:200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = array([[1.7550201, 0.797831 , 2.1070554, 1.2118826]], dtype=float32), exponent = array(2)

    @numpy_handle_methods
    def numpy_pow_frnt(input, exponent, *, out=None):
        from ...ivy.general import numpy_is_array_bknd
        from .creation_ops import numpy_as_tensor_frnt
        from ...backends.numpy.creation import numpy_asarray
        from .__init__ import numpy_promote_types_of_torch_inputs_frnt
        from ...ivy.data_type import numpy_is_int_dtype_bknd
        from ...backends.numpy.elementwise import numpy_pow
        from ...backends.numpy.utility import numpy_any
        from ...backends.numpy.searching import numpy_where
        from ...backends.numpy.elementwise import numpy_bitwise_and
        from ....data_classes.array.data_type import numpy_astype_bknd_
    
        if not numpy_is_array_bknd(input):
            input = numpy_as_tensor_frnt(input)
        if not numpy_is_array_bknd(exponent):
            if (
                any(dtype in str(input.dtype) for dtype in ["int8", "int16"])
                and isinstance(exponent, (int,))
                or "float16" in str(input.dtype)
                and isinstance(exponent, (float,))
            ):
                exponent = numpy_asarray(exponent, dtype=input.dtype)
            else:
                exponent = numpy_as_tensor_frnt(exponent)
>       input, exponent = numpy_promote_types_of_torch_inputs_frnt(input, exponent)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/pointwise_ops.py:91: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x1 = array([[1.7550201, 0.797831 , 2.1070554, 1.2118826]], dtype=float32), x2 = array(2)

    def numpy_promote_types_of_torch_inputs_frnt(x1, x2, /):
        from ...ivy.general import numpy_isscalar_bknd
        from ...ivy.data_type import numpy_is_int_dtype_bknd
        from ...backends.numpy.creation import numpy_asarray
        from ...ivy.data_type import numpy_default_dtype_bknd
        from .tensor import numpy_shape_frnt_
        from ...ivy.device import numpy_default_device_bknd
        from ....data_classes.array.data_type import numpy_astype_bknd_
    
        """Promote the dtype of the given native array inputs to a common dtype
        based on type promotion rules.
    
        While passing float or integer values or any other non-array input
        to this function, it should be noted that the return will be an
        array-like object. Therefore, outputs from this function should be
        used as inputs only for those functions that expect an array-like or
        tensor-like objects, otherwise it might give unexpected results.
        """
        if (
            numpy_isscalar_bknd(x1) or isinstance(x1, (list, tuple))
        ) and numpy_is_int_dtype_bknd(x1):
            x1 = numpy_asarray(x1, dtype="int64")
        elif numpy_isscalar_bknd(x1) or isinstance(x1, (list, tuple)):
            x1 = numpy_asarray(x1)
        if (
            numpy_isscalar_bknd(x2) or isinstance(x2, (list, tuple))
        ) and numpy_is_int_dtype_bknd(x2):
            x2 = numpy_asarray(x2, dtype="int64")
        elif numpy_isscalar_bknd(x2) or isinstance(x2, (list, tuple)):
            x2 = numpy_asarray(x2)
        type1 = numpy_default_dtype_bknd(item=x1).strip("u123456789")
        type2 = numpy_default_dtype_bknd(item=x2).strip("u123456789")
        if numpy_shape_frnt_(x1) != () and numpy_shape_frnt_(x2) == () and type1 == type2:
            x2 = numpy_asarray(
                x2,
                dtype=x1.dtype,
                device=numpy_default_device_bknd(item=x1, as_native=False),
            )
        elif numpy_shape_frnt_(x1) == () and numpy_shape_frnt_(x2) != () and type1 == type2:
            x1 = numpy_asarray(
                x1,
                dtype=x2.dtype,
                device=numpy_default_device_bknd(item=x2, as_native=False),
            )
        elif x1.dtype != x2.dtype:
>           promoted = numpy_promote_types_torch_frnt(x1.dtype, x2.dtype)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/__init__.py:87: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

type1 = dtype('float32'), type2 = dtype('int64')

    def numpy_promote_types_torch_frnt(type1, type2, /):
        from ...backends.numpy.general import numpy_get_item
        from ...backends.numpy.data_type import numpy_as_ivy_dtype
    
        try:
            ret = numpy_get_item(
>               torch_promotion_table,
                (numpy_as_ivy_dtype(type1), numpy_as_ivy_dtype(type2)),
            )
E           NameError: name 'torch_promotion_table' is not defined

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/__init__.py:34: NameError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.epipolar._metrics.symmetrical_epipolar_distance
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/geometry/test_epipolar.py::test_find_essential[numpy-s2s-False] - AttributeError: module 'numpy' has no attribute 'bool'.
FAILED kornia/geometry/test_epipolar.py::test_find_fundamental[numpy-s2s-False] - AttributeError: module 'numpy' has no attribute 'bool'.
FAILED kornia/geometry/test_epipolar.py::test_sampson_epipolar_distance[numpy-s2s-False] - NameError: name 'torch_promotion_table' is not defined
FAILED kornia/geometry/test_epipolar.py::test_symmetrical_epipolar_distance[numpy-s2s-False] - NameError: name 'torch_promotion_table' is not defined
============================================================================== 4 failed, 22 passed in 1534.69s (0:25:34) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 18 items

kornia/augmentation/test_augmentation1.py .......F..........                                                                                                                                     [100%]

=============================================================================================== FAILURES ===============================================================================================
________________________________________________________________________________ test_RandomClahe[tensorflow-s2s-False] ________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_RandomClahe(target_framework, mode, backend_compile):
        print("kornia.augmentation.RandomClahe")
    
        init_args = ()
        init_kwargs = {}
        call_args = (torch.rand(2, 3, 10, 20),)
        call_kwargs = {}
    
>       _test_augmentation_class(
            kornia.augmentation.RandomClahe,
            target_framework,
            init_args,
            init_kwargs,
            call_args,
            call_kwargs,
            deterministic_output=False,
            backend_compile=backend_compile,
        )

kornia/augmentation/test_augmentation1.py:216: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

augmentation_cls = <class 'kornia.augmentation._2d.intensity.clahe.RandomClahe'>, target = 'tensorflow', init_args = (), init_kwargs = {}
call_args = (tensor([[[[0.1908, 0.8038, 0.7293,  ..., 0.0708, 0.0105, 0.6092],
          [0.4244, 0.9658, 0.9093,  ..., 0.7639, 0...., 0.6567, 0.1731,  ..., 0.8092, 0.0942, 0.1918],
          [0.6122, 0.0995, 0.7284,  ..., 0.1995, 0.2348, 0.4001]]]]),)
call_kwargs = {}, deterministic_output = False, backend_compile = False, tolerance = 0.001

    def _test_augmentation_class(
        augmentation_cls,
        target,
        init_args=(),
        init_kwargs={},
        call_args=(),
        call_kwargs={},
        deterministic_output=True,
        backend_compile=False,
        tolerance=1e-3,
    ):
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, target=target)
        transpiled_cls = eval("transpiled_" + f"{augmentation_cls.__module__}.{augmentation_cls.__name__}")
    
        torch_aug = augmentation_cls(*init_args, **init_kwargs)
        transpiled_init_args = _nest_torch_tensor_to_new_framework(init_args, target)
        transpiled_init_kwargs = _nest_torch_tensor_to_new_framework(init_kwargs, target)
        transpiled_aug = transpiled_cls(*transpiled_init_args, **transpiled_init_kwargs)
    
        # assert dir(torch_aug) == dir(transpiled_aug), f"attributes/methods of transpiled object do not align with the original - orig: {dir(torch_aug)} != transpiled: {dir(transpiled_aug)}"
    
        torch_out = torch_aug(*call_args, **call_kwargs)
        transpiled_call_args = _nest_torch_tensor_to_new_framework(call_args, target)
        transpiled_call_kwargs = _nest_torch_tensor_to_new_framework(call_kwargs, target)
>       transpiled_out = transpiled_aug(*transpiled_call_args, **transpiled_call_kwargs)

kornia/augmentation/test_augmentation1.py:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomClahe(clip_limit_factor=(40.0, 40.0), p=0.5, p_batch=1.0, same_on_batch=False, grid_size=(8, 8), slow_and_differentiable=False)
args = (<tf.Tensor: shape=(2, 3, 10, 20), dtype=float32, numpy=
array([[[[0.19083053, 0.8037547 , 0.7292734 , ..., 0.07083112...
         [0.6121892 , 0.09945101, 0.7283598 , ..., 0.19946468,
          0.23484182, 0.40005296]]]], dtype=float32)>,)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x5555a15ced90, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...kexec', code_context=['        return self._inner_hookexec(hook_name, methods, kwargs, firstresult)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomClahe(clip_limit_factor=(40.0, 40.0), p=0.5, p_batch=1.0, same_on_batch=False, grid_size=(8, 8), slo...,
         [0.6121892 , 0.09945101, 0.7283598 , ..., 0.19946468,
          0.23484182, 0.40005296]]]], dtype=float32)>)
kwargs = {}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomClahe(clip_limit_factor=(40.0, 40.0), p=0.5, p_batch=1.0, same_on_batch=False, grid_size=(8, 8), slow_and_differentiable=False), v = None, buffers = None
args = (<tf.Tensor: shape=(2, 3, 10, 20), dtype=float32, numpy=
array([[[[0.19083053, 0.8037547 , 0.7292734 , ..., 0.07083112...
         [0.6121892 , 0.09945101, 0.7283598 , ..., 0.19946468,
          0.23484182, 0.40005296]]]], dtype=float32)>,)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomClahe(clip_limit_factor=(40.0, 40.0), p=0.5, p_batch=1.0, same_on_batch=False, grid_size=(8, 8), slo...,
         [0.6121892 , 0.09945101, 0.7283598 , ..., 0.19946468,
          0.23484182, 0.40005296]]]], dtype=float32)>)
kwargs = {'buffers': None, 'v': None}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomClahe(clip_limit_factor=(40.0, 40.0), p=0.5, p_batch=1.0, same_on_batch=False, grid_size=(8, 8), slow_and_differentiable=False), v = None, buffers = None
args = (<tf.Tensor: shape=(2, 3, 10, 20), dtype=float32, numpy=
array([[[[0.19083053, 0.8037547 , 0.7292734 , ..., 0.07083112...
         [0.6121892 , 0.09945101, 0.7283598 , ..., 0.19946468,
          0.23484182, 0.40005296]]]], dtype=float32)>,)
kwargs = {}
first_arr = <tf.Tensor: shape=(2, 3, 10, 20), dtype=float32, numpy=
array([[[[0.19083053, 0.8037547 , 0.7292734 , ..., 0.07083112,...],
         [0.6121892 , 0.09945101, 0.7283598 , ..., 0.19946468,
          0.23484182, 0.40005296]]]], dtype=float32)>
replace_v = False, replace_buffers = False, call_signature = <Signature (input, params=None, **kwargs)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Layer, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Layer, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Layer, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomClahe(clip_limit_factor=(40.0, 40.0), p=0.5, p_batch=1.0, same_on_batch=False, grid_size=(8, 8), slow_and_differentiable=False),)
kwargs = {'input': <tf.Tensor: shape=(2, 3, 10, 20), dtype=float32, numpy=
array([[[[0.19083053, 0.8037547 , 0.7292734 , ..., 0...,
         [0.6121892 , 0.09945101, 0.7283598 , ..., 0.19946468,
          0.23484182, 0.40005296]]]], dtype=float32)>}

    @wraps(fn)
    def error_handler(*args, **kwargs):
        if not is_traceback_filtering_enabled():
            return fn(*args, **kwargs)
    
        filtered_tb = None
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            filtered_tb = _process_traceback_frames(e.__traceback__)
            # To get the full stack trace, call:
            # `keras.config.disable_traceback_filtering()`
>           raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/keras/src/utils/traceback_utils.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomClahe(clip_limit_factor=(40.0, 40.0), p=0.5, p_batch=1.0, same_on_batch=False, grid_size=(8, 8), slow_and_differentiable=False)
input = <tf.Tensor: shape=(2, 3, 10, 20), dtype=float32, numpy=
array([[[[0.19083053, 0.8037547 , 0.7292734 , ..., 0.07083112,...],
         [0.6121892 , 0.09945101, 0.7283598 , ..., 0.19946468,
          0.23484182, 0.40005296]]]], dtype=float32)>
params = {'batch_prob': <tf.Tensor: shape=(2,), dtype=float32, numpy=array([0., 1.], dtype=float32)>, 'clip_limit_factor': <tf....ray([40.], dtype=float32)>, 'forward_input_shape': <tf.Tensor: shape=(4,), dtype=int64, numpy=array([ 2,  3, 10, 20])>}
kwargs = {}, tensorflow_shape_frnt_ = <function tensorflow_shape_frnt_ at 0x7f193436d000>, tensorflow_set_item = <function tensorflow_set_item at 0x7f192f06f1c0>
tensor = <function tensorflow_tensor_frnt at 0x7f193b5e3eb0>
in_tensor = <tf.Tensor: shape=(2, 3, 10, 20), dtype=float32, numpy=
array([[[[0.19083053, 0.8037547 , 0.7292734 , ..., 0.07083112,...],
         [0.6121892 , 0.09945101, 0.7283598 , ..., 0.19946468,
          0.23484182, 0.40005296]]]], dtype=float32)>
input_shape = ivy.frontends.torch.Size([2, 3, 10, 20]), batch_shape = ivy.frontends.torch.Size([2, 3, 10, 20]), flags = {'grid_size': (8, 8), 'slow_and_differentiable': False}

    def call(self, input, params=None, **kwargs):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ...ivy.functional.backends.tensorflow.general import tensorflow_set_item
        from ..core._backend import tensor
    
        in_tensor = self.__unpack_input__(input)
        input_shape = tensorflow_shape_frnt_(in_tensor)
        in_tensor = self.transform_tensor(in_tensor)
        batch_shape = tensorflow_shape_frnt_(in_tensor)
        if params is None:
            params = self.forward_parameters(batch_shape)
        if "batch_prob" not in params:
            params = tensorflow_set_item(
                params, "batch_prob", tensor([True] * batch_shape[0])
            )
        params, flags = self._process_kwargs_to_params_and_flags(
            params, self.flags, **kwargs
        )
>       output = self.apply_func(in_tensor, params, flags)

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/base.py:236: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomClahe(clip_limit_factor=(40.0, 40.0), p=0.5, p_batch=1.0, same_on_batch=False, grid_size=(8, 8), slow_and_differentiable=False)
in_tensor = <tf.Tensor: shape=(2, 3, 10, 20), dtype=float32, numpy=
array([[[[0.19083053, 0.8037547 , 0.7292734 , ..., 0.07083112,...],
         [0.6121892 , 0.09945101, 0.7283598 , ..., 0.19946468,
          0.23484182, 0.40005296]]]], dtype=float32)>
params = {'batch_prob': <tf.Tensor: shape=(2,), dtype=float32, numpy=array([0., 1.], dtype=float32)>, 'clip_limit_factor': <tf....ray([40.], dtype=float32)>, 'forward_input_shape': <tf.Tensor: shape=(4,), dtype=int64, numpy=array([ 2,  3, 10, 20])>}
flags = {'grid_size': (8, 8), 'slow_and_differentiable': False}

    def apply_func(self, in_tensor, params, flags=None):
        if flags is None:
            flags = self.flags
        trans_matrix = self.generate_transformation_matrix(in_tensor, params, flags)
>       output = self.transform_inputs(in_tensor, params, flags, trans_matrix)

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/_2d/base.py:127: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomClahe(clip_limit_factor=(40.0, 40.0), p=0.5, p_batch=1.0, same_on_batch=False, grid_size=(8, 8), slow_and_differentiable=False)
input = <tf.Tensor: shape=(2, 3, 10, 20), dtype=float32, numpy=
array([[[[0.19083053, 0.8037547 , 0.7292734 , ..., 0.07083112,...],
         [0.6121892 , 0.09945101, 0.7283598 , ..., 0.19946468,
          0.23484182, 0.40005296]]]], dtype=float32)>
params = {'batch_prob': <tf.Tensor: shape=(2,), dtype=float32, numpy=array([0., 1.], dtype=float32)>, 'clip_limit_factor': <tf....ray([40.], dtype=float32)>, 'forward_input_shape': <tf.Tensor: shape=(4,), dtype=int64, numpy=array([ 2,  3, 10, 20])>}
flags = {'grid_size': (8, 8), 'slow_and_differentiable': False}
transform = <tf.Tensor: shape=(2, 3, 3), dtype=float32, numpy=
array([[[1., 0., 0.],
        [0., 1., 0.],
        [0., 0., 1.]],

       [[1., 0., 0.],
        [0., 1., 0.],
        [0., 0., 1.]]], dtype=float32)>
kwargs = {}, tensorflow_shape_frnt_ = <function tensorflow_shape_frnt_ at 0x7f193436d000>, tensorflow_all_frnt_ = <function tensorflow_all_frnt_ at 0x7f193436e710>
tensorflow_any_frnt_ = <function tensorflow_any_frnt_ at 0x7f192cae36d0>, tensorflow_get_item = <function tensorflow_get_item at 0x7f192f06f010>
tensorflow_is_autocast_enabled = <function tensorflow_is_autocast_enabled at 0x7f193b97e050>, tensorflow_type_frnt_ = <function tensorflow_type_frnt_ at 0x7f192cae23b0>
tensorflow_index_put_frnt_ = <function tensorflow_index_put_frnt_ at 0x7f192cae3760>

    def transform_inputs(self, input, params, flags, transform=None, **kwargs):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_all_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_any_frnt_
        from ...ivy.functional.backends.tensorflow.general import tensorflow_get_item
        from ..utils.helpers import tensorflow_is_autocast_enabled
        from ...ivy.functional.frontends.torch.tensor import tensorflow_type_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_index_put_frnt_
        from .utils.helpers import tensorflow__transform_output_shape
    
        params, flags = self._process_kwargs_to_params_and_flags(
            self._params if params is None else params, flags, **kwargs
        )
        batch_prob = params["batch_prob"]
        to_apply = batch_prob > 0.5
        ori_shape = tensorflow_shape_frnt_(input)
        in_tensor = self.transform_tensor(input)
        self.validate_tensor(in_tensor)
        if tensorflow_all_frnt_(to_apply):
            output = self.apply_transform(in_tensor, params, flags, transform=transform)
        elif not tensorflow_any_frnt_(to_apply):
            output = self.apply_non_transform(
                in_tensor, params, flags, transform=transform
            )
        else:
            output = self.apply_non_transform(
                in_tensor, params, flags, transform=transform
            )
>           applied = self.apply_transform(
                tensorflow_get_item(in_tensor, to_apply),
                params,
                flags,
                transform=transform
                if transform is None
                else tensorflow_get_item(transform, to_apply),
            )

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/base.py:363: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomClahe(clip_limit_factor=(40.0, 40.0), p=0.5, p_batch=1.0, same_on_batch=False, grid_size=(8, 8), slow_and_differentiable=False)
input = <tf.Tensor: shape=(1, 3, 10, 20), dtype=float32, numpy=
array([[[[6.93601370e-01, 8.06718946e-01, 2.21929252e-01,
    ...          4.93429422e-01, 1.00198686e-01, 1.99464679e-01,
          2.34841824e-01, 4.00052965e-01]]]], dtype=float32)>
params = {'batch_prob': <tf.Tensor: shape=(2,), dtype=float32, numpy=array([0., 1.], dtype=float32)>, 'clip_limit_factor': <tf....ray([40.], dtype=float32)>, 'forward_input_shape': <tf.Tensor: shape=(4,), dtype=int64, numpy=array([ 2,  3, 10, 20])>}
flags = {'grid_size': (8, 8), 'slow_and_differentiable': False}
transform = <tf.Tensor: shape=(1, 3, 3), dtype=float32, numpy=
array([[[1., 0., 0.],
        [0., 1., 0.],
        [0., 0., 1.]]], dtype=float32)>

    def apply_transform(self, input, params, flags, transform=None):
        from ....enhance.equalization import tensorflow_equalize_clahe
    
        clip_limit = float(params["clip_limit_factor"][0])
>       return tensorflow_equalize_clahe(
            input, clip_limit, flags["grid_size"], flags["slow_and_differentiable"]
        )

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/_2d/intensity/clahe.py:61: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = <tf.Tensor: shape=(1, 3, 10, 20), dtype=float32, numpy=
array([[[[6.93601370e-01, 8.06718946e-01, 2.21929252e-01,
    ...          4.93429422e-01, 1.00198686e-01, 1.99464679e-01,
          2.34841824e-01, 4.00052965e-01]]]], dtype=float32)>
args = (40.0, (8, 8), False), kwargs = {}, tensorflow_numel_frnt_ = <function tensorflow_numel_frnt_ at 0x7f193436e440>, tensorflow_shape_frnt_ = <function tensorflow_shape_frnt_ at 0x7f193436d000>
tensorflow_view_frnt_ = <function tensorflow_view_frnt_ at 0x7f193436f370>, input_shape = ivy.frontends.torch.Size([1, 3, 10, 20])

    @wraps(f)
    def _wrapper(input, *args, **kwargs):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_numel_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_view_frnt_
    
        if not isinstance(input, (tensorflow.Tensor, tensorflow.keras.Variable)):
            raise TypeError(f"Input input type is not a Tensor. Got {type(input)}")
        if tensorflow_numel_frnt_(input) == 0:
            raise ValueError("Invalid input tensor, it is empty.")
        input_shape = tensorflow_shape_frnt_(input)
        input = tensorflow__to_bchw(input)
>       output = f(input, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/kornia/utils/image.py:73: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = <tf.Tensor: shape=(1, 3, 10, 20), dtype=float32, numpy=
array([[[[6.93601370e-01, 8.06718946e-01, 2.21929252e-01,
    ...          4.93429422e-01, 1.00198686e-01, 1.99464679e-01,
          2.34841824e-01, 4.00052965e-01]]]], dtype=float32)>
clip_limit = 40.0, grid_size = (8, 8), slow_and_differentiable = False

    @tensorflow_perform_keep_shape_image
    def tensorflow_equalize_clahe(
        input, clip_limit=40.0, grid_size=(8, 8), slow_and_differentiable=False
    ):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_reshape_as_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_permute_frnt_
        from ...ivy.functional.backends.tensorflow.general import tensorflow_get_item
        from ...ivy.functional.frontends.torch.tensor import tensorflow_dim_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_squeeze_frnt_
    
        if not isinstance(clip_limit, (float,)):
            raise TypeError(f"Input clip_limit type is not float. Got {type(clip_limit)}")
        if not isinstance(grid_size, (tuple,)):
            raise TypeError(f"Input grid_size type is not Tuple. Got {type(grid_size)}")
        if len(grid_size) != 2:
            raise TypeError(
                f"Input grid_size is not a Tuple with 2 elements. Got {len(grid_size)}"
            )
        if isinstance(grid_size[0], (float,)) or isinstance(grid_size[1], (float,)):
            raise TypeError("Input grid_size type is not valid, must be a Tuple[int, int].")
        if grid_size[0] <= 0 or grid_size[1] <= 0:
            raise ValueError(f"Input grid_size elements must be positive. Got {grid_size}")
        imgs: typing.Any = input
>       hist_tiles, img_padded = tensorflow__compute_tiles(imgs, grid_size, True)

ivy_transpiled_outputs/tensorflow_outputs/kornia/enhance/equalization.py:518: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

imgs = <tf.Tensor: shape=(1, 3, 10, 20), dtype=float32, numpy=
array([[[[6.93601370e-01, 8.06718946e-01, 2.21929252e-01,
    ...          4.93429422e-01, 1.00198686e-01, 1.99464679e-01,
          2.34841824e-01, 4.00052965e-01]]]], dtype=float32)>
grid_size = (8, 8), even_tile_size = True

    def tensorflow__compute_tiles(imgs, grid_size, even_tile_size=False):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ...ivy.functional.frontends.torch.nn.functional.vision_functions import (
            tensorflow_pad_frnt,
        )
        from ...ivy.functional.frontends.torch.tensor import tensorflow_contiguous_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_squeeze_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_unfold_frnt_
    
        batch: typing.Any = imgs
        h, w = tensorflow_shape_frnt_(batch)[-2:][0], tensorflow_shape_frnt_(batch)[-2:][1]
        kernel_vert: typing.Any = math.ceil(h / grid_size[0])
        kernel_horz: typing.Any = math.ceil(w / grid_size[1])
        if even_tile_size:
            kernel_vert = kernel_vert + (1 if kernel_vert % 2 else 0)
            kernel_horz = kernel_horz + (1 if kernel_horz % 2 else 0)
        pad_vert = kernel_vert * grid_size[0] - h
        pad_horz = kernel_horz * grid_size[1] - w
        if (
            pad_vert > tensorflow_shape_frnt_(batch)[-2]
            or pad_horz > tensorflow_shape_frnt_(batch)[-1]
        ):
            raise ValueError(
                "Cannot compute tiles on the image according to the given grid size"
            )
        if pad_vert > 0 or pad_horz > 0:
            batch = tensorflow_pad_frnt(batch, [0, pad_horz, 0, pad_vert], mode="reflect")
        c: typing.Any = tensorflow_shape_frnt_(batch)[-3]
        tiles: typing.Any = tensorflow_contiguous_frnt_(
            tensorflow_squeeze_frnt_(
>               tensorflow_unfold_frnt_(
                    tensorflow_unfold_frnt_(
                        tensorflow_unfold_frnt_(batch, 1, c, c), 2, kernel_vert, kernel_vert
                    ),
                    3,
                    kernel_horz,
                    kernel_horz,
                ),
                1,
            )
        )

ivy_transpiled_outputs/tensorflow_outputs/kornia/enhance/equalization.py:65: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (<tf.Tensor: shape=(1, 1, 1, 2, 16, 32), dtype=float32, numpy=
array([[[[[[6.9360137e-01, 8.0671895e-01, 2.2192925e-01...-01, 5.7236421e-01, ...,
            1.2735236e-01, 5.8912277e-01, 8.0045509e-01]]]]]],
      dtype=float32)>, 3, 4, 4)
kwargs = {}, tensorflow_is_array_bknd = <function tensorflow_is_array_bknd at 0x7f192f0cd090>
array_like = <tf.Tensor: shape=(1, 1, 1, 2, 16, 32), dtype=float32, numpy=
array([[[[[[6.9360137e-01, 8.0671895e-01, 2.2192925e-01,...8.8772911e-01, 5.7236421e-01, ...,
            1.2735236e-01, 5.8912277e-01, 8.0045509e-01]]]]]],
      dtype=float32)>

    @functools.wraps(fn)
    def wrapper(*args, **kwargs):
        from ..functional.ivy.general import tensorflow_is_array_bknd
    
        array_like = args[0]
        if hasattr(array_like, "__class__") and array_like.__class__.__name__ in [
            "list",
            "tuple",
        ]:
            array_like = array_like[0]
        if tensorflow_is_array_bknd(array_like):
>           return fn(*args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:202: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = <tf.Tensor: shape=(1, 1, 1, 2, 16, 32), dtype=float32, numpy=
array([[[[[[6.9360137e-01, 8.0671895e-01, 2.2192925e-01,...8.8772911e-01, 5.7236421e-01, ...,
            1.2735236e-01, 5.8912277e-01, 8.0045509e-01]]]]]],
      dtype=float32)>
dimension = 3, size = 4, step = 4

    @tensorflow_handle_methods
    def tensorflow_unfold_frnt_(tensor, dimension, size, step):
        from ...backends.tensorflow.general import tensorflow_get_item
        from ...backends.tensorflow.general import tensorflow_set_item
        from .indexing_slicing_joining_mutating_ops import tensorflow_stack_frnt
    
        slices = []
        self_shape = tuple(tensorflow_shape_frnt_(tensor))
        for i in range(0, tensorflow_get_item(self_shape, dimension) - size + 1, step):
            slicing = [slice(None)] * len(tensorflow_shape_frnt_(tensor))
            slicing = tensorflow_set_item(slicing, dimension, slice(i, i + size))
            slices.append(tensorflow_get_item(tensor, tuple(slicing)))
>       stacked = tensorflow_stack_frnt(slices, dim=dimension)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/tensor.py:660: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensors = [], dim = 3

    def tensorflow_stack_frnt(tensors, dim=0, *, out=None):
        from ...backends.tensorflow.manipulation import tensorflow_stack
    
>       return tensorflow_stack(tensors, axis=dim, out=out)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/indexing_slicing_joining_mutating_ops.py:147: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

arrays = []

    def tensorflow_stack(
        arrays: Union[Tuple[tensorflow.Tensor], List[tensorflow.Tensor]],
        /,
        *,
        axis: int = 0,
        out: Optional[Union[tensorflow.Tensor, tensorflow.Variable]] = None,
    ):
        try:
>           return tensorflow.experimental.numpy.stack(arrays, axis)
E           IndexError: Exception encountered when calling tensorflow_RandomClahe.call().
E           
E           [1mlist index out of range[0m
E           
E           Arguments received by tensorflow_RandomClahe.call():
E             • input=tf.Tensor(shape=(2, 3, 10, 20), dtype=float32)
E             • params=None
E             • kwargs=<class 'inspect._empty'>

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/backends/tensorflow/manipulation.py:260: IndexError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.RandomClahe
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/augmentation/test_augmentation1.py::test_RandomClahe[tensorflow-s2s-False] - IndexError: Exception encountered when calling tensorflow_RandomClahe.call().
============================================================================== 1 failed, 17 passed in 3746.09s (1:02:26) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 1 item

kornia/geometry/test_ransac.py s                                                                                                                                                                 [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
========================================================================================== 1 skipped in 5.01s ==========================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 2 items

kornia/geometry/test_line.py .F                                                                                                                                                                  [100%]

=============================================================================================== FAILURES ===============================================================================================
_________________________________________________________________________________ test_ParametrizedLine[jax-s2s-False] _________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_ParametrizedLine(target_framework, mode, backend_compile):
        print("kornia.geometry.line.ParametrizedLine")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target_framework)
    
        origin = torch.tensor([0.0, 0.0], requires_grad=True)
        direction = torch.tensor([1.0, 1.0], requires_grad=True)
        torch_line = kornia.geometry.line.ParametrizedLine(origin, direction)
    
        transpiled_origin = _nest_torch_tensor_to_new_framework(origin, target_framework)
        transpiled_direction = _nest_torch_tensor_to_new_framework(direction, target_framework)
        transpiled_line = transpiled_kornia.geometry.line.ParametrizedLine(transpiled_origin, transpiled_direction)
    
        # Test .dim()
        torch_dim = torch_line.dim()
        transpiled_dim = transpiled_line.dim()
        assert torch_dim == transpiled_dim
    
        # Test .direction property
        _to_numpy_and_allclose(torch_line.direction, transpiled_line.direction)
    
        # Test .origin property
        _to_numpy_and_allclose(torch_line.origin, transpiled_line.origin)
    
        # Test .distance()
        point = torch.tensor([1.0, 0.0], requires_grad=True)
        transpiled_point = _nest_torch_tensor_to_new_framework(point, target_framework)
    
        torch_distance = torch_line.distance(point)
        transpiled_distance = transpiled_line.distance(transpiled_point)
        _to_numpy_and_allclose(torch_distance, transpiled_distance)
    
        # Test .point_at()
        t_value = torch.tensor(0.5)
        transpiled_t_value = _nest_torch_tensor_to_new_framework(t_value, target_framework)
    
        torch_point_at = torch_line.point_at(t_value)
        transpiled_point_at = transpiled_line.point_at(transpiled_t_value)
        _to_numpy_and_allclose(torch_point_at, transpiled_point_at)
    
        # Test .projection()
        torch_projection = torch_line.projection(point)
        transpiled_projection = transpiled_line.projection(transpiled_point)
        _to_numpy_and_allclose(torch_projection, transpiled_projection)
    
        # Test .squared_distance()
        torch_squared_distance = torch_line.squared_distance(point)
        transpiled_squared_distance = transpiled_line.squared_distance(transpiled_point)
        _to_numpy_and_allclose(torch_squared_distance, transpiled_squared_distance)
    
        # Test class method .through()
        p0 = torch.tensor([0.0, 0.0], requires_grad=True)
        p1 = torch.tensor([1.0, 1.0], requires_grad=True)
        transpiled_p0 = _nest_torch_tensor_to_new_framework(p0, target_framework)
        transpiled_p1 = _nest_torch_tensor_to_new_framework(p1, target_framework)
    
        torch_line_through = kornia.geometry.line.ParametrizedLine.through(p0, p1)
>       transpiled_line_through = transpiled_kornia.geometry.line.ParametrizedLine.through(transpiled_p0, transpiled_p1)
E       TypeError: 'classmethod' object is not callable

kornia/geometry/test_line.py:107: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.line.ParametrizedLine
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/geometry/test_line.py::test_ParametrizedLine[jax-s2s-False] - TypeError: 'classmethod' object is not callable
================================================================================ 1 failed, 1 passed in 76.54s (0:01:16) ================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 6 items

kornia/augmentation/test_container.py ssssss                                                                                                                                                     [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
========================================================================================== 6 skipped in 5.33s ==========================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 7 items

kornia/test_morphology.py .......                                                                                                                                                                [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
==================================================================================== 7 passed in 451.83s (0:07:31) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 3 items

kornia/augmentation/test_auto.py sss                                                                                                                                                             [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
========================================================================================== 3 skipped in 5.37s ==========================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 5 items

kornia/geometry/test_calibration.py ....F                                                                                                                                                        [100%]

=============================================================================================== FAILURES ===============================================================================================
_________________________________________________________________________________ test_solve_pnp_dlt[numpy-s2s-False] __________________________________________________________________________________

target_framework = 'numpy', mode = 's2s', backend_compile = False

    def test_solve_pnp_dlt(target_framework, mode, backend_compile):
        trace_args = (
            torch.tensor([[
                [5.0, -5.0, 0.0], [0.0, 0.0, 1.5],
                [2.5, 3.0, 6.0], [9.0, -2.0, 3.0],
                [-4.0, 5.0, 2.0], [-5.0, 5.0, 1.0]
            ]], dtype=torch.float64),
            torch.tensor([[
                [1409.1504, -800.936], [407.0207, -182.1229],
                [392.7021, 177.9428], [1016.838, -2.9416],
                [-63.1116, 142.9204], [-219.3874, 99.666]
            ]], dtype=torch.float64),
            torch.tensor([[
                [500.0, 0.0, 250.0],
                [0.0, 500.0, 250.0],
                [0.0, 0.0, 1.0]
            ]], dtype=torch.float64),
        )
        trace_kwargs = {'svd_eps': 1e-3}
        test_args = (
            torch.tensor([[
                [10.0, -10.0, 0.0], [0.0, 0.0, 3.0],
                [5.0, 6.0, 12.0], [18.0, -4.0, 6.0],
                [-8.0, 10.0, 4.0], [-10.0, 10.0, 2.0]
            ]], dtype=torch.float64),
            torch.tensor([[
                [2818.3008, -1601.872], [814.0414, -364.2458],
                [785.4042, 355.8856], [2033.676, -5.8832],
                [-126.2232, 285.8408], [-438.7748, 199.332]
            ]], dtype=torch.float64),
            torch.tensor([[
                [1000.0, 0.0, 500.0],
                [0.0, 1000.0, 500.0],
                [0.0, 0.0, 1.0]
            ]], dtype=torch.float64),
        )
        test_kwargs = {'svd_eps': 1e-3}
>       _test_function(
            kornia.geometry.calibration.solve_pnp_dlt,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/geometry/test_calibration.py:148: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function solve_pnp_dlt at 0x7f0a53db0af0>
trace_args = (tensor([[[ 5.0000, -5.0000,  0.0000],
         [ 0.0000,  0.0000,  1.5000],
         [ 2.5000,  3.0000,  6.0000],
   ...loat64), tensor([[[500.,   0., 250.],
         [  0., 500., 250.],
         [  0.,   0.,   1.]]], dtype=torch.float64))
trace_kwargs = {'svd_eps': 0.001}
test_args = (tensor([[[ 10., -10.,   0.],
         [  0.,   0.,   3.],
         [  5.,   6.,  12.],
         [ 18.,  -4.,   6.],
 ...tensor([[[1000.,    0.,  500.],
         [   0., 1000.,  500.],
         [   0.,    0.,    1.]]], dtype=torch.float64))
test_kwargs = {'svd_eps': 0.001}, target = 'numpy', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function solve_pnp_dlt at 0x7f0a53db0af0>, fn_name = 'kornia.geometry.calibration.solve_pnp_dlt'
trace_args = (tensor([[[ 5.0000, -5.0000,  0.0000],
         [ 0.0000,  0.0000,  1.5000],
         [ 2.5000,  3.0000,  6.0000],
   ...loat64), tensor([[[500.,   0., 250.],
         [  0., 500., 250.],
         [  0.,   0.,   1.]]], dtype=torch.float64))
trace_kwargs = {'svd_eps': 0.001}
test_args = (tensor([[[ 10., -10.,   0.],
         [  0.,   0.,   3.],
         [  5.,   6.,  12.],
         [ 18.,  -4.,   6.],
 ...tensor([[[1000.,    0.,  500.],
         [   0., 1000.,  500.],
         [   0.,    0.,    1.]]], dtype=torch.float64))
test_kwargs = {'svd_eps': 0.001}, target = 'numpy', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:232: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

world_points = array([[[ 5. , -5. ,  0. ],
        [ 0. ,  0. ,  1.5],
        [ 2.5,  3. ,  6. ],
        [ 9. , -2. ,  3. ],
        [-4. ,  5. ,  2. ],
        [-5. ,  5. ,  1. ]]])
img_points = array([[[1409.1504, -800.936 ],
        [ 407.0207, -182.1229],
        [ 392.7021,  177.9428],
        [1016.838 ,   -2.9416],
        [ -63.1116,  142.9204],
        [-219.3874,   99.666 ]]])
intrinsics = array([[[500.,   0., 250.],
        [  0., 500., 250.],
        [  0.,   0.,   1.]]]), weights = None, svd_eps = 0.001

    def numpy_solve_pnp_dlt(
        world_points, img_points, intrinsics, weights=None, svd_eps=0.0001
    ):
        from ....ivy.functional.frontends.torch.tensor import numpy_shape_frnt_
        from ...utils.helpers import numpy__torch_linalg_svdvals
        from ....ivy.functional.frontends.torch.reduction_ops import numpy_any_frnt
        from ....ivy.functional.frontends.torch.blas_and_lapack_ops import (
            numpy_inverse_frnt,
        )
        from ..conversions import numpy_convert_points_to_homogeneous
        from ..linalg import numpy_transform_points
        from ....ivy.functional.backends.numpy.general import numpy_set_item
        from ....ivy.functional.frontends.torch.blas_and_lapack_ops import (
            numpy_svd_frnt_base_count_1_frnt,
        )
        from ....ivy.functional.frontends.torch.tensor import numpy_reshape_frnt_
        from ...utils.misc import numpy_eye_like
        from ....ivy.functional.frontends.torch.blas_and_lapack_ops import numpy_bmm_frnt
        from ....ivy.functional.frontends.torch.blas_and_lapack_ops import numpy_det_frnt
        from ....ivy.functional.frontends.torch.reduction_ops import numpy_norm_frnt
        from ....ivy.functional.frontends.torch.linalg import numpy_qr_frnt
        from ....ivy.functional.frontends.torch.pointwise_ops import numpy_sign_frnt
        from ....ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            numpy_cat_frnt,
        )
        from ...core._backend import zeros
        from ...core._backend import ones_like
        from ...core._backend import where
    
        if not isinstance(world_points, (numpy.ndarray, numpy.ndarray)):
            raise AssertionError(
                f"world_points is not an instance of torch.Tensor. Type of world_points is {type(world_points)}"
            )
        if not isinstance(img_points, (numpy.ndarray, numpy.ndarray)):
            raise AssertionError(
                f"img_points is not an instance of torch.Tensor. Type of img_points is {type(img_points)}"
            )
        if not isinstance(intrinsics, (numpy.ndarray, numpy.ndarray)):
            raise AssertionError(
                f"intrinsics is not an instance of torch.Tensor. Type of intrinsics is {type(intrinsics)}"
            )
        if weights is not None and not isinstance(weights, (numpy.ndarray, numpy.ndarray)):
            raise AssertionError(
                f"If weights is not None, then weights should be an instance of torch.Tensor. Type of weights is {type(weights)}"
            )
        if not isinstance(svd_eps, (float,)):
            raise AssertionError(f"Type of svd_eps is not float. Got {type(svd_eps)}")
        accepted_dtypes = np.float32, np.float64
        if world_points.dtype not in accepted_dtypes:
            raise AssertionError(
                f"world_points must have one of the following dtypes {accepted_dtypes}. Currently it has {world_points.dtype}."
            )
        if img_points.dtype not in accepted_dtypes:
            raise AssertionError(
                f"img_points must have one of the following dtypes {accepted_dtypes}. Currently it has {img_points.dtype}."
            )
        if intrinsics.dtype not in accepted_dtypes:
            raise AssertionError(
                f"intrinsics must have one of the following dtypes {accepted_dtypes}. Currently it has {intrinsics.dtype}."
            )
        if (
            len(numpy_shape_frnt_(world_points)) != 3
            or numpy_shape_frnt_(world_points)[2] != 3
        ):
            raise AssertionError(
                f"world_points must be of shape (B, N, 3). Got shape {numpy_shape_frnt_(world_points)}."
            )
        if len(numpy_shape_frnt_(img_points)) != 3 or numpy_shape_frnt_(img_points)[2] != 2:
            raise AssertionError(
                f"img_points must be of shape (B, N, 2). Got shape {numpy_shape_frnt_(img_points)}."
            )
        if len(numpy_shape_frnt_(intrinsics)) != 3 or numpy_shape_frnt_(intrinsics)[1:] != (
            3,
            3,
        ):
            raise AssertionError(
                f"intrinsics must be of shape (B, 3, 3). Got shape {numpy_shape_frnt_(intrinsics)}."
            )
        if numpy_shape_frnt_(world_points)[1] != numpy_shape_frnt_(img_points)[1]:
            raise AssertionError(
                "world_points and img_points must have equal number of points."
            )
        if (
            numpy_shape_frnt_(world_points)[0] != numpy_shape_frnt_(img_points)[0]
            or numpy_shape_frnt_(world_points)[0] != numpy_shape_frnt_(intrinsics)[0]
        ):
            raise AssertionError(
                "world_points, img_points and intrinsics must have the same batch size."
            )
        if numpy_shape_frnt_(world_points)[1] < 6:
            raise AssertionError(
                f"At least 6 points are required to use this function. Got {numpy_shape_frnt_(world_points)[1]} points."
            )
        B, N = (
            numpy_shape_frnt_(world_points)[:2][0],
            numpy_shape_frnt_(world_points)[:2][1],
        )
        world_points_norm, world_transform_norm = numpy__mean_isotropic_scale_normalize(
            world_points
        )
        s = numpy__torch_linalg_svdvals(world_points_norm)
        if numpy_any_frnt(s[:, -1] < svd_eps):
            raise AssertionError(
                f"The last singular value of one/more of the elements of the batch is smaller than {svd_eps}. This function cannot be used if all world_points (of any element of the batch) lie on a line or if all world_points (of any element of the batch) lie on a plane."
            )
        intrinsics_inv = numpy_inverse_frnt(intrinsics)
        world_points_norm_h = numpy_convert_points_to_homogeneous(world_points_norm)
        img_points_inv = numpy_transform_points(intrinsics_inv, img_points)
        img_points_norm, img_transform_norm = numpy__mean_isotropic_scale_normalize(
            img_points_inv
        )
        inv_img_transform_norm = numpy_inverse_frnt(img_transform_norm)
        system = zeros((B, 2 * N, 12), dtype=world_points.dtype, device=None)
        system = numpy_set_item(
            system,
            (slice(None, None, None), slice(0, None, 2), slice(0, 4, None)),
            world_points_norm_h,
        )
        system = numpy_set_item(
            system,
            (slice(None, None, None), slice(1, None, 2), slice(4, 8, None)),
            world_points_norm_h,
        )
        system = numpy_set_item(
            system,
            (slice(None, None, None), slice(0, None, 2), slice(8, 12, None)),
            world_points_norm_h * -1 * img_points_norm[..., 0:1],
        )
        system = numpy_set_item(
            system,
            (slice(None, None, None), slice(1, None, 2), slice(8, 12, None)),
            world_points_norm_h * -1 * img_points_norm[..., 1:2],
        )
        _, _, v = numpy_svd_frnt_base_count_1_frnt(system)
        solution = v[..., -1]
        solution = numpy_reshape_frnt_(solution, B, 3, 4)
        solution_4x4 = numpy_eye_like(4, solution)
        solution_4x4 = numpy_set_item(
            solution_4x4,
            (slice(None, None, None), slice(None, 3, None), slice(None, None, None)),
            solution,
        )
        intermediate = numpy_bmm_frnt(solution_4x4, world_transform_norm)
        solution = numpy_bmm_frnt(inv_img_transform_norm, intermediate[:, :3, :])
        det = numpy_det_frnt(solution[:, :3, :3])
        ones = ones_like(det)
        sign_fix = where(det < 0, ones * -1, ones)
        solution = solution * sign_fix[:, None, None]
>       norm_col = numpy_norm_frnt(input=solution[:, :3, 0], p=2, dim=1)

ivy_transpiled_outputs/numpy_outputs/kornia/geometry/calibration/pnp.py:225: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (), kwargs = {'dim': 1, 'input': array([[0.0754885 , 0.02388223, 0.0574928 ]]), 'p': 2}, numpy_is_array_bknd = <function numpy_is_array_bknd at 0x7f09fa557490>

    @functools.wraps(fn)
    def wrapper(*args, **kwargs):
        from ..functional.ivy.general import numpy_is_array_bknd
    
>       array_like = args[0]
E       IndexError: tuple index out of range

ivy_transpiled_outputs/numpy_outputs/ivy/utils/decorator_utils.py:193: IndexError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.calibration.pnp.solve_pnp_dlt
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/geometry/test_calibration.py::test_solve_pnp_dlt[numpy-s2s-False] - IndexError: tuple index out of range
=============================================================================== 1 failed, 4 passed in 309.66s (0:05:09) ================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 44 items

kornia/test_filters.py ............................................                                                                                                                              [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
=================================================================================== 44 passed in 3903.13s (1:05:03) ====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 26 items

kornia/geometry/test_epipolar.py ..........................                                                                                                                                      [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
=================================================================================== 26 passed in 1704.86s (0:28:24) ====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 26 items

kornia/geometry/test_epipolar.py ..........................                                                                                                                                      [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
=================================================================================== 26 passed in 1754.99s (0:29:14) ====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 39 items

kornia/test_enhance.py ..............F........................                                                                                                                                   [100%]

=============================================================================================== FAILURES ===============================================================================================
______________________________________________________________________________ test_equalize_clahe[tensorflow-s2s-False] _______________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_equalize_clahe(target_framework, mode, backend_compile):
        trace_args = (torch.rand(1, 10, 20),)
        trace_kwargs = {
            "clip_limit": 40.0,
            "grid_size": (8, 8),
            "slow_and_differentiable": False,
        }
        test_args = (torch.rand(2, 3, 10, 20),)
        test_kwargs = {
            "clip_limit": 20.0,
            "grid_size": (4, 4),
            "slow_and_differentiable": False,
        }
>       _test_function(
            kornia.enhance.equalize_clahe,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
            skip=True,
        )

kornia/test_enhance.py:363: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function equalize_clahe at 0x7f65f2fffa30>
trace_args = (tensor([[[0.7797, 0.2073, 0.7368, 0.7358, 0.3811, 0.8732, 0.1539, 0.5519,
          0.8300, 0.1585, 0.6498, 0.0426, 0...         0.7581, 0.9361, 0.4948, 0.3495, 0.8324, 0.9945, 0.6825, 0.9597,
          0.8796, 0.9887, 0.4904, 0.7564]]]),)
trace_kwargs = {'clip_limit': 40.0, 'grid_size': (8, 8), 'slow_and_differentiable': False}
test_args = (tensor([[[[0.8728, 0.0225, 0.8517,  ..., 0.9147, 0.1524, 0.7710],
          [0.6233, 0.2913, 0.9570,  ..., 0.5427, 0...., 0.0998, 0.4278,  ..., 0.1427, 0.9486, 0.9228],
          [0.5866, 0.2074, 0.1388,  ..., 0.4717, 0.8476, 0.8597]]]]),)
test_kwargs = {'clip_limit': 20.0, 'grid_size': (4, 4), 'slow_and_differentiable': False}, target = 'tensorflow', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = True
deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function equalize_clahe at 0x7f65f2fffa30>, fn_name = 'kornia.enhance.equalize_clahe'
trace_args = (tensor([[[0.7797, 0.2073, 0.7368, 0.7358, 0.3811, 0.8732, 0.1539, 0.5519,
          0.8300, 0.1585, 0.6498, 0.0426, 0...         0.7581, 0.9361, 0.4948, 0.3495, 0.8324, 0.9945, 0.6825, 0.9597,
          0.8796, 0.9887, 0.4904, 0.7564]]]),)
trace_kwargs = {'clip_limit': 40.0, 'grid_size': (8, 8), 'slow_and_differentiable': False}
test_args = (tensor([[[[0.8728, 0.0225, 0.8517,  ..., 0.9147, 0.1524, 0.7710],
          [0.6233, 0.2913, 0.9570,  ..., 0.5427, 0...., 0.0998, 0.4278,  ..., 0.1427, 0.9486, 0.9228],
          [0.5866, 0.2074, 0.1388,  ..., 0.4717, 0.8476, 0.8597]]]]),)
test_kwargs = {'clip_limit': 20.0, 'grid_size': (4, 4), 'slow_and_differentiable': False}, target = 'tensorflow', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
>           graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:326: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:232: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = <tf.Tensor: shape=(1, 1, 10, 20), dtype=float32, numpy=
array([[[[0.7796958 , 0.20731449, 0.736813  , 0.7358386 , 0.38...0.99446225, 0.6824589 ,
          0.9596872 , 0.8795646 , 0.9886725 , 0.49041432, 0.75644857]]]],
      dtype=float32)>
args = (), kwargs = {'clip_limit': 40.0, 'grid_size': (8, 8), 'slow_and_differentiable': False}, tensorflow_numel_frnt_ = <function tensorflow_numel_frnt_ at 0x7f65987676d0>
tensorflow_shape_frnt_ = <function tensorflow_shape_frnt_ at 0x7f6598767880>, tensorflow_view_frnt_ = <function tensorflow_view_frnt_ at 0x7f65987652d0>
input_shape = ivy.frontends.torch.Size([1, 10, 20])

    @wraps(f)
    def _wrapper(input, *args, **kwargs):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_numel_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_view_frnt_
    
        if not isinstance(input, (tensorflow.Tensor, tensorflow.keras.Variable)):
            raise TypeError(f"Input input type is not a Tensor. Got {type(input)}")
        if tensorflow_numel_frnt_(input) == 0:
            raise ValueError("Invalid input tensor, it is empty.")
        input_shape = tensorflow_shape_frnt_(input)
        input = tensorflow__to_bchw(input)
>       output = f(input, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/kornia/utils/image.py:73: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = <tf.Tensor: shape=(1, 1, 10, 20), dtype=float32, numpy=
array([[[[0.7796958 , 0.20731449, 0.736813  , 0.7358386 , 0.38...0.99446225, 0.6824589 ,
          0.9596872 , 0.8795646 , 0.9886725 , 0.49041432, 0.75644857]]]],
      dtype=float32)>
clip_limit = 40.0, grid_size = (8, 8), slow_and_differentiable = False

    @tensorflow_perform_keep_shape_image
    def tensorflow_equalize_clahe(
        input, clip_limit=40.0, grid_size=(8, 8), slow_and_differentiable=False
    ):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_reshape_as_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_permute_frnt_
        from ...ivy.functional.backends.tensorflow.general import tensorflow_get_item
        from ...ivy.functional.frontends.torch.tensor import tensorflow_dim_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_squeeze_frnt_
    
        if not isinstance(clip_limit, (float,)):
            raise TypeError(f"Input clip_limit type is not float. Got {type(clip_limit)}")
        if not isinstance(grid_size, (tuple,)):
            raise TypeError(f"Input grid_size type is not Tuple. Got {type(grid_size)}")
        if len(grid_size) != 2:
            raise TypeError(
                f"Input grid_size is not a Tuple with 2 elements. Got {len(grid_size)}"
            )
        if isinstance(grid_size[0], (float,)) or isinstance(grid_size[1], (float,)):
            raise TypeError("Input grid_size type is not valid, must be a Tuple[int, int].")
        if grid_size[0] <= 0 or grid_size[1] <= 0:
            raise ValueError(f"Input grid_size elements must be positive. Got {grid_size}")
        imgs: typing.Any = input
>       hist_tiles, img_padded = tensorflow__compute_tiles(imgs, grid_size, True)

ivy_transpiled_outputs/tensorflow_outputs/kornia/enhance/equalization.py:518: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

imgs = <tf.Tensor: shape=(1, 1, 10, 20), dtype=float32, numpy=
array([[[[0.7796958 , 0.20731449, 0.736813  , 0.7358386 , 0.38...0.99446225, 0.6824589 ,
          0.9596872 , 0.8795646 , 0.9886725 , 0.49041432, 0.75644857]]]],
      dtype=float32)>
grid_size = (8, 8), even_tile_size = True

    def tensorflow__compute_tiles(imgs, grid_size, even_tile_size=False):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ...ivy.functional.frontends.torch.nn.functional.vision_functions import (
            tensorflow_pad_frnt,
        )
        from ...ivy.functional.frontends.torch.tensor import tensorflow_contiguous_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_squeeze_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_unfold_frnt_
    
        batch: typing.Any = imgs
        h, w = tensorflow_shape_frnt_(batch)[-2:][0], tensorflow_shape_frnt_(batch)[-2:][1]
        kernel_vert: typing.Any = math.ceil(h / grid_size[0])
        kernel_horz: typing.Any = math.ceil(w / grid_size[1])
        if even_tile_size:
            kernel_vert = kernel_vert + (1 if kernel_vert % 2 else 0)
            kernel_horz = kernel_horz + (1 if kernel_horz % 2 else 0)
        pad_vert = kernel_vert * grid_size[0] - h
        pad_horz = kernel_horz * grid_size[1] - w
        if (
            pad_vert > tensorflow_shape_frnt_(batch)[-2]
            or pad_horz > tensorflow_shape_frnt_(batch)[-1]
        ):
            raise ValueError(
                "Cannot compute tiles on the image according to the given grid size"
            )
        if pad_vert > 0 or pad_horz > 0:
            batch = tensorflow_pad_frnt(batch, [0, pad_horz, 0, pad_vert], mode="reflect")
        c: typing.Any = tensorflow_shape_frnt_(batch)[-3]
        tiles: typing.Any = tensorflow_contiguous_frnt_(
            tensorflow_squeeze_frnt_(
                tensorflow_unfold_frnt_(
>                   tensorflow_unfold_frnt_(
                        tensorflow_unfold_frnt_(batch, 1, c, c), 2, kernel_vert, kernel_vert
                    ),
                    3,
                    kernel_horz,
                    kernel_horz,
                ),
                1,
            )
        )

ivy_transpiled_outputs/tensorflow_outputs/kornia/enhance/equalization.py:66: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (<tf.Tensor: shape=(1, 1, 1, 32, 16), dtype=float32, numpy=
array([[[[[0.7796958 , 0.3584137 , 0.46941298, 0.939525  ,...      0.22325748, 0.59681696, 0.48142868, 0.36381727, 0.21413755,
           0.17221272]]]]], dtype=float32)>, 2, 2, 2)
kwargs = {}, tensorflow_is_array_bknd = <function tensorflow_is_array_bknd at 0x7f6584aed240>
array_like = <tf.Tensor: shape=(1, 1, 1, 32, 16), dtype=float32, numpy=
array([[[[[0.7796958 , 0.3584137 , 0.46941298, 0.939525  , ...1  ,
           0.22325748, 0.59681696, 0.48142868, 0.36381727, 0.21413755,
           0.17221272]]]]], dtype=float32)>

    @functools.wraps(fn)
    def wrapper(*args, **kwargs):
        from ..functional.ivy.general import tensorflow_is_array_bknd
    
        array_like = args[0]
        if hasattr(array_like, "__class__") and array_like.__class__.__name__ in [
            "list",
            "tuple",
        ]:
            array_like = array_like[0]
        if tensorflow_is_array_bknd(array_like):
>           return fn(*args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:202: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = <tf.Tensor: shape=(1, 1, 1, 32, 16), dtype=float32, numpy=
array([[[[[0.7796958 , 0.3584137 , 0.46941298, 0.939525  , ...1  ,
           0.22325748, 0.59681696, 0.48142868, 0.36381727, 0.21413755,
           0.17221272]]]]], dtype=float32)>
dimension = 2, size = 2, step = 2

    @tensorflow_handle_methods
    def tensorflow_unfold_frnt_(tensor, dimension, size, step):
        from ...backends.tensorflow.general import tensorflow_get_item
        from ...backends.tensorflow.general import tensorflow_set_item
        from .indexing_slicing_joining_mutating_ops import tensorflow_stack_frnt
    
        slices = []
        self_shape = tuple(tensorflow_shape_frnt_(tensor))
        for i in range(0, tensorflow_get_item(self_shape, dimension) - size + 1, step):
            slicing = [slice(None)] * len(tensorflow_shape_frnt_(tensor))
            slicing = tensorflow_set_item(slicing, dimension, slice(i, i + size))
            slices.append(tensorflow_get_item(tensor, tuple(slicing)))
>       stacked = tensorflow_stack_frnt(slices, dim=dimension)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/tensor.py:263: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensors = [], dim = 2

    def tensorflow_stack_frnt(tensors, dim=0, *, out=None):
        from ...backends.tensorflow.manipulation import tensorflow_stack
    
>       return tensorflow_stack(tensors, axis=dim, out=out)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/indexing_slicing_joining_mutating_ops.py:130: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

arrays = []

    def tensorflow_stack(
        arrays: Union[Tuple[tensorflow.Tensor], List[tensorflow.Tensor]],
        /,
        *,
        axis: int = 0,
        out: Optional[Union[tensorflow.Tensor, tensorflow.Variable]] = None,
    ):
        try:
>           return tensorflow.experimental.numpy.stack(arrays, axis)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/backends/tensorflow/manipulation.py:224: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

arrays = [], axis = 2

    @tf_export.tf_export('experimental.numpy.stack', v1=[])
    @np_utils.np_doc('stack')
    def stack(arrays, axis=0):  # pylint: disable=missing-function-docstring
      if isinstance(arrays, (np_arrays.ndarray, tensor_lib.Tensor)):
        arrays = asarray(arrays)
        if axis == 0:
          return arrays
        else:
          return swapaxes(arrays, 0, axis)
      arrays = _promote_dtype(*arrays)  # pylint: disable=protected-access
      unwrapped_arrays = [
          a if isinstance(a, np_arrays.ndarray) else a for a in arrays
      ]
>     return asarray(array_ops_stack.stack(unwrapped_arrays, axis))

/opt/fw/tensorflow/tensorflow/python/ops/numpy_ops/np_array_ops.py:1211: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = ([], 2), kwargs = {}

    def error_handler(*args, **kwargs):
      try:
        if not is_traceback_filtering_enabled():
          return fn(*args, **kwargs)
      except NameError:
        # In some very rare cases,
        # `is_traceback_filtering_enabled` (from the outer scope) may not be
        # accessible from inside this function
        return fn(*args, **kwargs)
    
      filtered_tb = None
      try:
        return fn(*args, **kwargs)
      except Exception as e:
        filtered_tb = _process_traceback_frames(e.__traceback__)
>       raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/tensorflow/python/util/traceback_utils.py:153: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

values = [], axis = 2, name = 'stack'

    @tf_export("stack")
    @dispatch.add_dispatch_support
    def stack(values, axis=0, name="stack"):
      """Stacks a list of rank-`R` tensors into one rank-`(R+1)` tensor.
    
      See also `tf.concat`, `tf.tile`, `tf.repeat`.
    
      Packs the list of tensors in `values` into a tensor with rank one higher than
      each tensor in `values`, by packing them along the `axis` dimension.
      Given a list of length `N` of tensors of shape `(A, B, C)`;
    
      if `axis == 0` then the `output` tensor will have the shape `(N, A, B, C)`.
      if `axis == 1` then the `output` tensor will have the shape `(A, N, B, C)`.
      Etc.
    
      For example:
    
      >>> x = tf.constant([1, 4])
      >>> y = tf.constant([2, 5])
      >>> z = tf.constant([3, 6])
      >>> tf.stack([x, y, z])
      <tf.Tensor: shape=(3, 2), dtype=int32, numpy=
      array([[1, 4],
             [2, 5],
             [3, 6]], dtype=int32)>
      >>> tf.stack([x, y, z], axis=1)
      <tf.Tensor: shape=(2, 3), dtype=int32, numpy=
      array([[1, 2, 3],
             [4, 5, 6]], dtype=int32)>
    
      This is the opposite of unstack.  The numpy equivalent is `np.stack`
    
      >>> np.array_equal(np.stack([x, y, z]), tf.stack([x, y, z]))
      True
    
      Args:
        values: A list of `Tensor` objects with the same shape and type.
        axis: An `int`. The axis to stack along. Defaults to the first dimension.
          Negative values wrap around, so the valid range is `[-(R+1), R+1)`.
        name: A name for this operation (optional).
    
      Returns:
        output: A stacked `Tensor` with the same type as `values`.
    
      Raises:
        ValueError: If `axis` is out of the range [-(R+1), R+1).
      """
      if axis == 0:
        try:
          # If the input is a constant list, it can be converted to a constant op
          return ops.convert_to_tensor(values, name=name)
        except (TypeError, ValueError, NotImplementedError):
          pass  # Input list contains non-constant tensors
    
>     value_shape = ops.convert_to_tensor(values[0], name=name)._shape_tuple()  # pylint: disable=protected-access
E     IndexError: list index out of range

/opt/fw/tensorflow/tensorflow/python/ops/array_ops_stack.py:78: IndexError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.enhance.equalization.equalize_clahe
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/test_enhance.py::test_equalize_clahe[tensorflow-s2s-False] - IndexError: list index out of range
============================================================================== 1 failed, 38 passed in 2741.33s (0:45:41) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 69 items

kornia/test_color.py ...........F...........F.........sssssssssssssssssssssssssssssssss.ss                                                                                                       [100%]

=============================================================================================== FAILURES ===============================================================================================
___________________________________________________________________________________ test_rgb_to_hls[numpy-s2s-False] ___________________________________________________________________________________

target_framework = 'numpy', mode = 's2s', backend_compile = False

    def test_rgb_to_hls(target_framework, mode, backend_compile):
        # Note: We test this function with requires_grad=True,
        # because otherwise we simply get an empty_like tensor
        # with garbage values on each run leading to test failures
        trace_args = (
            torch.rand(1, 3, 4, 5).requires_grad_(True),
        )
        trace_kwargs = {'eps': 1e-8}
        test_args = (
            torch.rand(5, 3, 4, 5).requires_grad_(True),
        )
        test_kwargs = {'eps': 1e-8}
>       _test_function(
            kornia.color.rgb_to_hls,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/test_color.py:295: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function rgb_to_hls at 0x7fd3420a0160>
trace_args = (tensor([[[[0.1516, 0.9272, 0.9477, 0.1703, 0.1303],
          [0.4718, 0.1749, 0.5307, 0.8520, 0.7678],
          [0.... [0.8291, 0.6348, 0.2076, 0.1660, 0.8898],
          [0.7682, 0.7245, 0.8022, 0.3749, 0.2981]]]], requires_grad=True),)
trace_kwargs = {'eps': 1e-08}
test_args = (tensor([[[[9.1131e-01, 4.4882e-01, 1.6443e-02, 6.7200e-02, 2.6796e-01],
          [5.0558e-01, 4.6867e-01, 8.0313e-02...1, 9.8294e-01],
          [3.5199e-01, 6.2679e-01, 6.5603e-01, 6.7852e-02, 5.2648e-01]]]],
       requires_grad=True),)
test_kwargs = {'eps': 1e-08}, target = 'numpy', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function rgb_to_hls at 0x7fd3420a0160>, fn_name = 'kornia.color.rgb_to_hls'
trace_args = (tensor([[[[0.1516, 0.9272, 0.9477, 0.1703, 0.1303],
          [0.4718, 0.1749, 0.5307, 0.8520, 0.7678],
          [0.... [0.8291, 0.6348, 0.2076, 0.1660, 0.8898],
          [0.7682, 0.7245, 0.8022, 0.3749, 0.2981]]]], requires_grad=True),)
trace_kwargs = {'eps': 1e-08}
test_args = (tensor([[[[9.1131e-01, 4.4882e-01, 1.6443e-02, 6.7200e-02, 2.6796e-01],
          [5.0558e-01, 4.6867e-01, 8.0313e-02...1, 9.8294e-01],
          [3.5199e-01, 6.2679e-01, 6.5603e-01, 6.7852e-02, 5.2648e-01]]]],
       requires_grad=True),)
test_kwargs = {'eps': 1e-08}, target = 'numpy', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:232: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

image = array([[[[0.15158182, 0.9272013 , 0.9477422 , 0.170259  , 0.1302951 ],
         [0.471821  , 0.17486823, 0.5307223 , 0...0.16601747, 0.8897871 ],
         [0.7681776 , 0.72449744, 0.8022314 , 0.3748827 , 0.29813963]]]],
      dtype=float32)
eps = 1e-08

    def numpy_rgb_to_hls(image, eps=1e-08):
        from ..core._backend import tensor
        from ...ivy.functional.frontends.torch.pointwise_ops import sub
        from ..core._backend import where
        from ..core._backend import stack
        from ...ivy.functional.frontends.torch.tensor import numpy_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_max_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_min_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_requires_grad_frnt_
        from ...ivy.functional.frontends.torch.creation_ops import numpy_empty_like_frnt
        from ...ivy.functional.frontends.torch.pointwise_ops import numpy_add_frnt
        from ...ivy.functional.frontends.torch.tensor import numpy_unsqueeze_frnt_
        from ...ivy.functional.frontends.torch.pointwise_ops import numpy_mul_frnt
    
        if not isinstance(image, (numpy.ndarray, numpy.ndarray)):
            raise TypeError(f"Input type is not a Tensor. Got {type(image)}")
        if len(numpy_shape_frnt_(image)) < 3 or numpy_shape_frnt_(image)[-3] != 3:
            raise ValueError(
                f"Input size must have a shape of (*, 3, H, W). Got {numpy_shape_frnt_(image)}"
            )
        _RGB2HSL_IDX = tensor([[[0.0]], [[1.0]], [[2.0]]], device=None, dtype=image.dtype)
        _img_max: typing.Any = numpy_max_frnt_(image, -3)
        maxc = _img_max[0]
        imax = _img_max[1]
        minc: typing.Any = numpy_min_frnt_(image, -3)[0]
        if numpy_requires_grad_frnt_(image):
            l_ = maxc + minc
            s = maxc - minc
            h = l_
            image_hls = l_
        else:
            image_hls = numpy_empty_like_frnt(image)
            h, l_, s = (
                image_hls[..., 0, :, :],
                image_hls[..., 1, :, :],
                image_hls[..., 2, :, :],
            )
            numpy_add_frnt(maxc, minc, out=l_)
            sub(maxc, minc, out=s)
        im = image / numpy_unsqueeze_frnt_(s + eps, -3)
        s = s / (where(l_ < 1.0, l_, 2.0 - l_) + eps)
        l_ = l_ / 2
        r, g, b = im[..., 0, :, :], im[..., 1, :, :], im[..., 2, :, :]
        cond = imax[..., None, :, :] == _RGB2HSL_IDX
        if numpy_requires_grad_frnt_(image):
            h = (g - b) % 6 * cond[..., 0, :, :]
        else:
>           numpy_mul_frnt((g - b) % 6, cond[..., 0, :, :], out=h)

ivy_transpiled_outputs/numpy_outputs/kornia/color/hls.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = array([[[1.        , 1.        , 5.        , 5.        , 5.        ],
        [0.1995256 , 0.5938848 , 5.        , 5.5..., 5.        , 5.498794  ],
        [5.702172  , 0.6198286 , 5.        , 0.68755794, 5.        ]]],
      dtype=float32)
other = array([[[False, False, False, False, False],
        [False, False, False,  True, False],
        [ True, False, False, False, False],
        [False, False, False,  True, False]]])

    def numpy_mul_frnt(input, other, *, out=None):
        from .__init__ import numpy_promote_types_of_torch_inputs_frnt
        from ...backends.numpy.elementwise import numpy_multiply
    
>       input, other = numpy_promote_types_of_torch_inputs_frnt(input, other)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/pointwise_ops.py:60: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x1 = array([[[1.        , 1.        , 5.        , 5.        , 5.        ],
        [0.1995256 , 0.5938848 , 5.        , 5.5..., 5.        , 5.498794  ],
        [5.702172  , 0.6198286 , 5.        , 0.68755794, 5.        ]]],
      dtype=float32)
x2 = array([[[False, False, False, False, False],
        [False, False, False,  True, False],
        [ True, False, False, False, False],
        [False, False, False,  True, False]]])

    def numpy_promote_types_of_torch_inputs_frnt(x1, x2, /):
        from ...ivy.general import numpy_isscalar_bknd
        from ...ivy.data_type import numpy_is_int_dtype_bknd
        from ...backends.numpy.creation import numpy_asarray
        from ...ivy.data_type import numpy_default_dtype_bknd
        from .tensor import numpy_shape_frnt_
        from ...ivy.device import numpy_default_device_bknd
        from ....data_classes.array.data_type import numpy_astype_bknd_
    
        """Promote the dtype of the given native array inputs to a common dtype
        based on type promotion rules.
    
        While passing float or integer values or any other non-array input
        to this function, it should be noted that the return will be an
        array-like object. Therefore, outputs from this function should be
        used as inputs only for those functions that expect an array-like or
        tensor-like objects, otherwise it might give unexpected results.
        """
        if (
            numpy_isscalar_bknd(x1) or isinstance(x1, (list, tuple))
        ) and numpy_is_int_dtype_bknd(x1):
            x1 = numpy_asarray(x1, dtype="int64")
        elif numpy_isscalar_bknd(x1) or isinstance(x1, (list, tuple)):
            x1 = numpy_asarray(x1)
        if (
            numpy_isscalar_bknd(x2) or isinstance(x2, (list, tuple))
        ) and numpy_is_int_dtype_bknd(x2):
            x2 = numpy_asarray(x2, dtype="int64")
        elif numpy_isscalar_bknd(x2) or isinstance(x2, (list, tuple)):
            x2 = numpy_asarray(x2)
        type1 = numpy_default_dtype_bknd(item=x1).strip("u123456789")
        type2 = numpy_default_dtype_bknd(item=x2).strip("u123456789")
        if numpy_shape_frnt_(x1) != () and numpy_shape_frnt_(x2) == () and type1 == type2:
            x2 = numpy_asarray(
                x2,
                dtype=x1.dtype,
                device=numpy_default_device_bknd(item=x1, as_native=False),
            )
        elif numpy_shape_frnt_(x1) == () and numpy_shape_frnt_(x2) != () and type1 == type2:
            x1 = numpy_asarray(
                x1,
                dtype=x2.dtype,
                device=numpy_default_device_bknd(item=x2, as_native=False),
            )
        elif x1.dtype != x2.dtype:
>           promoted = numpy_promote_types_torch_frnt(x1.dtype, x2.dtype)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/__init__.py:87: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

type1 = dtype('float32'), type2 = dtype('bool')

    def numpy_promote_types_torch_frnt(type1, type2, /):
        from ...backends.numpy.general import numpy_get_item
        from ...backends.numpy.data_type import numpy_as_ivy_dtype
    
        try:
            ret = numpy_get_item(
>               torch_promotion_table,
                (numpy_as_ivy_dtype(type1), numpy_as_ivy_dtype(type2)),
            )
E           NameError: name 'torch_promotion_table' is not defined

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/__init__.py:34: NameError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.color.hls.rgb_to_hls
_________________________________________________________________________________ test_rgb_to_yuv420[numpy-s2s-False] __________________________________________________________________________________

target_framework = 'numpy', mode = 's2s', backend_compile = False

    def test_rgb_to_yuv420(target_framework, mode, backend_compile):
        trace_args = (
            torch.rand(1, 3, 4, 6),
        )
        trace_kwargs = {}
        test_args = (
            torch.rand(5, 3, 4, 6),
        )
        test_kwargs = {}
>       _test_function(
            kornia.color.rgb_to_yuv420,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/test_color.py:563: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function rgb_to_yuv420 at 0x7fd3420a1ea0>
trace_args = (tensor([[[[0.7299, 0.6541, 0.9574, 0.3758, 0.1282, 0.9715],
          [0.4948, 0.1836, 0.2888, 0.7606, 0.8934, 0.6115...     [0.9491, 0.4690, 0.4452, 0.2322, 0.4421, 0.8241],
          [0.6920, 0.3094, 0.6081, 0.4908, 0.3780, 0.7458]]]]),)
trace_kwargs = {}
test_args = (tensor([[[[0.4235, 0.3860, 0.4319, 0.4342, 0.1710, 0.0639],
          [0.6479, 0.0693, 0.6621, 0.8872, 0.2780, 0.5133...     [0.3985, 0.5346, 0.1525, 0.1573, 0.7366, 0.5928],
          [0.0427, 0.3905, 0.2062, 0.6644, 0.3127, 0.5549]]]]),)
test_kwargs = {}, target = 'numpy', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function rgb_to_yuv420 at 0x7fd3420a1ea0>, fn_name = 'kornia.color.rgb_to_yuv420'
trace_args = (tensor([[[[0.7299, 0.6541, 0.9574, 0.3758, 0.1282, 0.9715],
          [0.4948, 0.1836, 0.2888, 0.7606, 0.8934, 0.6115...     [0.9491, 0.4690, 0.4452, 0.2322, 0.4421, 0.8241],
          [0.6920, 0.3094, 0.6081, 0.4908, 0.3780, 0.7458]]]]),)
trace_kwargs = {}
test_args = (tensor([[[[0.4235, 0.3860, 0.4319, 0.4342, 0.1710, 0.0639],
          [0.6479, 0.0693, 0.6621, 0.8872, 0.2780, 0.5133...     [0.3985, 0.5346, 0.1525, 0.1573, 0.7366, 0.5928],
          [0.0427, 0.3905, 0.2062, 0.6644, 0.3127, 0.5549]]]]),)
test_kwargs = {}, target = 'numpy', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
        graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
    
        if deterministic:
>           _to_numpy_and_allclose(orig_out, graph_out, tolerance=tolerance)

helpers.py:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

torch_x = (tensor([[[[0.4560, 0.6745, 0.4241, 0.2780, 0.2916, 0.5665],
          [0.5066, 0.3160, 0.5868, 0.8149, 0.3739, 0.2859...       [ 0.1172, -0.0099, -0.0563]],

         [[ 0.0240,  0.0612,  0.2383],
          [-0.0967, -0.0226, -0.1951]]]]))
transpiled_x = (array([[[[0.45595238, 0.67454606, 0.4240657 , 0.27797225, 0.29156926,
          0.5665087 ],
         [0.50660574, 0....
        [[ 0.15612495, -0.16510308,  0.02420463],
         [-0.0615429 , -0.01168551,  0.06717196]]]], dtype=float32))
tolerance = 0.001

    def _to_numpy_and_allclose(torch_x, transpiled_x, tolerance=1e-3):
        orig_data = _nest_array_to_numpy(torch_x)
        transpiled_data = _nest_array_to_numpy(transpiled_x)
>       _check_allclose(orig_data, transpiled_data, tolerance=tolerance)

helpers.py:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = (array([[[[0.45595238, 0.67454606, 0.4240657 , 0.27797225, 0.29156926,
          0.5665087 ],
         [0.50660574, 0....
        [[ 0.02397581,  0.06118239,  0.23834535],
         [-0.09667887, -0.02255956, -0.19509506]]]], dtype=float32))
y = (array([[[[0.45595238, 0.67454606, 0.4240657 , 0.27797225, 0.29156926,
          0.5665087 ],
         [0.50660574, 0....
        [[ 0.15612495, -0.16510308,  0.02420463],
         [-0.0615429 , -0.01168551,  0.06717196]]]], dtype=float32))
tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
            assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
            return
    
        if isinstance(x, (list, set, tuple)):
>           all([
                _check_allclose(element_x, element_y, tolerance=tolerance) for element_x, element_y in zip(x, y)
            ])

helpers.py:30: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

.0 = <zip object at 0x7fd2e8f51c80>

    all([
>       _check_allclose(element_x, element_y, tolerance=tolerance) for element_x, element_y in zip(x, y)
    ])

helpers.py:31: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[[-0.08808362,  0.06632669, -0.02119955],
         [ 0.11724793, -0.00987892, -0.0562786 ]],

        [[ 0.02397581,  0.06118239,  0.23834535],
         [-0.09667887, -0.02255956, -0.19509506]]]], dtype=float32)
y = array([[[[ 0.01422279, -0.10572611,  0.00050132],
         [ 0.11619845, -0.08925445,  0.07219189]],

        [[ 0.15612495, -0.16510308,  0.02420463],
         [-0.0615429 , -0.01168551,  0.06717196]]]], dtype=float32)
tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
>           assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
E           AssertionError: numpy array values are not all close

helpers.py:26: AssertionError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.color.yuv.rgb_to_yuv420
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/test_color.py::test_rgb_to_hls[numpy-s2s-False] - NameError: name 'torch_promotion_table' is not defined
FAILED kornia/test_color.py::test_rgb_to_yuv420[numpy-s2s-False] - AssertionError: numpy array values are not all close
======================================================================== 2 failed, 32 passed, 35 skipped in 1611.81s (0:26:51) =========================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 1 item

transformers/test_vision.py .                                                                                                                                                                    [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
==================================================================================== 1 passed in 303.01s (0:05:03) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 14 items

kornia/test_feature4.py ssssssssssssss                                                                                                                                                           [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
========================================================================================= 14 skipped in 5.01s ==========================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 6 items

kornia/test_nerf.py ssssss                                                                                                                                                                       [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
========================================================================================== 6 skipped in 5.35s ==========================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 5 items

kornia/geometry/test_solvers.py .....                                                                                                                                                            [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
==================================================================================== 5 passed in 266.94s (0:04:26) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 13 items

kornia/test_utils.py .............                                                                                                                                                               [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
==================================================================================== 13 passed in 745.84s (0:12:25) ====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 4 items

kornia/test_sensors.py ....                                                                                                                                                                      [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
===================================================================================== 4 passed in 91.04s (0:01:31) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 2 items

kornia/geometry/test_line.py .F                                                                                                                                                                  [100%]

=============================================================================================== FAILURES ===============================================================================================
_____________________________________________________________________________ test_ParametrizedLine[tensorflow-s2s-False] ______________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_ParametrizedLine(target_framework, mode, backend_compile):
        print("kornia.geometry.line.ParametrizedLine")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target_framework)
    
        origin = torch.tensor([0.0, 0.0], requires_grad=True)
        direction = torch.tensor([1.0, 1.0], requires_grad=True)
        torch_line = kornia.geometry.line.ParametrizedLine(origin, direction)
    
        transpiled_origin = _nest_torch_tensor_to_new_framework(origin, target_framework)
        transpiled_direction = _nest_torch_tensor_to_new_framework(direction, target_framework)
        transpiled_line = transpiled_kornia.geometry.line.ParametrizedLine(transpiled_origin, transpiled_direction)
    
        # Test .dim()
        torch_dim = torch_line.dim()
        transpiled_dim = transpiled_line.dim()
        assert torch_dim == transpiled_dim
    
        # Test .direction property
        _to_numpy_and_allclose(torch_line.direction, transpiled_line.direction)
    
        # Test .origin property
        _to_numpy_and_allclose(torch_line.origin, transpiled_line.origin)
    
        # Test .distance()
        point = torch.tensor([1.0, 0.0], requires_grad=True)
        transpiled_point = _nest_torch_tensor_to_new_framework(point, target_framework)
    
        torch_distance = torch_line.distance(point)
        transpiled_distance = transpiled_line.distance(transpiled_point)
        _to_numpy_and_allclose(torch_distance, transpiled_distance)
    
        # Test .point_at()
        t_value = torch.tensor(0.5)
        transpiled_t_value = _nest_torch_tensor_to_new_framework(t_value, target_framework)
    
        torch_point_at = torch_line.point_at(t_value)
        transpiled_point_at = transpiled_line.point_at(transpiled_t_value)
        _to_numpy_and_allclose(torch_point_at, transpiled_point_at)
    
        # Test .projection()
        torch_projection = torch_line.projection(point)
        transpiled_projection = transpiled_line.projection(transpiled_point)
        _to_numpy_and_allclose(torch_projection, transpiled_projection)
    
        # Test .squared_distance()
        torch_squared_distance = torch_line.squared_distance(point)
        transpiled_squared_distance = transpiled_line.squared_distance(transpiled_point)
        _to_numpy_and_allclose(torch_squared_distance, transpiled_squared_distance)
    
        # Test class method .through()
        p0 = torch.tensor([0.0, 0.0], requires_grad=True)
        p1 = torch.tensor([1.0, 1.0], requires_grad=True)
        transpiled_p0 = _nest_torch_tensor_to_new_framework(p0, target_framework)
        transpiled_p1 = _nest_torch_tensor_to_new_framework(p1, target_framework)
    
        torch_line_through = kornia.geometry.line.ParametrizedLine.through(p0, p1)
>       transpiled_line_through = transpiled_kornia.geometry.line.ParametrizedLine.through(transpiled_p0, transpiled_p1)
E       TypeError: 'classmethod' object is not callable

kornia/geometry/test_line.py:107: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.line.ParametrizedLine
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/geometry/test_line.py::test_ParametrizedLine[tensorflow-s2s-False] - TypeError: 'classmethod' object is not callable
================================================================================ 1 failed, 1 passed in 82.04s (0:01:22) ================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 4 items

kornia/geometry/test_liegroup.py FFFF                                                                                                                                                            [100%]

=============================================================================================== FAILURES ===============================================================================================
_______________________________________________________________________________________ test_So3[jax-s2s-False] ________________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_So3(target_framework, mode, backend_compile):
        print("kornia.geometry.liegroup.So3")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target_framework)
    
        # Initialize a Quaternion and create an So3 object
        quaternion_data = torch.tensor([1., 0., 0., 0.])
        torch_quaternion = kornia.geometry.quaternion.Quaternion(quaternion_data)
        torch_so3 = kornia.geometry.liegroup.So3(torch_quaternion)
    
        # Transpile the So3 class
        transpiled_quaternion = transpiled_kornia.geometry.quaternion.Quaternion(_nest_torch_tensor_to_new_framework(quaternion_data, target_framework))
        transpiled_so3 = transpiled_kornia.geometry.liegroup.So3(transpiled_quaternion)
    
        # Test .matrix()
        torch_matrix = torch_so3.matrix()
        transpiled_matrix = transpiled_so3.matrix()
        _to_numpy_and_allclose(torch_matrix, transpiled_matrix)
    
        # Test .inverse()
        torch_inverse = torch_so3.inverse()
        transpiled_inverse = transpiled_so3.inverse()
        _to_numpy_and_allclose(torch_inverse.q.data, transpiled_inverse.q.data)
    
        # Test .log()
        torch_log = torch_so3.log()
        transpiled_log = transpiled_so3.log()
        _to_numpy_and_allclose(torch_log, transpiled_log)
    
        # Test .__mul__()
        other_quaternion_data = torch.tensor([0., 1., 0., 0.])
        other_torch_quaternion = kornia.geometry.quaternion.Quaternion(other_quaternion_data)
        other_torch_so3 = kornia.geometry.liegroup.So3(other_torch_quaternion)
    
        transpiled_other_quaternion = _nest_torch_tensor_to_new_framework(other_quaternion_data, target_framework)
        transpiled_other_quaternion_obj = transpiled_kornia.geometry.quaternion.Quaternion(transpiled_other_quaternion)
        transpiled_other_so3 = transpiled_kornia.geometry.liegroup.So3(transpiled_other_quaternion_obj)
    
        torch_composed_so3 = torch_so3 * other_torch_so3
        transpiled_composed_so3 = transpiled_so3 * transpiled_other_so3
        _to_numpy_and_allclose(torch_composed_so3.q.data, transpiled_composed_so3.q.data)
    
        # Test .adjoint()
        torch_adjoint = torch_so3.adjoint()
        transpiled_adjoint = transpiled_so3.adjoint()
        _to_numpy_and_allclose(torch_adjoint, transpiled_adjoint)
    
        # Test .from_matrix()
        rotation_matrix = torch.eye(3)
        transpiled_rotation_matrix = _nest_torch_tensor_to_new_framework(rotation_matrix, target_framework)
    
        torch_from_matrix = kornia.geometry.liegroup.So3.from_matrix(rotation_matrix)
>       transpiled_from_matrix = transpiled_kornia.geometry.liegroup.So3.from_matrix(transpiled_rotation_matrix)
E       TypeError: 'classmethod' object is not callable

kornia/geometry/test_liegroup.py:70: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.liegroup.So3
_______________________________________________________________________________________ test_Se3[jax-s2s-False] ________________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_Se3(target_framework, mode, backend_compile):
        print("kornia.geometry.liegroup.Se3")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        quaternion_data = torch.tensor([1., 0., 0., 0.])
        translation_data = torch.tensor([1., 1., 1.])
        torch_quaternion = kornia.geometry.quaternion.Quaternion(quaternion_data)
        torch_se3 = kornia.geometry.liegroup.Se3(torch_quaternion, translation_data)
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target_framework)
    
        transpiled_translation = _nest_torch_tensor_to_new_framework(translation_data, target_framework)
        transpiled_quaternion = transpiled_kornia.geometry.quaternion.Quaternion(_nest_torch_tensor_to_new_framework(quaternion_data, target_framework))
        transpiled_se3 = transpiled_kornia.geometry.liegroup.Se3(transpiled_quaternion, transpiled_translation)
    
        # Test .matrix()
        torch_matrix = torch_se3.matrix()
        transpiled_matrix = transpiled_se3.matrix()
        _to_numpy_and_allclose(torch_matrix, transpiled_matrix)
    
        # Test .inverse()
        torch_inverse = torch_se3.inverse()
        transpiled_inverse = transpiled_se3.inverse()
        _to_numpy_and_allclose(torch_inverse.r.q.data, transpiled_inverse.r.q.data)
        _to_numpy_and_allclose(torch_inverse.t, transpiled_inverse.t)
    
        # Test .log()
        torch_log = torch_se3.log()
        transpiled_log = transpiled_se3.log()
        _to_numpy_and_allclose(torch_log, transpiled_log)
    
        # Test .__mul__()
        other_quaternion_data = torch.tensor([0., 1., 0., 0.])
        other_translation_data = torch.tensor([2., 2., 2.])
        other_torch_quaternion = kornia.geometry.quaternion.Quaternion(other_quaternion_data)
        other_torch_se3 = kornia.geometry.liegroup.Se3(other_torch_quaternion, other_translation_data)
    
        transpiled_other_quaternion = _nest_torch_tensor_to_new_framework(other_quaternion_data, target_framework)
        transpiled_other_translation = _nest_torch_tensor_to_new_framework(other_translation_data, target_framework)
        transpiled_other_quaternion_obj = transpiled_kornia.geometry.quaternion.Quaternion(transpiled_other_quaternion)
        transpiled_other_se3 = transpiled_kornia.geometry.liegroup.Se3(transpiled_other_quaternion_obj, transpiled_other_translation)
    
        torch_composed_se3 = torch_se3 * other_torch_se3
        transpiled_composed_se3 = transpiled_se3 * transpiled_other_se3
        _to_numpy_and_allclose(torch_composed_se3.r.q.data, transpiled_composed_se3.r.q.data)
        _to_numpy_and_allclose(torch_composed_se3.t, transpiled_composed_se3.t)
    
        # Test .adjoint()
        torch_adjoint = torch_se3.adjoint()
        transpiled_adjoint = transpiled_se3.adjoint()
        _to_numpy_and_allclose(torch_adjoint, transpiled_adjoint)
    
        # Test .from_matrix()
        rotation_translation_matrix = torch.eye(4)
        transpiled_rotation_translation_matrix = _nest_torch_tensor_to_new_framework(rotation_translation_matrix, target_framework)
    
        torch_from_matrix = kornia.geometry.liegroup.Se3.from_matrix(rotation_translation_matrix)
>       transpiled_from_matrix = transpiled_kornia.geometry.liegroup.Se3.from_matrix(transpiled_rotation_translation_matrix)
E       TypeError: 'classmethod' object is not callable

kornia/geometry/test_liegroup.py:141: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.liegroup.Se3
_______________________________________________________________________________________ test_So2[jax-s2s-False] ________________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_So2(target_framework, mode, backend_compile):
        print("kornia.geometry.liegroup.So2")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target_framework)
    
        real_part = torch.tensor([1.0], requires_grad=True)
        imaginary_part = torch.tensor([2.0], requires_grad=True)
        complex_number = torch.complex(real_part, imaginary_part)
        torch_so2 = kornia.geometry.liegroup.So2(complex_number)
    
        transpiled_complex_number = _nest_torch_tensor_to_new_framework(complex_number, target_framework)
        transpiled_so2 = transpiled_kornia.geometry.liegroup.So2(transpiled_complex_number)
    
        # Test .matrix()
        torch_matrix = torch_so2.matrix()
        transpiled_matrix = transpiled_so2.matrix()
        _to_numpy_and_allclose(torch_matrix, transpiled_matrix)
    
        # Test .inverse()
        torch_inverse = torch_so2.inverse()
        transpiled_inverse = transpiled_so2.inverse()
        _to_numpy_and_allclose(torch_inverse.z, transpiled_inverse.z)
    
        # Test .log()
        torch_log = torch_so2.log()
        transpiled_log = transpiled_so2.log()
        _to_numpy_and_allclose(torch_log, transpiled_log)
    
        # Test .__mul__()
        other_real_part = torch.tensor([0.5], requires_grad=True)
        other_imaginary_part = torch.tensor([0.5], requires_grad=True)
        other_complex_number = torch.complex(other_real_part, other_imaginary_part)
        other_torch_so2 = kornia.geometry.liegroup.So2(other_complex_number)
    
        transpiled_other_complex_number = _nest_torch_tensor_to_new_framework(other_complex_number, target_framework)
        transpiled_other_so2 = transpiled_kornia.geometry.liegroup.So2(transpiled_other_complex_number)
    
        torch_composed_so2 = torch_so2 * other_torch_so2
        transpiled_composed_so2 = transpiled_so2 * transpiled_other_so2
        _to_numpy_and_allclose(torch_composed_so2.z, transpiled_composed_so2.z)
    
        # Test .adjoint()
        torch_adjoint = torch_so2.adjoint()
        transpiled_adjoint = transpiled_so2.adjoint()
        _to_numpy_and_allclose(torch_adjoint, transpiled_adjoint)
    
        # Test .from_matrix()
        rotation_matrix = torch.eye(2)
        transpiled_rotation_matrix = _nest_torch_tensor_to_new_framework(rotation_matrix, target_framework)
    
        torch_from_matrix = kornia.geometry.liegroup.So2.from_matrix(rotation_matrix)
>       transpiled_from_matrix = transpiled_kornia.geometry.liegroup.So2.from_matrix(transpiled_rotation_matrix)
E       TypeError: 'classmethod' object is not callable

kornia/geometry/test_liegroup.py:209: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.liegroup.So2
_______________________________________________________________________________________ test_Se2[jax-s2s-False] ________________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_Se2(target_framework, mode, backend_compile):
        print("kornia.geometry.liegroup.Se2")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target_framework)
    
        so2_rotation = kornia.geometry.liegroup.So2.identity(1)
        translation_vector = torch.ones((1, 2), requires_grad=True)
        torch_se2 = kornia.geometry.liegroup.Se2(so2_rotation, translation_vector)
    
>       transpiled_so2_rotation = transpiled_kornia.geometry.liegroup.Se2.identity(1)
E       TypeError: 'classmethod' object is not callable

kornia/geometry/test_liegroup.py:250: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.liegroup.Se2
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/geometry/test_liegroup.py::test_So3[jax-s2s-False] - TypeError: 'classmethod' object is not callable
FAILED kornia/geometry/test_liegroup.py::test_Se3[jax-s2s-False] - TypeError: 'classmethod' object is not callable
FAILED kornia/geometry/test_liegroup.py::test_So2[jax-s2s-False] - TypeError: 'classmethod' object is not callable
FAILED kornia/geometry/test_liegroup.py::test_Se2[jax-s2s-False] - TypeError: 'classmethod' object is not callable
==================================================================================== 4 failed in 315.90s (0:05:15) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 5 items

kornia/test_x.py sssss                                                                                                                                                                           [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
==================================================================================== 5 skipped in 296.41s (0:04:56) ====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 8 items

kornia/geometry/test_linalg.py ........                                                                                                                                                          [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
==================================================================================== 8 passed in 303.07s (0:05:03) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 1 item

transformers/test_vision.py .                                                                                                                                                                    [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
==================================================================================== 1 passed in 340.93s (0:05:40) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 5 items

kornia/geometry/test_solvers.py .....                                                                                                                                                            [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
==================================================================================== 5 passed in 295.18s (0:04:55) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 18 items

kornia/augmentation/test_augmentation1.py ssssssssssssssssss                                                                                                                                     [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
========================================================================================= 18 skipped in 5.20s ==========================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 2 items

kornia/test_io.py ..                                                                                                                                                                             [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
==================================================================================== 2 passed in 134.26s (0:02:14) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 15 items

kornia/geometry/test_subpix.py ..F.........F..                                                                                                                                                   [100%]

=============================================================================================== FAILURES ===============================================================================================
________________________________________________________________________________ test_conv_quad_interp3d[jax-s2s-False] ________________________________________________________________________________
jax.errors.SimplifiedTraceback: For simplicity, JAX has removed its internal frames from the traceback of the following exception. Set JAX_TRACEBACK_FILTERING=off to include these.

The above exception was the direct cause of the following exception:

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_conv_quad_interp3d(target_framework, mode, backend_compile):
        trace_args = (
            torch.rand(2, 2, 2, 5, 5),
        )
        trace_kwargs = {
            'strict_maxima_bonus': 10.0,
            'eps': 1e-7,
        }
        test_args = (
            torch.rand(1, 2, 2, 5, 5),
        )
        test_kwargs = {
            'strict_maxima_bonus': 5.0,
            'eps': 1e-7,
        }
>       _test_function(
            kornia.geometry.subpix.conv_quad_interp3d,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/geometry/test_subpix.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function conv_quad_interp3d at 0x7f41588aef80>
trace_args = (tensor([[[[[0.4735, 0.0235, 0.7606, 0.6111, 0.7215],
           [0.2589, 0.9620, 0.2068, 0.3353, 0.6567],
           ....4220],
           [0.2018, 0.9698, 0.7921, 0.9978, 0.4109],
           [0.1116, 0.8157, 0.3445, 0.6982, 0.1114]]]]]),)
trace_kwargs = {'eps': 1e-07, 'strict_maxima_bonus': 10.0}
test_args = (tensor([[[[[0.3511, 0.1068, 0.6611, 0.6828, 0.5119],
           [0.6291, 0.1068, 0.2813, 0.8845, 0.3389],
           ....7947],
           [0.7450, 0.6345, 0.3782, 0.7083, 0.4257],
           [0.4627, 0.0323, 0.4873, 0.8891, 0.8839]]]]]),)
test_kwargs = {'eps': 1e-07, 'strict_maxima_bonus': 5.0}, target = 'jax', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function conv_quad_interp3d at 0x7f41588aef80>, fn_name = 'kornia.geometry.subpix.conv_quad_interp3d'
trace_args = (tensor([[[[[0.4735, 0.0235, 0.7606, 0.6111, 0.7215],
           [0.2589, 0.9620, 0.2068, 0.3353, 0.6567],
           ....4220],
           [0.2018, 0.9698, 0.7921, 0.9978, 0.4109],
           [0.1116, 0.8157, 0.3445, 0.6982, 0.1114]]]]]),)
trace_kwargs = {'eps': 1e-07, 'strict_maxima_bonus': 10.0}
test_args = (tensor([[[[[0.3511, 0.1068, 0.6611, 0.6828, 0.5119],
           [0.6291, 0.1068, 0.2813, 0.8845, 0.3389],
           ....7947],
           [0.7450, 0.6345, 0.3782, 0.7083, 0.4257],
           [0.4627, 0.0323, 0.4873, 0.8891, 0.8839]]]]]),)
test_kwargs = {'eps': 1e-07, 'strict_maxima_bonus': 5.0}, target = 'jax', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:232: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = Array([[[[[0.4735011 , 0.02353776, 0.76064056, 0.61111134, 0.72145957],
          [0.2589146 , 0.9619998 , 0.20675176,....99779487, 0.41086173],
          [0.11161417, 0.81572497, 0.344532  , 0.6981652 , 0.11136103]]]]],      dtype=float32)
strict_maxima_bonus = 10.0, eps = 1e-07

    def jax_conv_quad_interp3d(input, strict_maxima_bonus=10.0, eps=1e-07):
        from ...core._backend import stack
        from ...core._backend import rand
        from ...core._backend import zeros_like
        from ...core._backend import where
        from ....ivy.functional.frontends.torch.tensor_functions import jax_is_tensor_frnt_
        from ....ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ....ivy.functional.frontends.torch.tensor import jax_permute_frnt_
        from ...utils.grid import jax_create_meshgrid3d
        from ....ivy.functional.frontends.torch.tensor import jax_to_frnt_
        from ...filters.sobel import jax_spatial_gradient3d
        from ....ivy.functional.frontends.torch.tensor import jax_reshape_frnt_
        from ....ivy.functional.frontends.torch.tensor import jax_view_frnt_
        from ...utils._compat import jax_torch_version_ge
        from ....ivy.functional.frontends.torch.tensor import jax_abs_frnt_
        from ....ivy.functional.frontends.torch.tensor import jax_size_frnt_
        from .nms import jax_nms3d
        from ...utils.helpers import jax_safe_solve_with_mask
        from ....ivy.functional.backends.jax.general import jax_get_item
        from ....ivy.functional.frontends.torch.tensor import jax_masked_scatter_frnt_
        from ....ivy.functional.backends.jax.general import jax_set_item
        from ....ivy.functional.frontends.torch.tensor import jax_max_frnt_
        from ....ivy.functional.frontends.torch.tensor import jax_masked_fill__frnt_
        from ....ivy.functional.frontends.torch.tensor import jax_expand_as_frnt_
        from ....ivy.functional.frontends.torch.blas_and_lapack_ops import jax_bmm_frnt
        from ....ivy.functional.frontends.torch.tensor import jax_flip_frnt_
        from ....ivy.functional.frontends.torch.tensor import jax_unsqueeze_frnt_
        from ....ivy.functional.frontends.torch.tensor import jax_repeat_frnt_
    
        if not jax_is_tensor_frnt_(input):
            raise TypeError(f"Input type is not a Tensor. Got {type(input)}")
        if not len(jax_shape_frnt_(input)) == 5:
            raise ValueError(
                f"Invalid input shape, we expect BxCxDxHxW. Got: {jax_shape_frnt_(input)}"
            )
        B, CH, D, H, W = jax_shape_frnt_(input)
        grid_global: typing.Any = jax_permute_frnt_(
            jax_create_meshgrid3d(D, H, W, False, device=input.device), 0, 4, 1, 2, 3
        )
        grid_global = jax_to_frnt_(grid_global, input.dtype)
        b: typing.Any = jax_spatial_gradient3d(input, order=1, mode="diff")
        b = jax_reshape_frnt_(jax_permute_frnt_(b, 0, 1, 3, 4, 5, 2), -1, 3, 1)
        A: typing.Any = jax_spatial_gradient3d(input, order=2, mode="diff")
        A = jax_reshape_frnt_(jax_permute_frnt_(A, 0, 1, 3, 4, 5, 2), -1, 6)
        dxx = A[..., 0]
        dyy = A[..., 1]
        dss = A[..., 2]
        dxy = 0.25 * A[..., 3]
        dys = 0.25 * A[..., 4]
        dxs = 0.25 * A[..., 5]
        Hes = jax_view_frnt_(
            stack([dxx, dxy, dxs, dxy, dyy, dys, dxs, dys, dss], -1), -1, 3, 3
        )
        if not jax_torch_version_ge(1, 10):
            Hes = (
                Hes
                + jax_abs_frnt_(rand(jax_size_frnt_(Hes[0]), device=Hes.device))[None] * eps
            )
        nms_mask: typing.Any = jax_nms3d(input, (3, 3, 3), True)
        x_solved: typing.Any = zeros_like(b)
>       x_solved_masked, _, solved_correctly = jax_safe_solve_with_mask(
            jax_get_item(b, jax_view_frnt_(nms_mask, -1)),
            jax_get_item(Hes, jax_view_frnt_(nms_mask, -1)),
        )

ivy_transpiled_outputs/jax_outputs/kornia/geometry/subpix/spatial_soft_argmax.py:90: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

B = Array([], shape=(0, 3, 1), dtype=float32), A = Array([], shape=(0, 3, 3), dtype=float32)

    def jax_safe_solve_with_mask(B, A):
        from ._compat import jax_torch_version_ge
        from ...ivy.functional.frontends.torch.creation_ops import jax_ones_frnt
        from ...ivy.functional.frontends.torch.linalg import jax_lu_factor_ex_frnt
        from ...ivy.functional.frontends.torch.tensor import jax_to_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_unsqueeze_frnt_
        from ...ivy.functional.frontends.torch.linalg import jax_lu_solve_frnt
        from ...ivy.functional.frontends.torch.miscellaneous_ops import (
            jax_lu_solve_frnt_base_count_1_frnt,
        )
        from ...ivy.functional.frontends.torch.linalg import lu
    
        if not jax_torch_version_ge(1, 10):
            sol = jax__torch_solve_cast(A, B)
            warnings.warn(
                "PyTorch version < 1.10, solve validness mask maybe not correct",
                RuntimeWarning,
            )
            return sol, sol, jax_ones_frnt(len(A), dtype=jnp.bool, device=A.device)
        if not isinstance(B, (jax.Array, nnx.Param)):
            raise AssertionError(f"B must be Tensor. Got: {type(B)}.")
        dtype: typing.Any = B.dtype
        if dtype not in (jnp.float32, jnp.float64):
            dtype = jnp.float32
        if TYPE_CHECKING:
            A_LU: typing.Any
            pivots: typing.Any
            info: typing.Any
        elif jax_torch_version_ge(1, 13):
>           A_LU, pivots, info = jax_lu_factor_ex_frnt(jax_to_frnt_(A, dtype))

ivy_transpiled_outputs/jax_outputs/kornia/utils/helpers.py:73: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

A = Array([], shape=(0, 3, 3), dtype=float32)

    def jax_lu_factor_ex_frnt(A, *, pivot=True, check_errors=False, out=None):
        from ...backends.jax.experimental.linear_algebra import jax_lu_factor
        from ...backends.jax.creation import jax_zeros
        from .tensor import jax_shape_frnt_
        from ...backends.jax.creation import jax_full_like
        from ...backends.jax.creation import jax_ones
    
        try:
>           LU, pivots = jax_lu_factor(A, pivot=pivot, out=out)

ivy_transpiled_outputs/jax_outputs/ivy/functional/frontends/torch/linalg.py:48: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = [Array([], shape=(0, 3, 3), dtype=float32)], kwargs = {'out': None, 'pivot': True}, jax_is_array_bknd = <function jax_is_array_bknd at 0x7f40d07563b0>
jax_set_item = <function jax_set_item at 0x7f40d07497e0>, jax_asarray = <function jax_asarray at 0x7f40d0757250>, jax_get_item = <function jax_get_item at 0x7f40d0749630>, num_args = 1
type_hints = mappingproxy(OrderedDict([('x', <Parameter "x: jax.Array">), ('pivot', <Parameter "pivot: Optional[bool] = True">), ('out', <Parameter "out: Optional[jax.Array] = None">)]))
parameters = ['x', 'pivot', 'out'], annotations = [<class 'jax.Array'>, typing.Optional[bool], typing.Optional[jax.Array]], device = CpuDevice(id=0), i = 0

    @functools.wraps(fn)
    def _handle_array_like_without_promotion(*args, **kwargs):
        from .functional.ivy.general import jax_is_array_bknd
        from .functional.backends.jax.general import jax_set_item
        from .functional.backends.jax.creation import jax_asarray
        from .functional.backends.jax.general import jax_get_item
    
        args = list(args)
        num_args = len(args)
        try:
            type_hints = inspect.signature(fn).parameters
        except (TypeError, ValueError):
            return fn(*args, **kwargs)
        parameters = list(type_hints.keys())
        annotations = [param.annotation for param in type_hints.values()]
        device = jax__get_preferred_device(args, kwargs)
        for i, (annotation, parameter, arg) in enumerate(
            zip(annotations, parameters, args)
        ):
            annotation_str = str(annotation)
            if (
                ("rray" in annotation_str or "Tensor" in annotation_str)
                and parameter != "out"
                and all(
                    sq not in annotation_str
                    for sq in ["Sequence", "List", "Tuple", "float", "int", "bool"]
                )
            ):
                if i < num_args:
                    if arg is None or jax__check_in_nested_sequence(
                        arg, value=Ellipsis, _type=slice
                    ):
                        continue
                    if not jax_is_array_bknd(arg):
                        args = jax_set_item(args, i, jax_asarray(arg, device=device))
                elif parameters in kwargs:
                    kwarg = jax_get_item(kwargs, parameter)
                    if not jax_is_array_bknd(kwarg):
                        kwargs = jax_set_item(
                            kwargs, parameter, jax_asarray(kwarg, device=device)
                        )
>       return fn(*args, **kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/func_wrapper.py:130: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = Array([], shape=(0, 3, 3), dtype=float32)

    @jax_handle_array_like_without_promotion
    def jax_lu_factor(
        x: jax.Array, /, *, pivot: Optional[bool] = True, out: Optional[jax.Array] = None
    ):
>       ret = jax.scipy.linalg.lu(x)

ivy_transpiled_outputs/jax_outputs/ivy/functional/backends/jax/experimental/linear_algebra.py:38: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = Traced<ShapedArray(float32[0,3,3])>with<DynamicJaxprTrace(level=1/0)>, permute_l = False

    @partial(jit, static_argnames=('permute_l', 'overwrite_a', 'check_finite'))
    def lu(a: ArrayLike, permute_l: bool = False, overwrite_a: bool = False,
           check_finite: bool = True) -> tuple[Array, Array] | tuple[Array, Array, Array]:
      """Compute the LU decomposition
    
      JAX implementation of :func:`scipy.linalg.lu`.
    
      The LU decomposition of a matrix `A` is:
    
      .. math::
    
         A = P L U
    
      where `P` is a permutation matrix, `L` is lower-triangular and `U` is upper-triangular.
    
      Args:
        a: array of shape ``(..., M, N)`` to decompose.
        permute_l: if True, then permute ``L`` and return ``(P @ L, U)`` (default: False)
        overwrite_a: not used by JAX
        check_finite: not used by JAX
    
      Returns:
        A tuple of arrays ``(P @ L, U)`` if ``permute_l`` is True, else ``(P, L, U)``:
    
        - ``P`` is a permutation matrix of shape ``(..., M, M)``
        - ``L`` is a lower-triangular matrix of shape ``(... M, K)``
        - ``U`` is an upper-triangular matrix of shape ``(..., K, N)``
    
        with ``K = min(M, N)``
    
      See also:
        - :func:`jax.numpy.linalg.lu`: NumPy-style API for LU decomposition.
        - :func:`jax.lax.linalg.lu`: XLA-style API for LU decomposition.
        - :func:`jax.scipy.linalg.lu_solve`: LU-based linear solver.
    
      Examples:
        An LU decomposition of a 3x3 matrix:
    
        >>> a = jnp.array([[1., 2., 3.],
        ...                [5., 4., 2.],
        ...                [3., 2., 1.]])
        >>> P, L, U = jax.scipy.linalg.lu(a)
    
        ``P`` is a permutation matrix: i.e. each row and column has a single ``1``:
    
        >>> P
        Array([[0., 1., 0.],
               [1., 0., 0.],
               [0., 0., 1.]], dtype=float32)
    
        ``L`` and ``U`` are lower-triangular and upper-triangular matrices:
    
        >>> with jnp.printoptions(precision=3):
        ...   print(L)
        ...   print(U)
        [[ 1.     0.     0.   ]
         [ 0.2    1.     0.   ]
         [ 0.6   -0.333  1.   ]]
        [[5.    4.    2.   ]
         [0.    1.2   2.6  ]
         [0.    0.    0.667]]
    
        The original matrix can be reconstructed by multiplying the three together:
    
        >>> a_reconstructed = P @ L @ U
        >>> jnp.allclose(a, a_reconstructed)
        Array(True, dtype=bool)
      """
      del overwrite_a, check_finite  # unused
>     return _lu(a, permute_l)

/opt/fw/jax/jax/_src/scipy/linalg.py:821: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = Traced<ShapedArray(float32[0,3,3])>with<DynamicJaxprTrace(level=2/0)>, permute_l = False

    @partial(jit, static_argnums=(1,))
    def _lu(a: ArrayLike, permute_l: bool) -> tuple[Array, Array] | tuple[Array, Array, Array]:
      a, = promote_dtypes_inexact(jnp.asarray(a))
      lu, _, permutation = lax_linalg.lu(a)
      dtype = lax.dtype(a)
>     m, n = jnp.shape(a)
E     ValueError: too many values to unpack (expected 2)

/opt/fw/jax/jax/_src/scipy/linalg.py:729: ValueError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.subpix.spatial_soft_argmax.conv_quad_interp3d
_________________________________________________________________________________ test_ConvQuadInterp3d[jax-s2s-False] _________________________________________________________________________________
jax.errors.SimplifiedTraceback: For simplicity, JAX has removed its internal frames from the traceback of the following exception. Set JAX_TRACEBACK_FILTERING=off to include these.

The above exception was the direct cause of the following exception:

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_ConvQuadInterp3d(target_framework, mode, backend_compile):
        print("kornia.geometry.subpix.ConvQuadInterp3d")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target_framework)
    
        conv_quad_interp3d = kornia.geometry.subpix.ConvQuadInterp3d()
        transpiled_conv_quad_interp3d = transpiled_kornia.geometry.subpix.ConvQuadInterp3d()
    
        heatmap = torch.randn(1, 1, 3, 5, 5, requires_grad=True)
        transpiled_heatmap = _nest_torch_tensor_to_new_framework(heatmap, target_framework)
    
        torch_output = conv_quad_interp3d(heatmap)
>       transpiled_output = transpiled_conv_quad_interp3d(transpiled_heatmap)

kornia/geometry/test_subpix.py:363: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_ConvQuadInterp3d(strict_maxima_bonus=10.0)
x = Array([[[[[ 1.7251254 , -0.3827509 , -0.17951472, -0.35125312,
           -1.6881562 ],
          [-0.45588017, -0.443...1.4803851 ],
          [ 1.1582191 , -2.361451  , -0.713566  ,  0.16294314,
           -1.4039541 ]]]]], dtype=float32)

    def __call__(self, x):
>       return jax_conv_quad_interp3d(x, self.strict_maxima_bonus, self.eps)

ivy_transpiled_outputs/jax_outputs/kornia/geometry/subpix/spatial_soft_argmax.py:143: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = Array([[[[[ 1.7251254 , -0.3827509 , -0.17951472, -0.35125312,
           -1.6881562 ],
          [-0.45588017, -0.443...1.4803851 ],
          [ 1.1582191 , -2.361451  , -0.713566  ,  0.16294314,
           -1.4039541 ]]]]], dtype=float32)
strict_maxima_bonus = 10.0, eps = 1e-07

    def jax_conv_quad_interp3d(input, strict_maxima_bonus=10.0, eps=1e-07):
        from ...core._backend import stack
        from ...core._backend import rand
        from ...core._backend import zeros_like
        from ...core._backend import where
        from ....ivy.functional.frontends.torch.tensor_functions import jax_is_tensor_frnt_
        from ....ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ....ivy.functional.frontends.torch.tensor import jax_permute_frnt_
        from ...utils.grid import jax_create_meshgrid3d
        from ....ivy.functional.frontends.torch.tensor import jax_to_frnt_
        from ...filters.sobel import jax_spatial_gradient3d
        from ....ivy.functional.frontends.torch.tensor import jax_reshape_frnt_
        from ....ivy.functional.frontends.torch.tensor import jax_view_frnt_
        from ...utils._compat import jax_torch_version_ge
        from ....ivy.functional.frontends.torch.tensor import jax_abs_frnt_
        from ....ivy.functional.frontends.torch.tensor import jax_size_frnt_
        from .nms import jax_nms3d
        from ...utils.helpers import jax_safe_solve_with_mask
        from ....ivy.functional.backends.jax.general import jax_get_item
        from ....ivy.functional.frontends.torch.tensor import jax_masked_scatter_frnt_
        from ....ivy.functional.backends.jax.general import jax_set_item
        from ....ivy.functional.frontends.torch.tensor import jax_max_frnt_
        from ....ivy.functional.frontends.torch.tensor import jax_masked_fill__frnt_
        from ....ivy.functional.frontends.torch.tensor import jax_expand_as_frnt_
        from ....ivy.functional.frontends.torch.blas_and_lapack_ops import jax_bmm_frnt
        from ....ivy.functional.frontends.torch.tensor import jax_flip_frnt_
        from ....ivy.functional.frontends.torch.tensor import jax_unsqueeze_frnt_
        from ....ivy.functional.frontends.torch.tensor import jax_repeat_frnt_
    
        if not jax_is_tensor_frnt_(input):
            raise TypeError(f"Input type is not a Tensor. Got {type(input)}")
        if not len(jax_shape_frnt_(input)) == 5:
            raise ValueError(
                f"Invalid input shape, we expect BxCxDxHxW. Got: {jax_shape_frnt_(input)}"
            )
        B, CH, D, H, W = jax_shape_frnt_(input)
        grid_global: typing.Any = jax_permute_frnt_(
            jax_create_meshgrid3d(D, H, W, False, device=input.device), 0, 4, 1, 2, 3
        )
        grid_global = jax_to_frnt_(grid_global, input.dtype)
        b: typing.Any = jax_spatial_gradient3d(input, order=1, mode="diff")
        b = jax_reshape_frnt_(jax_permute_frnt_(b, 0, 1, 3, 4, 5, 2), -1, 3, 1)
        A: typing.Any = jax_spatial_gradient3d(input, order=2, mode="diff")
        A = jax_reshape_frnt_(jax_permute_frnt_(A, 0, 1, 3, 4, 5, 2), -1, 6)
        dxx = A[..., 0]
        dyy = A[..., 1]
        dss = A[..., 2]
        dxy = 0.25 * A[..., 3]
        dys = 0.25 * A[..., 4]
        dxs = 0.25 * A[..., 5]
        Hes = jax_view_frnt_(
            stack([dxx, dxy, dxs, dxy, dyy, dys, dxs, dys, dss], -1), -1, 3, 3
        )
        if not jax_torch_version_ge(1, 10):
            Hes = (
                Hes
                + jax_abs_frnt_(rand(jax_size_frnt_(Hes[0]), device=Hes.device))[None] * eps
            )
        nms_mask: typing.Any = jax_nms3d(input, (3, 3, 3), True)
        x_solved: typing.Any = zeros_like(b)
>       x_solved_masked, _, solved_correctly = jax_safe_solve_with_mask(
            jax_get_item(b, jax_view_frnt_(nms_mask, -1)),
            jax_get_item(Hes, jax_view_frnt_(nms_mask, -1)),
        )

ivy_transpiled_outputs/jax_outputs/kornia/geometry/subpix/spatial_soft_argmax.py:93: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

B = Array([[[-0.04913952],
        [ 0.68937016],
        [-0.07964608]]], dtype=float32)
A = Array([[[-3.701058  ,  0.08401811,  0.62305444],
        [ 0.08401811, -8.157953  ,  0.500573  ],
        [ 0.62305444,  0.500573  , -5.0377645 ]]], dtype=float32)

    def jax_safe_solve_with_mask(B, A):
        from ._compat import jax_torch_version_ge
        from ...ivy.functional.frontends.torch.creation_ops import jax_ones_frnt
        from ...ivy.functional.frontends.torch.linalg import jax_lu_factor_ex_frnt
        from ...ivy.functional.frontends.torch.tensor import jax_to_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_unsqueeze_frnt_
        from ...ivy.functional.frontends.torch.linalg import jax_lu_solve_frnt
        from ...ivy.functional.frontends.torch.miscellaneous_ops import (
            jax_lu_solve_frnt_base_count_1_frnt,
        )
        from ...ivy.functional.frontends.torch.linalg import lu
    
        if not jax_torch_version_ge(1, 10):
            sol = jax__torch_solve_cast(A, B)
            warnings.warn(
                "PyTorch version < 1.10, solve validness mask maybe not correct",
                RuntimeWarning,
            )
            return sol, sol, jax_ones_frnt(len(A), dtype=jnp.bool, device=A.device)
        if not isinstance(B, (jax.Array, nnx.Param)):
            raise AssertionError(f"B must be Tensor. Got: {type(B)}.")
        dtype: typing.Any = B.dtype
        if dtype not in (jnp.float32, jnp.float64):
            dtype = jnp.float32
        if TYPE_CHECKING:
            A_LU: typing.Any
            pivots: typing.Any
            info: typing.Any
        elif jax_torch_version_ge(1, 13):
>           A_LU, pivots, info = jax_lu_factor_ex_frnt(jax_to_frnt_(A, dtype))

ivy_transpiled_outputs/jax_outputs/kornia/utils/helpers.py:73: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

A = Array([[[-3.701058  ,  0.08401811,  0.62305444],
        [ 0.08401811, -8.157953  ,  0.500573  ],
        [ 0.62305444,  0.500573  , -5.0377645 ]]], dtype=float32)

    def jax_lu_factor_ex_frnt(A, *, pivot=True, check_errors=False, out=None):
        from ...backends.jax.experimental.linear_algebra import jax_lu_factor
        from ...backends.jax.creation import jax_zeros
        from .tensor import jax_shape_frnt_
        from ...backends.jax.creation import jax_full_like
        from ...backends.jax.creation import jax_ones
    
        try:
>           LU, pivots = jax_lu_factor(A, pivot=pivot, out=out)

ivy_transpiled_outputs/jax_outputs/ivy/functional/frontends/torch/linalg.py:48: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = [Array([[[-3.701058  ,  0.08401811,  0.62305444],
        [ 0.08401811, -8.157953  ,  0.500573  ],
        [ 0.62305444,  0.500573  , -5.0377645 ]]], dtype=float32)]
kwargs = {'out': None, 'pivot': True}, jax_is_array_bknd = <function jax_is_array_bknd at 0x7f40d0d23250>, jax_set_item = <function jax_set_item at 0x7f40bc9be680>
jax_asarray = <function jax_asarray at 0x7f40bc9bc160>, jax_get_item = <function jax_get_item at 0x7f40bc9be4d0>, num_args = 1
type_hints = mappingproxy(OrderedDict([('x', <Parameter "x: jax.Array">), ('pivot', <Parameter "pivot: Optional[bool] = True">), ('out', <Parameter "out: Optional[jax.Array] = None">)]))
parameters = ['x', 'pivot', 'out'], annotations = [<class 'jax.Array'>, typing.Optional[bool], typing.Optional[jax.Array]], device = CpuDevice(id=0), i = 0

    @functools.wraps(fn)
    def _handle_array_like_without_promotion(*args, **kwargs):
        from .functional.ivy.general import jax_is_array_bknd
        from .functional.backends.jax.general import jax_set_item
        from .functional.backends.jax.creation import jax_asarray
        from .functional.backends.jax.general import jax_get_item
    
        args = list(args)
        num_args = len(args)
        try:
            type_hints = inspect.signature(fn).parameters
        except (TypeError, ValueError):
            return fn(*args, **kwargs)
        parameters = list(type_hints.keys())
        annotations = [param.annotation for param in type_hints.values()]
        device = jax__get_preferred_device(args, kwargs)
        for i, (annotation, parameter, arg) in enumerate(
            zip(annotations, parameters, args)
        ):
            annotation_str = str(annotation)
            if (
                ("rray" in annotation_str or "Tensor" in annotation_str)
                and parameter != "out"
                and all(
                    sq not in annotation_str
                    for sq in ["Sequence", "List", "Tuple", "float", "int", "bool"]
                )
            ):
                if i < num_args:
                    if arg is None or jax__check_in_nested_sequence(
                        arg, value=Ellipsis, _type=slice
                    ):
                        continue
                    if not jax_is_array_bknd(arg):
                        args = jax_set_item(args, i, jax_asarray(arg, device=device))
                elif parameters in kwargs:
                    kwarg = jax_get_item(kwargs, parameter)
                    if not jax_is_array_bknd(kwarg):
                        kwargs = jax_set_item(
                            kwargs, parameter, jax_asarray(kwarg, device=device)
                        )
>       return fn(*args, **kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/func_wrapper.py:130: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = Array([[[-3.701058  ,  0.08401811,  0.62305444],
        [ 0.08401811, -8.157953  ,  0.500573  ],
        [ 0.62305444,  0.500573  , -5.0377645 ]]], dtype=float32)

    @jax_handle_array_like_without_promotion
    def jax_lu_factor(
        x: jax.Array, /, *, pivot: Optional[bool] = True, out: Optional[jax.Array] = None
    ):
>       ret = jax.scipy.linalg.lu(x)

ivy_transpiled_outputs/jax_outputs/ivy/functional/backends/jax/experimental/linear_algebra.py:38: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = Traced<ShapedArray(float32[1,3,3])>with<DynamicJaxprTrace(level=1/0)>, permute_l = False

    @partial(jit, static_argnames=('permute_l', 'overwrite_a', 'check_finite'))
    def lu(a: ArrayLike, permute_l: bool = False, overwrite_a: bool = False,
           check_finite: bool = True) -> tuple[Array, Array] | tuple[Array, Array, Array]:
      """Compute the LU decomposition
    
      JAX implementation of :func:`scipy.linalg.lu`.
    
      The LU decomposition of a matrix `A` is:
    
      .. math::
    
         A = P L U
    
      where `P` is a permutation matrix, `L` is lower-triangular and `U` is upper-triangular.
    
      Args:
        a: array of shape ``(..., M, N)`` to decompose.
        permute_l: if True, then permute ``L`` and return ``(P @ L, U)`` (default: False)
        overwrite_a: not used by JAX
        check_finite: not used by JAX
    
      Returns:
        A tuple of arrays ``(P @ L, U)`` if ``permute_l`` is True, else ``(P, L, U)``:
    
        - ``P`` is a permutation matrix of shape ``(..., M, M)``
        - ``L`` is a lower-triangular matrix of shape ``(... M, K)``
        - ``U`` is an upper-triangular matrix of shape ``(..., K, N)``
    
        with ``K = min(M, N)``
    
      See also:
        - :func:`jax.numpy.linalg.lu`: NumPy-style API for LU decomposition.
        - :func:`jax.lax.linalg.lu`: XLA-style API for LU decomposition.
        - :func:`jax.scipy.linalg.lu_solve`: LU-based linear solver.
    
      Examples:
        An LU decomposition of a 3x3 matrix:
    
        >>> a = jnp.array([[1., 2., 3.],
        ...                [5., 4., 2.],
        ...                [3., 2., 1.]])
        >>> P, L, U = jax.scipy.linalg.lu(a)
    
        ``P`` is a permutation matrix: i.e. each row and column has a single ``1``:
    
        >>> P
        Array([[0., 1., 0.],
               [1., 0., 0.],
               [0., 0., 1.]], dtype=float32)
    
        ``L`` and ``U`` are lower-triangular and upper-triangular matrices:
    
        >>> with jnp.printoptions(precision=3):
        ...   print(L)
        ...   print(U)
        [[ 1.     0.     0.   ]
         [ 0.2    1.     0.   ]
         [ 0.6   -0.333  1.   ]]
        [[5.    4.    2.   ]
         [0.    1.2   2.6  ]
         [0.    0.    0.667]]
    
        The original matrix can be reconstructed by multiplying the three together:
    
        >>> a_reconstructed = P @ L @ U
        >>> jnp.allclose(a, a_reconstructed)
        Array(True, dtype=bool)
      """
      del overwrite_a, check_finite  # unused
>     return _lu(a, permute_l)

/opt/fw/jax/jax/_src/scipy/linalg.py:821: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = Traced<ShapedArray(float32[1,3,3])>with<DynamicJaxprTrace(level=2/0)>, permute_l = False

    @partial(jit, static_argnums=(1,))
    def _lu(a: ArrayLike, permute_l: bool) -> tuple[Array, Array] | tuple[Array, Array, Array]:
      a, = promote_dtypes_inexact(jnp.asarray(a))
      lu, _, permutation = lax_linalg.lu(a)
      dtype = lax.dtype(a)
>     m, n = jnp.shape(a)
E     ValueError: too many values to unpack (expected 2)

/opt/fw/jax/jax/_src/scipy/linalg.py:729: ValueError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.subpix.ConvQuadInterp3d
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/geometry/test_subpix.py::test_conv_quad_interp3d[jax-s2s-False] - ValueError: too many values to unpack (expected 2)
FAILED kornia/geometry/test_subpix.py::test_ConvQuadInterp3d[jax-s2s-False] - ValueError: too many values to unpack (expected 2)
============================================================================== 2 failed, 13 passed in 1163.78s (0:19:23) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 56 items

kornia/geometry/test_transform.py ........................................ssssssssssssssss                                                                                                       [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
============================================================================= 40 passed, 16 skipped in 3364.42s (0:56:04) ==============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 19 items

kornia/test_feature1.py .....F.............                                                                                                                                                      [100%]

=============================================================================================== FAILURES ===============================================================================================
______________________________________________________________________________ test_get_laf_descriptors[numpy-s2s-False] _______________________________________________________________________________

target_framework = 'numpy', mode = 's2s', backend_compile = False

    def test_get_laf_descriptors(target_framework, mode, backend_compile):
        trace_args = (
            torch.rand(1, 1, 32, 32),
            torch.rand(1, 3, 2, 3),
            kornia.feature.OriNet(pretrained=False),
        )
        trace_kwargs = {'patch_size': 32, 'grayscale_descriptor': True}
        test_args = (
            torch.rand(5, 1, 32, 32),
            torch.rand(5, 3, 2, 3),
            kornia.feature.OriNet(pretrained=False),
        )
        test_kwargs = {'patch_size': 32, 'grayscale_descriptor': True}
        class_info = {
            'trace_args': {
                2: {'object': kornia.feature.OriNet, 'kwargs': {'pretrained': False}}
            },
            'test_args': {
                2: {'object': kornia.feature.OriNet, 'kwargs': {'pretrained': False}}
            }
        }
>       _test_function(
            kornia.feature.get_laf_descriptors,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
            class_info=class_info,
        )

kornia/test_feature1.py:148: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function get_laf_descriptors at 0x7ff6b0ff9b40>
trace_args = (tensor([[[[0.4246, 0.0548, 0.9095,  ..., 0.2918, 0.3486, 0.8237],
          [0.2079, 0.2416, 0.8648,  ..., 0.2732, 0...., kernel_size=(8, 8), stride=(1, 1), padding=(1, 1))
    (20): Tanh()
    (21): AdaptiveAvgPool2d(output_size=1)
  )
))
trace_kwargs = {'grayscale_descriptor': True, 'patch_size': 32}
test_args = (tensor([[[[0.4269, 0.0699, 0.7606,  ..., 0.8912, 0.2758, 0.7034],
          [0.1036, 0.0244, 0.9888,  ..., 0.9199, 0...., kernel_size=(8, 8), stride=(1, 1), padding=(1, 1))
    (20): Tanh()
    (21): AdaptiveAvgPool2d(output_size=1)
  )
))
test_kwargs = {'grayscale_descriptor': True, 'patch_size': 32}, target = 'numpy', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = True
class_info = {'test_args': {2: {'kwargs': {'pretrained': False}, 'object': <class 'kornia.feature.orientation.OriNet'>}}, 'trace_args': {2: {'kwargs': {'pretrained': False}, 'object': <class 'kornia.feature.orientation.OriNet'>}}}

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function get_laf_descriptors at 0x7ff6b0ff9b40>, fn_name = 'kornia.feature.get_laf_descriptors'
trace_args = (tensor([[[[0.4246, 0.0548, 0.9095,  ..., 0.2918, 0.3486, 0.8237],
          [0.2079, 0.2416, 0.8648,  ..., 0.2732, 0...., kernel_size=(8, 8), stride=(1, 1), padding=(1, 1))
    (20): Tanh()
    (21): AdaptiveAvgPool2d(output_size=1)
  )
))
trace_kwargs = {'grayscale_descriptor': True, 'patch_size': 32}
test_args = (tensor([[[[0.4269, 0.0699, 0.7606,  ..., 0.8912, 0.2758, 0.7034],
          [0.1036, 0.0244, 0.9888,  ..., 0.9199, 0...., kernel_size=(8, 8), stride=(1, 1), padding=(1, 1))
    (20): Tanh()
    (21): AdaptiveAvgPool2d(output_size=1)
  )
))
test_kwargs = {'grayscale_descriptor': True, 'patch_size': 32}, target = 'numpy', backend_compile = False, tolerance = 0.001, deterministic = True
class_info = {'test_args': {2: {'kwargs': {'pretrained': False}, 'object': <class 'kornia.feature.orientation.OriNet'>}}, 'trace_args': {2: {'kwargs': {'pretrained': False}, 'object': <class 'kornia.feature.orientation.OriNet'>}}}

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
>       transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]

helpers.py:305: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

.0 = <enumerate object at 0x7ff658483140>

    transpiled_trace_args = [
>       transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
        for i, arg in enumerate(trace_args)
    ]

helpers.py:306: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

arg = OriNet(
  (features): Sequential(
    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False...2, kernel_size=(8, 8), stride=(1, 1), padding=(1, 1))
    (20): Tanh()
    (21): AdaptiveAvgPool2d(output_size=1)
  )
)
arg_class_info = {'kwargs': {'pretrained': False}, 'object': <class 'kornia.feature.orientation.OriNet'>}

    def transpile_and_instantiate(arg, arg_class_info=None):
        if arg_class_info:
            # If we have class info, transpile the class and instantiate it
>           transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)

helpers.py:277: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

object = <class 'kornia.feature.orientation.OriNet'>, source = 'torch', target = 'numpy', reuse_existing = True, output_dir = 'ivy_transpiled_outputs/'

    def transpile(
        object,
        source: str = "torch",
        target: str = "tensorflow",
        reuse_existing: bool = True,
        output_dir: str = "ivy_transpiled_outputs/",
    ):
        """Converts a given object (class/function) from one framework to another.
    
        This function performs source-to-source translation of a given object from the source framework
        to the target framework.
    
        The object can be translated between two frameworks or between the Ivy IR as well
        e.g. (source="torch_frontend", target="ivy") or (source="torch_frontend", target="tensorflow") etc.
    
        Args:
            object: The object (class/function) to be translated.
            source (str, optional): The source framework. Defaults to 'torch'.
            target (str, optional): The target framework. Defaults to 'tensorflow'.
            reuse_existing (bool, optional): If True, the function will check if `object`
                                             already exists in the translated directory and reuse it.
                                             If False, it will re-translate `object`,
                                             even if it already exists in the directory, and overwrite
                                             the old implementation. Defaults to 'True'.
            output_dir (str, optional): The path to the directory where translated files will be saved.
                                        Defaults to 'ivy_transpiled_outputs/' in the current working directory.
    
        Returns:
            The translated object."""
    
        from ._compiler import transpile as _transpile
    
>       return _transpile(
            object=object,
            source=source,
            target=target,
            reuse_existing=reuse_existing,
            output_dir=output_dir,
        )

../ivy/ivy/compiler/compiler.py:208: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:322: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:310: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:300: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXL.pyx:24: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

MC.pyx:143: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

MC.pyx:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   I.InvalidObjectException: Cannot transpile the object '<class 'ivy_transpiled_outputs.ivy_outputs.kornia.feature.orientation.ivy_OriNet'>' to `numpy` because it is an instance of a stateful class.

IL.pyx:247: InvalidObjectException
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.integrated.get_laf_descriptors
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/test_feature1.py::test_get_laf_descriptors[numpy-s2s-False] - I.InvalidObjectException: Cannot transpile the object '<class 'ivy_transpiled_outputs.ivy_outputs.kornia.feature.orientat...
============================================================================== 1 failed, 18 passed in 1291.21s (0:21:31) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 69 items

kornia/test_color.py ...........F...........F......F.............F....F......F.....F.....F                                                                                                       [100%]

=============================================================================================== FAILURES ===============================================================================================
________________________________________________________________________________ test_rgb_to_hls[tensorflow-s2s-False] _________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_rgb_to_hls(target_framework, mode, backend_compile):
        # Note: We test this function with requires_grad=True,
        # because otherwise we simply get an empty_like tensor
        # with garbage values on each run leading to test failures
        trace_args = (
            torch.rand(1, 3, 4, 5).requires_grad_(True),
        )
        trace_kwargs = {'eps': 1e-8}
        test_args = (
            torch.rand(5, 3, 4, 5).requires_grad_(True),
        )
        test_kwargs = {'eps': 1e-8}
>       _test_function(
            kornia.color.rgb_to_hls,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/test_color.py:295: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function rgb_to_hls at 0x7fa0f6978160>
trace_args = (tensor([[[[0.3354, 0.4660, 0.9948, 0.3776, 0.8283],
          [0.1909, 0.1914, 0.8833, 0.3857, 0.0083],
          [0.... [0.3162, 0.1486, 0.6167, 0.7876, 0.1923],
          [0.5843, 0.2691, 0.3369, 0.7144, 0.6566]]]], requires_grad=True),)
trace_kwargs = {'eps': 1e-08}
test_args = (tensor([[[[1.2275e-01, 8.9040e-01, 7.5625e-01, 8.9582e-01, 3.5901e-01],
          [8.3853e-01, 3.9163e-01, 7.4013e-01...1, 7.7974e-01],
          [2.1594e-01, 1.0542e-01, 2.2774e-01, 3.0894e-01, 8.9599e-01]]]],
       requires_grad=True),)
test_kwargs = {'eps': 1e-08}, target = 'tensorflow', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function rgb_to_hls at 0x7fa0f6978160>, fn_name = 'kornia.color.rgb_to_hls'
trace_args = (tensor([[[[0.3354, 0.4660, 0.9948, 0.3776, 0.8283],
          [0.1909, 0.1914, 0.8833, 0.3857, 0.0083],
          [0.... [0.3162, 0.1486, 0.6167, 0.7876, 0.1923],
          [0.5843, 0.2691, 0.3369, 0.7144, 0.6566]]]], requires_grad=True),)
trace_kwargs = {'eps': 1e-08}
test_args = (tensor([[[[1.2275e-01, 8.9040e-01, 7.5625e-01, 8.9582e-01, 3.5901e-01],
          [8.3853e-01, 3.9163e-01, 7.4013e-01...1, 7.7974e-01],
          [2.1594e-01, 1.0542e-01, 2.2774e-01, 3.0894e-01, 8.9599e-01]]]],
       requires_grad=True),)
test_kwargs = {'eps': 1e-08}, target = 'tensorflow', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
        graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
    
        if deterministic:
>           _to_numpy_and_allclose(orig_out, graph_out, tolerance=tolerance)

helpers.py:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

torch_x = tensor([[[[2.0196, 6.1071, 0.0456, 2.2912, 1.2316],
          [2.5740, 2.9865, 6.0339, 1.8124, 4.0998],
          [5.8....9061, 0.7586, 0.6598, 0.5587],
          [0.5980, 0.2932, 0.7906, 0.8196, 0.7124]]]],
       grad_fn=<StackBackward0>)
transpiled_x = <tf.Tensor: shape=(1, 3, 4, 5), dtype=float32, numpy=
array([[[[0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.],
  ...., 0.],
         [0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.]]]], dtype=float32)>
tolerance = 0.001

    def _to_numpy_and_allclose(torch_x, transpiled_x, tolerance=1e-3):
        orig_data = _nest_array_to_numpy(torch_x)
        transpiled_data = _nest_array_to_numpy(transpiled_x)
>       _check_allclose(orig_data, transpiled_data, tolerance=tolerance)

helpers.py:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[[2.0195901 , 6.107073  , 0.04559293, 2.291201  , 1.2316123 ],
         [2.5740387 , 2.9864922 , 6.0339    , 1...0.6597762 , 0.5587257 ],
         [0.5979771 , 0.29317078, 0.7905524 , 0.81961244, 0.71237785]]]],
      dtype=float32)
y = array([[[[0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.],
         [0., 0., 0., 0.,...0., 0.],
         [0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.]]]], dtype=float32)
tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
>           assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
E           AssertionError: numpy array values are not all close

helpers.py:26: AssertionError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.color.hls.rgb_to_hls
_______________________________________________________________________________ test_rgb_to_yuv420[tensorflow-s2s-False] _______________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_rgb_to_yuv420(target_framework, mode, backend_compile):
        trace_args = (
            torch.rand(1, 3, 4, 6),
        )
        trace_kwargs = {}
        test_args = (
            torch.rand(5, 3, 4, 6),
        )
        test_kwargs = {}
>       _test_function(
            kornia.color.rgb_to_yuv420,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/test_color.py:563: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function rgb_to_yuv420 at 0x7fa0f6979ea0>
trace_args = (tensor([[[[0.6628, 0.6367, 0.5638, 0.3952, 0.3165, 0.9988],
          [0.6179, 0.5948, 0.6698, 0.4609, 0.1274, 0.7787...     [0.2135, 0.8840, 0.8767, 0.7864, 0.9534, 0.6237],
          [0.6440, 0.2554, 0.4576, 0.3445, 0.3692, 0.3046]]]]),)
trace_kwargs = {}
test_args = (tensor([[[[0.4305, 0.0985, 0.2170, 0.4608, 0.6464, 0.2816],
          [0.9991, 0.5985, 0.4617, 0.0697, 0.1951, 0.6298...     [0.3300, 0.8931, 0.3643, 0.5734, 0.7496, 0.8722],
          [0.9408, 0.1670, 0.3042, 0.2762, 0.5561, 0.9057]]]]),)
test_kwargs = {}, target = 'tensorflow', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function rgb_to_yuv420 at 0x7fa0f6979ea0>, fn_name = 'kornia.color.rgb_to_yuv420'
trace_args = (tensor([[[[0.6628, 0.6367, 0.5638, 0.3952, 0.3165, 0.9988],
          [0.6179, 0.5948, 0.6698, 0.4609, 0.1274, 0.7787...     [0.2135, 0.8840, 0.8767, 0.7864, 0.9534, 0.6237],
          [0.6440, 0.2554, 0.4576, 0.3445, 0.3692, 0.3046]]]]),)
trace_kwargs = {}
test_args = (tensor([[[[0.4305, 0.0985, 0.2170, 0.4608, 0.6464, 0.2816],
          [0.9991, 0.5985, 0.4617, 0.0697, 0.1951, 0.6298...     [0.3300, 0.8931, 0.3643, 0.5734, 0.7496, 0.8722],
          [0.9408, 0.1670, 0.3042, 0.2762, 0.5561, 0.9057]]]]),)
test_kwargs = {}, target = 'tensorflow', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
        graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
    
        if deterministic:
>           _to_numpy_and_allclose(orig_out, graph_out, tolerance=tolerance)

helpers.py:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

torch_x = (tensor([[[[0.5117, 0.3850, 0.3982, 0.4528, 0.3420, 0.8712],
          [0.3865, 0.7274, 0.4487, 0.6897, 0.3160, 0.7029...       [-0.0092, -0.0750,  0.0219]],

         [[ 0.1100,  0.0220, -0.0023],
          [-0.1203, -0.0549,  0.0561]]]]))
transpiled_x = (<tf.Tensor: shape=(1, 1, 4, 6), dtype=float32, numpy=
array([[[[0.5117189 , 0.38502118, 0.39816564, 0.4528408 , 0.341...        [[ 0.22851026, -0.01241448,  0.03967793],
         [-0.10050129, -0.14695683,  0.0022371 ]]]], dtype=float32)>)
tolerance = 0.001

    def _to_numpy_and_allclose(torch_x, transpiled_x, tolerance=1e-3):
        orig_data = _nest_array_to_numpy(torch_x)
        transpiled_data = _nest_array_to_numpy(transpiled_x)
>       _check_allclose(orig_data, transpiled_data, tolerance=tolerance)

helpers.py:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = (array([[[[0.5117189 , 0.38502118, 0.39816564, 0.4528408 , 0.3419598 ,
          0.8712204 ],
         [0.38646537, 0....
        [[ 0.11000554,  0.02198466, -0.00234159],
         [-0.12025428, -0.05494597,  0.05610434]]]], dtype=float32))
y = (array([[[[0.5117189 , 0.38502118, 0.39816564, 0.4528408 , 0.3419598 ,
          0.8712204 ],
         [0.38646537, 0....
        [[ 0.22851026, -0.01241448,  0.03967793],
         [-0.10050129, -0.14695683,  0.0022371 ]]]], dtype=float32))
tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
            assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
            return
    
        if isinstance(x, (list, set, tuple)):
>           all([
                _check_allclose(element_x, element_y, tolerance=tolerance) for element_x, element_y in zip(x, y)
            ])

helpers.py:30: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

.0 = <zip object at 0x7fa072a08140>

    all([
>       _check_allclose(element_x, element_y, tolerance=tolerance) for element_x, element_y in zip(x, y)
    ])

helpers.py:31: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[[ 0.14958851, -0.06431031, -0.11107528],
         [-0.00919018, -0.07501663,  0.02186113]],

        [[ 0.11000554,  0.02198466, -0.00234159],
         [-0.12025428, -0.05494597,  0.05610434]]]], dtype=float32)
y = array([[[[ 0.02485567,  0.16236448, -0.04849147],
         [-0.01856142, -0.04283943, -0.16547059]],

        [[ 0.22851026, -0.01241448,  0.03967793],
         [-0.10050129, -0.14695683,  0.0022371 ]]]], dtype=float32)
tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
>           assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
E           AssertionError: numpy array values are not all close

helpers.py:26: AssertionError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.color.yuv.rgb_to_yuv420
________________________________________________________________________________ test_raw_to_rgb[tensorflow-s2s-False] _________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_raw_to_rgb(target_framework, mode, backend_compile):
        print("kornia.color.raw_to_rgb")
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target_framework)
    
        torch_x = torch.rand(5, 1, 4, 6)
        transpiled_x = _array_to_new_backend(torch_x, target_framework)
    
        torch_out = kornia.color.raw_to_rgb(torch_x, kornia.color.CFA.RG)
        transpiled_out = transpiled_kornia.color.raw_to_rgb(transpiled_x, transpiled_kornia.color.CFA.RG)
    
>       _to_numpy_and_allclose(torch_out, transpiled_out)

kornia/test_color.py:715: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

torch_x = tensor([[[[0.7963, 0.7963, 0.8554, 0.9145, 0.9468, 0.9790],
          [0.7963, 0.7963, 0.8554, 0.9145, 0.9468, 0.9790]...       [0.4038, 0.4713, 0.5389, 0.2818, 0.0248, 0.0248],
          [0.4038, 0.4713, 0.5389, 0.2818, 0.0248, 0.0248]]]])
transpiled_x = <tf.Tensor: shape=(5, 3, 4, 6), dtype=float32, numpy=
array([[[[0.7963428 , 0.7963428 , 0.8554307 , 0.9191273 , 0.9559...77968],
         [0.40376437, 0.4520328 , 0.52926224, 0.2818478 , 0.02477968,
          0.02477968]]]], dtype=float32)>
tolerance = 0.001

    def _to_numpy_and_allclose(torch_x, transpiled_x, tolerance=1e-3):
        orig_data = _nest_array_to_numpy(torch_x)
        transpiled_data = _nest_array_to_numpy(transpiled_x)
>       _check_allclose(orig_data, transpiled_data, tolerance=tolerance)

helpers.py:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[[0.7963428 , 0.7963428 , 0.8554307 , 0.9145187 , 0.9467786 ,
          0.97903854],
         [0.7963428 , 0.7...477968],
         [0.40376437, 0.47134012, 0.53891593, 0.2818478 , 0.02477968,
          0.02477968]]]], dtype=float32)
y = array([[[[0.7963428 , 0.7963428 , 0.8554307 , 0.9191273 , 0.95599574,
          0.97903854],
         [0.7963428 , 0.7...477968],
         [0.40376437, 0.4520328 , 0.52926224, 0.2818478 , 0.02477968,
          0.02477968]]]], dtype=float32)
tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
>           assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
E           AssertionError: numpy array values are not all close

helpers.py:26: AssertionError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.color.raw_to_rgb
_________________________________________________________________________________ test_RgbToHls[tensorflow-s2s-False] __________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_RgbToHls(target_framework, mode, backend_compile):
        args = (
            torch.rand(2, 3, 4, 5),
        )
>       _test_color_class(
            kornia.color.RgbToHls,
            "kornia.color.RgbToHls",
            args,
            target_framework,
            backend_compile,
            tolerance=1e-3,
        )

kornia/test_color.py:920: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'kornia.color.hls.RgbToHls'>, cls_name = 'kornia.color.RgbToHls'
args = (tensor([[[[0.3892, 0.3524, 0.6099, 0.0277, 0.8178],
          [0.2862, 0.3130, 0.8184, 0.2627, 0.3758],
          [0...., 0.1298],
          [0.0362, 0.7308, 0.1650, 0.9924, 0.2485],
          [0.4755, 0.0464, 0.8847, 0.5658, 0.0811]]]]),)
target = 'tensorflow', backend_compile = False, tolerance = 0.001, init_args = ()

    def _test_color_class(
        cls,
        cls_name,
        args,
        target,
        backend_compile=False,
        tolerance=1e-3,
        init_args=(),
    ):
        print(f"{cls.__module__}.{cls.__name__}")
    
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
    
        torch_obj = cls(*init_args)
        if cls_name:
            transpiled_obj = eval("transpiled_" + f"{cls_name}")(*init_args)
        else:
            transpiled_obj = eval("transpiled_" + f"{cls.__module__}.{cls.__name__}")(*init_args)
    
        torch_out = torch_obj(*args)
        transpile_args = _nest_torch_tensor_to_new_framework(args, target)
        transpiled_out = transpiled_obj(*transpile_args)
    
        orig_np = _nest_array_to_numpy(torch_out)
        graph_np = _nest_array_to_numpy(transpiled_out)
    
>       _check_allclose(orig_np, graph_np, tolerance=tolerance)

kornia/test_color.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[[4.44826   , 3.6301641 , 2.631535  , 4.1545115 , 1.28907   ],
         [2.0102096 , 3.08956   , 4.964927  , 6...0.98466605, 0.6690408 ],
         [0.57224435, 0.8914039 , 0.8447034 , 0.13502878, 0.8154291 ]]]],
      dtype=float32)
y = array([[[[0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.],
         [0., 0., 0., 0.,...0., 0.],
         [0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.]]]], dtype=float32)
tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
>           assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
E           AssertionError: numpy array values are not all close

helpers.py:26: AssertionError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.color.hls.RgbToHls
_________________________________________________________________________________ test_LuvToRgb[tensorflow-s2s-False] __________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_LuvToRgb(target_framework, mode, backend_compile):
        args = (
            torch.rand(2, 3, 4, 5),
        )
>       _test_color_class(
            kornia.color.LuvToRgb,
            "kornia.color.RgbToLuv",
            args,
            target_framework,
            backend_compile,
            tolerance=1e-3,
        )

kornia/test_color.py:990: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'kornia.color.luv.LuvToRgb'>, cls_name = 'kornia.color.RgbToLuv'
args = (tensor([[[[0.0346, 0.8252, 0.6226, 0.8823, 0.1820],
          [0.5825, 0.1404, 0.4360, 0.0284, 0.9042],
          [0...., 0.1084],
          [0.5340, 0.6212, 0.7992, 0.4543, 0.7689],
          [0.0729, 0.8713, 0.9452, 0.1335, 0.8059]]]]),)
target = 'tensorflow', backend_compile = False, tolerance = 0.001, init_args = ()

    def _test_color_class(
        cls,
        cls_name,
        args,
        target,
        backend_compile=False,
        tolerance=1e-3,
        init_args=(),
    ):
        print(f"{cls.__module__}.{cls.__name__}")
    
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
    
        torch_obj = cls(*init_args)
        if cls_name:
            transpiled_obj = eval("transpiled_" + f"{cls_name}")(*init_args)
        else:
            transpiled_obj = eval("transpiled_" + f"{cls.__module__}.{cls.__name__}")(*init_args)
    
        torch_out = torch_obj(*args)
        transpile_args = _nest_torch_tensor_to_new_framework(args, target)
        transpiled_out = transpiled_obj(*transpile_args)
    
        orig_np = _nest_array_to_numpy(torch_out)
        graph_np = _nest_array_to_numpy(transpiled_out)
    
>       _check_allclose(orig_np, graph_np, tolerance=tolerance)

kornia/test_color.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[[ 0.0024248 ,  0.02559083,  0.02365924,  0.01833387,
           0.00963905],
         [ 0.01252648,  0.006286...  -0.00280268],
         [ 0.00970468,  0.00166335, -0.00404521,  0.00531203,
          -0.00395006]]]], dtype=float32)
y = array([[[[ 41.578568,  80.47362 ,  81.44581 ,  55.923676,  65.28098 ],
         [ 40.927307,  51.19249 ,  38.864323,  ... 68.64491 , -84.32734 ],
         [ 45.480858, -59.177505, -18.445415,  10.240575, -69.51869 ]]]],
      dtype=float32)
tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
>           assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
E           AssertionError: numpy array values are not all close

helpers.py:26: AssertionError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.color.luv.LuvToRgb
________________________________________________________________________________ test_RgbToYuv420[tensorflow-s2s-False] ________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_RgbToYuv420(target_framework, mode, backend_compile):
        args = (
            torch.rand(2, 3, 4, 6),
        )
>       _test_color_class(
            kornia.color.RgbToYuv420,
            "kornia.color.RgbToYuv420",
            args,
            target_framework,
            backend_compile,
            tolerance=1e-3,
        )

kornia/test_color.py:1088: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'kornia.color.yuv.RgbToYuv420'>, cls_name = 'kornia.color.RgbToYuv420'
args = (tensor([[[[7.7708e-01, 9.6678e-01, 8.6971e-01, 5.2846e-01, 6.2707e-02,
           7.5187e-01],
          [8.0079e-01,...       8.4200e-02],
          [5.6154e-01, 9.1227e-01, 9.0701e-01, 4.6786e-01, 3.1185e-04,
           5.0549e-02]]]]),)
target = 'tensorflow', backend_compile = False, tolerance = 0.001, init_args = ()

    def _test_color_class(
        cls,
        cls_name,
        args,
        target,
        backend_compile=False,
        tolerance=1e-3,
        init_args=(),
    ):
        print(f"{cls.__module__}.{cls.__name__}")
    
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
    
        torch_obj = cls(*init_args)
        if cls_name:
            transpiled_obj = eval("transpiled_" + f"{cls_name}")(*init_args)
        else:
            transpiled_obj = eval("transpiled_" + f"{cls.__module__}.{cls.__name__}")(*init_args)
    
        torch_out = torch_obj(*args)
        transpile_args = _nest_torch_tensor_to_new_framework(args, target)
        transpiled_out = transpiled_obj(*transpile_args)
    
        orig_np = _nest_array_to_numpy(torch_out)
        graph_np = _nest_array_to_numpy(transpiled_out)
    
>       _check_allclose(orig_np, graph_np, tolerance=tolerance)

kornia/test_color.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = (array([[[[0.5861917 , 0.8615008 , 0.79655063, 0.74419576, 0.0691382 ,
          0.5113282 ],
         [0.42874047, 0....
        [[ 0.08859536,  0.14365162, -0.15491243],
         [-0.15612835,  0.00566402,  0.0730244 ]]]], dtype=float32))
y = (array([[[[0.5861917 , 0.8615008 , 0.79655063, 0.74419576, 0.0691382 ,
          0.5113282 ],
         [0.42874047, 0....
        [[ 0.04097136,  0.01207216, -0.11603819],
         [ 0.22680603, -0.15428841, -0.0096283 ]]]], dtype=float32))
tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
            assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
            return
    
        if isinstance(x, (list, set, tuple)):
>           all([
                _check_allclose(element_x, element_y, tolerance=tolerance) for element_x, element_y in zip(x, y)
            ])

helpers.py:30: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

.0 = <zip object at 0x7fa072b88ec0>

    all([
>       _check_allclose(element_x, element_y, tolerance=tolerance) for element_x, element_y in zip(x, y)
    ])

helpers.py:31: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[[-0.09170726,  0.01033048, -0.00633965],
         [ 0.02184821, -0.10227109,  0.07348385]],

        [[ 0.070...

        [[ 0.08859536,  0.14365162, -0.15491243],
         [-0.15612835,  0.00566402,  0.0730244 ]]]], dtype=float32)
y = array([[[[-0.07929941,  0.02337586, -0.14708209],
         [ 0.11271482,  0.00561612, -0.00998077]],

        [[ 0.122...

        [[ 0.04097136,  0.01207216, -0.11603819],
         [ 0.22680603, -0.15428841, -0.0096283 ]]]], dtype=float32)
tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
>           assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
E           AssertionError: numpy array values are not all close

helpers.py:26: AssertionError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.color.yuv.RgbToYuv420
_________________________________________________________________________________ test_RawToRgb[tensorflow-s2s-False] __________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_RawToRgb(target_framework, mode, backend_compile):
        print("kornia.color.RawToRgb")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target_framework)
    
        torch_x = torch.rand(2, 1, 4, 6)
        transpiled_x = _array_to_new_backend(torch_x, target_framework)
    
        torch_out = kornia.color.RawToRgb(kornia.color.CFA.RG)(torch_x)
        transpiled_out = transpiled_kornia.color.RawToRgb(transpiled_kornia.color.CFA.RG)(transpiled_x)
    
>       _to_numpy_and_allclose(torch_out, transpiled_out)

kornia/test_color.py:1184: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

torch_x = tensor([[[[0.6632, 0.6632, 0.4027, 0.1422, 0.1302, 0.1182],
          [0.6632, 0.6632, 0.4027, 0.1422, 0.1302, 0.1182]...       [0.1992, 0.3871, 0.5751, 0.3090, 0.0429, 0.0429],
          [0.1992, 0.3871, 0.5751, 0.3090, 0.0429, 0.0429]]]])
transpiled_x = <tf.Tensor: shape=(2, 3, 4, 6), dtype=float32, numpy=
array([[[[0.6631552 , 0.6631552 , 0.402688  , 0.14050148, 0.1267...93436],
         [0.19919586, 0.33343887, 0.54822755, 0.30900526, 0.04293436,
          0.04293436]]]], dtype=float32)>
tolerance = 0.001

    def _to_numpy_and_allclose(torch_x, transpiled_x, tolerance=1e-3):
        orig_data = _nest_array_to_numpy(torch_x)
        transpiled_data = _nest_array_to_numpy(transpiled_x)
>       _check_allclose(orig_data, transpiled_data, tolerance=tolerance)

helpers.py:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[[0.6631552 , 0.6631552 , 0.40268797, 0.1422208 , 0.1301856 ,
          0.11815041],
         [0.6631552 , 0.6...293436],
         [0.19919586, 0.387136  , 0.57507616, 0.30900526, 0.04293436,
          0.04293436]]]], dtype=float32)
y = array([[[[0.6631552 , 0.6631552 , 0.402688  , 0.14050148, 0.12674697,
          0.11815041],
         [0.6631552 , 0.6...293436],
         [0.19919586, 0.33343887, 0.54822755, 0.30900526, 0.04293436,
          0.04293436]]]], dtype=float32)
tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
>           assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
E           AssertionError: numpy array values are not all close

helpers.py:26: AssertionError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.color.RawToRgb
______________________________________________________________________________ test_apply_colormap[tensorflow-s2s-False] _______________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_apply_colormap(target_framework, mode, backend_compile):
        print("kornia.color.ColorMap")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target_framework)
    
        torch_x = torch.tensor([[[0, 1, 2], [15, 25, 33], [128, 158, 188]]])
        transpiled_x = _array_to_new_backend(torch_x, target_framework)
    
        colormap = kornia.color.ColorMap(base=kornia.color.ColorMapType.autumn)
        torch_out = kornia.color.apply_colormap(torch_x, colormap)
    
        transpiled_colormap = transpiled_kornia.color.ColorMap(base=transpiled_kornia.color.ColorMapType.autumn)
>       transpiled_out = transpiled_kornia.color.apply_colormap(transpiled_x, transpiled_colormap)

kornia/test_color.py:1285: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:230: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:153: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   AttributeError: module 'ivy_transpiled_outputs.tensorflow_outputs.kornia.color.colormap' has no attribute 'tensorflow_ColorMap'

IXC.pyx:162: AttributeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.color.ColorMap
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/test_color.py::test_rgb_to_hls[tensorflow-s2s-False] - AssertionError: numpy array values are not all close
FAILED kornia/test_color.py::test_rgb_to_yuv420[tensorflow-s2s-False] - AssertionError: numpy array values are not all close
FAILED kornia/test_color.py::test_raw_to_rgb[tensorflow-s2s-False] - AssertionError: numpy array values are not all close
FAILED kornia/test_color.py::test_RgbToHls[tensorflow-s2s-False] - AssertionError: numpy array values are not all close
FAILED kornia/test_color.py::test_LuvToRgb[tensorflow-s2s-False] - AssertionError: numpy array values are not all close
FAILED kornia/test_color.py::test_RgbToYuv420[tensorflow-s2s-False] - AssertionError: numpy array values are not all close
FAILED kornia/test_color.py::test_RawToRgb[tensorflow-s2s-False] - AssertionError: numpy array values are not all close
FAILED kornia/test_color.py::test_apply_colormap[tensorflow-s2s-False] - AttributeError: module 'ivy_transpiled_outputs.tensorflow_outputs.kornia.color.colormap' has no attribute 'tensorflow_ColorMap'
============================================================================== 8 failed, 61 passed in 4070.41s (1:07:50) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 1 item

kornia/geometry/test_ransac.py .                                                                                                                                                                 [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
==================================================================================== 1 passed in 166.95s (0:02:46) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 1 item

kornia/test_tracking.py s                                                                                                                                                                        [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
========================================================================================== 1 skipped in 5.21s ==========================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 13 items

kornia/test_utils.py .............                                                                                                                                                               [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
==================================================================================== 13 passed in 806.06s (0:13:26) ====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 7 items

kornia/test_morphology.py .......                                                                                                                                                                [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
==================================================================================== 7 passed in 472.35s (0:07:52) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 35 items

kornia/test_losses.py .................ssssssssssssssssss                                                                                                                                        [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
============================================================================== 17 passed, 18 skipped in 941.57s (0:15:41) ==============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 15 items

kornia/geometry/test_subpix.py .FF....FFssssss                                                                                                                                                   [100%]

=============================================================================================== FAILURES ===============================================================================================
_______________________________________________________________________________ test_conv_soft_argmax3d[numpy-s2s-False] _______________________________________________________________________________

target_framework = 'numpy', mode = 's2s', backend_compile = False

    def test_conv_soft_argmax3d(target_framework, mode, backend_compile):
        trace_args = (
            torch.rand(20, 16, 3, 50, 32),
        )
        trace_kwargs = {
            'kernel_size': (3, 3, 3),
            'stride': (1, 1, 1),
            'padding': (1, 1, 1),
            'temperature': torch.tensor(1.0),
            'normalized_coordinates': False,
            'eps': 1e-8,
            'output_value': True,
            'strict_maxima_bonus': 0.0,
        }
        test_args = (
            torch.rand(10, 16, 5, 50, 32),
        )
        test_kwargs = {
            'kernel_size': (3, 3, 3),
            'stride': (1, 1, 1),
            'padding': (1, 1, 1),
            'temperature': torch.tensor(0.5),
            'normalized_coordinates': False,
            'eps': 1e-8,
            'output_value': True,
            'strict_maxima_bonus': 0.0,
        }
>       _test_function(
            kornia.geometry.subpix.conv_soft_argmax3d,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/geometry/test_subpix.py:81: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function conv_soft_argmax3d at 0x7fb8f29eee60>
trace_args = (tensor([[[[[8.3362e-01, 7.2261e-01, 6.8192e-02,  ..., 1.5621e-01,
            6.7259e-01, 4.7717e-01],
           [6....1609e-02],
           [4.6314e-01, 3.6920e-01, 8.8080e-01,  ..., 5.8455e-01,
            6.0616e-01, 2.9422e-02]]]]]),)
trace_kwargs = {'eps': 1e-08, 'kernel_size': (3, 3, 3), 'normalized_coordinates': False, 'output_value': True, ...}
test_args = (tensor([[[[[6.3868e-01, 9.9886e-01, 5.4603e-01,  ..., 1.5296e-01,
            9.5703e-01, 9.2516e-01],
           [8....6919e-02],
           [9.1590e-01, 6.4754e-01, 9.7756e-01,  ..., 4.4302e-01,
            7.2779e-01, 3.6722e-02]]]]]),)
test_kwargs = {'eps': 1e-08, 'kernel_size': (3, 3, 3), 'normalized_coordinates': False, 'output_value': True, ...}, target = 'numpy', backend_compile = False, tolerance = 0.001, mode = 's2s'
skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function conv_soft_argmax3d at 0x7fb8f29eee60>, fn_name = 'kornia.geometry.subpix.conv_soft_argmax3d'
trace_args = (tensor([[[[[8.3362e-01, 7.2261e-01, 6.8192e-02,  ..., 1.5621e-01,
            6.7259e-01, 4.7717e-01],
           [6....1609e-02],
           [4.6314e-01, 3.6920e-01, 8.8080e-01,  ..., 5.8455e-01,
            6.0616e-01, 2.9422e-02]]]]]),)
trace_kwargs = {'eps': 1e-08, 'kernel_size': (3, 3, 3), 'normalized_coordinates': False, 'output_value': True, ...}
test_args = (tensor([[[[[6.3868e-01, 9.9886e-01, 5.4603e-01,  ..., 1.5296e-01,
            9.5703e-01, 9.2516e-01],
           [8....6919e-02],
           [9.1590e-01, 6.4754e-01, 9.7756e-01,  ..., 4.4302e-01,
            7.2779e-01, 3.6722e-02]]]]]),)
test_kwargs = {'eps': 1e-08, 'kernel_size': (3, 3, 3), 'normalized_coordinates': False, 'output_value': True, ...}, target = 'numpy', backend_compile = False, tolerance = 0.001, deterministic = True
class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:221: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:322: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:310: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:300: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXL.pyx:24: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

MC.pyx:145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

MC.pyx:127: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7fb899a99b70>, node = <gast.gast.Module object at 0x7fb893ff3310>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7fb899a99b70>, node = <gast.gast.Module object at 0x7fb893ff3310>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
>                       value = self.visit(value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:486: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7fb899a99b70>, node = <gast.gast.FunctionDef object at 0x7fb893ff2c80>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:273: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7fb899a99b70>, node = <gast.gast.If object at 0x7fb89851a680>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7fb899a99b70>, node = <gast.gast.If object at 0x7fb89851a680>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
>                       value = self.visit(value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:486: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7fb899a99b70>, node = <gast.gast.AnnAssign object at 0x7fb89851b760>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7fb899a99b70>, node = <gast.gast.Call object at 0x7fb898519840>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7fb899a99b70>, node = <gast.gast.Call object at 0x7fb898519840>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
>                       value = self.visit(value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:486: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7fb899a99b70>, node = <gast.gast.Call object at 0x7fb898518610>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7fb899a99b70>, node = <gast.gast.Call object at 0x7fb898518610>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
                        value = self.visit(value)
                        if value is None:
                            continue
                        elif not isinstance(value, AST):
                            new_values.extend(value)
                            continue
                    new_values.append(value)
                old_value[:] = new_values
            elif isinstance(old_value, AST):
>               new_node = self.visit(old_value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:495: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7fb899a99b70>, node = <gast.gast.Name object at 0x7fb89851b850>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:324: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:141: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:111: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:95: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

MC.pyx:127: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7fb8980e3340>, node = <gast.gast.Module object at 0x7fb893a70a90>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7fb8980e3340>, node = <gast.gast.Module object at 0x7fb893a70a90>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
>                       value = self.visit(value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:486: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7fb8980e3340>, node = <gast.gast.FunctionDef object at 0x7fb893a70be0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:273: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7fb8980e3340>, node = <gast.gast.Return object at 0x7fb893a71b40>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7fb8980e3340>, node = <gast.gast.Return object at 0x7fb893a71b40>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
                        value = self.visit(value)
                        if value is None:
                            continue
                        elif not isinstance(value, AST):
                            new_values.extend(value)
                            continue
                    new_values.append(value)
                old_value[:] = new_values
            elif isinstance(old_value, AST):
>               new_node = self.visit(old_value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:495: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7fb8980e3340>, node = <gast.gast.Call object at 0x7fb893a72470>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7fb8980e3340>, node = <gast.gast.Call object at 0x7fb893a72470>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
                        value = self.visit(value)
                        if value is None:
                            continue
                        elif not isinstance(value, AST):
                            new_values.extend(value)
                            continue
                    new_values.append(value)
                old_value[:] = new_values
            elif isinstance(old_value, AST):
>               new_node = self.visit(old_value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:495: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7fb8980e3340>, node = <gast.gast.Call object at 0x7fb893a70040>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7fb8980e3340>, node = <gast.gast.Call object at 0x7fb893a70040>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
                        value = self.visit(value)
                        if value is None:
                            continue
                        elif not isinstance(value, AST):
                            new_values.extend(value)
                            continue
                    new_values.append(value)
                old_value[:] = new_values
            elif isinstance(old_value, AST):
>               new_node = self.visit(old_value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:495: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7fb8980e3340>, node = <gast.gast.Name object at 0x7fb893a704c0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:324: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:141: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:111: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:91: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   I.InvalidObjectException: Cannot transpile the object '<class 'ivy_transpiled_outputs.ivy_outputs.kornia.geometry.subpix.nms.ivy_NonMaximaSuppression3d'>' to `numpy` because it is an instance of a stateful class.

IL.pyx:247: InvalidObjectException
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.subpix.spatial_soft_argmax.conv_soft_argmax3d
_______________________________________________________________________________ test_conv_quad_interp3d[numpy-s2s-False] _______________________________________________________________________________

target_framework = 'numpy', mode = 's2s', backend_compile = False

    def test_conv_quad_interp3d(target_framework, mode, backend_compile):
        trace_args = (
            torch.rand(2, 2, 2, 5, 5),
        )
        trace_kwargs = {
            'strict_maxima_bonus': 10.0,
            'eps': 1e-7,
        }
        test_args = (
            torch.rand(1, 2, 2, 5, 5),
        )
        test_kwargs = {
            'strict_maxima_bonus': 5.0,
            'eps': 1e-7,
        }
>       _test_function(
            kornia.geometry.subpix.conv_quad_interp3d,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/geometry/test_subpix.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function conv_quad_interp3d at 0x7fb8f29eef80>
trace_args = (tensor([[[[[0.0031, 0.9486, 0.3046, 0.9891, 0.2102],
           [0.0963, 0.7620, 0.1505, 0.8648, 0.7798],
           ....6601],
           [0.0354, 0.4254, 0.2361, 0.9483, 0.7552],
           [0.0692, 0.2385, 0.7817, 0.8300, 0.0028]]]]]),)
trace_kwargs = {'eps': 1e-07, 'strict_maxima_bonus': 10.0}
test_args = (tensor([[[[[0.6568, 0.9713, 0.4571, 0.6426, 0.1755],
           [0.8492, 0.3240, 0.5265, 0.4924, 0.8766],
           ....9119],
           [0.1001, 0.8083, 0.7231, 0.6721, 0.1441],
           [0.5986, 0.2614, 0.1489, 0.0258, 0.6193]]]]]),)
test_kwargs = {'eps': 1e-07, 'strict_maxima_bonus': 5.0}, target = 'numpy', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function conv_quad_interp3d at 0x7fb8f29eef80>, fn_name = 'kornia.geometry.subpix.conv_quad_interp3d'
trace_args = (tensor([[[[[0.0031, 0.9486, 0.3046, 0.9891, 0.2102],
           [0.0963, 0.7620, 0.1505, 0.8648, 0.7798],
           ....6601],
           [0.0354, 0.4254, 0.2361, 0.9483, 0.7552],
           [0.0692, 0.2385, 0.7817, 0.8300, 0.0028]]]]]),)
trace_kwargs = {'eps': 1e-07, 'strict_maxima_bonus': 10.0}
test_args = (tensor([[[[[0.6568, 0.9713, 0.4571, 0.6426, 0.1755],
           [0.8492, 0.3240, 0.5265, 0.4924, 0.8766],
           ....9119],
           [0.1001, 0.8083, 0.7231, 0.6721, 0.1441],
           [0.5986, 0.2614, 0.1489, 0.0258, 0.6193]]]]]),)
test_kwargs = {'eps': 1e-07, 'strict_maxima_bonus': 5.0}, target = 'numpy', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:221: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:322: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:310: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:300: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXL.pyx:24: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

MC.pyx:145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

MC.pyx:127: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7fb899e47400>, node = <gast.gast.Module object at 0x7fb8981aaef0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7fb899e47400>, node = <gast.gast.Module object at 0x7fb8981aaef0>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
>                       value = self.visit(value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:486: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7fb899e47400>, node = <gast.gast.FunctionDef object at 0x7fb8981a8640>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:273: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7fb899e47400>, node = <gast.gast.AnnAssign object at 0x7fb8980e1a80>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7fb899e47400>, node = <gast.gast.Call object at 0x7fb89a3d3ac0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7fb899e47400>, node = <gast.gast.Call object at 0x7fb89a3d3ac0>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
                        value = self.visit(value)
                        if value is None:
                            continue
                        elif not isinstance(value, AST):
                            new_values.extend(value)
                            continue
                    new_values.append(value)
                old_value[:] = new_values
            elif isinstance(old_value, AST):
>               new_node = self.visit(old_value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:495: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7fb899e47400>, node = <gast.gast.Name object at 0x7fb89a3d3f70>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:324: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:141: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:111: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:95: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

MC.pyx:127: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7fb899c16620>, node = <gast.gast.Module object at 0x7fb899872e30>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7fb899c16620>, node = <gast.gast.Module object at 0x7fb899872e30>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
>                       value = self.visit(value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:486: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7fb899c16620>, node = <gast.gast.FunctionDef object at 0x7fb8998709d0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:273: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7fb899c16620>, node = <gast.gast.Return object at 0x7fb89a222380>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7fb899c16620>, node = <gast.gast.Return object at 0x7fb89a222380>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
                        value = self.visit(value)
                        if value is None:
                            continue
                        elif not isinstance(value, AST):
                            new_values.extend(value)
                            continue
                    new_values.append(value)
                old_value[:] = new_values
            elif isinstance(old_value, AST):
>               new_node = self.visit(old_value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:495: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7fb899c16620>, node = <gast.gast.Call object at 0x7fb899acd1e0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7fb899c16620>, node = <gast.gast.Call object at 0x7fb899acd1e0>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
                        value = self.visit(value)
                        if value is None:
                            continue
                        elif not isinstance(value, AST):
                            new_values.extend(value)
                            continue
                    new_values.append(value)
                old_value[:] = new_values
            elif isinstance(old_value, AST):
>               new_node = self.visit(old_value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:495: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7fb899c16620>, node = <gast.gast.Call object at 0x7fb899acefb0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7fb899c16620>, node = <gast.gast.Call object at 0x7fb899acefb0>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
                        value = self.visit(value)
                        if value is None:
                            continue
                        elif not isinstance(value, AST):
                            new_values.extend(value)
                            continue
                    new_values.append(value)
                old_value[:] = new_values
            elif isinstance(old_value, AST):
>               new_node = self.visit(old_value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:495: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7fb899c16620>, node = <gast.gast.Name object at 0x7fb899acf3d0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:324: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:141: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:111: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:91: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   I.InvalidObjectException: Cannot transpile the object '<class 'ivy_transpiled_outputs.ivy_outputs.kornia.geometry.subpix.nms.ivy_NonMaximaSuppression3d'>' to `numpy` because it is an instance of a stateful class.

IL.pyx:247: InvalidObjectException
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.subpix.spatial_soft_argmax.conv_quad_interp3d
_____________________________________________________________________________________ test_nms2d[numpy-s2s-False] ______________________________________________________________________________________

target_framework = 'numpy', mode = 's2s', backend_compile = False

    def test_nms2d(target_framework, mode, backend_compile):
        trace_args = (
            torch.rand(1, 1, 5, 5),
            (3, 3),
        )
        trace_kwargs = {
            'mask_only': False,
        }
        test_args = (
            torch.rand(10, 1, 5, 5),
            (3, 3),
        )
        test_kwargs = {
            'mask_only': False,
        }
>       _test_function(
            kornia.geometry.subpix.nms2d,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/geometry/test_subpix.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function nms2d at 0x7fb8f29ee170>
trace_args = (tensor([[[[8.4823e-04, 8.5951e-01, 7.9969e-01, 8.9602e-01, 3.2914e-01],
          [2.8336e-01, 7.5030e-01, 4.2837e-01....8634e-01, 9.3266e-01, 8.4802e-01],
          [1.5246e-02, 7.4220e-01, 3.3765e-01, 9.0648e-01, 1.4083e-02]]]]), (3, 3))
trace_kwargs = {'mask_only': False}
test_args = (tensor([[[[0.5632, 0.3065, 0.3661, 0.3230, 0.0031],
          [0.4136, 0.8507, 0.3627, 0.7014, 0.3742],
          [0....3],
          [0.1442, 0.1610, 0.1349, 0.2292, 0.0574],
          [0.5930, 0.2338, 0.0940, 0.7415, 0.9814]]]]), (3, 3))
test_kwargs = {'mask_only': False}, target = 'numpy', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function nms2d at 0x7fb8f29ee170>, fn_name = 'kornia.geometry.subpix.nms2d'
trace_args = (tensor([[[[8.4823e-04, 8.5951e-01, 7.9969e-01, 8.9602e-01, 3.2914e-01],
          [2.8336e-01, 7.5030e-01, 4.2837e-01....8634e-01, 9.3266e-01, 8.4802e-01],
          [1.5246e-02, 7.4220e-01, 3.3765e-01, 9.0648e-01, 1.4083e-02]]]]), (3, 3))
trace_kwargs = {'mask_only': False}
test_args = (tensor([[[[0.5632, 0.3065, 0.3661, 0.3230, 0.0031],
          [0.4136, 0.8507, 0.3627, 0.7014, 0.3742],
          [0....3],
          [0.1442, 0.1610, 0.1349, 0.2292, 0.0574],
          [0.5930, 0.2338, 0.0940, 0.7415, 0.9814]]]]), (3, 3))
test_kwargs = {'mask_only': False}, target = 'numpy', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:221: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:322: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:310: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:300: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXL.pyx:24: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

MC.pyx:145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

MC.pyx:127: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7fb893ab03d0>, node = <gast.gast.Module object at 0x7fb89b7dc5e0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7fb893ab03d0>, node = <gast.gast.Module object at 0x7fb89b7dc5e0>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
>                       value = self.visit(value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:486: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7fb893ab03d0>, node = <gast.gast.FunctionDef object at 0x7fb898415810>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:273: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7fb893ab03d0>, node = <gast.gast.Return object at 0x7fb898415bd0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7fb893ab03d0>, node = <gast.gast.Return object at 0x7fb898415bd0>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
                        value = self.visit(value)
                        if value is None:
                            continue
                        elif not isinstance(value, AST):
                            new_values.extend(value)
                            continue
                    new_values.append(value)
                old_value[:] = new_values
            elif isinstance(old_value, AST):
>               new_node = self.visit(old_value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:495: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7fb893ab03d0>, node = <gast.gast.Call object at 0x7fb8984156c0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7fb893ab03d0>, node = <gast.gast.Call object at 0x7fb8984156c0>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
                        value = self.visit(value)
                        if value is None:
                            continue
                        elif not isinstance(value, AST):
                            new_values.extend(value)
                            continue
                    new_values.append(value)
                old_value[:] = new_values
            elif isinstance(old_value, AST):
>               new_node = self.visit(old_value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:495: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7fb893ab03d0>, node = <gast.gast.Call object at 0x7fb8984158d0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7fb893ab03d0>, node = <gast.gast.Call object at 0x7fb8984158d0>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
                        value = self.visit(value)
                        if value is None:
                            continue
                        elif not isinstance(value, AST):
                            new_values.extend(value)
                            continue
                    new_values.append(value)
                old_value[:] = new_values
            elif isinstance(old_value, AST):
>               new_node = self.visit(old_value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:495: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7fb893ab03d0>, node = <gast.gast.Name object at 0x7fb898417070>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:324: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:141: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:111: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:91: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   I.InvalidObjectException: Cannot transpile the object '<class 'ivy_transpiled_outputs.ivy_outputs.kornia.geometry.subpix.nms.ivy_NonMaximaSuppression2d'>' to `numpy` because it is an instance of a stateful class.

IL.pyx:247: InvalidObjectException
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.subpix.nms.nms2d
_____________________________________________________________________________________ test_nms3d[numpy-s2s-False] ______________________________________________________________________________________

target_framework = 'numpy', mode = 's2s', backend_compile = False

    def test_nms3d(target_framework, mode, backend_compile):
        trace_args = (
            torch.rand(1, 1, 5, 5, 5),
            (3, 3, 3),
        )
        trace_kwargs = {
            'mask_only': False,
        }
        test_args = (
            torch.rand(10, 1, 5, 5, 5),
            (3, 3, 3),
        )
        test_kwargs = {
            'mask_only': False,
        }
>       _test_function(
            kornia.geometry.subpix.nms3d,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/geometry/test_subpix.py:275: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function nms3d at 0x7fb8f29ee560>
trace_args = (tensor([[[[[0.2817, 0.5303, 0.1293, 0.0542, 0.3766],
           [0.3132, 0.9498, 0.1653, 0.8829, 0.6755],
           ...         [0.2664, 0.3502, 0.0100, 0.2935, 0.3171],
           [0.9778, 0.9263, 0.1863, 0.7564, 0.5457]]]]]), (3, 3, 3))
trace_kwargs = {'mask_only': False}
test_args = (tensor([[[[[1.4450e-01, 3.4265e-01, 5.6080e-01, 2.4315e-01, 3.8563e-02],
           [3.4444e-01, 8.5632e-01, 1.6829e-...e-01, 3.7113e-01, 1.7873e-02],
           [6.5002e-01, 5.7335e-01, 2.8305e-01, 3.8843e-02, 7.6084e-01]]]]]), (3, 3, 3))
test_kwargs = {'mask_only': False}, target = 'numpy', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function nms3d at 0x7fb8f29ee560>, fn_name = 'kornia.geometry.subpix.nms3d'
trace_args = (tensor([[[[[0.2817, 0.5303, 0.1293, 0.0542, 0.3766],
           [0.3132, 0.9498, 0.1653, 0.8829, 0.6755],
           ...         [0.2664, 0.3502, 0.0100, 0.2935, 0.3171],
           [0.9778, 0.9263, 0.1863, 0.7564, 0.5457]]]]]), (3, 3, 3))
trace_kwargs = {'mask_only': False}
test_args = (tensor([[[[[1.4450e-01, 3.4265e-01, 5.6080e-01, 2.4315e-01, 3.8563e-02],
           [3.4444e-01, 8.5632e-01, 1.6829e-...e-01, 3.7113e-01, 1.7873e-02],
           [6.5002e-01, 5.7335e-01, 2.8305e-01, 3.8843e-02, 7.6084e-01]]]]]), (3, 3, 3))
test_kwargs = {'mask_only': False}, target = 'numpy', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:221: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:322: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:310: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:300: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXL.pyx:24: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

MC.pyx:145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

MC.pyx:127: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7fb893cc26b0>, node = <gast.gast.Module object at 0x7fb893cfca90>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7fb893cc26b0>, node = <gast.gast.Module object at 0x7fb893cfca90>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
>                       value = self.visit(value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:486: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7fb893cc26b0>, node = <gast.gast.FunctionDef object at 0x7fb893cffd60>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:273: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7fb893cc26b0>, node = <gast.gast.Return object at 0x7fb893cfc340>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7fb893cc26b0>, node = <gast.gast.Return object at 0x7fb893cfc340>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
                        value = self.visit(value)
                        if value is None:
                            continue
                        elif not isinstance(value, AST):
                            new_values.extend(value)
                            continue
                    new_values.append(value)
                old_value[:] = new_values
            elif isinstance(old_value, AST):
>               new_node = self.visit(old_value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:495: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7fb893cc26b0>, node = <gast.gast.Call object at 0x7fb893cfc4c0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7fb893cc26b0>, node = <gast.gast.Call object at 0x7fb893cfc4c0>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
                        value = self.visit(value)
                        if value is None:
                            continue
                        elif not isinstance(value, AST):
                            new_values.extend(value)
                            continue
                    new_values.append(value)
                old_value[:] = new_values
            elif isinstance(old_value, AST):
>               new_node = self.visit(old_value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:495: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7fb893cc26b0>, node = <gast.gast.Call object at 0x7fb893cfd210>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7fb893cc26b0>, node = <gast.gast.Call object at 0x7fb893cfd210>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
                        value = self.visit(value)
                        if value is None:
                            continue
                        elif not isinstance(value, AST):
                            new_values.extend(value)
                            continue
                    new_values.append(value)
                old_value[:] = new_values
            elif isinstance(old_value, AST):
>               new_node = self.visit(old_value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:495: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7fb893cc26b0>, node = <gast.gast.Name object at 0x7fb893cfce80>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:324: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:141: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:111: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:91: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   I.InvalidObjectException: Cannot transpile the object '<class 'ivy_transpiled_outputs.ivy_outputs.kornia.geometry.subpix.nms.ivy_NonMaximaSuppression3d'>' to `numpy` because it is an instance of a stateful class.

IL.pyx:247: InvalidObjectException
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.subpix.nms.nms3d
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/geometry/test_subpix.py::test_conv_soft_argmax3d[numpy-s2s-False] - I.InvalidObjectException: Cannot transpile the object '<class 'ivy_transpiled_outputs.ivy_outputs.kornia.geometry.s...
FAILED kornia/geometry/test_subpix.py::test_conv_quad_interp3d[numpy-s2s-False] - I.InvalidObjectException: Cannot transpile the object '<class 'ivy_transpiled_outputs.ivy_outputs.kornia.geometry.s...
FAILED kornia/geometry/test_subpix.py::test_nms2d[numpy-s2s-False] - I.InvalidObjectException: Cannot transpile the object '<class 'ivy_transpiled_outputs.ivy_outputs.kornia.geometry.subpix.nms.ivy...
FAILED kornia/geometry/test_subpix.py::test_nms3d[numpy-s2s-False] - I.InvalidObjectException: Cannot transpile the object '<class 'ivy_transpiled_outputs.ivy_outputs.kornia.geometry.subpix.nms.ivy...
========================================================================== 4 failed, 5 passed, 6 skipped in 623.19s (0:10:23) ==========================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 19 items

kornia/geometry/test_camera.py ...................                                                                                                                                               [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
=================================================================================== 19 passed in 1104.99s (0:18:24) ====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 1 item

kornia/test_tracking.py F                                                                                                                                                                        [100%]

=============================================================================================== FAILURES ===============================================================================================
________________________________________________________________________________ test_HomographyTracker[jax-s2s-False] _________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_HomographyTracker(target_framework, mode, backend_compile):
        print("kornia.tracking.HomographyTracker")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledHomographyTracker = ivy.transpile(kornia.tracking.HomographyTracker, source="torch", target=target_framework)
    
        tracker = kornia.tracking.HomographyTracker()
>       transpiled_tracker = TranspiledHomographyTracker()

kornia/test_tracking.py:33: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.tracking.planar_tracker.jax_HomographyTracker'>, args = (), kwargs = {}

    def __call__(cls, *args: Any, **kwargs: Any) -> Any:
>     return _graph_node_meta_call(cls, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.tracking.planar_tracker.jax_HomographyTracker'>, args = (), kwargs = {}
node = jax_HomographyTracker(
  (initial_matcher): jax_LocalFeatureMatcher(
    (local_feature): jax_GFTTAffNetHardNet(
     ...alse, 
        )
      ), patch_size=32, grayscale_descriptor='True)
    )
    (matcher): jax_DescriptorMatcher()
  )
)

    def _graph_node_meta_call(cls: tp.Type[G], *args, **kwargs) -> G:
      node = cls.__new__(cls, *args, **kwargs)
      vars(node)['_object__state'] = ObjectState()
>     cls._object_meta_construct(node, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:88: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.tracking.planar_tracker.jax_HomographyTracker'>
self = jax_HomographyTracker(
  (initial_matcher): jax_LocalFeatureMatcher(
    (local_feature): jax_GFTTAffNetHardNet(
     ...alse, 
        )
      ), patch_size=32, grayscale_descriptor='True)
    )
    (matcher): jax_DescriptorMatcher()
  )
)
args = (), kwargs = {}

    def _object_meta_construct(cls, self, *args, **kwargs):
>     self.__init__(*args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:82: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_HomographyTracker(
  (initial_matcher): jax_LocalFeatureMatcher(
    (local_feature): jax_GFTTAffNetHardNet(
     ...alse, 
        )
      ), patch_size=32, grayscale_descriptor='True)
    )
    (matcher): jax_DescriptorMatcher()
  )
)
initial_matcher = None, fast_matcher = None, ransac = None, minimum_inliers_num = 30

    def __init__(
        self,
        initial_matcher=None,
        fast_matcher=None,
        ransac=None,
        minimum_inliers_num=30,
    ):
        from ..feature.integrated import jax_LocalFeatureMatcher
        from ..feature.integrated import jax_GFTTAffNetHardNet
        from ..feature.matching import jax_DescriptorMatcher
        from ..feature.loftr.loftr import jax_LoFTR
        from ..geometry.ransac import jax_RANSAC
    
        self.super___init__(
            initial_matcher=initial_matcher,
            fast_matcher=fast_matcher,
            ransac=ransac,
            minimum_inliers_num=minimum_inliers_num,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        self.initial_matcher = initial_matcher or jax_LocalFeatureMatcher(
            jax_GFTTAffNetHardNet(3000), jax_DescriptorMatcher("smnn", 0.95)
        )
>       self.fast_matcher = fast_matcher or jax_LoFTR("outdoor")

ivy_transpiled_outputs/jax_outputs/kornia/tracking/planar_tracker.py:59: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.loftr.loftr.jax_LoFTR'>, args = ('outdoor',), kwargs = {}

    def __call__(cls, *args: Any, **kwargs: Any) -> Any:
>     return _graph_node_meta_call(cls, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.loftr.loftr.jax_LoFTR'>, args = ('outdoor',), kwargs = {}, node = jax_LoFTR()

    def _graph_node_meta_call(cls: tp.Type[G], *args, **kwargs) -> G:
      node = cls.__new__(cls, *args, **kwargs)
      vars(node)['_object__state'] = ObjectState()
>     cls._object_meta_construct(node, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:88: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.loftr.loftr.jax_LoFTR'>, self = jax_LoFTR(), args = ('outdoor',), kwargs = {}

    def _object_meta_construct(cls, self, *args, **kwargs):
>     self.__init__(*args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:82: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_LoFTR(), args = ('outdoor',), kwargs = {}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/utils/decorator_utils.py:245: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_LoFTR(), pretrained = 'outdoor'
config = {'backbone_type': 'ResNetFPN', 'coarse': {'attention': 'linear', 'd_ffn': 256, 'd_model': 256, 'layer_names': ['self',...: 'linear', 'd_ffn': 128, 'd_model': 128, 'layer_names': ['self', 'cross'], ...}, 'fine_concat_coarse_feat': True, ...}

    @jax_store_config_info
    def __init__(self, pretrained="outdoor", config=default_cfg):
        from ....ivy.functional.backends.jax.general import jax_set_item
        from .backbone.__init__ import jax_build_backbone
        from .utils.position_encoding import jax_PositionEncodingSine
        from .loftr_module.transformer import jax_LocalFeatureTransformer
        from .utils.coarse_matching import jax_CoarseMatching
        from .loftr_module.fine_preprocess import jax_FinePreprocess
        from .utils.fine_matching import jax_FineMatching
        from ....ivy.functional.frontends.torch.hub.hub import (
            jax_load_state_dict_from_url_frnt,
        )
        from ....ivy.functional.backends.jax.general import jax_get_item
        from ...utils.helpers import jax_map_location_to_cpu
    
        self.super___init__(
            pretrained=pretrained,
            config=config,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        self.config = config
        if pretrained == "indoor_new":
            self.config["coarse"] = jax_set_item(
                self.config["coarse"], "temp_bug_fix", True
            )
>       self.backbone = jax_build_backbone(config)

ivy_transpiled_outputs/jax_outputs/kornia/feature/loftr/loftr.py:110: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

config = {'backbone_type': 'ResNetFPN', 'coarse': {'attention': 'linear', 'd_ffn': 256, 'd_model': 256, 'layer_names': ['self',...: 'linear', 'd_ffn': 128, 'd_model': 128, 'layer_names': ['self', 'cross'], ...}, 'fine_concat_coarse_feat': True, ...}

    def jax_build_backbone(config):
        if config["backbone_type"] == "ResNetFPN":
            if config["resolution"] == (8, 2):
>               return kornia.feature.loftr.resnet_fpn.ResNetFPN_8_2(config["resnetfpn"])
E               NameError: name 'kornia' is not defined

ivy_transpiled_outputs/jax_outputs/kornia/feature/loftr/backbone/__init__.py:42: NameError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.tracking.HomographyTracker
----------------------------------------------------------------------------------------- Captured stderr call -----------------------------------------------------------------------------------------
Downloading: "https://github.com/ducha-aiki/affnet/raw/master/pretrained/AffNet.pth" to /root/.cache/torch/hub/checkpoints/AffNet.pth

  0%|          | 0.00/332k [00:00<?, ?B/s]
100%|██████████| 332k/332k [00:00<00:00, 12.5MB/s]
Downloading: "https://github.com/DagnyT/hardnet/raw/master/pretrained/train_liberty_with_aug/checkpoint_liberty_with_aug.pth" to /root/.cache/torch/hub/checkpoints/checkpoint_liberty_with_aug.pth

  0%|          | 0.00/5.10M [00:00<?, ?B/s]
100%|██████████| 5.10M/5.10M [00:00<00:00, 84.6MB/s]
Downloading: "http://cmp.felk.cvut.cz/~mishkdmy/models/loftr_outdoor.ckpt" to /root/.cache/torch/hub/checkpoints/loftr_outdoor.ckpt

  0%|          | 0.00/44.2M [00:00<?, ?B/s]
  0%|          | 128k/44.2M [00:00<02:38, 292kB/s]
  1%|          | 256k/44.2M [00:00<01:36, 480kB/s]
  1%|          | 512k/44.2M [00:00<00:52, 880kB/s]
  2%|▏         | 896k/44.2M [00:00<00:31, 1.42MB/s]
  4%|▍         | 1.75M/44.2M [00:01<00:15, 2.87MB/s]
  8%|▊         | 3.50M/44.2M [00:01<00:07, 5.73MB/s]
 15%|█▍        | 6.50M/44.2M [00:01<00:03, 10.4MB/s]
 21%|██        | 9.38M/44.2M [00:01<00:02, 13.3MB/s]
 28%|██▊       | 12.4M/44.2M [00:01<00:02, 15.6MB/s]
 34%|███▍      | 15.1M/44.2M [00:01<00:01, 16.7MB/s]
 41%|████      | 18.0M/44.2M [00:01<00:01, 17.3MB/s]
 48%|████▊     | 21.0M/44.2M [00:02<00:01, 18.4MB/s]
 54%|█████▍    | 24.0M/44.2M [00:02<00:01, 19.2MB/s]
 61%|██████    | 27.0M/44.2M [00:02<00:00, 19.7MB/s]
 68%|██████▊   | 29.9M/44.2M [00:02<00:00, 19.9MB/s]
 74%|███████▍  | 32.9M/44.2M [00:02<00:00, 20.1MB/s]
 81%|████████  | 35.9M/44.2M [00:02<00:00, 20.3MB/s]
 88%|████████▊ | 38.9M/44.2M [00:03<00:00, 20.5MB/s]
 94%|█████████▍| 41.8M/44.2M [00:03<00:00, 20.4MB/s]
100%|██████████| 44.2M/44.2M [00:03<00:00, 14.6MB/s]
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/test_tracking.py::test_HomographyTracker[jax-s2s-False] - NameError: name 'kornia' is not defined
==================================================================================== 1 failed in 442.48s (0:07:22) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 13 items

kornia/test_metrics.py ...F.........                                                                                                                                                             [100%]

=============================================================================================== FAILURES ===============================================================================================
__________________________________________________________________________ test_mean_average_precision[tensorflow-s2s-False] ___________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_mean_average_precision(target_framework, mode, backend_compile):
        trace_args = (
            [torch.tensor([[100, 50, 150, 100.]])],
            [torch.tensor([1.])],
            [torch.tensor([0.7])],
            [torch.tensor([[100, 50, 150, 100.]])],
            [torch.tensor([1.])],
            2,
        )
        trace_kwargs = {}
        test_args = (
            [torch.tensor([[50, 25, 75, 50], [100, 50, 150, 100.]])],
            [torch.tensor([1, 2.])],
            [torch.tensor([0.6, 0.8])],
            [torch.tensor([[50, 25, 75, 50], [100, 50, 150, 100.]])],
            [torch.tensor([1, 2.])],
            3,
        )
        kornia.metrics.mean_average_precision(*trace_args)
        kornia.metrics.mean_average_precision(*test_args)
        test_kwargs = {}
    
        # NOTE: this test fails due to the use of dynamic control flow; skipping
>       _test_function(
            kornia.metrics.mean_average_precision,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
            skip=True,
        )

kornia/test_metrics.py:118: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function mean_average_precision at 0x7fcffc0a64d0>
trace_args = ([<tf.Tensor: shape=(1, 4), dtype=float32, numpy=array([[100.,  50., 150., 100.]], dtype=float32)>], [<tf.Tensor: shap....,  50., 150., 100.]], dtype=float32)>], [<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>], 2)
trace_kwargs = {}
test_args = ([<tf.Tensor: shape=(2, 4), dtype=float32, numpy=
array([[ 50.,  25.,  75.,  50.],
       [100.,  50., 150., 100.]], d...50., 150., 100.]], dtype=float32)>], [<tf.Tensor: shape=(2,), dtype=float32, numpy=array([1., 2.], dtype=float32)>], 3)
test_kwargs = {}, target = 'tensorflow', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = True, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function mean_average_precision at 0x7fcffc0a64d0>, fn_name = 'kornia.metrics.mean_average_precision'
trace_args = ([<tf.Tensor: shape=(1, 4), dtype=float32, numpy=array([[100.,  50., 150., 100.]], dtype=float32)>], [<tf.Tensor: shap....,  50., 150., 100.]], dtype=float32)>], [<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>], 2)
trace_kwargs = {}
test_args = ([<tf.Tensor: shape=(2, 4), dtype=float32, numpy=
array([[ 50.,  25.,  75.,  50.],
       [100.,  50., 150., 100.]], d...50., 150., 100.]], dtype=float32)>], [<tf.Tensor: shape=(2,), dtype=float32, numpy=array([1., 2.], dtype=float32)>], 3)
test_kwargs = {}, target = 'tensorflow', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
>       orig_out = fn(*trace_args, **trace_kwargs)

helpers.py:335: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred_boxes = [<tf.Tensor: shape=(1, 4), dtype=float32, numpy=array([[100.,  50., 150., 100.]], dtype=float32)>]
pred_labels = [<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>], pred_scores = [<tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.7], dtype=float32)>]
gt_boxes = [<tf.Tensor: shape=(1, 4), dtype=float32, numpy=array([[100.,  50., 150., 100.]], dtype=float32)>], gt_labels = [<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>]
n_classes = 2, threshold = 0.5

    def mean_average_precision(
        pred_boxes: List[Tensor],
        pred_labels: List[Tensor],
        pred_scores: List[Tensor],
        gt_boxes: List[Tensor],
        gt_labels: List[Tensor],
        n_classes: int,
        threshold: float = 0.5,
    ) -> Tuple[Tensor, Dict[int, float]]:
        """Calculate the Mean Average Precision (mAP) of detected objects.
    
        Code altered from https://github.com/sgrvinod/a-PyTorch-Tutorial-to-Object-Detection/blob/master/utils.py#L271.
        Background class (0 index) is excluded.
    
        Args:
            pred_boxes: a tensor list of predicted bounding boxes.
            pred_labels: a tensor list of predicted labels.
            pred_scores: a tensor list of predicted labels' scores.
            gt_boxes: a tensor list of ground truth bounding boxes.
            gt_labels: a tensor list of ground truth labels.
            n_classes: the number of classes.
            threshold: count as a positive if the overlap is greater than the threshold.
    
        Returns:
            mean average precision (mAP), list of average precisions for each class.
    
        Examples:
            >>> boxes, labels, scores = torch.tensor([[100, 50, 150, 100.]]), torch.tensor([1]), torch.tensor([.7])
            >>> gt_boxes, gt_labels = torch.tensor([[100, 50, 150, 100.]]), torch.tensor([1])
            >>> mean_average_precision([boxes], [labels], [scores], [gt_boxes], [gt_labels], 2)
            (tensor(1.), {1: 1.0})
        """
        # these are all lists of tensors of the same length, i.e. number of images
        if not len(pred_boxes) == len(pred_labels) == len(pred_scores) == len(gt_boxes) == len(gt_labels):
            raise AssertionError
    
        # Store all (true) objects in a single continuous tensor while keeping track of the image it is from
        gt_images = []
        for i, labels in enumerate(gt_labels):
>           gt_images.extend([i] * labels.size(0))
E           TypeError: 'numpy.int64' object is not callable

/opt/miniconda/envs/multienv/lib/python3.10/site-packages/kornia/metrics/mean_average_precision.py:49: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.metrics.mean_average_precision.mean_average_precision
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/test_metrics.py::test_mean_average_precision[tensorflow-s2s-False] - TypeError: 'numpy.int64' object is not callable
=============================================================================== 1 failed, 12 passed in 948.70s (0:15:48) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 5 items

kornia/geometry/test_calibration.py ....F                                                                                                                                                        [100%]

=============================================================================================== FAILURES ===============================================================================================
_______________________________________________________________________________ test_solve_pnp_dlt[tensorflow-s2s-False] _______________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_solve_pnp_dlt(target_framework, mode, backend_compile):
        trace_args = (
            torch.tensor([[
                [5.0, -5.0, 0.0], [0.0, 0.0, 1.5],
                [2.5, 3.0, 6.0], [9.0, -2.0, 3.0],
                [-4.0, 5.0, 2.0], [-5.0, 5.0, 1.0]
            ]], dtype=torch.float64),
            torch.tensor([[
                [1409.1504, -800.936], [407.0207, -182.1229],
                [392.7021, 177.9428], [1016.838, -2.9416],
                [-63.1116, 142.9204], [-219.3874, 99.666]
            ]], dtype=torch.float64),
            torch.tensor([[
                [500.0, 0.0, 250.0],
                [0.0, 500.0, 250.0],
                [0.0, 0.0, 1.0]
            ]], dtype=torch.float64),
        )
        trace_kwargs = {'svd_eps': 1e-3}
        test_args = (
            torch.tensor([[
                [10.0, -10.0, 0.0], [0.0, 0.0, 3.0],
                [5.0, 6.0, 12.0], [18.0, -4.0, 6.0],
                [-8.0, 10.0, 4.0], [-10.0, 10.0, 2.0]
            ]], dtype=torch.float64),
            torch.tensor([[
                [2818.3008, -1601.872], [814.0414, -364.2458],
                [785.4042, 355.8856], [2033.676, -5.8832],
                [-126.2232, 285.8408], [-438.7748, 199.332]
            ]], dtype=torch.float64),
            torch.tensor([[
                [1000.0, 0.0, 500.0],
                [0.0, 1000.0, 500.0],
                [0.0, 0.0, 1.0]
            ]], dtype=torch.float64),
        )
        test_kwargs = {'svd_eps': 1e-3}
>       _test_function(
            kornia.geometry.calibration.solve_pnp_dlt,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/geometry/test_calibration.py:148: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function solve_pnp_dlt at 0x7f881fff4af0>
trace_args = (tensor([[[ 5.0000, -5.0000,  0.0000],
         [ 0.0000,  0.0000,  1.5000],
         [ 2.5000,  3.0000,  6.0000],
   ...loat64), tensor([[[500.,   0., 250.],
         [  0., 500., 250.],
         [  0.,   0.,   1.]]], dtype=torch.float64))
trace_kwargs = {'svd_eps': 0.001}
test_args = (tensor([[[ 10., -10.,   0.],
         [  0.,   0.,   3.],
         [  5.,   6.,  12.],
         [ 18.,  -4.,   6.],
 ...tensor([[[1000.,    0.,  500.],
         [   0., 1000.,  500.],
         [   0.,    0.,    1.]]], dtype=torch.float64))
test_kwargs = {'svd_eps': 0.001}, target = 'tensorflow', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function solve_pnp_dlt at 0x7f881fff4af0>, fn_name = 'kornia.geometry.calibration.solve_pnp_dlt'
trace_args = (tensor([[[ 5.0000, -5.0000,  0.0000],
         [ 0.0000,  0.0000,  1.5000],
         [ 2.5000,  3.0000,  6.0000],
   ...loat64), tensor([[[500.,   0., 250.],
         [  0., 500., 250.],
         [  0.,   0.,   1.]]], dtype=torch.float64))
trace_kwargs = {'svd_eps': 0.001}
test_args = (tensor([[[ 10., -10.,   0.],
         [  0.,   0.,   3.],
         [  5.,   6.,  12.],
         [ 18.,  -4.,   6.],
 ...tensor([[[1000.,    0.,  500.],
         [   0., 1000.,  500.],
         [   0.,    0.,    1.]]], dtype=torch.float64))
test_kwargs = {'svd_eps': 0.001}, target = 'tensorflow', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
>           graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:326: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:232: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

world_points = <tf.Tensor: shape=(1, 6, 3), dtype=float64, numpy=
array([[[ 5. , -5. ,  0. ],
        [ 0. ,  0. ,  1.5],
        [ 2.5,  3. ,  6. ],
        [ 9. , -2. ,  3. ],
        [-4. ,  5. ,  2. ],
        [-5. ,  5. ,  1. ]]])>
img_points = <tf.Tensor: shape=(1, 6, 2), dtype=float64, numpy=
array([[[1409.1504, -800.936 ],
        [ 407.0207, -182.1229],
   ...92.7021,  177.9428],
        [1016.838 ,   -2.9416],
        [ -63.1116,  142.9204],
        [-219.3874,   99.666 ]]])>
intrinsics = <tf.Tensor: shape=(1, 3, 3), dtype=float64, numpy=
array([[[500.,   0., 250.],
        [  0., 500., 250.],
        [  0.,   0.,   1.]]])>, weights = None, svd_eps = 0.001

    def tensorflow_solve_pnp_dlt(
        world_points, img_points, intrinsics, weights=None, svd_eps=0.0001
    ):
        from ....ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ...utils.helpers import tensorflow__torch_linalg_svdvals
        from ....ivy.functional.frontends.torch.reduction_ops import tensorflow_any_frnt
        from ....ivy.functional.frontends.torch.blas_and_lapack_ops import (
            tensorflow_inverse_frnt,
        )
        from ..conversions import tensorflow_convert_points_to_homogeneous
        from ..linalg import tensorflow_transform_points
        from ....ivy.functional.backends.tensorflow.general import tensorflow_set_item
        from ....ivy.functional.frontends.torch.blas_and_lapack_ops import (
            tensorflow_svd_frnt_base_count_1_frnt,
        )
        from ....ivy.functional.frontends.torch.tensor import tensorflow_reshape_frnt_
        from ...utils.misc import tensorflow_eye_like
        from ....ivy.functional.frontends.torch.blas_and_lapack_ops import (
            tensorflow_bmm_frnt,
        )
        from ....ivy.functional.frontends.torch.blas_and_lapack_ops import (
            tensorflow_det_frnt,
        )
        from ....ivy.functional.frontends.torch.reduction_ops import tensorflow_norm_frnt
        from ....ivy.functional.frontends.torch.linalg import tensorflow_qr_frnt
        from ....ivy.functional.frontends.torch.pointwise_ops import tensorflow_sign_frnt
        from ....ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            tensorflow_cat_frnt,
        )
        from ...core._backend import zeros
        from ...core._backend import ones_like
        from ...core._backend import where
    
        if not isinstance(world_points, (tensorflow.Tensor, tensorflow.keras.Variable)):
            raise AssertionError(
                f"world_points is not an instance of torch.Tensor. Type of world_points is {type(world_points)}"
            )
        if not isinstance(img_points, (tensorflow.Tensor, tensorflow.keras.Variable)):
            raise AssertionError(
                f"img_points is not an instance of torch.Tensor. Type of img_points is {type(img_points)}"
            )
        if not isinstance(intrinsics, (tensorflow.Tensor, tensorflow.keras.Variable)):
            raise AssertionError(
                f"intrinsics is not an instance of torch.Tensor. Type of intrinsics is {type(intrinsics)}"
            )
        if weights is not None and not isinstance(
            weights, (tensorflow.Tensor, tensorflow.keras.Variable)
        ):
            raise AssertionError(
                f"If weights is not None, then weights should be an instance of torch.Tensor. Type of weights is {type(weights)}"
            )
        if not isinstance(svd_eps, (float,)):
            raise AssertionError(f"Type of svd_eps is not float. Got {type(svd_eps)}")
        accepted_dtypes = tf.float32, tf.float64
        if world_points.dtype not in accepted_dtypes:
            raise AssertionError(
                f"world_points must have one of the following dtypes {accepted_dtypes}. Currently it has {world_points.dtype}."
            )
        if img_points.dtype not in accepted_dtypes:
            raise AssertionError(
                f"img_points must have one of the following dtypes {accepted_dtypes}. Currently it has {img_points.dtype}."
            )
        if intrinsics.dtype not in accepted_dtypes:
            raise AssertionError(
                f"intrinsics must have one of the following dtypes {accepted_dtypes}. Currently it has {intrinsics.dtype}."
            )
        if (
            len(tensorflow_shape_frnt_(world_points)) != 3
            or tensorflow_shape_frnt_(world_points)[2] != 3
        ):
            raise AssertionError(
                f"world_points must be of shape (B, N, 3). Got shape {tensorflow_shape_frnt_(world_points)}."
            )
        if (
            len(tensorflow_shape_frnt_(img_points)) != 3
            or tensorflow_shape_frnt_(img_points)[2] != 2
        ):
            raise AssertionError(
                f"img_points must be of shape (B, N, 2). Got shape {tensorflow_shape_frnt_(img_points)}."
            )
        if len(tensorflow_shape_frnt_(intrinsics)) != 3 or tensorflow_shape_frnt_(
            intrinsics
        )[1:] != (3, 3):
            raise AssertionError(
                f"intrinsics must be of shape (B, 3, 3). Got shape {tensorflow_shape_frnt_(intrinsics)}."
            )
        if tensorflow_shape_frnt_(world_points)[1] != tensorflow_shape_frnt_(img_points)[1]:
            raise AssertionError(
                "world_points and img_points must have equal number of points."
            )
        if (
            tensorflow_shape_frnt_(world_points)[0] != tensorflow_shape_frnt_(img_points)[0]
            or tensorflow_shape_frnt_(world_points)[0]
            != tensorflow_shape_frnt_(intrinsics)[0]
        ):
            raise AssertionError(
                "world_points, img_points and intrinsics must have the same batch size."
            )
        if tensorflow_shape_frnt_(world_points)[1] < 6:
            raise AssertionError(
                f"At least 6 points are required to use this function. Got {tensorflow_shape_frnt_(world_points)[1]} points."
            )
        B, N = (
            tensorflow_shape_frnt_(world_points)[:2][0],
            tensorflow_shape_frnt_(world_points)[:2][1],
        )
        world_points_norm, world_transform_norm = (
            tensorflow__mean_isotropic_scale_normalize(world_points)
        )
        s = tensorflow__torch_linalg_svdvals(world_points_norm)
        if tensorflow_any_frnt(s[:, -1] < svd_eps):
            raise AssertionError(
                f"The last singular value of one/more of the elements of the batch is smaller than {svd_eps}. This function cannot be used if all world_points (of any element of the batch) lie on a line or if all world_points (of any element of the batch) lie on a plane."
            )
        intrinsics_inv = tensorflow_inverse_frnt(intrinsics)
        world_points_norm_h = tensorflow_convert_points_to_homogeneous(world_points_norm)
        img_points_inv = tensorflow_transform_points(intrinsics_inv, img_points)
        img_points_norm, img_transform_norm = tensorflow__mean_isotropic_scale_normalize(
            img_points_inv
        )
        inv_img_transform_norm = tensorflow_inverse_frnt(img_transform_norm)
        system = zeros((B, 2 * N, 12), dtype=world_points.dtype, device=world_points.device)
        system = tensorflow_set_item(
            system,
            (slice(None, None, None), slice(0, None, 2), slice(0, 4, None)),
            world_points_norm_h,
        )
        system = tensorflow_set_item(
            system,
            (slice(None, None, None), slice(1, None, 2), slice(4, 8, None)),
            world_points_norm_h,
        )
        system = tensorflow_set_item(
            system,
            (slice(None, None, None), slice(0, None, 2), slice(8, 12, None)),
            world_points_norm_h * -1 * img_points_norm[..., 0:1],
        )
        system = tensorflow_set_item(
            system,
            (slice(None, None, None), slice(1, None, 2), slice(8, 12, None)),
            world_points_norm_h * -1 * img_points_norm[..., 1:2],
        )
        _, _, v = tensorflow_svd_frnt_base_count_1_frnt(system)
        solution = v[..., -1]
        solution = tensorflow_reshape_frnt_(solution, B, 3, 4)
        solution_4x4 = tensorflow_eye_like(4, solution)
        solution_4x4 = tensorflow_set_item(
            solution_4x4,
            (slice(None, None, None), slice(None, 3, None), slice(None, None, None)),
            solution,
        )
        intermediate = tensorflow_bmm_frnt(solution_4x4, world_transform_norm)
        solution = tensorflow_bmm_frnt(inv_img_transform_norm, intermediate[:, :3, :])
        det = tensorflow_det_frnt(solution[:, :3, :3])
        ones = ones_like(det)
        sign_fix = where(det < 0, ones * -1, ones)
        solution = solution * sign_fix[:, None, None]
>       norm_col = tensorflow_norm_frnt(input=solution[:, :3, 0], p=2, dim=1)

ivy_transpiled_outputs/tensorflow_outputs/kornia/geometry/calibration/pnp.py:239: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (), kwargs = {'dim': 1, 'input': <tf.Tensor: shape=(1, 3), dtype=float64, numpy=array([[-0.02017229,  0.02388222,  0.0574928 ]])>, 'p': 2}
tensorflow_is_array_bknd = <function tensorflow_is_array_bknd at 0x7f87b421a440>

    @functools.wraps(fn)
    def wrapper(*args, **kwargs):
        from ..functional.ivy.general import tensorflow_is_array_bknd
    
>       array_like = args[0]
E       IndexError: tuple index out of range

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:195: IndexError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.calibration.pnp.solve_pnp_dlt
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/geometry/test_calibration.py::test_solve_pnp_dlt[tensorflow-s2s-False] - IndexError: tuple index out of range
=============================================================================== 1 failed, 4 passed in 363.77s (0:06:03) ================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 38 items

kornia/geometry/test_conversions.py ......................................                                                                                                                       [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
=================================================================================== 38 passed in 1905.09s (0:31:45) ====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 15 items

kornia/test_contrib.py ....FF..F...F..                                                                                                                                                           [100%]

=============================================================================================== FAILURES ===============================================================================================
______________________________________________________________________________ test_diamond_square[tensorflow-s2s-False] _______________________________________________________________________________

self = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
rhs = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def impl(self, rhs):
        try:
>           return original_method(self, rhs)

ivy_transpiled_outputs/tensorflow_outputs/__init__.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (<tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>, tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]]))
kwargs = {}, arg = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def rep_method(*args, **kwargs):
        for arg in args:
            if ivy.is_ivy_array(arg):
                return NotImplemented
>       return func(*args, **kwargs)

../ivy/ivy/functional/backends/tensorflow/__init__.py:40: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (<tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>, tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]]))
kwargs = {}

    def error_handler(*args, **kwargs):
      try:
        if not is_traceback_filtering_enabled():
          return fn(*args, **kwargs)
      except NameError:
        # In some very rare cases,
        # `is_traceback_filtering_enabled` (from the outer scope) may not be
        # accessible from inside this function
        return fn(*args, **kwargs)
    
      filtered_tb = None
      try:
        return fn(*args, **kwargs)
      except Exception as e:
        filtered_tb = _process_traceback_frames(e.__traceback__)
>       raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/tensorflow/python/util/traceback_utils.py:153: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

arrays_and_dtypes = [<class 'numpy.float32'>, tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])]

    def _result_type(*arrays_and_dtypes):
      """Returns the resulting type given a set of arrays."""
    
      def preprocess_float(x):
        if is_prefer_float32():
          if isinstance(x, float):
            return np.float32(x)
          elif isinstance(x, complex):
            return np.complex64(x)
        return x
    
      arrays_and_dtypes = [preprocess_float(x) for x in arrays_and_dtypes]
>     dtype = np.result_type(*arrays_and_dtypes)
E     TypeError: Cannot interpret 'tensor([[[[0.3333, 1.0000, 0.3333],
E               [1.0000, 0.3333, 1.0000],
E               [0.3333, 1.0000, 0.3333]]]])' as a data type

/opt/fw/tensorflow/tensorflow/python/ops/numpy_ops/np_dtypes.py:190: TypeError

During handling of the above exception, another exception occurred:

self = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
rhs = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def impl(self, rhs):
        try:
>           return original_method(self, rhs)

ivy_transpiled_outputs/tensorflow_outputs/__init__.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
rhs = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def impl(self, rhs):
        try:
            return original_method(self, rhs)
        except Exception:
>           return patched_method(self, rhs)

ivy_transpiled_outputs/tensorflow_outputs/__init__.py:65: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
other = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

>   ???

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/tensor.py:124: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
other = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_mul_frnt(input, other, *, out=None):
        from .__init__ import tensorflow_promote_types_of_torch_inputs_frnt
        from ...backends.tensorflow.elementwise import tensorflow_multiply
    
>       input, other = tensorflow_promote_types_of_torch_inputs_frnt(input, other)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/pointwise_ops.py:74: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x1 = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
x2 = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_promote_types_of_torch_inputs_frnt(x1, x2, /):
        from ...ivy.general import tensorflow_isscalar_bknd
        from ...ivy.data_type import tensorflow_is_int_dtype_bknd
        from ...backends.tensorflow.creation import tensorflow_asarray
        from ...ivy.data_type import tensorflow_default_dtype_bknd
        from .tensor import tensorflow_shape_frnt_
        from ...ivy.device import tensorflow_default_device_bknd
        from ....data_classes.array.data_type import tensorflow_astype_bknd_
    
        """Promote the dtype of the given native array inputs to a common dtype
        based on type promotion rules.
    
        While passing float or integer values or any other non-array input
        to this function, it should be noted that the return will be an
        array-like object. Therefore, outputs from this function should be
        used as inputs only for those functions that expect an array-like or
        tensor-like objects, otherwise it might give unexpected results.
        """
        if (
            tensorflow_isscalar_bknd(x1) or isinstance(x1, (list, tuple))
        ) and tensorflow_is_int_dtype_bknd(x1):
            x1 = tensorflow_asarray(x1, dtype="int64")
        elif tensorflow_isscalar_bknd(x1) or isinstance(x1, (list, tuple)):
            x1 = tensorflow_asarray(x1)
        if (
            tensorflow_isscalar_bknd(x2) or isinstance(x2, (list, tuple))
        ) and tensorflow_is_int_dtype_bknd(x2):
            x2 = tensorflow_asarray(x2, dtype="int64")
        elif tensorflow_isscalar_bknd(x2) or isinstance(x2, (list, tuple)):
            x2 = tensorflow_asarray(x2)
        type1 = tensorflow_default_dtype_bknd(item=x1).strip("u123456789")
>       type2 = tensorflow_default_dtype_bknd(item=x2).strip("u123456789")

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/__init__.py:220: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def tensorflow_default_dtype_bknd(
        *,
        dtype: Optional[Union[str, str]] = None,
        item: Optional[Union[tensorflow.Tensor, tf.Tensor]] = None,
        as_native: bool = False,
    ):
        from ..backends.tensorflow.data_type import tensorflow_as_ivy_dtype
        from ..backends.tensorflow.data_type import tensorflow_as_native_dtype
        from .general import tensorflow_exists_bknd
        from .general import tensorflow_default_bknd
    
        if tensorflow_exists_bknd(dtype):
            if as_native is True:
                return tensorflow_as_native_dtype(dtype)
            return tensorflow_as_ivy_dtype(dtype)
        as_native = tensorflow_default_bknd(as_native, False)
        if tensorflow_exists_bknd(item):
            if hasattr(item, "override_dtype_check"):
                return item.override_dtype_check()
            elif isinstance(item, (list, tuple, dict)) and len(item) == 0:
                pass
>           elif tensorflow_is_complex_dtype_bknd(item):

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:185: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_is_complex_dtype_bknd(
        dtype_in: Union[str, str, tensorflow.Tensor, tf.Tensor, Number], /
    ):
        from ..backends.tensorflow.data_type import tensorflow_dtype
        from .general import tensorflow_is_array_bknd
        from .nest import tensorflow_nested_argwhere_bknd
    
        if tensorflow_is_array_bknd(dtype_in):
            dtype_in = tensorflow_dtype(dtype_in)
        elif isinstance(dtype_in, tuple):
            dtype_in = tensorflow_default_int_dtype_bknd()
        elif isinstance(dtype_in, np.ndarray):
            return "complex" in dtype_in.dtype.name
        elif isinstance(dtype_in, Number):
            return isinstance(dtype_in, (complex, np.complexfloating))
        elif isinstance(dtype_in, (list, tuple, dict)):
            return tensorflow_nested_argwhere_bknd(
                dtype_in,
                lambda x: isinstance(x, (complex, np.complexfloating))
                or tensorflow_is_array_bknd(x)
                and "complex" in tensorflow_dtype(x),
            )
>       return "complex" in tensorflow_as_ivy_dtype_bknd(dtype_in)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:562: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_as_ivy_dtype_bknd(dtype_in: Union[str, str], /):
        from ..backends.tensorflow.data_type import tensorflow_as_ivy_dtype
    
>       return tensorflow_as_ivy_dtype(dtype_in)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:49: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_as_ivy_dtype(
        dtype_in: Union[tensorflow.DType, str, int, float, complex, bool, np.dtype], /
    ):
        from ...ivy.data_type import tensorflow_default_int_dtype_bknd
        from ...ivy.data_type import tensorflow_default_float_dtype_bknd
        from ...ivy.data_type import tensorflow_default_complex_dtype_bknd
    
        if dtype_in is int:
            return tensorflow_default_int_dtype_bknd()
        if dtype_in is float:
            return tensorflow_default_float_dtype_bknd()
        if dtype_in is complex:
            return tensorflow_default_complex_dtype_bknd()
        if dtype_in is bool:
            return str("bool")
        if isinstance(dtype_in, np.dtype):
            dtype_in = dtype_in.name
        if isinstance(dtype_in, str):
            if dtype_in in native_dtype_dict:
                dtype_str = dtype_in
            else:
                raise Exception(
                    f"Cannot convert to ivy dtype. {dtype_in} is not supported by TensorFlow backend."
                )
        else:
>           dtype_str = ivy_dtype_dict[dtype_in]
E           KeyError: tensor([[[[0.3333, 1.0000, 0.3333],
E                     [1.0000, 0.3333, 1.0000],
E                     [0.3333, 1.0000, 0.3333]]]])

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/backends/tensorflow/data_type.py:184: KeyError

During handling of the above exception, another exception occurred:

self = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
rhs = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def impl(self, rhs):
        try:
>           return original_method(self, rhs)

ivy_transpiled_outputs/tensorflow_outputs/__init__.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
rhs = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def impl(self, rhs):
        try:
            return original_method(self, rhs)
        except Exception:
>           return patched_method(self, rhs)

ivy_transpiled_outputs/tensorflow_outputs/__init__.py:65: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
other = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

>   ???

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/tensor.py:124: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
other = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_mul_frnt(input, other, *, out=None):
        from .__init__ import tensorflow_promote_types_of_torch_inputs_frnt
        from ...backends.tensorflow.elementwise import tensorflow_multiply
    
>       input, other = tensorflow_promote_types_of_torch_inputs_frnt(input, other)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/pointwise_ops.py:74: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x1 = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
x2 = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_promote_types_of_torch_inputs_frnt(x1, x2, /):
        from ...ivy.general import tensorflow_isscalar_bknd
        from ...ivy.data_type import tensorflow_is_int_dtype_bknd
        from ...backends.tensorflow.creation import tensorflow_asarray
        from ...ivy.data_type import tensorflow_default_dtype_bknd
        from .tensor import tensorflow_shape_frnt_
        from ...ivy.device import tensorflow_default_device_bknd
        from ....data_classes.array.data_type import tensorflow_astype_bknd_
    
        """Promote the dtype of the given native array inputs to a common dtype
        based on type promotion rules.
    
        While passing float or integer values or any other non-array input
        to this function, it should be noted that the return will be an
        array-like object. Therefore, outputs from this function should be
        used as inputs only for those functions that expect an array-like or
        tensor-like objects, otherwise it might give unexpected results.
        """
        if (
            tensorflow_isscalar_bknd(x1) or isinstance(x1, (list, tuple))
        ) and tensorflow_is_int_dtype_bknd(x1):
            x1 = tensorflow_asarray(x1, dtype="int64")
        elif tensorflow_isscalar_bknd(x1) or isinstance(x1, (list, tuple)):
            x1 = tensorflow_asarray(x1)
        if (
            tensorflow_isscalar_bknd(x2) or isinstance(x2, (list, tuple))
        ) and tensorflow_is_int_dtype_bknd(x2):
            x2 = tensorflow_asarray(x2, dtype="int64")
        elif tensorflow_isscalar_bknd(x2) or isinstance(x2, (list, tuple)):
            x2 = tensorflow_asarray(x2)
        type1 = tensorflow_default_dtype_bknd(item=x1).strip("u123456789")
>       type2 = tensorflow_default_dtype_bknd(item=x2).strip("u123456789")

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/__init__.py:220: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def tensorflow_default_dtype_bknd(
        *,
        dtype: Optional[Union[str, str]] = None,
        item: Optional[Union[tensorflow.Tensor, tf.Tensor]] = None,
        as_native: bool = False,
    ):
        from ..backends.tensorflow.data_type import tensorflow_as_ivy_dtype
        from ..backends.tensorflow.data_type import tensorflow_as_native_dtype
        from .general import tensorflow_exists_bknd
        from .general import tensorflow_default_bknd
    
        if tensorflow_exists_bknd(dtype):
            if as_native is True:
                return tensorflow_as_native_dtype(dtype)
            return tensorflow_as_ivy_dtype(dtype)
        as_native = tensorflow_default_bknd(as_native, False)
        if tensorflow_exists_bknd(item):
            if hasattr(item, "override_dtype_check"):
                return item.override_dtype_check()
            elif isinstance(item, (list, tuple, dict)) and len(item) == 0:
                pass
>           elif tensorflow_is_complex_dtype_bknd(item):

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:185: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_is_complex_dtype_bknd(
        dtype_in: Union[str, str, tensorflow.Tensor, tf.Tensor, Number], /
    ):
        from ..backends.tensorflow.data_type import tensorflow_dtype
        from .general import tensorflow_is_array_bknd
        from .nest import tensorflow_nested_argwhere_bknd
    
        if tensorflow_is_array_bknd(dtype_in):
            dtype_in = tensorflow_dtype(dtype_in)
        elif isinstance(dtype_in, tuple):
            dtype_in = tensorflow_default_int_dtype_bknd()
        elif isinstance(dtype_in, np.ndarray):
            return "complex" in dtype_in.dtype.name
        elif isinstance(dtype_in, Number):
            return isinstance(dtype_in, (complex, np.complexfloating))
        elif isinstance(dtype_in, (list, tuple, dict)):
            return tensorflow_nested_argwhere_bknd(
                dtype_in,
                lambda x: isinstance(x, (complex, np.complexfloating))
                or tensorflow_is_array_bknd(x)
                and "complex" in tensorflow_dtype(x),
            )
>       return "complex" in tensorflow_as_ivy_dtype_bknd(dtype_in)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:562: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_as_ivy_dtype_bknd(dtype_in: Union[str, str], /):
        from ..backends.tensorflow.data_type import tensorflow_as_ivy_dtype
    
>       return tensorflow_as_ivy_dtype(dtype_in)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:49: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_as_ivy_dtype(
        dtype_in: Union[tensorflow.DType, str, int, float, complex, bool, np.dtype], /
    ):
        from ...ivy.data_type import tensorflow_default_int_dtype_bknd
        from ...ivy.data_type import tensorflow_default_float_dtype_bknd
        from ...ivy.data_type import tensorflow_default_complex_dtype_bknd
    
        if dtype_in is int:
            return tensorflow_default_int_dtype_bknd()
        if dtype_in is float:
            return tensorflow_default_float_dtype_bknd()
        if dtype_in is complex:
            return tensorflow_default_complex_dtype_bknd()
        if dtype_in is bool:
            return str("bool")
        if isinstance(dtype_in, np.dtype):
            dtype_in = dtype_in.name
        if isinstance(dtype_in, str):
            if dtype_in in native_dtype_dict:
                dtype_str = dtype_in
            else:
                raise Exception(
                    f"Cannot convert to ivy dtype. {dtype_in} is not supported by TensorFlow backend."
                )
        else:
>           dtype_str = ivy_dtype_dict[dtype_in]
E           KeyError: tensor([[[[0.3333, 1.0000, 0.3333],
E                     [1.0000, 0.3333, 1.0000],
E                     [0.3333, 1.0000, 0.3333]]]])

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/backends/tensorflow/data_type.py:184: KeyError

During handling of the above exception, another exception occurred:

self = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
rhs = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def impl(self, rhs):
        try:
>           return original_method(self, rhs)

ivy_transpiled_outputs/tensorflow_outputs/__init__.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
rhs = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def impl(self, rhs):
        try:
            return original_method(self, rhs)
        except Exception:
>           return patched_method(self, rhs)

ivy_transpiled_outputs/tensorflow_outputs/__init__.py:65: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
other = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

>   ???

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/tensor.py:124: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
other = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_mul_frnt(input, other, *, out=None):
        from .__init__ import tensorflow_promote_types_of_torch_inputs_frnt
        from ...backends.tensorflow.elementwise import tensorflow_multiply
    
>       input, other = tensorflow_promote_types_of_torch_inputs_frnt(input, other)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/pointwise_ops.py:74: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x1 = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
x2 = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_promote_types_of_torch_inputs_frnt(x1, x2, /):
        from ...ivy.general import tensorflow_isscalar_bknd
        from ...ivy.data_type import tensorflow_is_int_dtype_bknd
        from ...backends.tensorflow.creation import tensorflow_asarray
        from ...ivy.data_type import tensorflow_default_dtype_bknd
        from .tensor import tensorflow_shape_frnt_
        from ...ivy.device import tensorflow_default_device_bknd
        from ....data_classes.array.data_type import tensorflow_astype_bknd_
    
        """Promote the dtype of the given native array inputs to a common dtype
        based on type promotion rules.
    
        While passing float or integer values or any other non-array input
        to this function, it should be noted that the return will be an
        array-like object. Therefore, outputs from this function should be
        used as inputs only for those functions that expect an array-like or
        tensor-like objects, otherwise it might give unexpected results.
        """
        if (
            tensorflow_isscalar_bknd(x1) or isinstance(x1, (list, tuple))
        ) and tensorflow_is_int_dtype_bknd(x1):
            x1 = tensorflow_asarray(x1, dtype="int64")
        elif tensorflow_isscalar_bknd(x1) or isinstance(x1, (list, tuple)):
            x1 = tensorflow_asarray(x1)
        if (
            tensorflow_isscalar_bknd(x2) or isinstance(x2, (list, tuple))
        ) and tensorflow_is_int_dtype_bknd(x2):
            x2 = tensorflow_asarray(x2, dtype="int64")
        elif tensorflow_isscalar_bknd(x2) or isinstance(x2, (list, tuple)):
            x2 = tensorflow_asarray(x2)
        type1 = tensorflow_default_dtype_bknd(item=x1).strip("u123456789")
>       type2 = tensorflow_default_dtype_bknd(item=x2).strip("u123456789")

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/__init__.py:220: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def tensorflow_default_dtype_bknd(
        *,
        dtype: Optional[Union[str, str]] = None,
        item: Optional[Union[tensorflow.Tensor, tf.Tensor]] = None,
        as_native: bool = False,
    ):
        from ..backends.tensorflow.data_type import tensorflow_as_ivy_dtype
        from ..backends.tensorflow.data_type import tensorflow_as_native_dtype
        from .general import tensorflow_exists_bknd
        from .general import tensorflow_default_bknd
    
        if tensorflow_exists_bknd(dtype):
            if as_native is True:
                return tensorflow_as_native_dtype(dtype)
            return tensorflow_as_ivy_dtype(dtype)
        as_native = tensorflow_default_bknd(as_native, False)
        if tensorflow_exists_bknd(item):
            if hasattr(item, "override_dtype_check"):
                return item.override_dtype_check()
            elif isinstance(item, (list, tuple, dict)) and len(item) == 0:
                pass
>           elif tensorflow_is_complex_dtype_bknd(item):

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:185: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_is_complex_dtype_bknd(
        dtype_in: Union[str, str, tensorflow.Tensor, tf.Tensor, Number], /
    ):
        from ..backends.tensorflow.data_type import tensorflow_dtype
        from .general import tensorflow_is_array_bknd
        from .nest import tensorflow_nested_argwhere_bknd
    
        if tensorflow_is_array_bknd(dtype_in):
            dtype_in = tensorflow_dtype(dtype_in)
        elif isinstance(dtype_in, tuple):
            dtype_in = tensorflow_default_int_dtype_bknd()
        elif isinstance(dtype_in, np.ndarray):
            return "complex" in dtype_in.dtype.name
        elif isinstance(dtype_in, Number):
            return isinstance(dtype_in, (complex, np.complexfloating))
        elif isinstance(dtype_in, (list, tuple, dict)):
            return tensorflow_nested_argwhere_bknd(
                dtype_in,
                lambda x: isinstance(x, (complex, np.complexfloating))
                or tensorflow_is_array_bknd(x)
                and "complex" in tensorflow_dtype(x),
            )
>       return "complex" in tensorflow_as_ivy_dtype_bknd(dtype_in)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:562: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_as_ivy_dtype_bknd(dtype_in: Union[str, str], /):
        from ..backends.tensorflow.data_type import tensorflow_as_ivy_dtype
    
>       return tensorflow_as_ivy_dtype(dtype_in)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:49: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_as_ivy_dtype(
        dtype_in: Union[tensorflow.DType, str, int, float, complex, bool, np.dtype], /
    ):
        from ...ivy.data_type import tensorflow_default_int_dtype_bknd
        from ...ivy.data_type import tensorflow_default_float_dtype_bknd
        from ...ivy.data_type import tensorflow_default_complex_dtype_bknd
    
        if dtype_in is int:
            return tensorflow_default_int_dtype_bknd()
        if dtype_in is float:
            return tensorflow_default_float_dtype_bknd()
        if dtype_in is complex:
            return tensorflow_default_complex_dtype_bknd()
        if dtype_in is bool:
            return str("bool")
        if isinstance(dtype_in, np.dtype):
            dtype_in = dtype_in.name
        if isinstance(dtype_in, str):
            if dtype_in in native_dtype_dict:
                dtype_str = dtype_in
            else:
                raise Exception(
                    f"Cannot convert to ivy dtype. {dtype_in} is not supported by TensorFlow backend."
                )
        else:
>           dtype_str = ivy_dtype_dict[dtype_in]
E           KeyError: tensor([[[[0.3333, 1.0000, 0.3333],
E                     [1.0000, 0.3333, 1.0000],
E                     [0.3333, 1.0000, 0.3333]]]])

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/backends/tensorflow/data_type.py:184: KeyError

During handling of the above exception, another exception occurred:

self = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
rhs = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def impl(self, rhs):
        try:
>           return original_method(self, rhs)

ivy_transpiled_outputs/tensorflow_outputs/__init__.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
rhs = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def impl(self, rhs):
        try:
            return original_method(self, rhs)
        except Exception:
>           return patched_method(self, rhs)

ivy_transpiled_outputs/tensorflow_outputs/__init__.py:65: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
other = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

>   ???

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/tensor.py:124: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
other = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_mul_frnt(input, other, *, out=None):
        from .__init__ import tensorflow_promote_types_of_torch_inputs_frnt
        from ...backends.tensorflow.elementwise import tensorflow_multiply
    
>       input, other = tensorflow_promote_types_of_torch_inputs_frnt(input, other)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/pointwise_ops.py:74: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x1 = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
x2 = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_promote_types_of_torch_inputs_frnt(x1, x2, /):
        from ...ivy.general import tensorflow_isscalar_bknd
        from ...ivy.data_type import tensorflow_is_int_dtype_bknd
        from ...backends.tensorflow.creation import tensorflow_asarray
        from ...ivy.data_type import tensorflow_default_dtype_bknd
        from .tensor import tensorflow_shape_frnt_
        from ...ivy.device import tensorflow_default_device_bknd
        from ....data_classes.array.data_type import tensorflow_astype_bknd_
    
        """Promote the dtype of the given native array inputs to a common dtype
        based on type promotion rules.
    
        While passing float or integer values or any other non-array input
        to this function, it should be noted that the return will be an
        array-like object. Therefore, outputs from this function should be
        used as inputs only for those functions that expect an array-like or
        tensor-like objects, otherwise it might give unexpected results.
        """
        if (
            tensorflow_isscalar_bknd(x1) or isinstance(x1, (list, tuple))
        ) and tensorflow_is_int_dtype_bknd(x1):
            x1 = tensorflow_asarray(x1, dtype="int64")
        elif tensorflow_isscalar_bknd(x1) or isinstance(x1, (list, tuple)):
            x1 = tensorflow_asarray(x1)
        if (
            tensorflow_isscalar_bknd(x2) or isinstance(x2, (list, tuple))
        ) and tensorflow_is_int_dtype_bknd(x2):
            x2 = tensorflow_asarray(x2, dtype="int64")
        elif tensorflow_isscalar_bknd(x2) or isinstance(x2, (list, tuple)):
            x2 = tensorflow_asarray(x2)
        type1 = tensorflow_default_dtype_bknd(item=x1).strip("u123456789")
>       type2 = tensorflow_default_dtype_bknd(item=x2).strip("u123456789")

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/__init__.py:220: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def tensorflow_default_dtype_bknd(
        *,
        dtype: Optional[Union[str, str]] = None,
        item: Optional[Union[tensorflow.Tensor, tf.Tensor]] = None,
        as_native: bool = False,
    ):
        from ..backends.tensorflow.data_type import tensorflow_as_ivy_dtype
        from ..backends.tensorflow.data_type import tensorflow_as_native_dtype
        from .general import tensorflow_exists_bknd
        from .general import tensorflow_default_bknd
    
        if tensorflow_exists_bknd(dtype):
            if as_native is True:
                return tensorflow_as_native_dtype(dtype)
            return tensorflow_as_ivy_dtype(dtype)
        as_native = tensorflow_default_bknd(as_native, False)
        if tensorflow_exists_bknd(item):
            if hasattr(item, "override_dtype_check"):
                return item.override_dtype_check()
            elif isinstance(item, (list, tuple, dict)) and len(item) == 0:
                pass
>           elif tensorflow_is_complex_dtype_bknd(item):

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:185: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_is_complex_dtype_bknd(
        dtype_in: Union[str, str, tensorflow.Tensor, tf.Tensor, Number], /
    ):
        from ..backends.tensorflow.data_type import tensorflow_dtype
        from .general import tensorflow_is_array_bknd
        from .nest import tensorflow_nested_argwhere_bknd
    
        if tensorflow_is_array_bknd(dtype_in):
            dtype_in = tensorflow_dtype(dtype_in)
        elif isinstance(dtype_in, tuple):
            dtype_in = tensorflow_default_int_dtype_bknd()
        elif isinstance(dtype_in, np.ndarray):
            return "complex" in dtype_in.dtype.name
        elif isinstance(dtype_in, Number):
            return isinstance(dtype_in, (complex, np.complexfloating))
        elif isinstance(dtype_in, (list, tuple, dict)):
            return tensorflow_nested_argwhere_bknd(
                dtype_in,
                lambda x: isinstance(x, (complex, np.complexfloating))
                or tensorflow_is_array_bknd(x)
                and "complex" in tensorflow_dtype(x),
            )
>       return "complex" in tensorflow_as_ivy_dtype_bknd(dtype_in)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:562: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_as_ivy_dtype_bknd(dtype_in: Union[str, str], /):
        from ..backends.tensorflow.data_type import tensorflow_as_ivy_dtype
    
>       return tensorflow_as_ivy_dtype(dtype_in)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:49: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_as_ivy_dtype(
        dtype_in: Union[tensorflow.DType, str, int, float, complex, bool, np.dtype], /
    ):
        from ...ivy.data_type import tensorflow_default_int_dtype_bknd
        from ...ivy.data_type import tensorflow_default_float_dtype_bknd
        from ...ivy.data_type import tensorflow_default_complex_dtype_bknd
    
        if dtype_in is int:
            return tensorflow_default_int_dtype_bknd()
        if dtype_in is float:
            return tensorflow_default_float_dtype_bknd()
        if dtype_in is complex:
            return tensorflow_default_complex_dtype_bknd()
        if dtype_in is bool:
            return str("bool")
        if isinstance(dtype_in, np.dtype):
            dtype_in = dtype_in.name
        if isinstance(dtype_in, str):
            if dtype_in in native_dtype_dict:
                dtype_str = dtype_in
            else:
                raise Exception(
                    f"Cannot convert to ivy dtype. {dtype_in} is not supported by TensorFlow backend."
                )
        else:
>           dtype_str = ivy_dtype_dict[dtype_in]
E           KeyError: tensor([[[[0.3333, 1.0000, 0.3333],
E                     [1.0000, 0.3333, 1.0000],
E                     [0.3333, 1.0000, 0.3333]]]])

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/backends/tensorflow/data_type.py:184: KeyError

During handling of the above exception, another exception occurred:

self = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
rhs = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def impl(self, rhs):
        try:
>           return original_method(self, rhs)

ivy_transpiled_outputs/tensorflow_outputs/__init__.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
rhs = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def impl(self, rhs):
        try:
            return original_method(self, rhs)
        except Exception:
>           return patched_method(self, rhs)

ivy_transpiled_outputs/tensorflow_outputs/__init__.py:65: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
other = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

>   ???

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/tensor.py:124: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
other = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_mul_frnt(input, other, *, out=None):
        from .__init__ import tensorflow_promote_types_of_torch_inputs_frnt
        from ...backends.tensorflow.elementwise import tensorflow_multiply
    
>       input, other = tensorflow_promote_types_of_torch_inputs_frnt(input, other)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/pointwise_ops.py:74: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x1 = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
x2 = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_promote_types_of_torch_inputs_frnt(x1, x2, /):
        from ...ivy.general import tensorflow_isscalar_bknd
        from ...ivy.data_type import tensorflow_is_int_dtype_bknd
        from ...backends.tensorflow.creation import tensorflow_asarray
        from ...ivy.data_type import tensorflow_default_dtype_bknd
        from .tensor import tensorflow_shape_frnt_
        from ...ivy.device import tensorflow_default_device_bknd
        from ....data_classes.array.data_type import tensorflow_astype_bknd_
    
        """Promote the dtype of the given native array inputs to a common dtype
        based on type promotion rules.
    
        While passing float or integer values or any other non-array input
        to this function, it should be noted that the return will be an
        array-like object. Therefore, outputs from this function should be
        used as inputs only for those functions that expect an array-like or
        tensor-like objects, otherwise it might give unexpected results.
        """
        if (
            tensorflow_isscalar_bknd(x1) or isinstance(x1, (list, tuple))
        ) and tensorflow_is_int_dtype_bknd(x1):
            x1 = tensorflow_asarray(x1, dtype="int64")
        elif tensorflow_isscalar_bknd(x1) or isinstance(x1, (list, tuple)):
            x1 = tensorflow_asarray(x1)
        if (
            tensorflow_isscalar_bknd(x2) or isinstance(x2, (list, tuple))
        ) and tensorflow_is_int_dtype_bknd(x2):
            x2 = tensorflow_asarray(x2, dtype="int64")
        elif tensorflow_isscalar_bknd(x2) or isinstance(x2, (list, tuple)):
            x2 = tensorflow_asarray(x2)
        type1 = tensorflow_default_dtype_bknd(item=x1).strip("u123456789")
>       type2 = tensorflow_default_dtype_bknd(item=x2).strip("u123456789")

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/__init__.py:220: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def tensorflow_default_dtype_bknd(
        *,
        dtype: Optional[Union[str, str]] = None,
        item: Optional[Union[tensorflow.Tensor, tf.Tensor]] = None,
        as_native: bool = False,
    ):
        from ..backends.tensorflow.data_type import tensorflow_as_ivy_dtype
        from ..backends.tensorflow.data_type import tensorflow_as_native_dtype
        from .general import tensorflow_exists_bknd
        from .general import tensorflow_default_bknd
    
        if tensorflow_exists_bknd(dtype):
            if as_native is True:
                return tensorflow_as_native_dtype(dtype)
            return tensorflow_as_ivy_dtype(dtype)
        as_native = tensorflow_default_bknd(as_native, False)
        if tensorflow_exists_bknd(item):
            if hasattr(item, "override_dtype_check"):
                return item.override_dtype_check()
            elif isinstance(item, (list, tuple, dict)) and len(item) == 0:
                pass
>           elif tensorflow_is_complex_dtype_bknd(item):

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:185: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_is_complex_dtype_bknd(
        dtype_in: Union[str, str, tensorflow.Tensor, tf.Tensor, Number], /
    ):
        from ..backends.tensorflow.data_type import tensorflow_dtype
        from .general import tensorflow_is_array_bknd
        from .nest import tensorflow_nested_argwhere_bknd
    
        if tensorflow_is_array_bknd(dtype_in):
            dtype_in = tensorflow_dtype(dtype_in)
        elif isinstance(dtype_in, tuple):
            dtype_in = tensorflow_default_int_dtype_bknd()
        elif isinstance(dtype_in, np.ndarray):
            return "complex" in dtype_in.dtype.name
        elif isinstance(dtype_in, Number):
            return isinstance(dtype_in, (complex, np.complexfloating))
        elif isinstance(dtype_in, (list, tuple, dict)):
            return tensorflow_nested_argwhere_bknd(
                dtype_in,
                lambda x: isinstance(x, (complex, np.complexfloating))
                or tensorflow_is_array_bknd(x)
                and "complex" in tensorflow_dtype(x),
            )
>       return "complex" in tensorflow_as_ivy_dtype_bknd(dtype_in)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:562: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_as_ivy_dtype_bknd(dtype_in: Union[str, str], /):
        from ..backends.tensorflow.data_type import tensorflow_as_ivy_dtype
    
>       return tensorflow_as_ivy_dtype(dtype_in)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:49: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_as_ivy_dtype(
        dtype_in: Union[tensorflow.DType, str, int, float, complex, bool, np.dtype], /
    ):
        from ...ivy.data_type import tensorflow_default_int_dtype_bknd
        from ...ivy.data_type import tensorflow_default_float_dtype_bknd
        from ...ivy.data_type import tensorflow_default_complex_dtype_bknd
    
        if dtype_in is int:
            return tensorflow_default_int_dtype_bknd()
        if dtype_in is float:
            return tensorflow_default_float_dtype_bknd()
        if dtype_in is complex:
            return tensorflow_default_complex_dtype_bknd()
        if dtype_in is bool:
            return str("bool")
        if isinstance(dtype_in, np.dtype):
            dtype_in = dtype_in.name
        if isinstance(dtype_in, str):
            if dtype_in in native_dtype_dict:
                dtype_str = dtype_in
            else:
                raise Exception(
                    f"Cannot convert to ivy dtype. {dtype_in} is not supported by TensorFlow backend."
                )
        else:
>           dtype_str = ivy_dtype_dict[dtype_in]
E           KeyError: tensor([[[[0.3333, 1.0000, 0.3333],
E                     [1.0000, 0.3333, 1.0000],
E                     [0.3333, 1.0000, 0.3333]]]])

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/backends/tensorflow/data_type.py:184: KeyError

During handling of the above exception, another exception occurred:

self = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
rhs = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def impl(self, rhs):
        try:
>           return original_method(self, rhs)

ivy_transpiled_outputs/tensorflow_outputs/__init__.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
rhs = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def impl(self, rhs):
        try:
            return original_method(self, rhs)
        except Exception:
>           return patched_method(self, rhs)

ivy_transpiled_outputs/tensorflow_outputs/__init__.py:65: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
other = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

>   ???

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/tensor.py:124: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
other = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_mul_frnt(input, other, *, out=None):
        from .__init__ import tensorflow_promote_types_of_torch_inputs_frnt
        from ...backends.tensorflow.elementwise import tensorflow_multiply
    
>       input, other = tensorflow_promote_types_of_torch_inputs_frnt(input, other)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/pointwise_ops.py:74: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x1 = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
x2 = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_promote_types_of_torch_inputs_frnt(x1, x2, /):
        from ...ivy.general import tensorflow_isscalar_bknd
        from ...ivy.data_type import tensorflow_is_int_dtype_bknd
        from ...backends.tensorflow.creation import tensorflow_asarray
        from ...ivy.data_type import tensorflow_default_dtype_bknd
        from .tensor import tensorflow_shape_frnt_
        from ...ivy.device import tensorflow_default_device_bknd
        from ....data_classes.array.data_type import tensorflow_astype_bknd_
    
        """Promote the dtype of the given native array inputs to a common dtype
        based on type promotion rules.
    
        While passing float or integer values or any other non-array input
        to this function, it should be noted that the return will be an
        array-like object. Therefore, outputs from this function should be
        used as inputs only for those functions that expect an array-like or
        tensor-like objects, otherwise it might give unexpected results.
        """
        if (
            tensorflow_isscalar_bknd(x1) or isinstance(x1, (list, tuple))
        ) and tensorflow_is_int_dtype_bknd(x1):
            x1 = tensorflow_asarray(x1, dtype="int64")
        elif tensorflow_isscalar_bknd(x1) or isinstance(x1, (list, tuple)):
            x1 = tensorflow_asarray(x1)
        if (
            tensorflow_isscalar_bknd(x2) or isinstance(x2, (list, tuple))
        ) and tensorflow_is_int_dtype_bknd(x2):
            x2 = tensorflow_asarray(x2, dtype="int64")
        elif tensorflow_isscalar_bknd(x2) or isinstance(x2, (list, tuple)):
            x2 = tensorflow_asarray(x2)
        type1 = tensorflow_default_dtype_bknd(item=x1).strip("u123456789")
>       type2 = tensorflow_default_dtype_bknd(item=x2).strip("u123456789")

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/__init__.py:220: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def tensorflow_default_dtype_bknd(
        *,
        dtype: Optional[Union[str, str]] = None,
        item: Optional[Union[tensorflow.Tensor, tf.Tensor]] = None,
        as_native: bool = False,
    ):
        from ..backends.tensorflow.data_type import tensorflow_as_ivy_dtype
        from ..backends.tensorflow.data_type import tensorflow_as_native_dtype
        from .general import tensorflow_exists_bknd
        from .general import tensorflow_default_bknd
    
        if tensorflow_exists_bknd(dtype):
            if as_native is True:
                return tensorflow_as_native_dtype(dtype)
            return tensorflow_as_ivy_dtype(dtype)
        as_native = tensorflow_default_bknd(as_native, False)
        if tensorflow_exists_bknd(item):
            if hasattr(item, "override_dtype_check"):
                return item.override_dtype_check()
            elif isinstance(item, (list, tuple, dict)) and len(item) == 0:
                pass
>           elif tensorflow_is_complex_dtype_bknd(item):

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:185: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_is_complex_dtype_bknd(
        dtype_in: Union[str, str, tensorflow.Tensor, tf.Tensor, Number], /
    ):
        from ..backends.tensorflow.data_type import tensorflow_dtype
        from .general import tensorflow_is_array_bknd
        from .nest import tensorflow_nested_argwhere_bknd
    
        if tensorflow_is_array_bknd(dtype_in):
            dtype_in = tensorflow_dtype(dtype_in)
        elif isinstance(dtype_in, tuple):
            dtype_in = tensorflow_default_int_dtype_bknd()
        elif isinstance(dtype_in, np.ndarray):
            return "complex" in dtype_in.dtype.name
        elif isinstance(dtype_in, Number):
            return isinstance(dtype_in, (complex, np.complexfloating))
        elif isinstance(dtype_in, (list, tuple, dict)):
            return tensorflow_nested_argwhere_bknd(
                dtype_in,
                lambda x: isinstance(x, (complex, np.complexfloating))
                or tensorflow_is_array_bknd(x)
                and "complex" in tensorflow_dtype(x),
            )
>       return "complex" in tensorflow_as_ivy_dtype_bknd(dtype_in)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:562: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_as_ivy_dtype_bknd(dtype_in: Union[str, str], /):
        from ..backends.tensorflow.data_type import tensorflow_as_ivy_dtype
    
>       return tensorflow_as_ivy_dtype(dtype_in)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:49: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_as_ivy_dtype(
        dtype_in: Union[tensorflow.DType, str, int, float, complex, bool, np.dtype], /
    ):
        from ...ivy.data_type import tensorflow_default_int_dtype_bknd
        from ...ivy.data_type import tensorflow_default_float_dtype_bknd
        from ...ivy.data_type import tensorflow_default_complex_dtype_bknd
    
        if dtype_in is int:
            return tensorflow_default_int_dtype_bknd()
        if dtype_in is float:
            return tensorflow_default_float_dtype_bknd()
        if dtype_in is complex:
            return tensorflow_default_complex_dtype_bknd()
        if dtype_in is bool:
            return str("bool")
        if isinstance(dtype_in, np.dtype):
            dtype_in = dtype_in.name
        if isinstance(dtype_in, str):
            if dtype_in in native_dtype_dict:
                dtype_str = dtype_in
            else:
                raise Exception(
                    f"Cannot convert to ivy dtype. {dtype_in} is not supported by TensorFlow backend."
                )
        else:
>           dtype_str = ivy_dtype_dict[dtype_in]
E           KeyError: tensor([[[[0.3333, 1.0000, 0.3333],
E                     [1.0000, 0.3333, 1.0000],
E                     [0.3333, 1.0000, 0.3333]]]])

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/backends/tensorflow/data_type.py:184: KeyError

During handling of the above exception, another exception occurred:

self = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
rhs = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def impl(self, rhs):
        try:
>           return original_method(self, rhs)

ivy_transpiled_outputs/tensorflow_outputs/__init__.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
rhs = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def impl(self, rhs):
        try:
            return original_method(self, rhs)
        except Exception:
>           return patched_method(self, rhs)

ivy_transpiled_outputs/tensorflow_outputs/__init__.py:65: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
other = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow___mul___frnt_(tensor, other):
        from .pointwise_ops import tensorflow_mul_frnt
    
>       return tensorflow_mul_frnt(tensor, other)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/tensor.py:125: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
other = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_mul_frnt(input, other, *, out=None):
        from .__init__ import tensorflow_promote_types_of_torch_inputs_frnt
        from ...backends.tensorflow.elementwise import tensorflow_multiply
    
>       input, other = tensorflow_promote_types_of_torch_inputs_frnt(input, other)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/pointwise_ops.py:74: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x1 = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
x2 = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_promote_types_of_torch_inputs_frnt(x1, x2, /):
        from ...ivy.general import tensorflow_isscalar_bknd
        from ...ivy.data_type import tensorflow_is_int_dtype_bknd
        from ...backends.tensorflow.creation import tensorflow_asarray
        from ...ivy.data_type import tensorflow_default_dtype_bknd
        from .tensor import tensorflow_shape_frnt_
        from ...ivy.device import tensorflow_default_device_bknd
        from ....data_classes.array.data_type import tensorflow_astype_bknd_
    
        """Promote the dtype of the given native array inputs to a common dtype
        based on type promotion rules.
    
        While passing float or integer values or any other non-array input
        to this function, it should be noted that the return will be an
        array-like object. Therefore, outputs from this function should be
        used as inputs only for those functions that expect an array-like or
        tensor-like objects, otherwise it might give unexpected results.
        """
        if (
            tensorflow_isscalar_bknd(x1) or isinstance(x1, (list, tuple))
        ) and tensorflow_is_int_dtype_bknd(x1):
            x1 = tensorflow_asarray(x1, dtype="int64")
        elif tensorflow_isscalar_bknd(x1) or isinstance(x1, (list, tuple)):
            x1 = tensorflow_asarray(x1)
        if (
            tensorflow_isscalar_bknd(x2) or isinstance(x2, (list, tuple))
        ) and tensorflow_is_int_dtype_bknd(x2):
            x2 = tensorflow_asarray(x2, dtype="int64")
        elif tensorflow_isscalar_bknd(x2) or isinstance(x2, (list, tuple)):
            x2 = tensorflow_asarray(x2)
        type1 = tensorflow_default_dtype_bknd(item=x1).strip("u123456789")
>       type2 = tensorflow_default_dtype_bknd(item=x2).strip("u123456789")

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/__init__.py:220: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def tensorflow_default_dtype_bknd(
        *,
        dtype: Optional[Union[str, str]] = None,
        item: Optional[Union[tensorflow.Tensor, tf.Tensor]] = None,
        as_native: bool = False,
    ):
        from ..backends.tensorflow.data_type import tensorflow_as_ivy_dtype
        from ..backends.tensorflow.data_type import tensorflow_as_native_dtype
        from .general import tensorflow_exists_bknd
        from .general import tensorflow_default_bknd
    
        if tensorflow_exists_bknd(dtype):
            if as_native is True:
                return tensorflow_as_native_dtype(dtype)
            return tensorflow_as_ivy_dtype(dtype)
        as_native = tensorflow_default_bknd(as_native, False)
        if tensorflow_exists_bknd(item):
            if hasattr(item, "override_dtype_check"):
                return item.override_dtype_check()
            elif isinstance(item, (list, tuple, dict)) and len(item) == 0:
                pass
>           elif tensorflow_is_complex_dtype_bknd(item):

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:185: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_is_complex_dtype_bknd(
        dtype_in: Union[str, str, tensorflow.Tensor, tf.Tensor, Number], /
    ):
        from ..backends.tensorflow.data_type import tensorflow_dtype
        from .general import tensorflow_is_array_bknd
        from .nest import tensorflow_nested_argwhere_bknd
    
        if tensorflow_is_array_bknd(dtype_in):
            dtype_in = tensorflow_dtype(dtype_in)
        elif isinstance(dtype_in, tuple):
            dtype_in = tensorflow_default_int_dtype_bknd()
        elif isinstance(dtype_in, np.ndarray):
            return "complex" in dtype_in.dtype.name
        elif isinstance(dtype_in, Number):
            return isinstance(dtype_in, (complex, np.complexfloating))
        elif isinstance(dtype_in, (list, tuple, dict)):
            return tensorflow_nested_argwhere_bknd(
                dtype_in,
                lambda x: isinstance(x, (complex, np.complexfloating))
                or tensorflow_is_array_bknd(x)
                and "complex" in tensorflow_dtype(x),
            )
>       return "complex" in tensorflow_as_ivy_dtype_bknd(dtype_in)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:562: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_as_ivy_dtype_bknd(dtype_in: Union[str, str], /):
        from ..backends.tensorflow.data_type import tensorflow_as_ivy_dtype
    
>       return tensorflow_as_ivy_dtype(dtype_in)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:49: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_as_ivy_dtype(
        dtype_in: Union[tensorflow.DType, str, int, float, complex, bool, np.dtype], /
    ):
        from ...ivy.data_type import tensorflow_default_int_dtype_bknd
        from ...ivy.data_type import tensorflow_default_float_dtype_bknd
        from ...ivy.data_type import tensorflow_default_complex_dtype_bknd
    
        if dtype_in is int:
            return tensorflow_default_int_dtype_bknd()
        if dtype_in is float:
            return tensorflow_default_float_dtype_bknd()
        if dtype_in is complex:
            return tensorflow_default_complex_dtype_bknd()
        if dtype_in is bool:
            return str("bool")
        if isinstance(dtype_in, np.dtype):
            dtype_in = dtype_in.name
        if isinstance(dtype_in, str):
            if dtype_in in native_dtype_dict:
                dtype_str = dtype_in
            else:
                raise Exception(
                    f"Cannot convert to ivy dtype. {dtype_in} is not supported by TensorFlow backend."
                )
        else:
>           dtype_str = ivy_dtype_dict[dtype_in]
E           KeyError: tensor([[[[0.3333, 1.0000, 0.3333],
E                     [1.0000, 0.3333, 1.0000],
E                     [0.3333, 1.0000, 0.3333]]]])

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/backends/tensorflow/data_type.py:184: KeyError

During handling of the above exception, another exception occurred:

self = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
rhs = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def impl(self, rhs):
        try:
>           return original_method(self, rhs)

ivy_transpiled_outputs/tensorflow_outputs/__init__.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
rhs = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def impl(self, rhs):
        try:
            return original_method(self, rhs)
        except Exception:
>           return patched_method(self, rhs)

ivy_transpiled_outputs/tensorflow_outputs/__init__.py:65: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
other = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow___mul___frnt_(tensor, other):
        from .pointwise_ops import tensorflow_mul_frnt
    
>       return tensorflow_mul_frnt(tensor, other)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/tensor.py:125: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
other = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_mul_frnt(input, other, *, out=None):
        from .__init__ import tensorflow_promote_types_of_torch_inputs_frnt
        from ...backends.tensorflow.elementwise import tensorflow_multiply
    
>       input, other = tensorflow_promote_types_of_torch_inputs_frnt(input, other)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/pointwise_ops.py:74: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x1 = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
x2 = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_promote_types_of_torch_inputs_frnt(x1, x2, /):
        from ...ivy.general import tensorflow_isscalar_bknd
        from ...ivy.data_type import tensorflow_is_int_dtype_bknd
        from ...backends.tensorflow.creation import tensorflow_asarray
        from ...ivy.data_type import tensorflow_default_dtype_bknd
        from .tensor import tensorflow_shape_frnt_
        from ...ivy.device import tensorflow_default_device_bknd
        from ....data_classes.array.data_type import tensorflow_astype_bknd_
    
        """Promote the dtype of the given native array inputs to a common dtype
        based on type promotion rules.
    
        While passing float or integer values or any other non-array input
        to this function, it should be noted that the return will be an
        array-like object. Therefore, outputs from this function should be
        used as inputs only for those functions that expect an array-like or
        tensor-like objects, otherwise it might give unexpected results.
        """
        if (
            tensorflow_isscalar_bknd(x1) or isinstance(x1, (list, tuple))
        ) and tensorflow_is_int_dtype_bknd(x1):
            x1 = tensorflow_asarray(x1, dtype="int64")
        elif tensorflow_isscalar_bknd(x1) or isinstance(x1, (list, tuple)):
            x1 = tensorflow_asarray(x1)
        if (
            tensorflow_isscalar_bknd(x2) or isinstance(x2, (list, tuple))
        ) and tensorflow_is_int_dtype_bknd(x2):
            x2 = tensorflow_asarray(x2, dtype="int64")
        elif tensorflow_isscalar_bknd(x2) or isinstance(x2, (list, tuple)):
            x2 = tensorflow_asarray(x2)
        type1 = tensorflow_default_dtype_bknd(item=x1).strip("u123456789")
>       type2 = tensorflow_default_dtype_bknd(item=x2).strip("u123456789")

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/__init__.py:220: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def tensorflow_default_dtype_bknd(
        *,
        dtype: Optional[Union[str, str]] = None,
        item: Optional[Union[tensorflow.Tensor, tf.Tensor]] = None,
        as_native: bool = False,
    ):
        from ..backends.tensorflow.data_type import tensorflow_as_ivy_dtype
        from ..backends.tensorflow.data_type import tensorflow_as_native_dtype
        from .general import tensorflow_exists_bknd
        from .general import tensorflow_default_bknd
    
        if tensorflow_exists_bknd(dtype):
            if as_native is True:
                return tensorflow_as_native_dtype(dtype)
            return tensorflow_as_ivy_dtype(dtype)
        as_native = tensorflow_default_bknd(as_native, False)
        if tensorflow_exists_bknd(item):
            if hasattr(item, "override_dtype_check"):
                return item.override_dtype_check()
            elif isinstance(item, (list, tuple, dict)) and len(item) == 0:
                pass
>           elif tensorflow_is_complex_dtype_bknd(item):

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:185: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_is_complex_dtype_bknd(
        dtype_in: Union[str, str, tensorflow.Tensor, tf.Tensor, Number], /
    ):
        from ..backends.tensorflow.data_type import tensorflow_dtype
        from .general import tensorflow_is_array_bknd
        from .nest import tensorflow_nested_argwhere_bknd
    
        if tensorflow_is_array_bknd(dtype_in):
            dtype_in = tensorflow_dtype(dtype_in)
        elif isinstance(dtype_in, tuple):
            dtype_in = tensorflow_default_int_dtype_bknd()
        elif isinstance(dtype_in, np.ndarray):
            return "complex" in dtype_in.dtype.name
        elif isinstance(dtype_in, Number):
            return isinstance(dtype_in, (complex, np.complexfloating))
        elif isinstance(dtype_in, (list, tuple, dict)):
            return tensorflow_nested_argwhere_bknd(
                dtype_in,
                lambda x: isinstance(x, (complex, np.complexfloating))
                or tensorflow_is_array_bknd(x)
                and "complex" in tensorflow_dtype(x),
            )
>       return "complex" in tensorflow_as_ivy_dtype_bknd(dtype_in)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:562: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_as_ivy_dtype_bknd(dtype_in: Union[str, str], /):
        from ..backends.tensorflow.data_type import tensorflow_as_ivy_dtype
    
>       return tensorflow_as_ivy_dtype(dtype_in)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:49: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_as_ivy_dtype(
        dtype_in: Union[tensorflow.DType, str, int, float, complex, bool, np.dtype], /
    ):
        from ...ivy.data_type import tensorflow_default_int_dtype_bknd
        from ...ivy.data_type import tensorflow_default_float_dtype_bknd
        from ...ivy.data_type import tensorflow_default_complex_dtype_bknd
    
        if dtype_in is int:
            return tensorflow_default_int_dtype_bknd()
        if dtype_in is float:
            return tensorflow_default_float_dtype_bknd()
        if dtype_in is complex:
            return tensorflow_default_complex_dtype_bknd()
        if dtype_in is bool:
            return str("bool")
        if isinstance(dtype_in, np.dtype):
            dtype_in = dtype_in.name
        if isinstance(dtype_in, str):
            if dtype_in in native_dtype_dict:
                dtype_str = dtype_in
            else:
                raise Exception(
                    f"Cannot convert to ivy dtype. {dtype_in} is not supported by TensorFlow backend."
                )
        else:
>           dtype_str = ivy_dtype_dict[dtype_in]
E           KeyError: tensor([[[[0.3333, 1.0000, 0.3333],
E                     [1.0000, 0.3333, 1.0000],
E                     [0.3333, 1.0000, 0.3333]]]])

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/backends/tensorflow/data_type.py:184: KeyError

During handling of the above exception, another exception occurred:

self = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
rhs = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def impl(self, rhs):
        try:
>           return original_method(self, rhs)

ivy_transpiled_outputs/tensorflow_outputs/__init__.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
rhs = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def impl(self, rhs):
        try:
            return original_method(self, rhs)
        except Exception:
>           return patched_method(self, rhs)

ivy_transpiled_outputs/tensorflow_outputs/__init__.py:65: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
other = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow___mul___frnt_(tensor, other):
        from .pointwise_ops import tensorflow_mul_frnt
    
>       return tensorflow_mul_frnt(tensor, other)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/tensor.py:125: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
other = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_mul_frnt(input, other, *, out=None):
        from .__init__ import tensorflow_promote_types_of_torch_inputs_frnt
        from ...backends.tensorflow.elementwise import tensorflow_multiply
    
>       input, other = tensorflow_promote_types_of_torch_inputs_frnt(input, other)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/pointwise_ops.py:74: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x1 = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
x2 = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_promote_types_of_torch_inputs_frnt(x1, x2, /):
        from ...ivy.general import tensorflow_isscalar_bknd
        from ...ivy.data_type import tensorflow_is_int_dtype_bknd
        from ...backends.tensorflow.creation import tensorflow_asarray
        from ...ivy.data_type import tensorflow_default_dtype_bknd
        from .tensor import tensorflow_shape_frnt_
        from ...ivy.device import tensorflow_default_device_bknd
        from ....data_classes.array.data_type import tensorflow_astype_bknd_
    
        """Promote the dtype of the given native array inputs to a common dtype
        based on type promotion rules.
    
        While passing float or integer values or any other non-array input
        to this function, it should be noted that the return will be an
        array-like object. Therefore, outputs from this function should be
        used as inputs only for those functions that expect an array-like or
        tensor-like objects, otherwise it might give unexpected results.
        """
        if (
            tensorflow_isscalar_bknd(x1) or isinstance(x1, (list, tuple))
        ) and tensorflow_is_int_dtype_bknd(x1):
            x1 = tensorflow_asarray(x1, dtype="int64")
        elif tensorflow_isscalar_bknd(x1) or isinstance(x1, (list, tuple)):
            x1 = tensorflow_asarray(x1)
        if (
            tensorflow_isscalar_bknd(x2) or isinstance(x2, (list, tuple))
        ) and tensorflow_is_int_dtype_bknd(x2):
            x2 = tensorflow_asarray(x2, dtype="int64")
        elif tensorflow_isscalar_bknd(x2) or isinstance(x2, (list, tuple)):
            x2 = tensorflow_asarray(x2)
        type1 = tensorflow_default_dtype_bknd(item=x1).strip("u123456789")
>       type2 = tensorflow_default_dtype_bknd(item=x2).strip("u123456789")

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/__init__.py:220: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def tensorflow_default_dtype_bknd(
        *,
        dtype: Optional[Union[str, str]] = None,
        item: Optional[Union[tensorflow.Tensor, tf.Tensor]] = None,
        as_native: bool = False,
    ):
        from ..backends.tensorflow.data_type import tensorflow_as_ivy_dtype
        from ..backends.tensorflow.data_type import tensorflow_as_native_dtype
        from .general import tensorflow_exists_bknd
        from .general import tensorflow_default_bknd
    
        if tensorflow_exists_bknd(dtype):
            if as_native is True:
                return tensorflow_as_native_dtype(dtype)
            return tensorflow_as_ivy_dtype(dtype)
        as_native = tensorflow_default_bknd(as_native, False)
        if tensorflow_exists_bknd(item):
            if hasattr(item, "override_dtype_check"):
                return item.override_dtype_check()
            elif isinstance(item, (list, tuple, dict)) and len(item) == 0:
                pass
>           elif tensorflow_is_complex_dtype_bknd(item):

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:185: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_is_complex_dtype_bknd(
        dtype_in: Union[str, str, tensorflow.Tensor, tf.Tensor, Number], /
    ):
        from ..backends.tensorflow.data_type import tensorflow_dtype
        from .general import tensorflow_is_array_bknd
        from .nest import tensorflow_nested_argwhere_bknd
    
        if tensorflow_is_array_bknd(dtype_in):
            dtype_in = tensorflow_dtype(dtype_in)
        elif isinstance(dtype_in, tuple):
            dtype_in = tensorflow_default_int_dtype_bknd()
        elif isinstance(dtype_in, np.ndarray):
            return "complex" in dtype_in.dtype.name
        elif isinstance(dtype_in, Number):
            return isinstance(dtype_in, (complex, np.complexfloating))
        elif isinstance(dtype_in, (list, tuple, dict)):
            return tensorflow_nested_argwhere_bknd(
                dtype_in,
                lambda x: isinstance(x, (complex, np.complexfloating))
                or tensorflow_is_array_bknd(x)
                and "complex" in tensorflow_dtype(x),
            )
>       return "complex" in tensorflow_as_ivy_dtype_bknd(dtype_in)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:562: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_as_ivy_dtype_bknd(dtype_in: Union[str, str], /):
        from ..backends.tensorflow.data_type import tensorflow_as_ivy_dtype
    
>       return tensorflow_as_ivy_dtype(dtype_in)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:49: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_as_ivy_dtype(
        dtype_in: Union[tensorflow.DType, str, int, float, complex, bool, np.dtype], /
    ):
        from ...ivy.data_type import tensorflow_default_int_dtype_bknd
        from ...ivy.data_type import tensorflow_default_float_dtype_bknd
        from ...ivy.data_type import tensorflow_default_complex_dtype_bknd
    
        if dtype_in is int:
            return tensorflow_default_int_dtype_bknd()
        if dtype_in is float:
            return tensorflow_default_float_dtype_bknd()
        if dtype_in is complex:
            return tensorflow_default_complex_dtype_bknd()
        if dtype_in is bool:
            return str("bool")
        if isinstance(dtype_in, np.dtype):
            dtype_in = dtype_in.name
        if isinstance(dtype_in, str):
            if dtype_in in native_dtype_dict:
                dtype_str = dtype_in
            else:
                raise Exception(
                    f"Cannot convert to ivy dtype. {dtype_in} is not supported by TensorFlow backend."
                )
        else:
>           dtype_str = ivy_dtype_dict[dtype_in]
E           KeyError: tensor([[[[0.3333, 1.0000, 0.3333],
E                     [1.0000, 0.3333, 1.0000],
E                     [0.3333, 1.0000, 0.3333]]]])

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/backends/tensorflow/data_type.py:184: KeyError

During handling of the above exception, another exception occurred:

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_diamond_square(target_framework, mode, backend_compile):
        trace_args = ((1, 1, 8, 8),)
        trace_kwargs = {
            "roughness": 0.5,
            "random_scale": 1.0,
            "normalize_range": (0.0, 1.0),
            "random_fn": torch.ones,
        }
        test_args = ((5, 1, 8, 8),)
        test_kwargs = {
            "roughness": 0.7,
            "random_scale": 0.9,
            "normalize_range": (-1.0, 1.0),
            "random_fn": torch.ones,
        }
>       _test_function(
            kornia.contrib.diamond_square,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/test_contrib.py:141: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function diamond_square at 0x7fe56af612d0>, trace_args = ((1, 1, 8, 8),)
trace_kwargs = {'normalize_range': (0.0, 1.0), 'random_fn': <built-in method ones of type object at 0x7fe5832f88c0>, 'random_scale': 1.0, 'roughness': 0.5}, test_args = ((5, 1, 8, 8),)
test_kwargs = {'normalize_range': (-1.0, 1.0), 'random_fn': <built-in method ones of type object at 0x7fe5832f88c0>, 'random_scale': 0.9, 'roughness': 0.7}, target = 'tensorflow'
backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function diamond_square at 0x7fe56af612d0>, fn_name = 'kornia.contrib.diamond_square', trace_args = ((1, 1, 8, 8),)
trace_kwargs = {'normalize_range': (0.0, 1.0), 'random_fn': <built-in method ones of type object at 0x7fe5832f88c0>, 'random_scale': 1.0, 'roughness': 0.5}, test_args = ((5, 1, 8, 8),)
test_kwargs = {'normalize_range': (-1.0, 1.0), 'random_fn': <built-in method ones of type object at 0x7fe5832f88c0>, 'random_scale': 0.9, 'roughness': 0.7}, target = 'tensorflow'
backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
>           graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:326: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:232: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

output_size = (1, 1, 8, 8), roughness = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[0.5]]]], dtype=float32)>
random_scale = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>, random_fn = <built-in method ones of type object at 0x7fe5832f88c0>, normalize_range = (0.0, 1.0)
device = None, dtype = None

    def tensorflow_diamond_square(
        output_size,
        roughness=0.5,
        random_scale=1.0,
        random_fn=tensorflow_rand_frnt,
        normalize_range=None,
        device=None,
        dtype=None,
    ):
        from ..core.check import tensorflow_KORNIA_CHECK
        from ...ivy.functional.frontends.torch.tensor import tensorflow_to_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_expand_frnt_
        from ..core.check import tensorflow_KORNIA_CHECK_IS_TENSOR
        from ...ivy.functional.frontends.torch.tensor import tensorflow_view_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_reshape_frnt_
        from ...ivy.functional.backends.tensorflow.general import tensorflow_get_item
        from ..enhance.normalize import tensorflow_normalize_min_max
        from ...ivy.functional.frontends.torch.tensor import tensorflow_contiguous_frnt_
    
        tensorflow_KORNIA_CHECK(len(output_size) == 4, "output_size must be (B,C,H,W)")
        if not isinstance(random_scale, (tensorflow.Tensor, tensorflow.keras.Variable)):
            random_scale = tensorflow_to_frnt_(
                tensorflow.convert_to_tensor([[[[random_scale]]]]), device, dtype
            )
            random_scale = tensorflow_expand_frnt_(
                random_scale, [output_size[0] * output_size[1], 1, 1, 1]
            )
        else:
            tensorflow_KORNIA_CHECK_IS_TENSOR(random_scale)
            random_scale = tensorflow_view_frnt_(random_scale, -1, 1, 1, 1)
            random_scale = tensorflow_expand_frnt_(
                random_scale, [output_size[0], output_size[1], 1, 1]
            )
            random_scale = tensorflow_reshape_frnt_(random_scale, [-1, 1, 1, 1])
        if not isinstance(roughness, (tensorflow.Tensor, tensorflow.keras.Variable)):
            roughness = tensorflow_to_frnt_(
                tensorflow.convert_to_tensor([[[[roughness]]]]), device, dtype
            )
            roughness = tensorflow_expand_frnt_(
                roughness, [output_size[0] * output_size[1], 1, 1, 1]
            )
        else:
            roughness = tensorflow_view_frnt_(roughness, -1, 1, 1, 1)
            roughness = tensorflow_expand_frnt_(
                roughness, [output_size[0], output_size[1], 1, 1]
            )
            roughness = tensorflow_reshape_frnt_(roughness, [-1, 1, 1, 1])
        width, height = output_size[-2:][0], output_size[-2:][1]
        num_samples: typing.Any = 1
        for x in output_size[:-2]:
            num_samples = num_samples * x
        p2_width: typing.Any = 2 ** math.ceil(math.log2(width - 1)) + 1
        p2_height: typing.Any = 2 ** math.ceil(math.log2(height - 1)) + 1
        recursion_depth: typing.Any = int(
            min(math.log2(p2_width - 1) - 1, math.log2(p2_height - 1) - 1)
        )
        seed_width: typing.Any = (p2_width - 1) // 2**recursion_depth + 1
        seed_height: typing.Any = (p2_height - 1) // 2**recursion_depth + 1
>       img: typing.Any = random_scale * tensorflow__diamond_square_seed(
            num_samples, seed_width, seed_height, random_fn, device, dtype
        )

ivy_transpiled_outputs/tensorflow_outputs/kornia/contrib/diamond_square.py:243: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
rhs = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def impl(self, rhs):
        try:
            return original_method(self, rhs)
        except Exception:
>           return patched_method(self, rhs)

ivy_transpiled_outputs/tensorflow_outputs/__init__.py:65: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
other = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow___mul___frnt_(tensor, other):
        from .pointwise_ops import tensorflow_mul_frnt
    
>       return tensorflow_mul_frnt(tensor, other)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/tensor.py:125: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
other = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_mul_frnt(input, other, *, out=None):
        from .__init__ import tensorflow_promote_types_of_torch_inputs_frnt
        from ...backends.tensorflow.elementwise import tensorflow_multiply
    
>       input, other = tensorflow_promote_types_of_torch_inputs_frnt(input, other)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/pointwise_ops.py:74: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x1 = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
x2 = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_promote_types_of_torch_inputs_frnt(x1, x2, /):
        from ...ivy.general import tensorflow_isscalar_bknd
        from ...ivy.data_type import tensorflow_is_int_dtype_bknd
        from ...backends.tensorflow.creation import tensorflow_asarray
        from ...ivy.data_type import tensorflow_default_dtype_bknd
        from .tensor import tensorflow_shape_frnt_
        from ...ivy.device import tensorflow_default_device_bknd
        from ....data_classes.array.data_type import tensorflow_astype_bknd_
    
        """Promote the dtype of the given native array inputs to a common dtype
        based on type promotion rules.
    
        While passing float or integer values or any other non-array input
        to this function, it should be noted that the return will be an
        array-like object. Therefore, outputs from this function should be
        used as inputs only for those functions that expect an array-like or
        tensor-like objects, otherwise it might give unexpected results.
        """
        if (
            tensorflow_isscalar_bknd(x1) or isinstance(x1, (list, tuple))
        ) and tensorflow_is_int_dtype_bknd(x1):
            x1 = tensorflow_asarray(x1, dtype="int64")
        elif tensorflow_isscalar_bknd(x1) or isinstance(x1, (list, tuple)):
            x1 = tensorflow_asarray(x1)
        if (
            tensorflow_isscalar_bknd(x2) or isinstance(x2, (list, tuple))
        ) and tensorflow_is_int_dtype_bknd(x2):
            x2 = tensorflow_asarray(x2, dtype="int64")
        elif tensorflow_isscalar_bknd(x2) or isinstance(x2, (list, tuple)):
            x2 = tensorflow_asarray(x2)
        type1 = tensorflow_default_dtype_bknd(item=x1).strip("u123456789")
>       type2 = tensorflow_default_dtype_bknd(item=x2).strip("u123456789")

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/__init__.py:220: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def tensorflow_default_dtype_bknd(
        *,
        dtype: Optional[Union[str, str]] = None,
        item: Optional[Union[tensorflow.Tensor, tf.Tensor]] = None,
        as_native: bool = False,
    ):
        from ..backends.tensorflow.data_type import tensorflow_as_ivy_dtype
        from ..backends.tensorflow.data_type import tensorflow_as_native_dtype
        from .general import tensorflow_exists_bknd
        from .general import tensorflow_default_bknd
    
        if tensorflow_exists_bknd(dtype):
            if as_native is True:
                return tensorflow_as_native_dtype(dtype)
            return tensorflow_as_ivy_dtype(dtype)
        as_native = tensorflow_default_bknd(as_native, False)
        if tensorflow_exists_bknd(item):
            if hasattr(item, "override_dtype_check"):
                return item.override_dtype_check()
            elif isinstance(item, (list, tuple, dict)) and len(item) == 0:
                pass
>           elif tensorflow_is_complex_dtype_bknd(item):

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:185: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_is_complex_dtype_bknd(
        dtype_in: Union[str, str, tensorflow.Tensor, tf.Tensor, Number], /
    ):
        from ..backends.tensorflow.data_type import tensorflow_dtype
        from .general import tensorflow_is_array_bknd
        from .nest import tensorflow_nested_argwhere_bknd
    
        if tensorflow_is_array_bknd(dtype_in):
            dtype_in = tensorflow_dtype(dtype_in)
        elif isinstance(dtype_in, tuple):
            dtype_in = tensorflow_default_int_dtype_bknd()
        elif isinstance(dtype_in, np.ndarray):
            return "complex" in dtype_in.dtype.name
        elif isinstance(dtype_in, Number):
            return isinstance(dtype_in, (complex, np.complexfloating))
        elif isinstance(dtype_in, (list, tuple, dict)):
            return tensorflow_nested_argwhere_bknd(
                dtype_in,
                lambda x: isinstance(x, (complex, np.complexfloating))
                or tensorflow_is_array_bknd(x)
                and "complex" in tensorflow_dtype(x),
            )
>       return "complex" in tensorflow_as_ivy_dtype_bknd(dtype_in)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:562: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_as_ivy_dtype_bknd(dtype_in: Union[str, str], /):
        from ..backends.tensorflow.data_type import tensorflow_as_ivy_dtype
    
>       return tensorflow_as_ivy_dtype(dtype_in)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:49: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_as_ivy_dtype(
        dtype_in: Union[tensorflow.DType, str, int, float, complex, bool, np.dtype], /
    ):
        from ...ivy.data_type import tensorflow_default_int_dtype_bknd
        from ...ivy.data_type import tensorflow_default_float_dtype_bknd
        from ...ivy.data_type import tensorflow_default_complex_dtype_bknd
    
        if dtype_in is int:
            return tensorflow_default_int_dtype_bknd()
        if dtype_in is float:
            return tensorflow_default_float_dtype_bknd()
        if dtype_in is complex:
            return tensorflow_default_complex_dtype_bknd()
        if dtype_in is bool:
            return str("bool")
        if isinstance(dtype_in, np.dtype):
            dtype_in = dtype_in.name
        if isinstance(dtype_in, str):
            if dtype_in in native_dtype_dict:
                dtype_str = dtype_in
            else:
                raise Exception(
                    f"Cannot convert to ivy dtype. {dtype_in} is not supported by TensorFlow backend."
                )
        else:
>           dtype_str = ivy_dtype_dict[dtype_in]
E           KeyError: tensor([[[[0.3333, 1.0000, 0.3333],
E                     [1.0000, 0.3333, 1.0000],
E                     [0.3333, 1.0000, 0.3333]]]])

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/backends/tensorflow/data_type.py:184: KeyError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.contrib.diamond_square.diamond_square
_______________________________________________________________________________ test_EdgeDetector[tensorflow-s2s-False] ________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_EdgeDetector(target_framework, mode, backend_compile):
        print("kornia.contrib.EdgeDetector")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, target=target_framework)
    
        torch_detector = kornia.contrib.EdgeDetector()
>       transpiled_detector = transpiled_kornia.contrib.EdgeDetector()

kornia/test_contrib.py:163: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:232: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_EdgeDetector()

    def __init__(self):
        from ..filters.dexined import tensorflow_DexiNed
    
        self.super___init__(
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
>       self.model = tensorflow_DexiNed(pretrained=True)

ivy_transpiled_outputs/tensorflow_outputs/kornia/contrib/edge_detection.py:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_DexiNed(
  (block_1): tensorflow_DoubleConvBlock(
    (conv1): KerasConv2D()
    (bn1): KerasBatchNorm2D()
...e2d()
    )
  )
  (block_cat): tensorflow_SingleConvBlock(
    (conv): KerasConv2D()
    (bn): KerasBatchNorm2D()
  )
)
args = (), kwargs = {'pretrained': True}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_DexiNed(
  (block_1): tensorflow_DoubleConvBlock(
    (conv1): KerasConv2D()
    (bn1): KerasBatchNorm2D()
...e2d()
    )
  )
  (block_cat): tensorflow_SingleConvBlock(
    (conv): KerasConv2D()
    (bn): KerasBatchNorm2D()
  )
)
pretrained = True

    @tensorflow_store_config_info
    def __init__(self, pretrained):
        from ...torch.nn.modules.pooling import tensorflow_MaxPool2d
    
        self.super___init__(
            pretrained,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        self.block_1 = tensorflow_DoubleConvBlock(3, 32, 64, stride=2)
        self.block_2 = tensorflow_DoubleConvBlock(64, 128, use_act=False)
        self.dblock_3 = tensorflow__DenseBlock(2, 128, 256)
        self.dblock_4 = tensorflow__DenseBlock(3, 256, 512)
        self.dblock_5 = tensorflow__DenseBlock(3, 512, 512)
        self.dblock_6 = tensorflow__DenseBlock(3, 512, 256)
        self.maxpool = tensorflow_MaxPool2d(kernel_size=3, stride=2, padding=1)
        self.side_1 = tensorflow_SingleConvBlock(64, 128, 2)
        self.side_2 = tensorflow_SingleConvBlock(128, 256, 2)
        self.side_3 = tensorflow_SingleConvBlock(256, 512, 2)
        self.side_4 = tensorflow_SingleConvBlock(512, 512, 1)
        self.side_5 = tensorflow_SingleConvBlock(512, 256, 1)
        self.pre_dense_2 = tensorflow_SingleConvBlock(128, 256, 2)
        self.pre_dense_3 = tensorflow_SingleConvBlock(128, 256, 1)
        self.pre_dense_4 = tensorflow_SingleConvBlock(256, 512, 1)
        self.pre_dense_5 = tensorflow_SingleConvBlock(512, 512, 1)
        self.pre_dense_6 = tensorflow_SingleConvBlock(512, 256, 1)
        self.up_block_1 = tensorflow_UpConvBlock(64, 1)
        self.up_block_2 = tensorflow_UpConvBlock(128, 1)
        self.up_block_3 = tensorflow_UpConvBlock(256, 2)
        self.up_block_4 = tensorflow_UpConvBlock(512, 3)
        self.up_block_5 = tensorflow_UpConvBlock(512, 4)
        self.up_block_6 = tensorflow_UpConvBlock(256, 4)
        self.block_cat = tensorflow_SingleConvBlock(6, 1, stride=1, use_bs=False)
        if pretrained:
>           self.load_from_file(url)

ivy_transpiled_outputs/tensorflow_outputs/kornia/filters/dexined.py:600: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_DexiNed(
  (block_1): tensorflow_DoubleConvBlock(
    (conv1): KerasConv2D()
    (bn1): KerasBatchNorm2D()
...e2d()
    )
  )
  (block_cat): tensorflow_SingleConvBlock(
    (conv): KerasConv2D()
    (bn): KerasBatchNorm2D()
  )
)
path_file = 'http://cmp.felk.cvut.cz/~mishkdmy/models/DexiNed_BIPED_10.pth'

    def load_from_file(self, path_file):
        from ...ivy.functional.frontends.torch.hub.hub import (
            tensorflow_load_state_dict_from_url_frnt,
        )
        from ..utils.helpers import tensorflow_map_location_to_cpu
    
        pretrained_dict = tensorflow_load_state_dict_from_url_frnt(
            path_file, map_location=tensorflow_map_location_to_cpu
        )
>       self.load_state_dict(pretrained_dict, strict=True)

ivy_transpiled_outputs/tensorflow_outputs/kornia/filters/dexined.py:613: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_DexiNed(
  (block_1): tensorflow_DoubleConvBlock(
    (conv1): KerasConv2D()
    (bn1): KerasBatchNorm2D()
...e2d()
    )
  )
  (block_cat): tensorflow_SingleConvBlock(
    (conv): KerasConv2D()
    (bn): KerasBatchNorm2D()
  )
)
state_dict = OrderedDict([('block_1.conv1.weight', <tf.Tensor: shape=(32, 3, 3, 3), dtype=float32, numpy=
array([[[[ 2.31264587e-02...numpy=array([1.], dtype=float32)>), ('block_cat.bn.num_batches_tracked', <tf.Tensor: shape=(), dtype=int64, numpy=0>)])
strict = True, assign = False

    def load_state_dict(
        self,
        state_dict: typing.Mapping[str, Any],
        strict: bool = True,
        assign: bool = False,
    ):
        r"""Copy parameters and buffers from :attr:`state_dict` into this module and its descendants.
    
        If :attr:`strict` is ``True``, then
        the keys of :attr:`state_dict` must exactly match the keys returned
        by this module's :meth:`~Module.state_dict` function.
    
        Args:
            state_dict (dict): a dict containing parameters and
                persistent buffers.
            strict (bool, optional): whether to strictly enforce that the keys
                in :attr:`state_dict` match the keys returned by this module's
                :meth:`~Module.state_dict` function. Default: ``True``
    
        Returns:
            ``NamedTuple`` with ``missing_keys`` and ``unexpected_keys`` fields:
                * **missing_keys** is a list of str containing any keys that are expected
                    by this module but missing from the provided ``state_dict``.
                * **unexpected_keys** is a list of str containing the keys that are not
                    expected by this module but present in the provided ``state_dict``.
        """
        if not isinstance(state_dict, typing.Mapping):
            raise TypeError(
                f"Expected state_dict to be dict-like, got {type(state_dict)}."
            )
    
        missing_keys: List[str] = []
        unexpected_keys: List[str] = []
        error_msgs: List[str] = []
    
        state_dict = tf.nest.map_structure(
            lambda x: tf.convert_to_tensor(x.numpy()),
            state_dict,
        )
        state_dict = OrderedDict(state_dict)
    
        def load(module, local_state_dict, prefix=""):
            module._load_from_state_dict(
                local_state_dict,
                prefix,
                strict,
                missing_keys,
                unexpected_keys,
                error_msgs,
            )
            # TODO: maybe we should implement this similar to PT
            # and make this recursive.
    
>       load(self, state_dict)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:600: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

module = tensorflow_DexiNed(
  (block_1): tensorflow_DoubleConvBlock(
    (conv1): KerasConv2D()
    (bn1): KerasBatchNorm2D()
...e2d()
    )
  )
  (block_cat): tensorflow_SingleConvBlock(
    (conv): KerasConv2D()
    (bn): KerasBatchNorm2D()
  )
)
local_state_dict = OrderedDict([('block_1.conv1.weight', <tf.Tensor: shape=(32, 3, 3, 3), dtype=float32, numpy=
array([[[[ 2.31264587e-02...numpy=array([1.], dtype=float32)>), ('block_cat.bn.num_batches_tracked', <tf.Tensor: shape=(), dtype=int64, numpy=0>)])
prefix = ''

    def load(module, local_state_dict, prefix=""):
>       module._load_from_state_dict(
            local_state_dict,
            prefix,
            strict,
            missing_keys,
            unexpected_keys,
            error_msgs,
        )

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:589: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_DexiNed(
  (block_1): tensorflow_DoubleConvBlock(
    (conv1): KerasConv2D()
    (bn1): KerasBatchNorm2D()
...e2d()
    )
  )
  (block_cat): tensorflow_SingleConvBlock(
    (conv): KerasConv2D()
    (bn): KerasBatchNorm2D()
  )
)
state_dict = OrderedDict([('block_1.conv1.weight', <tf.Tensor: shape=(32, 3, 3, 3), dtype=float32, numpy=
array([[[[ 2.31264587e-02...numpy=array([1.], dtype=float32)>), ('block_cat.bn.num_batches_tracked', <tf.Tensor: shape=(), dtype=int64, numpy=0>)])
prefix = '', strict = True, missing_keys = [], unexpected_keys = [], error_msgs = []

    def _load_from_state_dict(
        self, state_dict, prefix, strict, missing_keys, unexpected_keys, error_msgs
    ):
        def _retrive_layer(model, key):
            if len(key.split(".")) == 1:
                return model, key
    
            module_path, weight_name = key.rsplit(".", 1)
    
            # Retrieve the layer using the module path
            layer = model
            for attr in module_path.split("."):
                layer = getattr(layer, attr)
    
            return layer, weight_name
    
        persistent_buffers = {k: v for k, v in self._buffers.items()}
        local_name_params = itertools.chain(
            self._parameters.items(), persistent_buffers.items()
        )
        local_state = {k: v for k, v in local_name_params if v is not None}
    
        for name, param in local_state.items():
            key = prefix + name
            if key in state_dict:
                input_param = state_dict[key]
                if not isinstance(input_param, tf.Tensor):
                    error_msgs.append(
                        f'While copying the parameter named "{key}", '
                        "expected ArrayLike object from checkpoint but "
                        f"received {type(input_param)}"
                    )
                    continue
    
                if not isinstance(input_param, KerasVariable):
>                   input_param = KerasVariable(input_param)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:522: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <KerasVariable shape=<unknown>, dtype=float32, path=variable_87>, initializer = <tf.Tensor: shape=(), dtype=int64, numpy=79200>, shape = None, dtype = 'float32', trainable = True
autocast = True, aggregation = 'mean', name = 'variable_87'

    def __init__(
        self,
        initializer,
        shape=None,
        dtype=None,
        trainable=True,
        autocast=True,
        aggregation="mean",
        name=None,
    ):
        name = name or auto_name(self.__class__.__name__)
        if not isinstance(name, str) or "/" in name:
            raise ValueError(
                "Argument `name` must be a string and "
                "cannot contain character `/`. "
                f"Received: name={name}"
            )
        if aggregation not in ("mean", "sum", "only_first_replica"):
            raise ValueError(
                "Invalid valid for argument `aggregation`. Expected "
                "one of {'mean', 'sum', 'only_first_replica'}. "
                f"Received: aggregation={aggregation}"
            )
        self.name = name
        parent_path = current_path()
        if parent_path:
            self.path = current_path() + "/" + self.name
        else:
            self.path = self.name
        dtype = standardize_dtype(dtype)
        self._dtype = dtype
        self._shape = None
        self._initializer = None
        self._regularizer = None
        self._constraint = None
        self._trainable = trainable
        self._autocast = autocast
        self._aggregation = aggregation
        # `self._overwrite_with_gradient` is an internal property to determine
        # whether this variable should be overwritten by the computed gradient.
        # Ref: https://github.com/google/flax/blob/main/flax/linen/fp8_ops.py
        self._overwrite_with_gradient = False
        if isinstance(initializer, str):
            from keras.src import initializers
    
            initializer = initializers.get(initializer)
        if callable(initializer):
            if shape is None:
                raise ValueError(
                    "When creating a Variable from an initializer, "
                    "the `shape` argument should be specified. "
                    f"Received: initializer={initializer} "
                    f"and shape={shape}"
                )
    
        if in_stateless_scope():
            if callable(initializer):
                self._value = None
                self._initializer = initializer
                self._shape = self._validate_shape(shape)
                register_uninitialized_variable(self)
            else:
                raise ValueError(
                    "You are attempting to create a variable "
                    "while in a stateless scope. This is disallowed. "
                    "Make sure that all variables are created "
                    "before you start using your layer/model objects.\n\n"
                    "In some cases, you might be seeing this error "
                    "because you need to "
                    "implement a `def build(self, input_shape)` method "
                    "on your layer/model, which will "
                    "create its variables.\n\n"
                    "In some other cases, you might be seeing this error "
                    "because you are instantiating a `Variable` and "
                    "assigning it to a layer without going through "
                    "self.add_variable()/self.add_weight(). Always prefer "
                    "using these methods "
                    "(with a `shape` and `initializer` argument)."
                )
        else:
            if callable(initializer):
                self._shape = self._validate_shape(shape)
                self._initialize_with_initializer(initializer)
            else:
>               self._initialize(initializer)

/opt/fw/tensorflow/keras/src/backend/common/variables.py:165: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <KerasVariable shape=<unknown>, dtype=float32, path=variable_87>, value = <tf.Tensor: shape=(), dtype=int64, numpy=79200>

    def _initialize(self, value):
>       self._value = tf.Variable(
            value, dtype=self._dtype, trainable=self.trainable, name=self.name
        )

/opt/fw/tensorflow/keras/src/backend/tensorflow/core.py:35: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (<class 'tensorflow.python.ops.variables.Variable'>, <tf.Tensor: shape=(), dtype=int64, numpy=79200>), kwargs = {'dtype': 'float32', 'name': 'variable_87', 'trainable': True}

    def error_handler(*args, **kwargs):
      try:
        if not is_traceback_filtering_enabled():
          return fn(*args, **kwargs)
      except NameError:
        # In some very rare cases,
        # `is_traceback_filtering_enabled` (from the outer scope) may not be
        # accessible from inside this function
        return fn(*args, **kwargs)
    
      filtered_tb = None
      try:
        return fn(*args, **kwargs)
      except Exception as e:
        filtered_tb = _process_traceback_frames(e.__traceback__)
>       raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/tensorflow/python/util/traceback_utils.py:153: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <tf.Tensor: shape=(), dtype=int64, numpy=79200>, dtype = tf.float32, name = 'initial_value'

    def __tf_tensor__(
        self, dtype: Optional[dtypes.DType] = None, name: Optional[str] = None
        ) -> "Tensor":
      if dtype is not None and not dtype.is_compatible_with(self.dtype):
>       raise ValueError(
            _add_error_prefix(
                f"Tensor conversion requested dtype {dtype.name} "
                f"for Tensor with dtype {self.dtype.name}: {self!r}",
                name=name))
E       ValueError: initial_value: Tensor conversion requested dtype float32 for Tensor with dtype int64: <tf.Tensor: shape=(), dtype=int64, numpy=79200>

/opt/fw/tensorflow/tensorflow/python/framework/tensor.py:761: ValueError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.contrib.EdgeDetector
----------------------------------------------------------------------------------------- Captured stderr call -----------------------------------------------------------------------------------------
Downloading: "http://cmp.felk.cvut.cz/~mishkdmy/models/DexiNed_BIPED_10.pth" to /root/.cache/torch/hub/checkpoints/DexiNed_BIPED_10.pth

  0%|          | 0.00/135M [00:00<?, ?B/s]
  0%|          | 128k/135M [00:00<05:43, 411kB/s]
  0%|          | 256k/135M [00:00<03:28, 674kB/s]
  0%|          | 512k/135M [00:00<01:53, 1.24MB/s]
  1%|          | 896k/135M [00:00<01:10, 2.00MB/s]
  1%|▏         | 1.75M/135M [00:00<00:34, 4.02MB/s]
  3%|▎         | 3.50M/135M [00:00<00:17, 8.04MB/s]
  5%|▍         | 6.12M/135M [00:00<00:10, 13.4MB/s]
  7%|▋         | 9.12M/135M [00:01<00:07, 18.2MB/s]
  9%|▉         | 12.0M/135M [00:01<00:06, 21.3MB/s]
 11%|█         | 15.0M/135M [00:01<00:05, 23.7MB/s]
 13%|█▎        | 17.9M/135M [00:01<00:04, 25.0MB/s]
 15%|█▌        | 20.8M/135M [00:01<00:04, 26.0MB/s]
 18%|█▊        | 23.8M/135M [00:01<00:04, 27.0MB/s]
 20%|█▉        | 26.6M/135M [00:01<00:04, 27.4MB/s]
 22%|██▏       | 29.6M/135M [00:01<00:03, 27.9MB/s]
 24%|██▍       | 32.5M/135M [00:01<00:03, 27.9MB/s]
 26%|██▋       | 35.5M/135M [00:02<00:03, 28.4MB/s]
 29%|██▊       | 38.4M/135M [00:02<00:03, 28.5MB/s]
 31%|███       | 41.4M/135M [00:02<00:03, 28.6MB/s]
 33%|███▎      | 44.4M/135M [00:02<00:03, 28.9MB/s]
 35%|███▌      | 47.4M/135M [00:02<00:03, 28.7MB/s]
 37%|███▋      | 50.4M/135M [00:02<00:03, 29.0MB/s]
 40%|███▉      | 53.2M/135M [00:02<00:02, 29.3MB/s]
 42%|████▏     | 56.2M/135M [00:02<00:02, 28.8MB/s]
 44%|████▍     | 59.2M/135M [00:02<00:02, 29.0MB/s]
 46%|████▌     | 62.1M/135M [00:02<00:02, 29.3MB/s]
 48%|████▊     | 65.0M/135M [00:03<00:02, 28.4MB/s]
 50%|█████     | 67.9M/135M [00:03<00:02, 28.4MB/s]
 53%|█████▎    | 70.8M/135M [00:03<00:02, 28.3MB/s]
 55%|█████▍    | 73.8M/135M [00:03<00:02, 28.6MB/s]
 57%|█████▋    | 76.6M/135M [00:03<00:02, 28.4MB/s]
 59%|█████▉    | 79.5M/135M [00:03<00:02, 28.4MB/s]
 61%|██████▏   | 82.5M/135M [00:03<00:01, 28.6MB/s]
 63%|██████▎   | 85.4M/135M [00:03<00:01, 28.6MB/s]
 66%|██████▌   | 88.4M/135M [00:03<00:01, 28.8MB/s]
 68%|██████▊   | 91.4M/135M [00:04<00:01, 28.6MB/s]
 70%|███████   | 94.4M/135M [00:04<00:01, 28.7MB/s]
 72%|███████▏  | 97.4M/135M [00:04<00:01, 28.9MB/s]
 75%|███████▍  | 100M/135M [00:04<00:01, 28.8MB/s] 
 77%|███████▋  | 103M/135M [00:04<00:01, 29.0MB/s]
 79%|███████▉  | 106M/135M [00:04<00:01, 29.1MB/s]
 81%|████████  | 109M/135M [00:04<00:00, 28.6MB/s]
 83%|████████▎ | 112M/135M [00:04<00:00, 28.5MB/s]
 85%|████████▌ | 115M/135M [00:04<00:00, 28.8MB/s]
 88%|████████▊ | 118M/135M [00:05<00:00, 28.7MB/s]
 90%|████████▉ | 121M/135M [00:05<00:00, 28.9MB/s]
 92%|█████████▏| 124M/135M [00:05<00:00, 28.7MB/s]
 94%|█████████▍| 126M/135M [00:05<00:00, 28.1MB/s]
 96%|█████████▋| 130M/135M [00:05<00:00, 28.5MB/s]
 98%|█████████▊| 132M/135M [00:05<00:00, 28.8MB/s]
100%|██████████| 135M/135M [00:05<00:00, 25.2MB/s]
__________________________________________________________________________________ test_KMeans[tensorflow-s2s-False] ___________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_KMeans(target_framework, mode, backend_compile):
        print("kornia.contrib.KMeans")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, target=target_framework)
    
        torch_kmeans = kornia.contrib.KMeans(3, None, 10e-4, 100, 0)
        transpiled_kmeans = transpiled_kornia.contrib.KMeans(3, None, 10e-4, 100, 0)
    
        torch_x1 = torch.rand((1000, 5))
        torch_x2 = torch.rand((10, 5))
        transpiled_x1 = _array_to_new_backend(torch_x1, target_framework)
        transpiled_x2 = _array_to_new_backend(torch_x2, target_framework)
    
        torch_kmeans.fit(torch_x1)
        torch_predictions = torch_kmeans.predict(torch_x2)
    
>       transpiled_kmeans.fit(transpiled_x1)

kornia/test_contrib.py:245: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <ivy_transpiled_outputs.tensorflow_outputs.kornia.contrib.kmeans.tensorflow_KMeans object at 0x7fe56c3c9d20>
X = <tf.Tensor: shape=(1000, 5), dtype=float32, numpy=
array([[0.4962566 , 0.7682218 , 0.08847743, 0.13203049, 0.30742282]...5, 0.49248123, 0.4287302 ],
       [0.3786084 , 0.04217941, 0.28761953, 0.5166052 , 0.11317676]],
      dtype=float32)>

    def fit(self, X):
        from ..core.check import tensorflow_KORNIA_CHECK
        from ..core.check import tensorflow_KORNIA_CHECK_SHAPE
        from ...ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_argmin_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_clone_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_squeeze_frnt_
        from ...ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            tensorflow_nonzero_frnt,
        )
        from ...ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            tensorflow_index_select_frnt,
        )
        from ...ivy.functional.frontends.torch.random_sampling import (
            tensorflow_randint_frnt,
        )
        from ...ivy.functional.frontends.torch.tensor import tensorflow_mean_frnt_
        from ...ivy.functional.frontends.torch.reduction_ops import tensorflow_sum_frnt
        from ...ivy.functional.frontends.torch.pointwise_ops import tensorflow_sqrt_frnt
    
        tensorflow_KORNIA_CHECK_SHAPE(X, ["N", "D"])
        if self._cluster_centers is None:
            self._cluster_centers = self._initialise_cluster_centers(
                X, self.num_clusters
            )
        else:
            tensorflow_KORNIA_CHECK(
                tensorflow_shape_frnt_(X)[1]
                == tensorflow_shape_frnt_(self._cluster_centers)[1],
                f"Dimensions at position 1 of X and cluster_centers do not match.                 {tensorflow_shape_frnt_(X)[1]} != {tensorflow_shape_frnt_(self._cluster_centers)[1]}",
            )
        current_centers = self._cluster_centers
        previous_centers: typing.Any = None
        iteration: typing.Any = 0
        while True:
            distance: typing.Any = self._pairwise_euclidean_distance(X, current_centers)
            cluster_assignment = tensorflow_argmin_frnt_(distance, -1)
            previous_centers = tensorflow_clone_frnt_(current_centers)
            for index in range(self.num_clusters):
                selected = tensorflow_squeeze_frnt_(
                    tensorflow_nonzero_frnt(cluster_assignment == index)
                )
                selected = tensorflow_index_select_frnt(X, 0, selected)
                if tensorflow_shape_frnt_(selected)[0] == 0:
                    selected = X[tensorflow_randint_frnt(len(X), (1,), device=X.device)]
>               current_centers[index] = tensorflow_mean_frnt_(selected, dim=0)
E               TypeError: 'tensorflow.python.framework.ops.EagerTensor' object does not support item assignment

ivy_transpiled_outputs/tensorflow_outputs/kornia/contrib/kmeans.py:149: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.contrib.KMeans
_______________________________________________________________________________ test_ImageStitcher[tensorflow-s2s-False] _______________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_ImageStitcher(target_framework, mode, backend_compile):
        print("kornia.contrib.ImageStitcher")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, target=target_framework)
    
        torch_matcher = kornia.feature.LoFTR(pretrained='outdoor')
>       transpiled_matcher = transpiled_kornia.feature.LoFTR(pretrained='outdoor')

kornia/test_contrib.py:313: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:232: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_LoFTR(), pretrained = 'outdoor'
config = {'backbone_type': 'ResNetFPN', 'coarse': {'attention': 'linear', 'd_ffn': 256, 'd_model': 256, 'layer_names': ['self',...: 'linear', 'd_ffn': 128, 'd_model': 128, 'layer_names': ['self', 'cross'], ...}, 'fine_concat_coarse_feat': True, ...}

    def __init__(self, pretrained="outdoor", config=default_cfg):
        from ....ivy.functional.backends.tensorflow.general import tensorflow_set_item
        from .backbone.__init__ import tensorflow_build_backbone
        from .utils.position_encoding import tensorflow_PositionEncodingSine
        from .loftr_module.transformer import tensorflow_LocalFeatureTransformer
        from .utils.coarse_matching import tensorflow_CoarseMatching
        from .loftr_module.fine_preprocess import tensorflow_FinePreprocess
        from .utils.fine_matching import tensorflow_FineMatching
        from ....ivy.functional.frontends.torch.hub.hub import (
            tensorflow_load_state_dict_from_url_frnt,
        )
        from ....ivy.functional.backends.tensorflow.general import tensorflow_get_item
        from ...utils.helpers import tensorflow_map_location_to_cpu
    
        self.super___init__(
            pretrained=pretrained,
            config=config,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        self.config = config
        if pretrained == "indoor_new":
            self.config["coarse"] = tensorflow_set_item(
                self.config["coarse"], "temp_bug_fix", True
            )
>       self.backbone = tensorflow_build_backbone(config)

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/loftr/loftr.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

config = {'backbone_type': 'ResNetFPN', 'coarse': {'attention': 'linear', 'd_ffn': 256, 'd_model': 256, 'layer_names': ['self',...: 'linear', 'd_ffn': 128, 'd_model': 128, 'layer_names': ['self', 'cross'], ...}, 'fine_concat_coarse_feat': True, ...}

    def tensorflow_build_backbone(config):
        if config["backbone_type"] == "ResNetFPN":
            if config["resolution"] == (8, 2):
>               return kornia.feature.loftr.resnet_fpn.ResNetFPN_8_2(config["resnetfpn"])
E               NameError: name 'kornia' is not defined

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/loftr/backbone/__init__.py:41: NameError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.contrib.ImageStitcher
----------------------------------------------------------------------------------------- Captured stderr call -----------------------------------------------------------------------------------------
Downloading: "http://cmp.felk.cvut.cz/~mishkdmy/models/loftr_outdoor.ckpt" to /root/.cache/torch/hub/checkpoints/loftr_outdoor.ckpt

  0%|          | 0.00/44.2M [00:00<?, ?B/s]
  0%|          | 128k/44.2M [00:00<01:52, 409kB/s]
  1%|          | 256k/44.2M [00:00<01:08, 673kB/s]
  1%|          | 512k/44.2M [00:00<00:37, 1.23MB/s]
  2%|▏         | 896k/44.2M [00:00<00:22, 2.00MB/s]
  4%|▍         | 1.75M/44.2M [00:00<00:11, 4.03MB/s]
  8%|▊         | 3.50M/44.2M [00:00<00:05, 8.05MB/s]
 15%|█▍        | 6.50M/44.2M [00:00<00:02, 14.5MB/s]
 21%|██        | 9.38M/44.2M [00:01<00:01, 18.7MB/s]
 28%|██▊       | 12.2M/44.2M [00:01<00:01, 21.6MB/s]
 35%|███▍      | 15.2M/44.2M [00:01<00:01, 23.9MB/s]
 41%|████      | 18.1M/44.2M [00:01<00:01, 25.1MB/s]
 48%|████▊     | 21.1M/44.2M [00:01<00:00, 26.4MB/s]
 54%|█████▍    | 24.0M/44.2M [00:01<00:00, 27.0MB/s]
 61%|██████    | 27.0M/44.2M [00:01<00:00, 27.7MB/s]
 68%|██████▊   | 30.0M/44.2M [00:01<00:00, 28.2MB/s]
 74%|███████▍  | 32.8M/44.2M [00:01<00:00, 27.8MB/s]
 81%|████████  | 35.8M/44.2M [00:02<00:00, 28.3MB/s]
 88%|████████▊ | 38.8M/44.2M [00:02<00:00, 28.6MB/s]
 94%|█████████▍| 41.6M/44.2M [00:02<00:00, 28.5MB/s]
100%|██████████| 44.2M/44.2M [00:02<00:00, 20.5MB/s]
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/test_contrib.py::test_diamond_square[tensorflow-s2s-False] - KeyError: tensor([[[[0.3333, 1.0000, 0.3333],
FAILED kornia/test_contrib.py::test_EdgeDetector[tensorflow-s2s-False] - ValueError: initial_value: Tensor conversion requested dtype float32 for Tensor with dtype int64: <tf.Tensor: shape=(), dtyp...
FAILED kornia/test_contrib.py::test_KMeans[tensorflow-s2s-False] - TypeError: 'tensorflow.python.framework.ops.EagerTensor' object does not support item assignment
FAILED kornia/test_contrib.py::test_ImageStitcher[tensorflow-s2s-False] - NameError: name 'kornia' is not defined
============================================================================== 4 failed, 11 passed in 1618.62s (0:26:58) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 44 items

kornia/test_filters.py ............................................                                                                                                                              [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
=================================================================================== 44 passed in 3690.65s (1:01:30) ====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 7 items

kornia/test_morphology.py .......                                                                                                                                                                [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
==================================================================================== 7 passed in 595.98s (0:09:55) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 69 items

kornia/test_color.py ...........F...........F....................F....F......F...........F                                                                                                       [100%]

=============================================================================================== FAILURES ===============================================================================================
____________________________________________________________________________________ test_rgb_to_hls[jax-s2s-False] ____________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_rgb_to_hls(target_framework, mode, backend_compile):
        # Note: We test this function with requires_grad=True,
        # because otherwise we simply get an empty_like tensor
        # with garbage values on each run leading to test failures
        trace_args = (
            torch.rand(1, 3, 4, 5).requires_grad_(True),
        )
        trace_kwargs = {'eps': 1e-8}
        test_args = (
            torch.rand(5, 3, 4, 5).requires_grad_(True),
        )
        test_kwargs = {'eps': 1e-8}
>       _test_function(
            kornia.color.rgb_to_hls,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/test_color.py:295: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function rgb_to_hls at 0x7fbbed364160>
trace_args = (tensor([[[[0.9078, 0.9738, 0.5224, 0.3690, 0.7501],
          [0.3299, 0.3103, 0.0966, 0.6051, 0.3025],
          [0.... [0.9281, 0.2707, 0.5039, 0.3604, 0.3298],
          [0.1810, 0.9034, 0.5764, 0.4733, 0.6867]]]], requires_grad=True),)
trace_kwargs = {'eps': 1e-08}
test_args = (tensor([[[[0.0857, 0.1178, 0.7706, 0.5069, 0.3148],
          [0.3333, 0.2968, 0.5225, 0.0764, 0.2382],
          [0.... [0.4086, 0.9770, 0.6045, 0.0378, 0.8731],
          [0.4510, 0.8595, 0.3193, 0.3926, 0.7451]]]], requires_grad=True),)
test_kwargs = {'eps': 1e-08}, target = 'jax', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function rgb_to_hls at 0x7fbbed364160>, fn_name = 'kornia.color.rgb_to_hls'
trace_args = (tensor([[[[0.9078, 0.9738, 0.5224, 0.3690, 0.7501],
          [0.3299, 0.3103, 0.0966, 0.6051, 0.3025],
          [0.... [0.9281, 0.2707, 0.5039, 0.3604, 0.3298],
          [0.1810, 0.9034, 0.5764, 0.4733, 0.6867]]]], requires_grad=True),)
trace_kwargs = {'eps': 1e-08}
test_args = (tensor([[[[0.0857, 0.1178, 0.7706, 0.5069, 0.3148],
          [0.3333, 0.2968, 0.5225, 0.0764, 0.2382],
          [0.... [0.4086, 0.9770, 0.6045, 0.0378, 0.8731],
          [0.4510, 0.8595, 0.3193, 0.3926, 0.7451]]]], requires_grad=True),)
test_kwargs = {'eps': 1e-08}, target = 'jax', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
        graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
    
        if deterministic:
>           _to_numpy_and_allclose(orig_out, graph_out, tolerance=tolerance)

helpers.py:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

torch_x = tensor([[[[0.3157, 0.2084, 0.6815, 1.8351, 5.0844],
          [4.4746, 2.5839, 3.0676, 5.6454, 2.3773],
          [4.7....5388, 0.4321, 0.7506, 0.9581],
          [0.4690, 0.7370, 0.7193, 0.9921, 0.5029]]]],
       grad_fn=<StackBackward0>)
transpiled_x = Array([[[[0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.],
         [0., 0., 0., 0.,...0., 0.],
         [0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.]]]], dtype=float32)
tolerance = 0.001

    def _to_numpy_and_allclose(torch_x, transpiled_x, tolerance=1e-3):
        orig_data = _nest_array_to_numpy(torch_x)
        transpiled_data = _nest_array_to_numpy(transpiled_x)
>       _check_allclose(orig_data, transpiled_data, tolerance=tolerance)

helpers.py:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[[0.31572866, 0.20839494, 0.6815284 , 1.8350533 , 5.084418  ],
         [4.4746275 , 2.5839336 , 3.0675528 , 5...0.75061786, 0.95811844],
         [0.46896544, 0.736966  , 0.71926713, 0.99214214, 0.502931  ]]]],
      dtype=float32)
y = array([[[[0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.],
         [0., 0., 0., 0.,...0., 0.],
         [0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.]]]], dtype=float32)
tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
>           assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
E           AssertionError: numpy array values are not all close

helpers.py:26: AssertionError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.color.hls.rgb_to_hls
__________________________________________________________________________________ test_rgb_to_yuv420[jax-s2s-False] ___________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_rgb_to_yuv420(target_framework, mode, backend_compile):
        trace_args = (
            torch.rand(1, 3, 4, 6),
        )
        trace_kwargs = {}
        test_args = (
            torch.rand(5, 3, 4, 6),
        )
        test_kwargs = {}
>       _test_function(
            kornia.color.rgb_to_yuv420,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/test_color.py:563: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function rgb_to_yuv420 at 0x7fbbed365ea0>
trace_args = (tensor([[[[0.4923, 0.0203, 0.5113, 0.3480, 0.5724, 0.7248],
          [0.9033, 0.0959, 0.3311, 0.6469, 0.4540, 0.3077...     [0.5353, 0.9113, 0.2540, 0.2093, 0.1585, 0.5731],
          [0.4122, 0.5108, 0.5184, 0.9993, 0.4465, 0.8473]]]]),)
trace_kwargs = {}
test_args = (tensor([[[[0.7438, 0.1954, 0.5380, 0.1632, 0.1851, 0.7548],
          [0.6717, 0.3417, 0.6274, 0.3104, 0.3353, 0.7102...     [0.4588, 0.6024, 0.4099, 0.5320, 0.4544, 0.5059],
          [0.2088, 0.6219, 0.3948, 0.7093, 0.2575, 0.0520]]]]),)
test_kwargs = {}, target = 'jax', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function rgb_to_yuv420 at 0x7fbbed365ea0>, fn_name = 'kornia.color.rgb_to_yuv420'
trace_args = (tensor([[[[0.4923, 0.0203, 0.5113, 0.3480, 0.5724, 0.7248],
          [0.9033, 0.0959, 0.3311, 0.6469, 0.4540, 0.3077...     [0.5353, 0.9113, 0.2540, 0.2093, 0.1585, 0.5731],
          [0.4122, 0.5108, 0.5184, 0.9993, 0.4465, 0.8473]]]]),)
trace_kwargs = {}
test_args = (tensor([[[[0.7438, 0.1954, 0.5380, 0.1632, 0.1851, 0.7548],
          [0.6717, 0.3417, 0.6274, 0.3104, 0.3353, 0.7102...     [0.4588, 0.6024, 0.4099, 0.5320, 0.4544, 0.5059],
          [0.2088, 0.6219, 0.3948, 0.7093, 0.2575, 0.0520]]]]),)
test_kwargs = {}, target = 'jax', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
        graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
    
        if deterministic:
>           _to_numpy_and_allclose(orig_out, graph_out, tolerance=tolerance)

helpers.py:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

torch_x = (tensor([[[[0.2095, 0.2161, 0.7577, 0.2898, 0.4789, 0.4351],
          [0.3908, 0.7176, 0.6398, 0.3421, 0.7338, 0.5285...       [ 0.0717,  0.0079, -0.0169]],

         [[-0.0049, -0.0421, -0.0257],
          [ 0.0756,  0.0365,  0.0051]]]]))
transpiled_x = (Array([[[[0.20952477, 0.21614073, 0.75774896, 0.28979072, 0.4788672 ,
          0.43506157],
         [0.39078295, 0....
        [[ 0.09722862, -0.15047722,  0.1728629 ],
         [ 0.24135292, -0.25493374, -0.06153911]]]], dtype=float32))
tolerance = 0.001

    def _to_numpy_and_allclose(torch_x, transpiled_x, tolerance=1e-3):
        orig_data = _nest_array_to_numpy(torch_x)
        transpiled_data = _nest_array_to_numpy(transpiled_x)
>       _check_allclose(orig_data, transpiled_data, tolerance=tolerance)

helpers.py:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = (array([[[[0.20952477, 0.21614073, 0.75774896, 0.28979072, 0.4788672 ,
          0.43506157],
         [0.39078295, 0....
        [[-0.00489867, -0.04213294, -0.02570593],
         [ 0.07558964,  0.03654718,  0.00509508]]]], dtype=float32))
y = (array([[[[0.20952477, 0.21614073, 0.75774896, 0.28979072, 0.4788672 ,
          0.43506157],
         [0.39078295, 0....
        [[ 0.09722862, -0.15047722,  0.1728629 ],
         [ 0.24135292, -0.25493374, -0.06153911]]]], dtype=float32))
tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
            assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
            return
    
        if isinstance(x, (list, set, tuple)):
>           all([
                _check_allclose(element_x, element_y, tolerance=tolerance) for element_x, element_y in zip(x, y)
            ])

helpers.py:30: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

.0 = <zip object at 0x7fbb4eab6f00>

    all([
>       _check_allclose(element_x, element_y, tolerance=tolerance) for element_x, element_y in zip(x, y)
    ])

helpers.py:31: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[[ 0.04447219, -0.02727884, -0.00652532],
         [ 0.07174253,  0.00793683, -0.01694653]],

        [[-0.00489867, -0.04213294, -0.02570593],
         [ 0.07558964,  0.03654718,  0.00509508]]]], dtype=float32)
y = array([[[[-0.07569741, -0.04157364, -0.06257652],
         [ 0.05667822,  0.01602902,  0.18054119]],

        [[ 0.09722862, -0.15047722,  0.1728629 ],
         [ 0.24135292, -0.25493374, -0.06153911]]]], dtype=float32)
tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
>           assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
E           AssertionError: numpy array values are not all close

helpers.py:26: AssertionError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.color.yuv.rgb_to_yuv420
_____________________________________________________________________________________ test_RgbToHls[jax-s2s-False] _____________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_RgbToHls(target_framework, mode, backend_compile):
        args = (
            torch.rand(2, 3, 4, 5),
        )
>       _test_color_class(
            kornia.color.RgbToHls,
            "kornia.color.RgbToHls",
            args,
            target_framework,
            backend_compile,
            tolerance=1e-3,
        )

kornia/test_color.py:920: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'kornia.color.hls.RgbToHls'>, cls_name = 'kornia.color.RgbToHls'
args = (tensor([[[[0.2025, 0.3488, 0.5071, 0.6911, 0.5703],
          [0.4988, 0.5675, 0.2011, 0.4201, 0.2478],
          [0...., 0.0486],
          [0.8288, 0.4923, 0.7554, 0.1107, 0.4975],
          [0.2532, 0.5247, 0.2395, 0.6343, 0.5768]]]]),)
target = 'jax', backend_compile = False, tolerance = 0.001, init_args = ()

    def _test_color_class(
        cls,
        cls_name,
        args,
        target,
        backend_compile=False,
        tolerance=1e-3,
        init_args=(),
    ):
        print(f"{cls.__module__}.{cls.__name__}")
    
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
    
        torch_obj = cls(*init_args)
        if cls_name:
            transpiled_obj = eval("transpiled_" + f"{cls_name}")(*init_args)
        else:
            transpiled_obj = eval("transpiled_" + f"{cls.__module__}.{cls.__name__}")(*init_args)
    
        torch_out = torch_obj(*args)
        transpile_args = _nest_torch_tensor_to_new_framework(args, target)
        transpiled_out = transpiled_obj(*transpile_args)
    
        orig_np = _nest_array_to_numpy(torch_out)
        graph_np = _nest_array_to_numpy(transpiled_out)
    
>       _check_allclose(orig_np, graph_np, tolerance=tolerance)

kornia/test_color.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[[2.0063977 , 2.3195245 , 2.1061137 , 3.2132144 , 0.68674654],
         [0.35949904, 4.751307  , 5.143968  , 0...0.72690314, 0.34116733],
         [0.74509704, 0.8194052 , 0.42200083, 0.7214076 , 0.9984407 ]]]],
      dtype=float32)
y = array([[[[0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.],
         [0., 0., 0., 0.,...0., 0.],
         [0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.]]]], dtype=float32)
tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
>           assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
E           AssertionError: numpy array values are not all close

helpers.py:26: AssertionError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.color.hls.RgbToHls
_____________________________________________________________________________________ test_LuvToRgb[jax-s2s-False] _____________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_LuvToRgb(target_framework, mode, backend_compile):
        args = (
            torch.rand(2, 3, 4, 5),
        )
>       _test_color_class(
            kornia.color.LuvToRgb,
            "kornia.color.RgbToLuv",
            args,
            target_framework,
            backend_compile,
            tolerance=1e-3,
        )

kornia/test_color.py:990: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'kornia.color.luv.LuvToRgb'>, cls_name = 'kornia.color.RgbToLuv'
args = (tensor([[[[0.6353, 0.7019, 0.4940, 0.8889, 0.4265],
          [0.9914, 0.0718, 0.9871, 0.0264, 0.4133],
          [0...., 0.4746],
          [0.2128, 0.3398, 0.9926, 0.5202, 0.1368],
          [0.2114, 0.0354, 0.5618, 0.5720, 0.2168]]]]),)
target = 'jax', backend_compile = False, tolerance = 0.001, init_args = ()

    def _test_color_class(
        cls,
        cls_name,
        args,
        target,
        backend_compile=False,
        tolerance=1e-3,
        init_args=(),
    ):
        print(f"{cls.__module__}.{cls.__name__}")
    
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
    
        torch_obj = cls(*init_args)
        if cls_name:
            transpiled_obj = eval("transpiled_" + f"{cls_name}")(*init_args)
        else:
            transpiled_obj = eval("transpiled_" + f"{cls.__module__}.{cls.__name__}")(*init_args)
    
        torch_out = torch_obj(*args)
        transpile_args = _nest_torch_tensor_to_new_framework(args, target)
        transpiled_out = transpiled_obj(*transpile_args)
    
        orig_np = _nest_array_to_numpy(torch_out)
        graph_np = _nest_array_to_numpy(transpiled_out)
    
>       _check_allclose(orig_np, graph_np, tolerance=tolerance)

kornia/test_color.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[[ 0.02359531,  0.01399916,  0.01685725,  0.02942303,
           0.01422871],
         [ 0.01511236,  0.004654...   0.00459785],
         [ 0.00627287,  0.00656855, -0.00396166,  0.00371057,
           0.00789602]]]], dtype=float32)
y = array([[[[  81.37709   ,   44.796104  ,   61.653854  ,   92.30568   ,
            59.744255  ],
         [  59.1484   ...6  ],
         [  79.296684  ,   23.390255  ,   44.019882  ,  -40.217854  ,
            19.478718  ]]]], dtype=float32)
tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
>           assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
E           AssertionError: numpy array values are not all close

helpers.py:26: AssertionError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.color.luv.LuvToRgb
___________________________________________________________________________________ test_RgbToYuv420[jax-s2s-False] ____________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_RgbToYuv420(target_framework, mode, backend_compile):
        args = (
            torch.rand(2, 3, 4, 6),
        )
>       _test_color_class(
            kornia.color.RgbToYuv420,
            "kornia.color.RgbToYuv420",
            args,
            target_framework,
            backend_compile,
            tolerance=1e-3,
        )

kornia/test_color.py:1088: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'kornia.color.yuv.RgbToYuv420'>, cls_name = 'kornia.color.RgbToYuv420'
args = (tensor([[[[0.0787, 0.7670, 0.2185, 0.7589, 0.5183, 0.2042],
          [0.8347, 0.7635, 0.0018, 0.6180, 0.4573, 0.1838...     [0.6138, 0.2417, 0.0434, 0.3286, 0.7033, 0.1563],
          [0.8437, 0.6390, 0.8908, 0.1971, 0.7280, 0.8587]]]]),)
target = 'jax', backend_compile = False, tolerance = 0.001, init_args = ()

    def _test_color_class(
        cls,
        cls_name,
        args,
        target,
        backend_compile=False,
        tolerance=1e-3,
        init_args=(),
    ):
        print(f"{cls.__module__}.{cls.__name__}")
    
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
    
        torch_obj = cls(*init_args)
        if cls_name:
            transpiled_obj = eval("transpiled_" + f"{cls_name}")(*init_args)
        else:
            transpiled_obj = eval("transpiled_" + f"{cls.__module__}.{cls.__name__}")(*init_args)
    
        torch_out = torch_obj(*args)
        transpile_args = _nest_torch_tensor_to_new_framework(args, target)
        transpiled_out = transpiled_obj(*transpile_args)
    
        orig_np = _nest_array_to_numpy(torch_out)
        graph_np = _nest_array_to_numpy(transpiled_out)
    
>       _check_allclose(orig_np, graph_np, tolerance=tolerance)

kornia/test_color.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = (array([[[[0.6324681 , 0.411752  , 0.6019742 , 0.7860492 , 0.2808908 ,
          0.74512845],
         [0.69995385, 0....
        [[ 0.03138998, -0.0045669 , -0.00495549],
         [-0.09011918, -0.05559353, -0.05061496]]]], dtype=float32))
y = (array([[[[0.6324681 , 0.411752  , 0.6019742 , 0.7860492 , 0.2808908 ,
          0.74512845],
         [0.69995385, 0....
        [[ 0.02882006,  0.10453263, -0.16872466],
         [-0.02550593,  0.14833057, -0.26191276]]]], dtype=float32))
tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
            assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
            return
    
        if isinstance(x, (list, set, tuple)):
>           all([
                _check_allclose(element_x, element_y, tolerance=tolerance) for element_x, element_y in zip(x, y)
            ])

helpers.py:30: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

.0 = <zip object at 0x7fbb46cb4a40>

    all([
>       _check_allclose(element_x, element_y, tolerance=tolerance) for element_x, element_y in zip(x, y)
    ])

helpers.py:31: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[[ 0.10456963, -0.10723113,  0.11479031],
         [-0.1971286 ,  0.02851268, -0.01229935]],

        [[ 0.072...

        [[ 0.03138998, -0.0045669 , -0.00495549],
         [-0.09011918, -0.05559353, -0.05061496]]]], dtype=float32)
y = array([[[[-0.12106761,  0.00054524, -0.01711483],
         [-0.03832958,  0.11754052, -0.01036018]],

        [[-0.198...

        [[ 0.02882006,  0.10453263, -0.16872466],
         [-0.02550593,  0.14833057, -0.26191276]]]], dtype=float32)
tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
>           assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
E           AssertionError: numpy array values are not all close

helpers.py:26: AssertionError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.color.yuv.RgbToYuv420
__________________________________________________________________________________ test_apply_colormap[jax-s2s-False] __________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_apply_colormap(target_framework, mode, backend_compile):
        print("kornia.color.ColorMap")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target_framework)
    
        torch_x = torch.tensor([[[0, 1, 2], [15, 25, 33], [128, 158, 188]]])
        transpiled_x = _array_to_new_backend(torch_x, target_framework)
    
        colormap = kornia.color.ColorMap(base=kornia.color.ColorMapType.autumn)
        torch_out = kornia.color.apply_colormap(torch_x, colormap)
    
        transpiled_colormap = transpiled_kornia.color.ColorMap(base=transpiled_kornia.color.ColorMapType.autumn)
>       transpiled_out = transpiled_kornia.color.apply_colormap(transpiled_x, transpiled_colormap)

kornia/test_color.py:1285: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:230: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:153: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   AttributeError: module 'ivy_transpiled_outputs.jax_outputs.kornia.color.colormap' has no attribute 'jax_ColorMap'

IXC.pyx:162: AttributeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.color.ColorMap
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/test_color.py::test_rgb_to_hls[jax-s2s-False] - AssertionError: numpy array values are not all close
FAILED kornia/test_color.py::test_rgb_to_yuv420[jax-s2s-False] - AssertionError: numpy array values are not all close
FAILED kornia/test_color.py::test_RgbToHls[jax-s2s-False] - AssertionError: numpy array values are not all close
FAILED kornia/test_color.py::test_LuvToRgb[jax-s2s-False] - AssertionError: numpy array values are not all close
FAILED kornia/test_color.py::test_RgbToYuv420[jax-s2s-False] - AssertionError: numpy array values are not all close
FAILED kornia/test_color.py::test_apply_colormap[jax-s2s-False] - AttributeError: module 'ivy_transpiled_outputs.jax_outputs.kornia.color.colormap' has no attribute 'jax_ColorMap'
============================================================================== 6 failed, 63 passed in 4235.08s (1:10:35) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 39 items

kornia/test_enhance.py ....F....F...FFFFF........sssssssssssss                                                                                                                                   [100%]

=============================================================================================== FAILURES ===============================================================================================
__________________________________________________________________________________ test_adjust_gamma[numpy-s2s-False] __________________________________________________________________________________

target_framework = 'numpy', mode = 's2s', backend_compile = False

    def test_adjust_gamma(target_framework, mode, backend_compile):
        trace_args = (
            torch.rand(1, 1, 2, 2),
            2.2,
        )
        trace_kwargs = {}
        test_args = (
            torch.rand(5, 1, 2, 2),
            0.4,
        )
        test_kwargs = {}
>       _test_function(
            kornia.enhance.adjust_gamma,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/test_enhance.py:128: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function adjust_gamma at 0x7f57ef34d120>, trace_args = (tensor([[[[0.1534, 0.1552],
          [0.0250, 0.9341]]]]), 2.2), trace_kwargs = {}
test_args = (tensor([[[[0.1950, 0.7538],
          [0.5748, 0.3638]]],


        [[[0.7759, 0.9589],
          [0.4569, 0.7923]]],...   [[[0.0311, 0.1977],
          [0.6544, 0.9959]]],


        [[[0.9212, 0.9999],
          [0.8556, 0.3583]]]]), 0.4)
test_kwargs = {}, target = 'numpy', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function adjust_gamma at 0x7f57ef34d120>, fn_name = 'kornia.enhance.adjust_gamma', trace_args = (tensor([[[[0.1534, 0.1552],
          [0.0250, 0.9341]]]]), 2.2), trace_kwargs = {}
test_args = (tensor([[[[0.1950, 0.7538],
          [0.5748, 0.3638]]],


        [[[0.7759, 0.9589],
          [0.4569, 0.7923]]],...   [[[0.0311, 0.1977],
          [0.6544, 0.9959]]],


        [[[0.9212, 0.9999],
          [0.8556, 0.3583]]]]), 0.4)
test_kwargs = {}, target = 'numpy', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:232: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = array([[[[0.15340757, 0.15519744],
         [0.02504063, 0.93414474]]]], dtype=float32), gamma = 2.2, gain = 1.0

    def numpy_adjust_gamma(input, gamma, gain=1.0):
        from ...ivy.functional.frontends.torch.tensor import numpy_to_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_any_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_shape_frnt_
        from ...ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            numpy_unsqueeze_frnt,
        )
        from ...ivy.functional.frontends.torch.pointwise_ops import numpy_pow_frnt
        from ...ivy.functional.frontends.torch.pointwise_ops import numpy_clamp_frnt
    
        if not isinstance(input, (numpy.ndarray, numpy.ndarray)):
            raise TypeError(f"Input type is not a Tensor. Got {type(input)}")
        if not isinstance(gamma, (float, numpy.ndarray, numpy.ndarray)):
            raise TypeError(
                f"The gamma should be a positive float or Tensor. Got {type(gamma)}"
            )
        if not isinstance(gain, (float, numpy.ndarray, numpy.ndarray)):
            raise TypeError(
                f"The gain should be a positive float or Tensor. Got {type(gain)}"
            )
        if isinstance(gamma, (float,)):
>           gamma = numpy.ndarray([gamma])
E           TypeError: 'float' object cannot be interpreted as an integer

ivy_transpiled_outputs/numpy_outputs/kornia/enhance/adjust.py:52: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.enhance.adjust.adjust_gamma
_____________________________________________________________________________________ test_invert[numpy-s2s-False] _____________________________________________________________________________________

>   ???

VM.pyx:243: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    """
    Copyright (c) 2024 Transpile AI Ltd. All rights reserved.
    
    This file is automatically generated by Transpile AI Ltd.'s software.
    
    License: Non-Enterprise Use Only
    
    This software is licensed for personal, educational, or non-commercial use only.
    Non-commercial use includes personal projects, educational purposes, or other activities
    that do not generate revenue or are not used in any business, organization, or institution.
    Commercial, production, or enterprise use—including any use in a for-profit business environment, within an organization,
    or in a revenue-generating activity—is strictly prohibited without a valid enterprise contract with Transpile AI Ltd.
    Unauthorized enterprise use may result in legal action, including but not limited to injunctions, damages, and financial penalties.
    
    To obtain an enterprise license, please visit https://ivy.dev/ or contact enterprise@ivy.dev.
    
    Redistribution: You may not distribute, sublicense, or sell copies of the generated source code or
    any derivative works thereof without express written permission from Transpile AI Ltd.
    
    Termination: This license automatically terminates upon failure to comply with any of its terms and conditions.
    Upon termination, you must immediately cease all use of the software and destroy any copies in your possession.
    
    Disclaimer: This software is provided "AS IS", WITHOUT WARRANTY OF ANY KIND, either express or implied.
    Transpile AI Ltd. disclaims all liability for damages or liabilities arising from the use of this software, to the fullest extent permitted by law.
    """
    
    import numpy
    
    
>   def numpy_invert(image, max_val=numpy.ndarray([1.0])):
E   TypeError: 'float' object cannot be interpreted as an integer

ivy_transpiled_outputs/numpy_outputs/kornia/enhance/adjust.py:30: TypeError

During handling of the above exception, another exception occurred:

target_framework = 'numpy', mode = 's2s', backend_compile = False

    def test_invert(target_framework, mode, backend_compile):
        trace_args = (torch.rand(1, 1, 2, 2),)
        trace_kwargs = {}
        test_args = (torch.rand(5, 1, 2, 2),)
        test_kwargs = {}
>       _test_function(
            kornia.enhance.invert,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/test_enhance.py:244: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function invert at 0x7f57ef34dc60>, trace_args = (tensor([[[[0.9908, 0.9810],
          [0.1544, 0.4700]]]]),), trace_kwargs = {}
test_args = (tensor([[[[0.8403, 0.1394],
          [0.2660, 0.7570]]],


        [[[0.9910, 0.0199],
          [0.3975, 0.6422]]],...       [[[0.8084, 0.7884],
          [0.2169, 0.4637]]],


        [[[0.6911, 0.4757],
          [0.9052, 0.3841]]]]),)
test_kwargs = {}, target = 'numpy', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function invert at 0x7f57ef34dc60>, fn_name = 'kornia.enhance.invert', trace_args = (tensor([[[[0.9908, 0.9810],
          [0.1544, 0.4700]]]]),), trace_kwargs = {}
test_args = (tensor([[[[0.8403, 0.1394],
          [0.2660, 0.7570]]],


        [[[0.9910, 0.0199],
          [0.3975, 0.6422]]],...       [[[0.8084, 0.7884],
          [0.2169, 0.4637]]],


        [[[0.6911, 0.4757],
          [0.9052, 0.3841]]]]),)
test_kwargs = {}, target = 'numpy', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:221: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:322: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:310: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:300: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXL.pyx:24: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

MC.pyx:159: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   ImportError: Error loading module ivy_transpiled_outputs.numpy_outputs.kornia.enhance.adjust: 'float' object cannot be interpreted as an integer

VM.pyx:246: ImportError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.enhance.adjust.invert
____________________________________________________________________________________ test_equalize[numpy-s2s-False] ____________________________________________________________________________________

target_framework = 'numpy', mode = 's2s', backend_compile = False

    def test_equalize(target_framework, mode, backend_compile):
        trace_args = (torch.rand(1, 2, 3, 3),)
        trace_kwargs = {}
        test_args = (torch.rand(5, 2, 3, 3),)
        test_kwargs = {}
>       _test_function(
            kornia.enhance.equalize,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
            skip=True,
        )

kornia/test_enhance.py:335: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function equalize at 0x7f57ef34dab0>
trace_args = (tensor([[[[0.5081, 0.6426, 0.6664],
          [0.1968, 0.5203, 0.0629],
          [0.2276, 0.0820, 0.6078]],

         [[0.2231, 0.4268, 0.7296],
          [0.5917, 0.7261, 0.7544],
          [0.2676, 0.1559, 0.8787]]]]),)
trace_kwargs = {}
test_args = (tensor([[[[0.6166, 0.6726, 0.4183],
          [0.0243, 0.8145, 0.6922],
          [0.4919, 0.6265, 0.5870]],

       ...38]],

         [[0.6217, 0.3649, 0.9991],
          [0.3045, 0.5754, 0.8594],
          [0.6790, 0.8134, 0.5091]]]]),)
test_kwargs = {}, target = 'numpy', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = True, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function equalize at 0x7f57ef34dab0>, fn_name = 'kornia.enhance.equalize'
trace_args = (tensor([[[[0.5081, 0.6426, 0.6664],
          [0.1968, 0.5203, 0.0629],
          [0.2276, 0.0820, 0.6078]],

         [[0.2231, 0.4268, 0.7296],
          [0.5917, 0.7261, 0.7544],
          [0.2676, 0.1559, 0.8787]]]]),)
trace_kwargs = {}
test_args = (tensor([[[[0.6166, 0.6726, 0.4183],
          [0.0243, 0.8145, 0.6922],
          [0.4919, 0.6265, 0.5870]],

       ...38]],

         [[0.6217, 0.3649, 0.9991],
          [0.3045, 0.5754, 0.8594],
          [0.6790, 0.8134, 0.5091]]]]),)
test_kwargs = {}, target = 'numpy', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:232: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = array([[[[0.50810117, 0.6426117 , 0.6663675 ],
         [0.19678187, 0.5203157 , 0.06288391],
         [0.22760475, 0....5733 ],
         [0.5917307 , 0.7261339 , 0.75443625],
         [0.26763773, 0.15590554, 0.87872237]]]], dtype=float32)
args = (), kwargs = {}, numpy_numel_frnt_ = <function numpy_numel_frnt_ at 0x7f579653fb50>, numpy_shape_frnt_ = <function numpy_shape_frnt_ at 0x7f579653cc10>
numpy_view_frnt_ = <function numpy_view_frnt_ at 0x7f579653feb0>, input_shape = ivy.frontends.torch.Size([1, 2, 3, 3])

    @wraps(f)
    def _wrapper(input, *args, **kwargs):
        from ...ivy.functional.frontends.torch.tensor import numpy_numel_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_view_frnt_
    
        if not isinstance(input, (numpy.ndarray, numpy.ndarray)):
            raise TypeError(f"Input input type is not a Tensor. Got {type(input)}")
        if numpy_numel_frnt_(input) == 0:
            raise ValueError("Invalid input tensor, it is empty.")
        input_shape = numpy_shape_frnt_(input)
        input = numpy__to_bchw(input)
>       output = f(input, *args, **kwargs)

ivy_transpiled_outputs/numpy_outputs/kornia/utils/image.py:70: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = array([[[[0.50810117, 0.6426117 , 0.6663675 ],
         [0.19678187, 0.5203157 , 0.06288391],
         [0.22760475, 0....5733 ],
         [0.5917307 , 0.7261339 , 0.75443625],
         [0.26763773, 0.15590554, 0.87872237]]]], dtype=float32)

    @numpy_perform_keep_shape_image
    def numpy_equalize(input):
        from ...ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            numpy_stack_frnt,
        )
        from ...ivy.functional.backends.numpy.general import numpy_get_item
    
        res = []
        for image in input:
            scaled_image = numpy_stack_frnt(
>               [
                    numpy__scale_channel(
                        numpy_get_item(
                            image, (i, slice(None, None, None), slice(None, None, None))
                        )
                    )
                    for i in range(len(image))
                ]
            )

ivy_transpiled_outputs/numpy_outputs/kornia/enhance/adjust.py:111: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

.0 = <range_iterator object at 0x7f57969a65e0>

        [
>           numpy__scale_channel(
                numpy_get_item(
                    image, (i, slice(None, None, None), slice(None, None, None))
                )
            )
            for i in range(len(image))
        ]
    )

ivy_transpiled_outputs/numpy_outputs/kornia/enhance/adjust.py:112: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

im = array([[129.5658  , 163.86598 , 169.9237  ],
       [ 50.17938 , 132.68051 ,  16.035398],
       [ 58.03921 ,  20.898636, 154.98283 ]], dtype=float32)

    def numpy__scale_channel(im):
        from ...ivy.functional.frontends.torch.tensor import numpy_min_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_max_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_item_frnt_
        from ...ivy.functional.frontends.torch.comparison_ops import numpy_isclose_frnt
        from ...ivy.functional.frontends.torch.creation_ops import numpy_as_tensor_frnt
        from ...ivy.functional.frontends.torch.tensor import numpy_shape_frnt_
        from ..utils.helpers import numpy__torch_histc_cast
        from ...ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            numpy_reshape_frnt,
        )
        from ...ivy.functional.backends.numpy.general import numpy_get_item
        from ...ivy.functional.frontends.torch.pointwise_ops import numpy_div_frnt
        from ...ivy.functional.frontends.torch.reduction_ops import numpy_sum_frnt
        from ...ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            numpy_gather_frnt,
        )
        from ...ivy.functional.frontends.torch.tensor import numpy_long_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_flatten_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_reshape_as_frnt_
    
        min_ = numpy_min_frnt_(im)
        max_ = numpy_max_frnt_(im)
        if numpy_item_frnt_(min_) < 0.0 and not numpy_isclose_frnt(
            min_, numpy_as_tensor_frnt(0.0, dtype=min_.dtype)
        ):
            raise ValueError(
                f"Values in the input tensor must greater or equal to 0.0. Found {numpy_item_frnt_(min_)}."
            )
        if numpy_item_frnt_(max_) > 1.0 and not numpy_isclose_frnt(
            max_, numpy_as_tensor_frnt(1.0, dtype=max_.dtype)
        ):
            raise ValueError(
                f"Values in the input tensor must lower or equal to 1.0. Found {numpy_item_frnt_(max_)}."
            )
        ndims = len(numpy_shape_frnt_(im))
        if ndims not in (2, 3):
            raise TypeError(f"Input tensor must have 2 or 3 dimensions. Found {ndims}.")
        im = im * 255.0
        histo = numpy__torch_histc_cast(im, bins=256, min=0, max=255)
        nonzero_histo = numpy_reshape_frnt(numpy_get_item(histo, histo != 0), [-1])
>       step = numpy_div_frnt(
            numpy_sum_frnt(nonzero_histo) - nonzero_histo[-1], 255, rounding_mode="trunc"
        )

ivy_transpiled_outputs/numpy_outputs/kornia/enhance/adjust.py:88: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = 8.0, other = 255

    def numpy_div_frnt(input, other, *, rounding_mode=None, out=None):
        from .__init__ import numpy_promote_types_of_torch_inputs_frnt
        from ...backends.numpy.data_type import numpy_astype
        from ...ivy.elementwise import numpy_trunc_divide_bknd
        from ...backends.numpy.elementwise import numpy_floor_divide
        from ...backends.numpy.elementwise import numpy_divide
    
>       input, other = numpy_promote_types_of_torch_inputs_frnt(input, other)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/pointwise_ops.py:55: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x1 = array(8., dtype=float32), x2 = array(255)

    def numpy_promote_types_of_torch_inputs_frnt(x1, x2, /):
        from ...ivy.general import numpy_isscalar_bknd
        from ...ivy.data_type import numpy_is_int_dtype_bknd
        from ...backends.numpy.creation import numpy_asarray
        from ...ivy.data_type import numpy_default_dtype_bknd
        from .tensor import numpy_shape_frnt_
        from ...ivy.device import numpy_default_device_bknd
        from ....data_classes.array.data_type import numpy_astype_bknd_
    
        """Promote the dtype of the given native array inputs to a common dtype
        based on type promotion rules.
    
        While passing float or integer values or any other non-array input
        to this function, it should be noted that the return will be an
        array-like object. Therefore, outputs from this function should be
        used as inputs only for those functions that expect an array-like or
        tensor-like objects, otherwise it might give unexpected results.
        """
        if (
            numpy_isscalar_bknd(x1) or isinstance(x1, (list, tuple))
        ) and numpy_is_int_dtype_bknd(x1):
            x1 = numpy_asarray(x1, dtype="int64")
        elif numpy_isscalar_bknd(x1) or isinstance(x1, (list, tuple)):
            x1 = numpy_asarray(x1)
        if (
            numpy_isscalar_bknd(x2) or isinstance(x2, (list, tuple))
        ) and numpy_is_int_dtype_bknd(x2):
            x2 = numpy_asarray(x2, dtype="int64")
        elif numpy_isscalar_bknd(x2) or isinstance(x2, (list, tuple)):
            x2 = numpy_asarray(x2)
        type1 = numpy_default_dtype_bknd(item=x1).strip("u123456789")
        type2 = numpy_default_dtype_bknd(item=x2).strip("u123456789")
        if numpy_shape_frnt_(x1) != () and numpy_shape_frnt_(x2) == () and type1 == type2:
            x2 = numpy_asarray(
                x2,
                dtype=x1.dtype,
                device=numpy_default_device_bknd(item=x1, as_native=False),
            )
        elif numpy_shape_frnt_(x1) == () and numpy_shape_frnt_(x2) != () and type1 == type2:
            x1 = numpy_asarray(
                x1,
                dtype=x2.dtype,
                device=numpy_default_device_bknd(item=x2, as_native=False),
            )
        elif x1.dtype != x2.dtype:
>           promoted = numpy_promote_types_torch_frnt(x1.dtype, x2.dtype)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/__init__.py:87: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

type1 = dtype('float32'), type2 = dtype('int64')

    def numpy_promote_types_torch_frnt(type1, type2, /):
        from ...backends.numpy.general import numpy_get_item
        from ...backends.numpy.data_type import numpy_as_ivy_dtype
    
        try:
            ret = numpy_get_item(
>               torch_promotion_table,
                (numpy_as_ivy_dtype(type1), numpy_as_ivy_dtype(type2)),
            )
E           NameError: name 'torch_promotion_table' is not defined

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/__init__.py:34: NameError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.enhance.adjust.equalize
_________________________________________________________________________________ test_equalize_clahe[numpy-s2s-False] _________________________________________________________________________________

target_framework = 'numpy', mode = 's2s', backend_compile = False

    def test_equalize_clahe(target_framework, mode, backend_compile):
        trace_args = (torch.rand(1, 10, 20),)
        trace_kwargs = {
            "clip_limit": 40.0,
            "grid_size": (8, 8),
            "slow_and_differentiable": False,
        }
        test_args = (torch.rand(2, 3, 10, 20),)
        test_kwargs = {
            "clip_limit": 20.0,
            "grid_size": (4, 4),
            "slow_and_differentiable": False,
        }
>       _test_function(
            kornia.enhance.equalize_clahe,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
            skip=True,
        )

kornia/test_enhance.py:363: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function equalize_clahe at 0x7f57ef34fa30>
trace_args = (tensor([[[0.3415, 0.0422, 0.3106, 0.8687, 0.8347, 0.4038, 0.9360, 0.1244,
          0.6172, 0.2648, 0.3739, 0.7349, 0...         0.4953, 0.0086, 0.0456, 0.7171, 0.2669, 0.4052, 0.3305, 0.6870,
          0.5742, 0.9330, 0.8751, 0.3679]]]),)
trace_kwargs = {'clip_limit': 40.0, 'grid_size': (8, 8), 'slow_and_differentiable': False}
test_args = (tensor([[[[0.1487, 0.0464, 0.3009,  ..., 0.1185, 0.3830, 0.5653],
          [0.2623, 0.0536, 0.5782,  ..., 0.3440, 0...., 0.6720, 0.0947,  ..., 0.8555, 0.1602, 0.9982],
          [0.3832, 0.5014, 0.7500,  ..., 0.9978, 0.1974, 0.2731]]]]),)
test_kwargs = {'clip_limit': 20.0, 'grid_size': (4, 4), 'slow_and_differentiable': False}, target = 'numpy', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = True, deterministic = True
class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function equalize_clahe at 0x7f57ef34fa30>, fn_name = 'kornia.enhance.equalize_clahe'
trace_args = (tensor([[[0.3415, 0.0422, 0.3106, 0.8687, 0.8347, 0.4038, 0.9360, 0.1244,
          0.6172, 0.2648, 0.3739, 0.7349, 0...         0.4953, 0.0086, 0.0456, 0.7171, 0.2669, 0.4052, 0.3305, 0.6870,
          0.5742, 0.9330, 0.8751, 0.3679]]]),)
trace_kwargs = {'clip_limit': 40.0, 'grid_size': (8, 8), 'slow_and_differentiable': False}
test_args = (tensor([[[[0.1487, 0.0464, 0.3009,  ..., 0.1185, 0.3830, 0.5653],
          [0.2623, 0.0536, 0.5782,  ..., 0.3440, 0...., 0.6720, 0.0947,  ..., 0.8555, 0.1602, 0.9982],
          [0.3832, 0.5014, 0.7500,  ..., 0.9978, 0.1974, 0.2731]]]]),)
test_kwargs = {'clip_limit': 20.0, 'grid_size': (4, 4), 'slow_and_differentiable': False}, target = 'numpy', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:232: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = array([[[[0.34147555, 0.04218149, 0.31063813, 0.86870193, 0.8346968 ,
          0.40377092, 0.93596345, 0.12436759, 0.... 0.40517843, 0.330467  ,
          0.6870346 , 0.57423395, 0.9330198 , 0.87509847, 0.3679049 ]]]],
      dtype=float32)
args = (), kwargs = {'clip_limit': 40.0, 'grid_size': (8, 8), 'slow_and_differentiable': False}, numpy_numel_frnt_ = <function numpy_numel_frnt_ at 0x7f5796297760>
numpy_shape_frnt_ = <function numpy_shape_frnt_ at 0x7f579621c3a0>, numpy_view_frnt_ = <function numpy_view_frnt_ at 0x7f57962967a0>, input_shape = ivy.frontends.torch.Size([1, 10, 20])

    @wraps(f)
    def _wrapper(input, *args, **kwargs):
        from ...ivy.functional.frontends.torch.tensor import numpy_numel_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_view_frnt_
    
        if not isinstance(input, (numpy.ndarray, numpy.ndarray)):
            raise TypeError(f"Input input type is not a Tensor. Got {type(input)}")
        if numpy_numel_frnt_(input) == 0:
            raise ValueError("Invalid input tensor, it is empty.")
        input_shape = numpy_shape_frnt_(input)
        input = numpy__to_bchw(input)
>       output = f(input, *args, **kwargs)

ivy_transpiled_outputs/numpy_outputs/kornia/utils/image.py:70: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = array([[[[0.34147555, 0.04218149, 0.31063813, 0.86870193, 0.8346968 ,
          0.40377092, 0.93596345, 0.12436759, 0.... 0.40517843, 0.330467  ,
          0.6870346 , 0.57423395, 0.9330198 , 0.87509847, 0.3679049 ]]]],
      dtype=float32)
clip_limit = 40.0, grid_size = (8, 8), slow_and_differentiable = False

    @numpy_perform_keep_shape_image
    def numpy_equalize_clahe(
        input, clip_limit=40.0, grid_size=(8, 8), slow_and_differentiable=False
    ):
        from ...ivy.functional.frontends.torch.tensor import numpy_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_reshape_as_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_permute_frnt_
        from ...ivy.functional.backends.numpy.general import numpy_get_item
        from ...ivy.functional.frontends.torch.tensor import numpy_dim_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_squeeze_frnt_
    
        if not isinstance(clip_limit, (float,)):
            raise TypeError(f"Input clip_limit type is not float. Got {type(clip_limit)}")
        if not isinstance(grid_size, (tuple,)):
            raise TypeError(f"Input grid_size type is not Tuple. Got {type(grid_size)}")
        if len(grid_size) != 2:
            raise TypeError(
                f"Input grid_size is not a Tuple with 2 elements. Got {len(grid_size)}"
            )
        if isinstance(grid_size[0], (float,)) or isinstance(grid_size[1], (float,)):
            raise TypeError("Input grid_size type is not valid, must be a Tuple[int, int].")
        if grid_size[0] <= 0 or grid_size[1] <= 0:
            raise ValueError(f"Input grid_size elements must be positive. Got {grid_size}")
        imgs: typing.Any = input
>       hist_tiles, img_padded = numpy__compute_tiles(imgs, grid_size, True)

ivy_transpiled_outputs/numpy_outputs/kornia/enhance/equalization.py:490: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

imgs = array([[[[0.34147555, 0.04218149, 0.31063813, 0.86870193, 0.8346968 ,
          0.40377092, 0.93596345, 0.12436759, 0.... 0.40517843, 0.330467  ,
          0.6870346 , 0.57423395, 0.9330198 , 0.87509847, 0.3679049 ]]]],
      dtype=float32)
grid_size = (8, 8), even_tile_size = True

    def numpy__compute_tiles(imgs, grid_size, even_tile_size=False):
        from ...ivy.functional.frontends.torch.tensor import numpy_shape_frnt_
        from ...ivy.functional.frontends.torch.nn.functional.vision_functions import (
            numpy_pad_frnt,
        )
        from ...ivy.functional.frontends.torch.tensor import numpy_contiguous_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_squeeze_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_unfold_frnt_
    
        batch: typing.Any = imgs
        h, w = numpy_shape_frnt_(batch)[-2:][0], numpy_shape_frnt_(batch)[-2:][1]
        kernel_vert: typing.Any = math.ceil(h / grid_size[0])
        kernel_horz: typing.Any = math.ceil(w / grid_size[1])
        if even_tile_size:
            kernel_vert = kernel_vert + (1 if kernel_vert % 2 else 0)
            kernel_horz = kernel_horz + (1 if kernel_horz % 2 else 0)
        pad_vert = kernel_vert * grid_size[0] - h
        pad_horz = kernel_horz * grid_size[1] - w
        if (
            pad_vert > numpy_shape_frnt_(batch)[-2]
            or pad_horz > numpy_shape_frnt_(batch)[-1]
        ):
            raise ValueError(
                "Cannot compute tiles on the image according to the given grid size"
            )
        if pad_vert > 0 or pad_horz > 0:
            batch = numpy_pad_frnt(batch, [0, pad_horz, 0, pad_vert], mode="reflect")
        c: typing.Any = numpy_shape_frnt_(batch)[-3]
        tiles: typing.Any = numpy_contiguous_frnt_(
            numpy_squeeze_frnt_(
                numpy_unfold_frnt_(
>                   numpy_unfold_frnt_(
                        numpy_unfold_frnt_(batch, 1, c, c), 2, kernel_vert, kernel_vert
                    ),
                    3,
                    kernel_horz,
                    kernel_horz,
                ),
                1,
            )
        )

ivy_transpiled_outputs/numpy_outputs/kornia/enhance/equalization.py:64: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (array([[[[[0.34147555, 0.4171694 , 0.2783894 , 0.02694857, 0.58610755,
           0.32486188, 0.2948526 , 0.42060798,...       0.36795843, 0.7225116 , 0.47842324, 0.6918013 , 0.16143477,
           0.04965281]]]]], dtype=float32), 2, 2, 2)
kwargs = {}, numpy_is_array_bknd = <function numpy_is_array_bknd at 0x7f5795a21870>
array_like = array([[[[[0.34147555, 0.4171694 , 0.2783894 , 0.02694857, 0.58610755,
           0.32486188, 0.2948526 , 0.42060798, ...401 ,
           0.36795843, 0.7225116 , 0.47842324, 0.6918013 , 0.16143477,
           0.04965281]]]]], dtype=float32)

    @functools.wraps(fn)
    def wrapper(*args, **kwargs):
        from ..functional.ivy.general import numpy_is_array_bknd
    
        array_like = args[0]
        if hasattr(array_like, "__class__") and array_like.__class__.__name__ in [
            "list",
            "tuple",
        ]:
            array_like = array_like[0]
        if numpy_is_array_bknd(array_like):
>           return fn(*args, **kwargs)

ivy_transpiled_outputs/numpy_outputs/ivy/utils/decorator_utils.py:200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = array([[[[[0.34147555, 0.4171694 , 0.2783894 , 0.02694857, 0.58610755,
           0.32486188, 0.2948526 , 0.42060798, ...401 ,
           0.36795843, 0.7225116 , 0.47842324, 0.6918013 , 0.16143477,
           0.04965281]]]]], dtype=float32)
dimension = 2, size = 2, step = 2

    @numpy_handle_methods
    def numpy_unfold_frnt_(tensor, dimension, size, step):
        from ...backends.numpy.general import numpy_get_item
        from ...backends.numpy.general import numpy_set_item
        from .indexing_slicing_joining_mutating_ops import numpy_stack_frnt
    
        slices = []
        self_shape = tuple(numpy_shape_frnt_(tensor))
        for i in range(0, numpy_get_item(self_shape, dimension) - size + 1, step):
            slicing = [slice(None)] * len(numpy_shape_frnt_(tensor))
            slicing = numpy_set_item(slicing, dimension, slice(i, i + size))
            slices.append(numpy_get_item(tensor, tuple(slicing)))
>       stacked = numpy_stack_frnt(slices, dim=dimension)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/tensor.py:257: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensors = [], dim = 2

    def numpy_stack_frnt(tensors, dim=0, *, out=None):
        from ...backends.numpy.manipulation import numpy_stack
    
>       return numpy_stack(tensors, axis=dim, out=out)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/indexing_slicing_joining_mutating_ops.py:119: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

arrays = []

    def numpy_stack(
        arrays: Union[Tuple[np.ndarray], List[np.ndarray]],
        /,
        *,
        axis: int = 0,
        out: Optional[np.ndarray] = None,
    ):
>       return np.stack(arrays, axis, out=out)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/backends/numpy/manipulation.py:117: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

arrays = [], axis = 2, out = None

    @array_function_dispatch(_stack_dispatcher)
    def stack(arrays, axis=0, out=None, *, dtype=None, casting="same_kind"):
        """
        Join a sequence of arrays along a new axis.
    
        The ``axis`` parameter specifies the index of the new axis in the
        dimensions of the result. For example, if ``axis=0`` it will be the first
        dimension and if ``axis=-1`` it will be the last dimension.
    
        .. versionadded:: 1.10.0
    
        Parameters
        ----------
        arrays : sequence of array_like
            Each array must have the same shape.
    
        axis : int, optional
            The axis in the result array along which the input arrays are stacked.
    
        out : ndarray, optional
            If provided, the destination to place the result. The shape must be
            correct, matching that of what stack would have returned if no
            out argument were specified.
    
        dtype : str or dtype
            If provided, the destination array will have this dtype. Cannot be
            provided together with `out`.
    
            .. versionadded:: 1.24
    
        casting : {'no', 'equiv', 'safe', 'same_kind', 'unsafe'}, optional
            Controls what kind of data casting may occur. Defaults to 'same_kind'.
    
            .. versionadded:: 1.24
    
    
        Returns
        -------
        stacked : ndarray
            The stacked array has one more dimension than the input arrays.
    
        See Also
        --------
        concatenate : Join a sequence of arrays along an existing axis.
        block : Assemble an nd-array from nested lists of blocks.
        split : Split array into a list of multiple sub-arrays of equal size.
    
        Examples
        --------
        >>> arrays = [np.random.randn(3, 4) for _ in range(10)]
        >>> np.stack(arrays, axis=0).shape
        (10, 3, 4)
    
        >>> np.stack(arrays, axis=1).shape
        (3, 10, 4)
    
        >>> np.stack(arrays, axis=2).shape
        (3, 4, 10)
    
        >>> a = np.array([1, 2, 3])
        >>> b = np.array([4, 5, 6])
        >>> np.stack((a, b))
        array([[1, 2, 3],
               [4, 5, 6]])
    
        >>> np.stack((a, b), axis=-1)
        array([[1, 4],
               [2, 5],
               [3, 6]])
    
        """
        arrays = [asanyarray(arr) for arr in arrays]
        if not arrays:
>           raise ValueError('need at least one array to stack')
E           ValueError: need at least one array to stack

/opt/fw/mxnet/numpy/core/shape_base.py:445: ValueError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.enhance.equalization.equalize_clahe
___________________________________________________________________________________ test_equalize3d[numpy-s2s-False] ___________________________________________________________________________________

target_framework = 'numpy', mode = 's2s', backend_compile = False

    def test_equalize3d(target_framework, mode, backend_compile):
        trace_args = (torch.rand(1, 2, 3, 3, 3),)
        trace_kwargs = {}
        test_args = (torch.rand(5, 2, 3, 3, 3),)
        test_kwargs = {}
>       _test_function(
            kornia.enhance.equalize3d,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
            skip=True,
        )

kornia/test_enhance.py:383: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function equalize3d at 0x7f57ef34dbd0>
trace_args = (tensor([[[[[0.9841, 0.2656, 0.1803],
           [0.4314, 0.1523, 0.6733],
           [0.2456, 0.2658, 0.2294]],

    ...,

          [[0.9528, 0.8031, 0.8701],
           [0.2810, 0.8990, 0.7645],
           [0.8383, 0.8507, 0.2981]]]]]),)
trace_kwargs = {}
test_args = (tensor([[[[[0.1383, 0.2518, 0.7341],
           [0.5559, 0.1353, 0.7175],
           [0.5998, 0.8919, 0.3899]],

    ...,

          [[0.9329, 0.9253, 0.1331],
           [0.7418, 0.1232, 0.5925],
           [0.8601, 0.2477, 0.5347]]]]]),)
test_kwargs = {}, target = 'numpy', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = True, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function equalize3d at 0x7f57ef34dbd0>, fn_name = 'kornia.enhance.equalize3d'
trace_args = (tensor([[[[[0.9841, 0.2656, 0.1803],
           [0.4314, 0.1523, 0.6733],
           [0.2456, 0.2658, 0.2294]],

    ...,

          [[0.9528, 0.8031, 0.8701],
           [0.2810, 0.8990, 0.7645],
           [0.8383, 0.8507, 0.2981]]]]]),)
trace_kwargs = {}
test_args = (tensor([[[[[0.1383, 0.2518, 0.7341],
           [0.5559, 0.1353, 0.7175],
           [0.5998, 0.8919, 0.3899]],

    ...,

          [[0.9329, 0.9253, 0.1331],
           [0.7418, 0.1232, 0.5925],
           [0.8601, 0.2477, 0.5347]]]]]),)
test_kwargs = {}, target = 'numpy', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:232: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = array([[[[[0.9841399 , 0.26555973, 0.18033803],
          [0.43138307, 0.15229684, 0.6732851 ],
          [0.24556392,...45],
          [0.28095716, 0.8989825 , 0.7644756 ],
          [0.8383485 , 0.85072005, 0.29808998]]]]], dtype=float32)
args = (), kwargs = {}, numpy_numel_frnt_ = <function numpy_numel_frnt_ at 0x7f5796a8b2e0>, numpy_shape_frnt_ = <function numpy_shape_frnt_ at 0x7f5796a8a3b0>
numpy_view_frnt_ = <function numpy_view_frnt_ at 0x7f5796a8add0>, input_shape = ivy.frontends.torch.Size([1, 2, 3, 3, 3])

    @wraps(f)
    def _wrapper(input, *args, **kwargs):
        from ...ivy.functional.frontends.torch.tensor import numpy_numel_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_view_frnt_
    
        if not isinstance(input, (numpy.ndarray, numpy.ndarray)):
            raise TypeError(f"Input input type is not a Tensor. Got {type(input)}")
        if numpy_numel_frnt_(input) == 0:
            raise ValueError("Invalid input tensor, it is empty.")
        input_shape = numpy_shape_frnt_(input)
        input = numpy__to_bcdhw(input)
>       output = f(input, *args, **kwargs)

ivy_transpiled_outputs/numpy_outputs/kornia/utils/image.py:71: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = array([[[[[0.9841399 , 0.26555973, 0.18033803],
          [0.43138307, 0.15229684, 0.6732851 ],
          [0.24556392,...45],
          [0.28095716, 0.8989825 , 0.7644756 ],
          [0.8383485 , 0.85072005, 0.29808998]]]]], dtype=float32)

    @numpy_perform_keep_shape_video
    def numpy_equalize3d(input):
        from ...ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            numpy_stack_frnt,
        )
        from ...ivy.functional.backends.numpy.general import numpy_get_item
    
        res = []
        for volume in input:
            scaled_input = numpy_stack_frnt(
>               [
                    numpy__scale_channel(
                        numpy_get_item(
                            volume,
                            (
                                i,
                                slice(None, None, None),
                                slice(None, None, None),
                                slice(None, None, None),
                            ),
                        )
                    )
                    for i in range(len(volume))
                ]
            )

ivy_transpiled_outputs/numpy_outputs/kornia/enhance/adjust.py:111: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

.0 = <range_iterator object at 0x7f579665fd50>

        [
>           numpy__scale_channel(
                numpy_get_item(
                    volume,
                    (
                        i,
                        slice(None, None, None),
                        slice(None, None, None),
                        slice(None, None, None),
                    ),
                )
            )
            for i in range(len(volume))
        ]
    )

ivy_transpiled_outputs/numpy_outputs/kornia/enhance/adjust.py:112: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

im = array([[[250.95567 ,  67.717735,  45.986195],
        [110.002686,  38.835693, 171.68771 ],
        [ 62.6188  ,  67.7...3.410587],
        [181.71002 , 179.63675 , 145.45728 ],
        [249.70871 , 218.62291 ,  27.481903]]], dtype=float32)

    def numpy__scale_channel(im):
        from ...ivy.functional.frontends.torch.tensor import numpy_min_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_max_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_item_frnt_
        from ...ivy.functional.frontends.torch.comparison_ops import numpy_isclose_frnt
        from ...ivy.functional.frontends.torch.creation_ops import numpy_as_tensor_frnt
        from ...ivy.functional.frontends.torch.tensor import numpy_shape_frnt_
        from ..utils.helpers import numpy__torch_histc_cast
        from ...ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            numpy_reshape_frnt,
        )
        from ...ivy.functional.backends.numpy.general import numpy_get_item
        from ...ivy.functional.frontends.torch.pointwise_ops import numpy_div_frnt
        from ...ivy.functional.frontends.torch.reduction_ops import numpy_sum_frnt
        from ...ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            numpy_gather_frnt,
        )
        from ...ivy.functional.frontends.torch.tensor import numpy_long_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_flatten_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_reshape_as_frnt_
    
        min_ = numpy_min_frnt_(im)
        max_ = numpy_max_frnt_(im)
        if numpy_item_frnt_(min_) < 0.0 and not numpy_isclose_frnt(
            min_, numpy_as_tensor_frnt(0.0, dtype=min_.dtype)
        ):
            raise ValueError(
                f"Values in the input tensor must greater or equal to 0.0. Found {numpy_item_frnt_(min_)}."
            )
        if numpy_item_frnt_(max_) > 1.0 and not numpy_isclose_frnt(
            max_, numpy_as_tensor_frnt(1.0, dtype=max_.dtype)
        ):
            raise ValueError(
                f"Values in the input tensor must lower or equal to 1.0. Found {numpy_item_frnt_(max_)}."
            )
        ndims = len(numpy_shape_frnt_(im))
        if ndims not in (2, 3):
            raise TypeError(f"Input tensor must have 2 or 3 dimensions. Found {ndims}.")
        im = im * 255.0
        histo = numpy__torch_histc_cast(im, bins=256, min=0, max=255)
        nonzero_histo = numpy_reshape_frnt(numpy_get_item(histo, histo != 0), [-1])
>       step = numpy_div_frnt(
            numpy_sum_frnt(nonzero_histo) - nonzero_histo[-1], 255, rounding_mode="trunc"
        )

ivy_transpiled_outputs/numpy_outputs/kornia/enhance/adjust.py:88: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = 26.0, other = 255

    def numpy_div_frnt(input, other, *, rounding_mode=None, out=None):
        from .__init__ import numpy_promote_types_of_torch_inputs_frnt
        from ...backends.numpy.data_type import numpy_astype
        from ...ivy.elementwise import numpy_trunc_divide_bknd
        from ...backends.numpy.elementwise import numpy_floor_divide
        from ...backends.numpy.elementwise import numpy_divide
    
>       input, other = numpy_promote_types_of_torch_inputs_frnt(input, other)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/pointwise_ops.py:55: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x1 = array(26., dtype=float32), x2 = array(255)

    def numpy_promote_types_of_torch_inputs_frnt(x1, x2, /):
        from ...ivy.general import numpy_isscalar_bknd
        from ...ivy.data_type import numpy_is_int_dtype_bknd
        from ...backends.numpy.creation import numpy_asarray
        from ...ivy.data_type import numpy_default_dtype_bknd
        from .tensor import numpy_shape_frnt_
        from ...ivy.device import numpy_default_device_bknd
        from ....data_classes.array.data_type import numpy_astype_bknd_
    
        """Promote the dtype of the given native array inputs to a common dtype
        based on type promotion rules.
    
        While passing float or integer values or any other non-array input
        to this function, it should be noted that the return will be an
        array-like object. Therefore, outputs from this function should be
        used as inputs only for those functions that expect an array-like or
        tensor-like objects, otherwise it might give unexpected results.
        """
        if (
            numpy_isscalar_bknd(x1) or isinstance(x1, (list, tuple))
        ) and numpy_is_int_dtype_bknd(x1):
            x1 = numpy_asarray(x1, dtype="int64")
        elif numpy_isscalar_bknd(x1) or isinstance(x1, (list, tuple)):
            x1 = numpy_asarray(x1)
        if (
            numpy_isscalar_bknd(x2) or isinstance(x2, (list, tuple))
        ) and numpy_is_int_dtype_bknd(x2):
            x2 = numpy_asarray(x2, dtype="int64")
        elif numpy_isscalar_bknd(x2) or isinstance(x2, (list, tuple)):
            x2 = numpy_asarray(x2)
        type1 = numpy_default_dtype_bknd(item=x1).strip("u123456789")
        type2 = numpy_default_dtype_bknd(item=x2).strip("u123456789")
        if numpy_shape_frnt_(x1) != () and numpy_shape_frnt_(x2) == () and type1 == type2:
            x2 = numpy_asarray(
                x2,
                dtype=x1.dtype,
                device=numpy_default_device_bknd(item=x1, as_native=False),
            )
        elif numpy_shape_frnt_(x1) == () and numpy_shape_frnt_(x2) != () and type1 == type2:
            x1 = numpy_asarray(
                x1,
                dtype=x2.dtype,
                device=numpy_default_device_bknd(item=x2, as_native=False),
            )
        elif x1.dtype != x2.dtype:
>           promoted = numpy_promote_types_torch_frnt(x1.dtype, x2.dtype)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/__init__.py:87: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

type1 = dtype('float32'), type2 = dtype('int64')

    def numpy_promote_types_torch_frnt(type1, type2, /):
        from ...backends.numpy.general import numpy_get_item
        from ...backends.numpy.data_type import numpy_as_ivy_dtype
    
        try:
            ret = numpy_get_item(
>               torch_promotion_table,
                (numpy_as_ivy_dtype(type1), numpy_as_ivy_dtype(type2)),
            )
E           NameError: name 'torch_promotion_table' is not defined

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/__init__.py:34: NameError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.enhance.adjust.equalize3d
___________________________________________________________________________________ test_histogram[numpy-s2s-False] ____________________________________________________________________________________

target_framework = 'numpy', mode = 's2s', backend_compile = False

    def test_histogram(target_framework, mode, backend_compile):
        trace_args = (
            torch.rand(1, 10),
            torch.linspace(0, 255, 128),
            torch.tensor(0.9),
        )
        trace_kwargs = {"epsilon": 1e-10}
        test_args = (
            torch.rand(5, 10),
            torch.linspace(0, 255, 128),
            torch.tensor(0.9),
        )
        test_kwargs = {"epsilon": 1e-10}
>       _test_function(
            kornia.enhance.histogram,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/test_enhance.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function histogram at 0x7f57ef34f490>
trace_args = (tensor([[0.1337, 0.4803, 0.1104, 0.5494, 0.4822, 0.3814, 0.3145, 0.3848, 0.3872,
         0.4208]]), tensor([  0.0000...    238.9370, 240.9449, 242.9528, 244.9606, 246.9685, 248.9764, 250.9843,
        252.9921, 255.0000]), tensor(0.9000))
trace_kwargs = {'epsilon': 1e-10}
test_args = (tensor([[0.6160, 0.2518, 0.0511, 0.8951, 0.6432, 0.1131, 0.9909, 0.2144, 0.2086,
         0.0272],
        [0.0422, 0...    238.9370, 240.9449, 242.9528, 244.9606, 246.9685, 248.9764, 250.9843,
        252.9921, 255.0000]), tensor(0.9000))
test_kwargs = {'epsilon': 1e-10}, target = 'numpy', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function histogram at 0x7f57ef34f490>, fn_name = 'kornia.enhance.histogram'
trace_args = (tensor([[0.1337, 0.4803, 0.1104, 0.5494, 0.4822, 0.3814, 0.3145, 0.3848, 0.3872,
         0.4208]]), tensor([  0.0000...    238.9370, 240.9449, 242.9528, 244.9606, 246.9685, 248.9764, 250.9843,
        252.9921, 255.0000]), tensor(0.9000))
trace_kwargs = {'epsilon': 1e-10}
test_args = (tensor([[0.6160, 0.2518, 0.0511, 0.8951, 0.6432, 0.1131, 0.9909, 0.2144, 0.2086,
         0.0272],
        [0.0422, 0...    238.9370, 240.9449, 242.9528, 244.9606, 246.9685, 248.9764, 250.9843,
        252.9921, 255.0000]), tensor(0.9000))
test_kwargs = {'epsilon': 1e-10}, target = 'numpy', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:232: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[0.1336835 , 0.48026383, 0.1103946 , 0.5494401 , 0.48216385,
        0.38138694, 0.31450653, 0.38484108, 0.38724738, 0.42081338]],
      dtype=float32)
bins = array([  0.      ,   2.007874,   4.015748,   6.023622,   8.031496,
        10.03937 ,  12.047244,  14.055119,  16.0629... 240.94489 , 242.95276 , 244.96063 , 246.9685  , 248.97638 ,
       250.98425 , 252.99213 , 255.      ], dtype=float32)
bandwidth = array(0.9, dtype=float32), epsilon = 1e-10

    def numpy_histogram(x, bins, bandwidth, epsilon=1e-10):
        from ...ivy.functional.frontends.torch.tensor import numpy_unsqueeze_frnt_
    
>       pdf, _ = numpy_marginal_pdf(numpy_unsqueeze_frnt_(x, 2), bins, bandwidth, epsilon)

ivy_transpiled_outputs/numpy_outputs/kornia/enhance/histogram.py:68: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

values = array([[[0.1336835 ],
        [0.48026383],
        [0.1103946 ],
        [0.5494401 ],
        [0.48216385],
        [0.38138694],
        [0.31450653],
        [0.38484108],
        [0.38724738],
        [0.42081338]]], dtype=float32)
bins = array([  0.      ,   2.007874,   4.015748,   6.023622,   8.031496,
        10.03937 ,  12.047244,  14.055119,  16.0629... 240.94489 , 242.95276 , 244.96063 , 246.9685  , 248.97638 ,
       250.98425 , 252.99213 , 255.      ], dtype=float32)
sigma = array(0.9, dtype=float32), epsilon = 1e-10

    def numpy_marginal_pdf(values, bins, sigma, epsilon=1e-10):
        from ...ivy.functional.frontends.torch.tensor import numpy_dim_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_unsqueeze_frnt_
        from ...ivy.functional.frontends.torch.pointwise_ops import numpy_exp_frnt
        from ...ivy.functional.frontends.torch.tensor import numpy_pow_frnt_
        from ...ivy.functional.frontends.torch.reduction_ops import numpy_mean_frnt
        from ...ivy.functional.frontends.torch.reduction_ops import numpy_sum_frnt
    
        if not isinstance(values, (numpy.ndarray, numpy.ndarray)):
            raise TypeError(f"Input values type is not a torch.Tensor. Got {type(values)}")
        if not isinstance(bins, (numpy.ndarray, numpy.ndarray)):
            raise TypeError(f"Input bins type is not a torch.Tensor. Got {type(bins)}")
        if not isinstance(sigma, (numpy.ndarray, numpy.ndarray)):
            raise TypeError(f"Input sigma type is not a torch.Tensor. Got {type(sigma)}")
        if not numpy_dim_frnt_(values) == 3:
            raise ValueError(
                f"Input values must be a of the shape BxNx1. Got {numpy_shape_frnt_(values)}"
            )
        if not numpy_dim_frnt_(bins) == 1:
            raise ValueError(
                f"Input bins must be a of the shape NUM_BINS. Got {numpy_shape_frnt_(bins)}"
            )
        if not numpy_dim_frnt_(sigma) == 0:
            raise ValueError(
                f"Input sigma must be a of the shape 1. Got {numpy_shape_frnt_(sigma)}"
            )
        residuals = values - numpy_unsqueeze_frnt_(numpy_unsqueeze_frnt_(bins, 0), 0)
>       kernel_values = numpy_exp_frnt(-0.5 * numpy_pow_frnt_(residuals / sigma, 2))

ivy_transpiled_outputs/numpy_outputs/kornia/enhance/histogram.py:58: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (array([[[ 1.4853723e-01, -2.0824339e+00, -4.3134050e+00, ...,
         -2.7872287e+02, -2.8095383e+02, -2.8318481e+02...01, -1.7634008e+00, -3.9943719e+00, ...,
         -2.7840384e+02, -2.8063480e+02, -2.8286578e+02]]], dtype=float32), 2)
kwargs = {}, numpy_is_array_bknd = <function numpy_is_array_bknd at 0x7f5796078e50>
array_like = array([[[ 1.4853723e-01, -2.0824339e+00, -4.3134050e+00, ...,
         -2.7872287e+02, -2.8095383e+02, -2.8318481e+02]...42e-01, -1.7634008e+00, -3.9943719e+00, ...,
         -2.7840384e+02, -2.8063480e+02, -2.8286578e+02]]], dtype=float32)

    @functools.wraps(fn)
    def wrapper(*args, **kwargs):
        from ..functional.ivy.general import numpy_is_array_bknd
    
        array_like = args[0]
        if hasattr(array_like, "__class__") and array_like.__class__.__name__ in [
            "list",
            "tuple",
        ]:
            array_like = array_like[0]
        if numpy_is_array_bknd(array_like):
>           return fn(*args, **kwargs)

ivy_transpiled_outputs/numpy_outputs/ivy/utils/decorator_utils.py:200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = array([[[ 1.4853723e-01, -2.0824339e+00, -4.3134050e+00, ...,
         -2.7872287e+02, -2.8095383e+02, -2.8318481e+02]...42e-01, -1.7634008e+00, -3.9943719e+00, ...,
         -2.7840384e+02, -2.8063480e+02, -2.8286578e+02]]], dtype=float32)
exponent = 2

    @numpy_handle_methods
    def numpy_pow_frnt_(tensor, exponent):
        from .pointwise_ops import numpy_pow_frnt
    
>       return numpy_pow_frnt(tensor, exponent)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/tensor.py:145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (array([[[ 1.4853723e-01, -2.0824339e+00, -4.3134050e+00, ...,
         -2.7872287e+02, -2.8095383e+02, -2.8318481e+02...01, -1.7634008e+00, -3.9943719e+00, ...,
         -2.7840384e+02, -2.8063480e+02, -2.8286578e+02]]], dtype=float32), 2)
kwargs = {}, numpy_is_array_bknd = <function numpy_is_array_bknd at 0x7f5796078e50>
array_like = array([[[ 1.4853723e-01, -2.0824339e+00, -4.3134050e+00, ...,
         -2.7872287e+02, -2.8095383e+02, -2.8318481e+02]...42e-01, -1.7634008e+00, -3.9943719e+00, ...,
         -2.7840384e+02, -2.8063480e+02, -2.8286578e+02]]], dtype=float32)

    @functools.wraps(fn)
    def wrapper(*args, **kwargs):
        from ..functional.ivy.general import numpy_is_array_bknd
    
        array_like = args[0]
        if hasattr(array_like, "__class__") and array_like.__class__.__name__ in [
            "list",
            "tuple",
        ]:
            array_like = array_like[0]
        if numpy_is_array_bknd(array_like):
>           return fn(*args, **kwargs)

ivy_transpiled_outputs/numpy_outputs/ivy/utils/decorator_utils.py:200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = array([[[ 1.4853723e-01, -2.0824339e+00, -4.3134050e+00, ...,
         -2.7872287e+02, -2.8095383e+02, -2.8318481e+02]...42e-01, -1.7634008e+00, -3.9943719e+00, ...,
         -2.7840384e+02, -2.8063480e+02, -2.8286578e+02]]], dtype=float32)
exponent = array(2)

    @numpy_handle_methods
    def numpy_pow_frnt(input, exponent, *, out=None):
        from ...ivy.general import numpy_is_array_bknd
        from .creation_ops import numpy_as_tensor_frnt
        from ...backends.numpy.creation import numpy_asarray
        from .__init__ import numpy_promote_types_of_torch_inputs_frnt
        from ...ivy.data_type import numpy_is_int_dtype_bknd
        from ...backends.numpy.elementwise import numpy_pow
        from ...backends.numpy.utility import numpy_any
        from ...backends.numpy.searching import numpy_where
        from ...backends.numpy.elementwise import numpy_bitwise_and
        from ....data_classes.array.data_type import numpy_astype_bknd_
    
        if not numpy_is_array_bknd(input):
            input = numpy_as_tensor_frnt(input)
        if not numpy_is_array_bknd(exponent):
            if (
                any(dtype in str(input.dtype) for dtype in ["int8", "int16"])
                and isinstance(exponent, (int,))
                or "float16" in str(input.dtype)
                and isinstance(exponent, (float,))
            ):
                exponent = numpy_asarray(exponent, dtype=input.dtype)
            else:
                exponent = numpy_as_tensor_frnt(exponent)
>       input, exponent = numpy_promote_types_of_torch_inputs_frnt(input, exponent)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/pointwise_ops.py:97: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x1 = array([[[ 1.4853723e-01, -2.0824339e+00, -4.3134050e+00, ...,
         -2.7872287e+02, -2.8095383e+02, -2.8318481e+02]...42e-01, -1.7634008e+00, -3.9943719e+00, ...,
         -2.7840384e+02, -2.8063480e+02, -2.8286578e+02]]], dtype=float32)
x2 = array(2)

    def numpy_promote_types_of_torch_inputs_frnt(x1, x2, /):
        from ...ivy.general import numpy_isscalar_bknd
        from ...ivy.data_type import numpy_is_int_dtype_bknd
        from ...backends.numpy.creation import numpy_asarray
        from ...ivy.data_type import numpy_default_dtype_bknd
        from .tensor import numpy_shape_frnt_
        from ...ivy.device import numpy_default_device_bknd
        from ....data_classes.array.data_type import numpy_astype_bknd_
    
        """Promote the dtype of the given native array inputs to a common dtype
        based on type promotion rules.
    
        While passing float or integer values or any other non-array input
        to this function, it should be noted that the return will be an
        array-like object. Therefore, outputs from this function should be
        used as inputs only for those functions that expect an array-like or
        tensor-like objects, otherwise it might give unexpected results.
        """
        if (
            numpy_isscalar_bknd(x1) or isinstance(x1, (list, tuple))
        ) and numpy_is_int_dtype_bknd(x1):
            x1 = numpy_asarray(x1, dtype="int64")
        elif numpy_isscalar_bknd(x1) or isinstance(x1, (list, tuple)):
            x1 = numpy_asarray(x1)
        if (
            numpy_isscalar_bknd(x2) or isinstance(x2, (list, tuple))
        ) and numpy_is_int_dtype_bknd(x2):
            x2 = numpy_asarray(x2, dtype="int64")
        elif numpy_isscalar_bknd(x2) or isinstance(x2, (list, tuple)):
            x2 = numpy_asarray(x2)
        type1 = numpy_default_dtype_bknd(item=x1).strip("u123456789")
        type2 = numpy_default_dtype_bknd(item=x2).strip("u123456789")
        if numpy_shape_frnt_(x1) != () and numpy_shape_frnt_(x2) == () and type1 == type2:
            x2 = numpy_asarray(
                x2,
                dtype=x1.dtype,
                device=numpy_default_device_bknd(item=x1, as_native=False),
            )
        elif numpy_shape_frnt_(x1) == () and numpy_shape_frnt_(x2) != () and type1 == type2:
            x1 = numpy_asarray(
                x1,
                dtype=x2.dtype,
                device=numpy_default_device_bknd(item=x2, as_native=False),
            )
        elif x1.dtype != x2.dtype:
>           promoted = numpy_promote_types_torch_frnt(x1.dtype, x2.dtype)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/__init__.py:87: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

type1 = dtype('float32'), type2 = dtype('int64')

    def numpy_promote_types_torch_frnt(type1, type2, /):
        from ...backends.numpy.general import numpy_get_item
        from ...backends.numpy.data_type import numpy_as_ivy_dtype
    
        try:
            ret = numpy_get_item(
>               torch_promotion_table,
                (numpy_as_ivy_dtype(type1), numpy_as_ivy_dtype(type2)),
            )
E           NameError: name 'torch_promotion_table' is not defined

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/__init__.py:34: NameError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.enhance.histogram.histogram
__________________________________________________________________________________ test_histogram2d[numpy-s2s-False] ___________________________________________________________________________________

target_framework = 'numpy', mode = 's2s', backend_compile = False

    def test_histogram2d(target_framework, mode, backend_compile):
        trace_args = (
            torch.rand(2, 32),
            torch.rand(2, 32),
            torch.linspace(0, 255, 128),
            torch.tensor(0.9),
        )
        trace_kwargs = {"epsilon": 1e-10}
        test_args = (
            torch.rand(5, 32),
            torch.rand(5, 32),
            torch.linspace(0, 255, 128),
            torch.tensor(0.9),
        )
        test_kwargs = {"epsilon": 1e-10}
>       _test_function(
            kornia.enhance.histogram2d,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/test_enhance.py:438: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function histogram2d at 0x7f57ef34f5b0>
trace_args = (tensor([[0.2951, 0.6640, 0.1257, 0.3732, 0.6806, 0.1887, 0.5346, 0.5628, 0.7590,
         0.9400, 0.0574, 0.7461, 0.7...    238.9370, 240.9449, 242.9528, 244.9606, 246.9685, 248.9764, 250.9843,
        252.9921, 255.0000]), tensor(0.9000))
trace_kwargs = {'epsilon': 1e-10}
test_args = (tensor([[0.8708, 0.3136, 0.3842, 0.4868, 0.0256, 0.6429, 0.3819, 0.6432, 0.8154,
         0.0056, 0.7938, 0.1515, 0.6...    238.9370, 240.9449, 242.9528, 244.9606, 246.9685, 248.9764, 250.9843,
        252.9921, 255.0000]), tensor(0.9000))
test_kwargs = {'epsilon': 1e-10}, target = 'numpy', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function histogram2d at 0x7f57ef34f5b0>, fn_name = 'kornia.enhance.histogram2d'
trace_args = (tensor([[0.2951, 0.6640, 0.1257, 0.3732, 0.6806, 0.1887, 0.5346, 0.5628, 0.7590,
         0.9400, 0.0574, 0.7461, 0.7...    238.9370, 240.9449, 242.9528, 244.9606, 246.9685, 248.9764, 250.9843,
        252.9921, 255.0000]), tensor(0.9000))
trace_kwargs = {'epsilon': 1e-10}
test_args = (tensor([[0.8708, 0.3136, 0.3842, 0.4868, 0.0256, 0.6429, 0.3819, 0.6432, 0.8154,
         0.0056, 0.7938, 0.1515, 0.6...    238.9370, 240.9449, 242.9528, 244.9606, 246.9685, 248.9764, 250.9843,
        252.9921, 255.0000]), tensor(0.9000))
test_kwargs = {'epsilon': 1e-10}, target = 'numpy', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:232: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x1 = array([[0.29510957, 0.6640346 , 0.12570256, 0.37321675, 0.6805837 ,
        0.18868506, 0.53458   , 0.5627761 , 0.7590...8,
        0.4103673 , 0.16046894, 0.89683384, 0.40153164, 0.81188697,
        0.5071554 , 0.10458255]], dtype=float32)
x2 = array([[0.22548628, 0.09131724, 0.5441335 , 0.16701704, 0.13299668,
        0.76202387, 0.7202496 , 0.53342456, 0.6979...5,
        0.96389955, 0.10761803, 0.5368749 , 0.59833974, 0.17335635,
        0.8458915 , 0.6262593 ]], dtype=float32)
bins = array([  0.      ,   2.007874,   4.015748,   6.023622,   8.031496,
        10.03937 ,  12.047244,  14.055119,  16.0629... 240.94489 , 242.95276 , 244.96063 , 246.9685  , 248.97638 ,
       250.98425 , 252.99213 , 255.      ], dtype=float32)
bandwidth = array(0.9, dtype=float32), epsilon = 1e-10

    def numpy_histogram2d(x1, x2, bins, bandwidth, epsilon=1e-10):
        from ...ivy.functional.frontends.torch.tensor import numpy_unsqueeze_frnt_
    
>       _, kernel_values1 = numpy_marginal_pdf(
            numpy_unsqueeze_frnt_(x1, 2), bins, bandwidth, epsilon
        )

ivy_transpiled_outputs/numpy_outputs/kornia/enhance/histogram.py:107: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

values = array([[[0.29510957],
        [0.6640346 ],
        [0.12570256],
        [0.37321675],
        [0.6805837 ],
        ... [0.89683384],
        [0.40153164],
        [0.81188697],
        [0.5071554 ],
        [0.10458255]]], dtype=float32)
bins = array([  0.      ,   2.007874,   4.015748,   6.023622,   8.031496,
        10.03937 ,  12.047244,  14.055119,  16.0629... 240.94489 , 242.95276 , 244.96063 , 246.9685  , 248.97638 ,
       250.98425 , 252.99213 , 255.      ], dtype=float32)
sigma = array(0.9, dtype=float32), epsilon = 1e-10

    def numpy_marginal_pdf(values, bins, sigma, epsilon=1e-10):
        from ...ivy.functional.frontends.torch.tensor import numpy_dim_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_unsqueeze_frnt_
        from ...ivy.functional.frontends.torch.pointwise_ops import numpy_exp_frnt
        from ...ivy.functional.frontends.torch.tensor import numpy_pow_frnt_
        from ...ivy.functional.frontends.torch.reduction_ops import numpy_mean_frnt
        from ...ivy.functional.frontends.torch.reduction_ops import numpy_sum_frnt
    
        if not isinstance(values, (numpy.ndarray, numpy.ndarray)):
            raise TypeError(f"Input values type is not a torch.Tensor. Got {type(values)}")
        if not isinstance(bins, (numpy.ndarray, numpy.ndarray)):
            raise TypeError(f"Input bins type is not a torch.Tensor. Got {type(bins)}")
        if not isinstance(sigma, (numpy.ndarray, numpy.ndarray)):
            raise TypeError(f"Input sigma type is not a torch.Tensor. Got {type(sigma)}")
        if not numpy_dim_frnt_(values) == 3:
            raise ValueError(
                f"Input values must be a of the shape BxNx1. Got {numpy_shape_frnt_(values)}"
            )
        if not numpy_dim_frnt_(bins) == 1:
            raise ValueError(
                f"Input bins must be a of the shape NUM_BINS. Got {numpy_shape_frnt_(bins)}"
            )
        if not numpy_dim_frnt_(sigma) == 0:
            raise ValueError(
                f"Input sigma must be a of the shape 1. Got {numpy_shape_frnt_(sigma)}"
            )
        residuals = values - numpy_unsqueeze_frnt_(numpy_unsqueeze_frnt_(bins, 0), 0)
>       kernel_values = numpy_exp_frnt(-0.5 * numpy_pow_frnt_(residuals / sigma, 2))

ivy_transpiled_outputs/numpy_outputs/kornia/enhance/histogram.py:58: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (array([[[ 3.2789955e-01, -1.9030718e+00, -4.1340427e+00, ...,
         -2.7854352e+02, -2.8077448e+02, -2.8300543e+02...01, -2.1147683e+00, -4.3457394e+00, ...,
         -2.7875519e+02, -2.8098618e+02, -2.8321713e+02]]], dtype=float32), 2)
kwargs = {}, numpy_is_array_bknd = <function numpy_is_array_bknd at 0x7f5796a37e20>
array_like = array([[[ 3.2789955e-01, -1.9030718e+00, -4.1340427e+00, ...,
         -2.7854352e+02, -2.8077448e+02, -2.8300543e+02]...83e-01, -2.1147683e+00, -4.3457394e+00, ...,
         -2.7875519e+02, -2.8098618e+02, -2.8321713e+02]]], dtype=float32)

    @functools.wraps(fn)
    def wrapper(*args, **kwargs):
        from ..functional.ivy.general import numpy_is_array_bknd
    
        array_like = args[0]
        if hasattr(array_like, "__class__") and array_like.__class__.__name__ in [
            "list",
            "tuple",
        ]:
            array_like = array_like[0]
        if numpy_is_array_bknd(array_like):
>           return fn(*args, **kwargs)

ivy_transpiled_outputs/numpy_outputs/ivy/utils/decorator_utils.py:200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = array([[[ 3.2789955e-01, -1.9030718e+00, -4.1340427e+00, ...,
         -2.7854352e+02, -2.8077448e+02, -2.8300543e+02]...83e-01, -2.1147683e+00, -4.3457394e+00, ...,
         -2.7875519e+02, -2.8098618e+02, -2.8321713e+02]]], dtype=float32)
exponent = 2

    @numpy_handle_methods
    def numpy_pow_frnt_(tensor, exponent):
        from .pointwise_ops import numpy_pow_frnt
    
>       return numpy_pow_frnt(tensor, exponent)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/tensor.py:145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (array([[[ 3.2789955e-01, -1.9030718e+00, -4.1340427e+00, ...,
         -2.7854352e+02, -2.8077448e+02, -2.8300543e+02...01, -2.1147683e+00, -4.3457394e+00, ...,
         -2.7875519e+02, -2.8098618e+02, -2.8321713e+02]]], dtype=float32), 2)
kwargs = {}, numpy_is_array_bknd = <function numpy_is_array_bknd at 0x7f5796a37e20>
array_like = array([[[ 3.2789955e-01, -1.9030718e+00, -4.1340427e+00, ...,
         -2.7854352e+02, -2.8077448e+02, -2.8300543e+02]...83e-01, -2.1147683e+00, -4.3457394e+00, ...,
         -2.7875519e+02, -2.8098618e+02, -2.8321713e+02]]], dtype=float32)

    @functools.wraps(fn)
    def wrapper(*args, **kwargs):
        from ..functional.ivy.general import numpy_is_array_bknd
    
        array_like = args[0]
        if hasattr(array_like, "__class__") and array_like.__class__.__name__ in [
            "list",
            "tuple",
        ]:
            array_like = array_like[0]
        if numpy_is_array_bknd(array_like):
>           return fn(*args, **kwargs)

ivy_transpiled_outputs/numpy_outputs/ivy/utils/decorator_utils.py:200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = array([[[ 3.2789955e-01, -1.9030718e+00, -4.1340427e+00, ...,
         -2.7854352e+02, -2.8077448e+02, -2.8300543e+02]...83e-01, -2.1147683e+00, -4.3457394e+00, ...,
         -2.7875519e+02, -2.8098618e+02, -2.8321713e+02]]], dtype=float32)
exponent = array(2)

    @numpy_handle_methods
    def numpy_pow_frnt(input, exponent, *, out=None):
        from ...ivy.general import numpy_is_array_bknd
        from .creation_ops import numpy_as_tensor_frnt
        from ...backends.numpy.creation import numpy_asarray
        from .__init__ import numpy_promote_types_of_torch_inputs_frnt
        from ...ivy.data_type import numpy_is_int_dtype_bknd
        from ...backends.numpy.elementwise import numpy_pow
        from ...backends.numpy.utility import numpy_any
        from ...backends.numpy.searching import numpy_where
        from ...backends.numpy.elementwise import numpy_bitwise_and
        from ....data_classes.array.data_type import numpy_astype_bknd_
    
        if not numpy_is_array_bknd(input):
            input = numpy_as_tensor_frnt(input)
        if not numpy_is_array_bknd(exponent):
            if (
                any(dtype in str(input.dtype) for dtype in ["int8", "int16"])
                and isinstance(exponent, (int,))
                or "float16" in str(input.dtype)
                and isinstance(exponent, (float,))
            ):
                exponent = numpy_asarray(exponent, dtype=input.dtype)
            else:
                exponent = numpy_as_tensor_frnt(exponent)
>       input, exponent = numpy_promote_types_of_torch_inputs_frnt(input, exponent)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/pointwise_ops.py:97: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x1 = array([[[ 3.2789955e-01, -1.9030718e+00, -4.1340427e+00, ...,
         -2.7854352e+02, -2.8077448e+02, -2.8300543e+02]...83e-01, -2.1147683e+00, -4.3457394e+00, ...,
         -2.7875519e+02, -2.8098618e+02, -2.8321713e+02]]], dtype=float32)
x2 = array(2)

    def numpy_promote_types_of_torch_inputs_frnt(x1, x2, /):
        from ...ivy.general import numpy_isscalar_bknd
        from ...ivy.data_type import numpy_is_int_dtype_bknd
        from ...backends.numpy.creation import numpy_asarray
        from ...ivy.data_type import numpy_default_dtype_bknd
        from .tensor import numpy_shape_frnt_
        from ...ivy.device import numpy_default_device_bknd
        from ....data_classes.array.data_type import numpy_astype_bknd_
    
        """Promote the dtype of the given native array inputs to a common dtype
        based on type promotion rules.
    
        While passing float or integer values or any other non-array input
        to this function, it should be noted that the return will be an
        array-like object. Therefore, outputs from this function should be
        used as inputs only for those functions that expect an array-like or
        tensor-like objects, otherwise it might give unexpected results.
        """
        if (
            numpy_isscalar_bknd(x1) or isinstance(x1, (list, tuple))
        ) and numpy_is_int_dtype_bknd(x1):
            x1 = numpy_asarray(x1, dtype="int64")
        elif numpy_isscalar_bknd(x1) or isinstance(x1, (list, tuple)):
            x1 = numpy_asarray(x1)
        if (
            numpy_isscalar_bknd(x2) or isinstance(x2, (list, tuple))
        ) and numpy_is_int_dtype_bknd(x2):
            x2 = numpy_asarray(x2, dtype="int64")
        elif numpy_isscalar_bknd(x2) or isinstance(x2, (list, tuple)):
            x2 = numpy_asarray(x2)
        type1 = numpy_default_dtype_bknd(item=x1).strip("u123456789")
        type2 = numpy_default_dtype_bknd(item=x2).strip("u123456789")
        if numpy_shape_frnt_(x1) != () and numpy_shape_frnt_(x2) == () and type1 == type2:
            x2 = numpy_asarray(
                x2,
                dtype=x1.dtype,
                device=numpy_default_device_bknd(item=x1, as_native=False),
            )
        elif numpy_shape_frnt_(x1) == () and numpy_shape_frnt_(x2) != () and type1 == type2:
            x1 = numpy_asarray(
                x1,
                dtype=x2.dtype,
                device=numpy_default_device_bknd(item=x2, as_native=False),
            )
        elif x1.dtype != x2.dtype:
>           promoted = numpy_promote_types_torch_frnt(x1.dtype, x2.dtype)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/__init__.py:87: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

type1 = dtype('float32'), type2 = dtype('int64')

    def numpy_promote_types_torch_frnt(type1, type2, /):
        from ...backends.numpy.general import numpy_get_item
        from ...backends.numpy.data_type import numpy_as_ivy_dtype
    
        try:
            ret = numpy_get_item(
>               torch_promotion_table,
                (numpy_as_ivy_dtype(type1), numpy_as_ivy_dtype(type2)),
            )
E           NameError: name 'torch_promotion_table' is not defined

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/__init__.py:34: NameError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.enhance.histogram.histogram2d
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/test_enhance.py::test_adjust_gamma[numpy-s2s-False] - TypeError: 'float' object cannot be interpreted as an integer
FAILED kornia/test_enhance.py::test_invert[numpy-s2s-False] - ImportError: Error loading module ivy_transpiled_outputs.numpy_outputs.kornia.enhance.adjust: 'float' object cannot be interpreted as a...
FAILED kornia/test_enhance.py::test_equalize[numpy-s2s-False] - NameError: name 'torch_promotion_table' is not defined
FAILED kornia/test_enhance.py::test_equalize_clahe[numpy-s2s-False] - ValueError: need at least one array to stack
FAILED kornia/test_enhance.py::test_equalize3d[numpy-s2s-False] - NameError: name 'torch_promotion_table' is not defined
FAILED kornia/test_enhance.py::test_histogram[numpy-s2s-False] - NameError: name 'torch_promotion_table' is not defined
FAILED kornia/test_enhance.py::test_histogram2d[numpy-s2s-False] - NameError: name 'torch_promotion_table' is not defined
======================================================================== 7 failed, 19 passed, 13 skipped in 1594.61s (0:26:34) =========================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 17 items

kornia/augmentation/test_augmentation4.py sssssssssssssssss                                                                                                                                      [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
========================================================================================= 17 skipped in 5.44s ==========================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 15 items

kornia/test_contrib.py ....Fssssssssss                                                                                                                                                           [100%]

=============================================================================================== FAILURES ===============================================================================================
_________________________________________________________________________________ test_diamond_square[numpy-s2s-False] _________________________________________________________________________________

target_framework = 'numpy', mode = 's2s', backend_compile = False

    def test_diamond_square(target_framework, mode, backend_compile):
        trace_args = ((1, 1, 8, 8),)
        trace_kwargs = {
            "roughness": 0.5,
            "random_scale": 1.0,
            "normalize_range": (0.0, 1.0),
            "random_fn": torch.ones,
        }
        test_args = ((5, 1, 8, 8),)
        test_kwargs = {
            "roughness": 0.7,
            "random_scale": 0.9,
            "normalize_range": (-1.0, 1.0),
            "random_fn": torch.ones,
        }
>       _test_function(
            kornia.contrib.diamond_square,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/test_contrib.py:141: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function diamond_square at 0x7fe2c71452d0>, trace_args = ((1, 1, 8, 8),)
trace_kwargs = {'normalize_range': (0.0, 1.0), 'random_fn': <built-in method ones of type object at 0x7fe2df4ca8c0>, 'random_scale': 1.0, 'roughness': 0.5}, test_args = ((5, 1, 8, 8),)
test_kwargs = {'normalize_range': (-1.0, 1.0), 'random_fn': <built-in method ones of type object at 0x7fe2df4ca8c0>, 'random_scale': 0.9, 'roughness': 0.7}, target = 'numpy', backend_compile = False
tolerance = 0.001, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function diamond_square at 0x7fe2c71452d0>, fn_name = 'kornia.contrib.diamond_square', trace_args = ((1, 1, 8, 8),)
trace_kwargs = {'normalize_range': (0.0, 1.0), 'random_fn': <built-in method ones of type object at 0x7fe2df4ca8c0>, 'random_scale': 1.0, 'roughness': 0.5}, test_args = ((5, 1, 8, 8),)
test_kwargs = {'normalize_range': (-1.0, 1.0), 'random_fn': <built-in method ones of type object at 0x7fe2df4ca8c0>, 'random_scale': 0.9, 'roughness': 0.7}, target = 'numpy', backend_compile = False
tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:232: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

output_size = (1, 1, 8, 8), roughness = 0.5, random_scale = 1.0, random_fn = <built-in method ones of type object at 0x7fe2df4ca8c0>, normalize_range = (0.0, 1.0), device = None, dtype = None

    def numpy_diamond_square(
        output_size,
        roughness=0.5,
        random_scale=1.0,
        random_fn=numpy_rand_frnt,
        normalize_range=None,
        device=None,
        dtype=None,
    ):
        from ..core.check import numpy_KORNIA_CHECK
        from ...ivy.functional.frontends.torch.tensor import numpy_to_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_expand_frnt_
        from ..core.check import numpy_KORNIA_CHECK_IS_TENSOR
        from ...ivy.functional.frontends.torch.tensor import numpy_view_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_reshape_frnt_
        from ...ivy.functional.backends.numpy.general import numpy_get_item
        from ..enhance.normalize import numpy_normalize_min_max
        from ...ivy.functional.frontends.torch.tensor import numpy_contiguous_frnt_
    
        numpy_KORNIA_CHECK(len(output_size) == 4, "output_size must be (B,C,H,W)")
        if not isinstance(random_scale, (numpy.ndarray, numpy.ndarray)):
            random_scale = numpy_to_frnt_(
>               numpy.ndarray([[[[random_scale]]]]), device, dtype
            )
E           TypeError: 'list' object cannot be interpreted as an integer

ivy_transpiled_outputs/numpy_outputs/kornia/contrib/diamond_square.py:197: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.contrib.diamond_square.diamond_square
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/test_contrib.py::test_diamond_square[numpy-s2s-False] - TypeError: 'list' object cannot be interpreted as an integer
========================================================================= 1 failed, 4 passed, 10 skipped in 325.11s (0:05:25) ==========================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 4 items

kornia/test_sensors.py ssss                                                                                                                                                                      [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
========================================================================================== 4 skipped in 5.34s ==========================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 16 items

kornia/augmentation/test_augmentation3.py ssssssssssssssss                                                                                                                                       [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
========================================================================================= 16 skipped in 5.44s ==========================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 3 items

kornia/augmentation/test_auto.py FFF                                                                                                                                                             [100%]

=============================================================================================== FAILURES ===============================================================================================
________________________________________________________________________________ test_AutoAugment[tensorflow-s2s-False] ________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_AutoAugment(target_framework, mode, backend_compile):
        print("kornia.augmentation.auto.AutoAugment")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledAutoAugment = ivy.transpile(
            kornia.augmentation.auto.AutoAugment,
            source="torch",
            target=target_framework,
        )
    
        torch_aug = kornia.augmentation.auto.AutoAugment()
>       transpiled_aug = TranspiledAutoAugment()

kornia/augmentation/test_auto.py:29: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_AutoAugment object at 0x7f29abd52d70>, policy = 'imagenet', transformation_matrix_mode = 'silent'

    def __init__(self, policy="imagenet", transformation_matrix_mode="silent"):
        from ....core._backend import tensor
        from .....torch.distributions.categorical import tensorflow_Categorical
    
        if policy == "imagenet":
            _policy = imagenet_policy
        elif policy == "cifar10":
            _policy = cifar10_policy
        elif policy == "svhn":
            _policy = svhn_policy
        elif isinstance(policy, (list, tuple)):
            _policy = policy
        else:
            raise NotImplementedError(f"Invalid policy `{policy}`.")
>       super().__init__(_policy, transformation_matrix_mode=transformation_matrix_mode)

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/auto/autoaugment/autoaugment.py:129: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_AutoAugment object at 0x7f29abd52d70>
args = ([[('posterize', 0.4, 8), ('rotate', 0.6, 9)], [('solarize', 0.6, 5), ('auto_contrast', 0.6, None)], [('equalize', 0.8...rize', 0.6, 6)], [('equalize', 0.4, None), ('solarize', 0.2, 4)], [('equalize', 0.4, None), ('rotate', 0.8, 8)], ...],)
kwargs = {'transformation_matrix_mode': 'silent'}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_AutoAugment object at 0x7f29abd52d70>
policy = [[('posterize', 0.4, 8), ('rotate', 0.6, 9)], [('solarize', 0.6, 5), ('auto_contrast', 0.6, None)], [('equalize', 0.8,...terize', 0.6, 6)], [('equalize', 0.4, None), ('solarize', 0.2, 4)], [('equalize', 0.4, None), ('rotate', 0.8, 8)], ...]
transformation_matrix_mode = 'silent'

    @tensorflow_store_config_info
    def __init__(self, policy, transformation_matrix_mode="silence"):
        from .operations.policy import tensorflow_PolicySequential
    
>       policies = self.compose_policy(policy)

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/auto/base.py:46: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_AutoAugment object at 0x7f29abd52d70>
policy = [[('posterize', 0.4, 8), ('rotate', 0.6, 9)], [('solarize', 0.6, 5), ('auto_contrast', 0.6, None)], [('equalize', 0.8,...terize', 0.6, 6)], [('equalize', 0.4, None), ('solarize', 0.2, 4)], [('equalize', 0.4, None), ('rotate', 0.8, 8)], ...]

    def compose_policy(self, policy):
>       return [self.compose_subpolicy_sequential(subpolicy) for subpolicy in policy]

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/auto/base.py:61: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

.0 = <list_iterator object at 0x7f29abd51db0>

>   return [self.compose_subpolicy_sequential(subpolicy) for subpolicy in policy]

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/auto/base.py:61: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_AutoAugment object at 0x7f29abd52d70>, subpolicy = [('posterize', 0.4, 8), ('rotate', 0.6, 9)]

    def compose_subpolicy_sequential(self, subpolicy):
        from ..operations.policy import tensorflow_PolicySequential
    
        return tensorflow_PolicySequential(
>           *[
                getattr(kornia.augmentation.auto.autoaugment.ops, name)(prob, mag)
                for name, prob, mag in subpolicy
            ]
        )

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/auto/autoaugment/autoaugment.py:137: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

.0 = <list_iterator object at 0x7f29abd52620>

        *[
>           getattr(kornia.augmentation.auto.autoaugment.ops, name)(prob, mag)
            for name, prob, mag in subpolicy
        ]
    )
E   NameError: name 'kornia' is not defined

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/auto/autoaugment/autoaugment.py:138: NameError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.auto.AutoAugment
________________________________________________________________________________ test_RandAugment[tensorflow-s2s-False] ________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_RandAugment(target_framework, mode, backend_compile):
        print("kornia.augmentation.auto.RandAugment")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledRandAugment = ivy.transpile(
            kornia.augmentation.auto.RandAugment,
            source="torch",
            target=target_framework,
        )
    
        torch_aug = kornia.augmentation.auto.RandAugment(n=2, m=10)
>       transpiled_aug = TranspiledRandAugment(n=2, m=10)

kornia/augmentation/test_auto.py:69: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_RandAugment object at 0x7f29b09bead0>, n = 2, m = 10, policy = None
transformation_matrix_mode = 'silent'

    def __init__(self, n, m, policy=None, transformation_matrix_mode="silent"):
        if m <= 0 or m >= 30:
            raise ValueError(f"Expect `m` in [0, 30]. Got {m}.")
        if policy is None:
            _policy = default_policy
        else:
            _policy = policy
>       super().__init__(_policy, transformation_matrix_mode=transformation_matrix_mode)

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/auto/rand_augment/rand_augment.py:60: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_RandAugment object at 0x7f29b09bead0>
args = ([[('auto_contrast', 0, 1)], [('equalize', 0, 1)], [('invert', 0, 1)], [('rotate', -30.0, 30.0)], [('posterize', 0.0, 4)], [('solarize', 0.0, 1.0)], ...],)
kwargs = {'transformation_matrix_mode': 'silent'}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_RandAugment object at 0x7f29b09bead0>
policy = [[('auto_contrast', 0, 1)], [('equalize', 0, 1)], [('invert', 0, 1)], [('rotate', -30.0, 30.0)], [('posterize', 0.0, 4)], [('solarize', 0.0, 1.0)], ...], transformation_matrix_mode = 'silent'

    @tensorflow_store_config_info
    def __init__(self, policy, transformation_matrix_mode="silence"):
        from .operations.policy import tensorflow_PolicySequential
    
>       policies = self.compose_policy(policy)

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/auto/base.py:46: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_RandAugment object at 0x7f29b09bead0>
policy = [[('auto_contrast', 0, 1)], [('equalize', 0, 1)], [('invert', 0, 1)], [('rotate', -30.0, 30.0)], [('posterize', 0.0, 4)], [('solarize', 0.0, 1.0)], ...]

    def compose_policy(self, policy):
>       return [self.compose_subpolicy_sequential(subpolicy) for subpolicy in policy]

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/auto/base.py:61: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

.0 = <list_iterator object at 0x7f29b09bcfa0>

>   return [self.compose_subpolicy_sequential(subpolicy) for subpolicy in policy]

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/auto/base.py:61: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_RandAugment object at 0x7f29b09bead0>, subpolicy = [('auto_contrast', 0, 1)]

    def compose_subpolicy_sequential(self, subpolicy):
        from ..operations.policy import tensorflow_PolicySequential
    
        if len(subpolicy) != 1:
            raise RuntimeError(
                f"Each policy must have only one operation for RandAugment. Got {len(subpolicy)}."
            )
        name, low, high = subpolicy[0][0], subpolicy[0][1], subpolicy[0][2]
        return tensorflow_PolicySequential(
>           *[getattr(kornia.augmentation.auto.rand_augment.ops, name)(low, high)]
        )
E       NameError: name 'kornia' is not defined

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/auto/rand_augment/rand_augment.py:83: NameError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.auto.RandAugment
______________________________________________________________________________ test_TrivialAugment[tensorflow-s2s-False] _______________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_TrivialAugment(target_framework, mode, backend_compile):
        print("kornia.augmentation.auto.TrivialAugment")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledTrivialAugment = ivy.transpile(
            kornia.augmentation.auto.TrivialAugment,
            source="torch",
            target=target_framework,
        )
    
        torch_aug = kornia.augmentation.auto.TrivialAugment()
>       transpiled_aug = TranspiledTrivialAugment()

kornia/augmentation/test_auto.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_TrivialAugment object at 0x7f29aab812a0>, policy = None, transformation_matrix_mode = 'silent'

    def __init__(self, policy=None, transformation_matrix_mode="silent"):
        from .....ivy.functional.frontends.torch.creation_ops import (
            tensorflow_tensor_frnt,
        )
        from .....torch.distributions.categorical import tensorflow_Categorical
    
        if policy is None:
            _policy = default_policy
        else:
            _policy = policy
>       super().__init__(_policy, transformation_matrix_mode=transformation_matrix_mode)

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/auto/trivial_augment/trivial_augment.py:58: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_TrivialAugment object at 0x7f29aab812a0>
args = ([[('auto_contrast', 0, 1)], [('equalize', 0, 1)], [('rotate', -30.0, 30.0)], [('posterize', 0.0, 4)], [('solarize', 0.0, 1.0)], [('contrast', 0.1, 1.9)], ...],)
kwargs = {'transformation_matrix_mode': 'silent'}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_TrivialAugment object at 0x7f29aab812a0>
policy = [[('auto_contrast', 0, 1)], [('equalize', 0, 1)], [('rotate', -30.0, 30.0)], [('posterize', 0.0, 4)], [('solarize', 0.0, 1.0)], [('contrast', 0.1, 1.9)], ...]
transformation_matrix_mode = 'silent'

    @tensorflow_store_config_info
    def __init__(self, policy, transformation_matrix_mode="silence"):
        from .operations.policy import tensorflow_PolicySequential
    
>       policies = self.compose_policy(policy)

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/auto/base.py:46: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_TrivialAugment object at 0x7f29aab812a0>
policy = [[('auto_contrast', 0, 1)], [('equalize', 0, 1)], [('rotate', -30.0, 30.0)], [('posterize', 0.0, 4)], [('solarize', 0.0, 1.0)], [('contrast', 0.1, 1.9)], ...]

    def compose_policy(self, policy):
>       return [self.compose_subpolicy_sequential(subpolicy) for subpolicy in policy]

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/auto/base.py:61: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

.0 = <list_iterator object at 0x7f29b47dafe0>

>   return [self.compose_subpolicy_sequential(subpolicy) for subpolicy in policy]

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/auto/base.py:61: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_TrivialAugment object at 0x7f29aab812a0>, subpolicy = [('auto_contrast', 0, 1)]

    def compose_subpolicy_sequential(self, subpolicy):
        from ..operations.policy import tensorflow_PolicySequential
    
        if len(subpolicy) != 1:
            raise RuntimeError(
                f"Each policy must have only one operation for TrivialAugment. Got {len(subpolicy)}."
            )
        name, low, high = subpolicy[0][0], subpolicy[0][1], subpolicy[0][2]
        return tensorflow_PolicySequential(
>           *[getattr(kornia.augmentation.auto.rand_augment.ops, name)(low, high)]
        )
E       NameError: name 'kornia' is not defined

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/auto/trivial_augment/trivial_augment.py:71: NameError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.auto.TrivialAugment
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/augmentation/test_auto.py::test_AutoAugment[tensorflow-s2s-False] - NameError: name 'kornia' is not defined
FAILED kornia/augmentation/test_auto.py::test_RandAugment[tensorflow-s2s-False] - NameError: name 'kornia' is not defined
FAILED kornia/augmentation/test_auto.py::test_TrivialAugment[tensorflow-s2s-False] - NameError: name 'kornia' is not defined
==================================================================================== 3 failed in 1394.34s (0:23:14) ====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 8 items

kornia/geometry/test_linalg.py .......F                                                                                                                                                          [100%]

=============================================================================================== FAILURES ===============================================================================================
_______________________________________________________________________________ test_euclidean_distance[numpy-s2s-False] _______________________________________________________________________________

target_framework = 'numpy', mode = 's2s', backend_compile = False

    def test_euclidean_distance(target_framework, mode, backend_compile):
        trace_args = (
            torch.rand(3, 5),
            torch.rand(3, 5),
        )
        trace_kwargs = {'keepdim': False, 'eps': 1e-6}
        test_args = (
            torch.rand(5, 3, 5),
            torch.rand(5, 3, 5),
        )
        test_kwargs = {'keepdim': False, 'eps': 1e-6}
>       _test_function(
            kornia.geometry.linalg.euclidean_distance,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/geometry/test_linalg.py:184: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function euclidean_distance at 0x7f13e9a6be20>
trace_args = (tensor([[0.1154, 0.7799, 0.1216, 0.1660, 0.1282],
        [0.1649, 0.9167, 0.1979, 0.0921, 0.4657],
        [0.0229, ... 0.0692, 0.9179],
        [0.1936, 0.8638, 0.1893, 0.2224, 0.1350],
        [0.2514, 0.0729, 0.7938, 0.5156, 0.0071]]))
trace_kwargs = {'eps': 1e-06, 'keepdim': False}
test_args = (tensor([[[0.0997, 0.8460, 0.9352, 0.6983, 0.3125],
         [0.1816, 0.9341, 0.3299, 0.5674, 0.9077],
         [0.256...5109, 0.6934],
         [0.8699, 0.4822, 0.5966, 0.0111, 0.1851],
         [0.5347, 0.5181, 0.9687, 0.6786, 0.7669]]]))
test_kwargs = {'eps': 1e-06, 'keepdim': False}, target = 'numpy', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function euclidean_distance at 0x7f13e9a6be20>, fn_name = 'kornia.geometry.linalg.euclidean_distance'
trace_args = (tensor([[0.1154, 0.7799, 0.1216, 0.1660, 0.1282],
        [0.1649, 0.9167, 0.1979, 0.0921, 0.4657],
        [0.0229, ... 0.0692, 0.9179],
        [0.1936, 0.8638, 0.1893, 0.2224, 0.1350],
        [0.2514, 0.0729, 0.7938, 0.5156, 0.0071]]))
trace_kwargs = {'eps': 1e-06, 'keepdim': False}
test_args = (tensor([[[0.0997, 0.8460, 0.9352, 0.6983, 0.3125],
         [0.1816, 0.9341, 0.3299, 0.5674, 0.9077],
         [0.256...5109, 0.6934],
         [0.8699, 0.4822, 0.5966, 0.0111, 0.1851],
         [0.5347, 0.5181, 0.9687, 0.6786, 0.7669]]]))
test_kwargs = {'eps': 1e-06, 'keepdim': False}, target = 'numpy', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:232: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[0.11541265, 0.7799338 , 0.12159199, 0.16600496, 0.1282416 ],
       [0.16486967, 0.9166542 , 0.19787437, 0.09209079, 0.46565133],
       [0.02294958, 0.9000669 , 0.13348758, 0.93467534, 0.6861471 ]],
      dtype=float32)
y = array([[0.21630698, 0.966229  , 0.24390358, 0.06919372, 0.9179199 ],
       [0.19362485, 0.8638167 , 0.18928534, 0.22239554, 0.13504899],
       [0.25142717, 0.07288265, 0.7937545 , 0.51563036, 0.00710142]],
      dtype=float32)
keepdim = False, eps = 1e-06

    def numpy_euclidean_distance(x, y, keepdim=False, eps=1e-06):
        from ..core.check import numpy_KORNIA_CHECK_SHAPE
        from ...ivy.functional.frontends.torch.tensor import numpy_sqrt_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_sum_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_pow_frnt_
    
        numpy_KORNIA_CHECK_SHAPE(x, ["*", "N"])
        numpy_KORNIA_CHECK_SHAPE(y, ["*", "N"])
        return numpy_sqrt_frnt_(
>           numpy_sum_frnt_(numpy_pow_frnt_(x - y + eps, 2), -1, keepdim)
        )

ivy_transpiled_outputs/numpy_outputs/kornia/geometry/linalg.py:37: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (array([[-0.10089333, -0.18629421, -0.12231059,  0.09681223, -0.78967726],
       [-0.02875419,  0.05283855,  0.008590...0376,  0.33060336],
       [-0.2284766 ,  0.8271853 , -0.6602659 ,  0.41904598,  0.6790467 ]],
      dtype=float32), 2)
kwargs = {}, numpy_is_array_bknd = <function numpy_is_array_bknd at 0x7f1390b03250>
array_like = array([[-0.10089333, -0.18629421, -0.12231059,  0.09681223, -0.78967726],
       [-0.02875419,  0.05283855,  0.0085900...13030376,  0.33060336],
       [-0.2284766 ,  0.8271853 , -0.6602659 ,  0.41904598,  0.6790467 ]],
      dtype=float32)

    @functools.wraps(fn)
    def wrapper(*args, **kwargs):
        from ..functional.ivy.general import numpy_is_array_bknd
    
        array_like = args[0]
        if hasattr(array_like, "__class__") and array_like.__class__.__name__ in [
            "list",
            "tuple",
        ]:
            array_like = array_like[0]
        if numpy_is_array_bknd(array_like):
>           return fn(*args, **kwargs)

ivy_transpiled_outputs/numpy_outputs/ivy/utils/decorator_utils.py:200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = array([[-0.10089333, -0.18629421, -0.12231059,  0.09681223, -0.78967726],
       [-0.02875419,  0.05283855,  0.0085900...13030376,  0.33060336],
       [-0.2284766 ,  0.8271853 , -0.6602659 ,  0.41904598,  0.6790467 ]],
      dtype=float32)
exponent = 2

    @numpy_handle_methods
    def numpy_pow_frnt_(tensor, exponent):
        from .pointwise_ops import numpy_pow_frnt
    
>       return numpy_pow_frnt(tensor, exponent)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/tensor.py:147: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (array([[-0.10089333, -0.18629421, -0.12231059,  0.09681223, -0.78967726],
       [-0.02875419,  0.05283855,  0.008590...0376,  0.33060336],
       [-0.2284766 ,  0.8271853 , -0.6602659 ,  0.41904598,  0.6790467 ]],
      dtype=float32), 2)
kwargs = {}, numpy_is_array_bknd = <function numpy_is_array_bknd at 0x7f1390b03250>
array_like = array([[-0.10089333, -0.18629421, -0.12231059,  0.09681223, -0.78967726],
       [-0.02875419,  0.05283855,  0.0085900...13030376,  0.33060336],
       [-0.2284766 ,  0.8271853 , -0.6602659 ,  0.41904598,  0.6790467 ]],
      dtype=float32)

    @functools.wraps(fn)
    def wrapper(*args, **kwargs):
        from ..functional.ivy.general import numpy_is_array_bknd
    
        array_like = args[0]
        if hasattr(array_like, "__class__") and array_like.__class__.__name__ in [
            "list",
            "tuple",
        ]:
            array_like = array_like[0]
        if numpy_is_array_bknd(array_like):
>           return fn(*args, **kwargs)

ivy_transpiled_outputs/numpy_outputs/ivy/utils/decorator_utils.py:200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = array([[-0.10089333, -0.18629421, -0.12231059,  0.09681223, -0.78967726],
       [-0.02875419,  0.05283855,  0.0085900...13030376,  0.33060336],
       [-0.2284766 ,  0.8271853 , -0.6602659 ,  0.41904598,  0.6790467 ]],
      dtype=float32)
exponent = array(2)

    @numpy_handle_methods
    def numpy_pow_frnt(input, exponent, *, out=None):
        from ...ivy.general import numpy_is_array_bknd
        from .creation_ops import numpy_as_tensor_frnt
        from ...backends.numpy.creation import numpy_asarray
        from .__init__ import numpy_promote_types_of_torch_inputs_frnt
        from ...ivy.data_type import numpy_is_int_dtype_bknd
        from ...backends.numpy.elementwise import numpy_pow
        from ...backends.numpy.utility import numpy_any
        from ...backends.numpy.searching import numpy_where
        from ...backends.numpy.elementwise import numpy_bitwise_and
        from ....data_classes.array.data_type import numpy_astype_bknd_
    
        if not numpy_is_array_bknd(input):
            input = numpy_as_tensor_frnt(input)
        if not numpy_is_array_bknd(exponent):
            if (
                any(dtype in str(input.dtype) for dtype in ["int8", "int16"])
                and isinstance(exponent, (int,))
                or "float16" in str(input.dtype)
                and isinstance(exponent, (float,))
            ):
                exponent = numpy_asarray(exponent, dtype=input.dtype)
            else:
                exponent = numpy_as_tensor_frnt(exponent)
>       input, exponent = numpy_promote_types_of_torch_inputs_frnt(input, exponent)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/pointwise_ops.py:91: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x1 = array([[-0.10089333, -0.18629421, -0.12231059,  0.09681223, -0.78967726],
       [-0.02875419,  0.05283855,  0.0085900...13030376,  0.33060336],
       [-0.2284766 ,  0.8271853 , -0.6602659 ,  0.41904598,  0.6790467 ]],
      dtype=float32)
x2 = array(2)

    def numpy_promote_types_of_torch_inputs_frnt(x1, x2, /):
        from ...ivy.general import numpy_isscalar_bknd
        from ...ivy.data_type import numpy_is_int_dtype_bknd
        from ...backends.numpy.creation import numpy_asarray
        from ...ivy.data_type import numpy_default_dtype_bknd
        from .tensor import numpy_shape_frnt_
        from ...ivy.device import numpy_default_device_bknd
        from ....data_classes.array.data_type import numpy_astype_bknd_
    
        """Promote the dtype of the given native array inputs to a common dtype
        based on type promotion rules.
    
        While passing float or integer values or any other non-array input
        to this function, it should be noted that the return will be an
        array-like object. Therefore, outputs from this function should be
        used as inputs only for those functions that expect an array-like or
        tensor-like objects, otherwise it might give unexpected results.
        """
        if (
            numpy_isscalar_bknd(x1) or isinstance(x1, (list, tuple))
        ) and numpy_is_int_dtype_bknd(x1):
            x1 = numpy_asarray(x1, dtype="int64")
        elif numpy_isscalar_bknd(x1) or isinstance(x1, (list, tuple)):
            x1 = numpy_asarray(x1)
        if (
            numpy_isscalar_bknd(x2) or isinstance(x2, (list, tuple))
        ) and numpy_is_int_dtype_bknd(x2):
            x2 = numpy_asarray(x2, dtype="int64")
        elif numpy_isscalar_bknd(x2) or isinstance(x2, (list, tuple)):
            x2 = numpy_asarray(x2)
        type1 = numpy_default_dtype_bknd(item=x1).strip("u123456789")
        type2 = numpy_default_dtype_bknd(item=x2).strip("u123456789")
        if numpy_shape_frnt_(x1) != () and numpy_shape_frnt_(x2) == () and type1 == type2:
            x2 = numpy_asarray(
                x2,
                dtype=x1.dtype,
                device=numpy_default_device_bknd(item=x1, as_native=False),
            )
        elif numpy_shape_frnt_(x1) == () and numpy_shape_frnt_(x2) != () and type1 == type2:
            x1 = numpy_asarray(
                x1,
                dtype=x2.dtype,
                device=numpy_default_device_bknd(item=x2, as_native=False),
            )
        elif x1.dtype != x2.dtype:
>           promoted = numpy_promote_types_torch_frnt(x1.dtype, x2.dtype)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/__init__.py:87: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

type1 = dtype('float32'), type2 = dtype('int64')

    def numpy_promote_types_torch_frnt(type1, type2, /):
        from ...backends.numpy.general import numpy_get_item
        from ...backends.numpy.data_type import numpy_as_ivy_dtype
    
        try:
            ret = numpy_get_item(
>               torch_promotion_table,
                (numpy_as_ivy_dtype(type1), numpy_as_ivy_dtype(type2)),
            )
E           NameError: name 'torch_promotion_table' is not defined

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/__init__.py:34: NameError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.linalg.euclidean_distance
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/geometry/test_linalg.py::test_euclidean_distance[numpy-s2s-False] - NameError: name 'torch_promotion_table' is not defined
=============================================================================== 1 failed, 7 passed in 258.56s (0:04:18) ================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 19 items

kornia/test_feature1.py .....F.............                                                                                                                                                      [100%]

=============================================================================================== FAILURES ===============================================================================================
____________________________________________________________________________ test_get_laf_descriptors[tensorflow-s2s-False] ____________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_get_laf_descriptors(target_framework, mode, backend_compile):
        trace_args = (
            torch.rand(1, 1, 32, 32),
            torch.rand(1, 3, 2, 3),
            kornia.feature.OriNet(pretrained=False),
        )
        trace_kwargs = {'patch_size': 32, 'grayscale_descriptor': True}
        test_args = (
            torch.rand(5, 1, 32, 32),
            torch.rand(5, 3, 2, 3),
            kornia.feature.OriNet(pretrained=False),
        )
        test_kwargs = {'patch_size': 32, 'grayscale_descriptor': True}
        class_info = {
            'trace_args': {
                2: {'object': kornia.feature.OriNet, 'kwargs': {'pretrained': False}}
            },
            'test_args': {
                2: {'object': kornia.feature.OriNet, 'kwargs': {'pretrained': False}}
            }
        }
>       _test_function(
            kornia.feature.get_laf_descriptors,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
            class_info=class_info,
        )

kornia/test_feature1.py:148: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function get_laf_descriptors at 0x7f1b5cabdb40>
trace_args = (tensor([[[[0.0785, 0.9228, 0.6496,  ..., 0.6341, 0.3945, 0.1880],
          [0.3375, 0.1071, 0.8542,  ..., 0.0188, 0...., kernel_size=(8, 8), stride=(1, 1), padding=(1, 1))
    (20): Tanh()
    (21): AdaptiveAvgPool2d(output_size=1)
  )
))
trace_kwargs = {'grayscale_descriptor': True, 'patch_size': 32}
test_args = (tensor([[[[0.0106, 0.3812, 0.6707,  ..., 0.9229, 0.1660, 0.4272],
          [0.4784, 0.5774, 0.2961,  ..., 0.5717, 0...., kernel_size=(8, 8), stride=(1, 1), padding=(1, 1))
    (20): Tanh()
    (21): AdaptiveAvgPool2d(output_size=1)
  )
))
test_kwargs = {'grayscale_descriptor': True, 'patch_size': 32}, target = 'tensorflow', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = True
class_info = {'test_args': {2: {'kwargs': {'pretrained': False}, 'object': <class 'kornia.feature.orientation.OriNet'>}}, 'trace_args': {2: {'kwargs': {'pretrained': False}, 'object': <class 'kornia.feature.orientation.OriNet'>}}}

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function get_laf_descriptors at 0x7f1b5cabdb40>, fn_name = 'kornia.feature.get_laf_descriptors'
trace_args = (tensor([[[[0.0785, 0.9228, 0.6496,  ..., 0.6341, 0.3945, 0.1880],
          [0.3375, 0.1071, 0.8542,  ..., 0.0188, 0...., kernel_size=(8, 8), stride=(1, 1), padding=(1, 1))
    (20): Tanh()
    (21): AdaptiveAvgPool2d(output_size=1)
  )
))
trace_kwargs = {'grayscale_descriptor': True, 'patch_size': 32}
test_args = (tensor([[[[0.0106, 0.3812, 0.6707,  ..., 0.9229, 0.1660, 0.4272],
          [0.4784, 0.5774, 0.2961,  ..., 0.5717, 0...., kernel_size=(8, 8), stride=(1, 1), padding=(1, 1))
    (20): Tanh()
    (21): AdaptiveAvgPool2d(output_size=1)
  )
))
test_kwargs = {'grayscale_descriptor': True, 'patch_size': 32}, target = 'tensorflow', backend_compile = False, tolerance = 0.001, deterministic = True
class_info = {'test_args': {2: {'kwargs': {'pretrained': False}, 'object': <class 'kornia.feature.orientation.OriNet'>}}, 'trace_args': {2: {'kwargs': {'pretrained': False}, 'object': <class 'kornia.feature.orientation.OriNet'>}}}

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
>       [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]

helpers.py:331: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

.0 = <zip object at 0x7f1b0075e6c0>

>   [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]

helpers.py:331: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

original_model = OriNet(
  (features): Sequential(
    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False...2, kernel_size=(8, 8), stride=(1, 1), padding=(1, 1))
    (20): Tanh()
    (21): AdaptiveAvgPool2d(output_size=1)
  )
)
translated_model = tensorflow_OriNet(
  (features): tensorflow_Sequential(
    (0): KerasConv2D()
    (1): KerasBatchNorm2D()
    (2): te...tensorflow_Dropout()
    (19): KerasConv2D()
    (20): tensorflow_Tanh()
    (21): tensorflow_AdaptiveAvgPool2d()
  )
)

    def sync_models(
        original_model: "nn.Module",
        translated_model: Union["keras.Model", "KerasModel", "nnx.Module", "FlaxModel"],
    ):
        """Synchronizes the weights and buffers between a native PyTorch model
        (`torch.nn.Module`) and it's translated version in TensorFlow or Flax.
    
        Args:
        ----
            original_model (torch.nn.Module): The PyTorch model to synchronize from.
            translated_model (tf.keras.Model or nnx.Module): The target model to synchronize to,
                                                      either a TensorFlow or Flax model.
        """
        if not _is_submodule(original_model, "torch"):
            raise ivy.utils.exceptions.IvyException(
                "sync_models expected an instance of `nn.Module` as the first argument. got {}".format(
                    original_model
                )
            )
        if _is_submodule(translated_model, "keras"):
>           sync_models_torch_and_tf(original_model, translated_model)

../ivy/ivy/stateful/utilities.py:796: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

model_pt = OriNet(
  (features): Sequential(
    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False...2, kernel_size=(8, 8), stride=(1, 1), padding=(1, 1))
    (20): Tanh()
    (21): AdaptiveAvgPool2d(output_size=1)
  )
)
model_tf = tensorflow_OriNet(
  (features): tensorflow_Sequential(
    (0): KerasConv2D()
    (1): KerasBatchNorm2D()
    (2): te...tensorflow_Dropout()
    (19): KerasConv2D()
    (20): tensorflow_Tanh()
    (21): tensorflow_AdaptiveAvgPool2d()
  )
)

    def sync_models_torch_and_tf(
        model_pt: "nn.Module", model_tf: Union["keras.Model", "KerasModel"]
    ):
        """Synchronizes the weights and buffers between a PyTorch model
        (`torch.nn.Module`) and a TensorFlow model (`keras.Model`).
    
        This function ensures that both models have identical parameters and buffers by
        iterating through their submodules and synchronizing them. The TensorFlow model
        must either be an instance of `KerasModel` or have submodules that inherit from the
        translated `KerasModel`/`KerasLayer`, and expose interfaces similar to `torch.nn.Module`,
        including `named_parameters()` and `named_buffers()`.
    
        Args:
        ----
            model_pt (torch.nn.Module): The PyTorch model to synchronize from.
            model_tf (keras.Model): The TensorFlow model to synchronize to, with submodules
                                    inheriting from the custom `KerasModel`/`KerasLayer` class.
    
        Returns:
        -------
            None
    
    
        Example:
        -------
            ```python
            import torch.nn as nn
            import keras
    
            #`CustomKerasLinear` is a subclass of `Layer` that exposes a similar
            # interface to torch.nn.Module (with named_parameters and named_buffers).
            class CustomKerasLinear(Layer):
                def __init__(self, in_features, out_features):
                    super(CustomKerasLinear, self).__init__()
                    self.weight = tf.Variable(tf.random.normal([out_features, in_features]))
                    self.bias = tf.Variable(tf.random.normal([out_features]))
    
                def call(self, x):
                    return tf.matmul(x, self.weight) + self.bias
    
                def named_parameters(self):
                            return [("weight", self.weight), ("bias", self.bias)]
    
                def named_buffers(self):
                            return []
    
                def eval(self):
                    return False
    
            #`NativeKerasModel` is a subclass of keras.Model and does NOT exposes a similar
            # interface to torch.nn.Module (with named_parameters and named_buffers).
            class NativeKerasModel(keras.Model):
                def __init__(self):
                    super(NativeKerasModel, self).__init__()
                    self.linear = CustomKerasLinear(10, 5)
    
                def call(self, x):
                    return self.linear(x)
    
            class PyTorchModel(nn.Module):
                def __init__(self):
                    super(PyTorchModel, self).__init__()
                    self.linear = nn.Linear(10, 5)
    
                def forward(self, x):
                    return self.linear(x)
    
            # Instantiate both models
            model_pt = PyTorchModel()  # PyTorch model
            model_tf = NativeKerasModel()  # Native Keras model inheriting from keras.Model
    
            # Sync all submodules between the PyTorch and Keras models
            sync_models_torch_and_tf(model_pt, model_tf)
            ```
        """
    
        def _compute_module_dict_tf(model, prefix=""):
            _module_dict = dict()
            for key, value in model.__dict__.items():
                if isinstance(value, (tf.keras.Model, tf.keras.layers.Layer)):
                    if not hasattr(value, "named_parameters"):
                        _module_dict.update(
                            _compute_module_dict_tf(value, prefix=f"{key}.")
                        )
                    else:
                        _module_dict[prefix + key] = value
            return _module_dict
    
        try:
            pass
        except ModuleNotFoundError as exc:
            raise ModuleNotFoundError(
                "`torch` was not found installed on your system. Please proceed "
                "to install it and restart your interpreter to see the changes."
            ) from exc
    
        try:
            import tensorflow as tf
        except ModuleNotFoundError as exc:
            raise ModuleNotFoundError(
                "`tensorflow` was not found installed on your system. Please proceed "
                "to install it and restart your interpreter to see the changes."
            ) from exc
    
        if hasattr(model_tf, "named_parameters"):
>           _sync_models_torch_and_tf(model_pt, model_tf)

../ivy/ivy/stateful/utilities.py:626: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

model1 = OriNet(
  (features): Sequential(
    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False...2, kernel_size=(8, 8), stride=(1, 1), padding=(1, 1))
    (20): Tanh()
    (21): AdaptiveAvgPool2d(output_size=1)
  )
)
model2 = tensorflow_OriNet(
  (features): tensorflow_Sequential(
    (0): KerasConv2D()
    (1): KerasBatchNorm2D()
    (2): te...tensorflow_Dropout()
    (19): KerasConv2D()
    (20): tensorflow_Tanh()
    (21): tensorflow_AdaptiveAvgPool2d()
  )
)

    def _sync_models_torch_and_tf(model1: "nn.Module", model2: "KerasModel"):
        """Synchronizes the parameters and buffers of the original and the
        translated model.
    
        Args:
        ----
            model1 (torch.nn.Module): The original PyTorch model.
            model2 (ivy.Module converted keras.Model)): The converted ivy.Module converted keras.Model.
    
        Returns:
        -------
            None
        """
        def _pt_name_to_keras_name(layer, weight_name):
            if layer.__class__.__name__ in ("KerasConv2D", "KerasDense"):
                param_and_buff_map = {
                    "weight": "_kernel",
                    "bias": "bias",
                }
            elif layer.__class__.__name__ == "KerasDepthwiseConv2D":
                if parse(keras.__version__).major > 2:
                    param_and_buff_map = {
                        "weight": "kernel",
                        "bias": "bias",
                    }
                else:
                    param_and_buff_map = {
                        "weight": "depthwise_kernel",
                        "bias": "bias",
                    }
            elif layer.__class__.__name__ == "KerasBatchNorm2D":
                param_and_buff_map = {
                    "weight": "gamma",
                    "bias": "beta",
                    "running_mean": "moving_mean",
                    "running_var": "moving_variance",
                    "num_batches_tracked": "num_batches_tracked",
                }
            else:
                raise ValueError(f"Layer '{layer}' is not supported.")
    
            return param_and_buff_map[weight_name]
    
        def _maybe_update_keras_layer_weights(layer, weight_name, new_weight, original_weight):
            # Update the weight in the retrieved layer
            if hasattr(layer, weight_name):
                layer._is_built = True
                weight_var = getattr(layer, weight_name)
                if isinstance(weight_var, tf.Variable):
                    weight_var.assign(tf.Variable(new_weight, dtype=weight_var.dtype))
                elif isinstance(weight_var, KerasVariable):
                    weight_var.assign(
                        KerasVariable(
                            new_weight, dtype=weight_var.dtype, name=weight_var.name
                        )
                    )
                else:
                    setattr(
                        layer,
                        weight_name,
                        tf.convert_to_tensor(original_weight, dtype=weight_var.dtype),
                    )
                # now also update the PT placeholder weights for this layer
                layer._is_built = False
                pt_weight_name = (
                    "pt_weight"
                    if weight_name == "weight"
                    else "pt_bias" if weight_name == "bias" else weight_name
                )
                setattr(
                    layer,
                    pt_weight_name,
                    None if original_weight is None else tf.convert_to_tensor(original_weight, dtype=weight_var.dtype),
                )
            else:
                raise AttributeError(
                    f"Layer '{layer}' does not have a weight named '{weight_name}'"
                )
    
        import torch
        import tensorflow as tf
        import keras
    
        if parse(keras.__version__).major > 2:
            KerasVariable = keras.src.backend.Variable
        else:
            KerasVariable = tf.Variable
    
        has_keras_layers = os.environ.get("USE_NATIVE_FW_LAYERS", "true") == "true"
        transpose_weights = (
            has_keras_layers
            or os.environ.get("APPLY_TRANSPOSE_OPTIMIZATION", "true") == "true"
        )
    
        params1 = dict(model1.named_parameters())
        params2 = dict(model2.named_parameters())
        buffers1 = dict(model1.named_buffers())
        buffers2 = dict(model2.named_buffers())
        # TODO: remove this once the stateful attribute name-conflict has been resolved.
        key_mapping = {}
        for k in params2.keys():
            key_mapping[k.replace("pt_", "")] = k
    
        for k in buffers2.keys():
            key_mapping[k.replace("pt_", "")] = k
    
        params2 = {k.replace("pt_", ""): v for k, v in params2.items()}
        buffers2 = {k.replace("pt_", ""): v for k, v in buffers2.items()}
    
        # Check if both models have the same parameters and buffers
        assert params1.keys() == params2.keys()
        assert buffers1.keys() == buffers2.keys()
    
        # Set the parameters and buffers of the second model to be the same as the first model
        with torch.no_grad():
            for name in params1:
                layer, weight_name = _retrive_layer(model2, key_mapping[name])
    
                params1_np = params1[name].cpu().detach().numpy()
                # Transpose the parameters to match the TensorFlow format
                params1_np = transpose_weights_pt_to_tf_jax(layer, params1_np, transpose_weights, fw='tensorflow')
    
                # inplace update the native keras layer. This is done as the parameters in
                # self.v are a different copy than the parameters in self.weights. Hence, we
                # need to explicitly update self.weights, otherwise the changes won't reflect.
                if layer.__class__.__name__.startswith("Keras"):
                    keras_name = _pt_name_to_keras_name(layer, weight_name)
>                   _maybe_update_keras_layer_weights(
                        layer=layer, weight_name=weight_name, new_weight=params1_np, original_weight=params1[name].cpu().detach().numpy()
                    )

../ivy/ivy/stateful/utilities.py:460: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

layer = KerasConv2D(), weight_name = 'weight'
new_weight = array([[[[ 0.05678412, -0.20282948,  0.2530715 ,  0.08863219,
          -0.02489261, -0.22220072, -0.09047711, -0.1685...54699, -0.04944512,  0.02747289,
           0.03948478, -0.01115235, -0.29681787,  0.07257947]]]],
      dtype=float32)
original_weight = array([[[[ 0.05678412, -0.09282224,  0.10190165],
         [ 0.2613805 ,  0.0948174 ,  0.20408389],
         [ 0.25873...,
         [ 0.02439491, -0.24502961,  0.01139379],
         [-0.00630335,  0.18551466,  0.07257947]]]], dtype=float32)

    def _maybe_update_keras_layer_weights(layer, weight_name, new_weight, original_weight):
        # Update the weight in the retrieved layer
        if hasattr(layer, weight_name):
            layer._is_built = True
>           weight_var = getattr(layer, weight_name)

../ivy/ivy/stateful/utilities.py:380: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = KerasConv2D(), name = 'weight'

    def __getattribute__(self, name):
        built = object.__getattribute__(self, "__dict__").get("_is_built", False)
        use_bias = object.__getattribute__(self, "__dict__").get("use_bias", True)
        if built:
            attr_map = {"weight": "_kernel", "bias": "bias"}
        else:
            attr_map = {"weight": "pt_weight", "bias": "pt_bias"}
        if not use_bias:
            attr_map["bias"] = "pt_bias"
        new_name = attr_map[name] if name in attr_map else name
>       return super().__getattribute__(new_name)
E       AttributeError: 'KerasConv2D' object has no attribute '_kernel'. Did you mean: 'weights'?

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful_layers.py:626: AttributeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.integrated.get_laf_descriptors
All parameters and buffers are now synced!
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/test_feature1.py::test_get_laf_descriptors[tensorflow-s2s-False] - AttributeError: 'KerasConv2D' object has no attribute '_kernel'. Did you mean: 'weights'?
============================================================================== 1 failed, 18 passed in 1512.89s (0:25:12) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 3 items

kornia/augmentation/test_auto.py FFF                                                                                                                                                             [100%]

=============================================================================================== FAILURES ===============================================================================================
___________________________________________________________________________________ test_AutoAugment[jax-s2s-False] ____________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_AutoAugment(target_framework, mode, backend_compile):
        print("kornia.augmentation.auto.AutoAugment")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledAutoAugment = ivy.transpile(
            kornia.augmentation.auto.AutoAugment,
            source="torch",
            target=target_framework,
        )
    
        torch_aug = kornia.augmentation.auto.AutoAugment()
>       transpiled_aug = TranspiledAutoAugment()

kornia/augmentation/test_auto.py:29: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.augmentation.auto.autoaugment.autoaugment.jax_AutoAugment'>, args = (), kwargs = {}

    def __call__(cls, *args: Any, **kwargs: Any) -> Any:
>     return _graph_node_meta_call(cls, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.augmentation.auto.autoaugment.autoaugment.jax_AutoAugment'>, args = (), kwargs = {}
node = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] jax_AutoAugment object at 0x7f7ba9d7e920>

    def _graph_node_meta_call(cls: tp.Type[G], *args, **kwargs) -> G:
      node = cls.__new__(cls, *args, **kwargs)
      vars(node)['_object__state'] = ObjectState()
>     cls._object_meta_construct(node, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:88: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.augmentation.auto.autoaugment.autoaugment.jax_AutoAugment'>
self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] jax_AutoAugment object at 0x7f7ba9d7e920>, args = (), kwargs = {}

    def _object_meta_construct(cls, self, *args, **kwargs):
>     self.__init__(*args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:82: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] jax_AutoAugment object at 0x7f7ba9d7e920>, policy = 'imagenet', transformation_matrix_mode = 'silent'

    def __init__(self, policy="imagenet", transformation_matrix_mode="silent"):
        from ....core._backend import tensor
        from .....torch.distributions.categorical import jax_Categorical
    
        if policy == "imagenet":
            _policy = imagenet_policy
        elif policy == "cifar10":
            _policy = cifar10_policy
        elif policy == "svhn":
            _policy = svhn_policy
        elif isinstance(policy, (list, tuple)):
            _policy = policy
        else:
            raise NotImplementedError(f"Invalid policy `{policy}`.")
>       super().__init__(_policy, transformation_matrix_mode=transformation_matrix_mode)

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/auto/autoaugment/autoaugment.py:127: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] jax_AutoAugment object at 0x7f7ba9d7e920>
args = ([[('posterize', 0.4, 8), ('rotate', 0.6, 9)], [('solarize', 0.6, 5), ('auto_contrast', 0.6, None)], [('equalize', 0.8...rize', 0.6, 6)], [('equalize', 0.4, None), ('solarize', 0.2, 4)], [('equalize', 0.4, None), ('rotate', 0.8, 8)], ...],)
kwargs = {'transformation_matrix_mode': 'silent'}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/utils/decorator_utils.py:245: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] jax_AutoAugment object at 0x7f7ba9d7e920>
policy = [[('posterize', 0.4, 8), ('rotate', 0.6, 9)], [('solarize', 0.6, 5), ('auto_contrast', 0.6, None)], [('equalize', 0.8,...terize', 0.6, 6)], [('equalize', 0.4, None), ('solarize', 0.2, 4)], [('equalize', 0.4, None), ('rotate', 0.8, 8)], ...]
transformation_matrix_mode = 'silent'

    @jax_store_config_info
    def __init__(self, policy, transformation_matrix_mode="silence"):
        from .operations.policy import jax_PolicySequential
    
>       policies = self.compose_policy(policy)

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/auto/base.py:41: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] jax_AutoAugment object at 0x7f7ba9d7e920>
policy = [[('posterize', 0.4, 8), ('rotate', 0.6, 9)], [('solarize', 0.6, 5), ('auto_contrast', 0.6, None)], [('equalize', 0.8,...terize', 0.6, 6)], [('equalize', 0.4, None), ('solarize', 0.2, 4)], [('equalize', 0.4, None), ('rotate', 0.8, 8)], ...]

    def compose_policy(self, policy):
>       return [self.compose_subpolicy_sequential(subpolicy) for subpolicy in policy]

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/auto/base.py:54: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

.0 = <list_iterator object at 0x7f7ba9d7df60>

>   return [self.compose_subpolicy_sequential(subpolicy) for subpolicy in policy]

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/auto/base.py:54: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] jax_AutoAugment object at 0x7f7ba9d7e920>, subpolicy = [('posterize', 0.4, 8), ('rotate', 0.6, 9)]

    def compose_subpolicy_sequential(self, subpolicy):
        from ..operations.policy import jax_PolicySequential
    
        return jax_PolicySequential(
>           *[
                getattr(kornia.augmentation.auto.autoaugment.ops, name)(prob, mag)
                for name, prob, mag in subpolicy
            ]
        )

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/auto/autoaugment/autoaugment.py:135: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

.0 = <list_iterator object at 0x7f7ba9d7fa30>

        *[
>           getattr(kornia.augmentation.auto.autoaugment.ops, name)(prob, mag)
            for name, prob, mag in subpolicy
        ]
    )
E   NameError: name 'kornia' is not defined

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/auto/autoaugment/autoaugment.py:136: NameError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.auto.AutoAugment
___________________________________________________________________________________ test_RandAugment[jax-s2s-False] ____________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_RandAugment(target_framework, mode, backend_compile):
        print("kornia.augmentation.auto.RandAugment")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledRandAugment = ivy.transpile(
            kornia.augmentation.auto.RandAugment,
            source="torch",
            target=target_framework,
        )
    
        torch_aug = kornia.augmentation.auto.RandAugment(n=2, m=10)
>       transpiled_aug = TranspiledRandAugment(n=2, m=10)

kornia/augmentation/test_auto.py:69: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.augmentation.auto.rand_augment.rand_augment.jax_RandAugment'>, args = (), kwargs = {'m': 10, 'n': 2}

    def __call__(cls, *args: Any, **kwargs: Any) -> Any:
>     return _graph_node_meta_call(cls, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.augmentation.auto.rand_augment.rand_augment.jax_RandAugment'>, args = (), kwargs = {'m': 10, 'n': 2}
node = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] jax_RandAugment object at 0x7f7ba95a1de0>

    def _graph_node_meta_call(cls: tp.Type[G], *args, **kwargs) -> G:
      node = cls.__new__(cls, *args, **kwargs)
      vars(node)['_object__state'] = ObjectState()
>     cls._object_meta_construct(node, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:88: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.augmentation.auto.rand_augment.rand_augment.jax_RandAugment'>
self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] jax_RandAugment object at 0x7f7ba95a1de0>, args = (), kwargs = {'m': 10, 'n': 2}

    def _object_meta_construct(cls, self, *args, **kwargs):
>     self.__init__(*args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:82: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] jax_RandAugment object at 0x7f7ba95a1de0>, n = 2, m = 10, policy = None, transformation_matrix_mode = 'silent'

    def __init__(self, n, m, policy=None, transformation_matrix_mode="silent"):
        if m <= 0 or m >= 30:
            raise ValueError(f"Expect `m` in [0, 30]. Got {m}.")
        if policy is None:
            _policy = default_policy
        else:
            _policy = policy
>       super().__init__(_policy, transformation_matrix_mode=transformation_matrix_mode)

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/auto/rand_augment/rand_augment.py:58: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] jax_RandAugment object at 0x7f7ba95a1de0>
args = ([[('auto_contrast', 0, 1)], [('equalize', 0, 1)], [('invert', 0, 1)], [('rotate', -30.0, 30.0)], [('posterize', 0.0, 4)], [('solarize', 0.0, 1.0)], ...],)
kwargs = {'transformation_matrix_mode': 'silent'}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/utils/decorator_utils.py:245: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] jax_RandAugment object at 0x7f7ba95a1de0>
policy = [[('auto_contrast', 0, 1)], [('equalize', 0, 1)], [('invert', 0, 1)], [('rotate', -30.0, 30.0)], [('posterize', 0.0, 4)], [('solarize', 0.0, 1.0)], ...], transformation_matrix_mode = 'silent'

    @jax_store_config_info
    def __init__(self, policy, transformation_matrix_mode="silence"):
        from .operations.policy import jax_PolicySequential
    
>       policies = self.compose_policy(policy)

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/auto/base.py:41: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] jax_RandAugment object at 0x7f7ba95a1de0>
policy = [[('auto_contrast', 0, 1)], [('equalize', 0, 1)], [('invert', 0, 1)], [('rotate', -30.0, 30.0)], [('posterize', 0.0, 4)], [('solarize', 0.0, 1.0)], ...]

    def compose_policy(self, policy):
>       return [self.compose_subpolicy_sequential(subpolicy) for subpolicy in policy]

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/auto/base.py:54: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

.0 = <list_iterator object at 0x7f7bab489240>

>   return [self.compose_subpolicy_sequential(subpolicy) for subpolicy in policy]

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/auto/base.py:54: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] jax_RandAugment object at 0x7f7ba95a1de0>, subpolicy = [('auto_contrast', 0, 1)]

    def compose_subpolicy_sequential(self, subpolicy):
        from ..operations.policy import jax_PolicySequential
    
        if len(subpolicy) != 1:
            raise RuntimeError(
                f"Each policy must have only one operation for RandAugment. Got {len(subpolicy)}."
            )
        name, low, high = subpolicy[0][0], subpolicy[0][1], subpolicy[0][2]
        return jax_PolicySequential(
>           *[getattr(kornia.augmentation.auto.rand_augment.ops, name)(low, high)]
        )
E       NameError: name 'kornia' is not defined

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/auto/rand_augment/rand_augment.py:81: NameError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.auto.RandAugment
__________________________________________________________________________________ test_TrivialAugment[jax-s2s-False] __________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_TrivialAugment(target_framework, mode, backend_compile):
        print("kornia.augmentation.auto.TrivialAugment")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledTrivialAugment = ivy.transpile(
            kornia.augmentation.auto.TrivialAugment,
            source="torch",
            target=target_framework,
        )
    
        torch_aug = kornia.augmentation.auto.TrivialAugment()
>       transpiled_aug = TranspiledTrivialAugment()

kornia/augmentation/test_auto.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.augmentation.auto.trivial_augment.trivial_augment.jax_TrivialAugment'>, args = (), kwargs = {}

    def __call__(cls, *args: Any, **kwargs: Any) -> Any:
>     return _graph_node_meta_call(cls, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.augmentation.auto.trivial_augment.trivial_augment.jax_TrivialAugment'>, args = (), kwargs = {}
node = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] jax_TrivialAugment object at 0x7f7ba95a0070>

    def _graph_node_meta_call(cls: tp.Type[G], *args, **kwargs) -> G:
      node = cls.__new__(cls, *args, **kwargs)
      vars(node)['_object__state'] = ObjectState()
>     cls._object_meta_construct(node, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:88: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.augmentation.auto.trivial_augment.trivial_augment.jax_TrivialAugment'>
self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] jax_TrivialAugment object at 0x7f7ba95a0070>, args = (), kwargs = {}

    def _object_meta_construct(cls, self, *args, **kwargs):
>     self.__init__(*args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:82: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] jax_TrivialAugment object at 0x7f7ba95a0070>, policy = None, transformation_matrix_mode = 'silent'

    def __init__(self, policy=None, transformation_matrix_mode="silent"):
        from .....ivy.functional.frontends.torch.creation_ops import jax_tensor_frnt
        from .....torch.distributions.categorical import jax_Categorical
    
        if policy is None:
            _policy = default_policy
        else:
            _policy = policy
>       super().__init__(_policy, transformation_matrix_mode=transformation_matrix_mode)

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/auto/trivial_augment/trivial_augment.py:54: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] jax_TrivialAugment object at 0x7f7ba95a0070>
args = ([[('auto_contrast', 0, 1)], [('equalize', 0, 1)], [('rotate', -30.0, 30.0)], [('posterize', 0.0, 4)], [('solarize', 0.0, 1.0)], [('contrast', 0.1, 1.9)], ...],)
kwargs = {'transformation_matrix_mode': 'silent'}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/utils/decorator_utils.py:245: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] jax_TrivialAugment object at 0x7f7ba95a0070>
policy = [[('auto_contrast', 0, 1)], [('equalize', 0, 1)], [('rotate', -30.0, 30.0)], [('posterize', 0.0, 4)], [('solarize', 0.0, 1.0)], [('contrast', 0.1, 1.9)], ...]
transformation_matrix_mode = 'silent'

    @jax_store_config_info
    def __init__(self, policy, transformation_matrix_mode="silence"):
        from .operations.policy import jax_PolicySequential
    
>       policies = self.compose_policy(policy)

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/auto/base.py:41: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] jax_TrivialAugment object at 0x7f7ba95a0070>
policy = [[('auto_contrast', 0, 1)], [('equalize', 0, 1)], [('rotate', -30.0, 30.0)], [('posterize', 0.0, 4)], [('solarize', 0.0, 1.0)], [('contrast', 0.1, 1.9)], ...]

    def compose_policy(self, policy):
>       return [self.compose_subpolicy_sequential(subpolicy) for subpolicy in policy]

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/auto/base.py:54: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

.0 = <list_iterator object at 0x7f7ba95a0df0>

>   return [self.compose_subpolicy_sequential(subpolicy) for subpolicy in policy]

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/auto/base.py:54: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] jax_TrivialAugment object at 0x7f7ba95a0070>, subpolicy = [('auto_contrast', 0, 1)]

    def compose_subpolicy_sequential(self, subpolicy):
        from ..operations.policy import jax_PolicySequential
    
        if len(subpolicy) != 1:
            raise RuntimeError(
                f"Each policy must have only one operation for TrivialAugment. Got {len(subpolicy)}."
            )
        name, low, high = subpolicy[0][0], subpolicy[0][1], subpolicy[0][2]
        return jax_PolicySequential(
>           *[getattr(kornia.augmentation.auto.rand_augment.ops, name)(low, high)]
        )
E       NameError: name 'kornia' is not defined

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/auto/trivial_augment/trivial_augment.py:67: NameError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.auto.TrivialAugment
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/augmentation/test_auto.py::test_AutoAugment[jax-s2s-False] - NameError: name 'kornia' is not defined
FAILED kornia/augmentation/test_auto.py::test_RandAugment[jax-s2s-False] - NameError: name 'kornia' is not defined
FAILED kornia/augmentation/test_auto.py::test_TrivialAugment[jax-s2s-False] - NameError: name 'kornia' is not defined
==================================================================================== 3 failed in 1331.28s (0:22:11) ====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 1 item

kornia/geometry/test_quaternion.py F                                                                                                                                                             [100%]

=============================================================================================== FAILURES ===============================================================================================
________________________________________________________________________________ test_Quaternion[tensorflow-s2s-False] _________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_Quaternion(target_framework, mode, backend_compile):
        print("kornia.geometry.quaternion.Quaternion")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledQuaternion = ivy.transpile(Quaternion, source="torch", target=target_framework)
    
        # test Quaternion.identity
    
        torch_q = Quaternion.identity(batch_size=4)
        transpiled_q = TranspiledQuaternion.identity(batch_size=4)
    
        orig_np = _nest_array_to_numpy(torch_q.data)
        transpiled_np = _nest_array_to_numpy(transpiled_q.data)
        _check_allclose(orig_np, transpiled_np)
    
    
        # test Quaternion.__add__
    
        torch_q1 = Quaternion.identity()
        torch_q2 = Quaternion(torch.tensor([2., 0., 1., 1.]))
        torch_q3 = torch_q1 + torch_q2
        transpiled_q1 = TranspiledQuaternion.identity()
        transpiled_q2 = TranspiledQuaternion(_array_to_new_backend(torch.tensor([2., 0., 1., 1.]), target_framework))
        transpiled_q3 = transpiled_q1 + transpiled_q2
    
        orig_np = _nest_array_to_numpy(torch_q3.data)
        transpiled_np = _nest_array_to_numpy(transpiled_q3.data)
        _check_allclose(orig_np, transpiled_np)
    
    
        # test Quaternion.__init__()
    
        torch_q = Quaternion(torch.tensor([[1., 0., 0., 0.], [0., 1., 0., 0.]]))
        transpiled_q = TranspiledQuaternion(_array_to_new_backend(torch.tensor([[1., 0., 0., 0.], [0., 1., 0., 0.]]), target_framework))
    
        orig_np = _nest_array_to_numpy(torch_q.data)
        transpiled_np = _nest_array_to_numpy(transpiled_q.data)
        _check_allclose(orig_np, transpiled_np)
    
    
        # test Quaternion.__neg__()
    
        torch_q = -Quaternion(torch.tensor([1., 0., 0., 0.]))
        transpiled_q = -TranspiledQuaternion(_array_to_new_backend(torch.tensor([1., 0., 0., 0.]), target_framework))
    
        orig_np = _nest_array_to_numpy(torch_q.data)
        transpiled_np = _nest_array_to_numpy(transpiled_q.data)
        _check_allclose(orig_np, transpiled_np)
    
    
        # test Quaternion.__pow__()
    
        torch_q = Quaternion(torch.tensor([1., .5, 0., 0.])) ** 2
        transpiled_q = TranspiledQuaternion(_array_to_new_backend(torch.tensor([1., .5, 0., 0.]), target_framework)) ** 2
    
        orig_np = _nest_array_to_numpy(torch_q.data)
        transpiled_np = _nest_array_to_numpy(transpiled_q.data)
        _check_allclose(orig_np, transpiled_np)
    
    
        # test Quaternion.__sub__()
    
        torch_q1 = Quaternion(torch.tensor([2., 0., 1., 1.]))
        torch_q2 = Quaternion.identity()
        torch_q3 = torch_q1 - torch_q2
        transpiled_q1 = TranspiledQuaternion(_array_to_new_backend(torch.tensor([2., 0., 1., 1.]), target_framework))
        transpiled_q2 = TranspiledQuaternion.identity()
        transpiled_q3 = transpiled_q1 - transpiled_q2
    
        orig_np = _nest_array_to_numpy(torch_q3.data)
        transpiled_np = _nest_array_to_numpy(transpiled_q3.data)
        _check_allclose(orig_np, transpiled_np)
    
    
        # test Quaternion.coeffs
    
        torch_q = Quaternion(torch.tensor([1., 0., 0., 0.]))
        transpiled_q = TranspiledQuaternion(_array_to_new_backend(torch.tensor([1., 0., 0., 0.]), target_framework))
    
        torch_coeffs = _nest_array_to_numpy(torch_q.coeffs)
        transpiled_coeffs = _nest_array_to_numpy(transpiled_q.coeffs)
        _check_allclose(torch_coeffs, transpiled_coeffs)
    
    
        # test Quaternion.data
    
        torch_q = Quaternion(torch.tensor([1., 0., 0., 0.]))
        transpiled_q = TranspiledQuaternion(_array_to_new_backend(torch.tensor([1., 0., 0., 0.]), target_framework))
    
        orig_np = _nest_array_to_numpy(torch_q.data)
        transpiled_np = _nest_array_to_numpy(transpiled_q.data)
        _check_allclose(orig_np, transpiled_np)
    
    
        # test Quaternion.from_axis_angle()
    
        torch_q = Quaternion.from_axis_angle(torch.tensor([[1., 0., 0.]]))
        transpiled_q = TranspiledQuaternion.from_axis_angle(_array_to_new_backend(torch.tensor([[1., 0., 0.]]), target_framework))
    
        orig_np = _nest_array_to_numpy(torch_q.data)
        transpiled_np = _nest_array_to_numpy(transpiled_q.data)
        _check_allclose(orig_np, transpiled_np)
    
    
        # test Quaternion.from_coeffs()
    
        torch_q = Quaternion.from_coeffs(1., 0., 0., 0.)
        transpiled_q = TranspiledQuaternion.from_coeffs(1., 0., 0., 0.)
    
        orig_np = _nest_array_to_numpy(torch_q.data)
        transpiled_np = _nest_array_to_numpy(transpiled_q.data)
        _check_allclose(orig_np, transpiled_np)
    
    
        # test Quaternion.from_euler()
    
        roll, pitch, yaw = torch.tensor(0), torch.tensor(1), torch.tensor(0)
        torch_q = Quaternion.from_euler(roll, pitch, yaw)
>       transpiled_q = TranspiledQuaternion.from_euler(
            _array_to_new_backend(roll, target_framework), _array_to_new_backend(pitch, target_framework), _array_to_new_backend(yaw, target_framework)
        )

kornia/geometry/test_quaternion.py:137: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.tensorflow_outputs.kornia.geometry.quaternion.tensorflow_Quaternion'>, roll = <tf.Tensor: shape=(), dtype=int64, numpy=0>
pitch = <tf.Tensor: shape=(), dtype=int64, numpy=1>, yaw = <tf.Tensor: shape=(), dtype=int64, numpy=0>

    @classmethod
    def from_euler(cls, roll, pitch, yaw):
        from ..core._backend import stack
        from .conversions import tensorflow_quaternion_from_euler
    
        w, x, y, z = tensorflow_quaternion_from_euler(roll=roll, pitch=pitch, yaw=yaw)
        q = stack((w, x, y, z), -1)
>       return cls(q)

ivy_transpiled_outputs/tensorflow_outputs/kornia/geometry/quaternion.py:184: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'tensorflow_Quaternion' object has no attribute '_data'") raised in repr()] tensorflow_Quaternion object at 0x7fdcd31b8310>
data = <tf.Tensor: shape=(4,), dtype=float64, numpy=array([0.87758256, 0.        , 0.47942554, 0.        ])>

    def __init__(self, data):
        self.super___init__(
            data,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
>       self._data = tensorflow.keras.Variable(data)

ivy_transpiled_outputs/tensorflow_outputs/kornia/geometry/quaternion.py:43: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <KerasVariable shape=<unknown>, dtype=float32, path=variable_16>, initializer = <tf.Tensor: shape=(4,), dtype=float64, numpy=array([0.87758256, 0.        , 0.47942554, 0.        ])>
shape = None, dtype = 'float32', trainable = True, autocast = True, aggregation = 'mean', name = 'variable_16'

    def __init__(
        self,
        initializer,
        shape=None,
        dtype=None,
        trainable=True,
        autocast=True,
        aggregation="mean",
        name=None,
    ):
        name = name or auto_name(self.__class__.__name__)
        if not isinstance(name, str) or "/" in name:
            raise ValueError(
                "Argument `name` must be a string and "
                "cannot contain character `/`. "
                f"Received: name={name}"
            )
        if aggregation not in ("mean", "sum", "only_first_replica"):
            raise ValueError(
                "Invalid valid for argument `aggregation`. Expected "
                "one of {'mean', 'sum', 'only_first_replica'}. "
                f"Received: aggregation={aggregation}"
            )
        self.name = name
        parent_path = current_path()
        if parent_path:
            self.path = current_path() + "/" + self.name
        else:
            self.path = self.name
        dtype = standardize_dtype(dtype)
        self._dtype = dtype
        self._shape = None
        self._initializer = None
        self._regularizer = None
        self._constraint = None
        self._trainable = trainable
        self._autocast = autocast
        self._aggregation = aggregation
        # `self._overwrite_with_gradient` is an internal property to determine
        # whether this variable should be overwritten by the computed gradient.
        # Ref: https://github.com/google/flax/blob/main/flax/linen/fp8_ops.py
        self._overwrite_with_gradient = False
        if isinstance(initializer, str):
            from keras.src import initializers
    
            initializer = initializers.get(initializer)
        if callable(initializer):
            if shape is None:
                raise ValueError(
                    "When creating a Variable from an initializer, "
                    "the `shape` argument should be specified. "
                    f"Received: initializer={initializer} "
                    f"and shape={shape}"
                )
    
        if in_stateless_scope():
            if callable(initializer):
                self._value = None
                self._initializer = initializer
                self._shape = self._validate_shape(shape)
                register_uninitialized_variable(self)
            else:
                raise ValueError(
                    "You are attempting to create a variable "
                    "while in a stateless scope. This is disallowed. "
                    "Make sure that all variables are created "
                    "before you start using your layer/model objects.\n\n"
                    "In some cases, you might be seeing this error "
                    "because you need to "
                    "implement a `def build(self, input_shape)` method "
                    "on your layer/model, which will "
                    "create its variables.\n\n"
                    "In some other cases, you might be seeing this error "
                    "because you are instantiating a `Variable` and "
                    "assigning it to a layer without going through "
                    "self.add_variable()/self.add_weight(). Always prefer "
                    "using these methods "
                    "(with a `shape` and `initializer` argument)."
                )
        else:
            if callable(initializer):
                self._shape = self._validate_shape(shape)
                self._initialize_with_initializer(initializer)
            else:
>               self._initialize(initializer)

/opt/fw/tensorflow/keras/src/backend/common/variables.py:165: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <KerasVariable shape=<unknown>, dtype=float32, path=variable_16>, value = <tf.Tensor: shape=(4,), dtype=float64, numpy=array([0.87758256, 0.        , 0.47942554, 0.        ])>

    def _initialize(self, value):
>       self._value = tf.Variable(
            value, dtype=self._dtype, trainable=self.trainable, name=self.name
        )

/opt/fw/tensorflow/keras/src/backend/tensorflow/core.py:35: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (<class 'tensorflow.python.ops.variables.Variable'>, <tf.Tensor: shape=(4,), dtype=float64, numpy=array([0.87758256, 0.        , 0.47942554, 0.        ])>)
kwargs = {'dtype': 'float32', 'name': 'variable_16', 'trainable': True}

    def error_handler(*args, **kwargs):
      try:
        if not is_traceback_filtering_enabled():
          return fn(*args, **kwargs)
      except NameError:
        # In some very rare cases,
        # `is_traceback_filtering_enabled` (from the outer scope) may not be
        # accessible from inside this function
        return fn(*args, **kwargs)
    
      filtered_tb = None
      try:
        return fn(*args, **kwargs)
      except Exception as e:
        filtered_tb = _process_traceback_frames(e.__traceback__)
>       raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/tensorflow/python/util/traceback_utils.py:153: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <tf.Tensor: shape=(4,), dtype=float64, numpy=array([0.87758256, 0.        , 0.47942554, 0.        ])>, dtype = tf.float32, name = 'initial_value'

    def __tf_tensor__(
        self, dtype: Optional[dtypes.DType] = None, name: Optional[str] = None
        ) -> "Tensor":
      if dtype is not None and not dtype.is_compatible_with(self.dtype):
>       raise ValueError(
            _add_error_prefix(
                f"Tensor conversion requested dtype {dtype.name} "
                f"for Tensor with dtype {self.dtype.name}: {self!r}",
                name=name))
E       ValueError: initial_value: Tensor conversion requested dtype float32 for Tensor with dtype float64: <tf.Tensor: shape=(4,), dtype=float64, numpy=array([0.87758256, 0.        , 0.47942554, 0.        ])>

/opt/fw/tensorflow/tensorflow/python/framework/tensor.py:761: ValueError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.quaternion.Quaternion
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/geometry/test_quaternion.py::test_Quaternion[tensorflow-s2s-False] - ValueError: initial_value: Tensor conversion requested dtype float32 for Tensor with dtype float64: <tf.Tensor: sh...
===================================================================================== 1 failed in 98.23s (0:01:38) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 38 items

kornia/geometry/test_conversions.py ......................................                                                                                                                       [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
=================================================================================== 38 passed in 2176.48s (0:36:16) ====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 6 items

kornia/augmentation/test_container.py FFFFFF                                                                                                                                                     [100%]

=============================================================================================== FAILURES ===============================================================================================
__________________________________________________________________________ test_AugmentationSequential[tensorflow-s2s-False] ___________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_AugmentationSequential(target_framework, mode, backend_compile):
        print("kornia.augmentation.container.AugmentationSequential")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledAugmentationSequential = ivy.transpile(
            kornia.augmentation.container.AugmentationSequential,
            source="torch",
            target=target_framework,
        )
        TranspiledColorJiggle = ivy.transpile(
            kornia.augmentation.ColorJiggle,
            source="torch",
            target=target_framework,
        )
        TranspiledRandomAffine = ivy.transpile(
            kornia.augmentation.RandomAffine,
            source="torch",
            target=target_framework,
        )
    
        torch_aug_list = kornia.augmentation.container.AugmentationSequential(
            kornia.augmentation.ColorJiggle(0.1, 0.1, 0.1, 0.1, p=1.0),
            kornia.augmentation.RandomAffine(360, p=1.0),
            data_keys=["input", "mask", "bbox", "keypoints"],
            same_on_batch=False,
            random_apply=10,
        )
        transpiled_aug_list = TranspiledAugmentationSequential(
            TranspiledColorJiggle(0.1, 0.1, 0.1, 0.1, p=1.0),
            TranspiledRandomAffine(360, p=1.0),
            data_keys=["input", "mask", "bbox", "keypoints"],
            same_on_batch=False,
            random_apply=10,
        )
    
        torch_args = (
            torch.randn(2, 3, 5, 6),
            torch.ones(2, 3, 5, 6),
            torch.tensor([[
                [1., 1.],
                [2., 1.],
                [2., 2.],
                [1., 2.],
            ]]).expand(2, 1, -1, -1),
            torch.tensor([[[1., 1.]]]).expand(2, -1, -1),
        )
        torch_out = torch_aug_list(*torch_args)
    
        transpiled_args = _nest_torch_tensor_to_new_framework(torch_args, target_framework)
>       transpiled_out = transpiled_aug_list(*transpiled_args)

kornia/augmentation/test_container.py:68: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_AugmentationSequential(
  (tensorflow_ColorJiggle_0): tensorflow_ColorJiggle(brightness=0.1, contrast=0.1, ...one, shear=None, p=1.0, p_batch=1.0, same_on_batch=False, resample=bilinear, padding_mode=zeros, align_corners=False)
)
args = (<tf.Tensor: shape=(2, 3, 5, 6), dtype=float32, numpy=
array([[[[ 0.02694258, -0.43759882, -0.40375277,  0.33740783,
 ...=float32)>, <tf.Tensor: shape=(2, 1, 2), dtype=float32, numpy=
array([[[1., 1.]],

       [[1., 1.]]], dtype=float32)>)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x7f7c93cd2c40, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...ode_context=['        return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_AugmentationSequential(
  (tensorflow_ColorJiggle_0): tensorflow_ColorJiggle(brightness=0.1, contrast=0.1,...=float32)>, <tf.Tensor: shape=(2, 1, 2), dtype=float32, numpy=
array([[[1., 1.]],

       [[1., 1.]]], dtype=float32)>)
kwargs = {}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_AugmentationSequential(
  (tensorflow_ColorJiggle_0): tensorflow_ColorJiggle(brightness=0.1, contrast=0.1, ...one, shear=None, p=1.0, p_batch=1.0, same_on_batch=False, resample=bilinear, padding_mode=zeros, align_corners=False)
)
v = None, buffers = None
args = (<tf.Tensor: shape=(2, 3, 5, 6), dtype=float32, numpy=
array([[[[ 0.02694258, -0.43759882, -0.40375277,  0.33740783,
 ...=float32)>, <tf.Tensor: shape=(2, 1, 2), dtype=float32, numpy=
array([[[1., 1.]],

       [[1., 1.]]], dtype=float32)>)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_AugmentationSequential(
  (tensorflow_ColorJiggle_0): tensorflow_ColorJiggle(brightness=0.1, contrast=0.1,...=float32)>, <tf.Tensor: shape=(2, 1, 2), dtype=float32, numpy=
array([[[1., 1.]],

       [[1., 1.]]], dtype=float32)>)
kwargs = {'buffers': None, 'v': None}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_AugmentationSequential(
  (tensorflow_ColorJiggle_0): tensorflow_ColorJiggle(brightness=0.1, contrast=0.1, ...one, shear=None, p=1.0, p_batch=1.0, same_on_batch=False, resample=bilinear, padding_mode=zeros, align_corners=False)
)
v = None, buffers = None
args = (<tf.Tensor: shape=(2, 3, 5, 6), dtype=float32, numpy=
array([[[[ 0.02694258, -0.43759882, -0.40375277,  0.33740783,
 ...=float32)>, <tf.Tensor: shape=(2, 1, 2), dtype=float32, numpy=
array([[[1., 1.]],

       [[1., 1.]]], dtype=float32)>)
kwargs = {}, replace_v = False, replace_buffers = False, call_signature = <Signature (*args, params=None, data_keys=None)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Layer, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Layer, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Layer, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_AugmentationSequential(
  (tensorflow_ColorJiggle_0): tensorflow_ColorJiggle(brightness=0.1, contrast=0.1,...e, shear=None, p=1.0, p_batch=1.0, same_on_batch=False, resample=bilinear, padding_mode=zeros, align_corners=False)
),)
kwargs = {'args': <tf.Tensor: shape=(2, 3, 5, 6), dtype=float32, numpy=
array([[[[ 0.02694258, -0.43759882, -0.40375277,  0.337...    [1., 1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1., 1.]]]], dtype=float32)>}

    @wraps(fn)
    def error_handler(*args, **kwargs):
        if not is_traceback_filtering_enabled():
            return fn(*args, **kwargs)
    
        filtered_tb = None
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            filtered_tb = _process_traceback_frames(e.__traceback__)
            # To get the full stack trace, call:
            # `keras.config.disable_traceback_filtering()`
>           raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/keras/src/utils/traceback_utils.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <Signature (*args, params=None, data_keys=None)>, args = ()
kwargs = {'args': <tf.Tensor: shape=(2, 3, 5, 6), dtype=float32, numpy=
array([[[[ 0.02694258, -0.43759882, -0.40375277,  0.337...
         [ 0.7461158 ,  0.04484735,  1.329153  , -0.67095655,
           1.4290721 , -0.13674061]]]], dtype=float32)>}

    def bind(self, /, *args, **kwargs):
        """Get a BoundArguments object, that maps the passed `args`
        and `kwargs` to the function's signature.  Raises `TypeError`
        if the passed arguments can not be bound.
        """
>       return self._bind(args, kwargs)

/opt/miniconda/envs/multienv/lib/python3.10/inspect.py:3177: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <Signature (*args, params=None, data_keys=None)>, args = ()
kwargs = {'args': <tf.Tensor: shape=(2, 3, 5, 6), dtype=float32, numpy=
array([[[[ 0.02694258, -0.43759882, -0.40375277,  0.337...
         [ 0.7461158 ,  0.04484735,  1.329153  , -0.67095655,
           1.4290721 , -0.13674061]]]], dtype=float32)>}

    def _bind(self, args, kwargs, *, partial=False):
        """Private method. Don't use directly."""
    
        arguments = {}
    
        parameters = iter(self.parameters.values())
        parameters_ex = ()
        arg_vals = iter(args)
    
        while True:
            # Let's iterate through the positional arguments and corresponding
            # parameters
            try:
                arg_val = next(arg_vals)
            except StopIteration:
                # No more positional arguments
                try:
                    param = next(parameters)
                except StopIteration:
                    # No more parameters. That's it. Just need to check that
                    # we have no `kwargs` after this while loop
                    break
                else:
                    if param.kind == _VAR_POSITIONAL:
                        # That's OK, just empty *args.  Let's start parsing
                        # kwargs
                        break
                    elif param.name in kwargs:
                        if param.kind == _POSITIONAL_ONLY:
                            msg = '{arg!r} parameter is positional only, ' \
                                  'but was passed as a keyword'
                            msg = msg.format(arg=param.name)
                            raise TypeError(msg) from None
                        parameters_ex = (param,)
                        break
                    elif (param.kind == _VAR_KEYWORD or
                                                param.default is not _empty):
                        # That's fine too - we have a default value for this
                        # parameter.  So, lets start parsing `kwargs`, starting
                        # with the current parameter
                        parameters_ex = (param,)
                        break
                    else:
                        # No default, not VAR_KEYWORD, not VAR_POSITIONAL,
                        # not in `kwargs`
                        if partial:
                            parameters_ex = (param,)
                            break
                        else:
                            msg = 'missing a required argument: {arg!r}'
                            msg = msg.format(arg=param.name)
                            raise TypeError(msg) from None
            else:
                # We have a positional argument to process
                try:
                    param = next(parameters)
                except StopIteration:
                    raise TypeError('too many positional arguments') from None
                else:
                    if param.kind in (_VAR_KEYWORD, _KEYWORD_ONLY):
                        # Looks like we have no parameter for this positional
                        # argument
                        raise TypeError(
                            'too many positional arguments') from None
    
                    if param.kind == _VAR_POSITIONAL:
                        # We have an '*args'-like argument, let's fill it with
                        # all positional arguments we have left and move on to
                        # the next phase
                        values = [arg_val]
                        values.extend(arg_vals)
                        arguments[param.name] = tuple(values)
                        break
    
                    if param.name in kwargs and param.kind != _POSITIONAL_ONLY:
                        raise TypeError(
                            'multiple values for argument {arg!r}'.format(
                                arg=param.name)) from None
    
                    arguments[param.name] = arg_val
    
        # Now, we iterate through the remaining parameters to process
        # keyword arguments
        kwargs_param = None
        for param in itertools.chain(parameters_ex, parameters):
            if param.kind == _VAR_KEYWORD:
                # Memorize that we have a '**kwargs'-like parameter
                kwargs_param = param
                continue
    
            if param.kind == _VAR_POSITIONAL:
                # Named arguments don't refer to '*args'-like parameters.
                # We only arrive here if the positional arguments ended
                # before reaching the last parameter before *args.
                continue
    
            param_name = param.name
            try:
                arg_val = kwargs.pop(param_name)
            except KeyError:
                # We have no value for this parameter.  It's fine though,
                # if it has a default value, or it is an '*args'-like
                # parameter, left alone by the processing of positional
                # arguments.
                if (not partial and param.kind != _VAR_POSITIONAL and
                                                    param.default is _empty):
                    raise TypeError('missing a required argument: {arg!r}'. \
                                    format(arg=param_name)) from None
    
            else:
                if param.kind == _POSITIONAL_ONLY:
                    # This should never happen in case of a properly built
                    # Signature object (but let's have this check here
                    # to ensure correct behaviour just in case)
                    raise TypeError('{arg!r} parameter is positional only, '
                                    'but was passed as a keyword'. \
                                    format(arg=param.name))
    
                arguments[param_name] = arg_val
    
        if kwargs:
            if kwargs_param is not None:
                # Process our '**kwargs'-like parameter
                arguments[kwargs_param.name] = kwargs
            else:
>               raise TypeError(
                    'got an unexpected keyword argument {arg!r}'.format(
                        arg=next(iter(kwargs))))
E               TypeError: got an unexpected keyword argument 'args'

/opt/miniconda/envs/multienv/lib/python3.10/inspect.py:3166: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.container.AugmentationSequential
______________________________________________________________________ test_ManyToManyAugmentationDispather[tensorflow-s2s-False] ______________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_ManyToManyAugmentationDispather(target_framework, mode, backend_compile):
        print("kornia.augmentation.container.ManyToManyAugmentationDispather")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledManyToManyAugmentationDispather = ivy.transpile(
            kornia.augmentation.container.ManyToManyAugmentationDispather,
            source="torch",
            target=target_framework,
        )
        TranspiledAugmentationSequential = ivy.transpile(
            kornia.augmentation.container.AugmentationSequential,
            source="torch",
            target=target_framework,
        )
        TranspiledColorJiggle = ivy.transpile(
            kornia.augmentation.ColorJiggle,
            source="torch",
            target=target_framework,
        )
        TranspiledRandomAffine = ivy.transpile(
            kornia.augmentation.RandomAffine,
            source="torch",
            target=target_framework,
        )
    
        torch_aug_list = kornia.augmentation.container.ManyToManyAugmentationDispather(
            kornia.augmentation.container.AugmentationSequential(
                kornia.augmentation.ColorJiggle(0.1, 0.1, 0.1, 0.1, p=1.0),
                kornia.augmentation.RandomAffine(360, p=1.0),
                data_keys=["input", "mask",],
            ),
            kornia.augmentation.container.AugmentationSequential(
                kornia.augmentation.ColorJiggle(0.1, 0.1, 0.1, 0.1, p=1.0),
                kornia.augmentation.RandomAffine(360, p=1.0),
                data_keys=["input", "mask",],
            )
        )
        transpiled_aug_list = TranspiledManyToManyAugmentationDispather(
            TranspiledAugmentationSequential(
                TranspiledColorJiggle(0.1, 0.1, 0.1, 0.1, p=1.0),
                TranspiledRandomAffine(360, p=1.0),
                data_keys=["input", "mask",],
            ),
            TranspiledAugmentationSequential(
                TranspiledColorJiggle(0.1, 0.1, 0.1, 0.1, p=1.0),
                TranspiledRandomAffine(360, p=1.0),
                data_keys=["input", "mask",],
            )
        )
    
        torch_args = (
            (torch.randn(2, 3, 5, 6), torch.ones(2, 3, 5, 6)),
            (torch.randn(2, 3, 5, 6), torch.ones(2, 3, 5, 6)),
        )
        torch_out = torch_aug_list(*torch_args)
    
        transpiled_args = _nest_torch_tensor_to_new_framework(torch_args, target_framework)
>       transpiled_out = transpiled_aug_list(*transpiled_args)

kornia/augmentation/test_container.py:134: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_ManyToManyAugmentationDispather()
args = ((<tf.Tensor: shape=(2, 3, 5, 6), dtype=float32, numpy=
array([[[[-3.3681397 , -0.24483417, -0.45125595,  0.32530388,
...   [1., 1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1., 1.]]]], dtype=float32)>))
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x7f7c935a5640, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...ode_context=['        return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_ManyToManyAugmentationDispather(), (<tf.Tensor: shape=(2, 3, 5, 6), dtype=float32, numpy=
array([[[[-3.368...   [1., 1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1., 1.]]]], dtype=float32)>))
kwargs = {}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_ManyToManyAugmentationDispather(), v = None, buffers = None
args = ((<tf.Tensor: shape=(2, 3, 5, 6), dtype=float32, numpy=
array([[[[-3.3681397 , -0.24483417, -0.45125595,  0.32530388,
...   [1., 1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1., 1.]]]], dtype=float32)>))
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:2017: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_ManyToManyAugmentationDispather(), (<tf.Tensor: shape=(2, 3, 5, 6), dtype=float32, numpy=
array([[[[-3.368...   [1., 1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1., 1.]]]], dtype=float32)>))
kwargs = {'buffers': None, 'v': None}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_ManyToManyAugmentationDispather(), v = None, buffers = None
args = ((<tf.Tensor: shape=(2, 3, 5, 6), dtype=float32, numpy=
array([[[[-3.3681397 , -0.24483417, -0.45125595,  0.32530388,
...   [1., 1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1., 1.]]]], dtype=float32)>))
kwargs = {}
first_arr = <tf.Tensor: shape=(2, 3, 5, 6), dtype=float32, numpy=
array([[[[-3.3681397 , -0.24483417, -0.45125595,  0.32530388,
  ...,
         [-0.60188526, -0.0116622 , -0.17271534, -0.9770408 ,
          -0.95619875,  0.57072914]]]], dtype=float32)>
replace_v = False, replace_buffers = False, call_signature = <Signature (*input)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Model, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Model, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Model, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1787: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_ManyToManyAugmentationDispather(),)
kwargs = {'input': (<tf.Tensor: shape=(2, 3, 5, 6), dtype=float32, numpy=
array([[[[-3.3681397 , -0.24483417, -0.45125595,  0.3...   [1., 1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1., 1.]]]], dtype=float32)>)}

    @wraps(fn)
    def error_handler(*args, **kwargs):
        if not is_traceback_filtering_enabled():
            return fn(*args, **kwargs)
    
        filtered_tb = None
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            filtered_tb = _process_traceback_frames(e.__traceback__)
            # To get the full stack trace, call:
            # `keras.config.disable_traceback_filtering()`
>           raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/keras/src/utils/traceback_utils.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <Signature (*input)>, args = ()
kwargs = {'input': (<tf.Tensor: shape=(2, 3, 5, 6), dtype=float32, numpy=
array([[[[-3.3681397 , -0.24483417, -0.45125595,  0.3...   [1., 1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1., 1.]]]], dtype=float32)>)}

    def bind(self, /, *args, **kwargs):
        """Get a BoundArguments object, that maps the passed `args`
        and `kwargs` to the function's signature.  Raises `TypeError`
        if the passed arguments can not be bound.
        """
>       return self._bind(args, kwargs)

/opt/miniconda/envs/multienv/lib/python3.10/inspect.py:3177: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <Signature (*input)>, args = ()
kwargs = {'input': (<tf.Tensor: shape=(2, 3, 5, 6), dtype=float32, numpy=
array([[[[-3.3681397 , -0.24483417, -0.45125595,  0.3...   [1., 1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1., 1.]]]], dtype=float32)>)}

    def _bind(self, args, kwargs, *, partial=False):
        """Private method. Don't use directly."""
    
        arguments = {}
    
        parameters = iter(self.parameters.values())
        parameters_ex = ()
        arg_vals = iter(args)
    
        while True:
            # Let's iterate through the positional arguments and corresponding
            # parameters
            try:
                arg_val = next(arg_vals)
            except StopIteration:
                # No more positional arguments
                try:
                    param = next(parameters)
                except StopIteration:
                    # No more parameters. That's it. Just need to check that
                    # we have no `kwargs` after this while loop
                    break
                else:
                    if param.kind == _VAR_POSITIONAL:
                        # That's OK, just empty *args.  Let's start parsing
                        # kwargs
                        break
                    elif param.name in kwargs:
                        if param.kind == _POSITIONAL_ONLY:
                            msg = '{arg!r} parameter is positional only, ' \
                                  'but was passed as a keyword'
                            msg = msg.format(arg=param.name)
                            raise TypeError(msg) from None
                        parameters_ex = (param,)
                        break
                    elif (param.kind == _VAR_KEYWORD or
                                                param.default is not _empty):
                        # That's fine too - we have a default value for this
                        # parameter.  So, lets start parsing `kwargs`, starting
                        # with the current parameter
                        parameters_ex = (param,)
                        break
                    else:
                        # No default, not VAR_KEYWORD, not VAR_POSITIONAL,
                        # not in `kwargs`
                        if partial:
                            parameters_ex = (param,)
                            break
                        else:
                            msg = 'missing a required argument: {arg!r}'
                            msg = msg.format(arg=param.name)
                            raise TypeError(msg) from None
            else:
                # We have a positional argument to process
                try:
                    param = next(parameters)
                except StopIteration:
                    raise TypeError('too many positional arguments') from None
                else:
                    if param.kind in (_VAR_KEYWORD, _KEYWORD_ONLY):
                        # Looks like we have no parameter for this positional
                        # argument
                        raise TypeError(
                            'too many positional arguments') from None
    
                    if param.kind == _VAR_POSITIONAL:
                        # We have an '*args'-like argument, let's fill it with
                        # all positional arguments we have left and move on to
                        # the next phase
                        values = [arg_val]
                        values.extend(arg_vals)
                        arguments[param.name] = tuple(values)
                        break
    
                    if param.name in kwargs and param.kind != _POSITIONAL_ONLY:
                        raise TypeError(
                            'multiple values for argument {arg!r}'.format(
                                arg=param.name)) from None
    
                    arguments[param.name] = arg_val
    
        # Now, we iterate through the remaining parameters to process
        # keyword arguments
        kwargs_param = None
        for param in itertools.chain(parameters_ex, parameters):
            if param.kind == _VAR_KEYWORD:
                # Memorize that we have a '**kwargs'-like parameter
                kwargs_param = param
                continue
    
            if param.kind == _VAR_POSITIONAL:
                # Named arguments don't refer to '*args'-like parameters.
                # We only arrive here if the positional arguments ended
                # before reaching the last parameter before *args.
                continue
    
            param_name = param.name
            try:
                arg_val = kwargs.pop(param_name)
            except KeyError:
                # We have no value for this parameter.  It's fine though,
                # if it has a default value, or it is an '*args'-like
                # parameter, left alone by the processing of positional
                # arguments.
                if (not partial and param.kind != _VAR_POSITIONAL and
                                                    param.default is _empty):
                    raise TypeError('missing a required argument: {arg!r}'. \
                                    format(arg=param_name)) from None
    
            else:
                if param.kind == _POSITIONAL_ONLY:
                    # This should never happen in case of a properly built
                    # Signature object (but let's have this check here
                    # to ensure correct behaviour just in case)
                    raise TypeError('{arg!r} parameter is positional only, '
                                    'but was passed as a keyword'. \
                                    format(arg=param.name))
    
                arguments[param_name] = arg_val
    
        if kwargs:
            if kwargs_param is not None:
                # Process our '**kwargs'-like parameter
                arguments[kwargs_param.name] = kwargs
            else:
>               raise TypeError(
                    'got an unexpected keyword argument {arg!r}'.format(
                        arg=next(iter(kwargs))))
E               TypeError: got an unexpected keyword argument 'input'

/opt/miniconda/envs/multienv/lib/python3.10/inspect.py:3166: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.container.ManyToManyAugmentationDispather
______________________________________________________________________ test_ManyToOneAugmentationDispather[tensorflow-s2s-False] _______________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_ManyToOneAugmentationDispather(target_framework, mode, backend_compile):
        print("kornia.augmentation.container.ManyToOneAugmentationDispather")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledManyToOneAugmentationDispather = ivy.transpile(
            kornia.augmentation.container.ManyToOneAugmentationDispather,
            source="torch",
            target=target_framework,
        )
        TranspiledAugmentationSequential = ivy.transpile(
            kornia.augmentation.container.AugmentationSequential,
            source="torch",
            target=target_framework,
        )
        TranspiledColorJiggle = ivy.transpile(
            kornia.augmentation.ColorJiggle,
            source="torch",
            target=target_framework,
        )
        TranspiledRandomAffine = ivy.transpile(
            kornia.augmentation.RandomAffine,
            source="torch",
            target=target_framework,
        )
    
        torch_aug_list = kornia.augmentation.container.ManyToOneAugmentationDispather(
            kornia.augmentation.container.AugmentationSequential(
                kornia.augmentation.ColorJiggle(0.1, 0.1, 0.1, 0.1, p=1.0),
                kornia.augmentation.RandomAffine(360, p=1.0),
                data_keys=["input", "mask",],
            ),
            kornia.augmentation.container.AugmentationSequential(
                kornia.augmentation.ColorJiggle(0.1, 0.1, 0.1, 0.1, p=1.0),
                kornia.augmentation.RandomAffine(360, p=1.0),
                data_keys=["input", "mask",],
            )
        )
        transpiled_aug_list = TranspiledManyToOneAugmentationDispather(
            TranspiledAugmentationSequential(
                TranspiledColorJiggle(0.1, 0.1, 0.1, 0.1, p=1.0),
                TranspiledRandomAffine(360, p=1.0),
                data_keys=["input", "mask",],
            ),
            TranspiledAugmentationSequential(
                TranspiledColorJiggle(0.1, 0.1, 0.1, 0.1, p=1.0),
                TranspiledRandomAffine(360, p=1.0),
                data_keys=["input", "mask",],
            )
        )
    
        torch_args = (
            torch.randn(2, 3, 5, 6),
            torch.ones(2, 3, 5, 6),
        )
        torch_out = torch_aug_list(*torch_args)
    
        transpiled_args = _nest_torch_tensor_to_new_framework(torch_args, target_framework)
>       transpiled_out = transpiled_aug_list(*transpiled_args)

kornia/augmentation/test_container.py:200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_ManyToOneAugmentationDispather()
args = (<tf.Tensor: shape=(2, 3, 5, 6), dtype=float32, numpy=
array([[[[ 0.18497704, -1.0112575 , -2.0843856 , -0.20730329,
 ...    [1., 1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1., 1.]]]], dtype=float32)>)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x7f7c97add440, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...ode_context=['        return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_ManyToOneAugmentationDispather(), <tf.Tensor: shape=(2, 3, 5, 6), dtype=float32, numpy=
array([[[[ 0.18497...    [1., 1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1., 1.]]]], dtype=float32)>)
kwargs = {}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_ManyToOneAugmentationDispather(), v = None, buffers = None
args = (<tf.Tensor: shape=(2, 3, 5, 6), dtype=float32, numpy=
array([[[[ 0.18497704, -1.0112575 , -2.0843856 , -0.20730329,
 ...    [1., 1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1., 1.]]]], dtype=float32)>)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:2017: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_ManyToOneAugmentationDispather(), <tf.Tensor: shape=(2, 3, 5, 6), dtype=float32, numpy=
array([[[[ 0.18497...    [1., 1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1., 1.]]]], dtype=float32)>)
kwargs = {'buffers': None, 'v': None}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_ManyToOneAugmentationDispather(), v = None, buffers = None
args = (<tf.Tensor: shape=(2, 3, 5, 6), dtype=float32, numpy=
array([[[[ 0.18497704, -1.0112575 , -2.0843856 , -0.20730329,
 ...    [1., 1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1., 1.]]]], dtype=float32)>)
kwargs = {}
first_arr = <tf.Tensor: shape=(2, 3, 5, 6), dtype=float32, numpy=
array([[[[ 0.18497704, -1.0112575 , -2.0843856 , -0.20730329,
  ...,
         [-1.8108263 ,  1.9978555 ,  0.62164193,  1.4669497 ,
           2.420761  , -1.0120901 ]]]], dtype=float32)>
replace_v = False, replace_buffers = False, call_signature = <Signature (*input)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Model, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Model, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Model, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1787: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_ManyToOneAugmentationDispather(),)
kwargs = {'input': <tf.Tensor: shape=(2, 3, 5, 6), dtype=float32, numpy=
array([[[[ 0.18497704, -1.0112575 , -2.0843856 , -0.20...
         [-1.8108263 ,  1.9978555 ,  0.62164193,  1.4669497 ,
           2.420761  , -1.0120901 ]]]], dtype=float32)>}

    @wraps(fn)
    def error_handler(*args, **kwargs):
        if not is_traceback_filtering_enabled():
            return fn(*args, **kwargs)
    
        filtered_tb = None
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            filtered_tb = _process_traceback_frames(e.__traceback__)
            # To get the full stack trace, call:
            # `keras.config.disable_traceback_filtering()`
>           raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/keras/src/utils/traceback_utils.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <Signature (*input)>, args = ()
kwargs = {'input': <tf.Tensor: shape=(2, 3, 5, 6), dtype=float32, numpy=
array([[[[ 0.18497704, -1.0112575 , -2.0843856 , -0.20...
         [-1.8108263 ,  1.9978555 ,  0.62164193,  1.4669497 ,
           2.420761  , -1.0120901 ]]]], dtype=float32)>}

    def bind(self, /, *args, **kwargs):
        """Get a BoundArguments object, that maps the passed `args`
        and `kwargs` to the function's signature.  Raises `TypeError`
        if the passed arguments can not be bound.
        """
>       return self._bind(args, kwargs)

/opt/miniconda/envs/multienv/lib/python3.10/inspect.py:3177: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <Signature (*input)>, args = ()
kwargs = {'input': <tf.Tensor: shape=(2, 3, 5, 6), dtype=float32, numpy=
array([[[[ 0.18497704, -1.0112575 , -2.0843856 , -0.20...
         [-1.8108263 ,  1.9978555 ,  0.62164193,  1.4669497 ,
           2.420761  , -1.0120901 ]]]], dtype=float32)>}

    def _bind(self, args, kwargs, *, partial=False):
        """Private method. Don't use directly."""
    
        arguments = {}
    
        parameters = iter(self.parameters.values())
        parameters_ex = ()
        arg_vals = iter(args)
    
        while True:
            # Let's iterate through the positional arguments and corresponding
            # parameters
            try:
                arg_val = next(arg_vals)
            except StopIteration:
                # No more positional arguments
                try:
                    param = next(parameters)
                except StopIteration:
                    # No more parameters. That's it. Just need to check that
                    # we have no `kwargs` after this while loop
                    break
                else:
                    if param.kind == _VAR_POSITIONAL:
                        # That's OK, just empty *args.  Let's start parsing
                        # kwargs
                        break
                    elif param.name in kwargs:
                        if param.kind == _POSITIONAL_ONLY:
                            msg = '{arg!r} parameter is positional only, ' \
                                  'but was passed as a keyword'
                            msg = msg.format(arg=param.name)
                            raise TypeError(msg) from None
                        parameters_ex = (param,)
                        break
                    elif (param.kind == _VAR_KEYWORD or
                                                param.default is not _empty):
                        # That's fine too - we have a default value for this
                        # parameter.  So, lets start parsing `kwargs`, starting
                        # with the current parameter
                        parameters_ex = (param,)
                        break
                    else:
                        # No default, not VAR_KEYWORD, not VAR_POSITIONAL,
                        # not in `kwargs`
                        if partial:
                            parameters_ex = (param,)
                            break
                        else:
                            msg = 'missing a required argument: {arg!r}'
                            msg = msg.format(arg=param.name)
                            raise TypeError(msg) from None
            else:
                # We have a positional argument to process
                try:
                    param = next(parameters)
                except StopIteration:
                    raise TypeError('too many positional arguments') from None
                else:
                    if param.kind in (_VAR_KEYWORD, _KEYWORD_ONLY):
                        # Looks like we have no parameter for this positional
                        # argument
                        raise TypeError(
                            'too many positional arguments') from None
    
                    if param.kind == _VAR_POSITIONAL:
                        # We have an '*args'-like argument, let's fill it with
                        # all positional arguments we have left and move on to
                        # the next phase
                        values = [arg_val]
                        values.extend(arg_vals)
                        arguments[param.name] = tuple(values)
                        break
    
                    if param.name in kwargs and param.kind != _POSITIONAL_ONLY:
                        raise TypeError(
                            'multiple values for argument {arg!r}'.format(
                                arg=param.name)) from None
    
                    arguments[param.name] = arg_val
    
        # Now, we iterate through the remaining parameters to process
        # keyword arguments
        kwargs_param = None
        for param in itertools.chain(parameters_ex, parameters):
            if param.kind == _VAR_KEYWORD:
                # Memorize that we have a '**kwargs'-like parameter
                kwargs_param = param
                continue
    
            if param.kind == _VAR_POSITIONAL:
                # Named arguments don't refer to '*args'-like parameters.
                # We only arrive here if the positional arguments ended
                # before reaching the last parameter before *args.
                continue
    
            param_name = param.name
            try:
                arg_val = kwargs.pop(param_name)
            except KeyError:
                # We have no value for this parameter.  It's fine though,
                # if it has a default value, or it is an '*args'-like
                # parameter, left alone by the processing of positional
                # arguments.
                if (not partial and param.kind != _VAR_POSITIONAL and
                                                    param.default is _empty):
                    raise TypeError('missing a required argument: {arg!r}'. \
                                    format(arg=param_name)) from None
    
            else:
                if param.kind == _POSITIONAL_ONLY:
                    # This should never happen in case of a properly built
                    # Signature object (but let's have this check here
                    # to ensure correct behaviour just in case)
                    raise TypeError('{arg!r} parameter is positional only, '
                                    'but was passed as a keyword'. \
                                    format(arg=param.name))
    
                arguments[param_name] = arg_val
    
        if kwargs:
            if kwargs_param is not None:
                # Process our '**kwargs'-like parameter
                arguments[kwargs_param.name] = kwargs
            else:
>               raise TypeError(
                    'got an unexpected keyword argument {arg!r}'.format(
                        arg=next(iter(kwargs))))
E               TypeError: got an unexpected keyword argument 'input'

/opt/miniconda/envs/multienv/lib/python3.10/inspect.py:3166: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.container.ManyToOneAugmentationDispather
______________________________________________________________________________ test_ImageSequential[tensorflow-s2s-False] ______________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_ImageSequential(target_framework, mode, backend_compile):
        print("kornia.augmentation.container.ImageSequential")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledImageSequential = ivy.transpile(
            kornia.augmentation.container.ImageSequential,
            source="torch",
            target=target_framework,
        )
        TranspiledColorJiggle = ivy.transpile(
            kornia.augmentation.ColorJiggle,
            source="torch",
            target=target_framework,
        )
        TranspiledRandomAffine = ivy.transpile(
            kornia.augmentation.RandomAffine,
            source="torch",
            target=target_framework,
        )
        TranspiledBgrToRgb = ivy.transpile(
            kornia.color.BgrToRgb,
            source="torch",
            target=target_framework,
        )
        TranspiledMedianBlur = ivy.transpile(
            kornia.filters.MedianBlur,
            source="torch",
            target=target_framework,
        )
        TranspiledInvert = ivy.transpile(
            kornia.enhance.Invert,
            source="torch",
            target=target_framework,
        )
        TranspiledRandomMixUpV2 = ivy.transpile(
            kornia.augmentation.RandomMixUpV2,
            source="torch",
            target=target_framework,
        )
    
        torch_aug_list = kornia.augmentation.container.ImageSequential(
            kornia.color.BgrToRgb(),
            kornia.augmentation.ColorJiggle(0.1, 0.1, 0.1, 0.1, p=1.0),
            kornia.filters.MedianBlur((3, 3)),
            kornia.augmentation.RandomAffine(360, p=1.0),
            kornia.enhance.Invert(),
            kornia.augmentation.RandomMixUpV2(p=1.0),
            same_on_batch=True,
            random_apply=10,
        )
        transpiled_aug_list = TranspiledImageSequential(
            TranspiledBgrToRgb(),
>           TranspiledColorJiggle(0.1, 0.1, 0.1, 0.1, p=1.0),
            TranspiledMedianBlur((3, 3)),
            TranspiledRandomAffine(360, p=1.0),
            TranspiledInvert(),
            TranspiledRandomMixUpV2(p=1.0),
            same_on_batch=True,
            random_apply=10,
        )

kornia/augmentation/test_container.py:261: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'tensorflow_ColorJiggle' object has no attribute 'p'") raised in repr()] tensorflow_ColorJiggle object at 0x7f7c9095f010>, args = (0.1, 0.1, 0.1, 0.1), kwargs = {'p': 1.0}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'tensorflow_ColorJiggle' object has no attribute 'p'") raised in repr()] tensorflow_ColorJiggle object at 0x7f7c9095f010>, brightness = 0.1, contrast = 0.1, saturation = 0.1
hue = 0.1, same_on_batch = False, p = 1.0, keepdim = False

>   ???
E   ModuleNotFoundError: No module named 'ivy_transpiled_outputs.tensorflow_outputs.kornia.augmentation.random_generator._2d.color_jiggle'

/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/_2d/intensity/color_jiggle.py:46: ModuleNotFoundError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.container.ImageSequential
______________________________________________________________________________ test_PatchSequential[tensorflow-s2s-False] ______________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_PatchSequential(target_framework, mode, backend_compile):
        print("kornia.augmentation.container.PatchSequential")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledPatchSequential = ivy.transpile(
            kornia.augmentation.container.PatchSequential,
            source="torch",
            target=target_framework,
        )
        TranspiledImageSequential = ivy.transpile(
            kornia.augmentation.container.ImageSequential,
            source="torch",
            target=target_framework,
        )
        TranspiledColorJiggle = ivy.transpile(
            kornia.augmentation.ColorJiggle,
            source="torch",
            target=target_framework,
        )
        TranspiledRandomAffine = ivy.transpile(
            kornia.augmentation.RandomAffine,
            source="torch",
            target=target_framework,
        )
        TranspiledRandomPerspective = ivy.transpile(
            kornia.augmentation.RandomPerspective,
            source="torch",
            target=target_framework,
        )
        TranspiledRandomSolarize = ivy.transpile(
            kornia.augmentation.RandomSolarize,
            source="torch",
            target=target_framework,
        )
    
        torch_aug_list = kornia.augmentation.container.PatchSequential(
            kornia.augmentation.container.ImageSequential(
                kornia.augmentation.ColorJiggle(0.1, 0.1, 0.1, 0.1, p=0.5),
                kornia.augmentation.RandomPerspective(0.2, p=0.5),
                kornia.augmentation.RandomSolarize(0.1, 0.1, p=0.5),
            ),
            kornia.augmentation.RandomAffine(360, p=1.0),
            kornia.augmentation.container.ImageSequential(
                kornia.augmentation.ColorJiggle(0.1, 0.1, 0.1, 0.1, p=0.5),
                kornia.augmentation.RandomPerspective(0.2, p=0.5),
                kornia.augmentation.RandomSolarize(0.1, 0.1, p=0.5),
            ),
            kornia.augmentation.RandomSolarize(0.1, 0.1, p=0.1),
            grid_size=(2,2),
            patchwise_apply=True,
            same_on_batch=True,
            random_apply=False,
        )
        transpiled_aug_list = TranspiledPatchSequential(
            TranspiledImageSequential(
                TranspiledColorJiggle(0.1, 0.1, 0.1, 0.1, p=0.5),
                TranspiledRandomPerspective(0.2, p=0.5),
                TranspiledRandomSolarize(0.1, 0.1, p=0.5),
            ),
            TranspiledRandomAffine(360, p=1.0),
            TranspiledImageSequential(
                TranspiledColorJiggle(0.1, 0.1, 0.1, 0.1, p=0.5),
                TranspiledRandomPerspective(0.2, p=0.5),
                TranspiledRandomSolarize(0.1, 0.1, p=0.5),
            ),
            TranspiledRandomSolarize(0.1, 0.1, p=0.1),
            grid_size=(2,2),
            patchwise_apply=True,
            same_on_batch=True,
            random_apply=False,
        )
    
        torch_args = (
            torch.randn(2, 3, 224, 224),
        )
        torch_out = torch_aug_list(*torch_args)
    
        transpiled_args = _nest_torch_tensor_to_new_framework(torch_args, target_framework)
>       transpiled_out = transpiled_aug_list(*transpiled_args)

kornia/augmentation/test_container.py:363: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_PatchSequential(
  (tensorflow_ImageSequential_0): tensorflow_ImageSequential(
    (tensorflow_ColorJiggle_...w_RandomSolarize_3): tensorflow_RandomSolarize(thresholds=0.1, additions=0.1, p=0.1, p_batch=1.0, same_on_batch=True)
)
args = (<tf.Tensor: shape=(2, 3, 224, 224), dtype=float32, numpy=
array([[[[ 7.08629251e-01, -1.27079439e+00, -1.42825294e+00...202e-01,  6.30311549e-01, ...,
          -4.69820760e-02,  1.36646032e+00,  6.39333129e-01]]]],
      dtype=float32)>,)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x7f7c93cd2240, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...ode_context=['        return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_PatchSequential(
  (tensorflow_ImageSequential_0): tensorflow_ImageSequential(
    (tensorflow_ColorJiggle...3202e-01,  6.30311549e-01, ...,
          -4.69820760e-02,  1.36646032e+00,  6.39333129e-01]]]],
      dtype=float32)>)
kwargs = {}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_PatchSequential(
  (tensorflow_ImageSequential_0): tensorflow_ImageSequential(
    (tensorflow_ColorJiggle_...w_RandomSolarize_3): tensorflow_RandomSolarize(thresholds=0.1, additions=0.1, p=0.1, p_batch=1.0, same_on_batch=True)
)
v = None, buffers = None
args = (<tf.Tensor: shape=(2, 3, 224, 224), dtype=float32, numpy=
array([[[[ 7.08629251e-01, -1.27079439e+00, -1.42825294e+00...202e-01,  6.30311549e-01, ...,
          -4.69820760e-02,  1.36646032e+00,  6.39333129e-01]]]],
      dtype=float32)>,)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_PatchSequential(
  (tensorflow_ImageSequential_0): tensorflow_ImageSequential(
    (tensorflow_ColorJiggle...3202e-01,  6.30311549e-01, ...,
          -4.69820760e-02,  1.36646032e+00,  6.39333129e-01]]]],
      dtype=float32)>)
kwargs = {'buffers': None, 'v': None}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_PatchSequential(
  (tensorflow_ImageSequential_0): tensorflow_ImageSequential(
    (tensorflow_ColorJiggle_...w_RandomSolarize_3): tensorflow_RandomSolarize(thresholds=0.1, additions=0.1, p=0.1, p_batch=1.0, same_on_batch=True)
)
v = None, buffers = None
args = (<tf.Tensor: shape=(2, 3, 224, 224), dtype=float32, numpy=
array([[[[ 7.08629251e-01, -1.27079439e+00, -1.42825294e+00...202e-01,  6.30311549e-01, ...,
          -4.69820760e-02,  1.36646032e+00,  6.39333129e-01]]]],
      dtype=float32)>,)
kwargs = {}, replace_v = False, replace_buffers = False, call_signature = <Signature (input, params=None)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Layer, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Layer, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Layer, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_PatchSequential(
  (tensorflow_ImageSequential_0): tensorflow_ImageSequential(
    (tensorflow_ColorJiggle...RandomSolarize_3): tensorflow_RandomSolarize(thresholds=0.1, additions=0.1, p=0.1, p_batch=1.0, same_on_batch=True)
),)
kwargs = {'input': <tf.Tensor: shape=(2, 3, 224, 224), dtype=float32, numpy=
array([[[[ 7.08629251e-01, -1.27079439e+00, -1.428...3202e-01,  6.30311549e-01, ...,
          -4.69820760e-02,  1.36646032e+00,  6.39333129e-01]]]],
      dtype=float32)>}

    @wraps(fn)
    def error_handler(*args, **kwargs):
        if not is_traceback_filtering_enabled():
            return fn(*args, **kwargs)
    
        filtered_tb = None
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            filtered_tb = _process_traceback_frames(e.__traceback__)
            # To get the full stack trace, call:
            # `keras.config.disable_traceback_filtering()`
>           raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/keras/src/utils/traceback_utils.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_PatchSequential(
  (tensorflow_ImageSequential_0): tensorflow_ImageSequential(
    (tensorflow_ColorJiggle_...w_RandomSolarize_3): tensorflow_RandomSolarize(thresholds=0.1, additions=0.1, p=0.1, p_batch=1.0, same_on_batch=True)
)
input = <tf.Tensor: shape=(2, 3, 224, 224), dtype=float32, numpy=
array([[[[ 7.08629251e-01, -1.27079439e+00, -1.42825294e+00,...53202e-01,  6.30311549e-01, ...,
          -4.69820760e-02,  1.36646032e+00,  6.39333129e-01]]]],
      dtype=float32)>
params = [tensorflow_PatchParamItem(indices=[0, 3], param=tensorflow_ParamItem(name='tensorflow_ImageSequential_0', data=[tenso..., 1.], dtype=float32)>, 'forward_input_shape': <tf.Tensor: shape=(3,), dtype=int64, numpy=array([  2, 224, 224])>})]))]

    def call(self, input, params=None):
        from ....ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
    
        if isinstance(input, (tuple,)):
            raise ValueError("tuple input is not currently supported.")
        if params is None:
            params = self.forward_parameters(tensorflow_shape_frnt_(input))
>       output = self.transform_inputs(input, params=params)

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/container/patch.py:367: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_PatchSequential(
  (tensorflow_ImageSequential_0): tensorflow_ImageSequential(
    (tensorflow_ColorJiggle_...w_RandomSolarize_3): tensorflow_RandomSolarize(thresholds=0.1, additions=0.1, p=0.1, p_batch=1.0, same_on_batch=True)
)
input = <tf.Tensor: shape=(2, 4, 3, 112, 112), dtype=float32, numpy=
array([[[[[ 7.08629251e-01, -1.27079439e+00, -1.42825294e...520e+00, -1.10158753e+00, ...,
           -4.69820760e-02,  1.36646032e+00,  6.39333129e-01]]]]],
      dtype=float32)>
params = [tensorflow_PatchParamItem(indices=[0, 3], param=tensorflow_ParamItem(name='tensorflow_ImageSequential_0', data=[tenso..., 1.], dtype=float32)>, 'forward_input_shape': <tf.Tensor: shape=(3,), dtype=int64, numpy=array([  2, 224, 224])>})]))]
extra_args = {}

    def transform_inputs(self, input, params, extra_args={}):
        pad = self.compute_padding(input, self.padding)
        input = self.extract_patches(input, self.grid_size, pad)
>       input = self.forward_by_params(input, params)

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/container/patch.py:300: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_PatchSequential(
  (tensorflow_ImageSequential_0): tensorflow_ImageSequential(
    (tensorflow_ColorJiggle_...w_RandomSolarize_3): tensorflow_RandomSolarize(thresholds=0.1, additions=0.1, p=0.1, p_batch=1.0, same_on_batch=True)
)
input = <tf.Tensor: shape=(8, 3, 112, 112), dtype=float32, numpy=
array([[[[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,...02520e+00, -1.10158753e+00, ...,
          -4.69820760e-02,  1.36646032e+00,  6.39333129e-01]]]],
      dtype=float32)>
params = [tensorflow_PatchParamItem(indices=[0, 3], param=tensorflow_ParamItem(name='tensorflow_ImageSequential_0', data=[tenso..., 1.], dtype=float32)>, 'forward_input_shape': <tf.Tensor: shape=(3,), dtype=int64, numpy=array([  2, 224, 224])>})]))]

    def forward_by_params(self, input, params):
        from ....ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ....ivy.functional.frontends.torch.tensor import tensorflow_reshape_frnt_
        from ....ivy.functional.backends.tensorflow.general import tensorflow_get_item
        from .ops import tensorflow_InputSequentialOps
        from ....ivy.functional.backends.tensorflow.general import tensorflow_set_item
    
        in_shape = tensorflow_shape_frnt_(input)
        input = tensorflow_reshape_frnt_(input, -1, *in_shape[-3:])
        for patch_param in params:
            module = self.get_submodule(patch_param.param.name)
            _input = tensorflow_get_item(input, patch_param.indices)
>           output = tensorflow_InputSequentialOps.transform(
                _input, module, patch_param.param, extra_args={}
            )

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/container/patch.py:291: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.tensorflow_outputs.kornia.augmentation.container.ops.tensorflow_InputSequentialOps'>
input = <tf.Tensor: shape=(2, 3, 112, 112), dtype=float32, numpy=
array([[[[-1.03235535e-01,  1.39624190e+00, -1.09903133e+00,...06639e-02, -1.49820708e-02, ...,
          -1.03143990e+00, -3.94542813e-01,  7.95781434e-01]]]],
      dtype=float32)>
module = tensorflow_ImageSequential(
  (tensorflow_ColorJiggle_0): tensorflow_ColorJiggle(brightness=0.1, contrast=0.1, saturat...w_RandomSolarize_2): tensorflow_RandomSolarize(thresholds=0.1, additions=0.1, p=0.5, p_batch=1.0, same_on_batch=True)
)
param = tensorflow_ParamItem(name='tensorflow_ImageSequential_2', data=[tensorflow_ParamItem(name='tensorflow_ColorJiggle_0', ...1., 1.], dtype=float32)>, 'forward_input_shape': <tf.Tensor: shape=(3,), dtype=int64, numpy=array([  2, 224, 224])>})])
extra_args = {}

    @classmethod
    def transform(cls, input, module, param, extra_args={}):
        from .base import tensorflow_ImageSequentialBase
        from ..base import tensorflow__AugmentationBase
        from .._2d.mix.base import tensorflow_MixAugmentationBaseV2
        from ...constants import tensorflow_DataKey
        from ..auto.operations.base import tensorflow_OperationBase
        from ....ivy.functional.frontends.torch.tensor import tensorflow_data_frnt_
    
        if isinstance(
            module, (tensorflow__AugmentationBase, tensorflow_MixAugmentationBaseV2)
        ):
            input = module(
                input,
                params=cls.get_instance_module_param(param),
                data_keys=[tensorflow_DataKey.INPUT],
                **extra_args,
            )
        elif isinstance(module, (tensorflow_ImageSequentialBase,)):
>           input = module.transform_inputs(
                input,
                params=cls.get_sequential_module_param(param),
                extra_args=extra_args,

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/container/ops.py:208: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_ImageSequential(
  (tensorflow_ColorJiggle_0): tensorflow_ColorJiggle(brightness=0.1, contrast=0.1, saturat...w_RandomSolarize_2): tensorflow_RandomSolarize(thresholds=0.1, additions=0.1, p=0.5, p_batch=1.0, same_on_batch=True)
)
input = <tf.Tensor: shape=(2, 3, 112, 112), dtype=float32, numpy=
array([[[[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0....., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]]]], dtype=float32)>
params = [tensorflow_ParamItem(name='tensorflow_ColorJiggle_0', data={'brightness_factor': <tf.Tensor: shape=(0,), dtype=float3...[1., 1.], dtype=float32)>, 'forward_input_shape': <tf.Tensor: shape=(3,), dtype=int64, numpy=array([  2, 224, 224])>})]
extra_args = {}

    def transform_inputs(self, input, params, extra_args={}):
        from .ops import tensorflow_InputSequentialOps
    
        for param in params:
            module = self.get_submodule(param.name)
>           input = tensorflow_InputSequentialOps.transform(
                input, module=module, param=param, extra_args=extra_args
            )

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/container/base.py:173: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.tensorflow_outputs.kornia.augmentation.container.ops.tensorflow_InputSequentialOps'>
input = <tf.Tensor: shape=(2, 3, 112, 112), dtype=float32, numpy=
array([[[[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0....., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]]]], dtype=float32)>
module = tensorflow_RandomSolarize(thresholds=0.1, additions=0.1, p=0.5, p_batch=1.0, same_on_batch=True)
param = tensorflow_ParamItem(name='tensorflow_RandomSolarize_2', data={'thresholds': <tf.Tensor: shape=(2,), dtype=float32, nu...([1., 1.], dtype=float32)>, 'forward_input_shape': <tf.Tensor: shape=(3,), dtype=int64, numpy=array([  2, 224, 224])>})
extra_args = {}

    @classmethod
    def transform(cls, input, module, param, extra_args={}):
        from .base import tensorflow_ImageSequentialBase
        from ..base import tensorflow__AugmentationBase
        from .._2d.mix.base import tensorflow_MixAugmentationBaseV2
        from ...constants import tensorflow_DataKey
        from ..auto.operations.base import tensorflow_OperationBase
        from ....ivy.functional.frontends.torch.tensor import tensorflow_data_frnt_
    
        if isinstance(
            module, (tensorflow__AugmentationBase, tensorflow_MixAugmentationBaseV2)
        ):
>           input = module(
                input,
                params=cls.get_instance_module_param(param),
                data_keys=[tensorflow_DataKey.INPUT],
                **extra_args,

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/container/ops.py:201: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomSolarize(thresholds=0.1, additions=0.1, p=0.5, p_batch=1.0, same_on_batch=True)
args = (<tf.Tensor: shape=(2, 3, 112, 112), dtype=float32, numpy=
array([[[[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0... ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]]]], dtype=float32)>,)
kwargs = {'data_keys': [<tensorflow_DataKey.IMAGE: 0>], 'params': {'additions': <tf.Tensor: shape=(2,), dtype=float32, numpy=ar..., 224, 224])>, 'thresholds': <tf.Tensor: shape=(2,), dtype=float32, numpy=array([0.527087, 0.527087], dtype=float32)>}}
stack = [FrameInfo(frame=<frame at 0x7f7c93bfcc40, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/..., function='transform_inputs', code_context=['        input = self.forward_by_params(input, params)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomSolarize(thresholds=0.1, additions=0.1, p=0.5, p_batch=1.0, same_on_batch=True), v = None, buffers = None
args = (<tf.Tensor: shape=(2, 3, 112, 112), dtype=float32, numpy=
array([[[[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0... ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]]]], dtype=float32)>,)
kwargs = {'data_keys': [<tensorflow_DataKey.IMAGE: 0>], 'params': {'additions': <tf.Tensor: shape=(2,), dtype=float32, numpy=ar..., 224, 224])>, 'thresholds': <tf.Tensor: shape=(2,), dtype=float32, numpy=array([0.527087, 0.527087], dtype=float32)>}}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomSolarize(thresholds=0.1, additions=0.1, p=0.5, p_batch=1.0, same_on_batch=True), v = None, buffers = None
args = (<tf.Tensor: shape=(2, 3, 112, 112), dtype=float32, numpy=
array([[[[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0... ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]]]], dtype=float32)>,)
kwargs = {'data_keys': [<tensorflow_DataKey.IMAGE: 0>], 'params': {'additions': <tf.Tensor: shape=(2,), dtype=float32, numpy=ar..., 224, 224])>, 'thresholds': <tf.Tensor: shape=(2,), dtype=float32, numpy=array([0.527087, 0.527087], dtype=float32)>}}
first_arr = <tf.Tensor: shape=(2, 3, 112, 112), dtype=float32, numpy=
array([[[[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0....., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]]]], dtype=float32)>
replace_v = False, replace_buffers = False, call_signature = <Signature (input, params=None, **kwargs)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Layer, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Layer, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Layer, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomSolarize(thresholds=0.1, additions=0.1, p=0.5, p_batch=1.0, same_on_batch=True)
input = <tf.Tensor: shape=(2, 3, 112, 112), dtype=float32, numpy=
array([[[[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0....., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]]]], dtype=float32)>
params = {'additions': <tf.Tensor: shape=(2,), dtype=float32, numpy=array([0.07347185, 0.07347185], dtype=float32)>, 'batch_pro...low_DataKey.IMAGE: 0>], 'forward_input_shape': <tf.Tensor: shape=(3,), dtype=int64, numpy=array([  2, 224, 224])>, ...}
kwargs = {'data_keys': [<tensorflow_DataKey.IMAGE: 0>]}, tensorflow_shape_frnt_ = <function tensorflow_shape_frnt_ at 0x7f7c91992050>
tensorflow_set_item = <function tensorflow_set_item at 0x7f7c908eba30>, tensor = <function tensorflow_tensor_frnt at 0x7f7c90640820>
in_tensor = <tf.Tensor: shape=(2, 3, 112, 112), dtype=float32, numpy=
array([[[[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0....., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]]]], dtype=float32)>
input_shape = ivy.frontends.torch.Size([2, 3, 112, 112]), batch_shape = ivy.frontends.torch.Size([2, 3, 112, 112]), flags = {'data_keys': [<tensorflow_DataKey.IMAGE: 0>]}

    def call(self, input, params=None, **kwargs):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ...ivy.functional.backends.tensorflow.general import tensorflow_set_item
        from ..core._backend import tensor
    
        in_tensor = self.__unpack_input__(input)
        input_shape = tensorflow_shape_frnt_(in_tensor)
        in_tensor = self.transform_tensor(in_tensor)
        batch_shape = tensorflow_shape_frnt_(in_tensor)
        if params is None:
            params = self.forward_parameters(batch_shape)
        if "batch_prob" not in params:
            params = tensorflow_set_item(
                params, "batch_prob", tensor([True] * batch_shape[0])
            )
        params, flags = self._process_kwargs_to_params_and_flags(
            params, self.flags, **kwargs
        )
>       output = self.apply_func(in_tensor, params, flags)

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/base.py:236: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomSolarize(thresholds=0.1, additions=0.1, p=0.5, p_batch=1.0, same_on_batch=True)
in_tensor = <tf.Tensor: shape=(2, 3, 112, 112), dtype=float32, numpy=
array([[[[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0....., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]]]], dtype=float32)>
params = {'additions': <tf.Tensor: shape=(2,), dtype=float32, numpy=array([0.07347185, 0.07347185], dtype=float32)>, 'batch_pro...low_DataKey.IMAGE: 0>], 'forward_input_shape': <tf.Tensor: shape=(3,), dtype=int64, numpy=array([  2, 224, 224])>, ...}
flags = {'data_keys': [<tensorflow_DataKey.IMAGE: 0>]}

    def apply_func(self, in_tensor, params, flags=None):
        if flags is None:
            flags = self.flags
        trans_matrix = self.generate_transformation_matrix(in_tensor, params, flags)
>       output = self.transform_inputs(in_tensor, params, flags, trans_matrix)

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/_2d/base.py:127: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomSolarize(thresholds=0.1, additions=0.1, p=0.5, p_batch=1.0, same_on_batch=True)
input = <tf.Tensor: shape=(2, 3, 112, 112), dtype=float32, numpy=
array([[[[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0....., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]]]], dtype=float32)>
params = {'additions': <tf.Tensor: shape=(2,), dtype=float32, numpy=array([0.07347185, 0.07347185], dtype=float32)>, 'batch_pro...low_DataKey.IMAGE: 0>], 'forward_input_shape': <tf.Tensor: shape=(3,), dtype=int64, numpy=array([  2, 224, 224])>, ...}
flags = {'data_keys': [<tensorflow_DataKey.IMAGE: 0>]}
transform = <tf.Tensor: shape=(2, 3, 3), dtype=float32, numpy=
array([[[1., 0., 0.],
        [0., 1., 0.],
        [0., 0., 1.]],

       [[1., 0., 0.],
        [0., 1., 0.],
        [0., 0., 1.]]], dtype=float32)>
kwargs = {}, tensorflow_shape_frnt_ = <function tensorflow_shape_frnt_ at 0x7f7c91992050>, tensorflow_all_frnt_ = <function tensorflow_all_frnt_ at 0x7f7c919c9120>
tensorflow_any_frnt_ = <function tensorflow_any_frnt_ at 0x7f7c919fa710>, tensorflow_get_item = <function tensorflow_get_item at 0x7f7c908eb880>
tensorflow_is_autocast_enabled = <function tensorflow_is_autocast_enabled at 0x7f7c91e18f70>, tensorflow_type_frnt_ = <function tensorflow_type_frnt_ at 0x7f7c919fb1c0>
tensorflow_index_put_frnt_ = <function tensorflow_index_put_frnt_ at 0x7f7c919fb490>

    def transform_inputs(self, input, params, flags, transform=None, **kwargs):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_all_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_any_frnt_
        from ...ivy.functional.backends.tensorflow.general import tensorflow_get_item
        from ..utils.helpers import tensorflow_is_autocast_enabled
        from ...ivy.functional.frontends.torch.tensor import tensorflow_type_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_index_put_frnt_
        from .utils.helpers import tensorflow__transform_output_shape
    
        params, flags = self._process_kwargs_to_params_and_flags(
            self._params if params is None else params, flags, **kwargs
        )
        batch_prob = params["batch_prob"]
        to_apply = batch_prob > 0.5
        ori_shape = tensorflow_shape_frnt_(input)
        in_tensor = self.transform_tensor(input)
        self.validate_tensor(in_tensor)
        if tensorflow_all_frnt_(to_apply):
>           output = self.apply_transform(in_tensor, params, flags, transform=transform)

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/base.py:354: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomSolarize(thresholds=0.1, additions=0.1, p=0.5, p_batch=1.0, same_on_batch=True)
input = <tf.Tensor: shape=(2, 3, 112, 112), dtype=float32, numpy=
array([[[[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0....., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]]]], dtype=float32)>
params = {'additions': <tf.Tensor: shape=(2,), dtype=float32, numpy=array([0.07347185, 0.07347185], dtype=float32)>, 'batch_pro...low_DataKey.IMAGE: 0>], 'forward_input_shape': <tf.Tensor: shape=(3,), dtype=int64, numpy=array([  2, 224, 224])>, ...}
flags = {'data_keys': [<tensorflow_DataKey.IMAGE: 0>]}
transform = <tf.Tensor: shape=(2, 3, 3), dtype=float32, numpy=
array([[[1., 0., 0.],
        [0., 1., 0.],
        [0., 0., 1.]],

       [[1., 0., 0.],
        [0., 1., 0.],
        [0., 0., 1.]]], dtype=float32)>

    def apply_transform(self, input, params, flags, transform=None):
        from ....enhance.adjust import tensorflow_solarize
    
        thresholds = params["thresholds"]
        additions: typing.Any
        if "additions" in params:
            additions = params["additions"]
        else:
            additions = None
>       return tensorflow_solarize(input, thresholds, additions)

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/_2d/intensity/solarize.py:57: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = <tf.Tensor: shape=(2, 3, 112, 112), dtype=float32, numpy=
array([[[[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0....., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]]]], dtype=float32)>
thresholds = <tf.Tensor: shape=(2,), dtype=float32, numpy=array([0.527087, 0.527087], dtype=float32)>
additions = <tf.Tensor: shape=(2,), dtype=float32, numpy=array([0.07347185, 0.07347185], dtype=float32)>

    def tensorflow_solarize(input, thresholds=0.5, additions=None):
        from ...ivy.functional.frontends.torch.creation_ops import tensorflow_as_tensor_frnt
        from ...ivy.functional.frontends.torch.reduction_ops import tensorflow_all_frnt
        from ...ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_size_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_to_frnt_
        from ...ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            tensorflow_stack_frnt,
        )
        from ...ivy.functional.frontends.torch.tensor import tensorflow_expand_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_clamp_frnt_
    
        if not isinstance(input, (tensorflow.Tensor, tensorflow.keras.Variable)):
            raise TypeError(f"Input type is not a Tensor. Got {type(input)}")
        if not isinstance(
            thresholds, (float, tensorflow.Tensor, tensorflow.keras.Variable)
        ):
            raise TypeError(
                f"The factor should be either a float or Tensor. Got {type(thresholds)}"
            )
        if isinstance(thresholds, (float,)):
            thresholds = tensorflow_as_tensor_frnt(thresholds)
        if additions is not None:
            if not isinstance(
                additions, (float, tensorflow.Tensor, tensorflow.keras.Variable)
            ):
                raise TypeError(
                    f"The factor should be either a float or Tensor. Got {type(additions)}"
                )
            if isinstance(additions, (float,)):
                additions = tensorflow_as_tensor_frnt(additions)
>           if not tensorflow_all_frnt((additions < 0.5) * (additions > -0.5)):

ivy_transpiled_outputs/tensorflow_outputs/kornia/enhance/adjust.py:343: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <tf.Tensor: shape=(2,), dtype=bool, numpy=array([ True,  True])>, rhs = <tf.Tensor: shape=(2,), dtype=bool, numpy=array([ True,  True])>

    def impl(self, rhs):
        try:
            return original_method(self, rhs)
        except Exception:
>           return patched_method(self, rhs)

ivy_transpiled_outputs/tensorflow_outputs/__init__.py:143: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = <tf.Tensor: shape=(2,), dtype=bool, numpy=array([ True,  True])>, other = <tf.Tensor: shape=(2,), dtype=bool, numpy=array([ True,  True])>

    def tensorflow___mul___frnt_(tensor, other):
        from .pointwise_ops import tensorflow_mul_frnt
    
>       return tensorflow_mul_frnt(tensor, other)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/tensor.py:87: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = <tf.Tensor: shape=(2,), dtype=bool, numpy=array([ True,  True])>, other = <tf.Tensor: shape=(2,), dtype=bool, numpy=array([ True,  True])>

    def tensorflow_mul_frnt(input, other, *, out=None):
        from .__init__ import tensorflow_promote_types_of_torch_inputs_frnt
        from ...backends.tensorflow.elementwise import tensorflow_multiply
    
        input, other = tensorflow_promote_types_of_torch_inputs_frnt(input, other)
>       return tensorflow_multiply(input, other, out=out)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/pointwise_ops.py:137: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x1 = <tf.Tensor: shape=(2,), dtype=bool, numpy=array([ True,  True])>, x2 = <tf.Tensor: shape=(2,), dtype=bool, numpy=array([ True,  True])>

    def tensorflow_multiply(
        x1: Union[float, tensorflow.Tensor, tensorflow.Variable],
        x2: Union[float, tensorflow.Tensor, tensorflow.Variable],
        /,
        *,
        out: Optional[Union[tensorflow.Tensor, tensorflow.Variable]] = None,
    ):
        from ...ivy.data_type import tensorflow_promote_types_of_inputs_bknd
    
        x1, x2 = tensorflow_promote_types_of_inputs_bknd(x1, x2)
>       return tensorflow.math.multiply(x1, x2)
E       tensorflow.python.framework.errors_impl.InvalidArgumentError: Exception encountered when calling tensorflow_RandomSolarize.call().
E       
E       [1mValue for attr 'T' of bool is not in the list of allowed values: bfloat16, half, float, double, uint8, int8, uint16, int16, int32, uint32, uint64, int64, complex64, complex128
E       	; NodeDef: {{node Mul}}; Op<name=Mul; signature=x:T, y:T -> z:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE, DT_UINT8, DT_INT8, DT_UINT16, DT_INT16, DT_INT32, DT_UINT32, DT_UINT64, DT_INT64, DT_COMPLEX64, DT_COMPLEX128]; is_commutative=true> [Op:Mul] name: [0m
E       
E       Arguments received by tensorflow_RandomSolarize.call():
E         • input=tf.Tensor(shape=(2, 3, 112, 112), dtype=float32)
E         • params={'thresholds': 'tf.Tensor(shape=(2,), dtype=float32)', 'additions': 'tf.Tensor(shape=(2,), dtype=float32)', 'batch_prob': 'tf.Tensor(shape=(2,), dtype=float32)', 'forward_input_shape': 'tf.Tensor(shape=(3,), dtype=int64)'}
E         • kwargs={'data_keys': ['<tensorflow_DataKey.IMAGE: 0>']}

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/backends/tensorflow/elementwise.py:363: InvalidArgumentError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.container.PatchSequential
______________________________________________________________________________ test_VideoSequential[tensorflow-s2s-False] ______________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_VideoSequential(target_framework, mode, backend_compile):
        print("kornia.augmentation.container.VideoSequential")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledVideoSequential = ivy.transpile(
            kornia.augmentation.container.VideoSequential,
            source="torch",
            target=target_framework,
        )
        TranspiledColorJiggle = ivy.transpile(
            kornia.augmentation.ColorJiggle,
            source="torch",
            target=target_framework,
        )
        TranspiledRandomAffine = ivy.transpile(
            kornia.augmentation.RandomAffine,
            source="torch",
            target=target_framework,
        )
        TranspiledBgrToRgb = ivy.transpile(
            kornia.color.BgrToRgb,
            source="torch",
            target=target_framework,
        )
    
        torch_aug_list = kornia.augmentation.container.VideoSequential(
            kornia.augmentation.ColorJiggle(0.1, 0.1, 0.1, 0.1, p=1.0),
            kornia.color.BgrToRgb(),
            kornia.augmentation.RandomAffine(360, p=1.0),
            random_apply=10,
            data_format="BCTHW",
            same_on_frame=True
        )
        transpiled_aug_list =  TranspiledVideoSequential(
>           TranspiledColorJiggle(0.1, 0.1, 0.1, 0.1, p=1.0),
            TranspiledBgrToRgb(),
            TranspiledRandomAffine(360, p=1.0),
            random_apply=10,
            data_format="BCTHW",
            same_on_frame=True
        )

kornia/augmentation/test_container.py:406: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[ModuleNotFoundError("No module named 'ivy_transpiled_outputs.tensorflow_outputs.kornia.augmentation'") raised in repr()] tensorflow_ColorJiggle object at 0x7f7c906dd210>
args = (0.1, 0.1, 0.1, 0.1), kwargs = {'p': 1.0}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[ModuleNotFoundError("No module named 'ivy_transpiled_outputs.tensorflow_outputs.kornia.augmentation'") raised in repr()] tensorflow_ColorJiggle object at 0x7f7c906dd210>, brightness = 0.1
contrast = 0.1, saturation = 0.1, hue = 0.1, same_on_batch = False, p = 1.0, keepdim = False

>   ???
E   ModuleNotFoundError: No module named 'ivy_transpiled_outputs.tensorflow_outputs.kornia.augmentation'

/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/_2d/intensity/color_jiggle.py:46: ModuleNotFoundError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.container.VideoSequential
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/augmentation/test_container.py::test_AugmentationSequential[tensorflow-s2s-False] - TypeError: got an unexpected keyword argument 'args'
FAILED kornia/augmentation/test_container.py::test_ManyToManyAugmentationDispather[tensorflow-s2s-False] - TypeError: got an unexpected keyword argument 'input'
FAILED kornia/augmentation/test_container.py::test_ManyToOneAugmentationDispather[tensorflow-s2s-False] - TypeError: got an unexpected keyword argument 'input'
FAILED kornia/augmentation/test_container.py::test_ImageSequential[tensorflow-s2s-False] - ModuleNotFoundError: No module named 'ivy_transpiled_outputs.tensorflow_outputs.kornia.augmentation.random...
FAILED kornia/augmentation/test_container.py::test_PatchSequential[tensorflow-s2s-False] - tensorflow.python.framework.errors_impl.InvalidArgumentError: Exception encountered when calling tensorflo...
FAILED kornia/augmentation/test_container.py::test_VideoSequential[tensorflow-s2s-False] - ModuleNotFoundError: No module named 'ivy_transpiled_outputs.tensorflow_outputs.kornia.augmentation'
==================================================================================== 6 failed in 2242.41s (0:37:22) ====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 10 items

kornia/test_feature5.py ssssssssss                                                                                                                                                               [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
========================================================================================= 10 skipped in 5.28s ==========================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 2 items

kornia/geometry/test_boxes.py FF                                                                                                                                                                 [100%]

=============================================================================================== FAILURES ===============================================================================================
______________________________________________________________________________________ test_Boxes[jax-s2s-False] _______________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_Boxes(target_framework, mode, backend_compile):
        print("kornia.geometry.boxes.Boxes")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target_framework)
    
        torch_args = (
            torch.as_tensor([[0, 3, 1, 4], [5, 1, 8, 4]]),
        )
        transpiled_args = _nest_torch_tensor_to_new_framework(torch_args, target_framework)
    
        # test .from_tensor
        torch_boxes = kornia.geometry.boxes.Boxes.from_tensor(*torch_args, mode="xyxy")
>       transpiled_boxes = transpiled_kornia.geometry.boxes.Boxes.from_tensor(*transpiled_args, mode="xyxy")
E       TypeError: 'classmethod' object is not callable

kornia/geometry/test_boxes.py:43: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.boxes.Boxes
_____________________________________________________________________________________ test_Boxes3D[jax-s2s-False] ______________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_Boxes3D(target_framework, mode, backend_compile):
        print("kornia.geometry.boxes.Boxes3D")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target_framework)
    
        torch_args = (
            torch.as_tensor([[0, 3, 6, 1, 4, 8], [5, 1, 3, 8, 4, 9]]),
        )
        transpiled_args = _nest_torch_tensor_to_new_framework(torch_args, target_framework)
    
        # test .from_tensor
        torch_boxes3d = kornia.geometry.boxes.Boxes3D.from_tensor(*torch_args, mode="xyzxyz")
>       transpiled_boxes3d = transpiled_kornia.geometry.boxes.Boxes3D.from_tensor(*transpiled_args, mode="xyzxyz")
E       TypeError: 'classmethod' object is not callable

kornia/geometry/test_boxes.py:107: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.boxes.Boxes3D
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/geometry/test_boxes.py::test_Boxes[jax-s2s-False] - TypeError: 'classmethod' object is not callable
FAILED kornia/geometry/test_boxes.py::test_Boxes3D[jax-s2s-False] - TypeError: 'classmethod' object is not callable
========================================================================================== 2 failed in 5.58s ===========================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 35 items

kornia/test_losses.py .................FF..F.............                                                                                                                                        [100%]

=============================================================================================== FAILURES ===============================================================================================
______________________________________________________________________________ test_HausdorffERLoss[tensorflow-s2s-False] ______________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_HausdorffERLoss(target_framework, mode, backend_compile):
        print("kornia.losses.HausdorffERLoss")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledHausdorffERLoss = ivy.transpile(kornia.losses.HausdorffERLoss, source="torch", target=target_framework)
    
        torch_loss_fn = kornia.losses.HausdorffERLoss()
        transpiled_loss_fn = TranspiledHausdorffERLoss()
    
        torch_args = (
            torch.randn(5, 3, 20, 20),
            (torch.rand(5, 1, 20, 20) * 2).long(),
        )
        transpiled_args = _nest_torch_tensor_to_new_framework(torch_args, target_framework)
    
        torch_res = torch_loss_fn(*torch_args)
>       transpiled_res = transpiled_loss_fn(*transpiled_args)

kornia/test_losses.py:446: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_HausdorffERLoss()
args = (<tf.Tensor: shape=(5, 3, 20, 20), dtype=float32, numpy=
array([[[[-7.65146494e-01, -1.15070295e+00,  6.02523506e-01, ...        ...,
         [0, 0, 1, ..., 1, 1, 0],
         [1, 0, 1, ..., 1, 1, 1],
         [0, 0, 0, ..., 0, 1, 1]]]])>)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x7f72d4348e40, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...ode_context=['        return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_HausdorffERLoss(), <tf.Tensor: shape=(5, 3, 20, 20), dtype=float32, numpy=
array([[[[-7.65146494e-01, -1.1...        ...,
         [0, 0, 1, ..., 1, 1, 0],
         [1, 0, 1, ..., 1, 1, 1],
         [0, 0, 0, ..., 0, 1, 1]]]])>)
kwargs = {}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_HausdorffERLoss(), v = None, buffers = None
args = (<tf.Tensor: shape=(5, 3, 20, 20), dtype=float32, numpy=
array([[[[-7.65146494e-01, -1.15070295e+00,  6.02523506e-01, ...        ...,
         [0, 0, 1, ..., 1, 1, 0],
         [1, 0, 1, ..., 1, 1, 1],
         [0, 0, 0, ..., 0, 1, 1]]]])>)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_HausdorffERLoss(), <tf.Tensor: shape=(5, 3, 20, 20), dtype=float32, numpy=
array([[[[-7.65146494e-01, -1.1...        ...,
         [0, 0, 1, ..., 1, 1, 0],
         [1, 0, 1, ..., 1, 1, 1],
         [0, 0, 0, ..., 0, 1, 1]]]])>)
kwargs = {'buffers': None, 'v': None}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_HausdorffERLoss(), v = None, buffers = None
args = (<tf.Tensor: shape=(5, 3, 20, 20), dtype=float32, numpy=
array([[[[-7.65146494e-01, -1.15070295e+00,  6.02523506e-01, ...        ...,
         [0, 0, 1, ..., 1, 1, 0],
         [1, 0, 1, ..., 1, 1, 1],
         [0, 0, 0, ..., 0, 1, 1]]]])>)
kwargs = {}
first_arr = <tf.Tensor: shape=(5, 3, 20, 20), dtype=float32, numpy=
array([[[[-7.65146494e-01, -1.15070295e+00,  6.02523506e-01, ....11965e-02, -1.00119495e+00, ...,
           2.35005274e-01,  2.18948364e+00, -1.40955687e-01]]]],
      dtype=float32)>
replace_v = False, replace_buffers = False, call_signature = <Signature (pred, target)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Layer, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Layer, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Layer, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_HausdorffERLoss(),)
kwargs = {'pred': <tf.Tensor: shape=(5, 3, 20, 20), dtype=float32, numpy=
array([[[[-7.65146494e-01, -1.15070295e+00,  6.025235...        ...,
         [0, 0, 1, ..., 1, 1, 0],
         [1, 0, 1, ..., 1, 1, 1],
         [0, 0, 0, ..., 0, 1, 1]]]])>}

    @wraps(fn)
    def error_handler(*args, **kwargs):
        if not is_traceback_filtering_enabled():
            return fn(*args, **kwargs)
    
        filtered_tb = None
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            filtered_tb = _process_traceback_frames(e.__traceback__)
            # To get the full stack trace, call:
            # `keras.config.disable_traceback_filtering()`
>           raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/keras/src/utils/traceback_utils.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_HausdorffERLoss()
pred = <tf.Tensor: shape=(5, 3, 20, 20), dtype=float32, numpy=
array([[[[-7.65146494e-01, -1.15070295e+00,  6.02523506e-01, ....11965e-02, -1.00119495e+00, ...,
           2.35005274e-01,  2.18948364e+00, -1.40955687e-01]]]],
      dtype=float32)>
target = <tf.Tensor: shape=(5, 1, 20, 20), dtype=int64, numpy=
array([[[[1, 0, 0, ..., 0, 0, 0],
         [1, 0, 0, ..., 1, 0, ...         ...,
         [0, 0, 1, ..., 1, 1, 0],
         [1, 0, 1, ..., 1, 1, 1],
         [0, 0, 0, ..., 0, 1, 1]]]])>

    def call(self, pred, target):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_dim_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_max_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_size_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_min_frnt_
    
        if tensorflow_dim_frnt_(pred) != 4:
            raise ValueError(
                f"Only 2D images supported. Got {tensorflow_dim_frnt_(pred)}."
            )
        if not (
            tensorflow_max_frnt_(target) < tensorflow_size_frnt_(pred, 1)
            and tensorflow_min_frnt_(target) >= 0
            and target.dtype == tf.int64
        ):
            raise ValueError(
                f"Expect long type target value in range (0, {tensorflow_size_frnt_(pred, 1)}). ({tensorflow_min_frnt_(target)}, {tensorflow_max_frnt_(target)})"
            )
>       return super().call(pred, target)

ivy_transpiled_outputs/tensorflow_outputs/kornia/losses/hausdorff.py:289: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_HausdorffERLoss()
pred = <tf.Tensor: shape=(5, 3, 20, 20), dtype=float32, numpy=
array([[[[-7.65146494e-01, -1.15070295e+00,  6.02523506e-01, ....11965e-02, -1.00119495e+00, ...,
           2.35005274e-01,  2.18948364e+00, -1.40955687e-01]]]],
      dtype=float32)>
target = <tf.Tensor: shape=(5, 1, 20, 20), dtype=int64, numpy=
array([[[[1, 0, 0, ..., 0, 0, 0],
         [1, 0, 0, ..., 1, 0, ...         ...,
         [0, 0, 1, ..., 1, 1, 0],
         [1, 0, 1, ..., 1, 1, 1],
         [0, 0, 0, ..., 0, 1, 1]]]])>

    def call(self, pred, target):
        from ..core._backend import where
        from ..core._backend import stack
        from ..core._backend import tensor
        from ...ivy.functional.frontends.torch.tensor import tensorflow_size_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_item_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_max_frnt_
        from ...ivy.functional.backends.tensorflow.general import tensorflow_get_item
        from ...ivy.functional.frontends.torch.tensor import tensorflow_mean_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_sum_frnt_
    
        if not (
            tensorflow_shape_frnt_(pred)[2:] == tensorflow_shape_frnt_(target)[2:]
            and tensorflow_size_frnt_(pred, 0) == tensorflow_size_frnt_(target, 0)
            and tensorflow_size_frnt_(target, 1) == 1
        ):
            raise ValueError(
                f"Prediction and target need to be of same size, and target should not be one-hot.Got {tensorflow_shape_frnt_(pred)} and {tensorflow_shape_frnt_(target)}."
            )
        if tensorflow_size_frnt_(pred, 1) < tensorflow_item_frnt_(
            tensorflow_max_frnt_(target)
        ):
            raise ValueError("Invalid target value.")
        out = stack(
>           [
                self.perform_erosion(
                    tensorflow_get_item(
                        pred, (slice(None, None, None), slice(i, i + 1, None))
                    ),
                    where(
                        target == i,
                        tensor(1, device=target.device, dtype=target.dtype),
                        tensor(0, device=target.device, dtype=target.dtype),
                    ),
                )
                for i in range(tensorflow_size_frnt_(pred, 1))
            ]
        )

ivy_transpiled_outputs/tensorflow_outputs/kornia/losses/hausdorff.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

.0 = <range_iterator object at 0x7f72c846cab0>

        [
>           self.perform_erosion(
                tensorflow_get_item(
                    pred, (slice(None, None, None), slice(i, i + 1, None))
                ),
                where(
                    target == i,
                    tensor(1, device=target.device, dtype=target.dtype),
                    tensor(0, device=target.device, dtype=target.dtype),
                ),
            )
            for i in range(tensorflow_size_frnt_(pred, 1))
        ]
    )

ivy_transpiled_outputs/tensorflow_outputs/kornia/losses/hausdorff.py:123: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_HausdorffERLoss()
pred = <tf.Tensor: shape=(5, 1, 20, 20), dtype=float32, numpy=
array([[[[-7.65146494e-01, -1.15070295e+00,  6.02523506e-01, ....90051e+00,  1.04270875e+00, ...,
          -1.30769396e+00, -1.12300026e+00,  2.00381279e-01]]]],
      dtype=float32)>
target = <tf.Tensor: shape=(5, 1, 20, 20), dtype=int64, numpy=
array([[[[0, 1, 1, ..., 1, 1, 1],
         [0, 1, 1, ..., 0, 1, ...         ...,
         [1, 1, 0, ..., 0, 0, 1],
         [0, 1, 0, ..., 0, 0, 0],
         [1, 1, 1, ..., 1, 0, 0]]]])>

    def perform_erosion(self, pred, target):
        from ..core._backend import as_tensor
        from ..core._backend import zeros_like
        from ..core._backend import where
        from ...ivy.functional.frontends.torch.creation_ops import (
            tensorflow_ones_like_v_0p4p0_and_above_frnt,
        )
        from ...ivy.functional.frontends.torch.tensor import tensorflow_size_frnt_
        from ...ivy.functional.backends.tensorflow.general import tensorflow_set_item
        from ...ivy.functional.frontends.torch.tensor import tensorflow_squeeze_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_any_frnt_
    
        bound = (pred - target) ** 2
        kernel = as_tensor(self.kernel, device=pred.device, dtype=pred.dtype)
        eroded = zeros_like(bound, device=pred.device, dtype=pred.dtype)
        mask = tensorflow_ones_like_v_0p4p0_and_above_frnt(
            bound, device=pred.device, dtype=tf.bool
        )
        padding = (tensorflow_size_frnt_(kernel, -1) - 1) // 2
        for k in range(self.k):
>           dilation = self.conv(bound, weight=kernel, padding=padding, groups=1)
E           TypeError: Exception encountered when calling tensorflow_HausdorffERLoss.call().
E           
E           [1mtensorflow_conv2d_frnt() got multiple values for argument 'weight'[0m
E           
E           Arguments received by tensorflow_HausdorffERLoss.call():
E             • pred=tf.Tensor(shape=(5, 3, 20, 20), dtype=float32)
E             • target=tf.Tensor(shape=(5, 1, 20, 20), dtype=int64)

ivy_transpiled_outputs/tensorflow_outputs/kornia/losses/hausdorff.py:83: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.losses.HausdorffERLoss
_____________________________________________________________________________ test_HausdorffERLoss3D[tensorflow-s2s-False] _____________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_HausdorffERLoss3D(target_framework, mode, backend_compile):
        print("kornia.losses.HausdorffERLoss3D")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledHausdorffERLoss3D = ivy.transpile(kornia.losses.HausdorffERLoss3D, source="torch", target=target_framework)
    
        torch_loss_fn = kornia.losses.HausdorffERLoss3D()
        transpiled_loss_fn = TranspiledHausdorffERLoss3D()
    
        torch_args = (
            torch.randn(5, 3, 20, 20, 20),
            (torch.rand(5, 1, 20, 20, 20) * 2).long(),
        )
        transpiled_args = _nest_torch_tensor_to_new_framework(torch_args, target_framework)
    
        torch_res = torch_loss_fn(*torch_args)
>       transpiled_res = transpiled_loss_fn(*transpiled_args)

kornia/test_losses.py:471: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_HausdorffERLoss3D()
args = (<tf.Tensor: shape=(5, 3, 20, 20, 20), dtype=float32, numpy=
array([[[[[ 8.84407312e-02,  1.06564152e+00, -9.01989400e...    ...,
          [0, 0, 1, ..., 0, 1, 1],
          [0, 1, 1, ..., 0, 0, 1],
          [1, 1, 0, ..., 0, 1, 1]]]]])>)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x7f72d44717d0, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...ode_context=['        return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_HausdorffERLoss3D(), <tf.Tensor: shape=(5, 3, 20, 20, 20), dtype=float32, numpy=
array([[[[[ 8.84407312e-0...    ...,
          [0, 0, 1, ..., 0, 1, 1],
          [0, 1, 1, ..., 0, 0, 1],
          [1, 1, 0, ..., 0, 1, 1]]]]])>)
kwargs = {}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_HausdorffERLoss3D(), v = None, buffers = None
args = (<tf.Tensor: shape=(5, 3, 20, 20, 20), dtype=float32, numpy=
array([[[[[ 8.84407312e-02,  1.06564152e+00, -9.01989400e...    ...,
          [0, 0, 1, ..., 0, 1, 1],
          [0, 1, 1, ..., 0, 0, 1],
          [1, 1, 0, ..., 0, 1, 1]]]]])>)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_HausdorffERLoss3D(), <tf.Tensor: shape=(5, 3, 20, 20, 20), dtype=float32, numpy=
array([[[[[ 8.84407312e-0...    ...,
          [0, 0, 1, ..., 0, 1, 1],
          [0, 1, 1, ..., 0, 0, 1],
          [1, 1, 0, ..., 0, 1, 1]]]]])>)
kwargs = {'buffers': None, 'v': None}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_HausdorffERLoss3D(), v = None, buffers = None
args = (<tf.Tensor: shape=(5, 3, 20, 20, 20), dtype=float32, numpy=
array([[[[[ 8.84407312e-02,  1.06564152e+00, -9.01989400e...    ...,
          [0, 0, 1, ..., 0, 1, 1],
          [0, 1, 1, ..., 0, 0, 1],
          [1, 1, 0, ..., 0, 1, 1]]]]])>)
kwargs = {}
first_arr = <tf.Tensor: shape=(5, 3, 20, 20, 20), dtype=float32, numpy=
array([[[[[ 8.84407312e-02,  1.06564152e+00, -9.01989400e-...319e+00,  8.20726693e-01, ...,
            9.85262692e-01, -8.04572403e-02, -1.90644991e+00]]]]],
      dtype=float32)>
replace_v = False, replace_buffers = False, call_signature = <Signature (pred, target)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Layer, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Layer, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Layer, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_HausdorffERLoss3D(),)
kwargs = {'pred': <tf.Tensor: shape=(5, 3, 20, 20, 20), dtype=float32, numpy=
array([[[[[ 8.84407312e-02,  1.06564152e+00, -9.0...    ...,
          [0, 0, 1, ..., 0, 1, 1],
          [0, 1, 1, ..., 0, 0, 1],
          [1, 1, 0, ..., 0, 1, 1]]]]])>}

    @wraps(fn)
    def error_handler(*args, **kwargs):
        if not is_traceback_filtering_enabled():
            return fn(*args, **kwargs)
    
        filtered_tb = None
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            filtered_tb = _process_traceback_frames(e.__traceback__)
            # To get the full stack trace, call:
            # `keras.config.disable_traceback_filtering()`
>           raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/keras/src/utils/traceback_utils.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_HausdorffERLoss3D()
pred = <tf.Tensor: shape=(5, 3, 20, 20, 20), dtype=float32, numpy=
array([[[[[ 8.84407312e-02,  1.06564152e+00, -9.01989400e-...319e+00,  8.20726693e-01, ...,
            9.85262692e-01, -8.04572403e-02, -1.90644991e+00]]]]],
      dtype=float32)>
target = <tf.Tensor: shape=(5, 1, 20, 20, 20), dtype=int64, numpy=
array([[[[[1, 1, 1, ..., 0, 0, 0],
          [0, 1, 0, ..., ...     ...,
          [0, 0, 1, ..., 0, 1, 1],
          [0, 1, 1, ..., 0, 0, 1],
          [1, 1, 0, ..., 0, 1, 1]]]]])>

    def call(self, pred, target):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_dim_frnt_
    
        if tensorflow_dim_frnt_(pred) != 5:
            raise ValueError(
                f"Only 3D images supported. Got {tensorflow_dim_frnt_(pred)}."
            )
>       return super().call(pred, target)

ivy_transpiled_outputs/tensorflow_outputs/kornia/losses/hausdorff.py:280: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_HausdorffERLoss3D()
pred = <tf.Tensor: shape=(5, 3, 20, 20, 20), dtype=float32, numpy=
array([[[[[ 8.84407312e-02,  1.06564152e+00, -9.01989400e-...319e+00,  8.20726693e-01, ...,
            9.85262692e-01, -8.04572403e-02, -1.90644991e+00]]]]],
      dtype=float32)>
target = <tf.Tensor: shape=(5, 1, 20, 20, 20), dtype=int64, numpy=
array([[[[[1, 1, 1, ..., 0, 0, 0],
          [0, 1, 0, ..., ...     ...,
          [0, 0, 1, ..., 0, 1, 1],
          [0, 1, 1, ..., 0, 0, 1],
          [1, 1, 0, ..., 0, 1, 1]]]]])>

    def call(self, pred, target):
        from ..core._backend import where
        from ..core._backend import stack
        from ..core._backend import tensor
        from ...ivy.functional.frontends.torch.tensor import tensorflow_size_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_item_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_max_frnt_
        from ...ivy.functional.backends.tensorflow.general import tensorflow_get_item
        from ...ivy.functional.frontends.torch.tensor import tensorflow_mean_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_sum_frnt_
    
        if not (
            tensorflow_shape_frnt_(pred)[2:] == tensorflow_shape_frnt_(target)[2:]
            and tensorflow_size_frnt_(pred, 0) == tensorflow_size_frnt_(target, 0)
            and tensorflow_size_frnt_(target, 1) == 1
        ):
            raise ValueError(
                f"Prediction and target need to be of same size, and target should not be one-hot.Got {tensorflow_shape_frnt_(pred)} and {tensorflow_shape_frnt_(target)}."
            )
        if tensorflow_size_frnt_(pred, 1) < tensorflow_item_frnt_(
            tensorflow_max_frnt_(target)
        ):
            raise ValueError("Invalid target value.")
        out = stack(
>           [
                self.perform_erosion(
                    tensorflow_get_item(
                        pred, (slice(None, None, None), slice(i, i + 1, None))
                    ),
                    where(
                        target == i,
                        tensor(1, device=target.device, dtype=target.dtype),
                        tensor(0, device=target.device, dtype=target.dtype),
                    ),
                )
                for i in range(tensorflow_size_frnt_(pred, 1))
            ]
        )

ivy_transpiled_outputs/tensorflow_outputs/kornia/losses/hausdorff.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

.0 = <range_iterator object at 0x7f72d4f6af70>

        [
>           self.perform_erosion(
                tensorflow_get_item(
                    pred, (slice(None, None, None), slice(i, i + 1, None))
                ),
                where(
                    target == i,
                    tensor(1, device=target.device, dtype=target.dtype),
                    tensor(0, device=target.device, dtype=target.dtype),
                ),
            )
            for i in range(tensorflow_size_frnt_(pred, 1))
        ]
    )

ivy_transpiled_outputs/tensorflow_outputs/kornia/losses/hausdorff.py:123: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_HausdorffERLoss3D()
pred = <tf.Tensor: shape=(5, 1, 20, 20, 20), dtype=float32, numpy=
array([[[[[ 8.84407312e-02,  1.06564152e+00, -9.01989400e-...456e-01, -2.18518972e-01, ...,
           -5.10683179e-01, -1.74293056e-01,  1.53209293e+00]]]]],
      dtype=float32)>
target = <tf.Tensor: shape=(5, 1, 20, 20, 20), dtype=int64, numpy=
array([[[[[0, 0, 0, ..., 1, 1, 1],
          [1, 0, 1, ..., ...     ...,
          [1, 1, 0, ..., 1, 0, 0],
          [1, 0, 0, ..., 1, 1, 0],
          [0, 0, 1, ..., 1, 0, 0]]]]])>

    def perform_erosion(self, pred, target):
        from ..core._backend import as_tensor
        from ..core._backend import zeros_like
        from ..core._backend import where
        from ...ivy.functional.frontends.torch.creation_ops import (
            tensorflow_ones_like_v_0p4p0_and_above_frnt,
        )
        from ...ivy.functional.frontends.torch.tensor import tensorflow_size_frnt_
        from ...ivy.functional.backends.tensorflow.general import tensorflow_set_item
        from ...ivy.functional.frontends.torch.tensor import tensorflow_squeeze_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_any_frnt_
    
        bound = (pred - target) ** 2
        kernel = as_tensor(self.kernel, device=pred.device, dtype=pred.dtype)
        eroded = zeros_like(bound, device=pred.device, dtype=pred.dtype)
        mask = tensorflow_ones_like_v_0p4p0_and_above_frnt(
            bound, device=pred.device, dtype=tf.bool
        )
        padding = (tensorflow_size_frnt_(kernel, -1) - 1) // 2
        for k in range(self.k):
>           dilation = self.conv(bound, weight=kernel, padding=padding, groups=1)
E           TypeError: Exception encountered when calling tensorflow_HausdorffERLoss3D.call().
E           
E           [1mtensorflow_conv3d_frnt() got multiple values for argument 'weight'[0m
E           
E           Arguments received by tensorflow_HausdorffERLoss3D.call():
E             • pred=tf.Tensor(shape=(5, 3, 20, 20, 20), dtype=float32)
E             • target=tf.Tensor(shape=(5, 1, 20, 20, 20), dtype=int64)

ivy_transpiled_outputs/tensorflow_outputs/kornia/losses/hausdorff.py:83: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.losses.HausdorffERLoss3D
________________________________________________________________________________ test_MS_SSIMLoss[tensorflow-s2s-False] ________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_MS_SSIMLoss(target_framework, mode, backend_compile):
        print("kornia.losses.MS_SSIMLoss")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledMS_SSIMLoss = ivy.transpile(kornia.losses.MS_SSIMLoss, source="torch", target=target_framework)
    
        torch_loss_fn = kornia.losses.MS_SSIMLoss()
        transpiled_loss_fn = TranspiledMS_SSIMLoss()
    
        torch_args = (
            torch.rand(1, 3, 5, 5),
            torch.rand(1, 3, 5, 5),
        )
        transpiled_args = _nest_torch_tensor_to_new_framework(torch_args, target_framework)
    
        torch_res = torch_loss_fn(*torch_args)
>       transpiled_res = transpiled_loss_fn(*transpiled_args)

kornia/test_losses.py:546: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_MS_SSIMLoss()
args = (<tf.Tensor: shape=(1, 3, 5, 5), dtype=float32, numpy=
array([[[[0.9034829 , 0.6766982 , 0.78291196, 0.38908374, 0.784...5943166 , 0.894317  ],
         [0.4889546 , 0.85968655, 0.09348321, 0.38708806, 0.03999519]]]],
      dtype=float32)>)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x55fe5e4f9630, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...ode_context=['        return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_MS_SSIMLoss(), <tf.Tensor: shape=(1, 3, 5, 5), dtype=float32, numpy=
array([[[[0.9034829 , 0.6766982 , 0.7...5943166 , 0.894317  ],
         [0.4889546 , 0.85968655, 0.09348321, 0.38708806, 0.03999519]]]],
      dtype=float32)>)
kwargs = {}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_MS_SSIMLoss(), v = None, buffers = None
args = (<tf.Tensor: shape=(1, 3, 5, 5), dtype=float32, numpy=
array([[[[0.9034829 , 0.6766982 , 0.78291196, 0.38908374, 0.784...5943166 , 0.894317  ],
         [0.4889546 , 0.85968655, 0.09348321, 0.38708806, 0.03999519]]]],
      dtype=float32)>)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:2017: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_MS_SSIMLoss(), <tf.Tensor: shape=(1, 3, 5, 5), dtype=float32, numpy=
array([[[[0.9034829 , 0.6766982 , 0.7...5943166 , 0.894317  ],
         [0.4889546 , 0.85968655, 0.09348321, 0.38708806, 0.03999519]]]],
      dtype=float32)>)
kwargs = {'buffers': None, 'v': None}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_MS_SSIMLoss(), v = None, buffers = None
args = (<tf.Tensor: shape=(1, 3, 5, 5), dtype=float32, numpy=
array([[[[0.9034829 , 0.6766982 , 0.78291196, 0.38908374, 0.784...5943166 , 0.894317  ],
         [0.4889546 , 0.85968655, 0.09348321, 0.38708806, 0.03999519]]]],
      dtype=float32)>)
kwargs = {}
first_arr = <tf.Tensor: shape=(1, 3, 5, 5), dtype=float32, numpy=
array([[[[0.9034829 , 0.6766982 , 0.78291196, 0.38908374, 0.7849....53107846, 0.85230464],
         [0.64551616, 0.89350957, 0.81570303, 0.3277468 , 0.38761437]]]],
      dtype=float32)>
replace_v = False, replace_buffers = False, call_signature = <Signature (img1, img2)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Model, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Model, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Model, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1787: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_MS_SSIMLoss(),)
kwargs = {'img1': <tf.Tensor: shape=(1, 3, 5, 5), dtype=float32, numpy=
array([[[[0.9034829 , 0.6766982 , 0.78291196, 0.3890837...5943166 , 0.894317  ],
         [0.4889546 , 0.85968655, 0.09348321, 0.38708806, 0.03999519]]]],
      dtype=float32)>}

    @wraps(fn)
    def error_handler(*args, **kwargs):
        if not is_traceback_filtering_enabled():
            return fn(*args, **kwargs)
    
        filtered_tb = None
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            filtered_tb = _process_traceback_frames(e.__traceback__)
            # To get the full stack trace, call:
            # `keras.config.disable_traceback_filtering()`
>           raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/keras/src/utils/traceback_utils.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_MS_SSIMLoss()
img1 = <tf.Tensor: shape=(1, 3, 5, 5), dtype=float32, numpy=
array([[[[0.9034829 , 0.6766982 , 0.78291196, 0.38908374, 0.7849....53107846, 0.85230464],
         [0.64551616, 0.89350957, 0.81570303, 0.3277468 , 0.38761437]]]],
      dtype=float32)>
img2 = <tf.Tensor: shape=(1, 3, 5, 5), dtype=float32, numpy=
array([[[[0.49209303, 0.5249581 , 0.73387897, 0.6390659 , 0.9106....5943166 , 0.894317  ],
         [0.4889546 , 0.85968655, 0.09348321, 0.38708806, 0.03999519]]]],
      dtype=float32)>

    def call(self, img1, img2):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ...ivy.functional.frontends.torch.jit._jit_internal import (
            tensorflow_annotate_frnt,
        )
        from ...ivy.functional.frontends.torch.nn.functional.convolution_functions import (
            tensorflow_conv2d_frnt,
        )
        from ...ivy.functional.frontends.torch.tensor import tensorflow_prod_frnt_
        from ...ivy.functional.frontends.torch.nn.functional.loss_functions import (
            tensorflow_l1_loss_frnt,
        )
        from ...ivy.functional.frontends.torch.tensor import tensorflow_mean_frnt_
        from ...ivy.functional.backends.tensorflow.general import tensorflow_get_item
        from ...ivy.functional.frontends.torch.reduction_ops import tensorflow_mean_frnt
        from ...ivy.functional.frontends.torch.reduction_ops import tensorflow_sum_frnt
    
        if not isinstance(img1, (tensorflow.Tensor, tensorflow.keras.Variable)):
            raise TypeError(f"Input type is not a torch.Tensor. Got {type(img1)}")
        if not isinstance(img2, (tensorflow.Tensor, tensorflow.keras.Variable)):
            raise TypeError(f"Output type is not a torch.Tensor. Got {type(img2)}")
        if not len(tensorflow_shape_frnt_(img1)) == len(tensorflow_shape_frnt_(img2)):
            raise ValueError(
                f"Input shapes should be same. Got {type(img1)} and {type(img2)}."
            )
        g_masks: typing.Any = tensorflow_annotate_frnt(tensorflow.Tensor, self._g_masks)
        CH: typing.Any = tensorflow_shape_frnt_(img1)[-3]
>       mux = tensorflow_conv2d_frnt(img1, g_masks, groups=CH, padding=self.pad)

ivy_transpiled_outputs/tensorflow_outputs/kornia/losses/ms_ssim.py:136: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = <tf.Tensor: shape=(1, 3, 5, 5), dtype=float32, numpy=
array([[[[0.9034829 , 0.6766982 , 0.78291196, 0.38908374, 0.7849....53107846, 0.85230464],
         [0.64551616, 0.89350957, 0.81570303, 0.3277468 , 0.38761437]]]],
      dtype=float32)>
weight = <tf.Tensor: shape=(15, 1, 33, 33), dtype=float32, numpy=
array([[[[0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
 ...2472e-05, 6.2838459e-05, 7.8817087e-05, ...,
          7.8817087e-05, 6.2838459e-05, 4.9322472e-05]]]], dtype=float32)>
bias = None, stride = 1, padding = 16, dilation = 1, groups = 3

    def tensorflow_conv2d_frnt(
        input, weight, bias=None, stride=1, padding=0, dilation=1, groups=1
    ):
>       return tensorflow__conv_frnt(
            input,
            weight,
            bias=bias,
            stride=stride,
            padding=padding,
            dilation=dilation,
            groups=groups,
        )

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/nn/functional/convolution_functions.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = <tf.Tensor: shape=(1, 3, 5, 5), dtype=float32, numpy=
array([[[[0.9034829 , 0.6766982 , 0.78291196, 0.38908374, 0.7849....53107846, 0.85230464],
         [0.64551616, 0.89350957, 0.81570303, 0.3277468 , 0.38761437]]]],
      dtype=float32)>
weight = <tf.Tensor: shape=(15, 1, 33, 33), dtype=float32, numpy=
array([[[[0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
 ...2472e-05, 6.2838459e-05, 7.8817087e-05, ...,
          7.8817087e-05, 6.2838459e-05, 4.9322472e-05]]]], dtype=float32)>
bias = None, stride = 1, padding = [(16, 16), (16, 16)], dilation = 1, groups = 3

    def tensorflow__conv_frnt(
        input, weight, bias=None, stride=1, padding=0, dilation=1, groups=1
    ):
        from ...tensor import tensorflow_shape_frnt_
        from .....backends.tensorflow.layers import tensorflow_conv_general_dilated
    
        dims = len(tensorflow_shape_frnt_(input)) - 2
        if isinstance(padding, (str,)):
            padding = padding.upper()
        elif isinstance(padding, (int,)):
            padding = [*[(padding, padding) for _ in range(dims)]]
        else:
            padding = [*[(p, p) for p in padding]]
>       ret = tensorflow_conv_general_dilated(
            input,
            weight,
            stride,
            padding,
            dims=dims,
            data_format="channel_last",
            filter_format="channel_last",
            dilations=dilation,
            feature_group_count=groups,
            bias=bias,
        )

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/nn/functional/convolution_functions.py:45: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (<tf.Tensor: shape=(1, 3, 5, 5), dtype=float32, numpy=
array([[[[0.9034829 , 0.6766982 , 0.78291196, 0.38908374, 0.784....8817087e-05, ...,
          7.8817087e-05, 6.2838459e-05, 4.9322472e-05]]]], dtype=float32)>, 1, [(16, 16), (16, 16)])
kwargs = {'bias': None, 'data_format': 'channel_first', 'dilations': 1, 'dims': 2, ...}, tensorflow_set_item = <function tensorflow_set_item at 0x7f72c88f2cb0>
tensorflow_get_item = <function tensorflow_get_item at 0x7f72c88f2b00>, DATA_FORMAT = 'channels_first', value_map = {'NHWC': 'NCHW', 'NSC': 'NCS', 'channel_last': 'channel_first'}

    @functools.wraps(fn)
    def transpose_wrapper(*args, **kwargs):
        from ..functional.backends.tensorflow.general import tensorflow_set_item
        from ..functional.backends.tensorflow.general import tensorflow_get_item
    
        DATA_FORMAT = os.environ.get("DATA_FORMAT", "channels_first")
        if DATA_FORMAT == "channels_first":
            value_map = {"channel_last": "channel_first", "NHWC": "NCHW", "NSC": "NCS"}
            if "data_format" in kwargs and kwargs["data_format"] in value_map:
                kwargs = tensorflow_set_item(
                    kwargs,
                    "data_format",
                    tensorflow_get_item(value_map, kwargs["data_format"]),
                )
            if "filter_format" in kwargs and kwargs["filter_format"] in value_map:
                kwargs = tensorflow_set_item(
                    kwargs,
                    "filter_format",
                    tensorflow_get_item(value_map, kwargs["filter_format"]),
                )
            os.environ = tensorflow_set_item(os.environ, "DATA_FORMAT", "channels_last")
>       res = fn(*args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:460: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = [<tf.Tensor: shape=(1, 3, 5, 5), dtype=float32, numpy=
array([[[[0.9034829 , 0.6766982 , 0.78291196, 0.38908374, 0.784....8817087e-05, ...,
          7.8817087e-05, 6.2838459e-05, 4.9322472e-05]]]], dtype=float32)>, 1, [(16, 16), (16, 16)]]
kwargs = {'bias': None, 'data_format': 'channel_first', 'dilations': 1, 'dims': 2, ...}, tensorflow_is_array_bknd = <function tensorflow_is_array_bknd at 0x7f72c88f08b0>
tensorflow_set_item = <function tensorflow_set_item at 0x7f72c88f2cb0>, tensorflow_asarray = <function tensorflow_asarray at 0x7f72c88f1510>
tensorflow_get_item = <function tensorflow_get_item at 0x7f72c88f2b00>, num_args = 4
type_hints = mappingproxy(OrderedDict([('x', <Parameter "x: Union[tensorflow.python.framework.tensor.Tensor, tensorflow.python.ops...."out: Union[tensorflow.python.framework.tensor.Tensor, tensorflow.python.ops.variables.Variable, NoneType] = None">)]))
parameters = ['x', 'filters', 'strides', 'padding', 'dims', 'data_format', ...]
annotations = [typing.Union[tensorflow.python.framework.tensor.Tensor, tensorflow.python.ops.variables.Variable], typing.Union[tenso...le[int, int, int]], typing.Union[str, int, typing.Sequence[typing.Tuple[int, int]]], <class 'int'>, <class 'str'>, ...]
device = '/job:localhost/replica:0/task:0/device:CPU:0', i = 3

    @functools.wraps(fn)
    def _handle_array_like_without_promotion(*args, **kwargs):
        from .functional.ivy.general import tensorflow_is_array_bknd
        from .functional.backends.tensorflow.general import tensorflow_set_item
        from .functional.backends.tensorflow.creation import tensorflow_asarray
        from .functional.backends.tensorflow.general import tensorflow_get_item
    
        args = list(args)
        num_args = len(args)
        try:
            type_hints = inspect.signature(fn).parameters
        except (TypeError, ValueError):
            return fn(*args, **kwargs)
        parameters = list(type_hints.keys())
        annotations = [param.annotation for param in type_hints.values()]
        device = tensorflow__get_preferred_device(args, kwargs)
        for i, (annotation, parameter, arg) in enumerate(
            zip(annotations, parameters, args)
        ):
            annotation_str = str(annotation)
            if (
                ("rray" in annotation_str or "Tensor" in annotation_str)
                and parameter != "out"
                and all(
                    sq not in annotation_str
                    for sq in ["Sequence", "List", "Tuple", "float", "int", "bool"]
                )
            ):
                if i < num_args:
                    if arg is None or tensorflow__check_in_nested_sequence(
                        arg, value=Ellipsis, _type=slice
                    ):
                        continue
                    if not tensorflow_is_array_bknd(arg):
                        args = tensorflow_set_item(
                            args, i, tensorflow_asarray(arg, device=device)
                        )
                elif parameters in kwargs:
                    kwarg = tensorflow_get_item(kwargs, parameter)
                    if not tensorflow_is_array_bknd(kwarg):
                        kwargs = tensorflow_set_item(
                            kwargs, parameter, tensorflow_asarray(kwarg, device=device)
                        )
>       return fn(*args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/func_wrapper.py:139: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = <tf.Tensor: shape=(1, 5, 5, 3), dtype=float32, numpy=
array([[[[0.9034829 , 0.23322427, 0.85615176],
         [0.67669...0303],
         [0.14947689, 0.8863004 , 0.3277468 ],
         [0.5827009 , 0.99393475, 0.38761437]]]], dtype=float32)>
filters = <tf.Tensor: shape=(33, 33, 1, 15), dtype=float32, numpy=
array([[[[0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
 ...0000e+00, 0.0000000e+00, 0.0000000e+00, ...,
          4.9322472e-05, 4.9322472e-05, 4.9322472e-05]]]], dtype=float32)>
strides = 1, padding = [(16, 16), (16, 16)]

    @tensorflow_handle_transpose_in_input_and_output_for_functions
    @tensorflow_handle_array_like_without_promotion
    def tensorflow_conv_general_dilated(
        x: Union[tensorflow.Tensor, tensorflow.Variable],
        filters: Union[tensorflow.Tensor, tensorflow.Variable],
        strides: Union[int, Tuple[int], Tuple[int, int], Tuple[int, int, int]],
        padding: Union[str, int, Sequence[Tuple[int, int]]],
        /,
        *,
        dims: int = 2,
        data_format: str = "channel_last",
        filter_format: str = "channel_last",
        feature_group_count: int = 1,
        x_dilations: Union[int, Tuple[int], Tuple[int, int], Tuple[int, int, int]] = 1,
        dilations: Union[int, Tuple[int], Tuple[int, int], Tuple[int, int, int]] = 1,
        bias: Optional[Union[tensorflow.Tensor, tensorflow.Variable]] = None,
        out: Optional[Union[tensorflow.Tensor, tensorflow.Variable]] = None,
    ):
        from .device import tensorflow_dev
        from ...ivy.layers import tensorflow__get_x_data_format_bknd
    
        if filter_format == "channel_first":
            filters = tensorflow.transpose(filters, (*range(2, dims + 2), 1, 0))
        num_channels = x.shape[1] if data_format == "channel_first" else x.shape[-1]
        if filters.shape[-2] != num_channels // feature_group_count:
            raise Exception(
                f"given feature_group_count {feature_group_count} expected input channel of the filter to be {num_channels // feature_group_count} but got {filters.shape[-2]}"
            )
        if num_channels % feature_group_count != 0:
            raise Exception(
                f"input channel should be divisible by feature group count {feature_group_count} but got input channel {num_channels}"
            )
        permuted_x = False
        if data_format == "channel_first" and (
            tensorflow_dev(x) == "cpu" or feature_group_count != 1
        ):
            x = tensorflow.transpose(x, (0, *range(2, dims + 2), 1))
            data_format = "channel_last"
            permuted_x = True
        data_format = tensorflow__get_x_data_format_bknd(dims, data_format)
        x = tensorflow__x_dil_before_conv(x, dims, x_dilations, data_format)
        if dims == 2:
            padding = tensorflow__extend_2d_padding(padding, data_format)
            if feature_group_count == 1:
                res = tensorflow.nn.conv2d(
                    x,
                    filters,
                    strides,
                    padding,
                    data_format=data_format,
                    dilations=dilations,
                )
            else:
                if not isinstance(padding, str):
                    padding = padding[1:-1]
>               res = tensorflow_depthwise_conv2d(
                    x,
                    tensorflow.transpose(filters, (0, 1, 3, 2)),
                    strides,
                    padding,
                    data_format=data_format,
                    dilations=dilations,
                )

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/backends/tensorflow/layers.py:200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (<tf.Tensor: shape=(1, 5, 5, 3), dtype=float32, numpy=
array([[[[0.9034829 , 0.23322427, 0.85615176],
         [0.6766...      [4.9322472e-05],
         [4.9322472e-05],
         [4.9322472e-05]]]], dtype=float32)>, 1, [(16, 16), (16, 16)])
kwargs = {'data_format': 'NHWC', 'dilations': 1}, tensorflow_set_item = <function tensorflow_set_item at 0x7f72c88f2cb0>, tensorflow_get_item = <function tensorflow_get_item at 0x7f72c88f2b00>
DATA_FORMAT = 'channels_last'

    @functools.wraps(fn)
    def transpose_wrapper(*args, **kwargs):
        from ..functional.backends.tensorflow.general import tensorflow_set_item
        from ..functional.backends.tensorflow.general import tensorflow_get_item
    
        DATA_FORMAT = os.environ.get("DATA_FORMAT", "channels_first")
        if DATA_FORMAT == "channels_first":
            value_map = {"channel_last": "channel_first", "NHWC": "NCHW", "NSC": "NCS"}
            if "data_format" in kwargs and kwargs["data_format"] in value_map:
                kwargs = tensorflow_set_item(
                    kwargs,
                    "data_format",
                    tensorflow_get_item(value_map, kwargs["data_format"]),
                )
            if "filter_format" in kwargs and kwargs["filter_format"] in value_map:
                kwargs = tensorflow_set_item(
                    kwargs,
                    "filter_format",
                    tensorflow_get_item(value_map, kwargs["filter_format"]),
                )
            os.environ = tensorflow_set_item(os.environ, "DATA_FORMAT", "channels_last")
>       res = fn(*args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:460: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = <tf.Tensor: shape=(1, 5, 5, 3), dtype=float32, numpy=
array([[[[0.9034829 , 0.23322427, 0.85615176],
         [0.67669...0303],
         [0.14947689, 0.8863004 , 0.3277468 ],
         [0.5827009 , 0.99393475, 0.38761437]]]], dtype=float32)>
filters = <tf.Tensor: shape=(33, 33, 15, 1), dtype=float32, numpy=
array([[[[0.0000000e+00],
         [0.0000000e+00],
         ...00e+00],
         ...,
         [4.9322472e-05],
         [4.9322472e-05],
         [4.9322472e-05]]]], dtype=float32)>
strides = [1, 1, 1, 1], padding = [(0, 0), (16, 16), (16, 16), (0, 0)]

    @tensorflow_handle_transpose_in_input_and_output_for_functions
    def tensorflow_depthwise_conv2d(
        x: Union[tensorflow.Tensor, tensorflow.Variable],
        filters: Union[tensorflow.Tensor, tensorflow.Variable],
        strides: Union[int, Tuple[int, int]],
        padding: Union[str, int, Sequence[Tuple[int, int]]],
        /,
        *,
        data_format: str = "NHWC",
        dilations: Union[int, Tuple[int, int]] = 1,
        out: Optional[Union[tensorflow.Tensor, tensorflow.Variable]] = None,
    ):
        from .device import tensorflow_dev
    
        strides = [strides] * 2 if isinstance(strides, int) else strides
        dilations = [dilations] * 2 if isinstance(dilations, int) else dilations
        permuted_x = False
        if data_format == "NCHW" and tensorflow_dev(x) == "cpu":
            x = tensorflow.transpose(x, (0, 2, 3, 1))
            data_format = "NHWC"
            permuted_x = True
        if tensorflow.rank(filters) == 3:
            filters = tensorflow.expand_dims(filters, -1)
        padding = tensorflow__extend_2d_padding(padding, data_format)
        strides = [1, strides[0], strides[1], 1]
>       res = tensorflow.nn.depthwise_conv2d(
            x, filters, strides, padding, data_format, dilations
        )
E       tensorflow.python.framework.errors_impl.InvalidArgumentError: Exception encountered when calling tensorflow_MS_SSIMLoss.call().
E       
E       [1m{{function_node __wrapped__DepthwiseConv2dNative_device_/job:localhost/replica:0/task:0/device:CPU:0}} input and filter must have the same depth: 3 vs 15 [Op:DepthwiseConv2dNative] name: [0m
E       
E       Arguments received by tensorflow_MS_SSIMLoss.call():
E         • img1=tf.Tensor(shape=(1, 3, 5, 5), dtype=float32)
E         • img2=tf.Tensor(shape=(1, 3, 5, 5), dtype=float32)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/backends/tensorflow/layers.py:137: InvalidArgumentError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.losses.MS_SSIMLoss
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/test_losses.py::test_HausdorffERLoss[tensorflow-s2s-False] - TypeError: Exception encountered when calling tensorflow_HausdorffERLoss.call().
FAILED kornia/test_losses.py::test_HausdorffERLoss3D[tensorflow-s2s-False] - TypeError: Exception encountered when calling tensorflow_HausdorffERLoss3D.call().
FAILED kornia/test_losses.py::test_MS_SSIMLoss[tensorflow-s2s-False] - tensorflow.python.framework.errors_impl.InvalidArgumentError: Exception encountered when calling tensorflow_MS_SSIMLoss.call().
============================================================================== 3 failed, 32 passed in 2154.11s (0:35:54) ===============================================================================


========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 16 items

kornia/augmentation/test_augmentation3.py ........FF...FFF                                                                                                                                       [100%]

=============================================================================================== FAILURES ===============================================================================================
_____________________________________________________________________________ test_RandomResizedCrop[tensorflow-s2s-False] _____________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_RandomResizedCrop(target_framework, mode, backend_compile):
        print("kornia.augmentation.RandomResizedCrop")
    
        init_args = ()
        init_kwargs = {"size": (3, 3), "scale": (3., 3.), "ratio": (2., 2.), "p": 1., "cropping_mode": "resample"}
        call_args = (torch.tensor([[[0., 1., 2.],
                                    [3., 4., 5.],
                                    [6., 7., 8.]]]),)
        call_kwargs = {}
    
>       _test_augmentation_class(
            kornia.augmentation.RandomResizedCrop,
            target_framework,
            init_args,
            init_kwargs,
            call_args,
            call_kwargs,
            deterministic_output=False,
            backend_compile=backend_compile,
        )

kornia/augmentation/test_augmentation3.py:248: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

augmentation_cls = <class 'kornia.augmentation._2d.geometric.resized_crop.RandomResizedCrop'>, target = 'tensorflow', init_args = ()
init_kwargs = {'cropping_mode': 'resample', 'p': 1.0, 'ratio': (2.0, 2.0), 'scale': (3.0, 3.0), ...}, call_args = (tensor([[[0., 1., 2.],
         [3., 4., 5.],
         [6., 7., 8.]]]),)
call_kwargs = {}, deterministic_output = False, backend_compile = False, tolerance = 0.001

    def _test_augmentation_class(
        augmentation_cls,
        target,
        init_args=(),
        init_kwargs={},
        call_args=(),
        call_kwargs={},
        deterministic_output=True,
        backend_compile=False,
        tolerance=1e-3,
    ):
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, target=target)
        transpiled_cls = eval("transpiled_" + f"{augmentation_cls.__module__}.{augmentation_cls.__name__}")
    
        torch_aug = augmentation_cls(*init_args, **init_kwargs)
        transpiled_init_args = _nest_torch_tensor_to_new_framework(init_args, target)
        transpiled_init_kwargs = _nest_torch_tensor_to_new_framework(init_kwargs, target)
        transpiled_aug = transpiled_cls(*transpiled_init_args, **transpiled_init_kwargs)
    
        # assert dir(torch_aug) == dir(transpiled_aug), f"attributes/methods of transpiled object do not align with the original - orig: {dir(torch_aug)} != transpiled: {dir(transpiled_aug)}"
    
        torch_out = torch_aug(*call_args, **call_kwargs)
        transpiled_call_args = _nest_torch_tensor_to_new_framework(call_args, target)
        transpiled_call_kwargs = _nest_torch_tensor_to_new_framework(call_kwargs, target)
>       transpiled_out = transpiled_aug(*transpiled_call_args, **transpiled_call_kwargs)

kornia/augmentation/test_augmentation3.py:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomResizedCrop(scale=(3.0, 3.0), resize_to=(2.0, 2.0), output_size=(3, 3), p=1.0, p_batch=1.0, same_on_batch=False, size=(3, 3), resample=bilinear, align_corners=True, cropping_mode=resample, padding_mode=zeros)
args = (<tf.Tensor: shape=(1, 3, 3), dtype=float32, numpy=
array([[[0., 1., 2.],
        [3., 4., 5.],
        [6., 7., 8.]]], dtype=float32)>,), kwargs = {}
stack = [FrameInfo(frame=<frame at 0x7ff7443f5040, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...kexec', code_context=['        return self._inner_hookexec(hook_name, methods, kwargs, firstresult)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomResizedCrop(scale=(3.0, 3.0), resize_to=(2.0, 2.0), output_size=(3, 3), p=1.0, p_batch=1.0, same_on_...e=(1, 3, 3), dtype=float32, numpy=
array([[[0., 1., 2.],
        [3., 4., 5.],
        [6., 7., 8.]]], dtype=float32)>)
kwargs = {}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomResizedCrop(scale=(3.0, 3.0), resize_to=(2.0, 2.0), output_size=(3, 3), p=1.0, p_batch=1.0, same_on_batch=False, size=(3, 3), resample=bilinear, align_corners=True, cropping_mode=resample, padding_mode=zeros)
v = None, buffers = None, args = (<tf.Tensor: shape=(1, 3, 3), dtype=float32, numpy=
array([[[0., 1., 2.],
        [3., 4., 5.],
        [6., 7., 8.]]], dtype=float32)>,), kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomResizedCrop(scale=(3.0, 3.0), resize_to=(2.0, 2.0), output_size=(3, 3), p=1.0, p_batch=1.0, same_on_...e=(1, 3, 3), dtype=float32, numpy=
array([[[0., 1., 2.],
        [3., 4., 5.],
        [6., 7., 8.]]], dtype=float32)>)
kwargs = {'buffers': None, 'v': None}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomResizedCrop(scale=(3.0, 3.0), resize_to=(2.0, 2.0), output_size=(3, 3), p=1.0, p_batch=1.0, same_on_batch=False, size=(3, 3), resample=bilinear, align_corners=True, cropping_mode=resample, padding_mode=zeros)
v = None, buffers = None, args = (<tf.Tensor: shape=(1, 3, 3), dtype=float32, numpy=
array([[[0., 1., 2.],
        [3., 4., 5.],
        [6., 7., 8.]]], dtype=float32)>,), kwargs = {}
first_arr = <tf.Tensor: shape=(1, 3, 3), dtype=float32, numpy=
array([[[0., 1., 2.],
        [3., 4., 5.],
        [6., 7., 8.]]], dtype=float32)>, replace_v = False, replace_buffers = False
call_signature = <Signature (input, params=None, **kwargs)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Layer, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Layer, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Layer, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomResizedCrop(scale=(3.0, 3.0), resize_to=(2.0, 2.0), output_size=(3, 3), p=1.0, p_batch=1.0, same_on_batch=False, size=(3, 3), resample=bilinear, align_corners=True, cropping_mode=resample, padding_mode=zeros),)
kwargs = {'input': <tf.Tensor: shape=(1, 3, 3), dtype=float32, numpy=
array([[[0., 1., 2.],
        [3., 4., 5.],
        [6., 7., 8.]]], dtype=float32)>}

    @wraps(fn)
    def error_handler(*args, **kwargs):
        if not is_traceback_filtering_enabled():
            return fn(*args, **kwargs)
    
        filtered_tb = None
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            filtered_tb = _process_traceback_frames(e.__traceback__)
            # To get the full stack trace, call:
            # `keras.config.disable_traceback_filtering()`
>           raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/keras/src/utils/traceback_utils.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomResizedCrop(scale=(3.0, 3.0), resize_to=(2.0, 2.0), output_size=(3, 3), p=1.0, p_batch=1.0, same_on_batch=False, size=(3, 3), resample=bilinear, align_corners=True, cropping_mode=resample, padding_mode=zeros)
input = <tf.Tensor: shape=(1, 3, 3), dtype=float32, numpy=
array([[[0., 1., 2.],
        [3., 4., 5.],
        [6., 7., 8.]]], dtype=float32)>, params = None, kwargs = {}
tensorflow_shape_frnt_ = <function tensorflow_shape_frnt_ at 0x7ff72c43e950>, tensorflow_set_item = <function tensorflow_set_item at 0x7ff72c18d1b0>
tensor = <function tensorflow_tensor_frnt at 0x7ff72c1a0dc0>
in_tensor = <tf.Tensor: shape=(1, 1, 3, 3), dtype=float32, numpy=
array([[[[0., 1., 2.],
         [3., 4., 5.],
         [6., 7., 8.]]]], dtype=float32)>
input_shape = ivy.frontends.torch.Size([1, 3, 3]), batch_shape = ivy.frontends.torch.Size([1, 1, 3, 3])

    def call(self, input, params=None, **kwargs):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ...ivy.functional.backends.tensorflow.general import tensorflow_set_item
        from ..core._backend import tensor
    
        in_tensor = self.__unpack_input__(input)
        input_shape = tensorflow_shape_frnt_(in_tensor)
        in_tensor = self.transform_tensor(in_tensor)
        batch_shape = tensorflow_shape_frnt_(in_tensor)
        if params is None:
>           params = self.forward_parameters(batch_shape)

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/base.py:228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomResizedCrop(scale=(3.0, 3.0), resize_to=(2.0, 2.0), output_size=(3, 3), p=1.0, p_batch=1.0, same_on_batch=False, size=(3, 3), resample=bilinear, align_corners=True, cropping_mode=resample, padding_mode=zeros)
batch_shape = ivy.frontends.torch.Size([1, 1, 3, 3])

    def forward_parameters(self, batch_shape):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_sum_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_item_frnt_
        from ...ivy.functional.backends.tensorflow.general import tensorflow_set_item
        from ..core._backend import tensor
    
        batch_prob = self.__batch_prob_generator__(
            batch_shape, self.p, self.p_batch, self.same_on_batch
        )
        to_apply = batch_prob > 0.5
>       _params = self.generate_parameters(
            tuple(
                (
                    int(tensorflow_item_frnt_(tensorflow_sum_frnt_(to_apply))),
                    *batch_shape[1:],
                )
            )
        )

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/base.py:200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomResizedCrop(scale=(3.0, 3.0), resize_to=(2.0, 2.0), output_size=(3, 3), p=1.0, p_batch=1.0, same_on_batch=False, size=(3, 3), resample=bilinear, align_corners=True, cropping_mode=resample, padding_mode=zeros)
batch_shape = (1, 1, 3, 3)

    def generate_parameters(self, batch_shape):
        if self._param_generator is not None:
>           return self._param_generator(batch_shape, self.same_on_batch)

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/base.py:123: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = scale=(3.0, 3.0), resize_to=(2.0, 2.0), output_size=(3, 3), args = ((1, 1, 3, 3), False), kwargs = {}
stack = [FrameInfo(frame=<frame at 0x7ff7443f7640, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...ion.py', lineno=46, function='__call__', code_context=['            return call_fn(*args, **kwargs)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = scale=(3.0, 3.0), resize_to=(2.0, 2.0), output_size=(3, 3), v = None, buffers = None, args = ((1, 1, 3, 3), False), kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = scale=(3.0, 3.0), resize_to=(2.0, 2.0), output_size=(3, 3), v = None, buffers = None, args = ((1, 1, 3, 3), False), kwargs = {}, replace_v = False, replace_buffers = False
call_signature = <Signature (batch_shape, same_on_batch=False)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Layer, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Layer, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Layer, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = scale=(3.0, 3.0), resize_to=(2.0, 2.0), output_size=(3, 3), batch_shape = (1, 1, 3, 3), same_on_batch = False

    def call(self, batch_shape, same_on_batch=False):
        from ....utils.helpers import tensorflow__extract_device_dtype
        from .....ivy.functional.frontends.torch.tensor import tensorflow_to_frnt_
        from ...utils.helpers import tensorflow__adapted_rsampling
        from .....ivy.functional.frontends.torch.pointwise_ops import (
            tensorflow_exp_frnt,
        )
        from .....ivy.functional.frontends.torch.tensor import tensorflow_floor_frnt_
        from .....ivy.functional.frontends.torch.tensor import tensorflow_round_frnt_
        from .....ivy.functional.frontends.torch.pointwise_ops import (
            tensorflow_sqrt_frnt,
        )
        from .....ivy.functional.frontends.torch.tensor import tensorflow_int_frnt_
        from .....ivy.functional.frontends.torch.tensor import tensorflow_max_frnt_
        from .....ivy.functional.frontends.torch.tensor import tensorflow_cumsum_frnt_
        from .....ivy.functional.frontends.torch.tensor import tensorflow_bool_frnt_
        from .....ivy.functional.backends.tensorflow.general import tensorflow_get_item
        from .....ivy.functional.frontends.torch.creation_ops import (
            tensorflow_arange_frnt,
        )
        from .....ivy.functional.frontends.torch.tensor import tensorflow_all_frnt_
        from .....ivy.functional.frontends.torch.tensor import tensorflow_min_frnt_
        from .....ivy.functional.frontends.torch.pointwise_ops import (
            tensorflow_round_frnt,
        )
        from .....ivy.functional.frontends.torch.tensor import tensorflow_where_frnt_
        from .....ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            tensorflow_stack_frnt,
        )
        from ....core._backend import tensor
        from ....core._backend import zeros
    
        batch_size = batch_shape[0]
        size = batch_shape[-2], batch_shape[-1]
        _device, _dtype = tensorflow__extract_device_dtype([self.scale, self.ratio])
        if batch_size == 0:
            return {
                "src": zeros([0, 4, 2], device=_device, dtype=_dtype),
                "dst": zeros([0, 4, 2], device=_device, dtype=_dtype),
                "size": zeros([0, 2], device=_device, dtype=_dtype),
            }
        rand = tensorflow_to_frnt_(
            tensorflow__adapted_rsampling(
                (batch_size, 10), self.rand_sampler, same_on_batch
            ),
            device=_device,
            dtype=_dtype,
        )
        area = (
            (rand * (self.scale[1] - self.scale[0]) + self.scale[0]) * size[0] * size[1]
        )
        log_ratio = tensorflow_to_frnt_(
            tensorflow__adapted_rsampling(
                (batch_size, 10), self.log_ratio_sampler, same_on_batch
            ),
            device=_device,
            dtype=_dtype,
        )
        aspect_ratio = tensorflow_exp_frnt(log_ratio)
        w = tensorflow_floor_frnt_(
            tensorflow_round_frnt_(tensorflow_sqrt_frnt(area * aspect_ratio))
        )
        h = tensorflow_floor_frnt_(
            tensorflow_round_frnt_(tensorflow_sqrt_frnt(area / aspect_ratio))
        )
>       cond = tensorflow_int_frnt_((0 < w) * (w < size[0]) * (0 < h) * (h < size[1]))

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/random_generator/_2d/crop.py:328: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <tf.Tensor: shape=(1, 10), dtype=bool, numpy=
array([[ True,  True,  True,  True,  True,  True,  True,  True,  True,
         True]])>
rhs = <tf.Tensor: shape=(1, 10), dtype=bool, numpy=
array([[False, False, False, False, False, False, False, False, False,
        False]])>

    def impl(self, rhs):
        try:
            return original_method(self, rhs)
        except Exception:
>           return patched_method(self, rhs)

ivy_transpiled_outputs/tensorflow_outputs/__init__.py:65: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = <tf.Tensor: shape=(1, 10), dtype=bool, numpy=
array([[ True,  True,  True,  True,  True,  True,  True,  True,  True,
         True]])>
other = <tf.Tensor: shape=(1, 10), dtype=bool, numpy=
array([[False, False, False, False, False, False, False, False, False,
        False]])>

    def tensorflow___mul___frnt_(tensor, other):
        from .pointwise_ops import tensorflow_mul_frnt
    
>       return tensorflow_mul_frnt(tensor, other)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/tensor.py:131: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = <tf.Tensor: shape=(1, 10), dtype=bool, numpy=
array([[ True,  True,  True,  True,  True,  True,  True,  True,  True,
         True]])>
other = <tf.Tensor: shape=(1, 10), dtype=bool, numpy=
array([[False, False, False, False, False, False, False, False, False,
        False]])>

    def tensorflow_mul_frnt(input, other, *, out=None):
        from .__init__ import tensorflow_promote_types_of_torch_inputs_frnt
        from ...backends.tensorflow.elementwise import tensorflow_multiply
    
        input, other = tensorflow_promote_types_of_torch_inputs_frnt(input, other)
>       return tensorflow_multiply(input, other, out=out)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/pointwise_ops.py:118: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x1 = <tf.Tensor: shape=(1, 10), dtype=bool, numpy=
array([[ True,  True,  True,  True,  True,  True,  True,  True,  True,
         True]])>
x2 = <tf.Tensor: shape=(1, 10), dtype=bool, numpy=
array([[False, False, False, False, False, False, False, False, False,
        False]])>

    def tensorflow_multiply(
        x1: Union[float, tensorflow.Tensor, tensorflow.Variable],
        x2: Union[float, tensorflow.Tensor, tensorflow.Variable],
        /,
        *,
        out: Optional[Union[tensorflow.Tensor, tensorflow.Variable]] = None,
    ):
        from ...ivy.data_type import tensorflow_promote_types_of_inputs_bknd
    
        x1, x2 = tensorflow_promote_types_of_inputs_bknd(x1, x2)
>       return tensorflow.math.multiply(x1, x2)
E       tensorflow.python.framework.errors_impl.InvalidArgumentError: Exception encountered when calling tensorflow_ResizedCropGenerator.call().
E       
E       [1mValue for attr 'T' of bool is not in the list of allowed values: bfloat16, half, float, double, uint8, int8, uint16, int16, int32, uint32, uint64, int64, complex64, complex128
E       	; NodeDef: {{node Mul}}; Op<name=Mul; signature=x:T, y:T -> z:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE, DT_UINT8, DT_INT8, DT_UINT16, DT_INT16, DT_INT32, DT_UINT32, DT_UINT64, DT_INT64, DT_COMPLEX64, DT_COMPLEX128]; is_commutative=true> [Op:Mul] name: [0m
E       
E       Arguments received by tensorflow_ResizedCropGenerator.call():
E         • batch_shape=('1', '1', '3', '3')
E         • same_on_batch=False

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/backends/tensorflow/elementwise.py:353: InvalidArgumentError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.RandomResizedCrop
______________________________________________________________________________ test_RandomRotation[tensorflow-s2s-False] _______________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_RandomRotation(target_framework, mode, backend_compile):
        print("kornia.augmentation.RandomRotation")
    
        init_args = ()
        init_kwargs = {"degrees": 45.0, "p": 1.}
        call_args = (torch.tensor([[1., 0., 0., 2.],
                                   [0., 0., 0., 0.],
                                   [0., 1., 2., 0.],
                                   [0., 0., 1., 2.]]),)
        call_kwargs = {}
    
>       _test_augmentation_class(
            kornia.augmentation.RandomRotation,
            target_framework,
            init_args,
            init_kwargs,
            call_args,
            call_kwargs,
            deterministic_output=False,
            backend_compile=backend_compile,
        )

kornia/augmentation/test_augmentation3.py:271: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

augmentation_cls = <class 'kornia.augmentation._2d.geometric.rotation.RandomRotation'>, target = 'tensorflow', init_args = (), init_kwargs = {'degrees': 45.0, 'p': 1.0}
call_args = (tensor([[1., 0., 0., 2.],
        [0., 0., 0., 0.],
        [0., 1., 2., 0.],
        [0., 0., 1., 2.]]),), call_kwargs = {}, deterministic_output = False, backend_compile = False
tolerance = 0.001

    def _test_augmentation_class(
        augmentation_cls,
        target,
        init_args=(),
        init_kwargs={},
        call_args=(),
        call_kwargs={},
        deterministic_output=True,
        backend_compile=False,
        tolerance=1e-3,
    ):
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, target=target)
        transpiled_cls = eval("transpiled_" + f"{augmentation_cls.__module__}.{augmentation_cls.__name__}")
    
        torch_aug = augmentation_cls(*init_args, **init_kwargs)
        transpiled_init_args = _nest_torch_tensor_to_new_framework(init_args, target)
        transpiled_init_kwargs = _nest_torch_tensor_to_new_framework(init_kwargs, target)
        transpiled_aug = transpiled_cls(*transpiled_init_args, **transpiled_init_kwargs)
    
        # assert dir(torch_aug) == dir(transpiled_aug), f"attributes/methods of transpiled object do not align with the original - orig: {dir(torch_aug)} != transpiled: {dir(transpiled_aug)}"
    
        torch_out = torch_aug(*call_args, **call_kwargs)
        transpiled_call_args = _nest_torch_tensor_to_new_framework(call_args, target)
        transpiled_call_kwargs = _nest_torch_tensor_to_new_framework(call_kwargs, target)
>       transpiled_out = transpiled_aug(*transpiled_call_args, **transpiled_call_kwargs)

kornia/augmentation/test_augmentation3.py:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomRotation(degrees=45.0, p=1.0, p_batch=1.0, same_on_batch=False, resample=bilinear, align_corners=True)
args = (<tf.Tensor: shape=(4, 4), dtype=float32, numpy=
array([[1., 0., 0., 2.],
       [0., 0., 0., 0.],
       [0., 1., 2., 0.],
       [0., 0., 1., 2.]], dtype=float32)>,), kwargs = {}
stack = [FrameInfo(frame=<frame at 0x7ff745211640, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...kexec', code_context=['        return self._inner_hookexec(hook_name, methods, kwargs, firstresult)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomRotation(degrees=45.0, p=1.0, p_batch=1.0, same_on_batch=False, resample=bilinear, align_corners=Tru...=
array([[1., 0., 0., 2.],
       [0., 0., 0., 0.],
       [0., 1., 2., 0.],
       [0., 0., 1., 2.]], dtype=float32)>)
kwargs = {}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomRotation(degrees=45.0, p=1.0, p_batch=1.0, same_on_batch=False, resample=bilinear, align_corners=True), v = None, buffers = None
args = (<tf.Tensor: shape=(4, 4), dtype=float32, numpy=
array([[1., 0., 0., 2.],
       [0., 0., 0., 0.],
       [0., 1., 2., 0.],
       [0., 0., 1., 2.]], dtype=float32)>,), kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomRotation(degrees=45.0, p=1.0, p_batch=1.0, same_on_batch=False, resample=bilinear, align_corners=Tru...=
array([[1., 0., 0., 2.],
       [0., 0., 0., 0.],
       [0., 1., 2., 0.],
       [0., 0., 1., 2.]], dtype=float32)>)
kwargs = {'buffers': None, 'v': None}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomRotation(degrees=45.0, p=1.0, p_batch=1.0, same_on_batch=False, resample=bilinear, align_corners=True), v = None, buffers = None
args = (<tf.Tensor: shape=(4, 4), dtype=float32, numpy=
array([[1., 0., 0., 2.],
       [0., 0., 0., 0.],
       [0., 1., 2., 0.],
       [0., 0., 1., 2.]], dtype=float32)>,), kwargs = {}
first_arr = <tf.Tensor: shape=(4, 4), dtype=float32, numpy=
array([[1., 0., 0., 2.],
       [0., 0., 0., 0.],
       [0., 1., 2., 0.],
       [0., 0., 1., 2.]], dtype=float32)>, replace_v = False
replace_buffers = False, call_signature = <Signature (input, params=None, **kwargs)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Layer, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Layer, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Layer, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomRotation(degrees=45.0, p=1.0, p_batch=1.0, same_on_batch=False, resample=bilinear, align_corners=True),)
kwargs = {'input': <tf.Tensor: shape=(4, 4), dtype=float32, numpy=
array([[1., 0., 0., 2.],
       [0., 0., 0., 0.],
       [0., 1., 2., 0.],
       [0., 0., 1., 2.]], dtype=float32)>}

    @wraps(fn)
    def error_handler(*args, **kwargs):
        if not is_traceback_filtering_enabled():
            return fn(*args, **kwargs)
    
        filtered_tb = None
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            filtered_tb = _process_traceback_frames(e.__traceback__)
            # To get the full stack trace, call:
            # `keras.config.disable_traceback_filtering()`
>           raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/keras/src/utils/traceback_utils.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomRotation(degrees=45.0, p=1.0, p_batch=1.0, same_on_batch=False, resample=bilinear, align_corners=True)
input = <tf.Tensor: shape=(4, 4), dtype=float32, numpy=
array([[1., 0., 0., 2.],
       [0., 0., 0., 0.],
       [0., 1., 2., 0.],
       [0., 0., 1., 2.]], dtype=float32)>
params = {'batch_prob': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>, 'degrees': <tf.Tensor: shape=...y([23.692474], dtype=float32)>, 'forward_input_shape': <tf.Tensor: shape=(4,), dtype=int64, numpy=array([1, 1, 4, 4])>}
kwargs = {}, tensorflow_shape_frnt_ = <function tensorflow_shape_frnt_ at 0x7ff74bb3e4d0>, tensorflow_set_item = <function tensorflow_set_item at 0x7ff7447cb880>
tensor = <function tensorflow_tensor_frnt at 0x7ff72c428c10>
in_tensor = <tf.Tensor: shape=(1, 1, 4, 4), dtype=float32, numpy=
array([[[[1., 0., 0., 2.],
         [0., 0., 0., 0.],
         [0., 1., 2., 0.],
         [0., 0., 1., 2.]]]], dtype=float32)>
input_shape = ivy.frontends.torch.Size([4, 4]), batch_shape = ivy.frontends.torch.Size([1, 1, 4, 4]), flags = {'align_corners': True, 'resample': <tensorflow_Resample.BILINEAR: 1>}

    def call(self, input, params=None, **kwargs):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ...ivy.functional.backends.tensorflow.general import tensorflow_set_item
        from ..core._backend import tensor
    
        in_tensor = self.__unpack_input__(input)
        input_shape = tensorflow_shape_frnt_(in_tensor)
        in_tensor = self.transform_tensor(in_tensor)
        batch_shape = tensorflow_shape_frnt_(in_tensor)
        if params is None:
            params = self.forward_parameters(batch_shape)
        if "batch_prob" not in params:
            params = tensorflow_set_item(
                params, "batch_prob", tensor([True] * batch_shape[0])
            )
        params, flags = self._process_kwargs_to_params_and_flags(
            params, self.flags, **kwargs
        )
>       output = self.apply_func(in_tensor, params, flags)

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/base.py:236: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomRotation(degrees=45.0, p=1.0, p_batch=1.0, same_on_batch=False, resample=bilinear, align_corners=True)
in_tensor = <tf.Tensor: shape=(1, 1, 4, 4), dtype=float32, numpy=
array([[[[1., 0., 0., 2.],
         [0., 0., 0., 0.],
         [0., 1., 2., 0.],
         [0., 0., 1., 2.]]]], dtype=float32)>
params = {'batch_prob': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>, 'degrees': <tf.Tensor: shape=...y([23.692474], dtype=float32)>, 'forward_input_shape': <tf.Tensor: shape=(4,), dtype=int64, numpy=array([1, 1, 4, 4])>}
flags = {'align_corners': True, 'resample': <tensorflow_Resample.BILINEAR: 1>}

    def apply_func(self, in_tensor, params, flags=None):
        if flags is None:
            flags = self.flags
>       trans_matrix = self.generate_transformation_matrix(in_tensor, params, flags)

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/_2d/base.py:126: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomRotation(degrees=45.0, p=1.0, p_batch=1.0, same_on_batch=False, resample=bilinear, align_corners=True)
input = <tf.Tensor: shape=(1, 1, 4, 4), dtype=float32, numpy=
array([[[[1., 0., 0., 2.],
         [0., 0., 0., 0.],
         [0., 1., 2., 0.],
         [0., 0., 1., 2.]]]], dtype=float32)>
params = {'batch_prob': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>, 'degrees': <tf.Tensor: shape=...y([23.692474], dtype=float32)>, 'forward_input_shape': <tf.Tensor: shape=(4,), dtype=int64, numpy=array([1, 1, 4, 4])>}
flags = {'align_corners': True, 'resample': <tensorflow_Resample.BILINEAR: 1>}

    def generate_transformation_matrix(self, input, params, flags):
        from ....ivy.functional.frontends.torch.tensor import tensorflow_any_frnt_
        from ....ivy.functional.frontends.torch.tensor import tensorflow_all_frnt_
        from ....ivy.functional.backends.tensorflow.general import tensorflow_get_item
        from ...utils.helpers import tensorflow_is_autocast_enabled
        from ....ivy.functional.frontends.torch.tensor import tensorflow_type_frnt_
        from ....ivy.functional.frontends.torch.tensor import tensorflow_index_put_frnt_
    
        batch_prob = params["batch_prob"]
        to_apply = batch_prob > 0.5
        in_tensor = self.transform_tensor(input)
        if not tensorflow_any_frnt_(to_apply):
            trans_matrix = self.identity_matrix(in_tensor)
        elif tensorflow_all_frnt_(to_apply):
>           trans_matrix = self.compute_transformation(
                in_tensor, params=params, flags=flags
            )

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/_2d/base.py:92: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomRotation(degrees=45.0, p=1.0, p_batch=1.0, same_on_batch=False, resample=bilinear, align_corners=True)
input = <tf.Tensor: shape=(1, 1, 4, 4), dtype=float32, numpy=
array([[[[1., 0., 0., 2.],
         [0., 0., 0., 0.],
         [0., 1., 2., 0.],
         [0., 0., 1., 2.]]]], dtype=float32)>
params = {'batch_prob': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>, 'degrees': <tf.Tensor: shape=...y([23.692474], dtype=float32)>, 'forward_input_shape': <tf.Tensor: shape=(4,), dtype=int64, numpy=array([1, 1, 4, 4])>}
flags = {'align_corners': True, 'resample': <tensorflow_Resample.BILINEAR: 1>}

    def compute_transformation(self, input, params, flags):
        from .....ivy.functional.frontends.torch.tensor import tensorflow_to_frnt_
        from ....geometry.transform.affwarp import tensorflow__compute_tensor_center
        from ....geometry.transform.affwarp import tensorflow__compute_rotation_matrix
        from .....ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ....utils.misc import tensorflow_eye_like
        from .....ivy.functional.backends.tensorflow.general import tensorflow_set_item
    
        angles: typing.Any = tensorflow_to_frnt_(params["degrees"], input)
        center: typing.Any = tensorflow__compute_tensor_center(input)
        rotation_mat: typing.Any = tensorflow__compute_rotation_matrix(
>           angles, center.expand(tensorflow_shape_frnt_(angles)[0], -1)
        )
E       AttributeError: Exception encountered when calling tensorflow_RandomRotation.call().
E       
E       [1m'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'expand'[0m
E       
E       Arguments received by tensorflow_RandomRotation.call():
E         • input=tf.Tensor(shape=(4, 4), dtype=float32)
E         • params=None
E         • kwargs=<class 'inspect._empty'>

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/_2d/geometric/rotation.py:70: AttributeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.RandomRotation
______________________________________________________________________________ test_RandomCutMixV2[tensorflow-s2s-False] _______________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_RandomCutMixV2(target_framework, mode, backend_compile):
        print("kornia.augmentation.RandomCutMixV2")
    
        input = torch.rand(2, 1, 3, 3)
        input[0] = torch.ones((1, 3, 3))
        label = torch.tensor([0, 1])
    
        init_args = ()
        init_kwargs = {"data_keys": ["input", "class"]}
        call_args = (input, label)
        call_kwargs = {}
    
>       _test_augmentation_class(
            kornia.augmentation.RandomCutMixV2,
            target_framework,
            init_args,
            init_kwargs,
            call_args,
            call_kwargs,
            deterministic_output=False,
            backend_compile=backend_compile,
        )

kornia/augmentation/test_augmentation3.py:355: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

augmentation_cls = <class 'kornia.augmentation._2d.mix.cutmix.RandomCutMixV2'>, target = 'tensorflow', init_args = (), init_kwargs = {'data_keys': ['input', 'class']}
call_args = (tensor([[[[1.0000, 1.0000, 1.0000],
          [1.0000, 1.0000, 1.0000],
          [1.0000, 1.0000, 1.0000]]],


        [[[0.8316, 0.5492, 0.7932],
          [0.4576, 0.1436, 0.3986],
          [0.0323, 0.4177, 0.0227]]]]), tensor([0, 1]))
call_kwargs = {}, deterministic_output = False, backend_compile = False, tolerance = 0.001

    def _test_augmentation_class(
        augmentation_cls,
        target,
        init_args=(),
        init_kwargs={},
        call_args=(),
        call_kwargs={},
        deterministic_output=True,
        backend_compile=False,
        tolerance=1e-3,
    ):
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, target=target)
        transpiled_cls = eval("transpiled_" + f"{augmentation_cls.__module__}.{augmentation_cls.__name__}")
    
        torch_aug = augmentation_cls(*init_args, **init_kwargs)
        transpiled_init_args = _nest_torch_tensor_to_new_framework(init_args, target)
        transpiled_init_kwargs = _nest_torch_tensor_to_new_framework(init_kwargs, target)
>       transpiled_aug = transpiled_cls(*transpiled_init_args, **transpiled_init_kwargs)

kornia/augmentation/test_augmentation3.py:37: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:221: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:322: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:310: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:300: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXL.pyx:23: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

MC.pyx:145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

MC.pyx:127: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7ff745185480>, node = <gast.gast.Module object at 0x7ff72cfa3b50>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7ff745185480>, node = <gast.gast.Module object at 0x7ff72cfa3b50>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
>                       value = self.visit(value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:486: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7ff745185480>, node = <gast.gast.ClassDef object at 0x7ff72cfa03d0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:225: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7ff745185480>, node = <gast.gast.FunctionDef object at 0x7ff744e386a0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:273: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7ff745185480>, node = <gast.gast.AnnAssign object at 0x7ff73c641210>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7ff745185480>, node = <gast.gast.Call object at 0x7ff73c641bd0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7ff745185480>, node = <gast.gast.Call object at 0x7ff73c641bd0>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
                        value = self.visit(value)
                        if value is None:
                            continue
                        elif not isinstance(value, AST):
                            new_values.extend(value)
                            continue
                    new_values.append(value)
                old_value[:] = new_values
            elif isinstance(old_value, AST):
>               new_node = self.visit(old_value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:495: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7ff745185480>, node = <gast.gast.Attribute object at 0x7ff73c6429b0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:329: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:141: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:111: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:95: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

MC.pyx:127: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7ff74478c8b0>, node = <gast.gast.Module object at 0x7ff745e24eb0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7ff74478c8b0>, node = <gast.gast.Module object at 0x7ff745e24eb0>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
>                       value = self.visit(value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:486: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7ff74478c8b0>, node = <gast.gast.ClassDef object at 0x7ff745e27fd0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:225: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7ff74478c8b0>, node = <gast.gast.FunctionDef object at 0x7ff73fe90340>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:273: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7ff74478c8b0>, node = <gast.gast.Assign object at 0x7ff73fca4c70>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7ff74478c8b0>, node = <gast.gast.Assign object at 0x7ff73fca4c70>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
                        value = self.visit(value)
                        if value is None:
                            continue
                        elif not isinstance(value, AST):
                            new_values.extend(value)
                            continue
                    new_values.append(value)
                old_value[:] = new_values
            elif isinstance(old_value, AST):
>               new_node = self.visit(old_value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:495: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7ff74478c8b0>, node = <gast.gast.Call object at 0x7ff73fca4e80>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7ff74478c8b0>, node = <gast.gast.Call object at 0x7ff73fca4e80>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
                        value = self.visit(value)
                        if value is None:
                            continue
                        elif not isinstance(value, AST):
                            new_values.extend(value)
                            continue
                    new_values.append(value)
                old_value[:] = new_values
            elif isinstance(old_value, AST):
>               new_node = self.visit(old_value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:495: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7ff74478c8b0>, node = <gast.gast.Attribute object at 0x7ff745a72260>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:329: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:141: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:111: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:95: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

MC.pyx:127: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7ff74bf8a9e0>, node = <gast.gast.Module object at 0x7ff72c98b820>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7ff74bf8a9e0>, node = <gast.gast.Module object at 0x7ff72c98b820>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
>                       value = self.visit(value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:486: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7ff74bf8a9e0>, node = <gast.gast.ClassDef object at 0x7ff72c988a30>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:225: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7ff74bf8a9e0>, node = <gast.gast.FunctionDef object at 0x7ff745f827a0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:273: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7ff74bf8a9e0>, node = <gast.gast.Assign object at 0x7ff72c98a770>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7ff74bf8a9e0>, node = <gast.gast.Assign object at 0x7ff72c98a770>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
                        value = self.visit(value)
                        if value is None:
                            continue
                        elif not isinstance(value, AST):
                            new_values.extend(value)
                            continue
                    new_values.append(value)
                old_value[:] = new_values
            elif isinstance(old_value, AST):
>               new_node = self.visit(old_value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:495: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7ff74bf8a9e0>, node = <gast.gast.Call object at 0x7ff72c98a2f0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7ff74bf8a9e0>, node = <gast.gast.Call object at 0x7ff72c98a2f0>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
                        value = self.visit(value)
                        if value is None:
                            continue
                        elif not isinstance(value, AST):
                            new_values.extend(value)
                            continue
                    new_values.append(value)
                old_value[:] = new_values
            elif isinstance(old_value, AST):
>               new_node = self.visit(old_value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:495: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7ff74bf8a9e0>, node = <gast.gast.Attribute object at 0x7ff73fd05180>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:329: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:141: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:111: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:95: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

MC.pyx:127: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7ff7442d29e0>, node = <gast.gast.Module object at 0x7ff73c173fd0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7ff7442d29e0>, node = <gast.gast.Module object at 0x7ff73c173fd0>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
>                       value = self.visit(value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:486: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7ff7442d29e0>, node = <gast.gast.ClassDef object at 0x7ff73c1715a0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:225: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7ff7442d29e0>, node = <gast.gast.FunctionDef object at 0x7ff73c1726b0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:273: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7ff7442d29e0>, node = <gast.gast.Return object at 0x7ff74bb024d0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7ff7442d29e0>, node = <gast.gast.Return object at 0x7ff74bb024d0>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
                        value = self.visit(value)
                        if value is None:
                            continue
                        elif not isinstance(value, AST):
                            new_values.extend(value)
                            continue
                    new_values.append(value)
                old_value[:] = new_values
            elif isinstance(old_value, AST):
>               new_node = self.visit(old_value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:495: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7ff7442d29e0>, node = <gast.gast.Call object at 0x7ff74bb02950>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7ff7442d29e0>, node = <gast.gast.Call object at 0x7ff74bb02950>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
                        value = self.visit(value)
                        if value is None:
                            continue
                        elif not isinstance(value, AST):
                            new_values.extend(value)
                            continue
                    new_values.append(value)
                old_value[:] = new_values
            elif isinstance(old_value, AST):
>               new_node = self.visit(old_value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:495: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7ff7442d29e0>, node = <gast.gast.Attribute object at 0x7ff74bb010c0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:328: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7ff7442d29e0>, node = <gast.gast.Attribute object at 0x7ff74bb010c0>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
                        value = self.visit(value)
                        if value is None:
                            continue
                        elif not isinstance(value, AST):
                            new_values.extend(value)
                            continue
                    new_values.append(value)
                old_value[:] = new_values
            elif isinstance(old_value, AST):
>               new_node = self.visit(old_value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:495: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7ff7442d29e0>, node = <gast.gast.Name object at 0x7ff74bb02c20>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:324: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:141: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:111: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:95: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

MC.pyx:127: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7ff72c332050>, node = <gast.gast.Module object at 0x7ff73fe93640>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7ff72c332050>, node = <gast.gast.Module object at 0x7ff73fe93640>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
>                       value = self.visit(value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:486: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7ff72c332050>, node = <gast.gast.ClassDef object at 0x7ff73fe90fa0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

MC.pyx:127: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7ff72c8a3820>, node = <gast.gast.Module object at 0x7ff72c4c7880>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7ff72c8a3820>, node = <gast.gast.Module object at 0x7ff72c4c7880>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
>                       value = self.visit(value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:486: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7ff72c8a3820>, node = <gast.gast.ClassDef object at 0x7ff72c4c4460>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

MC.pyx:127: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7ff745e246d0>, node = <gast.gast.Module object at 0x7ff744429390>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7ff745e246d0>, node = <gast.gast.Module object at 0x7ff744429390>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
>                       value = self.visit(value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:486: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7ff745e246d0>, node = <gast.gast.ClassDef object at 0x7ff744429420>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:190: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IL.pyx:244: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IL.pyx:258: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IL.pyx:33: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IL.pyx:110: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IM.pyx:41: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

object = <class 'torch._C._FunctionBase'>

    def getsourcelines(object):
        """Return a list of source lines and starting line number for an object.
    
        The argument may be a module, class, method, function, traceback, frame,
        or code object.  The source code is returned as a list of the lines
        corresponding to the object and the line number indicates where in the
        original source file the first line of code was found.  An OSError is
        raised if the source code cannot be retrieved."""
        object = unwrap(object)
>       lines, lnum = findsource(object)

/opt/miniconda/envs/multienv/lib/python3.10/inspect.py:1129: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

object = <class 'torch._C._FunctionBase'>

    def findsource(object):
        """Return the entire source file and starting line number for an object.
    
        The argument may be a module, class, method, function, traceback, frame,
        or code object.  The source code is returned as a list of all the lines
        in the file and the line number indexes a line in that list.  An OSError
        is raised if the source code cannot be retrieved."""
    
        file = getsourcefile(object)
        if file:
            # Invalidate cache if needed.
            linecache.checkcache(file)
        else:
            file = getfile(object)
            # Allow filenames in form of "<something>" to pass through.
            # `doctest` monkeypatches `linecache` module to enable
            # inspection, so let `linecache.getlines` to be called.
            if not (file.startswith('<') and file.endswith('>')):
>               raise OSError('source code not available')
E               OSError: source code not available

/opt/miniconda/envs/multienv/lib/python3.10/inspect.py:950: OSError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.RandomCutMixV2
_______________________________________________________________________________ test_RandomJigsaw[tensorflow-s2s-False] ________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_RandomJigsaw(target_framework, mode, backend_compile):
        print("kornia.augmentation.RandomJigsaw")
    
        init_args = ((4, 4),)
        init_kwargs = {}
        call_args = (torch.randn(8, 3, 256, 256),)
        call_kwargs = {}
    
>       _test_augmentation_class(
            kornia.augmentation.RandomJigsaw,
            target_framework,
            init_args,
            init_kwargs,
            call_args,
            call_kwargs,
            deterministic_output=False,
            backend_compile=backend_compile,
        )

kornia/augmentation/test_augmentation3.py:375: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

augmentation_cls = <class 'kornia.augmentation._2d.mix.jigsaw.RandomJigsaw'>, target = 'tensorflow', init_args = ((4, 4),), init_kwargs = {}
call_args = (tensor([[[[ 4.8302e-01, -1.6817e-03, -4.2463e-01,  ..., -5.0238e-01,
            1.2931e-02,  9.1752e-01],
          ...7e-01],
          [-2.2866e+00,  2.1973e-01,  6.0011e-01,  ..., -1.3140e+00,
            8.9859e-01,  1.1554e+00]]]]),)
call_kwargs = {}, deterministic_output = False, backend_compile = False, tolerance = 0.001

    def _test_augmentation_class(
        augmentation_cls,
        target,
        init_args=(),
        init_kwargs={},
        call_args=(),
        call_kwargs={},
        deterministic_output=True,
        backend_compile=False,
        tolerance=1e-3,
    ):
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, target=target)
        transpiled_cls = eval("transpiled_" + f"{augmentation_cls.__module__}.{augmentation_cls.__name__}")
    
        torch_aug = augmentation_cls(*init_args, **init_kwargs)
        transpiled_init_args = _nest_torch_tensor_to_new_framework(init_args, target)
        transpiled_init_kwargs = _nest_torch_tensor_to_new_framework(init_kwargs, target)
        transpiled_aug = transpiled_cls(*transpiled_init_args, **transpiled_init_kwargs)
    
        # assert dir(torch_aug) == dir(transpiled_aug), f"attributes/methods of transpiled object do not align with the original - orig: {dir(torch_aug)} != transpiled: {dir(transpiled_aug)}"
    
        torch_out = torch_aug(*call_args, **call_kwargs)
        transpiled_call_args = _nest_torch_tensor_to_new_framework(call_args, target)
        transpiled_call_kwargs = _nest_torch_tensor_to_new_framework(call_kwargs, target)
>       transpiled_out = transpiled_aug(*transpiled_call_args, **transpiled_call_kwargs)

kornia/augmentation/test_augmentation3.py:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomJigsaw(grid=(4, 4), p=0.5, p_batch=1.0, same_on_batch=False, grid=(4, 4))
args = (<tf.Tensor: shape=(8, 3, 256, 256), dtype=float32, numpy=
array([[[[ 4.83022928e-01, -1.68174913e-03, -4.24632579e-01...505e-01,  6.00106418e-01, ...,
          -1.31399536e+00,  8.98593605e-01,  1.15544820e+00]]]],
      dtype=float32)>,)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x7ff7443f7c40, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...kexec', code_context=['        return self._inner_hookexec(hook_name, methods, kwargs, firstresult)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomJigsaw(grid=(4, 4), p=0.5, p_batch=1.0, same_on_batch=False, grid=(4, 4)), <tf.Tensor: shape=(8, 3, ...4505e-01,  6.00106418e-01, ...,
          -1.31399536e+00,  8.98593605e-01,  1.15544820e+00]]]],
      dtype=float32)>)
kwargs = {}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomJigsaw(grid=(4, 4), p=0.5, p_batch=1.0, same_on_batch=False, grid=(4, 4)), v = None, buffers = None
args = (<tf.Tensor: shape=(8, 3, 256, 256), dtype=float32, numpy=
array([[[[ 4.83022928e-01, -1.68174913e-03, -4.24632579e-01...505e-01,  6.00106418e-01, ...,
          -1.31399536e+00,  8.98593605e-01,  1.15544820e+00]]]],
      dtype=float32)>,)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomJigsaw(grid=(4, 4), p=0.5, p_batch=1.0, same_on_batch=False, grid=(4, 4)), <tf.Tensor: shape=(8, 3, ...4505e-01,  6.00106418e-01, ...,
          -1.31399536e+00,  8.98593605e-01,  1.15544820e+00]]]],
      dtype=float32)>)
kwargs = {'buffers': None, 'v': None}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomJigsaw(grid=(4, 4), p=0.5, p_batch=1.0, same_on_batch=False, grid=(4, 4)), v = None, buffers = None
args = (<tf.Tensor: shape=(8, 3, 256, 256), dtype=float32, numpy=
array([[[[ 4.83022928e-01, -1.68174913e-03, -4.24632579e-01...505e-01,  6.00106418e-01, ...,
          -1.31399536e+00,  8.98593605e-01,  1.15544820e+00]]]],
      dtype=float32)>,)
kwargs = {}
first_arr = <tf.Tensor: shape=(8, 3, 256, 256), dtype=float32, numpy=
array([[[[ 4.83022928e-01, -1.68174913e-03, -4.24632579e-01,...34505e-01,  6.00106418e-01, ...,
          -1.31399536e+00,  8.98593605e-01,  1.15544820e+00]]]],
      dtype=float32)>
replace_v = False, replace_buffers = False, call_signature = <Signature (*input, params=None, data_keys=None)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Layer, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Layer, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Layer, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomJigsaw(grid=(4, 4), p=0.5, p_batch=1.0, same_on_batch=False, grid=(4, 4)),)
kwargs = {'input': <tf.Tensor: shape=(8, 3, 256, 256), dtype=float32, numpy=
array([[[[ 4.83022928e-01, -1.68174913e-03, -4.246...4505e-01,  6.00106418e-01, ...,
          -1.31399536e+00,  8.98593605e-01,  1.15544820e+00]]]],
      dtype=float32)>}

    @wraps(fn)
    def error_handler(*args, **kwargs):
        if not is_traceback_filtering_enabled():
            return fn(*args, **kwargs)
    
        filtered_tb = None
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            filtered_tb = _process_traceback_frames(e.__traceback__)
            # To get the full stack trace, call:
            # `keras.config.disable_traceback_filtering()`
>           raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/keras/src/utils/traceback_utils.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <Signature (*input, params=None, data_keys=None)>, args = ()
kwargs = {'input': <tf.Tensor: shape=(8, 3, 256, 256), dtype=float32, numpy=
array([[[[ 4.83022928e-01, -1.68174913e-03, -4.246...4505e-01,  6.00106418e-01, ...,
          -1.31399536e+00,  8.98593605e-01,  1.15544820e+00]]]],
      dtype=float32)>}

    def bind(self, /, *args, **kwargs):
        """Get a BoundArguments object, that maps the passed `args`
        and `kwargs` to the function's signature.  Raises `TypeError`
        if the passed arguments can not be bound.
        """
>       return self._bind(args, kwargs)

/opt/miniconda/envs/multienv/lib/python3.10/inspect.py:3177: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <Signature (*input, params=None, data_keys=None)>, args = ()
kwargs = {'input': <tf.Tensor: shape=(8, 3, 256, 256), dtype=float32, numpy=
array([[[[ 4.83022928e-01, -1.68174913e-03, -4.246...4505e-01,  6.00106418e-01, ...,
          -1.31399536e+00,  8.98593605e-01,  1.15544820e+00]]]],
      dtype=float32)>}

    def _bind(self, args, kwargs, *, partial=False):
        """Private method. Don't use directly."""
    
        arguments = {}
    
        parameters = iter(self.parameters.values())
        parameters_ex = ()
        arg_vals = iter(args)
    
        while True:
            # Let's iterate through the positional arguments and corresponding
            # parameters
            try:
                arg_val = next(arg_vals)
            except StopIteration:
                # No more positional arguments
                try:
                    param = next(parameters)
                except StopIteration:
                    # No more parameters. That's it. Just need to check that
                    # we have no `kwargs` after this while loop
                    break
                else:
                    if param.kind == _VAR_POSITIONAL:
                        # That's OK, just empty *args.  Let's start parsing
                        # kwargs
                        break
                    elif param.name in kwargs:
                        if param.kind == _POSITIONAL_ONLY:
                            msg = '{arg!r} parameter is positional only, ' \
                                  'but was passed as a keyword'
                            msg = msg.format(arg=param.name)
                            raise TypeError(msg) from None
                        parameters_ex = (param,)
                        break
                    elif (param.kind == _VAR_KEYWORD or
                                                param.default is not _empty):
                        # That's fine too - we have a default value for this
                        # parameter.  So, lets start parsing `kwargs`, starting
                        # with the current parameter
                        parameters_ex = (param,)
                        break
                    else:
                        # No default, not VAR_KEYWORD, not VAR_POSITIONAL,
                        # not in `kwargs`
                        if partial:
                            parameters_ex = (param,)
                            break
                        else:
                            msg = 'missing a required argument: {arg!r}'
                            msg = msg.format(arg=param.name)
                            raise TypeError(msg) from None
            else:
                # We have a positional argument to process
                try:
                    param = next(parameters)
                except StopIteration:
                    raise TypeError('too many positional arguments') from None
                else:
                    if param.kind in (_VAR_KEYWORD, _KEYWORD_ONLY):
                        # Looks like we have no parameter for this positional
                        # argument
                        raise TypeError(
                            'too many positional arguments') from None
    
                    if param.kind == _VAR_POSITIONAL:
                        # We have an '*args'-like argument, let's fill it with
                        # all positional arguments we have left and move on to
                        # the next phase
                        values = [arg_val]
                        values.extend(arg_vals)
                        arguments[param.name] = tuple(values)
                        break
    
                    if param.name in kwargs and param.kind != _POSITIONAL_ONLY:
                        raise TypeError(
                            'multiple values for argument {arg!r}'.format(
                                arg=param.name)) from None
    
                    arguments[param.name] = arg_val
    
        # Now, we iterate through the remaining parameters to process
        # keyword arguments
        kwargs_param = None
        for param in itertools.chain(parameters_ex, parameters):
            if param.kind == _VAR_KEYWORD:
                # Memorize that we have a '**kwargs'-like parameter
                kwargs_param = param
                continue
    
            if param.kind == _VAR_POSITIONAL:
                # Named arguments don't refer to '*args'-like parameters.
                # We only arrive here if the positional arguments ended
                # before reaching the last parameter before *args.
                continue
    
            param_name = param.name
            try:
                arg_val = kwargs.pop(param_name)
            except KeyError:
                # We have no value for this parameter.  It's fine though,
                # if it has a default value, or it is an '*args'-like
                # parameter, left alone by the processing of positional
                # arguments.
                if (not partial and param.kind != _VAR_POSITIONAL and
                                                    param.default is _empty):
                    raise TypeError('missing a required argument: {arg!r}'. \
                                    format(arg=param_name)) from None
    
            else:
                if param.kind == _POSITIONAL_ONLY:
                    # This should never happen in case of a properly built
                    # Signature object (but let's have this check here
                    # to ensure correct behaviour just in case)
                    raise TypeError('{arg!r} parameter is positional only, '
                                    'but was passed as a keyword'. \
                                    format(arg=param.name))
    
                arguments[param_name] = arg_val
    
        if kwargs:
            if kwargs_param is not None:
                # Process our '**kwargs'-like parameter
                arguments[kwargs_param.name] = kwargs
            else:
>               raise TypeError(
                    'got an unexpected keyword argument {arg!r}'.format(
                        arg=next(iter(kwargs))))
E               TypeError: got an unexpected keyword argument 'input'

/opt/miniconda/envs/multienv/lib/python3.10/inspect.py:3166: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.RandomJigsaw
_______________________________________________________________________________ test_RandomMixUpV2[tensorflow-s2s-False] _______________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_RandomMixUpV2(target_framework, mode, backend_compile):
        print("kornia.augmentation.RandomMixUpV2")
    
        init_args = ()
        init_kwargs = {"data_keys": ["input", "class"]}
        call_args = (torch.rand(2, 1, 3, 3), torch.tensor([0, 1]))
        call_kwargs = {}
    
>       _test_augmentation_class(
            kornia.augmentation.RandomMixUpV2,
            target_framework,
            init_args,
            init_kwargs,
            call_args,
            call_kwargs,
            deterministic_output=False,
            backend_compile=backend_compile,
        )

kornia/augmentation/test_augmentation3.py:395: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

augmentation_cls = <class 'kornia.augmentation._2d.mix.mixup.RandomMixUpV2'>, target = 'tensorflow', init_args = (), init_kwargs = {'data_keys': ['input', 'class']}
call_args = (tensor([[[[0.5350, 0.5591, 0.7091],
          [0.5914, 0.2545, 0.9597],
          [0.9611, 0.0881, 0.7911]]],


        [[[0.4412, 0.6622, 0.8247],
          [0.2156, 0.5088, 0.0338],
          [0.9443, 0.9188, 0.7093]]]]), tensor([0, 1]))
call_kwargs = {}, deterministic_output = False, backend_compile = False, tolerance = 0.001

    def _test_augmentation_class(
        augmentation_cls,
        target,
        init_args=(),
        init_kwargs={},
        call_args=(),
        call_kwargs={},
        deterministic_output=True,
        backend_compile=False,
        tolerance=1e-3,
    ):
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, target=target)
        transpiled_cls = eval("transpiled_" + f"{augmentation_cls.__module__}.{augmentation_cls.__name__}")
    
        torch_aug = augmentation_cls(*init_args, **init_kwargs)
        transpiled_init_args = _nest_torch_tensor_to_new_framework(init_args, target)
        transpiled_init_kwargs = _nest_torch_tensor_to_new_framework(init_kwargs, target)
        transpiled_aug = transpiled_cls(*transpiled_init_args, **transpiled_init_kwargs)
    
        # assert dir(torch_aug) == dir(transpiled_aug), f"attributes/methods of transpiled object do not align with the original - orig: {dir(torch_aug)} != transpiled: {dir(transpiled_aug)}"
    
        torch_out = torch_aug(*call_args, **call_kwargs)
        transpiled_call_args = _nest_torch_tensor_to_new_framework(call_args, target)
        transpiled_call_kwargs = _nest_torch_tensor_to_new_framework(call_kwargs, target)
>       transpiled_out = transpiled_aug(*transpiled_call_args, **transpiled_call_kwargs)

kornia/augmentation/test_augmentation3.py:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomMixUpV2(lambda_val=None, p=1.0, p_batch=1.0, same_on_batch=False)
args = (<tf.Tensor: shape=(2, 1, 3, 3), dtype=float32, numpy=
array([[[[0.5350433 , 0.55914646, 0.709067  ],
         [0.5913...   [0.9443374 , 0.91881007, 0.70926404]]]], dtype=float32)>, <tf.Tensor: shape=(2,), dtype=int64, numpy=array([0, 1])>)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x55d5bc084fe0, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...kexec', code_context=['        return self._inner_hookexec(hook_name, methods, kwargs, firstresult)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomMixUpV2(lambda_val=None, p=1.0, p_batch=1.0, same_on_batch=False), <tf.Tensor: shape=(2, 1, 3, 3), d...   [0.9443374 , 0.91881007, 0.70926404]]]], dtype=float32)>, <tf.Tensor: shape=(2,), dtype=int64, numpy=array([0, 1])>)
kwargs = {}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomMixUpV2(lambda_val=None, p=1.0, p_batch=1.0, same_on_batch=False), v = None, buffers = None
args = (<tf.Tensor: shape=(2, 1, 3, 3), dtype=float32, numpy=
array([[[[0.5350433 , 0.55914646, 0.709067  ],
         [0.5913...   [0.9443374 , 0.91881007, 0.70926404]]]], dtype=float32)>, <tf.Tensor: shape=(2,), dtype=int64, numpy=array([0, 1])>)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomMixUpV2(lambda_val=None, p=1.0, p_batch=1.0, same_on_batch=False), <tf.Tensor: shape=(2, 1, 3, 3), d...   [0.9443374 , 0.91881007, 0.70926404]]]], dtype=float32)>, <tf.Tensor: shape=(2,), dtype=int64, numpy=array([0, 1])>)
kwargs = {'buffers': None, 'v': None}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomMixUpV2(lambda_val=None, p=1.0, p_batch=1.0, same_on_batch=False), v = None, buffers = None
args = (<tf.Tensor: shape=(2, 1, 3, 3), dtype=float32, numpy=
array([[[[0.5350433 , 0.55914646, 0.709067  ],
         [0.5913...   [0.9443374 , 0.91881007, 0.70926404]]]], dtype=float32)>, <tf.Tensor: shape=(2,), dtype=int64, numpy=array([0, 1])>)
kwargs = {}
first_arr = <tf.Tensor: shape=(2, 1, 3, 3), dtype=float32, numpy=
array([[[[0.5350433 , 0.55914646, 0.709067  ],
         [0.59139...931 ],
         [0.21560782, 0.50875765, 0.03378028],
         [0.9443374 , 0.91881007, 0.70926404]]]], dtype=float32)>
replace_v = False, replace_buffers = False, call_signature = <Signature (*input, params=None, data_keys=None)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Layer, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Layer, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Layer, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomMixUpV2(lambda_val=None, p=1.0, p_batch=1.0, same_on_batch=False),)
kwargs = {'input': <tf.Tensor: shape=(2, 1, 3, 3), dtype=float32, numpy=
array([[[[0.5350433 , 0.55914646, 0.709067  ],
       ...374 , 0.91881007, 0.70926404]]]], dtype=float32)>, 'params': <tf.Tensor: shape=(2,), dtype=int64, numpy=array([0, 1])>}

    @wraps(fn)
    def error_handler(*args, **kwargs):
        if not is_traceback_filtering_enabled():
            return fn(*args, **kwargs)
    
        filtered_tb = None
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            filtered_tb = _process_traceback_frames(e.__traceback__)
            # To get the full stack trace, call:
            # `keras.config.disable_traceback_filtering()`
>           raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/keras/src/utils/traceback_utils.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <Signature (*input, params=None, data_keys=None)>, args = ()
kwargs = {'input': <tf.Tensor: shape=(2, 1, 3, 3), dtype=float32, numpy=
array([[[[0.5350433 , 0.55914646, 0.709067  ],
       ...31 ],
         [0.21560782, 0.50875765, 0.03378028],
         [0.9443374 , 0.91881007, 0.70926404]]]], dtype=float32)>}

    def bind(self, /, *args, **kwargs):
        """Get a BoundArguments object, that maps the passed `args`
        and `kwargs` to the function's signature.  Raises `TypeError`
        if the passed arguments can not be bound.
        """
>       return self._bind(args, kwargs)

/opt/miniconda/envs/multienv/lib/python3.10/inspect.py:3177: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <Signature (*input, params=None, data_keys=None)>, args = ()
kwargs = {'input': <tf.Tensor: shape=(2, 1, 3, 3), dtype=float32, numpy=
array([[[[0.5350433 , 0.55914646, 0.709067  ],
       ...31 ],
         [0.21560782, 0.50875765, 0.03378028],
         [0.9443374 , 0.91881007, 0.70926404]]]], dtype=float32)>}

    def _bind(self, args, kwargs, *, partial=False):
        """Private method. Don't use directly."""
    
        arguments = {}
    
        parameters = iter(self.parameters.values())
        parameters_ex = ()
        arg_vals = iter(args)
    
        while True:
            # Let's iterate through the positional arguments and corresponding
            # parameters
            try:
                arg_val = next(arg_vals)
            except StopIteration:
                # No more positional arguments
                try:
                    param = next(parameters)
                except StopIteration:
                    # No more parameters. That's it. Just need to check that
                    # we have no `kwargs` after this while loop
                    break
                else:
                    if param.kind == _VAR_POSITIONAL:
                        # That's OK, just empty *args.  Let's start parsing
                        # kwargs
                        break
                    elif param.name in kwargs:
                        if param.kind == _POSITIONAL_ONLY:
                            msg = '{arg!r} parameter is positional only, ' \
                                  'but was passed as a keyword'
                            msg = msg.format(arg=param.name)
                            raise TypeError(msg) from None
                        parameters_ex = (param,)
                        break
                    elif (param.kind == _VAR_KEYWORD or
                                                param.default is not _empty):
                        # That's fine too - we have a default value for this
                        # parameter.  So, lets start parsing `kwargs`, starting
                        # with the current parameter
                        parameters_ex = (param,)
                        break
                    else:
                        # No default, not VAR_KEYWORD, not VAR_POSITIONAL,
                        # not in `kwargs`
                        if partial:
                            parameters_ex = (param,)
                            break
                        else:
                            msg = 'missing a required argument: {arg!r}'
                            msg = msg.format(arg=param.name)
                            raise TypeError(msg) from None
            else:
                # We have a positional argument to process
                try:
                    param = next(parameters)
                except StopIteration:
                    raise TypeError('too many positional arguments') from None
                else:
                    if param.kind in (_VAR_KEYWORD, _KEYWORD_ONLY):
                        # Looks like we have no parameter for this positional
                        # argument
                        raise TypeError(
                            'too many positional arguments') from None
    
                    if param.kind == _VAR_POSITIONAL:
                        # We have an '*args'-like argument, let's fill it with
                        # all positional arguments we have left and move on to
                        # the next phase
                        values = [arg_val]
                        values.extend(arg_vals)
                        arguments[param.name] = tuple(values)
                        break
    
                    if param.name in kwargs and param.kind != _POSITIONAL_ONLY:
                        raise TypeError(
                            'multiple values for argument {arg!r}'.format(
                                arg=param.name)) from None
    
                    arguments[param.name] = arg_val
    
        # Now, we iterate through the remaining parameters to process
        # keyword arguments
        kwargs_param = None
        for param in itertools.chain(parameters_ex, parameters):
            if param.kind == _VAR_KEYWORD:
                # Memorize that we have a '**kwargs'-like parameter
                kwargs_param = param
                continue
    
            if param.kind == _VAR_POSITIONAL:
                # Named arguments don't refer to '*args'-like parameters.
                # We only arrive here if the positional arguments ended
                # before reaching the last parameter before *args.
                continue
    
            param_name = param.name
            try:
                arg_val = kwargs.pop(param_name)
            except KeyError:
                # We have no value for this parameter.  It's fine though,
                # if it has a default value, or it is an '*args'-like
                # parameter, left alone by the processing of positional
                # arguments.
                if (not partial and param.kind != _VAR_POSITIONAL and
                                                    param.default is _empty):
                    raise TypeError('missing a required argument: {arg!r}'. \
                                    format(arg=param_name)) from None
    
            else:
                if param.kind == _POSITIONAL_ONLY:
                    # This should never happen in case of a properly built
                    # Signature object (but let's have this check here
                    # to ensure correct behaviour just in case)
                    raise TypeError('{arg!r} parameter is positional only, '
                                    'but was passed as a keyword'. \
                                    format(arg=param.name))
    
                arguments[param_name] = arg_val
    
        if kwargs:
            if kwargs_param is not None:
                # Process our '**kwargs'-like parameter
                arguments[kwargs_param.name] = kwargs
            else:
>               raise TypeError(
                    'got an unexpected keyword argument {arg!r}'.format(
                        arg=next(iter(kwargs))))
E               TypeError: got an unexpected keyword argument 'input'

/opt/miniconda/envs/multienv/lib/python3.10/inspect.py:3166: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.RandomMixUpV2
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/augmentation/test_augmentation3.py::test_RandomResizedCrop[tensorflow-s2s-False] - tensorflow.python.framework.errors_impl.InvalidArgumentError: Exception encountered when calling ten...
FAILED kornia/augmentation/test_augmentation3.py::test_RandomRotation[tensorflow-s2s-False] - AttributeError: Exception encountered when calling tensorflow_RandomRotation.call().
FAILED kornia/augmentation/test_augmentation3.py::test_RandomCutMixV2[tensorflow-s2s-False] - OSError: source code not available
FAILED kornia/augmentation/test_augmentation3.py::test_RandomJigsaw[tensorflow-s2s-False] - TypeError: got an unexpected keyword argument 'input'
FAILED kornia/augmentation/test_augmentation3.py::test_RandomMixUpV2[tensorflow-s2s-False] - TypeError: got an unexpected keyword argument 'input'
============================================================================== 5 failed, 11 passed in 3413.18s (0:56:53) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 16 items

kornia/augmentation/test_augmentation3.py .........F...FFF                                                                                                                                       [100%]

=============================================================================================== FAILURES ===============================================================================================
__________________________________________________________________________________ test_RandomRotation[jax-s2s-False] __________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_RandomRotation(target_framework, mode, backend_compile):
        print("kornia.augmentation.RandomRotation")
    
        init_args = ()
        init_kwargs = {"degrees": 45.0, "p": 1.}
        call_args = (torch.tensor([[1., 0., 0., 2.],
                                   [0., 0., 0., 0.],
                                   [0., 1., 2., 0.],
                                   [0., 0., 1., 2.]]),)
        call_kwargs = {}
    
>       _test_augmentation_class(
            kornia.augmentation.RandomRotation,
            target_framework,
            init_args,
            init_kwargs,
            call_args,
            call_kwargs,
            deterministic_output=False,
            backend_compile=backend_compile,
        )

kornia/augmentation/test_augmentation3.py:271: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

augmentation_cls = <class 'kornia.augmentation._2d.geometric.rotation.RandomRotation'>, target = 'jax', init_args = (), init_kwargs = {'degrees': 45.0, 'p': 1.0}
call_args = (tensor([[1., 0., 0., 2.],
        [0., 0., 0., 0.],
        [0., 1., 2., 0.],
        [0., 0., 1., 2.]]),), call_kwargs = {}, deterministic_output = False, backend_compile = False
tolerance = 0.001

    def _test_augmentation_class(
        augmentation_cls,
        target,
        init_args=(),
        init_kwargs={},
        call_args=(),
        call_kwargs={},
        deterministic_output=True,
        backend_compile=False,
        tolerance=1e-3,
    ):
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, target=target)
        transpiled_cls = eval("transpiled_" + f"{augmentation_cls.__module__}.{augmentation_cls.__name__}")
    
        torch_aug = augmentation_cls(*init_args, **init_kwargs)
        transpiled_init_args = _nest_torch_tensor_to_new_framework(init_args, target)
        transpiled_init_kwargs = _nest_torch_tensor_to_new_framework(init_kwargs, target)
        transpiled_aug = transpiled_cls(*transpiled_init_args, **transpiled_init_kwargs)
    
        # assert dir(torch_aug) == dir(transpiled_aug), f"attributes/methods of transpiled object do not align with the original - orig: {dir(torch_aug)} != transpiled: {dir(transpiled_aug)}"
    
        torch_out = torch_aug(*call_args, **call_kwargs)
        transpiled_call_args = _nest_torch_tensor_to_new_framework(call_args, target)
        transpiled_call_kwargs = _nest_torch_tensor_to_new_framework(call_kwargs, target)
>       transpiled_out = transpiled_aug(*transpiled_call_args, **transpiled_call_kwargs)

kornia/augmentation/test_augmentation3.py:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_RandomRotation(degrees=45.0, p=1.0, p_batch=1.0, same_on_batch=False, resample=bilinear, align_corners=True)
input = Array([[1., 0., 0., 2.],
       [0., 0., 0., 0.],
       [0., 1., 2., 0.],
       [0., 0., 1., 2.]], dtype=float32)
params = {'batch_prob': Array([1.], dtype=float32), 'degrees': Array([-35.516792], dtype=float32), 'forward_input_shape': Array([1, 1, 4, 4], dtype=int64)}, kwargs = {}
jax_shape_frnt_ = <function jax_shape_frnt_ at 0x7f42c02427a0>, jax_set_item = <function jax_set_item at 0x7f42e8c8b400>, tensor = <function jax_tensor_frnt at 0x7f42c069ed40>
in_tensor = Array([[[[1., 0., 0., 2.],
         [0., 0., 0., 0.],
         [0., 1., 2., 0.],
         [0., 0., 1., 2.]]]], dtype=float32), input_shape = ivy.frontends.torch.Size([4, 4])
batch_shape = ivy.frontends.torch.Size([1, 1, 4, 4]), flags = {'align_corners': True, 'resample': <jax_Resample.BILINEAR: 1>}

    def __call__(self, input, params=None, **kwargs):
        from ...ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ...ivy.functional.backends.jax.general import jax_set_item
        from ..core._backend import tensor
    
        in_tensor = self.__unpack_input__(input)
        input_shape = jax_shape_frnt_(in_tensor)
        in_tensor = self.transform_tensor(in_tensor)
        batch_shape = jax_shape_frnt_(in_tensor)
        if params is None:
            params = self.forward_parameters(batch_shape)
        if "batch_prob" not in params:
            params = jax_set_item(params, "batch_prob", tensor([True] * batch_shape[0]))
        params, flags = self._process_kwargs_to_params_and_flags(
            params, self.flags, **kwargs
        )
>       output = self.apply_func(in_tensor, params, flags)

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/base.py:219: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_RandomRotation(degrees=45.0, p=1.0, p_batch=1.0, same_on_batch=False, resample=bilinear, align_corners=True)
in_tensor = Array([[[[1., 0., 0., 2.],
         [0., 0., 0., 0.],
         [0., 1., 2., 0.],
         [0., 0., 1., 2.]]]], dtype=float32)
params = {'batch_prob': Array([1.], dtype=float32), 'degrees': Array([-35.516792], dtype=float32), 'forward_input_shape': Array([1, 1, 4, 4], dtype=int64)}
flags = {'align_corners': True, 'resample': <jax_Resample.BILINEAR: 1>}

    def apply_func(self, in_tensor, params, flags=None):
        if flags is None:
            flags = self.flags
>       trans_matrix = self.generate_transformation_matrix(in_tensor, params, flags)

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/_2d/base.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_RandomRotation(degrees=45.0, p=1.0, p_batch=1.0, same_on_batch=False, resample=bilinear, align_corners=True)
input = Array([[[[1., 0., 0., 2.],
         [0., 0., 0., 0.],
         [0., 1., 2., 0.],
         [0., 0., 1., 2.]]]], dtype=float32)
params = {'batch_prob': Array([1.], dtype=float32), 'degrees': Array([-35.516792], dtype=float32), 'forward_input_shape': Array([1, 1, 4, 4], dtype=int64)}
flags = {'align_corners': True, 'resample': <jax_Resample.BILINEAR: 1>}

    def generate_transformation_matrix(self, input, params, flags):
        from ....ivy.functional.frontends.torch.tensor import jax_any_frnt_
        from ....ivy.functional.frontends.torch.tensor import jax_all_frnt_
        from ....ivy.functional.backends.jax.general import jax_get_item
        from ...utils.helpers import jax_is_autocast_enabled
        from ....ivy.functional.frontends.torch.tensor import jax_type_frnt_
        from ....ivy.functional.frontends.torch.tensor import jax_index_put_frnt_
    
        batch_prob = params["batch_prob"]
        to_apply = batch_prob > 0.5
        in_tensor = self.transform_tensor(input)
        if not jax_any_frnt_(to_apply):
            trans_matrix = self.identity_matrix(in_tensor)
        elif jax_all_frnt_(to_apply):
>           trans_matrix = self.compute_transformation(
                in_tensor, params=params, flags=flags
            )

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/_2d/base.py:88: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_RandomRotation(degrees=45.0, p=1.0, p_batch=1.0, same_on_batch=False, resample=bilinear, align_corners=True)
input = Array([[[[1., 0., 0., 2.],
         [0., 0., 0., 0.],
         [0., 1., 2., 0.],
         [0., 0., 1., 2.]]]], dtype=float32)
params = {'batch_prob': Array([1.], dtype=float32), 'degrees': Array([-35.516792], dtype=float32), 'forward_input_shape': Array([1, 1, 4, 4], dtype=int64)}
flags = {'align_corners': True, 'resample': <jax_Resample.BILINEAR: 1>}

    def compute_transformation(self, input, params, flags):
        from .....ivy.functional.frontends.torch.tensor import jax_to_frnt_
        from ....geometry.transform.affwarp import jax__compute_tensor_center
        from ....geometry.transform.affwarp import jax__compute_rotation_matrix
        from .....ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ....utils.misc import jax_eye_like
        from .....ivy.functional.backends.jax.general import jax_set_item
    
        angles: typing.Any = jax_to_frnt_(params["degrees"], input)
        center: typing.Any = jax__compute_tensor_center(input)
        rotation_mat: typing.Any = jax__compute_rotation_matrix(
>           angles, center.expand(jax_shape_frnt_(angles)[0], -1)
        )
E       AttributeError: 'jaxlib.xla_extension.ArrayImpl' object has no attribute 'expand'

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/_2d/geometric/rotation.py:66: AttributeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.RandomRotation
__________________________________________________________________________________ test_RandomCutMixV2[jax-s2s-False] __________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_RandomCutMixV2(target_framework, mode, backend_compile):
        print("kornia.augmentation.RandomCutMixV2")
    
        input = torch.rand(2, 1, 3, 3)
        input[0] = torch.ones((1, 3, 3))
        label = torch.tensor([0, 1])
    
        init_args = ()
        init_kwargs = {"data_keys": ["input", "class"]}
        call_args = (input, label)
        call_kwargs = {}
    
>       _test_augmentation_class(
            kornia.augmentation.RandomCutMixV2,
            target_framework,
            init_args,
            init_kwargs,
            call_args,
            call_kwargs,
            deterministic_output=False,
            backend_compile=backend_compile,
        )

kornia/augmentation/test_augmentation3.py:355: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

augmentation_cls = <class 'kornia.augmentation._2d.mix.cutmix.RandomCutMixV2'>, target = 'jax', init_args = (), init_kwargs = {'data_keys': ['input', 'class']}
call_args = (tensor([[[[1.0000, 1.0000, 1.0000],
          [1.0000, 1.0000, 1.0000],
          [1.0000, 1.0000, 1.0000]]],


        [[[0.2894, 0.2283, 0.9488],
          [0.0458, 0.7035, 0.8907],
          [0.4037, 0.0269, 0.0202]]]]), tensor([0, 1]))
call_kwargs = {}, deterministic_output = False, backend_compile = False, tolerance = 0.001

    def _test_augmentation_class(
        augmentation_cls,
        target,
        init_args=(),
        init_kwargs={},
        call_args=(),
        call_kwargs={},
        deterministic_output=True,
        backend_compile=False,
        tolerance=1e-3,
    ):
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, target=target)
        transpiled_cls = eval("transpiled_" + f"{augmentation_cls.__module__}.{augmentation_cls.__name__}")
    
        torch_aug = augmentation_cls(*init_args, **init_kwargs)
        transpiled_init_args = _nest_torch_tensor_to_new_framework(init_args, target)
        transpiled_init_kwargs = _nest_torch_tensor_to_new_framework(init_kwargs, target)
>       transpiled_aug = transpiled_cls(*transpiled_init_args, **transpiled_init_kwargs)

kornia/augmentation/test_augmentation3.py:37: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:221: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:322: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:310: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:300: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXL.pyx:23: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

MC.pyx:145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

MC.pyx:127: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7f42d4e57160>, node = <gast.gast.Module object at 0x7f430072d4b0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7f42d4e57160>, node = <gast.gast.Module object at 0x7f430072d4b0>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
>                       value = self.visit(value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:486: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7f42d4e57160>, node = <gast.gast.ClassDef object at 0x7f430072cc10>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:225: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7f42d4e57160>, node = <gast.gast.FunctionDef object at 0x7f430072fe80>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:273: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7f42d4e57160>, node = <gast.gast.AnnAssign object at 0x7f42fb732f80>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7f42d4e57160>, node = <gast.gast.Call object at 0x7f42fb7304f0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7f42d4e57160>, node = <gast.gast.Call object at 0x7f42fb7304f0>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
                        value = self.visit(value)
                        if value is None:
                            continue
                        elif not isinstance(value, AST):
                            new_values.extend(value)
                            continue
                    new_values.append(value)
                old_value[:] = new_values
            elif isinstance(old_value, AST):
>               new_node = self.visit(old_value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:495: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7f42d4e57160>, node = <gast.gast.Attribute object at 0x7f42fb732920>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:329: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:141: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:111: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:95: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

MC.pyx:127: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7f4300aaffa0>, node = <gast.gast.Module object at 0x7f4300c0da80>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7f4300aaffa0>, node = <gast.gast.Module object at 0x7f4300c0da80>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
>                       value = self.visit(value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:486: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7f4300aaffa0>, node = <gast.gast.ClassDef object at 0x7f43006ebeb0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:225: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7f4300aaffa0>, node = <gast.gast.FunctionDef object at 0x7f42d4533f10>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:273: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7f4300aaffa0>, node = <gast.gast.Assign object at 0x7f42d4533490>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7f4300aaffa0>, node = <gast.gast.Assign object at 0x7f42d4533490>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
                        value = self.visit(value)
                        if value is None:
                            continue
                        elif not isinstance(value, AST):
                            new_values.extend(value)
                            continue
                    new_values.append(value)
                old_value[:] = new_values
            elif isinstance(old_value, AST):
>               new_node = self.visit(old_value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:495: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7f4300aaffa0>, node = <gast.gast.Call object at 0x7f42c0ee3d00>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7f4300aaffa0>, node = <gast.gast.Call object at 0x7f42c0ee3d00>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
                        value = self.visit(value)
                        if value is None:
                            continue
                        elif not isinstance(value, AST):
                            new_values.extend(value)
                            continue
                    new_values.append(value)
                old_value[:] = new_values
            elif isinstance(old_value, AST):
>               new_node = self.visit(old_value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:495: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7f4300aaffa0>, node = <gast.gast.Attribute object at 0x7f42e886d690>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:329: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:141: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:111: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:95: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

MC.pyx:127: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7f43006e9270>, node = <gast.gast.Module object at 0x7f42d48ad540>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7f43006e9270>, node = <gast.gast.Module object at 0x7f42d48ad540>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
>                       value = self.visit(value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:486: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7f43006e9270>, node = <gast.gast.ClassDef object at 0x7f42d48ae9e0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:225: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7f43006e9270>, node = <gast.gast.FunctionDef object at 0x7f42d48ae350>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:273: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7f43006e9270>, node = <gast.gast.Assign object at 0x7f42c0ee1ab0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7f43006e9270>, node = <gast.gast.Assign object at 0x7f42c0ee1ab0>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
                        value = self.visit(value)
                        if value is None:
                            continue
                        elif not isinstance(value, AST):
                            new_values.extend(value)
                            continue
                    new_values.append(value)
                old_value[:] = new_values
            elif isinstance(old_value, AST):
>               new_node = self.visit(old_value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:495: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7f43006e9270>, node = <gast.gast.Call object at 0x7f42c0ee5e10>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7f43006e9270>, node = <gast.gast.Call object at 0x7f42c0ee5e10>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
                        value = self.visit(value)
                        if value is None:
                            continue
                        elif not isinstance(value, AST):
                            new_values.extend(value)
                            continue
                    new_values.append(value)
                old_value[:] = new_values
            elif isinstance(old_value, AST):
>               new_node = self.visit(old_value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:495: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7f43006e9270>, node = <gast.gast.Attribute object at 0x7f42c0701120>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:329: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:141: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:111: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:95: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

MC.pyx:127: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7f42d4e48820>, node = <gast.gast.Module object at 0x7f42fb71c490>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7f42d4e48820>, node = <gast.gast.Module object at 0x7f42fb71c490>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
>                       value = self.visit(value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:486: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7f42d4e48820>, node = <gast.gast.ClassDef object at 0x7f42fb71d360>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:225: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7f42d4e48820>, node = <gast.gast.FunctionDef object at 0x7f42fb71ce80>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:273: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7f42d4e48820>, node = <gast.gast.Return object at 0x7f42d46e29e0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7f42d4e48820>, node = <gast.gast.Return object at 0x7f42d46e29e0>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
                        value = self.visit(value)
                        if value is None:
                            continue
                        elif not isinstance(value, AST):
                            new_values.extend(value)
                            continue
                    new_values.append(value)
                old_value[:] = new_values
            elif isinstance(old_value, AST):
>               new_node = self.visit(old_value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:495: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7f42d4e48820>, node = <gast.gast.Call object at 0x7f42d46e0e50>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7f42d4e48820>, node = <gast.gast.Call object at 0x7f42d46e0e50>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
                        value = self.visit(value)
                        if value is None:
                            continue
                        elif not isinstance(value, AST):
                            new_values.extend(value)
                            continue
                    new_values.append(value)
                old_value[:] = new_values
            elif isinstance(old_value, AST):
>               new_node = self.visit(old_value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:495: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7f42d4e48820>, node = <gast.gast.Attribute object at 0x7f42d46e35e0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:328: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7f42d4e48820>, node = <gast.gast.Attribute object at 0x7f42d46e35e0>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
                        value = self.visit(value)
                        if value is None:
                            continue
                        elif not isinstance(value, AST):
                            new_values.extend(value)
                            continue
                    new_values.append(value)
                old_value[:] = new_values
            elif isinstance(old_value, AST):
>               new_node = self.visit(old_value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:495: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7f42d4e48820>, node = <gast.gast.Name object at 0x7f42d46e1450>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:324: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:141: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:111: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:95: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

MC.pyx:127: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7f42d49ae4a0>, node = <gast.gast.Module object at 0x7f42c0495d50>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7f42d49ae4a0>, node = <gast.gast.Module object at 0x7f42c0495d50>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
>                       value = self.visit(value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:486: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7f42d49ae4a0>, node = <gast.gast.ClassDef object at 0x7f42d46f4d30>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

MC.pyx:127: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7f4301231810>, node = <gast.gast.Module object at 0x7f42f835fb80>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7f4301231810>, node = <gast.gast.Module object at 0x7f42f835fb80>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
>                       value = self.visit(value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:486: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7f4301231810>, node = <gast.gast.ClassDef object at 0x7f42f835ff40>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

MC.pyx:127: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7f42d4e57d90>, node = <gast.gast.Module object at 0x7f42e8a55840>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7f42d4e57d90>, node = <gast.gast.Module object at 0x7f42e8a55840>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
>                       value = self.visit(value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:486: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7f42d4e57d90>, node = <gast.gast.ClassDef object at 0x7f42e8a55060>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:190: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IL.pyx:244: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IL.pyx:258: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IL.pyx:33: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IL.pyx:110: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IM.pyx:41: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

object = <class 'torch._C._FunctionBase'>

    def getsourcelines(object):
        """Return a list of source lines and starting line number for an object.
    
        The argument may be a module, class, method, function, traceback, frame,
        or code object.  The source code is returned as a list of the lines
        corresponding to the object and the line number indicates where in the
        original source file the first line of code was found.  An OSError is
        raised if the source code cannot be retrieved."""
        object = unwrap(object)
>       lines, lnum = findsource(object)

/opt/miniconda/envs/multienv/lib/python3.10/inspect.py:1129: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

object = <class 'torch._C._FunctionBase'>

    def findsource(object):
        """Return the entire source file and starting line number for an object.
    
        The argument may be a module, class, method, function, traceback, frame,
        or code object.  The source code is returned as a list of all the lines
        in the file and the line number indexes a line in that list.  An OSError
        is raised if the source code cannot be retrieved."""
    
        file = getsourcefile(object)
        if file:
            # Invalidate cache if needed.
            linecache.checkcache(file)
        else:
            file = getfile(object)
            # Allow filenames in form of "<something>" to pass through.
            # `doctest` monkeypatches `linecache` module to enable
            # inspection, so let `linecache.getlines` to be called.
            if not (file.startswith('<') and file.endswith('>')):
>               raise OSError('source code not available')
E               OSError: source code not available

/opt/miniconda/envs/multienv/lib/python3.10/inspect.py:950: OSError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.RandomCutMixV2
___________________________________________________________________________________ test_RandomJigsaw[jax-s2s-False] ___________________________________________________________________________________

inp = jax_DType.INT64 | jax_DType.FLOAT16 | jax_DType.FLOAT32 | jax_DType.FLOAT64, query = '2', kwargs = {}

    @functools.wraps(fn)
    def wrapper(inp, query, **kwargs):
        try:
>           res = inp.__getitem__(query)

ivy_transpiled_outputs/jax_outputs/ivy/utils/decorator_utils.py:219: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = jax_DType.INT64 | jax_DType.FLOAT16 | jax_DType.FLOAT32 | jax_DType.FLOAT64, name = '2'

    def __getitem__(cls, name):
>       return cls._member_map_[name]
E       KeyError: '2'

/opt/miniconda/envs/multienv/lib/python3.10/enum.py:432: KeyError

During handling of the above exception, another exception occurred:

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_RandomJigsaw(target_framework, mode, backend_compile):
        print("kornia.augmentation.RandomJigsaw")
    
        init_args = ((4, 4),)
        init_kwargs = {}
        call_args = (torch.randn(8, 3, 256, 256),)
        call_kwargs = {}
    
>       _test_augmentation_class(
            kornia.augmentation.RandomJigsaw,
            target_framework,
            init_args,
            init_kwargs,
            call_args,
            call_kwargs,
            deterministic_output=False,
            backend_compile=backend_compile,
        )

kornia/augmentation/test_augmentation3.py:375: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

augmentation_cls = <class 'kornia.augmentation._2d.mix.jigsaw.RandomJigsaw'>, target = 'jax', init_args = ((4, 4),), init_kwargs = {}
call_args = (tensor([[[[ 1.0312e+00, -8.0829e-01, -2.2911e+00,  ...,  1.1976e+00,
           -2.5616e+00,  8.7867e-01],
          ...7e-01],
          [ 1.5317e+00, -9.1508e-02, -5.7730e-03,  ..., -1.0532e+00,
            2.1289e+00, -3.2748e-01]]]]),)
call_kwargs = {}, deterministic_output = False, backend_compile = False, tolerance = 0.001

    def _test_augmentation_class(
        augmentation_cls,
        target,
        init_args=(),
        init_kwargs={},
        call_args=(),
        call_kwargs={},
        deterministic_output=True,
        backend_compile=False,
        tolerance=1e-3,
    ):
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, target=target)
        transpiled_cls = eval("transpiled_" + f"{augmentation_cls.__module__}.{augmentation_cls.__name__}")
    
        torch_aug = augmentation_cls(*init_args, **init_kwargs)
        transpiled_init_args = _nest_torch_tensor_to_new_framework(init_args, target)
        transpiled_init_kwargs = _nest_torch_tensor_to_new_framework(init_kwargs, target)
        transpiled_aug = transpiled_cls(*transpiled_init_args, **transpiled_init_kwargs)
    
        # assert dir(torch_aug) == dir(transpiled_aug), f"attributes/methods of transpiled object do not align with the original - orig: {dir(torch_aug)} != transpiled: {dir(transpiled_aug)}"
    
        torch_out = torch_aug(*call_args, **call_kwargs)
        transpiled_call_args = _nest_torch_tensor_to_new_framework(call_args, target)
        transpiled_call_kwargs = _nest_torch_tensor_to_new_framework(call_kwargs, target)
>       transpiled_out = transpiled_aug(*transpiled_call_args, **transpiled_call_kwargs)

kornia/augmentation/test_augmentation3.py:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_RandomJigsaw(grid=(4, 4), p=0.5, p_batch=1.0, same_on_batch=False, grid=(4, 4)), params = None, data_keys = None
input = (Array([[[[ 1.03122997e+00, -8.08288097e-01, -2.29113317e+00, ...,
           1.19764781e+00, -2.56163478e+00,  8.7866...75392e-02, -5.77304047e-03, ...,
          -1.05319071e+00,  2.12892580e+00, -3.27476174e-01]]]],      dtype=float32),)
tensor = <function jax_tensor_frnt at 0x7f42b7be6710>

    def __call__(self, *input, params=None, data_keys=None):
        from ....core._backend import tensor
        from .....ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ....geometry.boxes import jax_Boxes
        from .....ivy.functional.backends.jax.general import jax_get_item
        from ....constants import jax_DType
        from ....core.check import jax_KORNIA_UNWRAP
    
        keys: typing.Any
        if data_keys is None:
            keys = self.data_keys
        else:
            keys = [jax_DataKey.get(inp) for inp in data_keys]
        if params is None:
            in_tensor_idx: typing.Any = keys.index(jax_DataKey.INPUT)
            in_tensor: typing.Any = jax_get_item(input, in_tensor_idx)
            in_tensor = self.transform_tensor(in_tensor)
            self._params = self.forward_parameters(jax_shape_frnt_(in_tensor))
>           self._params.update({"dtype": tensor(jax_DType.get(in_tensor.dtype).value)})

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/_2d/mix/base.py:193: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = jax_DType.INT64 | jax_DType.FLOAT16 | jax_DType.FLOAT32 | jax_DType.FLOAT64, value = dtype('float32')

    @classmethod
    def get(cls, value):
        from ..ivy.functional.backends.jax.general import jax_get_item
        from ..ivy.functional.frontends.torch.tensor import jax_item_frnt_
    
        if isinstance(value, (np.dtype,)):
>           return jax_get_item(cls, str(value).upper()[6:])

ivy_transpiled_outputs/jax_outputs/kornia/constants.py:77: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

inp = jax_DType.INT64 | jax_DType.FLOAT16 | jax_DType.FLOAT32 | jax_DType.FLOAT64, query = '2', kwargs = {}

    @functools.wraps(fn)
    def wrapper(inp, query, **kwargs):
        try:
            res = inp.__getitem__(query)
        except Exception:
>           res = fn(inp, query, **kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/utils/decorator_utils.py:221: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (jax_DType.INT64 | jax_DType.FLOAT16 | jax_DType.FLOAT32 | jax_DType.FLOAT64, '2'), kwargs = {}, handle_mixed_in_backend = True

    @functools.wraps(fn)
    def _handle_partial_mixed_function(*args, **kwargs):
        handle_mixed_in_backend = False
        if not hasattr(fn, "partial_mixed_handler"):
            handle_mixed_in_backend = True
        else:
            compos = getattr(fn, "compos")
            condition = getattr(fn, "partial_mixed_handler")
        if handle_mixed_in_backend or condition(*args, **kwargs):
>           return fn(*args, **kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/func_wrapper.py:160: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = jax_DType.INT64 | jax_DType.FLOAT16 | jax_DType.FLOAT32 | jax_DType.FLOAT64, query = '2'

    @jax_handle_get_item
    @jax_handle_partial_mixed_function
    def jax_get_item(
        x: jax.Array, /, query: Union[jax.Array, Tuple], *, copy: Optional[bool] = None
    ):
        from ...ivy.general import jax_is_array_bknd
        from ...ivy.data_type import jax_is_bool_dtype_bknd
    
        if copy:
            x = x.copy()
        if jax_is_array_bknd(query) and jax_is_bool_dtype_bknd(query):
            if not len(query.shape):
                if not query:
                    return jax.numpy.array([], dtype=x.dtype)
                else:
                    return jax.numpy.expand_dims(x, 0)
            query = jax__mask_to_index(query, x)
        elif isinstance(query, list):
            query = (query,)
>       return x.__getitem__(query)

ivy_transpiled_outputs/jax_outputs/ivy/functional/backends/jax/general.py:86: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = jax_DType.INT64 | jax_DType.FLOAT16 | jax_DType.FLOAT32 | jax_DType.FLOAT64, name = '2'

    def __getitem__(cls, name):
>       return cls._member_map_[name]
E       KeyError: '2'

/opt/miniconda/envs/multienv/lib/python3.10/enum.py:432: KeyError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.RandomJigsaw
__________________________________________________________________________________ test_RandomMixUpV2[jax-s2s-False] ___________________________________________________________________________________

inp = jax_DType.INT64 | jax_DType.FLOAT16 | jax_DType.FLOAT32 | jax_DType.FLOAT64, query = '2', kwargs = {}

    @functools.wraps(fn)
    def wrapper(inp, query, **kwargs):
        try:
>           res = inp.__getitem__(query)

ivy_transpiled_outputs/jax_outputs/ivy/utils/decorator_utils.py:219: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = jax_DType.INT64 | jax_DType.FLOAT16 | jax_DType.FLOAT32 | jax_DType.FLOAT64, name = '2'

    def __getitem__(cls, name):
>       return cls._member_map_[name]
E       KeyError: '2'

/opt/miniconda/envs/multienv/lib/python3.10/enum.py:432: KeyError

During handling of the above exception, another exception occurred:

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_RandomMixUpV2(target_framework, mode, backend_compile):
        print("kornia.augmentation.RandomMixUpV2")
    
        init_args = ()
        init_kwargs = {"data_keys": ["input", "class"]}
        call_args = (torch.rand(2, 1, 3, 3), torch.tensor([0, 1]))
        call_kwargs = {}
    
>       _test_augmentation_class(
            kornia.augmentation.RandomMixUpV2,
            target_framework,
            init_args,
            init_kwargs,
            call_args,
            call_kwargs,
            deterministic_output=False,
            backend_compile=backend_compile,
        )

kornia/augmentation/test_augmentation3.py:395: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

augmentation_cls = <class 'kornia.augmentation._2d.mix.mixup.RandomMixUpV2'>, target = 'jax', init_args = (), init_kwargs = {'data_keys': ['input', 'class']}
call_args = (tensor([[[[0.4689, 0.3662, 0.9610],
          [0.0553, 0.3232, 0.5067],
          [0.8493, 0.5935, 0.5155]]],


        [[[0.2007, 0.7465, 0.0843],
          [0.1002, 0.3941, 0.1149],
          [0.2324, 0.9166, 0.3729]]]]), tensor([0, 1]))
call_kwargs = {}, deterministic_output = False, backend_compile = False, tolerance = 0.001

    def _test_augmentation_class(
        augmentation_cls,
        target,
        init_args=(),
        init_kwargs={},
        call_args=(),
        call_kwargs={},
        deterministic_output=True,
        backend_compile=False,
        tolerance=1e-3,
    ):
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, target=target)
        transpiled_cls = eval("transpiled_" + f"{augmentation_cls.__module__}.{augmentation_cls.__name__}")
    
        torch_aug = augmentation_cls(*init_args, **init_kwargs)
        transpiled_init_args = _nest_torch_tensor_to_new_framework(init_args, target)
        transpiled_init_kwargs = _nest_torch_tensor_to_new_framework(init_kwargs, target)
        transpiled_aug = transpiled_cls(*transpiled_init_args, **transpiled_init_kwargs)
    
        # assert dir(torch_aug) == dir(transpiled_aug), f"attributes/methods of transpiled object do not align with the original - orig: {dir(torch_aug)} != transpiled: {dir(transpiled_aug)}"
    
        torch_out = torch_aug(*call_args, **call_kwargs)
        transpiled_call_args = _nest_torch_tensor_to_new_framework(call_args, target)
        transpiled_call_kwargs = _nest_torch_tensor_to_new_framework(call_kwargs, target)
>       transpiled_out = transpiled_aug(*transpiled_call_args, **transpiled_call_kwargs)

kornia/augmentation/test_augmentation3.py:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_RandomMixUpV2(lambda_val=None, p=1.0, p_batch=1.0, same_on_batch=False), params = None, data_keys = None
input = (Array([[[[0.46885502, 0.36624885, 0.9610226 ],
         [0.05530614, 0.3231578 , 0.50671726],
         [0.84930414, 0... 0.39405507, 0.11489028],
         [0.23244333, 0.91660404, 0.3729431 ]]]], dtype=float32), Array([0, 1], dtype=int64))
tensor = <function jax_tensor_frnt at 0x7f42b7c04790>

    def __call__(self, *input, params=None, data_keys=None):
        from ....core._backend import tensor
        from .....ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ....geometry.boxes import jax_Boxes
        from .....ivy.functional.backends.jax.general import jax_get_item
        from ....constants import jax_DType
        from ....core.check import jax_KORNIA_UNWRAP
    
        keys: typing.Any
        if data_keys is None:
            keys = self.data_keys
        else:
            keys = [jax_DataKey.get(inp) for inp in data_keys]
        if params is None:
            in_tensor_idx: typing.Any = keys.index(jax_DataKey.INPUT)
            in_tensor: typing.Any = jax_get_item(input, in_tensor_idx)
            in_tensor = self.transform_tensor(in_tensor)
            self._params = self.forward_parameters(jax_shape_frnt_(in_tensor))
>           self._params.update({"dtype": tensor(jax_DType.get(in_tensor.dtype).value)})

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/_2d/mix/base.py:193: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = jax_DType.INT64 | jax_DType.FLOAT16 | jax_DType.FLOAT32 | jax_DType.FLOAT64, value = dtype('float32')

    @classmethod
    def get(cls, value):
        from ..ivy.functional.backends.jax.general import jax_get_item
        from ..ivy.functional.frontends.torch.tensor import jax_item_frnt_
    
        if isinstance(value, (np.dtype,)):
>           return jax_get_item(cls, str(value).upper()[6:])

ivy_transpiled_outputs/jax_outputs/kornia/constants.py:77: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

inp = jax_DType.INT64 | jax_DType.FLOAT16 | jax_DType.FLOAT32 | jax_DType.FLOAT64, query = '2', kwargs = {}

    @functools.wraps(fn)
    def wrapper(inp, query, **kwargs):
        try:
            res = inp.__getitem__(query)
        except Exception:
>           res = fn(inp, query, **kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/utils/decorator_utils.py:221: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (jax_DType.INT64 | jax_DType.FLOAT16 | jax_DType.FLOAT32 | jax_DType.FLOAT64, '2'), kwargs = {}, handle_mixed_in_backend = True

    @functools.wraps(fn)
    def _handle_partial_mixed_function(*args, **kwargs):
        handle_mixed_in_backend = False
        if not hasattr(fn, "partial_mixed_handler"):
            handle_mixed_in_backend = True
        else:
            compos = getattr(fn, "compos")
            condition = getattr(fn, "partial_mixed_handler")
        if handle_mixed_in_backend or condition(*args, **kwargs):
>           return fn(*args, **kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/func_wrapper.py:160: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = jax_DType.INT64 | jax_DType.FLOAT16 | jax_DType.FLOAT32 | jax_DType.FLOAT64, query = '2'

    @jax_handle_get_item
    @jax_handle_partial_mixed_function
    def jax_get_item(
        x: jax.Array, /, query: Union[jax.Array, Tuple], *, copy: Optional[bool] = None
    ):
        from ...ivy.general import jax_is_array_bknd
        from ...ivy.data_type import jax_is_bool_dtype_bknd
    
        if copy:
            x = x.copy()
        if jax_is_array_bknd(query) and jax_is_bool_dtype_bknd(query):
            if not len(query.shape):
                if not query:
                    return jax.numpy.array([], dtype=x.dtype)
                else:
                    return jax.numpy.expand_dims(x, 0)
            query = jax__mask_to_index(query, x)
        elif isinstance(query, list):
            query = (query,)
>       return x.__getitem__(query)

ivy_transpiled_outputs/jax_outputs/ivy/functional/backends/jax/general.py:86: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = jax_DType.INT64 | jax_DType.FLOAT16 | jax_DType.FLOAT32 | jax_DType.FLOAT64, name = '2'

    def __getitem__(cls, name):
>       return cls._member_map_[name]
E       KeyError: '2'

/opt/miniconda/envs/multienv/lib/python3.10/enum.py:432: KeyError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.RandomMixUpV2
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/augmentation/test_augmentation3.py::test_RandomRotation[jax-s2s-False] - AttributeError: 'jaxlib.xla_extension.ArrayImpl' object has no attribute 'expand'
FAILED kornia/augmentation/test_augmentation3.py::test_RandomCutMixV2[jax-s2s-False] - OSError: source code not available
FAILED kornia/augmentation/test_augmentation3.py::test_RandomJigsaw[jax-s2s-False] - KeyError: '2'
FAILED kornia/augmentation/test_augmentation3.py::test_RandomMixUpV2[jax-s2s-False] - KeyError: '2'
============================================================================== 4 failed, 12 passed in 3285.22s (0:54:45) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 56 items

kornia/geometry/test_transform.py ........................F..................F............                                                                                                       [100%]

=============================================================================================== FAILURES ===============================================================================================
__________________________________________________________________________________ test_upscale_double[jax-s2s-False] __________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_upscale_double(target_framework, mode, backend_compile):
        trace_args = (
            torch.rand(1, 3, 4, 4),
        )
        trace_kwargs = {}
        test_args = (
            torch.rand(5, 3, 8, 8),
        )
        test_kwargs = {}
>       _test_function(
            kornia.geometry.transform.upscale_double,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/geometry/test_transform.py:612: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function upscale_double at 0x7ff654b69360>
trace_args = (tensor([[[[0.6920, 0.4353, 0.3731, 0.6608],
          [0.5547, 0.5841, 0.0062, 0.6056],
          [0.5257, 0.8082, 0...., 0.1449, 0.2857, 0.2592],
          [0.0431, 0.3010, 0.8811, 0.2306],
          [0.2367, 0.3310, 0.1442, 0.6988]]]]),)
trace_kwargs = {}
test_args = (tensor([[[[3.3666e-01, 5.4273e-01, 8.0359e-02, 7.1334e-01, 9.3760e-01,
           2.9394e-01, 9.9991e-01, 6.6758e-01]...      [3.4693e-01, 7.8785e-01, 3.6907e-01, 9.9723e-01, 3.1037e-01,
           8.4102e-01, 8.1904e-01, 9.6633e-01]]]]),)
test_kwargs = {}, target = 'jax', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function upscale_double at 0x7ff654b69360>, fn_name = 'kornia.geometry.transform.upscale_double'
trace_args = (tensor([[[[0.6920, 0.4353, 0.3731, 0.6608],
          [0.5547, 0.5841, 0.0062, 0.6056],
          [0.5257, 0.8082, 0...., 0.1449, 0.2857, 0.2592],
          [0.0431, 0.3010, 0.8811, 0.2306],
          [0.2367, 0.3310, 0.1442, 0.6988]]]]),)
trace_kwargs = {}
test_args = (tensor([[[[3.3666e-01, 5.4273e-01, 8.0359e-02, 7.1334e-01, 9.3760e-01,
           2.9394e-01, 9.9991e-01, 6.6758e-01]...      [3.4693e-01, 7.8785e-01, 3.6907e-01, 9.9723e-01, 3.1037e-01,
           8.4102e-01, 8.1904e-01, 9.6633e-01]]]]),)
test_kwargs = {}, target = 'jax', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:232: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = Array([[[[0.6919745 , 0.43533933, 0.37313426, 0.66082853],
         [0.55470157, 0.584132  , 0.00617081, 0.60562366],
... 0.30096018, 0.881096  , 0.23055339],
         [0.23670053, 0.33095568, 0.14421064, 0.6987614 ]]]],      dtype=float32)

    def jax_upscale_double(x):
        from ...core._backend import zeros
        from ...core.check import jax_KORNIA_CHECK_IS_TENSOR
        from ...core.check import jax_KORNIA_CHECK_SHAPE
        from ....ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ....ivy.functional.backends.jax.general import jax_set_item
    
        jax_KORNIA_CHECK_IS_TENSOR(x)
        jax_KORNIA_CHECK_SHAPE(x, ["*", "H", "W"])
        double_shape = jax_shape_frnt_(x)[:-2] + (
            jax_shape_frnt_(x)[-2] * 2,
            jax_shape_frnt_(x)[-1] * 2,
        )
        upscaled = zeros(double_shape, device=x.device, dtype=x.dtype)
        upscaled = jax_set_item(
            upscaled, (..., slice(None, None, 2), slice(None, None, 2)), x
        )
>       upscaled[..., ::2, 1::2] = jax_set_item(
            upscaled[..., ::2, 1::2],
            (..., slice(None, -1, None)),
            (upscaled[..., ::2, ::2][..., :-1] + upscaled[..., ::2, 2::2]) / 2,
        )

ivy_transpiled_outputs/jax_outputs/kornia/geometry/transform/pyramid.py:45: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = Array([[[[0.6919745 , 0.        , 0.43533933, 0.        , 0.37313426,
          0.        , 0.66082853, 0.        ],
 ...     , 0.        , 0.        , 0.        , 0.        ,
          0.        , 0.        , 0.        ]]]], dtype=float32)
i = (Ellipsis, slice(None, None, 2), slice(1, None, 2))
x = Array([[[[0.5636569 , 0.4042368 , 0.51698136, 0.        ],
         [0.56941676, 0.2951514 , 0.30589724, 0.        ],
... 0.5910281 , 0.5558247 , 0.        ],
         [0.2838281 , 0.23758316, 0.42148602, 0.        ]]]],      dtype=float32)

    def _unimplemented_setitem(self, i, x):
      msg = ("'{}' object does not support item assignment. JAX arrays are "
             "immutable. Instead of ``x[idx] = y``, use ``x = x.at[idx].set(y)`` "
             "or another .at[] method: "
             "https://jax.readthedocs.io/en/latest/_autosummary/jax.numpy.ndarray.at.html")
>     raise TypeError(msg.format(type(self)))
E     TypeError: '<class 'jaxlib.xla_extension.ArrayImpl'>' object does not support item assignment. JAX arrays are immutable. Instead of ``x[idx] = y``, use ``x = x.at[idx].set(y)`` or another .at[] method: https://jax.readthedocs.io/en/latest/_autosummary/jax.numpy.ndarray.at.html

/opt/fw/jax/jax/_src/numpy/array_methods.py:587: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.transform.pyramid.upscale_double
______________________________________________________________________________________ test_Shear[jax-s2s-False] _______________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_Shear(target_framework, mode, backend_compile):
        print("kornia.geometry.transform.Shear")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target_framework)
    
        x = torch.rand(2, 3, 4, 4)
        shear = torch.tensor([[0.5, 0.0], [0.0, 0.5]])
        torch_out = kornia.geometry.transform.Shear(shear)(x)
    
        transpiled_x = _nest_torch_tensor_to_new_framework(x, target_framework)
        transpiled_shear = _nest_torch_tensor_to_new_framework(shear, target_framework)
>       transpiled_out = transpiled_kornia.geometry.transform.Shear(transpiled_shear)(transpiled_x)

kornia/geometry/test_transform.py:1156: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_Shear()
input = Array([[[[0.3541125 , 0.5936095 , 0.7061551 , 0.71614033],
         [0.27994084, 0.92057294, 0.6256838 , 0.10688525],
... 0.56077856, 0.6945366 , 0.30560684],
         [0.27917558, 0.7440141 , 0.85935444, 0.2047993 ]]]],      dtype=float32)

    def __call__(self, input):
>       return shear(
            input, self.shear, self.mode, self.padding_mode, self.align_corners
        )
E       NameError: name 'shear' is not defined

ivy_transpiled_outputs/jax_outputs/kornia/geometry/transform/affwarp.py:52: NameError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.transform.Shear
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/geometry/test_transform.py::test_upscale_double[jax-s2s-False] - TypeError: '<class 'jaxlib.xla_extension.ArrayImpl'>' object does not support item assignment. JAX arrays are immutabl...
FAILED kornia/geometry/test_transform.py::test_Shear[jax-s2s-False] - NameError: name 'shear' is not defined
============================================================================== 2 failed, 54 passed in 4983.00s (1:23:02) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 2 items

kornia/geometry/test_vector.py FF                                                                                                                                                                [100%]

=============================================================================================== FAILURES ===============================================================================================
_____________________________________________________________________________________ test_Vector3[jax-s2s-False] ______________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_Vector3(target_framework, mode, backend_compile):
        print("kornia.geometry.vector.Vector3")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target_framework)
        # Initialize a Vector3 with a tensor
        vector = torch.tensor([1.0, 2.0, 3.0], requires_grad=True)
        torch_vector3 = kornia.geometry.vector.Vector3(vector)
    
        transpiled_vector = _nest_torch_tensor_to_new_framework(vector, target_framework)
        transpiled_vector3 = transpiled_kornia.geometry.vector.Vector3(transpiled_vector)
    
        # Test .x, .y, .z properties
        _to_numpy_and_allclose(torch_vector3.x, transpiled_vector3.x)
        _to_numpy_and_allclose(torch_vector3.y, transpiled_vector3.y)
        _to_numpy_and_allclose(torch_vector3.z, transpiled_vector3.z)
    
        # Test .normalized()
        torch_normalized = torch_vector3.normalized()
        transpiled_normalized = transpiled_vector3.normalized()
        _to_numpy_and_allclose(torch_normalized.data, transpiled_normalized.data)
    
        # Test .dot()
        another_vector = torch.tensor([4.0, 5.0, 6.0], requires_grad=True)
        transpiled_another_vector = _nest_torch_tensor_to_new_framework(another_vector, target_framework)
    
        torch_dot = torch_vector3.dot(kornia.geometry.vector.Vector3(another_vector))
        transpiled_dot = transpiled_vector3.dot(transpiled_kornia.geometry.vector.Vector3(transpiled_another_vector))
        _to_numpy_and_allclose(torch_dot.data, transpiled_dot.data)
    
        # Test .squared_norm()
        torch_squared_norm = torch_vector3.squared_norm()
        transpiled_squared_norm = transpiled_vector3.squared_norm()
        _to_numpy_and_allclose(torch_squared_norm.data, transpiled_squared_norm.data)
    
        # Test class method .random()
        torch_random_vector3 = kornia.geometry.vector.Vector3.random()
>       transpiled_random_vector3 = transpiled_kornia.geometry.vector.Vector3.random()
E       TypeError: 'classmethod' object is not callable

kornia/geometry/test_vector.py:56: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.vector.Vector3
_____________________________________________________________________________________ test_Vector2[jax-s2s-False] ______________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_Vector2(target_framework, mode, backend_compile):
        print("kornia.geometry.vector.Vector2")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target_framework)
        # Initialize a Vector2 with a tensor
        vector = torch.tensor([1.0, 2.0], requires_grad=True)
        torch_vector2 = kornia.geometry.vector.Vector2(vector)
    
    
        transpiled_vector = _nest_torch_tensor_to_new_framework(vector, target_framework)
        transpiled_vector2 = transpiled_kornia.geometry.vector.Vector2(transpiled_vector)
    
        # Test .x, .y properties
        _to_numpy_and_allclose(torch_vector2.x, transpiled_vector2.x)
        _to_numpy_and_allclose(torch_vector2.y, transpiled_vector2.y)
    
        # Test .normalized()
        torch_normalized = torch_vector2.normalized()
        transpiled_normalized = transpiled_vector2.normalized()
        _to_numpy_and_allclose(torch_normalized.data, transpiled_normalized.data)
    
        # Test .dot()
        another_vector = torch.tensor([3.0, 4.0], requires_grad=True)
        transpiled_another_vector = _nest_torch_tensor_to_new_framework(another_vector, target_framework)
    
        torch_dot = torch_vector2.dot(kornia.geometry.vector.Vector2(another_vector))
        transpiled_dot = transpiled_vector2.dot(transpiled_kornia.geometry.vector.Vector2(transpiled_another_vector))
        _to_numpy_and_allclose(torch_dot.data, transpiled_dot.data)
    
        # Test .squared_norm()
        torch_squared_norm = torch_vector2.squared_norm()
        transpiled_squared_norm = transpiled_vector2.squared_norm()
        _to_numpy_and_allclose(torch_squared_norm.data, transpiled_squared_norm.data)
    
        # Test class method .random()
        torch_random_vector2 = kornia.geometry.vector.Vector2.random()
>       transpiled_random_vector2 = transpiled_kornia.geometry.vector.Vector2.random()
E       TypeError: 'classmethod' object is not callable

kornia/geometry/test_vector.py:104: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.vector.Vector2
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/geometry/test_vector.py::test_Vector3[jax-s2s-False] - TypeError: 'classmethod' object is not callable
FAILED kornia/geometry/test_vector.py::test_Vector2[jax-s2s-False] - TypeError: 'classmethod' object is not callable
==================================================================================== 2 failed in 133.20s (0:02:13) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 8 items

kornia/geometry/test_homography.py FFFF.F.F                                                                                                                                                      [100%]

=============================================================================================== FAILURES ===============================================================================================
______________________________________________________________________________ test_find_homography_dlt[numpy-s2s-False] _______________________________________________________________________________

target_framework = 'numpy', mode = 's2s', backend_compile = False

    def test_find_homography_dlt(target_framework, mode, backend_compile):
        trace_args = (
            torch.rand(1, 4, 2),
            torch.rand(1, 4, 2),
        )
        trace_kwargs = {'weights': torch.rand(1, 4), 'solver': 'svd'}
        test_args = (
            torch.rand(5, 4, 2),
            torch.rand(5, 4, 2),
        )
        test_kwargs = {'weights': torch.rand(5, 4), 'solver': 'svd'}
>       _test_function(
            kornia.geometry.homography.find_homography_dlt,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=5e-2,
            mode=mode,
            # NOTE: numerical instability in svd()/lu() leads to logits not being allclose
            deterministic=False,
        )

kornia/geometry/test_homography.py:20: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function find_homography_dlt at 0x7f8ae2053130>
trace_args = (tensor([[[0.7271, 0.9093],
         [0.9444, 0.3807],
         [0.8734, 0.0260],
         [0.0640, 0.2819]]]), tensor([[[0.6111, 0.4342],
         [0.4822, 0.7069],
         [0.5984, 0.5379],
         [0.4380, 0.3536]]]))
trace_kwargs = {'solver': 'svd', 'weights': tensor([[0.0456, 0.7308, 0.8439, 0.8168]])}
test_args = (tensor([[[0.4260, 0.1463],
         [0.8607, 0.7796],
         [0.9918, 0.3881],
         [0.0534, 0.9487]],

       ...2959]],

        [[0.3611, 0.0762],
         [0.0426, 0.5171],
         [0.5524, 0.8316],
         [0.5729, 0.6029]]]))
test_kwargs = {'solver': 'svd', 'weights': tensor([[0.5914, 0.5190, 0.6261, 0.3811],
        [0.5241, 0.3056, 0.7664, 0.9463],
        [0.1616, 0.0123, 0.3411, 0.4065],
        [0.9484, 0.1223, 0.7068, 0.6181],
        [0.2432, 0.6067, 0.5494, 0.5091]])}
target = 'numpy', backend_compile = False, tolerance = 0.05, mode = 's2s', skip = False, deterministic = False, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function find_homography_dlt at 0x7f8ae2053130>, fn_name = 'kornia.geometry.homography.find_homography_dlt'
trace_args = (tensor([[[0.7271, 0.9093],
         [0.9444, 0.3807],
         [0.8734, 0.0260],
         [0.0640, 0.2819]]]), tensor([[[0.6111, 0.4342],
         [0.4822, 0.7069],
         [0.5984, 0.5379],
         [0.4380, 0.3536]]]))
trace_kwargs = {'solver': 'svd', 'weights': tensor([[0.0456, 0.7308, 0.8439, 0.8168]])}
test_args = (tensor([[[0.4260, 0.1463],
         [0.8607, 0.7796],
         [0.9918, 0.3881],
         [0.0534, 0.9487]],

       ...2959]],

        [[0.3611, 0.0762],
         [0.0426, 0.5171],
         [0.5524, 0.8316],
         [0.5729, 0.6029]]]))
test_kwargs = {'solver': 'svd', 'weights': tensor([[0.5914, 0.5190, 0.6261, 0.3811],
        [0.5241, 0.3056, 0.7664, 0.9463],
        [0.1616, 0.0123, 0.3411, 0.4065],
        [0.9484, 0.1223, 0.7068, 0.6181],
        [0.2432, 0.6067, 0.5494, 0.5091]])}
target = 'numpy', backend_compile = False, tolerance = 0.05, deterministic = False, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:232: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

points1 = array([[[0.7271209 , 0.909315  ],
        [0.9443511 , 0.38073063],
        [0.87335765, 0.0260191 ],
        [0.06395793, 0.28190583]]], dtype=float32)
points2 = array([[[0.61114675, 0.4342131 ],
        [0.4822008 , 0.70690113],
        [0.59835905, 0.53791213],
        [0.43796974, 0.3535667 ]]], dtype=float32)
weights = array([[0.04557866, 0.7308256 , 0.8439256 , 0.8168471 ]], dtype=float32), solver = 'svd'

    def numpy_find_homography_dlt(points1, points2, weights=None, solver="lu"):
        from ...ivy.functional.frontends.torch.tensor import numpy_shape_frnt_
        from ..core.check import numpy_KORNIA_CHECK_SHAPE
        from ..utils.helpers import numpy__extract_device_dtype
        from .epipolar.fundamental import numpy_normalize_points
        from ...ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            numpy_chunk_frnt,
        )
        from ...ivy.functional.frontends.torch.creation_ops import (
            numpy_ones_like_v_0p4p0_and_above_frnt,
        )
        from ...ivy.functional.frontends.torch.creation_ops import numpy_zeros_like_frnt
        from ...ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            numpy_cat_frnt,
        )
        from ...ivy.functional.frontends.torch.tensor import numpy_reshape_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_transpose_frnt_
        from ...ivy.functional.frontends.torch.miscellaneous_ops import (
            numpy_diag_embed_frnt,
        )
        from ...ivy.functional.frontends.torch.tensor import numpy_repeat_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_unsqueeze_frnt_
        from ..utils.helpers import numpy__torch_svd_cast
        from ...ivy.functional.frontends.torch.creation_ops import numpy_empty_frnt
        from ...ivy.functional.frontends.torch.tensor import numpy_size_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_view_frnt_
        from ...ivy.functional.frontends.torch.creation_ops import numpy_ones_frnt
        from ..utils.helpers import numpy_safe_solve_with_mask
        from ..utils.helpers import numpy_safe_inverse_with_mask
    
        if numpy_shape_frnt_(points1) != numpy_shape_frnt_(points2):
            raise AssertionError(numpy_shape_frnt_(points1))
        if numpy_shape_frnt_(points1)[1] < 4:
            raise AssertionError(numpy_shape_frnt_(points1))
        numpy_KORNIA_CHECK_SHAPE(points1, ["B", "N", "2"])
        numpy_KORNIA_CHECK_SHAPE(points2, ["B", "N", "2"])
        device, dtype = numpy__extract_device_dtype([points1, points2])
        eps: typing.Any = 1e-08
        points1_norm, transform1 = numpy_normalize_points(points1)
        points2_norm, transform2 = numpy_normalize_points(points2)
        x1, y1 = numpy_chunk_frnt(points1_norm, dim=-1, chunks=2)
        x2, y2 = numpy_chunk_frnt(points2_norm, dim=-1, chunks=2)
        ones, zeros = numpy_ones_like_v_0p4p0_and_above_frnt(x1), numpy_zeros_like_frnt(x1)
        ax = numpy_cat_frnt(
            [zeros, zeros, zeros, -x1, -y1, -ones, y2 * x1, y2 * y1, y2], dim=-1
        )
        ay = numpy_cat_frnt(
            [x1, y1, ones, zeros, zeros, zeros, -x2 * x1, -x2 * y1, -x2], dim=-1
        )
        A = numpy_reshape_frnt_(
            numpy_cat_frnt((ax, ay), dim=-1),
            numpy_shape_frnt_(ax)[0],
            -1,
            numpy_shape_frnt_(ax)[-1],
        )
        if weights is None:
            A = numpy_transpose_frnt_(A, -2, -1) @ A
        else:
            if not (
                len(numpy_shape_frnt_(weights)) == 2
                and numpy_shape_frnt_(weights) == numpy_shape_frnt_(points1)[:2]
            ):
                raise AssertionError(numpy_shape_frnt_(weights))
>           w_diag = numpy_diag_embed_frnt(
                numpy_reshape_frnt_(
                    numpy_repeat_frnt_(numpy_unsqueeze_frnt_(weights, dim=-1), 1, 1, 2),
                    numpy_shape_frnt_(weights)[0],
                    -1,
                )
            )

ivy_transpiled_outputs/numpy_outputs/kornia/geometry/homography.py:94: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = array([[[0.04557866, 0.04557866, 0.7308256 , 0.7308256 , 0.8439256 ,
         0.8439256 , 0.8168471 , 0.8168471 ]]], dtype=float32), offset = 0, dim1 = 1, dim2 = 2

    def numpy_diag_embed_frnt(input, offset=0, dim1=-2, dim2=-1):
        from ...backends.numpy.data_type import numpy_dtype
        from .tensor import numpy_ndim_frnt_
        from .tensor import numpy_shape_frnt_
        from ...backends.numpy.general import numpy_set_item
        from ...backends.numpy.creation import numpy_zeros
        from ...backends.numpy.manipulation import numpy_concat
        from ....data_classes.array.experimental.manipulation import numpy_moveaxis_bknd_
        from ....data_classes.array.manipulation import numpy_expand_dims_bknd_
        from ...backends.numpy.creation import numpy_arange
        from .tensor import numpy_reshape_frnt_
        from .tensor import numpy_logical_and_frnt_
        from ...backends.numpy.searching import numpy_where
        from ....data_classes.array.data_type import numpy_astype_bknd_
    
        def _handle_dim(rank, idx):
            if idx >= 0 and idx < rank:
                return idx
            if idx < 0:
                idx = idx + rank
            if idx < 0 or idx >= rank:
                raise IndexError
            return idx
    
        input_type = numpy_dtype(input)
        rank = numpy_ndim_frnt_(input) + 1
        dim1 = _handle_dim(rank, dim1)
        dim2 = _handle_dim(rank, dim2)
        if dim1 > dim2:
            dim1, dim2 = dim2, dim1
            offset = -offset
        last_dim = list(numpy_shape_frnt_(input))[-1]
        if offset != 0:
            t_shape = list(numpy_shape_frnt_(input))
            t_shape = numpy_set_item(t_shape, -1, abs(offset))
            z = numpy_zeros(t_shape, dtype=input.dtype, device=None)
            pair = (z, input) if offset > 0 else (input, z)
            input = numpy_concat(pair, axis=-1)
            last_dim = last_dim + abs(offset)
        input = numpy_moveaxis_bknd_(numpy_expand_dims_bknd_(input, axis=dim1), -1, dim2)
        a_range = numpy_arange(last_dim, device=None, dtype=np.int64)
        b_range = numpy_arange(offset, last_dim + offset, device=None, dtype=np.int64)
        cond = a_range == numpy_expand_dims_bknd_(b_range, axis=-1)
        ag__result_list_0 = []
        for i in range(len(numpy_shape_frnt_(input))):
            res = last_dim if i in (dim1, dim2) else 1
            ag__result_list_0.append(res)
        cond_shape = ag__result_list_0
        cond = numpy_reshape_frnt_(cond, cond_shape)
>       if input.dtype == np.bool:

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/miscellaneous_ops.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

attr = 'bool'

    def __getattr__(attr):
        # Warn for expired attributes, and return a dummy function
        # that always raises an exception.
        import warnings
        import math
        try:
            msg = __expired_functions__[attr]
        except KeyError:
            pass
        else:
            warnings.warn(msg, DeprecationWarning, stacklevel=2)
    
            def _expired(*args, **kwds):
                raise RuntimeError(msg)
    
            return _expired
    
        # Emit warnings for deprecated attributes
        try:
            val, msg = __deprecated_attrs__[attr]
        except KeyError:
            pass
        else:
            warnings.warn(msg, DeprecationWarning, stacklevel=2)
            return val
    
        if attr in __future_scalars__:
            # And future warnings for those that will change, but also give
            # the AttributeError
            warnings.warn(
                f"In the future `np.{attr}` will be defined as the "
                "corresponding NumPy scalar.", FutureWarning, stacklevel=2)
    
        if attr in __former_attrs__:
>           raise AttributeError(__former_attrs__[attr])
E           AttributeError: module 'numpy' has no attribute 'bool'.
E           `np.bool` was a deprecated alias for the builtin `bool`. To avoid this error in existing code, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
E           The aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:
E               https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations. Did you mean: 'bool_'?

/opt/fw/mxnet/numpy/__init__.py:324: AttributeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.homography.find_homography_dlt
----------------------------------------------------------------------------------------- Captured stderr call -----------------------------------------------------------------------------------------
/ivy/ivy-integration-tests/ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/miscellaneous_ops.py:79: FutureWarning: In the future `np.bool` will be defined as the corresponding NumPy scalar.
  if input.dtype == np.bool:
__________________________________________________________________________ test_find_homography_dlt_iterated[numpy-s2s-False] __________________________________________________________________________

target_framework = 'numpy', mode = 's2s', backend_compile = False

    def test_find_homography_dlt_iterated(target_framework, mode, backend_compile):
        trace_args = (
            torch.rand(1, 4, 2),
            torch.rand(1, 4, 2),
            torch.rand(1, 4),
        )
        trace_kwargs = {'soft_inl_th': 3.0, 'n_iter': 5}
        test_args = (
            torch.rand(5, 4, 2),
            torch.rand(5, 4, 2),
            torch.rand(5, 4),
        )
        test_kwargs = {'soft_inl_th': 4.0, 'n_iter': 5}
>       _test_function(
            kornia.geometry.homography.find_homography_dlt_iterated,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=5e-2,
            mode=mode,
            # NOTE: numerical instability in svd()/lu() leads to logits not being allclose
            deterministic=False,
        )

kornia/geometry/test_homography.py:48: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function find_homography_dlt_iterated at 0x7f8ae2053250>
trace_args = (tensor([[[0.7894, 0.5279],
         [0.5442, 0.7779],
         [0.8117, 0.2043],
         [0.5949, 0.9561]]]), tensor... [0.1067, 0.9845],
         [0.2773, 0.5363],
         [0.6328, 0.6919]]]), tensor([[0.5059, 0.5422, 0.6313, 0.5260]]))
trace_kwargs = {'n_iter': 5, 'soft_inl_th': 3.0}
test_args = (tensor([[[0.0680, 0.0109],
         [0.0165, 0.3515],
         [0.4576, 0.1724],
         [0.7447, 0.6742]],

       ...[0.1666, 0.8047, 0.5719, 0.0582],
        [0.2687, 0.2535, 0.3462, 0.3383],
        [0.8924, 0.9804, 0.8233, 0.2824]]))
test_kwargs = {'n_iter': 5, 'soft_inl_th': 4.0}, target = 'numpy', backend_compile = False, tolerance = 0.05, mode = 's2s', skip = False, deterministic = False, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function find_homography_dlt_iterated at 0x7f8ae2053250>, fn_name = 'kornia.geometry.homography.find_homography_dlt_iterated'
trace_args = (tensor([[[0.7894, 0.5279],
         [0.5442, 0.7779],
         [0.8117, 0.2043],
         [0.5949, 0.9561]]]), tensor... [0.1067, 0.9845],
         [0.2773, 0.5363],
         [0.6328, 0.6919]]]), tensor([[0.5059, 0.5422, 0.6313, 0.5260]]))
trace_kwargs = {'n_iter': 5, 'soft_inl_th': 3.0}
test_args = (tensor([[[0.0680, 0.0109],
         [0.0165, 0.3515],
         [0.4576, 0.1724],
         [0.7447, 0.6742]],

       ...[0.1666, 0.8047, 0.5719, 0.0582],
        [0.2687, 0.2535, 0.3462, 0.3383],
        [0.8924, 0.9804, 0.8233, 0.2824]]))
test_kwargs = {'n_iter': 5, 'soft_inl_th': 4.0}, target = 'numpy', backend_compile = False, tolerance = 0.05, deterministic = False, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:232: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

points1 = array([[[0.7894019 , 0.52789193],
        [0.5442365 , 0.77789736],
        [0.81167996, 0.20431513],
        [0.5948536 , 0.9560611 ]]], dtype=float32)
points2 = array([[[0.0452168 , 0.11327839],
        [0.10671353, 0.98453623],
        [0.2773059 , 0.536321  ],
        [0.63279265, 0.69190603]]], dtype=float32)
weights = array([[0.505918 , 0.5422346, 0.631289 , 0.5260289]], dtype=float32), soft_inl_th = 3.0, n_iter = 5

    def numpy_find_homography_dlt_iterated(
        points1, points2, weights, soft_inl_th=3.0, n_iter=5
    ):
        from ...ivy.functional.frontends.torch.pointwise_ops import numpy_exp_frnt
    
>       H: typing.Any = numpy_find_homography_dlt(points1, points2, weights)

ivy_transpiled_outputs/numpy_outputs/kornia/geometry/homography.py:183: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

points1 = array([[[0.7894019 , 0.52789193],
        [0.5442365 , 0.77789736],
        [0.81167996, 0.20431513],
        [0.5948536 , 0.9560611 ]]], dtype=float32)
points2 = array([[[0.0452168 , 0.11327839],
        [0.10671353, 0.98453623],
        [0.2773059 , 0.536321  ],
        [0.63279265, 0.69190603]]], dtype=float32)
weights = array([[0.505918 , 0.5422346, 0.631289 , 0.5260289]], dtype=float32), solver = 'lu'

    def numpy_find_homography_dlt(points1, points2, weights=None, solver="lu"):
        from ...ivy.functional.frontends.torch.tensor import numpy_shape_frnt_
        from ..core.check import numpy_KORNIA_CHECK_SHAPE
        from ..utils.helpers import numpy__extract_device_dtype
        from .epipolar.fundamental import numpy_normalize_points
        from ...ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            numpy_chunk_frnt,
        )
        from ...ivy.functional.frontends.torch.creation_ops import (
            numpy_ones_like_v_0p4p0_and_above_frnt,
        )
        from ...ivy.functional.frontends.torch.creation_ops import numpy_zeros_like_frnt
        from ...ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            numpy_cat_frnt,
        )
        from ...ivy.functional.frontends.torch.tensor import numpy_reshape_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_transpose_frnt_
        from ...ivy.functional.frontends.torch.miscellaneous_ops import (
            numpy_diag_embed_frnt,
        )
        from ...ivy.functional.frontends.torch.tensor import numpy_repeat_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_unsqueeze_frnt_
        from ..utils.helpers import numpy__torch_svd_cast
        from ...ivy.functional.frontends.torch.creation_ops import numpy_empty_frnt
        from ...ivy.functional.frontends.torch.tensor import numpy_size_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_view_frnt_
        from ...ivy.functional.frontends.torch.creation_ops import numpy_ones_frnt
        from ..utils.helpers import numpy_safe_solve_with_mask
        from ..utils.helpers import numpy_safe_inverse_with_mask
    
        if numpy_shape_frnt_(points1) != numpy_shape_frnt_(points2):
            raise AssertionError(numpy_shape_frnt_(points1))
        if numpy_shape_frnt_(points1)[1] < 4:
            raise AssertionError(numpy_shape_frnt_(points1))
        numpy_KORNIA_CHECK_SHAPE(points1, ["B", "N", "2"])
        numpy_KORNIA_CHECK_SHAPE(points2, ["B", "N", "2"])
        device, dtype = numpy__extract_device_dtype([points1, points2])
        eps: typing.Any = 1e-08
        points1_norm, transform1 = numpy_normalize_points(points1)
        points2_norm, transform2 = numpy_normalize_points(points2)
        x1, y1 = numpy_chunk_frnt(points1_norm, dim=-1, chunks=2)
        x2, y2 = numpy_chunk_frnt(points2_norm, dim=-1, chunks=2)
        ones, zeros = numpy_ones_like_v_0p4p0_and_above_frnt(x1), numpy_zeros_like_frnt(x1)
        ax = numpy_cat_frnt(
            [zeros, zeros, zeros, -x1, -y1, -ones, y2 * x1, y2 * y1, y2], dim=-1
        )
        ay = numpy_cat_frnt(
            [x1, y1, ones, zeros, zeros, zeros, -x2 * x1, -x2 * y1, -x2], dim=-1
        )
        A = numpy_reshape_frnt_(
            numpy_cat_frnt((ax, ay), dim=-1),
            numpy_shape_frnt_(ax)[0],
            -1,
            numpy_shape_frnt_(ax)[-1],
        )
        if weights is None:
            A = numpy_transpose_frnt_(A, -2, -1) @ A
        else:
            if not (
                len(numpy_shape_frnt_(weights)) == 2
                and numpy_shape_frnt_(weights) == numpy_shape_frnt_(points1)[:2]
            ):
                raise AssertionError(numpy_shape_frnt_(weights))
>           w_diag = numpy_diag_embed_frnt(
                numpy_reshape_frnt_(
                    numpy_repeat_frnt_(numpy_unsqueeze_frnt_(weights, dim=-1), 1, 1, 2),
                    numpy_shape_frnt_(weights)[0],
                    -1,
                )
            )

ivy_transpiled_outputs/numpy_outputs/kornia/geometry/homography.py:148: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = array([[[0.505918 , 0.505918 , 0.5422346, 0.5422346, 0.631289 ,
         0.631289 , 0.5260289, 0.5260289]]], dtype=float32), offset = 0, dim1 = 1, dim2 = 2

    def numpy_diag_embed_frnt(input, offset=0, dim1=-2, dim2=-1):
        from ...backends.numpy.data_type import numpy_dtype
        from .tensor import numpy_ndim_frnt_
        from .tensor import numpy_shape_frnt_
        from ...backends.numpy.general import numpy_set_item
        from ...backends.numpy.creation import numpy_zeros
        from ...backends.numpy.manipulation import numpy_concat
        from ....data_classes.array.experimental.manipulation import numpy_moveaxis_bknd_
        from ....data_classes.array.manipulation import numpy_expand_dims_bknd_
        from ...backends.numpy.creation import numpy_arange
        from .tensor import numpy_reshape_frnt_
        from .tensor import numpy_logical_and_frnt_
        from ...backends.numpy.searching import numpy_where
        from ....data_classes.array.data_type import numpy_astype_bknd_
    
        def _handle_dim(rank, idx):
            if idx >= 0 and idx < rank:
                return idx
            if idx < 0:
                idx = idx + rank
            if idx < 0 or idx >= rank:
                raise IndexError
            return idx
    
        input_type = numpy_dtype(input)
        rank = numpy_ndim_frnt_(input) + 1
        dim1 = _handle_dim(rank, dim1)
        dim2 = _handle_dim(rank, dim2)
        if dim1 > dim2:
            dim1, dim2 = dim2, dim1
            offset = -offset
        last_dim = list(numpy_shape_frnt_(input))[-1]
        if offset != 0:
            t_shape = list(numpy_shape_frnt_(input))
            t_shape = numpy_set_item(t_shape, -1, abs(offset))
            z = numpy_zeros(t_shape, dtype=input.dtype, device=None)
            pair = (z, input) if offset > 0 else (input, z)
            input = numpy_concat(pair, axis=-1)
            last_dim = last_dim + abs(offset)
        input = numpy_moveaxis_bknd_(numpy_expand_dims_bknd_(input, axis=dim1), -1, dim2)
        a_range = numpy_arange(last_dim, device=None, dtype=np.int64)
        b_range = numpy_arange(offset, last_dim + offset, device=None, dtype=np.int64)
        cond = a_range == numpy_expand_dims_bknd_(b_range, axis=-1)
        ag__result_list_0 = []
        for i in range(len(numpy_shape_frnt_(input))):
            res = last_dim if i in (dim1, dim2) else 1
            ag__result_list_0.append(res)
        cond_shape = ag__result_list_0
        cond = numpy_reshape_frnt_(cond, cond_shape)
>       if input.dtype == np.bool:

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/miscellaneous_ops.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

attr = 'bool'

    def __getattr__(attr):
        # Warn for expired attributes, and return a dummy function
        # that always raises an exception.
        import warnings
        import math
        try:
            msg = __expired_functions__[attr]
        except KeyError:
            pass
        else:
            warnings.warn(msg, DeprecationWarning, stacklevel=2)
    
            def _expired(*args, **kwds):
                raise RuntimeError(msg)
    
            return _expired
    
        # Emit warnings for deprecated attributes
        try:
            val, msg = __deprecated_attrs__[attr]
        except KeyError:
            pass
        else:
            warnings.warn(msg, DeprecationWarning, stacklevel=2)
            return val
    
        if attr in __future_scalars__:
            # And future warnings for those that will change, but also give
            # the AttributeError
            warnings.warn(
                f"In the future `np.{attr}` will be defined as the "
                "corresponding NumPy scalar.", FutureWarning, stacklevel=2)
    
        if attr in __former_attrs__:
>           raise AttributeError(__former_attrs__[attr])
E           AttributeError: module 'numpy' has no attribute 'bool'.
E           `np.bool` was a deprecated alias for the builtin `bool`. To avoid this error in existing code, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
E           The aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:
E               https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations. Did you mean: 'bool_'?

/opt/fw/mxnet/numpy/__init__.py:324: AttributeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.homography.find_homography_dlt_iterated
----------------------------------------------------------------------------------------- Captured stderr call -----------------------------------------------------------------------------------------
/ivy/ivy-integration-tests/ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/miscellaneous_ops.py:79: FutureWarning: In the future `np.bool` will be defined as the corresponding NumPy scalar.
  if input.dtype == np.bool:
___________________________________________________________________________ test_find_homography_lines_dlt[numpy-s2s-False] ____________________________________________________________________________

target_framework = 'numpy', mode = 's2s', backend_compile = False

    def test_find_homography_lines_dlt(target_framework, mode, backend_compile):
        trace_args = (
            torch.rand(1, 4, 2, 2),
            torch.rand(1, 4, 2, 2),
        )
        trace_kwargs = {'weights': torch.rand(1, 4)}
        test_args = (
            torch.rand(5, 4, 2, 2),
            torch.rand(5, 4, 2, 2),
        )
        test_kwargs = {'weights': torch.rand(5, 4)}
>       _test_function(
            kornia.geometry.homography.find_homography_lines_dlt,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=5e-2,
            mode=mode,
            # NOTE: numerical instability in svd()/lu() leads to logits not being allclose
            deterministic=False,
        )

kornia/geometry/test_homography.py:74: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function find_homography_lines_dlt at 0x7f8ae2053370>
trace_args = (tensor([[[[0.3740, 0.3146],
          [0.3396, 0.0819]],

         [[0.9870, 0.4861],
          [0.2184, 0.5032]],

 ...

         [[0.9399, 0.0118],
          [0.8309, 0.6717]],

         [[0.6717, 0.4652],
          [0.9894, 0.9573]]]]))
trace_kwargs = {'weights': tensor([[0.7713, 0.8733, 0.4738, 0.6597]])}
test_args = (tensor([[[[0.4514, 0.8704],
          [0.2751, 0.7288]],

         [[0.5347, 0.8504],
          [0.6434, 0.6109]],

 ...

         [[0.1308, 0.7851],
          [0.7649, 0.1321]],

         [[0.1489, 0.1842],
          [0.2143, 0.2829]]]]))
test_kwargs = {'weights': tensor([[0.6395, 0.3687, 0.7502, 0.2587],
        [0.3661, 0.5109, 0.0380, 0.7662],
        [0.9543, 0.7644, 0.5347, 0.0061],
        [0.3099, 0.3479, 0.7944, 0.6970],
        [0.4122, 0.5515, 0.1201, 0.9919]])}
target = 'numpy', backend_compile = False, tolerance = 0.05, mode = 's2s', skip = False, deterministic = False, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function find_homography_lines_dlt at 0x7f8ae2053370>, fn_name = 'kornia.geometry.homography.find_homography_lines_dlt'
trace_args = (tensor([[[[0.3740, 0.3146],
          [0.3396, 0.0819]],

         [[0.9870, 0.4861],
          [0.2184, 0.5032]],

 ...

         [[0.9399, 0.0118],
          [0.8309, 0.6717]],

         [[0.6717, 0.4652],
          [0.9894, 0.9573]]]]))
trace_kwargs = {'weights': tensor([[0.7713, 0.8733, 0.4738, 0.6597]])}
test_args = (tensor([[[[0.4514, 0.8704],
          [0.2751, 0.7288]],

         [[0.5347, 0.8504],
          [0.6434, 0.6109]],

 ...

         [[0.1308, 0.7851],
          [0.7649, 0.1321]],

         [[0.1489, 0.1842],
          [0.2143, 0.2829]]]]))
test_kwargs = {'weights': tensor([[0.6395, 0.3687, 0.7502, 0.2587],
        [0.3661, 0.5109, 0.0380, 0.7662],
        [0.9543, 0.7644, 0.5347, 0.0061],
        [0.3099, 0.3479, 0.7944, 0.6970],
        [0.4122, 0.5515, 0.1201, 0.9919]])}
target = 'numpy', backend_compile = False, tolerance = 0.05, deterministic = False, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:232: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

ls1 = array([[[[0.3739884 , 0.31455642],
         [0.339616  , 0.08189768]],

        [[0.9869678 , 0.4860764 ],
         [0...    [0.5902665 , 0.71870655]],

        [[0.7124788 , 0.16868687],
         [0.5510945 , 0.48240274]]]], dtype=float32)
ls2 = array([[[[0.19199085, 0.91729957],
         [0.86581266, 0.84338295]],

        [[0.31669885, 0.7319982 ],
         [0...    [0.83085203, 0.671661  ]],

        [[0.6716524 , 0.46522552],
         [0.9894122 , 0.95732653]]]], dtype=float32)
weights = array([[0.7712564 , 0.8732895 , 0.4737535 , 0.65970117]], dtype=float32)

    def numpy_find_homography_lines_dlt(ls1, ls2, weights=None):
        from ...ivy.functional.frontends.torch.tensor import numpy_shape_frnt_
        from ..core.check import numpy_KORNIA_CHECK_SHAPE
        from ..utils.helpers import numpy__extract_device_dtype
        from ...ivy.functional.frontends.torch.tensor import numpy_reshape_frnt_
        from .epipolar.fundamental import numpy_normalize_points
        from ...ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            numpy_chunk_frnt,
        )
        from ...ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            numpy_cat_frnt,
        )
        from ...ivy.functional.frontends.torch.tensor import numpy_transpose_frnt_
        from ...ivy.functional.frontends.torch.miscellaneous_ops import (
            numpy_diag_embed_frnt,
        )
        from ...ivy.functional.frontends.torch.tensor import numpy_repeat_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_unsqueeze_frnt_
        from ..utils.helpers import numpy__torch_svd_cast
        from ...ivy.functional.frontends.torch.creation_ops import numpy_empty_frnt
        from ...ivy.functional.frontends.torch.tensor import numpy_size_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_view_frnt_
        from ..utils.helpers import numpy_safe_inverse_with_mask
    
        if len(numpy_shape_frnt_(ls1)) == 3:
            ls1 = ls1[None]
        if len(numpy_shape_frnt_(ls2)) == 3:
            ls2 = ls2[None]
        numpy_KORNIA_CHECK_SHAPE(ls1, ["B", "N", "2", "2"])
        numpy_KORNIA_CHECK_SHAPE(ls2, ["B", "N", "2", "2"])
        BS, N = numpy_shape_frnt_(ls1)[:2][0], numpy_shape_frnt_(ls1)[:2][1]
        device, dtype = numpy__extract_device_dtype([ls1, ls2])
        points1 = numpy_reshape_frnt_(ls1, BS, 2 * N, 2)
        points2 = numpy_reshape_frnt_(ls2, BS, 2 * N, 2)
        points1_norm, transform1 = numpy_normalize_points(points1)
        points2_norm, transform2 = numpy_normalize_points(points2)
        lst1, le1 = numpy_chunk_frnt(points1_norm, dim=1, chunks=2)
        lst2, le2 = numpy_chunk_frnt(points2_norm, dim=1, chunks=2)
        xs1, ys1 = numpy_chunk_frnt(lst1, dim=-1, chunks=2)
        xs2, ys2 = numpy_chunk_frnt(lst2, dim=-1, chunks=2)
        xe1, ye1 = numpy_chunk_frnt(le1, dim=-1, chunks=2)
        xe2, ye2 = numpy_chunk_frnt(le2, dim=-1, chunks=2)
        A = ys2 - ye2
        B = xe2 - xs2
        C = xs2 * ye2 - xe2 * ys2
        eps: typing.Any = 1e-08
        ax = numpy_cat_frnt(
            [A * xs1, A * ys1, A, B * xs1, B * ys1, B, C * xs1, C * ys1, C], dim=-1
        )
        ay = numpy_cat_frnt(
            [A * xe1, A * ye1, A, B * xe1, B * ye1, B, C * xe1, C * ye1, C], dim=-1
        )
        A = numpy_reshape_frnt_(
            numpy_cat_frnt((ax, ay), dim=-1),
            numpy_shape_frnt_(ax)[0],
            -1,
            numpy_shape_frnt_(ax)[-1],
        )
        if weights is None:
            A = numpy_transpose_frnt_(A, -2, -1) @ A
        else:
            if not (
                len(numpy_shape_frnt_(weights)) == 2
                and numpy_shape_frnt_(weights) == numpy_shape_frnt_(ls1)[:2]
            ):
                raise AssertionError(numpy_shape_frnt_(weights))
>           w_diag = numpy_diag_embed_frnt(
                numpy_reshape_frnt_(
                    numpy_repeat_frnt_(numpy_unsqueeze_frnt_(weights, dim=-1), 1, 1, 2),
                    numpy_shape_frnt_(weights)[0],
                    -1,
                )
            )

ivy_transpiled_outputs/numpy_outputs/kornia/geometry/homography.py:97: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = array([[[0.7712564 , 0.7712564 , 0.8732895 , 0.8732895 , 0.4737535 ,
         0.4737535 , 0.65970117, 0.65970117]]], dtype=float32), offset = 0, dim1 = 1, dim2 = 2

    def numpy_diag_embed_frnt(input, offset=0, dim1=-2, dim2=-1):
        from ...backends.numpy.data_type import numpy_dtype
        from .tensor import numpy_ndim_frnt_
        from .tensor import numpy_shape_frnt_
        from ...backends.numpy.general import numpy_set_item
        from ...backends.numpy.creation import numpy_zeros
        from ...backends.numpy.manipulation import numpy_concat
        from ....data_classes.array.experimental.manipulation import numpy_moveaxis_bknd_
        from ....data_classes.array.manipulation import numpy_expand_dims_bknd_
        from ...backends.numpy.creation import numpy_arange
        from .tensor import numpy_reshape_frnt_
        from .tensor import numpy_logical_and_frnt_
        from ...backends.numpy.searching import numpy_where
        from ....data_classes.array.data_type import numpy_astype_bknd_
    
        def _handle_dim(rank, idx):
            if idx >= 0 and idx < rank:
                return idx
            if idx < 0:
                idx = idx + rank
            if idx < 0 or idx >= rank:
                raise IndexError
            return idx
    
        input_type = numpy_dtype(input)
        rank = numpy_ndim_frnt_(input) + 1
        dim1 = _handle_dim(rank, dim1)
        dim2 = _handle_dim(rank, dim2)
        if dim1 > dim2:
            dim1, dim2 = dim2, dim1
            offset = -offset
        last_dim = list(numpy_shape_frnt_(input))[-1]
        if offset != 0:
            t_shape = list(numpy_shape_frnt_(input))
            t_shape = numpy_set_item(t_shape, -1, abs(offset))
            z = numpy_zeros(t_shape, dtype=input.dtype, device=None)
            pair = (z, input) if offset > 0 else (input, z)
            input = numpy_concat(pair, axis=-1)
            last_dim = last_dim + abs(offset)
        input = numpy_moveaxis_bknd_(numpy_expand_dims_bknd_(input, axis=dim1), -1, dim2)
        a_range = numpy_arange(last_dim, device=None, dtype=np.int64)
        b_range = numpy_arange(offset, last_dim + offset, device=None, dtype=np.int64)
        cond = a_range == numpy_expand_dims_bknd_(b_range, axis=-1)
        ag__result_list_0 = []
        for i in range(len(numpy_shape_frnt_(input))):
            res = last_dim if i in (dim1, dim2) else 1
            ag__result_list_0.append(res)
        cond_shape = ag__result_list_0
        cond = numpy_reshape_frnt_(cond, cond_shape)
>       if input.dtype == np.bool:

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/miscellaneous_ops.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

attr = 'bool'

    def __getattr__(attr):
        # Warn for expired attributes, and return a dummy function
        # that always raises an exception.
        import warnings
        import math
        try:
            msg = __expired_functions__[attr]
        except KeyError:
            pass
        else:
            warnings.warn(msg, DeprecationWarning, stacklevel=2)
    
            def _expired(*args, **kwds):
                raise RuntimeError(msg)
    
            return _expired
    
        # Emit warnings for deprecated attributes
        try:
            val, msg = __deprecated_attrs__[attr]
        except KeyError:
            pass
        else:
            warnings.warn(msg, DeprecationWarning, stacklevel=2)
            return val
    
        if attr in __future_scalars__:
            # And future warnings for those that will change, but also give
            # the AttributeError
            warnings.warn(
                f"In the future `np.{attr}` will be defined as the "
                "corresponding NumPy scalar.", FutureWarning, stacklevel=2)
    
        if attr in __former_attrs__:
>           raise AttributeError(__former_attrs__[attr])
E           AttributeError: module 'numpy' has no attribute 'bool'.
E           `np.bool` was a deprecated alias for the builtin `bool`. To avoid this error in existing code, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
E           The aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:
E               https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations. Did you mean: 'bool_'?

/opt/fw/mxnet/numpy/__init__.py:324: AttributeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.homography.find_homography_lines_dlt
----------------------------------------------------------------------------------------- Captured stderr call -----------------------------------------------------------------------------------------
/ivy/ivy-integration-tests/ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/miscellaneous_ops.py:79: FutureWarning: In the future `np.bool` will be defined as the corresponding NumPy scalar.
  if input.dtype == np.bool:
_______________________________________________________________________ test_find_homography_lines_dlt_iterated[numpy-s2s-False] _______________________________________________________________________

target_framework = 'numpy', mode = 's2s', backend_compile = False

    def test_find_homography_lines_dlt_iterated(target_framework, mode, backend_compile):
        trace_args = (
            torch.rand(1, 4, 2, 2),
            torch.rand(1, 4, 2, 2),
            torch.rand(1, 4),
        )
        trace_kwargs = {'soft_inl_th': 4.0, 'n_iter': 5}
        test_args = (
            torch.rand(5, 4, 2, 2),
            torch.rand(5, 4, 2, 2),
            torch.rand(5, 4),
        )
        test_kwargs = {'soft_inl_th': 3.0, 'n_iter': 5}
>       _test_function(
            kornia.geometry.homography.find_homography_lines_dlt_iterated,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=5e-2,
            mode=mode,
            # NOTE: numerical instability in svd()/lu() leads to logits not being allclose
            deterministic=False,
        )

kornia/geometry/test_homography.py:102: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function find_homography_lines_dlt_iterated at 0x7f8ae2053490>
trace_args = (tensor([[[[0.8596, 0.6319],
          [0.7840, 0.3946]],

         [[0.6082, 0.5176],
          [0.3119, 0.1293]],

 ...603, 0.3275]],

         [[0.4569, 0.1504],
          [0.0337, 0.4369]]]]), tensor([[0.9282, 0.5700, 0.6957, 0.0656]]))
trace_kwargs = {'n_iter': 5, 'soft_inl_th': 4.0}
test_args = (tensor([[[[0.2128, 0.4307],
          [0.2358, 0.0256]],

         [[0.3055, 0.9111],
          [0.2817, 0.9276]],

 ...[0.0488, 0.3083, 0.9832, 0.0359],
        [0.5965, 0.1162, 0.4397, 0.9146],
        [0.1132, 0.9466, 0.9490, 0.8341]]))
test_kwargs = {'n_iter': 5, 'soft_inl_th': 3.0}, target = 'numpy', backend_compile = False, tolerance = 0.05, mode = 's2s', skip = False, deterministic = False, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function find_homography_lines_dlt_iterated at 0x7f8ae2053490>, fn_name = 'kornia.geometry.homography.find_homography_lines_dlt_iterated'
trace_args = (tensor([[[[0.8596, 0.6319],
          [0.7840, 0.3946]],

         [[0.6082, 0.5176],
          [0.3119, 0.1293]],

 ...603, 0.3275]],

         [[0.4569, 0.1504],
          [0.0337, 0.4369]]]]), tensor([[0.9282, 0.5700, 0.6957, 0.0656]]))
trace_kwargs = {'n_iter': 5, 'soft_inl_th': 4.0}
test_args = (tensor([[[[0.2128, 0.4307],
          [0.2358, 0.0256]],

         [[0.3055, 0.9111],
          [0.2817, 0.9276]],

 ...[0.0488, 0.3083, 0.9832, 0.0359],
        [0.5965, 0.1162, 0.4397, 0.9146],
        [0.1132, 0.9466, 0.9490, 0.8341]]))
test_kwargs = {'n_iter': 5, 'soft_inl_th': 3.0}, target = 'numpy', backend_compile = False, tolerance = 0.05, deterministic = False, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:232: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

ls1 = array([[[[0.8596425 , 0.6318557 ],
         [0.7840128 , 0.39462548]],

        [[0.60819495, 0.51761174],
         [0...    [0.14978927, 0.10113901]],

        [[0.59753734, 0.3701409 ],
         [0.68864393, 0.16774881]]]], dtype=float32)
ls2 = array([[[[0.91464174, 0.58212656],
         [0.5179722 , 0.17674208]],

        [[0.40333658, 0.42232025],
         [0...    [0.16029483, 0.32745743]],

        [[0.4568674 , 0.15039957],
         [0.03367478, 0.4368776 ]]]], dtype=float32)
weights = array([[0.9281878 , 0.56997436, 0.69566035, 0.06560528]], dtype=float32), soft_inl_th = 4.0, n_iter = 5

    def numpy_find_homography_lines_dlt_iterated(
        ls1, ls2, weights, soft_inl_th=4.0, n_iter=5
    ):
        from ...ivy.functional.frontends.torch.pointwise_ops import numpy_exp_frnt
    
>       H: typing.Any = numpy_find_homography_lines_dlt(ls1, ls2, weights)

ivy_transpiled_outputs/numpy_outputs/kornia/geometry/homography.py:159: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

ls1 = array([[[[0.8596425 , 0.6318557 ],
         [0.7840128 , 0.39462548]],

        [[0.60819495, 0.51761174],
         [0...    [0.14978927, 0.10113901]],

        [[0.59753734, 0.3701409 ],
         [0.68864393, 0.16774881]]]], dtype=float32)
ls2 = array([[[[0.91464174, 0.58212656],
         [0.5179722 , 0.17674208]],

        [[0.40333658, 0.42232025],
         [0...    [0.16029483, 0.32745743]],

        [[0.4568674 , 0.15039957],
         [0.03367478, 0.4368776 ]]]], dtype=float32)
weights = array([[0.9281878 , 0.56997436, 0.69566035, 0.06560528]], dtype=float32)

    def numpy_find_homography_lines_dlt(ls1, ls2, weights=None):
        from ...ivy.functional.frontends.torch.tensor import numpy_shape_frnt_
        from ..core.check import numpy_KORNIA_CHECK_SHAPE
        from ..utils.helpers import numpy__extract_device_dtype
        from ...ivy.functional.frontends.torch.tensor import numpy_reshape_frnt_
        from .epipolar.fundamental import numpy_normalize_points
        from ...ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            numpy_chunk_frnt,
        )
        from ...ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            numpy_cat_frnt,
        )
        from ...ivy.functional.frontends.torch.tensor import numpy_transpose_frnt_
        from ...ivy.functional.frontends.torch.miscellaneous_ops import (
            numpy_diag_embed_frnt,
        )
        from ...ivy.functional.frontends.torch.tensor import numpy_repeat_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_unsqueeze_frnt_
        from ..utils.helpers import numpy__torch_svd_cast
        from ...ivy.functional.frontends.torch.creation_ops import numpy_empty_frnt
        from ...ivy.functional.frontends.torch.tensor import numpy_size_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_view_frnt_
        from ..utils.helpers import numpy_safe_inverse_with_mask
    
        if len(numpy_shape_frnt_(ls1)) == 3:
            ls1 = ls1[None]
        if len(numpy_shape_frnt_(ls2)) == 3:
            ls2 = ls2[None]
        numpy_KORNIA_CHECK_SHAPE(ls1, ["B", "N", "2", "2"])
        numpy_KORNIA_CHECK_SHAPE(ls2, ["B", "N", "2", "2"])
        BS, N = numpy_shape_frnt_(ls1)[:2][0], numpy_shape_frnt_(ls1)[:2][1]
        device, dtype = numpy__extract_device_dtype([ls1, ls2])
        points1 = numpy_reshape_frnt_(ls1, BS, 2 * N, 2)
        points2 = numpy_reshape_frnt_(ls2, BS, 2 * N, 2)
        points1_norm, transform1 = numpy_normalize_points(points1)
        points2_norm, transform2 = numpy_normalize_points(points2)
        lst1, le1 = numpy_chunk_frnt(points1_norm, dim=1, chunks=2)
        lst2, le2 = numpy_chunk_frnt(points2_norm, dim=1, chunks=2)
        xs1, ys1 = numpy_chunk_frnt(lst1, dim=-1, chunks=2)
        xs2, ys2 = numpy_chunk_frnt(lst2, dim=-1, chunks=2)
        xe1, ye1 = numpy_chunk_frnt(le1, dim=-1, chunks=2)
        xe2, ye2 = numpy_chunk_frnt(le2, dim=-1, chunks=2)
        A = ys2 - ye2
        B = xe2 - xs2
        C = xs2 * ye2 - xe2 * ys2
        eps: typing.Any = 1e-08
        ax = numpy_cat_frnt(
            [A * xs1, A * ys1, A, B * xs1, B * ys1, B, C * xs1, C * ys1, C], dim=-1
        )
        ay = numpy_cat_frnt(
            [A * xe1, A * ye1, A, B * xe1, B * ye1, B, C * xe1, C * ye1, C], dim=-1
        )
        A = numpy_reshape_frnt_(
            numpy_cat_frnt((ax, ay), dim=-1),
            numpy_shape_frnt_(ax)[0],
            -1,
            numpy_shape_frnt_(ax)[-1],
        )
        if weights is None:
            A = numpy_transpose_frnt_(A, -2, -1) @ A
        else:
            if not (
                len(numpy_shape_frnt_(weights)) == 2
                and numpy_shape_frnt_(weights) == numpy_shape_frnt_(ls1)[:2]
            ):
                raise AssertionError(numpy_shape_frnt_(weights))
>           w_diag = numpy_diag_embed_frnt(
                numpy_reshape_frnt_(
                    numpy_repeat_frnt_(numpy_unsqueeze_frnt_(weights, dim=-1), 1, 1, 2),
                    numpy_shape_frnt_(weights)[0],
                    -1,
                )
            )

ivy_transpiled_outputs/numpy_outputs/kornia/geometry/homography.py:133: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = array([[[0.9281878 , 0.9281878 , 0.56997436, 0.56997436, 0.69566035,
         0.69566035, 0.06560528, 0.06560528]]], dtype=float32), offset = 0, dim1 = 1, dim2 = 2

    def numpy_diag_embed_frnt(input, offset=0, dim1=-2, dim2=-1):
        from ...backends.numpy.data_type import numpy_dtype
        from .tensor import numpy_ndim_frnt_
        from .tensor import numpy_shape_frnt_
        from ...backends.numpy.general import numpy_set_item
        from ...backends.numpy.creation import numpy_zeros
        from ...backends.numpy.manipulation import numpy_concat
        from ....data_classes.array.experimental.manipulation import numpy_moveaxis_bknd_
        from ....data_classes.array.manipulation import numpy_expand_dims_bknd_
        from ...backends.numpy.creation import numpy_arange
        from .tensor import numpy_reshape_frnt_
        from .tensor import numpy_logical_and_frnt_
        from ...backends.numpy.searching import numpy_where
        from ....data_classes.array.data_type import numpy_astype_bknd_
    
        def _handle_dim(rank, idx):
            if idx >= 0 and idx < rank:
                return idx
            if idx < 0:
                idx = idx + rank
            if idx < 0 or idx >= rank:
                raise IndexError
            return idx
    
        input_type = numpy_dtype(input)
        rank = numpy_ndim_frnt_(input) + 1
        dim1 = _handle_dim(rank, dim1)
        dim2 = _handle_dim(rank, dim2)
        if dim1 > dim2:
            dim1, dim2 = dim2, dim1
            offset = -offset
        last_dim = list(numpy_shape_frnt_(input))[-1]
        if offset != 0:
            t_shape = list(numpy_shape_frnt_(input))
            t_shape = numpy_set_item(t_shape, -1, abs(offset))
            z = numpy_zeros(t_shape, dtype=input.dtype, device=None)
            pair = (z, input) if offset > 0 else (input, z)
            input = numpy_concat(pair, axis=-1)
            last_dim = last_dim + abs(offset)
        input = numpy_moveaxis_bknd_(numpy_expand_dims_bknd_(input, axis=dim1), -1, dim2)
        a_range = numpy_arange(last_dim, device=None, dtype=np.int64)
        b_range = numpy_arange(offset, last_dim + offset, device=None, dtype=np.int64)
        cond = a_range == numpy_expand_dims_bknd_(b_range, axis=-1)
        ag__result_list_0 = []
        for i in range(len(numpy_shape_frnt_(input))):
            res = last_dim if i in (dim1, dim2) else 1
            ag__result_list_0.append(res)
        cond_shape = ag__result_list_0
        cond = numpy_reshape_frnt_(cond, cond_shape)
>       if input.dtype == np.bool:

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/miscellaneous_ops.py:91: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

attr = 'bool'

    def __getattr__(attr):
        # Warn for expired attributes, and return a dummy function
        # that always raises an exception.
        import warnings
        import math
        try:
            msg = __expired_functions__[attr]
        except KeyError:
            pass
        else:
            warnings.warn(msg, DeprecationWarning, stacklevel=2)
    
            def _expired(*args, **kwds):
                raise RuntimeError(msg)
    
            return _expired
    
        # Emit warnings for deprecated attributes
        try:
            val, msg = __deprecated_attrs__[attr]
        except KeyError:
            pass
        else:
            warnings.warn(msg, DeprecationWarning, stacklevel=2)
            return val
    
        if attr in __future_scalars__:
            # And future warnings for those that will change, but also give
            # the AttributeError
            warnings.warn(
                f"In the future `np.{attr}` will be defined as the "
                "corresponding NumPy scalar.", FutureWarning, stacklevel=2)
    
        if attr in __former_attrs__:
>           raise AttributeError(__former_attrs__[attr])
E           AttributeError: module 'numpy' has no attribute 'bool'.
E           `np.bool` was a deprecated alias for the builtin `bool`. To avoid this error in existing code, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
E           The aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:
E               https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations. Did you mean: 'bool_'?

/opt/fw/mxnet/numpy/__init__.py:324: AttributeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.homography.find_homography_lines_dlt_iterated
----------------------------------------------------------------------------------------- Captured stderr call -----------------------------------------------------------------------------------------
/ivy/ivy-integration-tests/ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/miscellaneous_ops.py:91: FutureWarning: In the future `np.bool` will be defined as the corresponding NumPy scalar.
_____________________________________________________________________________ test_oneway_transfer_error[numpy-s2s-False] ______________________________________________________________________________

target_framework = 'numpy', mode = 's2s', backend_compile = False

    def test_oneway_transfer_error(target_framework, mode, backend_compile):
        trace_args = (
            torch.rand(1, 4, 2),
            torch.rand(1, 4, 2),
            torch.rand(1, 3, 3),
        )
        trace_kwargs = {'squared': False, 'eps': 1e-8}
        test_args = (
            torch.rand(5, 4, 2),
            torch.rand(5, 4, 2),
            torch.rand(5, 3, 3),
        )
        test_kwargs = {'squared': False, 'eps': 1e-7}
>       _test_function(
            kornia.geometry.homography.oneway_transfer_error,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/geometry/test_homography.py:156: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function oneway_transfer_error at 0x7f8ae2052ef0>
trace_args = (tensor([[[0.4623, 0.5767],
         [0.0092, 0.8885],
         [0.5755, 0.4852],
         [0.8892, 0.8236]]]), tensor...0.6985]]]), tensor([[[0.6323, 0.4739, 0.6318],
         [0.1689, 0.8442, 0.1504],
         [0.8191, 0.7219, 0.1024]]]))
trace_kwargs = {'eps': 1e-08, 'squared': False}
test_args = (tensor([[[0.4193, 0.8885],
         [0.8432, 0.7103],
         [0.6069, 0.0217],
         [0.2763, 0.9459]],

       ... 0.8162]],

        [[0.7712, 0.1131, 0.3501],
         [0.3551, 0.4823, 0.5566],
         [0.2148, 0.4950, 0.9960]]]))
test_kwargs = {'eps': 1e-07, 'squared': False}, target = 'numpy', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function oneway_transfer_error at 0x7f8ae2052ef0>, fn_name = 'kornia.geometry.homography.oneway_transfer_error'
trace_args = (tensor([[[0.4623, 0.5767],
         [0.0092, 0.8885],
         [0.5755, 0.4852],
         [0.8892, 0.8236]]]), tensor...0.6985]]]), tensor([[[0.6323, 0.4739, 0.6318],
         [0.1689, 0.8442, 0.1504],
         [0.8191, 0.7219, 0.1024]]]))
trace_kwargs = {'eps': 1e-08, 'squared': False}
test_args = (tensor([[[0.4193, 0.8885],
         [0.8432, 0.7103],
         [0.6069, 0.0217],
         [0.2763, 0.9459]],

       ... 0.8162]],

        [[0.7712, 0.1131, 0.3501],
         [0.3551, 0.4823, 0.5566],
         [0.2148, 0.4950, 0.9960]]]))
test_kwargs = {'eps': 1e-07, 'squared': False}, target = 'numpy', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:232: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pts1 = array([[[0.462263  , 0.576698  ],
        [0.00917059, 0.8884914 ],
        [0.57551205, 0.4851576 ],
        [0.8892311 , 0.82361174]]], dtype=float32)
pts2 = array([[[0.18757945, 0.8290793 ],
        [0.25255477, 0.01577801],
        [0.10446304, 0.76368636],
        [0.14183569, 0.6984577 ]]], dtype=float32)
H = array([[[0.63229775, 0.47385293, 0.63183993],
        [0.16885483, 0.8442236 , 0.15039933],
        [0.8190651 , 0.7218809 , 0.10242444]]], dtype=float32), squared = False, eps = 1e-08

    def numpy_oneway_transfer_error(pts1, pts2, H, squared=True, eps=1e-08):
        from ..core.check import numpy_KORNIA_CHECK_SHAPE
        from ...ivy.functional.frontends.torch.tensor import numpy_size_frnt_
        from .conversions import numpy_convert_points_from_homogeneous
        from .linalg import numpy_transform_points
        from ...ivy.functional.frontends.torch.tensor import numpy_sum_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_pow_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_sqrt_frnt_
    
        numpy_KORNIA_CHECK_SHAPE(H, ["B", "3", "3"])
        if numpy_size_frnt_(pts1, -1) == 3:
            pts1 = numpy_convert_points_from_homogeneous(pts1)
        if numpy_size_frnt_(pts2, -1) == 3:
            pts2 = numpy_convert_points_from_homogeneous(pts2)
        pts1_in_2: typing.Any = numpy_transform_points(H, pts1)
        error_squared: typing.Any = numpy_sum_frnt_(
>           numpy_pow_frnt_(pts1_in_2 - pts2, 2), dim=-1
        )

ivy_transpiled_outputs/numpy_outputs/kornia/geometry/homography.py:46: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (array([[[ 1.1467838e+00, -3.1940341e-02],
        [ 1.1565009e+00,  1.1848187e+00],
        [ 1.2219279e+00, -5.2500427e-02],
        [ 9.6975923e-01,  2.4032593e-04]]], dtype=float32), 2)
kwargs = {}, numpy_is_array_bknd = <function numpy_is_array_bknd at 0x7f8a889e17e0>
array_like = array([[[ 1.1467838e+00, -3.1940341e-02],
        [ 1.1565009e+00,  1.1848187e+00],
        [ 1.2219279e+00, -5.2500427e-02],
        [ 9.6975923e-01,  2.4032593e-04]]], dtype=float32)

    @functools.wraps(fn)
    def wrapper(*args, **kwargs):
        from ..functional.ivy.general import numpy_is_array_bknd
    
        array_like = args[0]
        if hasattr(array_like, "__class__") and array_like.__class__.__name__ in [
            "list",
            "tuple",
        ]:
            array_like = array_like[0]
        if numpy_is_array_bknd(array_like):
>           return fn(*args, **kwargs)

ivy_transpiled_outputs/numpy_outputs/ivy/utils/decorator_utils.py:200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = array([[[ 1.1467838e+00, -3.1940341e-02],
        [ 1.1565009e+00,  1.1848187e+00],
        [ 1.2219279e+00, -5.2500427e-02],
        [ 9.6975923e-01,  2.4032593e-04]]], dtype=float32)
exponent = 2

    @numpy_handle_methods
    def numpy_pow_frnt_(tensor, exponent):
        from .pointwise_ops import numpy_pow_frnt
    
>       return numpy_pow_frnt(tensor, exponent)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/tensor.py:201: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (array([[[ 1.1467838e+00, -3.1940341e-02],
        [ 1.1565009e+00,  1.1848187e+00],
        [ 1.2219279e+00, -5.2500427e-02],
        [ 9.6975923e-01,  2.4032593e-04]]], dtype=float32), 2)
kwargs = {}, numpy_is_array_bknd = <function numpy_is_array_bknd at 0x7f8a889e17e0>
array_like = array([[[ 1.1467838e+00, -3.1940341e-02],
        [ 1.1565009e+00,  1.1848187e+00],
        [ 1.2219279e+00, -5.2500427e-02],
        [ 9.6975923e-01,  2.4032593e-04]]], dtype=float32)

    @functools.wraps(fn)
    def wrapper(*args, **kwargs):
        from ..functional.ivy.general import numpy_is_array_bknd
    
        array_like = args[0]
        if hasattr(array_like, "__class__") and array_like.__class__.__name__ in [
            "list",
            "tuple",
        ]:
            array_like = array_like[0]
        if numpy_is_array_bknd(array_like):
>           return fn(*args, **kwargs)

ivy_transpiled_outputs/numpy_outputs/ivy/utils/decorator_utils.py:200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = array([[[ 1.1467838e+00, -3.1940341e-02],
        [ 1.1565009e+00,  1.1848187e+00],
        [ 1.2219279e+00, -5.2500427e-02],
        [ 9.6975923e-01,  2.4032593e-04]]], dtype=float32)
exponent = array(2)

    @numpy_handle_methods
    def numpy_pow_frnt(input, exponent, *, out=None):
        from ...ivy.general import numpy_is_array_bknd
        from .creation_ops import numpy_as_tensor_frnt
        from ...backends.numpy.creation import numpy_asarray
        from .__init__ import numpy_promote_types_of_torch_inputs_frnt
        from ...ivy.data_type import numpy_is_int_dtype_bknd
        from ...backends.numpy.elementwise import numpy_pow
        from ...backends.numpy.utility import numpy_any
        from ...backends.numpy.searching import numpy_where
        from ...backends.numpy.elementwise import numpy_bitwise_and
        from ....data_classes.array.data_type import numpy_astype_bknd_
    
        if not numpy_is_array_bknd(input):
            input = numpy_as_tensor_frnt(input)
        if not numpy_is_array_bknd(exponent):
            if (
                any(dtype in str(input.dtype) for dtype in ["int8", "int16"])
                and isinstance(exponent, (int,))
                or "float16" in str(input.dtype)
                and isinstance(exponent, (float,))
            ):
                exponent = numpy_asarray(exponent, dtype=input.dtype)
            else:
                exponent = numpy_as_tensor_frnt(exponent)
>       input, exponent = numpy_promote_types_of_torch_inputs_frnt(input, exponent)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/pointwise_ops.py:97: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x1 = array([[[ 1.1467838e+00, -3.1940341e-02],
        [ 1.1565009e+00,  1.1848187e+00],
        [ 1.2219279e+00, -5.2500427e-02],
        [ 9.6975923e-01,  2.4032593e-04]]], dtype=float32)
x2 = array(2)

    def numpy_promote_types_of_torch_inputs_frnt(x1, x2, /):
        from ...ivy.general import numpy_isscalar_bknd
        from ...ivy.data_type import numpy_is_int_dtype_bknd
        from ...backends.numpy.creation import numpy_asarray
        from ...ivy.data_type import numpy_default_dtype_bknd
        from .tensor import numpy_shape_frnt_
        from ...ivy.device import numpy_default_device_bknd
        from ....data_classes.array.data_type import numpy_astype_bknd_
    
        """Promote the dtype of the given native array inputs to a common dtype
        based on type promotion rules.
    
        While passing float or integer values or any other non-array input
        to this function, it should be noted that the return will be an
        array-like object. Therefore, outputs from this function should be
        used as inputs only for those functions that expect an array-like or
        tensor-like objects, otherwise it might give unexpected results.
        """
        if (
            numpy_isscalar_bknd(x1) or isinstance(x1, (list, tuple))
        ) and numpy_is_int_dtype_bknd(x1):
            x1 = numpy_asarray(x1, dtype="int64")
        elif numpy_isscalar_bknd(x1) or isinstance(x1, (list, tuple)):
            x1 = numpy_asarray(x1)
        if (
            numpy_isscalar_bknd(x2) or isinstance(x2, (list, tuple))
        ) and numpy_is_int_dtype_bknd(x2):
            x2 = numpy_asarray(x2, dtype="int64")
        elif numpy_isscalar_bknd(x2) or isinstance(x2, (list, tuple)):
            x2 = numpy_asarray(x2)
        type1 = numpy_default_dtype_bknd(item=x1).strip("u123456789")
        type2 = numpy_default_dtype_bknd(item=x2).strip("u123456789")
        if numpy_shape_frnt_(x1) != () and numpy_shape_frnt_(x2) == () and type1 == type2:
            x2 = numpy_asarray(
                x2,
                dtype=x1.dtype,
                device=numpy_default_device_bknd(item=x1, as_native=False),
            )
        elif numpy_shape_frnt_(x1) == () and numpy_shape_frnt_(x2) != () and type1 == type2:
            x1 = numpy_asarray(
                x1,
                dtype=x2.dtype,
                device=numpy_default_device_bknd(item=x2, as_native=False),
            )
        elif x1.dtype != x2.dtype:
>           promoted = numpy_promote_types_torch_frnt(x1.dtype, x2.dtype)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/__init__.py:87: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

type1 = dtype('float32'), type2 = dtype('int64')

    def numpy_promote_types_torch_frnt(type1, type2, /):
        from ...backends.numpy.general import numpy_get_item
        from ...backends.numpy.data_type import numpy_as_ivy_dtype
    
        try:
            ret = numpy_get_item(
>               torch_promotion_table,
                (numpy_as_ivy_dtype(type1), numpy_as_ivy_dtype(type2)),
            )
E           NameError: name 'torch_promotion_table' is not defined

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/__init__.py:34: NameError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.homography.oneway_transfer_error
____________________________________________________________________________ test_symmetric_transfer_error[numpy-s2s-False] ____________________________________________________________________________

target_framework = 'numpy', mode = 's2s', backend_compile = False

    def test_symmetric_transfer_error(target_framework, mode, backend_compile):
        trace_args = (
            torch.rand(1, 4, 2),
            torch.rand(1, 4, 2),
            torch.rand(1, 3, 3),
        )
        trace_kwargs = {'squared': True, 'eps': 1e-8}
        test_args = (
            torch.rand(5, 4, 2),
            torch.rand(5, 4, 2),
            torch.rand(5, 3, 3),
        )
        test_kwargs = {'squared': True, 'eps': 1e-7}
>       _test_function(
            kornia.geometry.homography.symmetric_transfer_error,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/geometry/test_homography.py:206: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function symmetric_transfer_error at 0x7f8ae2053010>
trace_args = (tensor([[[0.3804, 0.7056],
         [0.1680, 0.8354],
         [0.0176, 0.1859],
         [0.5946, 0.1057]]]), tensor...0.2935]]]), tensor([[[0.1577, 0.5943, 0.5942],
         [0.9071, 0.4486, 0.8904],
         [0.5988, 0.3435, 0.5255]]]))
trace_kwargs = {'eps': 1e-08, 'squared': True}
test_args = (tensor([[[0.6646, 0.8546],
         [0.4872, 0.2097],
         [0.0273, 0.4705],
         [0.3863, 0.7562]],

       ... 0.7880]],

        [[0.9877, 0.3981, 0.6683],
         [0.4541, 0.7184, 0.0339],
         [0.3231, 0.7454, 0.3729]]]))
test_kwargs = {'eps': 1e-07, 'squared': True}, target = 'numpy', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function symmetric_transfer_error at 0x7f8ae2053010>, fn_name = 'kornia.geometry.homography.symmetric_transfer_error'
trace_args = (tensor([[[0.3804, 0.7056],
         [0.1680, 0.8354],
         [0.0176, 0.1859],
         [0.5946, 0.1057]]]), tensor...0.2935]]]), tensor([[[0.1577, 0.5943, 0.5942],
         [0.9071, 0.4486, 0.8904],
         [0.5988, 0.3435, 0.5255]]]))
trace_kwargs = {'eps': 1e-08, 'squared': True}
test_args = (tensor([[[0.6646, 0.8546],
         [0.4872, 0.2097],
         [0.0273, 0.4705],
         [0.3863, 0.7562]],

       ... 0.7880]],

        [[0.9877, 0.3981, 0.6683],
         [0.4541, 0.7184, 0.0339],
         [0.3231, 0.7454, 0.3729]]]))
test_kwargs = {'eps': 1e-07, 'squared': True}, target = 'numpy', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:232: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pts1 = array([[[0.380374  , 0.7055876 ],
        [0.16799515, 0.835361  ],
        [0.01759297, 0.18586284],
        [0.5946397 , 0.10565847]]], dtype=float32)
pts2 = array([[[0.34413588, 0.66616017],
        [0.4910934 , 0.7391322 ],
        [0.8462664 , 0.2754681 ],
        [0.40855443, 0.29352468]]], dtype=float32)
H = array([[[0.15766168, 0.5942629 , 0.59423167],
        [0.9071357 , 0.4486395 , 0.89040065],
        [0.5988073 , 0.34349483, 0.52551174]]], dtype=float32), squared = True, eps = 1e-08

    def numpy_symmetric_transfer_error(pts1, pts2, H, squared=True, eps=1e-08):
        from ..core.check import numpy_KORNIA_CHECK_SHAPE
        from ...ivy.functional.frontends.torch.tensor import numpy_size_frnt_
        from .conversions import numpy_convert_points_from_homogeneous
        from ...ivy.functional.frontends.torch.miscellaneous_ops import numpy_finfo_frnt
        from ..utils.helpers import numpy_safe_inverse_with_mask
        from ...ivy.functional.frontends.torch.tensor import numpy_expand_as_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_view_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_to_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_sqrt_frnt_
    
        numpy_KORNIA_CHECK_SHAPE(H, ["B", "3", "3"])
        if numpy_size_frnt_(pts1, -1) == 3:
            pts1 = numpy_convert_points_from_homogeneous(pts1)
        if numpy_size_frnt_(pts2, -1) == 3:
            pts2 = numpy_convert_points_from_homogeneous(pts2)
        max_num = numpy_finfo_frnt(pts1.dtype).max
        H_inv, good_H = numpy_safe_inverse_with_mask(H)
>       there: typing.Any = numpy_oneway_transfer_error(pts1, pts2, H, True, eps)

ivy_transpiled_outputs/numpy_outputs/kornia/geometry/homography.py:71: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pts1 = array([[[0.380374  , 0.7055876 ],
        [0.16799515, 0.835361  ],
        [0.01759297, 0.18586284],
        [0.5946397 , 0.10565847]]], dtype=float32)
pts2 = array([[[0.34413588, 0.66616017],
        [0.4910934 , 0.7391322 ],
        [0.8462664 , 0.2754681 ],
        [0.40855443, 0.29352468]]], dtype=float32)
H = array([[[0.15766168, 0.5942629 , 0.59423167],
        [0.9071357 , 0.4486395 , 0.89040065],
        [0.5988073 , 0.34349483, 0.52551174]]], dtype=float32), squared = True, eps = 1e-08

    def numpy_oneway_transfer_error(pts1, pts2, H, squared=True, eps=1e-08):
        from ..core.check import numpy_KORNIA_CHECK_SHAPE
        from ...ivy.functional.frontends.torch.tensor import numpy_size_frnt_
        from .conversions import numpy_convert_points_from_homogeneous
        from .linalg import numpy_transform_points
        from ...ivy.functional.frontends.torch.tensor import numpy_sum_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_pow_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_sqrt_frnt_
    
        numpy_KORNIA_CHECK_SHAPE(H, ["B", "3", "3"])
        if numpy_size_frnt_(pts1, -1) == 3:
            pts1 = numpy_convert_points_from_homogeneous(pts1)
        if numpy_size_frnt_(pts2, -1) == 3:
            pts2 = numpy_convert_points_from_homogeneous(pts2)
        pts1_in_2: typing.Any = numpy_transform_points(H, pts1)
        error_squared: typing.Any = numpy_sum_frnt_(
>           numpy_pow_frnt_(pts1_in_2 - pts2, 2), dim=-1
        )

ivy_transpiled_outputs/numpy_outputs/kornia/geometry/homography.py:46: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (array([[[0.7340629 , 0.89262956],
        [0.7324337 , 0.81343347],
        [0.33304548, 1.3744113 ],
        [0.4093879 , 1.3158612 ]]], dtype=float32), 2), kwargs = {}
numpy_is_array_bknd = <function numpy_is_array_bknd at 0x7f8a89a70b80>
array_like = array([[[0.7340629 , 0.89262956],
        [0.7324337 , 0.81343347],
        [0.33304548, 1.3744113 ],
        [0.4093879 , 1.3158612 ]]], dtype=float32)

    @functools.wraps(fn)
    def wrapper(*args, **kwargs):
        from ..functional.ivy.general import numpy_is_array_bknd
    
        array_like = args[0]
        if hasattr(array_like, "__class__") and array_like.__class__.__name__ in [
            "list",
            "tuple",
        ]:
            array_like = array_like[0]
        if numpy_is_array_bknd(array_like):
>           return fn(*args, **kwargs)

ivy_transpiled_outputs/numpy_outputs/ivy/utils/decorator_utils.py:200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = array([[[0.7340629 , 0.89262956],
        [0.7324337 , 0.81343347],
        [0.33304548, 1.3744113 ],
        [0.4093879 , 1.3158612 ]]], dtype=float32), exponent = 2

    @numpy_handle_methods
    def numpy_pow_frnt_(tensor, exponent):
        from .pointwise_ops import numpy_pow_frnt
    
>       return numpy_pow_frnt(tensor, exponent)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/tensor.py:272: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (array([[[0.7340629 , 0.89262956],
        [0.7324337 , 0.81343347],
        [0.33304548, 1.3744113 ],
        [0.4093879 , 1.3158612 ]]], dtype=float32), 2), kwargs = {}
numpy_is_array_bknd = <function numpy_is_array_bknd at 0x7f8a89a70b80>
array_like = array([[[0.7340629 , 0.89262956],
        [0.7324337 , 0.81343347],
        [0.33304548, 1.3744113 ],
        [0.4093879 , 1.3158612 ]]], dtype=float32)

    @functools.wraps(fn)
    def wrapper(*args, **kwargs):
        from ..functional.ivy.general import numpy_is_array_bknd
    
        array_like = args[0]
        if hasattr(array_like, "__class__") and array_like.__class__.__name__ in [
            "list",
            "tuple",
        ]:
            array_like = array_like[0]
        if numpy_is_array_bknd(array_like):
>           return fn(*args, **kwargs)

ivy_transpiled_outputs/numpy_outputs/ivy/utils/decorator_utils.py:200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = array([[[0.7340629 , 0.89262956],
        [0.7324337 , 0.81343347],
        [0.33304548, 1.3744113 ],
        [0.4093879 , 1.3158612 ]]], dtype=float32), exponent = array(2)

    @numpy_handle_methods
    def numpy_pow_frnt(input, exponent, *, out=None):
        from ...ivy.general import numpy_is_array_bknd
        from .creation_ops import numpy_as_tensor_frnt
        from ...backends.numpy.creation import numpy_asarray
        from .__init__ import numpy_promote_types_of_torch_inputs_frnt
        from ...ivy.data_type import numpy_is_int_dtype_bknd
        from ...backends.numpy.elementwise import numpy_pow
        from ...backends.numpy.utility import numpy_any
        from ...backends.numpy.searching import numpy_where
        from ...backends.numpy.elementwise import numpy_bitwise_and
        from ....data_classes.array.data_type import numpy_astype_bknd_
    
        if not numpy_is_array_bknd(input):
            input = numpy_as_tensor_frnt(input)
        if not numpy_is_array_bknd(exponent):
            if (
                any(dtype in str(input.dtype) for dtype in ["int8", "int16"])
                and isinstance(exponent, (int,))
                or "float16" in str(input.dtype)
                and isinstance(exponent, (float,))
            ):
                exponent = numpy_asarray(exponent, dtype=input.dtype)
            else:
                exponent = numpy_as_tensor_frnt(exponent)
>       input, exponent = numpy_promote_types_of_torch_inputs_frnt(input, exponent)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/pointwise_ops.py:97: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x1 = array([[[0.7340629 , 0.89262956],
        [0.7324337 , 0.81343347],
        [0.33304548, 1.3744113 ],
        [0.4093879 , 1.3158612 ]]], dtype=float32), x2 = array(2)

    def numpy_promote_types_of_torch_inputs_frnt(x1, x2, /):
        from ...ivy.general import numpy_isscalar_bknd
        from ...ivy.data_type import numpy_is_int_dtype_bknd
        from ...backends.numpy.creation import numpy_asarray
        from ...ivy.data_type import numpy_default_dtype_bknd
        from .tensor import numpy_shape_frnt_
        from ...ivy.device import numpy_default_device_bknd
        from ....data_classes.array.data_type import numpy_astype_bknd_
    
        """Promote the dtype of the given native array inputs to a common dtype
        based on type promotion rules.
    
        While passing float or integer values or any other non-array input
        to this function, it should be noted that the return will be an
        array-like object. Therefore, outputs from this function should be
        used as inputs only for those functions that expect an array-like or
        tensor-like objects, otherwise it might give unexpected results.
        """
        if (
            numpy_isscalar_bknd(x1) or isinstance(x1, (list, tuple))
        ) and numpy_is_int_dtype_bknd(x1):
            x1 = numpy_asarray(x1, dtype="int64")
        elif numpy_isscalar_bknd(x1) or isinstance(x1, (list, tuple)):
            x1 = numpy_asarray(x1)
        if (
            numpy_isscalar_bknd(x2) or isinstance(x2, (list, tuple))
        ) and numpy_is_int_dtype_bknd(x2):
            x2 = numpy_asarray(x2, dtype="int64")
        elif numpy_isscalar_bknd(x2) or isinstance(x2, (list, tuple)):
            x2 = numpy_asarray(x2)
        type1 = numpy_default_dtype_bknd(item=x1).strip("u123456789")
        type2 = numpy_default_dtype_bknd(item=x2).strip("u123456789")
        if numpy_shape_frnt_(x1) != () and numpy_shape_frnt_(x2) == () and type1 == type2:
            x2 = numpy_asarray(
                x2,
                dtype=x1.dtype,
                device=numpy_default_device_bknd(item=x1, as_native=False),
            )
        elif numpy_shape_frnt_(x1) == () and numpy_shape_frnt_(x2) != () and type1 == type2:
            x1 = numpy_asarray(
                x1,
                dtype=x2.dtype,
                device=numpy_default_device_bknd(item=x2, as_native=False),
            )
        elif x1.dtype != x2.dtype:
>           promoted = numpy_promote_types_torch_frnt(x1.dtype, x2.dtype)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/__init__.py:87: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

type1 = dtype('float32'), type2 = dtype('int64')

    def numpy_promote_types_torch_frnt(type1, type2, /):
        from ...backends.numpy.general import numpy_get_item
        from ...backends.numpy.data_type import numpy_as_ivy_dtype
    
        try:
            ret = numpy_get_item(
>               torch_promotion_table,
                (numpy_as_ivy_dtype(type1), numpy_as_ivy_dtype(type2)),
            )
E           NameError: name 'torch_promotion_table' is not defined

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/__init__.py:34: NameError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.homography.symmetric_transfer_error
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/geometry/test_homography.py::test_find_homography_dlt[numpy-s2s-False] - AttributeError: module 'numpy' has no attribute 'bool'.
FAILED kornia/geometry/test_homography.py::test_find_homography_dlt_iterated[numpy-s2s-False] - AttributeError: module 'numpy' has no attribute 'bool'.
FAILED kornia/geometry/test_homography.py::test_find_homography_lines_dlt[numpy-s2s-False] - AttributeError: module 'numpy' has no attribute 'bool'.
FAILED kornia/geometry/test_homography.py::test_find_homography_lines_dlt_iterated[numpy-s2s-False] - AttributeError: module 'numpy' has no attribute 'bool'.
FAILED kornia/geometry/test_homography.py::test_oneway_transfer_error[numpy-s2s-False] - NameError: name 'torch_promotion_table' is not defined
FAILED kornia/geometry/test_homography.py::test_symmetric_transfer_error[numpy-s2s-False] - NameError: name 'torch_promotion_table' is not defined
=============================================================================== 6 failed, 2 passed in 582.90s (0:09:42) ================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 2 items

kornia/geometry/test_vector.py FF                                                                                                                                                                [100%]

=============================================================================================== FAILURES ===============================================================================================
__________________________________________________________________________________ test_Vector3[tensorflow-s2s-False] __________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_Vector3(target_framework, mode, backend_compile):
        print("kornia.geometry.vector.Vector3")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target_framework)
        # Initialize a Vector3 with a tensor
        vector = torch.tensor([1.0, 2.0, 3.0], requires_grad=True)
        torch_vector3 = kornia.geometry.vector.Vector3(vector)
    
        transpiled_vector = _nest_torch_tensor_to_new_framework(vector, target_framework)
        transpiled_vector3 = transpiled_kornia.geometry.vector.Vector3(transpiled_vector)
    
        # Test .x, .y, .z properties
        _to_numpy_and_allclose(torch_vector3.x, transpiled_vector3.x)
        _to_numpy_and_allclose(torch_vector3.y, transpiled_vector3.y)
        _to_numpy_and_allclose(torch_vector3.z, transpiled_vector3.z)
    
        # Test .normalized()
        torch_normalized = torch_vector3.normalized()
        transpiled_normalized = transpiled_vector3.normalized()
        _to_numpy_and_allclose(torch_normalized.data, transpiled_normalized.data)
    
        # Test .dot()
        another_vector = torch.tensor([4.0, 5.0, 6.0], requires_grad=True)
        transpiled_another_vector = _nest_torch_tensor_to_new_framework(another_vector, target_framework)
    
        torch_dot = torch_vector3.dot(kornia.geometry.vector.Vector3(another_vector))
        transpiled_dot = transpiled_vector3.dot(transpiled_kornia.geometry.vector.Vector3(transpiled_another_vector))
        _to_numpy_and_allclose(torch_dot.data, transpiled_dot.data)
    
        # Test .squared_norm()
        torch_squared_norm = torch_vector3.squared_norm()
        transpiled_squared_norm = transpiled_vector3.squared_norm()
        _to_numpy_and_allclose(torch_squared_norm.data, transpiled_squared_norm.data)
    
        # Test class method .random()
        torch_random_vector3 = kornia.geometry.vector.Vector3.random()
>       transpiled_random_vector3 = transpiled_kornia.geometry.vector.Vector3.random()
E       TypeError: 'classmethod' object is not callable

kornia/geometry/test_vector.py:56: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.vector.Vector3
__________________________________________________________________________________ test_Vector2[tensorflow-s2s-False] __________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_Vector2(target_framework, mode, backend_compile):
        print("kornia.geometry.vector.Vector2")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target_framework)
        # Initialize a Vector2 with a tensor
        vector = torch.tensor([1.0, 2.0], requires_grad=True)
        torch_vector2 = kornia.geometry.vector.Vector2(vector)
    
    
        transpiled_vector = _nest_torch_tensor_to_new_framework(vector, target_framework)
        transpiled_vector2 = transpiled_kornia.geometry.vector.Vector2(transpiled_vector)
    
        # Test .x, .y properties
        _to_numpy_and_allclose(torch_vector2.x, transpiled_vector2.x)
        _to_numpy_and_allclose(torch_vector2.y, transpiled_vector2.y)
    
        # Test .normalized()
        torch_normalized = torch_vector2.normalized()
        transpiled_normalized = transpiled_vector2.normalized()
        _to_numpy_and_allclose(torch_normalized.data, transpiled_normalized.data)
    
        # Test .dot()
        another_vector = torch.tensor([3.0, 4.0], requires_grad=True)
        transpiled_another_vector = _nest_torch_tensor_to_new_framework(another_vector, target_framework)
    
        torch_dot = torch_vector2.dot(kornia.geometry.vector.Vector2(another_vector))
        transpiled_dot = transpiled_vector2.dot(transpiled_kornia.geometry.vector.Vector2(transpiled_another_vector))
        _to_numpy_and_allclose(torch_dot.data, transpiled_dot.data)
    
        # Test .squared_norm()
        torch_squared_norm = torch_vector2.squared_norm()
        transpiled_squared_norm = transpiled_vector2.squared_norm()
        _to_numpy_and_allclose(torch_squared_norm.data, transpiled_squared_norm.data)
    
        # Test class method .random()
        torch_random_vector2 = kornia.geometry.vector.Vector2.random()
>       transpiled_random_vector2 = transpiled_kornia.geometry.vector.Vector2.random()
E       TypeError: 'classmethod' object is not callable

kornia/geometry/test_vector.py:104: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.vector.Vector2
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/geometry/test_vector.py::test_Vector3[tensorflow-s2s-False] - TypeError: 'classmethod' object is not callable
FAILED kornia/geometry/test_vector.py::test_Vector2[tensorflow-s2s-False] - TypeError: 'classmethod' object is not callable
==================================================================================== 2 failed in 128.88s (0:02:08) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 13 items

kornia/test_metrics.py ...F.....ssss                                                                                                                                                             [100%]

=============================================================================================== FAILURES ===============================================================================================
_____________________________________________________________________________ test_mean_average_precision[numpy-s2s-False] _____________________________________________________________________________

target_framework = 'numpy', mode = 's2s', backend_compile = False

    def test_mean_average_precision(target_framework, mode, backend_compile):
        trace_args = (
            [torch.tensor([[100, 50, 150, 100.]])],
            [torch.tensor([1.])],
            [torch.tensor([0.7])],
            [torch.tensor([[100, 50, 150, 100.]])],
            [torch.tensor([1.])],
            2,
        )
        trace_kwargs = {}
        test_args = (
            [torch.tensor([[50, 25, 75, 50], [100, 50, 150, 100.]])],
            [torch.tensor([1, 2.])],
            [torch.tensor([0.6, 0.8])],
            [torch.tensor([[50, 25, 75, 50], [100, 50, 150, 100.]])],
            [torch.tensor([1, 2.])],
            3,
        )
        kornia.metrics.mean_average_precision(*trace_args)
        kornia.metrics.mean_average_precision(*test_args)
        test_kwargs = {}
    
        # NOTE: this test fails due to the use of dynamic control flow; skipping
>       _test_function(
            kornia.metrics.mean_average_precision,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
            skip=True,
        )

kornia/test_metrics.py:118: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function mean_average_precision at 0x7f0d353f24d0>
trace_args = ([array([[100.,  50., 150., 100.]], dtype=float32)], [array([1.], dtype=float32)], [array([0.7], dtype=float32)], [array([[100.,  50., 150., 100.]], dtype=float32)], [array([1.], dtype=float32)], 2)
trace_kwargs = {}
test_args = ([array([[ 50.,  25.,  75.,  50.],
       [100.,  50., 150., 100.]], dtype=float32)], [array([1., 2.], dtype=float32)]...rray([[ 50.,  25.,  75.,  50.],
       [100.,  50., 150., 100.]], dtype=float32)], [array([1., 2.], dtype=float32)], 3)
test_kwargs = {}, target = 'numpy', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = True, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function mean_average_precision at 0x7f0d353f24d0>, fn_name = 'kornia.metrics.mean_average_precision'
trace_args = ([array([[100.,  50., 150., 100.]], dtype=float32)], [array([1.], dtype=float32)], [array([0.7], dtype=float32)], [array([[100.,  50., 150., 100.]], dtype=float32)], [array([1.], dtype=float32)], 2)
trace_kwargs = {}
test_args = ([array([[ 50.,  25.,  75.,  50.],
       [100.,  50., 150., 100.]], dtype=float32)], [array([1., 2.], dtype=float32)]...rray([[ 50.,  25.,  75.,  50.],
       [100.,  50., 150., 100.]], dtype=float32)], [array([1., 2.], dtype=float32)], 3)
test_kwargs = {}, target = 'numpy', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
>       orig_out = fn(*trace_args, **trace_kwargs)

helpers.py:335: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred_boxes = [array([[100.,  50., 150., 100.]], dtype=float32)], pred_labels = [array([1.], dtype=float32)], pred_scores = [array([0.7], dtype=float32)]
gt_boxes = [array([[100.,  50., 150., 100.]], dtype=float32)], gt_labels = [array([1.], dtype=float32)], n_classes = 2, threshold = 0.5

    def mean_average_precision(
        pred_boxes: List[Tensor],
        pred_labels: List[Tensor],
        pred_scores: List[Tensor],
        gt_boxes: List[Tensor],
        gt_labels: List[Tensor],
        n_classes: int,
        threshold: float = 0.5,
    ) -> Tuple[Tensor, Dict[int, float]]:
        """Calculate the Mean Average Precision (mAP) of detected objects.
    
        Code altered from https://github.com/sgrvinod/a-PyTorch-Tutorial-to-Object-Detection/blob/master/utils.py#L271.
        Background class (0 index) is excluded.
    
        Args:
            pred_boxes: a tensor list of predicted bounding boxes.
            pred_labels: a tensor list of predicted labels.
            pred_scores: a tensor list of predicted labels' scores.
            gt_boxes: a tensor list of ground truth bounding boxes.
            gt_labels: a tensor list of ground truth labels.
            n_classes: the number of classes.
            threshold: count as a positive if the overlap is greater than the threshold.
    
        Returns:
            mean average precision (mAP), list of average precisions for each class.
    
        Examples:
            >>> boxes, labels, scores = torch.tensor([[100, 50, 150, 100.]]), torch.tensor([1]), torch.tensor([.7])
            >>> gt_boxes, gt_labels = torch.tensor([[100, 50, 150, 100.]]), torch.tensor([1])
            >>> mean_average_precision([boxes], [labels], [scores], [gt_boxes], [gt_labels], 2)
            (tensor(1.), {1: 1.0})
        """
        # these are all lists of tensors of the same length, i.e. number of images
        if not len(pred_boxes) == len(pred_labels) == len(pred_scores) == len(gt_boxes) == len(gt_labels):
            raise AssertionError
    
        # Store all (true) objects in a single continuous tensor while keeping track of the image it is from
        gt_images = []
        for i, labels in enumerate(gt_labels):
>           gt_images.extend([i] * labels.size(0))
E           TypeError: 'int' object is not callable

/opt/miniconda/envs/multienv/lib/python3.10/site-packages/kornia/metrics/mean_average_precision.py:49: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.metrics.mean_average_precision.mean_average_precision
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/test_metrics.py::test_mean_average_precision[numpy-s2s-False] - TypeError: 'int' object is not callable
========================================================================== 1 failed, 8 passed, 4 skipped in 465.56s (0:07:45) ==========================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 5 items

kornia/test_x.py sssss                                                                                                                                                                           [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
==================================================================================== 5 skipped in 326.78s (0:05:26) ====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 56 items

kornia/geometry/test_transform.py ........................F..................F.......F..FF                                                                                                       [100%]

=============================================================================================== FAILURES ===============================================================================================
______________________________________________________________________________ test_upscale_double[tensorflow-s2s-False] _______________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_upscale_double(target_framework, mode, backend_compile):
        trace_args = (
            torch.rand(1, 3, 4, 4),
        )
        trace_kwargs = {}
        test_args = (
            torch.rand(5, 3, 8, 8),
        )
        test_kwargs = {}
>       _test_function(
            kornia.geometry.transform.upscale_double,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/geometry/test_transform.py:612: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function upscale_double at 0x7f776d841360>
trace_args = (tensor([[[[0.1644, 0.4447, 0.4133, 0.0768],
          [0.6145, 0.5217, 0.1943, 0.9192],
          [0.9827, 0.2259, 0...., 0.7294, 0.3573, 0.0371],
          [0.9947, 0.3749, 0.5812, 0.0272],
          [0.9771, 0.8573, 0.9588, 0.0441]]]]),)
trace_kwargs = {}
test_args = (tensor([[[[7.2802e-01, 9.9785e-01, 4.5858e-01, 8.3812e-01, 8.9503e-01,
           7.7837e-01, 3.0302e-01, 5.5683e-01]...      [1.2518e-01, 9.9510e-01, 9.0649e-01, 6.2060e-01, 5.7301e-01,
           8.5515e-01, 5.4174e-01, 2.6923e-01]]]]),)
test_kwargs = {}, target = 'tensorflow', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function upscale_double at 0x7f776d841360>, fn_name = 'kornia.geometry.transform.upscale_double'
trace_args = (tensor([[[[0.1644, 0.4447, 0.4133, 0.0768],
          [0.6145, 0.5217, 0.1943, 0.9192],
          [0.9827, 0.2259, 0...., 0.7294, 0.3573, 0.0371],
          [0.9947, 0.3749, 0.5812, 0.0272],
          [0.9771, 0.8573, 0.9588, 0.0441]]]]),)
trace_kwargs = {}
test_args = (tensor([[[[7.2802e-01, 9.9785e-01, 4.5858e-01, 8.3812e-01, 8.9503e-01,
           7.7837e-01, 3.0302e-01, 5.5683e-01]...      [1.2518e-01, 9.9510e-01, 9.0649e-01, 6.2060e-01, 5.7301e-01,
           8.5515e-01, 5.4174e-01, 2.6923e-01]]]]),)
test_kwargs = {}, target = 'tensorflow', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
>           graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:326: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:232: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = <tf.Tensor: shape=(1, 3, 4, 4), dtype=float32, numpy=
array([[[[0.16439945, 0.44470382, 0.413256  , 0.07682323],
     ....37492025, 0.5812068 , 0.02724063],
         [0.97714233, 0.8572549 , 0.9588322 , 0.04410094]]]],
      dtype=float32)>

    def tensorflow_upscale_double(x):
        from ...core._backend import zeros
        from ...core.check import tensorflow_KORNIA_CHECK_IS_TENSOR
        from ...core.check import tensorflow_KORNIA_CHECK_SHAPE
        from ....ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ....ivy.functional.backends.tensorflow.general import tensorflow_set_item
    
        tensorflow_KORNIA_CHECK_IS_TENSOR(x)
        tensorflow_KORNIA_CHECK_SHAPE(x, ["*", "H", "W"])
        double_shape = tensorflow_shape_frnt_(x)[:-2] + (
            tensorflow_shape_frnt_(x)[-2] * 2,
            tensorflow_shape_frnt_(x)[-1] * 2,
        )
        upscaled = zeros(double_shape, device=x.device, dtype=x.dtype)
        upscaled = tensorflow_set_item(
            upscaled, (..., slice(None, None, 2), slice(None, None, 2)), x
        )
>       upscaled[..., ::2, 1::2] = tensorflow_set_item(
            upscaled[..., ::2, 1::2],
            (..., slice(None, -1, None)),
            (upscaled[..., ::2, ::2][..., :-1] + upscaled[..., ::2, 2::2]) / 2,
        )
E       TypeError: 'tensorflow.python.framework.ops.EagerTensor' object does not support item assignment

ivy_transpiled_outputs/tensorflow_outputs/kornia/geometry/transform/pyramid.py:49: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.transform.pyramid.upscale_double
___________________________________________________________________________________ test_Shear[tensorflow-s2s-False] ___________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_Shear(target_framework, mode, backend_compile):
        print("kornia.geometry.transform.Shear")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target_framework)
    
        x = torch.rand(2, 3, 4, 4)
        shear = torch.tensor([[0.5, 0.0], [0.0, 0.5]])
        torch_out = kornia.geometry.transform.Shear(shear)(x)
    
        transpiled_x = _nest_torch_tensor_to_new_framework(x, target_framework)
        transpiled_shear = _nest_torch_tensor_to_new_framework(shear, target_framework)
>       transpiled_out = transpiled_kornia.geometry.transform.Shear(transpiled_shear)(transpiled_x)

kornia/geometry/test_transform.py:1156: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Shear()
args = (<tf.Tensor: shape=(2, 3, 4, 4), dtype=float32, numpy=
array([[[[0.5369672 , 0.8321353 , 0.24060279, 0.41404498],
    ...3769766, 0.79326695, 0.12720037],
         [0.8004711 , 0.812127  , 0.8285019 , 0.41610807]]]],
      dtype=float32)>,)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x7f76e3d24dd0, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...ode_context=['        return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_Shear(), <tf.Tensor: shape=(2, 3, 4, 4), dtype=float32, numpy=
array([[[[0.5369672 , 0.8321353 , 0.2406027...23769766, 0.79326695, 0.12720037],
         [0.8004711 , 0.812127  , 0.8285019 , 0.41610807]]]],
      dtype=float32)>)
kwargs = {}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Shear(), v = None, buffers = None
args = (<tf.Tensor: shape=(2, 3, 4, 4), dtype=float32, numpy=
array([[[[0.5369672 , 0.8321353 , 0.24060279, 0.41404498],
    ...3769766, 0.79326695, 0.12720037],
         [0.8004711 , 0.812127  , 0.8285019 , 0.41610807]]]],
      dtype=float32)>,)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:2017: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_Shear(), <tf.Tensor: shape=(2, 3, 4, 4), dtype=float32, numpy=
array([[[[0.5369672 , 0.8321353 , 0.2406027...23769766, 0.79326695, 0.12720037],
         [0.8004711 , 0.812127  , 0.8285019 , 0.41610807]]]],
      dtype=float32)>)
kwargs = {'buffers': None, 'v': None}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Shear(), v = None, buffers = None
args = (<tf.Tensor: shape=(2, 3, 4, 4), dtype=float32, numpy=
array([[[[0.5369672 , 0.8321353 , 0.24060279, 0.41404498],
    ...3769766, 0.79326695, 0.12720037],
         [0.8004711 , 0.812127  , 0.8285019 , 0.41610807]]]],
      dtype=float32)>,)
kwargs = {}
first_arr = <tf.Tensor: shape=(2, 3, 4, 4), dtype=float32, numpy=
array([[[[0.5369672 , 0.8321353 , 0.24060279, 0.41404498],
     ....23769766, 0.79326695, 0.12720037],
         [0.8004711 , 0.812127  , 0.8285019 , 0.41610807]]]],
      dtype=float32)>
replace_v = False, replace_buffers = False, call_signature = <Signature (input)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Model, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Model, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Model, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1787: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_Shear(),)
kwargs = {'input': <tf.Tensor: shape=(2, 3, 4, 4), dtype=float32, numpy=
array([[[[0.5369672 , 0.8321353 , 0.24060279, 0.414044...23769766, 0.79326695, 0.12720037],
         [0.8004711 , 0.812127  , 0.8285019 , 0.41610807]]]],
      dtype=float32)>}

    @wraps(fn)
    def error_handler(*args, **kwargs):
        if not is_traceback_filtering_enabled():
            return fn(*args, **kwargs)
    
        filtered_tb = None
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            filtered_tb = _process_traceback_frames(e.__traceback__)
            # To get the full stack trace, call:
            # `keras.config.disable_traceback_filtering()`
>           raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/keras/src/utils/traceback_utils.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Shear()
input = <tf.Tensor: shape=(2, 3, 4, 4), dtype=float32, numpy=
array([[[[0.5369672 , 0.8321353 , 0.24060279, 0.41404498],
     ....23769766, 0.79326695, 0.12720037],
         [0.8004711 , 0.812127  , 0.8285019 , 0.41610807]]]],
      dtype=float32)>

    def call(self, input):
>       return shear(
            input, self.shear, self.mode, self.padding_mode, self.align_corners
        )
E       NameError: Exception encountered when calling tensorflow_Shear.call().
E       
E       [1mname 'shear' is not defined[0m
E       
E       Arguments received by tensorflow_Shear.call():
E         • input=tf.Tensor(shape=(2, 3, 4, 4), dtype=float32)

ivy_transpiled_outputs/tensorflow_outputs/kornia/geometry/transform/affwarp.py:55: NameError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.transform.Shear
__________________________________________________________________________________ test_Rescale[tensorflow-s2s-False] __________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_Rescale(target_framework, mode, backend_compile):
        print("kornia.geometry.transform.Rescale")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target_framework)
    
        x = torch.rand(1, 3, 4, 4)
        torch_out = kornia.geometry.transform.Rescale((2.0, 3.0))(x)
    
        transpiled_x = _nest_torch_tensor_to_new_framework(x, target_framework)
        transpiled_out = transpiled_kornia.geometry.transform.Rescale((2.0, 3.0))(transpiled_x)
    
>       _to_numpy_and_allclose(torch_out, transpiled_out)

kornia/geometry/test_transform.py:1294: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

torch_x = tensor([[[[0.8924, 0.9085, 0.9246, 0.9407, 0.9160, 0.8095, 0.7030, 0.5965,
           0.6087, 0.6801, 0.7515, 0.8229],...        [0.2175, 0.2798, 0.3421, 0.4044, 0.4274, 0.3721, 0.3167, 0.2613,
           0.2163, 0.1766, 0.1368, 0.0971]]]])
transpiled_x = <tf.Tensor: shape=(1, 3, 8, 12), dtype=float32, numpy=
array([[[[0.89239955, 0.89239955, 0.9120843 , 0.93176895, 0.951...      0.37820518, 0.3105292 , 0.24285322, 0.19425702, 0.14566085,
          0.09706467, 0.09706467]]]], dtype=float32)>
tolerance = 0.001

    def _to_numpy_and_allclose(torch_x, transpiled_x, tolerance=1e-3):
        orig_data = _nest_array_to_numpy(torch_x)
        transpiled_data = _nest_array_to_numpy(transpiled_x)
>       _check_allclose(orig_data, transpiled_data, tolerance=tolerance)

helpers.py:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[[0.89239955, 0.90850526, 0.9246109 , 0.94071656, 0.91596186,
          0.8094864 , 0.7030109 , 0.59653544, 0....       0.37205282, 0.31668153, 0.26131028, 0.2163462 , 0.17658569,
          0.13682519, 0.09706467]]]], dtype=float32)
y = array([[[[0.89239955, 0.89239955, 0.9120843 , 0.93176895, 0.9514537 ,
          0.821317  , 0.69118035, 0.5610437 , 0....       0.37820518, 0.3105292 , 0.24285322, 0.19425702, 0.14566085,
          0.09706467, 0.09706467]]]], dtype=float32)
tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
>           assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
E           AssertionError: numpy array values are not all close

helpers.py:26: AssertionError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.transform.Rescale
________________________________________________________________________________ test_Homography[tensorflow-s2s-False] _________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_Homography(target_framework, mode, backend_compile):
        print("kornia.geometry.transform.Homography")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target_framework)
    
        torch_out = kornia.geometry.transform.image_registrator.Homography()()
>       transpiled_out = transpiled_kornia.geometry.transform.image_registrator.Homography()()

kornia/geometry/test_transform.py:1350: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Homography(<KerasVariable shape=(3, 3), dtype=float32, path=variable>), args = (), kwargs = {}
stack = [FrameInfo(frame=<frame at 0x7f76e3fe8040, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...ode_context=['        return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_Homography(<KerasVariable shape=(3, 3), dtype=float32, path=variable>),), kwargs = {}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Homography(<KerasVariable shape=(3, 3), dtype=float32, path=variable>), v = None, buffers = None, args = (), kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_Homography(<KerasVariable shape=(3, 3), dtype=float32, path=variable>),), kwargs = {'buffers': None, 'v': None}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Homography(<KerasVariable shape=(3, 3), dtype=float32, path=variable>), v = None, buffers = None, args = (), kwargs = {}, first_arr = None, replace_v = False, replace_buffers = False
call_signature = <Signature ()>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Layer, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Layer, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Layer, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_Homography(<KerasVariable shape=(3, 3), dtype=float32, path=variable>),), kwargs = {}

    @wraps(fn)
    def error_handler(*args, **kwargs):
        if not is_traceback_filtering_enabled():
            return fn(*args, **kwargs)
    
        filtered_tb = None
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            filtered_tb = _process_traceback_frames(e.__traceback__)
            # To get the full stack trace, call:
            # `keras.config.disable_traceback_filtering()`
>           raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/keras/src/utils/traceback_utils.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <keras.src.layers.layer.CallSpec object at 0x7f76fccf9c90>, signature = <Signature ()>, args = (), kwargs = {}

    def __init__(self, signature, args, kwargs):
        # `training` and `mask` are special kwargs that are always available in
        # a layer, if user specifies them in their call without adding to spec,
        # we remove them to be able to bind variables. User is not using
        # `training` anyway so we can ignore.
        # TODO: If necessary use workaround for `mask`
        if "training" in kwargs and "training" not in signature.parameters:
            kwargs.pop("training")
            bound_args = signature.bind(*args, **kwargs)
        else:
            bound_args = signature.bind(*args, **kwargs)
        self.user_arguments_dict = {
            k: v for k, v in bound_args.arguments.items()
        }
        bound_args.apply_defaults()
        arg_dict = {}
        arg_names = []
        tensor_arg_dict = {}
        tensor_args = []
        tensor_arg_names = []
        nested_tensor_arg_names = []
        for name, value in bound_args.arguments.items():
            arg_dict[name] = value
            arg_names.append(name)
            if is_backend_tensor_or_symbolic(value):
                tensor_args.append(value)
                tensor_arg_names.append(name)
                tensor_arg_dict[name] = value
            elif tree.is_nested(value) and len(value) > 0:
                flat_values = tree.flatten(value)
                if all(
                    is_backend_tensor_or_symbolic(x, allow_none=True)
                    for x in flat_values
                ):
                    tensor_args.append(value)
                    tensor_arg_names.append(name)
                    tensor_arg_dict[name] = value
                    nested_tensor_arg_names.append(name)
                elif any(is_backend_tensor_or_symbolic(x) for x in flat_values):
                    raise ValueError(
                        "In a nested call() argument, "
                        "you cannot mix tensors and non-tensors. "
                        "Received invalid mixed argument: "
                        f"{name}={value}"
                    )
        self.arguments_dict = arg_dict
        self.argument_names = arg_names
        self.tensor_arguments_dict = tensor_arg_dict
        self.tensor_arguments_names = tensor_arg_names
        self.nested_tensor_argument_names = nested_tensor_arg_names
>       self.first_arg = arg_dict[arg_names[0]]
E       IndexError: list index out of range

/opt/fw/tensorflow/keras/src/layers/layer.py:1608: IndexError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.transform.Homography
________________________________________________________________________________ test_Similarity[tensorflow-s2s-False] _________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_Similarity(target_framework, mode, backend_compile):
        print("kornia.geometry.transform.Similarity")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target_framework)
    
        torch_out = kornia.geometry.transform.image_registrator.Similarity()()
>       transpiled_out = transpiled_kornia.geometry.transform.image_registrator.Similarity()()

kornia/geometry/test_transform.py:1386: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Similarity(angle = <KerasVariable shape=(1,), dtype=float32, path=variable_1>,               
 shift=<Keras...e shape=(1, 2, 1), dtype=float32, path=variable_2>, 
 scale=<KerasVariable shape=(1,), dtype=float32, path=variable_3>)
args = (), kwargs = {}
stack = [FrameInfo(frame=<frame at 0x5646d78abe50, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...ode_context=['        return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_Similarity(angle = <KerasVariable shape=(1,), dtype=float32, path=variable_1>,               
 shift=<Kera...shape=(1, 2, 1), dtype=float32, path=variable_2>, 
 scale=<KerasVariable shape=(1,), dtype=float32, path=variable_3>),)
kwargs = {}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Similarity(angle = <KerasVariable shape=(1,), dtype=float32, path=variable_1>,               
 shift=<Keras...e shape=(1, 2, 1), dtype=float32, path=variable_2>, 
 scale=<KerasVariable shape=(1,), dtype=float32, path=variable_3>)
v = None, buffers = None, args = (), kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_Similarity(angle = <KerasVariable shape=(1,), dtype=float32, path=variable_1>,               
 shift=<Kera...shape=(1, 2, 1), dtype=float32, path=variable_2>, 
 scale=<KerasVariable shape=(1,), dtype=float32, path=variable_3>),)
kwargs = {'buffers': None, 'v': None}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Similarity(angle = <KerasVariable shape=(1,), dtype=float32, path=variable_1>,               
 shift=<Keras...e shape=(1, 2, 1), dtype=float32, path=variable_2>, 
 scale=<KerasVariable shape=(1,), dtype=float32, path=variable_3>)
v = None, buffers = None, args = (), kwargs = {}, first_arr = None, replace_v = False, replace_buffers = False, call_signature = <Signature ()>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Layer, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Layer, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Layer, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_Similarity(angle = <KerasVariable shape=(1,), dtype=float32, path=variable_1>,               
 shift=<Kera...shape=(1, 2, 1), dtype=float32, path=variable_2>, 
 scale=<KerasVariable shape=(1,), dtype=float32, path=variable_3>),)
kwargs = {}

    @wraps(fn)
    def error_handler(*args, **kwargs):
        if not is_traceback_filtering_enabled():
            return fn(*args, **kwargs)
    
        filtered_tb = None
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            filtered_tb = _process_traceback_frames(e.__traceback__)
            # To get the full stack trace, call:
            # `keras.config.disable_traceback_filtering()`
>           raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/keras/src/utils/traceback_utils.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <keras.src.layers.layer.CallSpec object at 0x7f76fcab5cf0>, signature = <Signature ()>, args = (), kwargs = {}

    def __init__(self, signature, args, kwargs):
        # `training` and `mask` are special kwargs that are always available in
        # a layer, if user specifies them in their call without adding to spec,
        # we remove them to be able to bind variables. User is not using
        # `training` anyway so we can ignore.
        # TODO: If necessary use workaround for `mask`
        if "training" in kwargs and "training" not in signature.parameters:
            kwargs.pop("training")
            bound_args = signature.bind(*args, **kwargs)
        else:
            bound_args = signature.bind(*args, **kwargs)
        self.user_arguments_dict = {
            k: v for k, v in bound_args.arguments.items()
        }
        bound_args.apply_defaults()
        arg_dict = {}
        arg_names = []
        tensor_arg_dict = {}
        tensor_args = []
        tensor_arg_names = []
        nested_tensor_arg_names = []
        for name, value in bound_args.arguments.items():
            arg_dict[name] = value
            arg_names.append(name)
            if is_backend_tensor_or_symbolic(value):
                tensor_args.append(value)
                tensor_arg_names.append(name)
                tensor_arg_dict[name] = value
            elif tree.is_nested(value) and len(value) > 0:
                flat_values = tree.flatten(value)
                if all(
                    is_backend_tensor_or_symbolic(x, allow_none=True)
                    for x in flat_values
                ):
                    tensor_args.append(value)
                    tensor_arg_names.append(name)
                    tensor_arg_dict[name] = value
                    nested_tensor_arg_names.append(name)
                elif any(is_backend_tensor_or_symbolic(x) for x in flat_values):
                    raise ValueError(
                        "In a nested call() argument, "
                        "you cannot mix tensors and non-tensors. "
                        "Received invalid mixed argument: "
                        f"{name}={value}"
                    )
        self.arguments_dict = arg_dict
        self.argument_names = arg_names
        self.tensor_arguments_dict = tensor_arg_dict
        self.tensor_arguments_names = tensor_arg_names
        self.nested_tensor_argument_names = nested_tensor_arg_names
>       self.first_arg = arg_dict[arg_names[0]]
E       IndexError: list index out of range

/opt/fw/tensorflow/keras/src/layers/layer.py:1608: IndexError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.transform.Similarity
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/geometry/test_transform.py::test_upscale_double[tensorflow-s2s-False] - TypeError: 'tensorflow.python.framework.ops.EagerTensor' object does not support item assignment
FAILED kornia/geometry/test_transform.py::test_Shear[tensorflow-s2s-False] - NameError: Exception encountered when calling tensorflow_Shear.call().
FAILED kornia/geometry/test_transform.py::test_Rescale[tensorflow-s2s-False] - AssertionError: numpy array values are not all close
FAILED kornia/geometry/test_transform.py::test_Homography[tensorflow-s2s-False] - IndexError: list index out of range
FAILED kornia/geometry/test_transform.py::test_Similarity[tensorflow-s2s-False] - IndexError: list index out of range
============================================================================== 5 failed, 51 passed in 5740.95s (1:35:40) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 8 items

kornia/geometry/test_linalg.py ........                                                                                                                                                          [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
==================================================================================== 8 passed in 279.10s (0:04:39) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 17 items

kornia/augmentation/test_augmentation2.py sssssssssssssssss                                                                                                                                      [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
========================================================================================= 17 skipped in 5.42s ==========================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 13 items

kornia/test_feature3.py ........FF...                                                                                                                                                            [100%]

=============================================================================================== FAILURES ===============================================================================================
_____________________________________________________________________________ test_MultiResolutionDetector[jax-s2s-False] ______________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_MultiResolutionDetector(target_framework, mode, backend_compile):
        print("kornia.feature.MultiResolutionDetector")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target_framework)
    
        keynet_model = kornia.feature.KeyNet()
        transpiled_keynet_model = transpiled_kornia.feature.KeyNet()
    
        x = torch.rand(1, 1, 32, 32) * 10.
        transpiled_x = _nest_torch_tensor_to_new_framework(x, target_framework)
    
        model = kornia.feature.MultiResolutionDetector(keynet_model)
        torch_out = model(x)
    
>       transpiled_model = transpiled_kornia.feature.MultiResolutionDetector(transpiled_keynet_model)

kornia/test_feature3.py:170: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:230: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:153: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:161: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

name = 'ivy_transpiled_outputs.jax_outputs.kornia.feature.keynet', package = None

    def import_module(name, package=None):
        """Import a module.
    
        The 'package' argument is required when performing a relative import. It
        specifies the package to use as the anchor point from which to resolve the
        relative import to an absolute import.
    
        """
        level = 0
        if name.startswith('.'):
            if not package:
                msg = ("the 'package' argument is required to perform a relative "
                       "import for {!r}")
                raise TypeError(msg.format(name))
            for character in name:
                if character != '.':
                    break
                level += 1
>       return _bootstrap._gcd_import(name[level:], package, level)

/opt/miniconda/envs/multienv/lib/python3.10/importlib/__init__.py:126: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

name = 'ivy_transpiled_outputs.jax_outputs.kornia.feature.keynet', package = None, level = 0

>   ???

<frozen importlib._bootstrap>:1050: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

name = 'ivy_transpiled_outputs.jax_outputs.kornia.feature.keynet', import_ = <function _gcd_import at 0x7fbf73477400>

>   ???

<frozen importlib._bootstrap>:1027: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

name = 'ivy_transpiled_outputs.jax_outputs.kornia.feature.keynet', import_ = <function _gcd_import at 0x7fbf73477400>

>   ???
E   ModuleNotFoundError: No module named 'ivy_transpiled_outputs.jax_outputs.kornia.feature.keynet'

<frozen importlib._bootstrap>:1004: ModuleNotFoundError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.MultiResolutionDetector
________________________________________________________________________________ test_ScaleSpaceDetector[jax-s2s-False] ________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_ScaleSpaceDetector(target_framework, mode, backend_compile):
        print("kornia.feature.ScaleSpaceDetector")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target_framework)
    
        x = torch.rand(1, 1, 32, 32) * 10.
        transpiled_x = _nest_torch_tensor_to_new_framework(x, target_framework)
    
        model = kornia.feature.ScaleSpaceDetector()
        torch_out = model(x)
    
        transpiled_model = transpiled_kornia.feature.ScaleSpaceDetector()
        if target_framework == "tensorflow":
            # build the layers
            transpiled_model(transpiled_x)
    
        ivy.sync_models(model, transpiled_model)
    
        transpiled_out = transpiled_model(transpiled_x)
    
>       _to_numpy_and_allclose(torch_out, transpiled_out)

kornia/test_feature3.py:205: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

torch_x = (tensor([[[[10.7268,  0.0000, 14.9738],
          [ 0.0000, 10.7268, 21.0733]],

         [[10.7656,  0.0000, 18.9905]...00, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
         0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]))
transpiled_x = (Array([[[[10.726807 ,  0.       , 14.97381  ],
         [ 0.       , 10.726807 , 21.073303 ]],

        [[10.765559 ,...   , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ]],      dtype=float32))
tolerance = 0.001

    def _to_numpy_and_allclose(torch_x, transpiled_x, tolerance=1e-3):
        orig_data = _nest_array_to_numpy(torch_x)
        transpiled_data = _nest_array_to_numpy(transpiled_x)
>       _check_allclose(orig_data, transpiled_data, tolerance=tolerance)

helpers.py:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = (array([[[[10.726807,  0.      , 14.97381 ],
         [ 0.      , 10.726807, 21.073301]],

        [[10.765559,  0.   ...        ,  0.        ,
         0.        ,  0.        ,  0.        ,  0.        ,  0.        ]],
      dtype=float32))
y = (array([[[[10.726807 ,  0.       , 14.97381  ],
         [ 0.       , 10.726807 , 21.073303 ]],

        [[10.765559 ,...  , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ]],
      dtype=float32))
tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
            assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
            return
    
        if isinstance(x, (list, set, tuple)):
>           all([
                _check_allclose(element_x, element_y, tolerance=tolerance) for element_x, element_y in zip(x, y)
            ])

helpers.py:30: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

.0 = <zip object at 0x7fbee5a69d00>

    all([
>       _check_allclose(element_x, element_y, tolerance=tolerance) for element_x, element_y in zip(x, y)
    ])

helpers.py:31: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[[10.726807,  0.      , 14.97381 ],
         [ 0.      , 10.726807, 21.073301]],

        [[10.765559,  0.    ...27.999512]],

        [[48.362427,  0.      , 16.00296 ],
         [ 0.      , 48.362427, 24.0038  ]]]], dtype=float32)
y = array([[[[10.726807 ,  0.       , 14.97381  ],
         [ 0.       , 10.726807 , 21.073303 ]],

        [[10.765559 , ...115]],

        [[10.777307 ,  0.       , 17.995745 ],
         [ 0.       , 10.777307 ,  1.0162209]]]], dtype=float32)
tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
>           assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
E           AssertionError: numpy array values are not all close

helpers.py:26: AssertionError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.ScaleSpaceDetector
All parameters and buffers are now synced!
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/test_feature3.py::test_MultiResolutionDetector[jax-s2s-False] - ModuleNotFoundError: No module named 'ivy_transpiled_outputs.jax_outputs.kornia.feature.keynet'
FAILED kornia/test_feature3.py::test_ScaleSpaceDetector[jax-s2s-False] - AssertionError: numpy array values are not all close
============================================================================== 2 failed, 11 passed in 1765.75s (0:29:25) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 2 items

kornia/test_io.py ..                                                                                                                                                                             [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
==================================================================================== 2 passed in 125.62s (0:02:05) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 6 items

kornia/geometry/test_depth.py ......                                                                                                                                                             [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
==================================================================================== 6 passed in 369.94s (0:06:09) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 18 items

kornia/augmentation/test_augmentation1.py .......F..........                                                                                                                                     [100%]

=============================================================================================== FAILURES ===============================================================================================
___________________________________________________________________________________ test_RandomClahe[jax-s2s-False] ____________________________________________________________________________________

arrays = []

    def jax_stack(
        arrays: Union[Tuple[jax.Array], List[jax.Array]],
        /,
        *,
        axis: int = 0,
        out: Optional[jax.Array] = None,
    ):
        try:
>           return jax.numpy.stack(arrays, axis=axis)

ivy_transpiled_outputs/jax_outputs/ivy/functional/backends/jax/manipulation.py:147: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

arrays = [], axis = 3, out = None, dtype = None

    def stack(arrays: np.ndarray | Array | Sequence[ArrayLike],
              axis: int = 0, out: None = None, dtype: DTypeLike | None = None) -> Array:
      """Join arrays along a new axis.
    
      JAX implementation of :func:`numpy.stack`.
    
      Args:
        arrays: a sequence of arrays to stack; each must have the same shape. If a
          single array is given it will be treated equivalently to
          `arrays = unstack(arrays)`, but the implementation will avoid explicit
          unstacking.
        axis: specify the axis along which to stack.
        out: unused by JAX
        dtype: optional dtype of the resulting array. If not specified, the dtype
          will be determined via type promotion rules described in :ref:`type-promotion`.
    
      Returns:
        the stacked result.
    
      See also:
        - :func:`jax.numpy.unstack`: inverse of ``stack``.
        - :func:`jax.numpy.concatenate`: concatenation along existing axes.
        - :func:`jax.numpy.vstack`: stack vertically, i.e. along axis 0.
        - :func:`jax.numpy.hstack`: stack horizontally, i.e. along axis 1.
        - :func:`jax.numpy.dstack`: stack depth-wise, i.e. along axis 2.
        - :func:`jax.numpy.column_stack`: stack columns.
    
      Examples:
        >>> x = jnp.array([1, 2, 3])
        >>> y = jnp.array([4, 5, 6])
        >>> jnp.stack([x, y])
        Array([[1, 2, 3],
               [4, 5, 6]], dtype=int32)
        >>> jnp.stack([x, y], axis=1)
        Array([[1, 4],
               [2, 5],
               [3, 6]], dtype=int32)
    
        :func:`~jax.numpy.unstack` performs the inverse operation:
    
        >>> arr = jnp.stack([x, y], axis=1)
        >>> x, y = jnp.unstack(arr, axis=1)
        >>> x
        Array([1, 2, 3], dtype=int32)
        >>> y
        Array([4, 5, 6], dtype=int32)
      """
      if not len(arrays):
>       raise ValueError("Need at least one array to stack.")
E       ValueError: Need at least one array to stack.

/opt/fw/jax/jax/_src/numpy/lax_numpy.py:4094: ValueError

The above exception was the direct cause of the following exception:

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_RandomClahe(target_framework, mode, backend_compile):
        print("kornia.augmentation.RandomClahe")
    
        init_args = ()
        init_kwargs = {}
        call_args = (torch.rand(2, 3, 10, 20),)
        call_kwargs = {}
    
>       _test_augmentation_class(
            kornia.augmentation.RandomClahe,
            target_framework,
            init_args,
            init_kwargs,
            call_args,
            call_kwargs,
            deterministic_output=False,
            backend_compile=backend_compile,
        )

kornia/augmentation/test_augmentation1.py:216: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

augmentation_cls = <class 'kornia.augmentation._2d.intensity.clahe.RandomClahe'>, target = 'jax', init_args = (), init_kwargs = {}
call_args = (tensor([[[[3.5193e-01, 4.4954e-01, 2.1374e-01,  ..., 8.0257e-01,
           5.4706e-01, 5.3664e-01],
          [9.007... 2.6707e-01],
          [6.8488e-01, 9.1286e-01, 4.6374e-01,  ..., 5.0905e-01,
           8.4462e-01, 1.6767e-01]]]]),)
call_kwargs = {}, deterministic_output = False, backend_compile = False, tolerance = 0.001

    def _test_augmentation_class(
        augmentation_cls,
        target,
        init_args=(),
        init_kwargs={},
        call_args=(),
        call_kwargs={},
        deterministic_output=True,
        backend_compile=False,
        tolerance=1e-3,
    ):
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, target=target)
        transpiled_cls = eval("transpiled_" + f"{augmentation_cls.__module__}.{augmentation_cls.__name__}")
    
        torch_aug = augmentation_cls(*init_args, **init_kwargs)
        transpiled_init_args = _nest_torch_tensor_to_new_framework(init_args, target)
        transpiled_init_kwargs = _nest_torch_tensor_to_new_framework(init_kwargs, target)
        transpiled_aug = transpiled_cls(*transpiled_init_args, **transpiled_init_kwargs)
    
        # assert dir(torch_aug) == dir(transpiled_aug), f"attributes/methods of transpiled object do not align with the original - orig: {dir(torch_aug)} != transpiled: {dir(transpiled_aug)}"
    
        torch_out = torch_aug(*call_args, **call_kwargs)
        transpiled_call_args = _nest_torch_tensor_to_new_framework(call_args, target)
        transpiled_call_kwargs = _nest_torch_tensor_to_new_framework(call_kwargs, target)
>       transpiled_out = transpiled_aug(*transpiled_call_args, **transpiled_call_kwargs)

kornia/augmentation/test_augmentation1.py:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_RandomClahe(clip_limit_factor=(40.0, 40.0), p=0.5, p_batch=1.0, same_on_batch=False, grid_size=(8, 8), slow_and_differentiable=False)
input = Array([[[[3.51934612e-01, 4.49536860e-01, 2.13738441e-01, ...,
          8.02567780e-01, 5.47063887e-01, 5.36641657e-0... 9.12857950e-01, 4.63736475e-01, ...,
          5.09051025e-01, 8.44620287e-01, 1.67673349e-01]]]],      dtype=float32)
params = {'batch_prob': Array([0., 1.], dtype=float32), 'clip_limit_factor': Array([40.], dtype=float32), 'forward_input_shape': Array([ 2,  3, 10, 20], dtype=int64)}, kwargs = {}
jax_shape_frnt_ = <function jax_shape_frnt_ at 0x7facff8f04c0>, jax_set_item = <function jax_set_item at 0x7facd4eee680>, tensor = <function jax_tensor_frnt at 0x7facd48a9d80>
in_tensor = Array([[[[3.51934612e-01, 4.49536860e-01, 2.13738441e-01, ...,
          8.02567780e-01, 5.47063887e-01, 5.36641657e-0... 9.12857950e-01, 4.63736475e-01, ...,
          5.09051025e-01, 8.44620287e-01, 1.67673349e-01]]]],      dtype=float32)
input_shape = ivy.frontends.torch.Size([2, 3, 10, 20]), batch_shape = ivy.frontends.torch.Size([2, 3, 10, 20]), flags = {'grid_size': (8, 8), 'slow_and_differentiable': False}

    def __call__(self, input, params=None, **kwargs):
        from ...ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ...ivy.functional.backends.jax.general import jax_set_item
        from ..core._backend import tensor
    
        in_tensor = self.__unpack_input__(input)
        input_shape = jax_shape_frnt_(in_tensor)
        in_tensor = self.transform_tensor(in_tensor)
        batch_shape = jax_shape_frnt_(in_tensor)
        if params is None:
            params = self.forward_parameters(batch_shape)
        if "batch_prob" not in params:
            params = jax_set_item(params, "batch_prob", tensor([True] * batch_shape[0]))
        params, flags = self._process_kwargs_to_params_and_flags(
            params, self.flags, **kwargs
        )
>       output = self.apply_func(in_tensor, params, flags)

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/base.py:219: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_RandomClahe(clip_limit_factor=(40.0, 40.0), p=0.5, p_batch=1.0, same_on_batch=False, grid_size=(8, 8), slow_and_differentiable=False)
in_tensor = Array([[[[3.51934612e-01, 4.49536860e-01, 2.13738441e-01, ...,
          8.02567780e-01, 5.47063887e-01, 5.36641657e-0... 9.12857950e-01, 4.63736475e-01, ...,
          5.09051025e-01, 8.44620287e-01, 1.67673349e-01]]]],      dtype=float32)
params = {'batch_prob': Array([0., 1.], dtype=float32), 'clip_limit_factor': Array([40.], dtype=float32), 'forward_input_shape': Array([ 2,  3, 10, 20], dtype=int64)}
flags = {'grid_size': (8, 8), 'slow_and_differentiable': False}

    def apply_func(self, in_tensor, params, flags=None):
        if flags is None:
            flags = self.flags
        trans_matrix = self.generate_transformation_matrix(in_tensor, params, flags)
>       output = self.transform_inputs(in_tensor, params, flags, trans_matrix)

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/_2d/base.py:123: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_RandomClahe(clip_limit_factor=(40.0, 40.0), p=0.5, p_batch=1.0, same_on_batch=False, grid_size=(8, 8), slow_and_differentiable=False)
input = Array([[[[3.51934612e-01, 4.49536860e-01, 2.13738441e-01, ...,
          8.02567780e-01, 5.47063887e-01, 5.36641657e-0... 9.12857950e-01, 4.63736475e-01, ...,
          5.09051025e-01, 8.44620287e-01, 1.67673349e-01]]]],      dtype=float32)
params = {'batch_prob': Array([0., 1.], dtype=float32), 'clip_limit_factor': Array([40.], dtype=float32), 'forward_input_shape': Array([ 2,  3, 10, 20], dtype=int64)}
flags = {'grid_size': (8, 8), 'slow_and_differentiable': False}
transform = Array([[[1., 0., 0.],
        [0., 1., 0.],
        [0., 0., 1.]],

       [[1., 0., 0.],
        [0., 1., 0.],
        [0., 0., 1.]]], dtype=float32), kwargs = {}
jax_shape_frnt_ = <function jax_shape_frnt_ at 0x7facff8f04c0>, jax_all_frnt_ = <function jax_all_frnt_ at 0x7fad0ae0d7e0>, jax_any_frnt_ = <function jax_any_frnt_ at 0x7fad0adbbd00>
jax_get_item = <function jax_get_item at 0x7facd4eee4d0>, jax_is_autocast_enabled = <function jax_is_autocast_enabled at 0x7facd4ea0ca0>, jax_type_frnt_ = <function jax_type_frnt_ at 0x7fad0adbb490>
jax_index_put_frnt_ = <function jax_index_put_frnt_ at 0x7fad0adb85e0>

    def transform_inputs(self, input, params, flags, transform=None, **kwargs):
        from ...ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_all_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_any_frnt_
        from ...ivy.functional.backends.jax.general import jax_get_item
        from ..utils.helpers import jax_is_autocast_enabled
        from ...ivy.functional.frontends.torch.tensor import jax_type_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_index_put_frnt_
        from .utils.helpers import jax__transform_output_shape
    
        params, flags = self._process_kwargs_to_params_and_flags(
            self._params if params is None else params, flags, **kwargs
        )
        batch_prob = params["batch_prob"]
        to_apply = batch_prob > 0.5
        ori_shape = jax_shape_frnt_(input)
        in_tensor = self.transform_tensor(input)
        self.validate_tensor(in_tensor)
        if jax_all_frnt_(to_apply):
            output = self.apply_transform(in_tensor, params, flags, transform=transform)
        elif not jax_any_frnt_(to_apply):
            output = self.apply_non_transform(
                in_tensor, params, flags, transform=transform
            )
        else:
            output = self.apply_non_transform(
                in_tensor, params, flags, transform=transform
            )
>           applied = self.apply_transform(
                jax_get_item(in_tensor, to_apply),
                params,
                flags,
                transform=transform
                if transform is None
                else jax_get_item(transform, to_apply),
            )

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/base.py:342: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_RandomClahe(clip_limit_factor=(40.0, 40.0), p=0.5, p_batch=1.0, same_on_batch=False, grid_size=(8, 8), slow_and_differentiable=False)
input = Array([[[[1.65264308e-01, 6.23858035e-01, 8.65909815e-01,
          9.76723790e-01, 9.87988710e-03, 6.44371808e-01,
  ...
          9.78947818e-01, 2.73496330e-01, 5.09051025e-01,
          8.44620287e-01, 1.67673349e-01]]]], dtype=float32)
params = {'batch_prob': Array([0., 1.], dtype=float32), 'clip_limit_factor': Array([40.], dtype=float32), 'forward_input_shape': Array([ 2,  3, 10, 20], dtype=int64)}
flags = {'grid_size': (8, 8), 'slow_and_differentiable': False}, transform = Array([[[1., 0., 0.],
        [0., 1., 0.],
        [0., 0., 1.]]], dtype=float32)

    def apply_transform(self, input, params, flags, transform=None):
        from ....enhance.equalization import jax_equalize_clahe
    
        clip_limit = float(params["clip_limit_factor"][0])
>       return jax_equalize_clahe(
            input, clip_limit, flags["grid_size"], flags["slow_and_differentiable"]
        )

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/_2d/intensity/clahe.py:56: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = Array([[[[1.65264308e-01, 6.23858035e-01, 8.65909815e-01,
          9.76723790e-01, 9.87988710e-03, 6.44371808e-01,
  ...
          9.78947818e-01, 2.73496330e-01, 5.09051025e-01,
          8.44620287e-01, 1.67673349e-01]]]], dtype=float32)
args = (40.0, (8, 8), False), kwargs = {}, jax_numel_frnt_ = <function jax_numel_frnt_ at 0x7facff8a7c70>, jax_shape_frnt_ = <function jax_shape_frnt_ at 0x7facff8f04c0>
jax_view_frnt_ = <function jax_view_frnt_ at 0x7fad0adb4310>, input_shape = ivy.frontends.torch.Size([1, 3, 10, 20])

    @wraps(f)
    def _wrapper(input, *args, **kwargs):
        from ...ivy.functional.frontends.torch.tensor import jax_numel_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_view_frnt_
    
        if not isinstance(input, (jax.Array, nnx.Param)):
            raise TypeError(f"Input input type is not a Tensor. Got {type(input)}")
        if jax_numel_frnt_(input) == 0:
            raise ValueError("Invalid input tensor, it is empty.")
        input_shape = jax_shape_frnt_(input)
        input = jax__to_bchw(input)
>       output = f(input, *args, **kwargs)

ivy_transpiled_outputs/jax_outputs/kornia/utils/image.py:71: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = Array([[[[1.65264308e-01, 6.23858035e-01, 8.65909815e-01,
          9.76723790e-01, 9.87988710e-03, 6.44371808e-01,
  ...
          9.78947818e-01, 2.73496330e-01, 5.09051025e-01,
          8.44620287e-01, 1.67673349e-01]]]], dtype=float32)
clip_limit = 40.0, grid_size = (8, 8), slow_and_differentiable = False

    @jax_perform_keep_shape_image
    def jax_equalize_clahe(
        input, clip_limit=40.0, grid_size=(8, 8), slow_and_differentiable=False
    ):
        from ...ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_reshape_as_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_permute_frnt_
        from ...ivy.functional.backends.jax.general import jax_get_item
        from ...ivy.functional.frontends.torch.tensor import jax_dim_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_squeeze_frnt_
    
        if not isinstance(clip_limit, (float,)):
            raise TypeError(f"Input clip_limit type is not float. Got {type(clip_limit)}")
        if not isinstance(grid_size, (tuple,)):
            raise TypeError(f"Input grid_size type is not Tuple. Got {type(grid_size)}")
        if len(grid_size) != 2:
            raise TypeError(
                f"Input grid_size is not a Tuple with 2 elements. Got {len(grid_size)}"
            )
        if isinstance(grid_size[0], (float,)) or isinstance(grid_size[1], (float,)):
            raise TypeError("Input grid_size type is not valid, must be a Tuple[int, int].")
        if grid_size[0] <= 0 or grid_size[1] <= 0:
            raise ValueError(f"Input grid_size elements must be positive. Got {grid_size}")
        imgs: typing.Any = input
>       hist_tiles, img_padded = jax__compute_tiles(imgs, grid_size, True)

ivy_transpiled_outputs/jax_outputs/kornia/enhance/equalization.py:487: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

imgs = Array([[[[1.65264308e-01, 6.23858035e-01, 8.65909815e-01,
          9.76723790e-01, 9.87988710e-03, 6.44371808e-01,
  ...
          9.78947818e-01, 2.73496330e-01, 5.09051025e-01,
          8.44620287e-01, 1.67673349e-01]]]], dtype=float32)
grid_size = (8, 8), even_tile_size = True

    def jax__compute_tiles(imgs, grid_size, even_tile_size=False):
        from ...ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ...ivy.functional.frontends.torch.nn.functional.vision_functions import (
            jax_pad_frnt,
        )
        from ...ivy.functional.frontends.torch.tensor import jax_contiguous_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_squeeze_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_unfold_frnt_
    
        batch: typing.Any = imgs
        h, w = jax_shape_frnt_(batch)[-2:][0], jax_shape_frnt_(batch)[-2:][1]
        kernel_vert: typing.Any = math.ceil(h / grid_size[0])
        kernel_horz: typing.Any = math.ceil(w / grid_size[1])
        if even_tile_size:
            kernel_vert = kernel_vert + (1 if kernel_vert % 2 else 0)
            kernel_horz = kernel_horz + (1 if kernel_horz % 2 else 0)
        pad_vert = kernel_vert * grid_size[0] - h
        pad_horz = kernel_horz * grid_size[1] - w
        if pad_vert > jax_shape_frnt_(batch)[-2] or pad_horz > jax_shape_frnt_(batch)[-1]:
            raise ValueError(
                "Cannot compute tiles on the image according to the given grid size"
            )
        if pad_vert > 0 or pad_horz > 0:
            batch = jax_pad_frnt(batch, [0, pad_horz, 0, pad_vert], mode="reflect")
        c: typing.Any = jax_shape_frnt_(batch)[-3]
        tiles: typing.Any = jax_contiguous_frnt_(
            jax_squeeze_frnt_(
>               jax_unfold_frnt_(
                    jax_unfold_frnt_(
                        jax_unfold_frnt_(batch, 1, c, c), 2, kernel_vert, kernel_vert
                    ),
                    3,
                    kernel_horz,
                    kernel_horz,
                ),
                1,
            )
        )

ivy_transpiled_outputs/jax_outputs/kornia/enhance/equalization.py:60: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (Array([[[[[[0.16526431, 0.62385803, 0.8659098 , ..., 0.7992013 ,
            0.9588008 , 0.264466  ],
           [0.1...0.57616806, 0.42357498, 0.17831504, ..., 0.91161   ,
            0.79190594, 0.15813446]]]]]], dtype=float32), 3, 4, 4)
kwargs = {}, jax_is_array_bknd = <function jax_is_array_bknd at 0x7fad0a7ae680>
array_like = Array([[[[[[0.16526431, 0.62385803, 0.8659098 , ..., 0.7992013 ,
            0.9588008 , 0.264466  ],
           [0.17...         [0.57616806, 0.42357498, 0.17831504, ..., 0.91161   ,
            0.79190594, 0.15813446]]]]]], dtype=float32)

    @functools.wraps(fn)
    def wrapper(*args, **kwargs):
        from ..functional.ivy.general import jax_is_array_bknd
    
        array_like = args[0]
        if hasattr(array_like, "__class__") and array_like.__class__.__name__ in [
            "list",
            "tuple",
        ]:
            array_like = array_like[0]
        if jax_is_array_bknd(array_like):
>           return fn(*args, **kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/utils/decorator_utils.py:200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = Array([[[[[[0.16526431, 0.62385803, 0.8659098 , ..., 0.7992013 ,
            0.9588008 , 0.264466  ],
           [0.17...         [0.57616806, 0.42357498, 0.17831504, ..., 0.91161   ,
            0.79190594, 0.15813446]]]]]], dtype=float32)
dimension = 3, size = 4, step = 4

    @jax_handle_methods
    def jax_unfold_frnt_(tensor, dimension, size, step):
        from ...backends.jax.general import jax_get_item
        from ...backends.jax.general import jax_set_item
        from .indexing_slicing_joining_mutating_ops import jax_stack_frnt
    
        slices = []
        self_shape = tuple(jax_shape_frnt_(tensor))
        for i in range(0, jax_get_item(self_shape, dimension) - size + 1, step):
            slicing = [slice(None)] * len(jax_shape_frnt_(tensor))
            slicing = jax_set_item(slicing, dimension, slice(i, i + size))
            slices.append(jax_get_item(tensor, tuple(slicing)))
>       stacked = jax_stack_frnt(slices, dim=dimension)

ivy_transpiled_outputs/jax_outputs/ivy/functional/frontends/torch/tensor.py:648: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensors = [], dim = 3

    def jax_stack_frnt(tensors, dim=0, *, out=None):
        from ...backends.jax.manipulation import jax_stack
    
>       return jax_stack(tensors, axis=dim, out=out)

ivy_transpiled_outputs/jax_outputs/ivy/functional/frontends/torch/indexing_slicing_joining_mutating_ops.py:136: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

arrays = []

    def jax_stack(
        arrays: Union[Tuple[jax.Array], List[jax.Array]],
        /,
        *,
        axis: int = 0,
        out: Optional[jax.Array] = None,
    ):
        try:
            return jax.numpy.stack(arrays, axis=axis)
        except ValueError as error:
>           raise Exception(error) from error
E           Exception: Need at least one array to stack.

ivy_transpiled_outputs/jax_outputs/ivy/functional/backends/jax/manipulation.py:149: Exception
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.RandomClahe
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/augmentation/test_augmentation1.py::test_RandomClahe[jax-s2s-False] - Exception: Need at least one array to stack.
============================================================================== 1 failed, 17 passed in 3495.24s (0:58:15) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 17 items

kornia/test_feature2.py ...........ssssss                                                                                                                                                        [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
============================================================================== 11 passed, 6 skipped in 621.73s (0:10:21) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 10 items

kornia/test_feature5.py .......FF.                                                                                                                                                               [100%]

=============================================================================================== FAILURES ===============================================================================================
______________________________________________________________________________________ test_DeDoDe[jax-s2s-False] ______________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_DeDoDe(target_framework, mode, backend_compile):
        print("kornia.feature.DeDoDe")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target_framework)
    
        x = torch.rand(1, 3, 256, 256)
        transpiled_x = _nest_torch_tensor_to_new_framework(x, target_framework)
    
        model = kornia.feature.DeDoDe(amp_dtype=torch.float32)
        torch_out = model(x)
    
        ivy.set_backend(target_framework)
>       transpiled_model = transpiled_kornia.feature.DeDoDe(amp_dtype=ivy.as_native_dtype("float32"))

kornia/test_feature5.py:182: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:232: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.dedode.dedode.jax_DeDoDe'>, args = (), kwargs = {'amp_dtype': dtype('float32')}

    def __call__(cls, *args: Any, **kwargs: Any) -> Any:
>     return _graph_node_meta_call(cls, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.dedode.dedode.jax_DeDoDe'>, args = (), kwargs = {'amp_dtype': dtype('float32')}, node = jax_DeDoDe()

    def _graph_node_meta_call(cls: tp.Type[G], *args, **kwargs) -> G:
      node = cls.__new__(cls, *args, **kwargs)
      vars(node)['_object__state'] = ObjectState()
>     cls._object_meta_construct(node, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:88: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.dedode.dedode.jax_DeDoDe'>, self = jax_DeDoDe(), args = (), kwargs = {'amp_dtype': dtype('float32')}

    def _object_meta_construct(cls, self, *args, **kwargs):
>     self.__init__(*args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:82: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_DeDoDe(), detector_model = 'L', descriptor_model = 'G', amp_dtype = dtype('float32')

    def __init__(self, detector_model="L", descriptor_model="G", amp_dtype=jnp.float16):
        from .dedode_models import jax_get_detector
        from .dedode_models import jax_get_descriptor
        from ...enhance.normalize import jax_Normalize
        from ....ivy.functional.frontends.torch.creation_ops import jax_tensor_frnt
    
        self.super___init__(
            detector_model=detector_model,
            descriptor_model=descriptor_model,
            amp_dtype=amp_dtype,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
>       self.detector: typing.Any = jax_get_detector(detector_model, amp_dtype)

ivy_transpiled_outputs/jax_outputs/kornia/feature/dedode/dedode.py:65: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

kind = 'L', amp_dtype = dtype('float32')

    def jax_get_detector(kind="L", amp_dtype=jnp.float16):
        if kind == "L":
>           return jax_dedode_detector_L(amp_dtype)

ivy_transpiled_outputs/jax_outputs/kornia/feature/dedode/dedode_models.py:214: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

amp_dtype = dtype('float32')

    def jax_dedode_detector_L(amp_dtype=jnp.float16):
        from ....torch.nn.modules.container import jax_ModuleDict
        from .decoder import jax_ConvRefiner
        from .encoder import jax_VGG19
        from .decoder import jax_Decoder
        from .detector import jax_DeDoDeDetector
    
        NUM_PROTOTYPES = 1
        residual = True
        hidden_blocks = 8
        amp = True
        conv_refiner = jax_ModuleDict(
            {
>               "8": jax_ConvRefiner(
                    512,
                    512,
                    256 + NUM_PROTOTYPES,
                    hidden_blocks=hidden_blocks,
                    residual=residual,
                    amp=amp,
                    amp_dtype=amp_dtype,
                ),
                "4": jax_ConvRefiner(
                    256 + 256,
                    256,
                    128 + NUM_PROTOTYPES,
                    hidden_blocks=hidden_blocks,
                    residual=residual,
                    amp=amp,
                    amp_dtype=amp_dtype,
                ),
                "2": jax_ConvRefiner(
                    128 + 128,
                    128,
                    64 + NUM_PROTOTYPES,
                    hidden_blocks=hidden_blocks,
                    residual=residual,
                    amp=amp,
                    amp_dtype=amp_dtype,
                ),
                "1": jax_ConvRefiner(
                    64 + 64,
                    64,
                    1 + NUM_PROTOTYPES,
                    hidden_blocks=hidden_blocks,
                    residual=residual,
                    amp=amp,
                    amp_dtype=amp_dtype,
                ),
            }
        )

ivy_transpiled_outputs/jax_outputs/kornia/feature/dedode/dedode_models.py:43: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.dedode.decoder.jax_ConvRefiner'>, args = (512, 512, 257)
kwargs = {'amp': True, 'amp_dtype': dtype('float32'), 'hidden_blocks': 8, 'residual': True}

    def __call__(cls, *args: Any, **kwargs: Any) -> Any:
>     return _graph_node_meta_call(cls, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.dedode.decoder.jax_ConvRefiner'>, args = (512, 512, 257)
kwargs = {'amp': True, 'amp_dtype': dtype('float32'), 'hidden_blocks': 8, 'residual': True}, node = jax_ConvRefiner()

    def _graph_node_meta_call(cls: tp.Type[G], *args, **kwargs) -> G:
      node = cls.__new__(cls, *args, **kwargs)
      vars(node)['_object__state'] = ObjectState()
>     cls._object_meta_construct(node, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:88: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.dedode.decoder.jax_ConvRefiner'>, self = jax_ConvRefiner(), args = (512, 512, 257)
kwargs = {'amp': True, 'amp_dtype': dtype('float32'), 'hidden_blocks': 8, 'residual': True}

    def _object_meta_construct(cls, self, *args, **kwargs):
>     self.__init__(*args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:82: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_ConvRefiner(), args = (512, 512, 257), kwargs = {'amp': True, 'amp_dtype': dtype('float32'), 'hidden_blocks': 8, 'residual': True}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/utils/decorator_utils.py:245: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_ConvRefiner(), in_dim = 512, hidden_dim = 512, out_dim = 257, dw = True, kernel_size = 5, hidden_blocks = 8, amp = True, residual = True, amp_dtype = dtype('float32')

    @jax_store_config_info
    def __init__(
        self,
        in_dim=6,
        hidden_dim=16,
        out_dim=2,
        dw=True,
        kernel_size=5,
        hidden_blocks=5,
        amp=True,
        residual=False,
        amp_dtype=jnp.float16,
    ):
        from ....torch.nn.modules.container import jax_Sequential
        from ....jax__stateful_layers import FlaxConv
    
        self.super___init__(
            in_dim=in_dim,
            hidden_dim=hidden_dim,
            out_dim=out_dim,
            dw=dw,
            kernel_size=kernel_size,
            hidden_blocks=hidden_blocks,
            amp=amp,
            residual=residual,
            amp_dtype=amp_dtype,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
>       self.block1 = self.create_block(in_dim, hidden_dim, dw=False, kernel_size=1)

ivy_transpiled_outputs/jax_outputs/kornia/feature/dedode/decoder.py:211: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_ConvRefiner(), in_dim = 512, out_dim = 512, dw = False, kernel_size = 1, bias = True, norm_type = <class 'ivy_transpiled_outputs.jax_outputs.jax__stateful_layers.FlaxBatchNorm'>

    def create_block(
        self,
        in_dim,
        out_dim,
        dw=True,
        kernel_size=5,
        bias=True,
        norm_type=FlaxBatchNorm,
    ):
        from ....torch.nn.modules.container import jax_Sequential
        from ....torch.nn.modules.activation import jax_ReLU
        from ....jax__stateful_layers import FlaxConv
        from ....jax__stateful_layers import FlaxBatchNorm
    
        num_groups = 1 if not dw else in_dim
        if dw:
            if out_dim % in_dim != 0:
                raise Exception("outdim must be divisible by indim for depthwise")
        conv1 = FlaxConv(
            in_features=in_dim,
            out_features=out_dim,
            kernel_size=kernel_size,
            strides=1,
            padding=kernel_size // 2,
            padding_mode="zeros",
            use_bias=bias,
            feature_group_count=num_groups,
            input_dilation=1,
            kernel_dilation=1,
        )
        norm = (
>           norm_type(out_dim)
            if norm_type is FlaxBatchNorm
            else norm_type(num_channels=out_dim)
        )

ivy_transpiled_outputs/jax_outputs/kornia/feature/dedode/decoder.py:268: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.jax__stateful_layers.FlaxBatchNorm'>, args = (512,), kwargs = {}

    def __call__(cls, *args: Any, **kwargs: Any) -> Any:
>     return _graph_node_meta_call(cls, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.jax__stateful_layers.FlaxBatchNorm'>, args = (512,), kwargs = {}
node = <[AttributeError("'FlaxBatchNorm' object has no attribute 'num_features'") raised in repr()] FlaxBatchNorm object at 0x7fe014346f50>

    def _graph_node_meta_call(cls: tp.Type[G], *args, **kwargs) -> G:
      node = cls.__new__(cls, *args, **kwargs)
      vars(node)['_object__state'] = ObjectState()
>     cls._object_meta_construct(node, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:88: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.jax__stateful_layers.FlaxBatchNorm'>
self = <[AttributeError("'FlaxBatchNorm' object has no attribute 'num_features'") raised in repr()] FlaxBatchNorm object at 0x7fe014346f50>, args = (512,), kwargs = {}

    def _object_meta_construct(cls, self, *args, **kwargs):
>     self.__init__(*args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:82: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'FlaxBatchNorm' object has no attribute 'num_features'") raised in repr()] FlaxBatchNorm object at 0x7fe014346f50>, args = (512,), kwargs = {}

    def __init__(self, *args, **kwargs):
        self._previous_frame_info = None
        self._built = False
    
        # Map PyTorch-style parameters to Flax parameters
        self.num_batches_tracked = jnp.array(0)
        self.track_running_stats = kwargs.pop("track_running_stats", True)
    
>       num_features = kwargs.pop("num_features")
E       KeyError: 'num_features'

ivy_transpiled_outputs/jax_outputs/jax__stateful_layers.py:428: KeyError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.DeDoDe
----------------------------------------------------------------------------------------- Captured stderr call -----------------------------------------------------------------------------------------
Downloading: "https://dl.fbaipublicfiles.com/dinov2/dinov2_vitl14/dinov2_vitl14_pretrain.pth" to /root/.cache/torch/hub/checkpoints/dinov2_vitl14_pretrain.pth

  0%|          | 0.00/1.13G [00:00<?, ?B/s]
  1%|▏         | 15.0M/1.13G [00:00<00:07, 157MB/s]
  3%|▎         | 35.9M/1.13G [00:00<00:06, 193MB/s]
  5%|▌         | 59.2M/1.13G [00:00<00:05, 216MB/s]
  7%|▋         | 85.2M/1.13G [00:00<00:04, 238MB/s]
  9%|▉         | 108M/1.13G [00:00<00:04, 235MB/s] 
 12%|█▏        | 141M/1.13G [00:00<00:03, 272MB/s]
 15%|█▍        | 168M/1.13G [00:00<00:03, 277MB/s]
 17%|█▋        | 200M/1.13G [00:00<00:03, 294MB/s]
 20%|█▉        | 231M/1.13G [00:00<00:03, 302MB/s]
 22%|██▏       | 260M/1.13G [00:01<00:03, 278MB/s]
 25%|██▍       | 290M/1.13G [00:01<00:03, 290MB/s]
 28%|██▊       | 320M/1.13G [00:01<00:02, 297MB/s]
 30%|███       | 349M/1.13G [00:01<00:02, 299MB/s]
 33%|███▎      | 384M/1.13G [00:01<00:02, 317MB/s]
 36%|███▌      | 419M/1.13G [00:01<00:02, 331MB/s]
 39%|███▉      | 452M/1.13G [00:01<00:02, 336MB/s]
 42%|████▏     | 484M/1.13G [00:01<00:02, 336MB/s]
 44%|████▍     | 516M/1.13G [00:01<00:02, 300MB/s]
 47%|████▋     | 546M/1.13G [00:01<00:02, 295MB/s]
 49%|████▉     | 574M/1.13G [00:02<00:02, 291MB/s]
 52%|█████▏    | 606M/1.13G [00:02<00:01, 303MB/s]
 55%|█████▌    | 640M/1.13G [00:02<00:01, 318MB/s]
 58%|█████▊    | 673M/1.13G [00:02<00:01, 324MB/s]
 61%|██████    | 706M/1.13G [00:02<00:01, 332MB/s]
 64%|██████▍   | 741M/1.13G [00:02<00:01, 340MB/s]
 67%|██████▋   | 774M/1.13G [00:02<00:01, 343MB/s]
 70%|██████▉   | 808M/1.13G [00:02<00:01, 346MB/s]
 73%|███████▎  | 842M/1.13G [00:02<00:00, 349MB/s]
 75%|███████▌  | 876M/1.13G [00:02<00:00, 353MB/s]
 78%|███████▊  | 910M/1.13G [00:03<00:00, 353MB/s]
 81%|████████▏ | 944M/1.13G [00:03<00:00, 346MB/s]
 84%|████████▍ | 977M/1.13G [00:03<00:00, 345MB/s]
 87%|████████▋ | 0.99G/1.13G [00:03<00:00, 345MB/s]
 90%|████████▉ | 1.02G/1.13G [00:03<00:00, 332MB/s]
 93%|█████████▎| 1.05G/1.13G [00:03<00:00, 309MB/s]
 95%|█████████▌| 1.08G/1.13G [00:03<00:00, 301MB/s]
 98%|█████████▊| 1.11G/1.13G [00:03<00:00, 275MB/s]
100%|██████████| 1.13G/1.13G [00:03<00:00, 306MB/s]
_______________________________________________________________________________________ test_DISK[jax-s2s-False] _______________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_DISK(target_framework, mode, backend_compile):
        print("kornia.feature.DISK")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target_framework)
    
        x = torch.rand(1, 3, 256, 256)
        transpiled_x = _nest_torch_tensor_to_new_framework(x, target_framework)
    
        model = kornia.feature.DISK()
        torch_out = model(x)
    
        transpiled_model = transpiled_kornia.feature.DISK()
        if target_framework == "tensorflow":
            # build the layers
            transpiled_model(transpiled_x)
    
        ivy.sync_models(model, transpiled_model)
    
        transpiled_out = transpiled_model(transpiled_x)
    
>       _to_numpy_and_shape_allclose(torch_out.keypoints, transpiled_out.keypoints)
E       AttributeError: 'list' object has no attribute 'keypoints'

kornia/test_feature5.py:217: AttributeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.DISK
All parameters and buffers are now synced!
----------------------------------------------------------------------------------------- Captured stderr call -----------------------------------------------------------------------------------------
/ivy/ivy-integration-tests/ivy_transpiled_outputs/jax_outputs/torch/nn/modules/instancenorm.py:129: UserWarning: input's size at dim=1 does not match num_features. You can silence this warning by not passing in num_features, which is not used because affine=False
  warnings.warn(
/ivy/ivy-integration-tests/ivy_transpiled_outputs/jax_outputs/torch/nn/modules/instancenorm.py:129: UserWarning: input's size at dim=1 does not match num_features. You can silence this warning by not passing in num_features, which is not used because affine=False
  warnings.warn(
/ivy/ivy-integration-tests/ivy_transpiled_outputs/jax_outputs/torch/nn/modules/instancenorm.py:129: UserWarning: input's size at dim=1 does not match num_features. You can silence this warning by not passing in num_features, which is not used because affine=False
  warnings.warn(
/ivy/ivy-integration-tests/ivy_transpiled_outputs/jax_outputs/torch/nn/modules/instancenorm.py:129: UserWarning: input's size at dim=1 does not match num_features. You can silence this warning by not passing in num_features, which is not used because affine=False
  warnings.warn(
/ivy/ivy-integration-tests/ivy_transpiled_outputs/jax_outputs/torch/nn/modules/instancenorm.py:129: UserWarning: input's size at dim=1 does not match num_features. You can silence this warning by not passing in num_features, which is not used because affine=False
  warnings.warn(
/ivy/ivy-integration-tests/ivy_transpiled_outputs/jax_outputs/torch/nn/modules/instancenorm.py:129: UserWarning: input's size at dim=1 does not match num_features. You can silence this warning by not passing in num_features, which is not used because affine=False
  warnings.warn(
/ivy/ivy-integration-tests/ivy_transpiled_outputs/jax_outputs/torch/nn/modules/instancenorm.py:129: UserWarning: input's size at dim=1 does not match num_features. You can silence this warning by not passing in num_features, which is not used because affine=False
  warnings.warn(
/ivy/ivy-integration-tests/ivy_transpiled_outputs/jax_outputs/torch/nn/modules/instancenorm.py:129: UserWarning: input's size at dim=1 does not match num_features. You can silence this warning by not passing in num_features, which is not used because affine=False
  warnings.warn(
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/test_feature5.py::test_DeDoDe[jax-s2s-False] - KeyError: 'num_features'
FAILED kornia/test_feature5.py::test_DISK[jax-s2s-False] - AttributeError: 'list' object has no attribute 'keypoints'
=============================================================================== 2 failed, 8 passed in 1799.86s (0:29:59) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 4 items

kornia/geometry/test_liegroup.py ssss                                                                                                                                                            [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
========================================================================================== 4 skipped in 4.90s ==========================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 44 items

kornia/test_filters.py ...........................sssssssssssssssss                                                                                                                              [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
============================================================================= 27 passed, 17 skipped in 1843.26s (0:30:43) ==============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 13 items

kornia/test_metrics.py ...F.........                                                                                                                                                             [100%]

=============================================================================================== FAILURES ===============================================================================================
______________________________________________________________________________ test_mean_average_precision[jax-s2s-False] ______________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_mean_average_precision(target_framework, mode, backend_compile):
        trace_args = (
            [torch.tensor([[100, 50, 150, 100.]])],
            [torch.tensor([1.])],
            [torch.tensor([0.7])],
            [torch.tensor([[100, 50, 150, 100.]])],
            [torch.tensor([1.])],
            2,
        )
        trace_kwargs = {}
        test_args = (
            [torch.tensor([[50, 25, 75, 50], [100, 50, 150, 100.]])],
            [torch.tensor([1, 2.])],
            [torch.tensor([0.6, 0.8])],
            [torch.tensor([[50, 25, 75, 50], [100, 50, 150, 100.]])],
            [torch.tensor([1, 2.])],
            3,
        )
        kornia.metrics.mean_average_precision(*trace_args)
        kornia.metrics.mean_average_precision(*test_args)
        test_kwargs = {}
    
        # NOTE: this test fails due to the use of dynamic control flow; skipping
>       _test_function(
            kornia.metrics.mean_average_precision,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
            skip=True,
        )

kornia/test_metrics.py:118: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function mean_average_precision at 0x7f9b08aae4d0>
trace_args = ([Array([[100.,  50., 150., 100.]], dtype=float32)], [Array([1.], dtype=float32)], [Array([0.7], dtype=float32)], [Array([[100.,  50., 150., 100.]], dtype=float32)], [Array([1.], dtype=float32)], 2)
trace_kwargs = {}
test_args = ([Array([[ 50.,  25.,  75.,  50.],
       [100.,  50., 150., 100.]], dtype=float32)], [Array([1., 2.], dtype=float32)]...rray([[ 50.,  25.,  75.,  50.],
       [100.,  50., 150., 100.]], dtype=float32)], [Array([1., 2.], dtype=float32)], 3)
test_kwargs = {}, target = 'jax', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = True, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function mean_average_precision at 0x7f9b08aae4d0>, fn_name = 'kornia.metrics.mean_average_precision'
trace_args = ([Array([[100.,  50., 150., 100.]], dtype=float32)], [Array([1.], dtype=float32)], [Array([0.7], dtype=float32)], [Array([[100.,  50., 150., 100.]], dtype=float32)], [Array([1.], dtype=float32)], 2)
trace_kwargs = {}
test_args = ([Array([[ 50.,  25.,  75.,  50.],
       [100.,  50., 150., 100.]], dtype=float32)], [Array([1., 2.], dtype=float32)]...rray([[ 50.,  25.,  75.,  50.],
       [100.,  50., 150., 100.]], dtype=float32)], [Array([1., 2.], dtype=float32)], 3)
test_kwargs = {}, target = 'jax', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
>       orig_out = fn(*trace_args, **trace_kwargs)

helpers.py:335: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred_boxes = [Array([[100.,  50., 150., 100.]], dtype=float32)], pred_labels = [Array([1.], dtype=float32)], pred_scores = [Array([0.7], dtype=float32)]
gt_boxes = [Array([[100.,  50., 150., 100.]], dtype=float32)], gt_labels = [Array([1.], dtype=float32)], n_classes = 2, threshold = 0.5

    def mean_average_precision(
        pred_boxes: List[Tensor],
        pred_labels: List[Tensor],
        pred_scores: List[Tensor],
        gt_boxes: List[Tensor],
        gt_labels: List[Tensor],
        n_classes: int,
        threshold: float = 0.5,
    ) -> Tuple[Tensor, Dict[int, float]]:
        """Calculate the Mean Average Precision (mAP) of detected objects.
    
        Code altered from https://github.com/sgrvinod/a-PyTorch-Tutorial-to-Object-Detection/blob/master/utils.py#L271.
        Background class (0 index) is excluded.
    
        Args:
            pred_boxes: a tensor list of predicted bounding boxes.
            pred_labels: a tensor list of predicted labels.
            pred_scores: a tensor list of predicted labels' scores.
            gt_boxes: a tensor list of ground truth bounding boxes.
            gt_labels: a tensor list of ground truth labels.
            n_classes: the number of classes.
            threshold: count as a positive if the overlap is greater than the threshold.
    
        Returns:
            mean average precision (mAP), list of average precisions for each class.
    
        Examples:
            >>> boxes, labels, scores = torch.tensor([[100, 50, 150, 100.]]), torch.tensor([1]), torch.tensor([.7])
            >>> gt_boxes, gt_labels = torch.tensor([[100, 50, 150, 100.]]), torch.tensor([1])
            >>> mean_average_precision([boxes], [labels], [scores], [gt_boxes], [gt_labels], 2)
            (tensor(1.), {1: 1.0})
        """
        # these are all lists of tensors of the same length, i.e. number of images
        if not len(pred_boxes) == len(pred_labels) == len(pred_scores) == len(gt_boxes) == len(gt_labels):
            raise AssertionError
    
        # Store all (true) objects in a single continuous tensor while keeping track of the image it is from
        gt_images = []
        for i, labels in enumerate(gt_labels):
>           gt_images.extend([i] * labels.size(0))
E           TypeError: 'int' object is not callable

/opt/miniconda/envs/multienv/lib/python3.10/site-packages/kornia/metrics/mean_average_precision.py:49: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.metrics.mean_average_precision.mean_average_precision
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/test_metrics.py::test_mean_average_precision[jax-s2s-False] - TypeError: 'int' object is not callable
=============================================================================== 1 failed, 12 passed in 798.30s (0:13:18) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 19 items

kornia/geometry/test_camera.py .................ss                                                                                                                                               [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
============================================================================== 17 passed, 2 skipped in 889.26s (0:14:49) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 8 items

kornia/geometry/test_bbox.py ..F.....                                                                                                                                                            [100%]

=============================================================================================== FAILURES ===============================================================================================
___________________________________________________________________________________ test_bbox_to_mask[jax-s2s-False] ___________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_bbox_to_mask(target_framework, mode, backend_compile):
        trace_args = (
            torch.tensor([[[1., 1.], [3., 1.], [3., 2.], [1., 2.]]]),
            5,
            5,
        )
        trace_kwargs = {}
        test_args = (
            torch.tensor([[[2., 2.], [4., 2.], [4., 3.], [2., 3.]]]),
            6,
            6,
        )
        test_kwargs = {}
>       _test_function(
            kornia.geometry.bbox.bbox_to_mask,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/geometry/test_bbox.py:82: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function bbox_to_mask at 0x7f1b5c65c0d0>, trace_args = (tensor([[[1., 1.],
         [3., 1.],
         [3., 2.],
         [1., 2.]]]), 5, 5), trace_kwargs = {}
test_args = (tensor([[[2., 2.],
         [4., 2.],
         [4., 3.],
         [2., 3.]]]), 6, 6), test_kwargs = {}, target = 'jax', backend_compile = False, tolerance = 0.001, mode = 's2s'
skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function bbox_to_mask at 0x7f1b5c65c0d0>, fn_name = 'kornia.geometry.bbox.bbox_to_mask', trace_args = (tensor([[[1., 1.],
         [3., 1.],
         [3., 2.],
         [1., 2.]]]), 5, 5)
trace_kwargs = {}, test_args = (tensor([[[2., 2.],
         [4., 2.],
         [4., 3.],
         [2., 3.]]]), 6, 6), test_kwargs = {}, target = 'jax', backend_compile = False, tolerance = 0.001
deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
        graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
    
        if deterministic:
>           _to_numpy_and_allclose(orig_out, graph_out, tolerance=tolerance)

helpers.py:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

torch_x = tensor([[[0., 0., 0., 0., 0.],
         [0., 1., 1., 1., 0.],
         [0., 1., 1., 1., 0.],
         [0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.]]])
transpiled_x = Array([[[0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0.]]], dtype=float32), tolerance = 0.001

    def _to_numpy_and_allclose(torch_x, transpiled_x, tolerance=1e-3):
        orig_data = _nest_array_to_numpy(torch_x)
        transpiled_data = _nest_array_to_numpy(transpiled_x)
>       _check_allclose(orig_data, transpiled_data, tolerance=tolerance)

helpers.py:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[0., 0., 0., 0., 0.],
        [0., 1., 1., 1., 0.],
        [0., 1., 1., 1., 0.],
        [0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0.]]], dtype=float32)
y = array([[[0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0.]]], dtype=float32), tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
>           assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
E           AssertionError: numpy array values are not all close

helpers.py:26: AssertionError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.bbox.bbox_to_mask
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/geometry/test_bbox.py::test_bbox_to_mask[jax-s2s-False] - AssertionError: numpy array values are not all close
=============================================================================== 1 failed, 7 passed in 472.91s (0:07:52) ================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 8 items

kornia/test_image.py .F.FF.FF                                                                                                                                                                    [100%]

=============================================================================================== FAILURES ===============================================================================================
________________________________________________________________________________ test_PixelFormat[tensorflow-s2s-False] ________________________________________________________________________________

>   ???

IM.pyx:94: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

object = <enum 'ColorSpace'>

    def getsource(object):
        """Return the text of the source code for an object.
    
        The argument may be a module, class, method, function, traceback, frame,
        or code object.  The source code is returned as a single string.  An
        OSError is raised if the source code cannot be retrieved."""
>       lines, lnum = getsourcelines(object)

/opt/miniconda/envs/multienv/lib/python3.10/inspect.py:1147: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

object = <enum 'ColorSpace'>

    def getsourcelines(object):
        """Return a list of source lines and starting line number for an object.
    
        The argument may be a module, class, method, function, traceback, frame,
        or code object.  The source code is returned as a list of the lines
        corresponding to the object and the line number indicates where in the
        original source file the first line of code was found.  An OSError is
        raised if the source code cannot be retrieved."""
        object = unwrap(object)
>       lines, lnum = findsource(object)

/opt/miniconda/envs/multienv/lib/python3.10/inspect.py:1129: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

object = <enum 'ColorSpace'>

    def findsource(object):
        """Return the entire source file and starting line number for an object.
    
        The argument may be a module, class, method, function, traceback, frame,
        or code object.  The source code is returned as a list of all the lines
        in the file and the line number indexes a line in that list.  An OSError
        is raised if the source code cannot be retrieved."""
    
        file = getsourcefile(object)
        if file:
            # Invalidate cache if needed.
            linecache.checkcache(file)
        else:
            file = getfile(object)
            # Allow filenames in form of "<something>" to pass through.
            # `doctest` monkeypatches `linecache` module to enable
            # inspection, so let `linecache.getlines` to be called.
            if not (file.startswith('<') and file.endswith('>')):
>               raise OSError('source code not available')
E               OSError: source code not available

/opt/miniconda/envs/multienv/lib/python3.10/inspect.py:950: OSError

During handling of the above exception, another exception occurred:

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_PixelFormat(target_framework, mode, backend_compile):
        print("kornia.image.PixelFormat")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target_framework)
    
>       pixel_format = transpiled_kornia.image.PixelFormat(ColorSpace.rgb, 8)

kornia/test_image.py:39: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:225: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:322: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:310: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:297: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   I.InvalidObjectException: Unable to access the source code of the object 'ColorSpace' of type 'EnumMeta'. This may occur if the object is dynamically created, defined in a Jupyter notebook, or not saved to disk.
E   
E   Suggested actions:
E   - Ensure that the object is defined in a Python module or script that is saved to disk.
E   - If you're working in a Jupyter notebook, consider using the `%%writefile` magic command to save the code to a file.
E     For example:
E     ```
E     %%writefile my_module.py
E     class MyClass:
E         def __init__(self):
E             pass
E     ```
E   - After saving the object to a file, you can then import it and call `ivy.transpile`.
E   - If the object is dynamically created, consider saving its definition to disk before transpiling.
E   Original error: source code not available

IM.pyx:96: InvalidObjectException
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.image.PixelFormat
________________________________________________________________________________ test_ImageLayout[tensorflow-s2s-False] ________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_ImageLayout(target_framework, mode, backend_compile):
        print("kornia.image.ImageLayout")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target_framework)
    
>       layout = transpiled_kornia.image.ImageLayout(transpiled_kornia.image.ImageSize(3, 4), 3, transpiled_kornia.image.ChannelsOrder.CHANNELS_LAST)

kornia/test_image.py:64: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:230: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:153: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:162: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_ImageSize(height=3, width=4), name = '__class__', value = <class 'ivy_transpiled_outputs.tensorflow_outputs.kornia.image.base.tensorflow_ImageSize'>

>   ???
E   dataclasses.FrozenInstanceError: cannot assign to field '__class__'

<string>:4: FrozenInstanceError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.image.ImageLayout
___________________________________________________________________________________ test_Image[tensorflow-s2s-False] ___________________________________________________________________________________

>   ???

IM.pyx:94: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

object = <enum 'ColorSpace'>

    def getsource(object):
        """Return the text of the source code for an object.
    
        The argument may be a module, class, method, function, traceback, frame,
        or code object.  The source code is returned as a single string.  An
        OSError is raised if the source code cannot be retrieved."""
>       lines, lnum = getsourcelines(object)

/opt/miniconda/envs/multienv/lib/python3.10/inspect.py:1147: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

object = <enum 'ColorSpace'>

    def getsourcelines(object):
        """Return a list of source lines and starting line number for an object.
    
        The argument may be a module, class, method, function, traceback, frame,
        or code object.  The source code is returned as a list of the lines
        corresponding to the object and the line number indicates where in the
        original source file the first line of code was found.  An OSError is
        raised if the source code cannot be retrieved."""
        object = unwrap(object)
>       lines, lnum = findsource(object)

/opt/miniconda/envs/multienv/lib/python3.10/inspect.py:1129: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

object = <enum 'ColorSpace'>

    def findsource(object):
        """Return the entire source file and starting line number for an object.
    
        The argument may be a module, class, method, function, traceback, frame,
        or code object.  The source code is returned as a list of all the lines
        in the file and the line number indexes a line in that list.  An OSError
        is raised if the source code cannot be retrieved."""
    
        file = getsourcefile(object)
        if file:
            # Invalidate cache if needed.
            linecache.checkcache(file)
        else:
            file = getfile(object)
            # Allow filenames in form of "<something>" to pass through.
            # `doctest` monkeypatches `linecache` module to enable
            # inspection, so let `linecache.getlines` to be called.
            if not (file.startswith('<') and file.endswith('>')):
>               raise OSError('source code not available')
E               OSError: source code not available

/opt/miniconda/envs/multienv/lib/python3.10/inspect.py:950: OSError

During handling of the above exception, another exception occurred:

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_Image(target_framework, mode, backend_compile):
        print("kornia.image.Image")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target_framework)
    
        torch_data = torch.randint(0, 255, (3, 4, 5), dtype=torch.uint8)
        transpiled_data = _array_to_new_backend(torch_data, target_framework)
    
        # torch
        pixel_format = kornia.image.PixelFormat(
            color_space=ColorSpace.rgb,
            bit_depth=8,
        )
        layout = kornia.image.ImageLayout(
            image_size=kornia.image.ImageSize(4, 5),
            channels=3,
            channels_order=kornia.image.ChannelsOrder.CHANNELS_FIRST,
        )
        torch_img = kornia.image.Image(torch_data, pixel_format, layout)
    
        # transpiled
>       pixel_format = transpiled_kornia.image.PixelFormat(
            color_space=ColorSpace.rgb,
            bit_depth=8,
        )

kornia/test_image.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:229: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:322: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:310: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:297: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   I.InvalidObjectException: Unable to access the source code of the object 'ColorSpace' of type 'EnumMeta'. This may occur if the object is dynamically created, defined in a Jupyter notebook, or not saved to disk.
E   
E   Suggested actions:
E   - Ensure that the object is defined in a Python module or script that is saved to disk.
E   - If you're working in a Jupyter notebook, consider using the `%%writefile` magic command to save the code to a file.
E     For example:
E     ```
E     %%writefile my_module.py
E     class MyClass:
E         def __init__(self):
E             pass
E     ```
E   - After saving the object to a file, you can then import it and call `ivy.transpile`.
E   - If the object is dynamically created, consider saving its definition to disk before transpiling.
E   Original error: source code not available

IM.pyx:96: InvalidObjectException
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.image.Image
_____________________________________________________________________________ test_Image_from_dlpack[tensorflow-s2s-False] _____________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_Image_from_dlpack(target_framework, mode, backend_compile):
        print("kornia.image.Image.from_dlpack")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target_framework)
    
        x = np.ones((4, 5, 3))
>       img = transpiled_kornia.image.Image.from_dlpack(x.__dlpack__())
E       TypeError: 'classmethod' object is not callable

kornia/test_image.py:139: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.image.Image.from_dlpack
______________________________________________________________________________ test_Image_to_numpy[tensorflow-s2s-False] _______________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_Image_to_numpy(target_framework, mode, backend_compile):
        print("kornia.image.Image.to_numpy")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target_framework)
    
        data = np.ones((4, 5, 3), dtype=np.uint8)
>       img = transpiled_kornia.image.Image.from_numpy(data, color_space=ColorSpace.rgb)
E       TypeError: 'classmethod' object is not callable

kornia/test_image.py:152: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.image.Image.to_numpy
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/test_image.py::test_PixelFormat[tensorflow-s2s-False] - I.InvalidObjectException: Unable to access the source code of the object 'ColorSpace' of type 'EnumMeta'. This may occur if the...
FAILED kornia/test_image.py::test_ImageLayout[tensorflow-s2s-False] - dataclasses.FrozenInstanceError: cannot assign to field '__class__'
FAILED kornia/test_image.py::test_Image[tensorflow-s2s-False] - I.InvalidObjectException: Unable to access the source code of the object 'ColorSpace' of type 'EnumMeta'. This may occur if the objec...
FAILED kornia/test_image.py::test_Image_from_dlpack[tensorflow-s2s-False] - TypeError: 'classmethod' object is not callable
FAILED kornia/test_image.py::test_Image_to_numpy[tensorflow-s2s-False] - TypeError: 'classmethod' object is not callable
=============================================================================== 5 failed, 3 passed in 246.49s (0:04:06) ================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 1 item

kornia/test_tracking.py F                                                                                                                                                                        [100%]

=============================================================================================== FAILURES ===============================================================================================
_____________________________________________________________________________ test_HomographyTracker[tensorflow-s2s-False] _____________________________________________________________________________

inp = <KerasVariable shape=(5, 1, 1), dtype=float32, path=variable>, query = slice(None, None, None)
val = <tf.Tensor: shape=(1, 5), dtype=float32, numpy=
array([[0.1190625 , 0.2311236 , 0.29962778, 0.2311236 , 0.1190625 ]],
      dtype=float32)>, kwargs = {}

    @functools.wraps(fn)
    def wrapper(inp, query, val, **kwargs):
        try:
>           inp.__setitem__(query, val)
E           AttributeError: 'Variable' object has no attribute '__setitem__'. Did you mean: '__getitem__'?

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:233: AttributeError

During handling of the above exception, another exception occurred:

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_HomographyTracker(target_framework, mode, backend_compile):
        print("kornia.tracking.HomographyTracker")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledHomographyTracker = ivy.transpile(kornia.tracking.HomographyTracker, source="torch", target=target_framework)
    
        tracker = kornia.tracking.HomographyTracker()
>       transpiled_tracker = TranspiledHomographyTracker()

kornia/test_tracking.py:33: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_HomographyTracker(), initial_matcher = None, fast_matcher = None, ransac = None, minimum_inliers_num = 30

    def __init__(
        self,
        initial_matcher=None,
        fast_matcher=None,
        ransac=None,
        minimum_inliers_num=30,
    ):
        from ..feature.integrated import tensorflow_LocalFeatureMatcher
        from ..feature.integrated import tensorflow_GFTTAffNetHardNet
        from ..feature.matching import tensorflow_DescriptorMatcher
        from ..feature.loftr.loftr import tensorflow_LoFTR
        from ..geometry.ransac import tensorflow_RANSAC
    
        self.super___init__(
            initial_matcher=initial_matcher,
            fast_matcher=fast_matcher,
            ransac=ransac,
            minimum_inliers_num=minimum_inliers_num,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        self.initial_matcher = initial_matcher or tensorflow_LocalFeatureMatcher(
>           tensorflow_GFTTAffNetHardNet(3000),
            tensorflow_DescriptorMatcher("smnn", 0.95),
        )

ivy_transpiled_outputs/tensorflow_outputs/kornia/tracking/planar_tracker.py:60: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_GFTTAffNetHardNet object at 0x7fc5cd8c3d60>, args = (3000,), kwargs = {}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_GFTTAffNetHardNet object at 0x7fc5cd8c3d60>, num_features = 3000, upright = False, device = 'cpu'
config = {'nms_size': 15, 'pyramid_levels': 4, 's_mult': 22.0, 'scale_factor_levels': 1.4142135623730951, ...}

    @tensorflow_store_config_info
    def __init__(
        self,
        num_features=8000,
        upright=False,
        device=tensorflow_device_frnt("cpu"),
        config=tensorflow_get_default_detector_config(),
    ):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_to_frnt_
        from .scale_space_detector import tensorflow_MultiResolutionDetector
        from .responses import tensorflow_CornerGFTT
        from .orientation import tensorflow_PassLAF
        from .orientation import tensorflow_LAFOrienter
        from .affine_shape import tensorflow_LAFAffNetShapeEstimator
    
        detector = tensorflow_to_frnt_(
            tensorflow_MultiResolutionDetector(
                tensorflow_CornerGFTT(),
                num_features,
                config,
                ori_module=tensorflow_PassLAF()
                if upright
>               else tensorflow_LAFOrienter(19),
                aff_module=tensorflow_LAFAffNetShapeEstimator(True).eval(),
            ),
            device,
        )

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/integrated.py:352: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'tensorflow_LAFOrienter' object has no attribute 'angle_detector'") raised in repr()] tensorflow_LAFOrienter object at 0x7fc5cd7de9e0>, args = (19,), kwargs = {}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'tensorflow_LAFOrienter' object has no attribute 'angle_detector'") raised in repr()] tensorflow_LAFOrienter object at 0x7fc5cd7de9e0>, patch_size = 19, num_angular_bins = 36
angle_detector = None

    @tensorflow_store_config_info
    def __init__(self, patch_size=32, num_angular_bins=36, angle_detector=None):
        self.super___init__(
            patch_size=patch_size,
            num_angular_bins=num_angular_bins,
            angle_detector=angle_detector,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        self.patch_size = patch_size
        self.num_ang_bins = num_angular_bins
        self.angle_detector: typing.Any
        if angle_detector is None:
>           self.angle_detector = tensorflow_PatchDominantGradientOrientation(
                self.patch_size, self.num_ang_bins
            )

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/orientation.py:387: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_PatchDominantGradientOrientation(patch_size=19, num_ang_bins=36, eps=1e-08), args = (19, 36), kwargs = {}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_PatchDominantGradientOrientation(patch_size=19, num_ang_bins=36, eps=1e-08), patch_size = 19, num_angular_bins = 36, eps = 1e-08

    @tensorflow_store_config_info
    def __init__(self, patch_size=32, num_angular_bins=36, eps=1e-08):
        from ..filters.sobel import tensorflow_SpatialGradient
        from ...torch.nn.modules.conv import tensorflow_Conv1d
        from ...ivy.functional.backends.tensorflow.general import tensorflow_set_item
        from ..filters.kernels import tensorflow_get_gaussian_discrete_kernel1d
        from ..filters.kernels import tensorflow_get_gaussian_kernel2d
    
        self.super___init__(
            patch_size=patch_size,
            num_angular_bins=num_angular_bins,
            eps=eps,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        self.patch_size = patch_size
        self.num_ang_bins = num_angular_bins
        self.gradient = tensorflow_SpatialGradient("sobel", 1)
        self.eps = eps
        self.angular_smooth = tensorflow_Conv1d(
            1, 1, kernel_size=5, padding=2, bias=False, padding_mode="circular"
        )
>       self.angular_smooth.weight = tensorflow_set_item(
            self.angular_smooth.weight,
            slice(None, None, None),
            tensorflow_get_gaussian_discrete_kernel1d(5, 1.6),
        )

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/orientation.py:178: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

inp = <KerasVariable shape=(5, 1, 1), dtype=float32, path=variable>, query = slice(None, None, None)
val = <tf.Tensor: shape=(1, 5), dtype=float32, numpy=
array([[0.1190625 , 0.2311236 , 0.29962778, 0.2311236 , 0.1190625 ]],
      dtype=float32)>, kwargs = {}

    @functools.wraps(fn)
    def wrapper(inp, query, val, **kwargs):
        try:
            inp.__setitem__(query, val)
            res = inp
        except IndexError:
            raise
        except Exception:
>           res = fn(inp, query, val, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:238: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (<KerasVariable shape=(5, 1, 1), dtype=float32, path=variable>, slice(None, None, None), <tf.Tensor: shape=(1, 5), dtype=float32, numpy=
array([[0.1190625 , 0.2311236 , 0.29962778, 0.2311236 , 0.1190625 ]],
      dtype=float32)>)
kwargs = {}, handle_mixed_in_backend = True

    @functools.wraps(fn)
    def _handle_partial_mixed_function(*args, **kwargs):
        handle_mixed_in_backend = False
        if not hasattr(fn, "partial_mixed_handler"):
            handle_mixed_in_backend = True
        else:
            compos = getattr(fn, "compos")
            condition = getattr(fn, "partial_mixed_handler")
        if handle_mixed_in_backend or condition(*args, **kwargs):
>           return fn(*args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/func_wrapper.py:173: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[0.]],

       [[0.]],

       [[0.]],

       [[0.]],

       [[0.]]], dtype=float32), query = slice(None, None, None)
val = array([[0.1190625 , 0.2311236 , 0.29962778, 0.2311236 , 0.1190625 ]],
      dtype=float32)

    @tensorflow_handle_set_item
    @tensorflow_handle_partial_mixed_function
    def tensorflow_set_item(
        x: Union[tensorflow.Tensor, tensorflow.Variable],
        query: Union[tensorflow.Tensor, tensorflow.Variable, Tuple],
        val: Union[tensorflow.Tensor, tensorflow.Variable],
        /,
        *,
        copy: Optional[bool] = False,
    ):
        if tensorflow.is_tensor(x):
            x = x.numpy()
        if tensorflow.is_tensor(val):
            val = val.numpy()
        if isinstance(query, (tensorflow.Tensor, tensorflow.Variable)):
            query = query.numpy()
        elif isinstance(query, tuple):
            query = tuple(
                q.numpy() if isinstance(q, (tensorflow.Tensor, tensorflow.Variable)) else q
                for q in query
            )
>       x[query] = val
E       ValueError: could not broadcast input array from shape (1,5) into shape (5,1,1)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/backends/tensorflow/general.py:109: ValueError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.tracking.HomographyTracker
----------------------------------------------------------------------------------------- Captured stderr call -----------------------------------------------------------------------------------------
Downloading: "https://github.com/ducha-aiki/affnet/raw/master/pretrained/AffNet.pth" to /root/.cache/torch/hub/checkpoints/AffNet.pth

  0%|          | 0.00/332k [00:00<?, ?B/s]
100%|██████████| 332k/332k [00:00<00:00, 13.7MB/s]
Downloading: "https://github.com/DagnyT/hardnet/raw/master/pretrained/train_liberty_with_aug/checkpoint_liberty_with_aug.pth" to /root/.cache/torch/hub/checkpoints/checkpoint_liberty_with_aug.pth

  0%|          | 0.00/5.10M [00:00<?, ?B/s]
100%|██████████| 5.10M/5.10M [00:00<00:00, 88.8MB/s]
Downloading: "http://cmp.felk.cvut.cz/~mishkdmy/models/loftr_outdoor.ckpt" to /root/.cache/torch/hub/checkpoints/loftr_outdoor.ckpt

  0%|          | 0.00/44.2M [00:00<?, ?B/s]
  0%|          | 128k/44.2M [00:00<02:34, 299kB/s]
  1%|          | 256k/44.2M [00:00<01:33, 492kB/s]
  1%|          | 512k/44.2M [00:00<00:51, 885kB/s]
  2%|▏         | 896k/44.2M [00:00<00:31, 1.44MB/s]
  4%|▍         | 1.75M/44.2M [00:01<00:15, 2.91MB/s]
  8%|▊         | 3.50M/44.2M [00:01<00:07, 5.84MB/s]
 15%|█▍        | 6.50M/44.2M [00:01<00:03, 10.6MB/s]
 21%|██▏       | 9.50M/44.2M [00:01<00:02, 13.9MB/s]
 28%|██▊       | 12.5M/44.2M [00:01<00:02, 16.2MB/s]
 35%|███▌      | 15.5M/44.2M [00:01<00:01, 17.8MB/s]
 41%|████      | 18.1M/44.2M [00:01<00:01, 18.1MB/s]
 48%|████▊     | 21.0M/44.2M [00:02<00:01, 18.9MB/s]
 54%|█████▍    | 24.0M/44.2M [00:02<00:01, 19.7MB/s]
 61%|██████    | 27.0M/44.2M [00:02<00:00, 20.2MB/s]
 68%|██████▊   | 30.0M/44.2M [00:02<00:00, 20.6MB/s]
 74%|███████▍  | 32.8M/44.2M [00:02<00:00, 20.3MB/s]
 81%|████████  | 35.6M/44.2M [00:02<00:00, 20.4MB/s]
 87%|████████▋ | 38.6M/44.2M [00:02<00:00, 20.7MB/s]
 94%|█████████▍| 41.6M/44.2M [00:03<00:00, 21.0MB/s]
100%|██████████| 44.2M/44.2M [00:03<00:00, 14.8MB/s]
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/test_tracking.py::test_HomographyTracker[tensorflow-s2s-False] - ValueError: could not broadcast input array from shape (1,5) into shape (5,1,1)
==================================================================================== 1 failed in 467.05s (0:07:47) =====================================================================================

